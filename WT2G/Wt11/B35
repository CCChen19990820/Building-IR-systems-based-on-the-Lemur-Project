<DOC>
<DOCNO>WT11-B35-1</DOCNO>
<DOCOLDNO>IA013-000136-B028-253</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.28.html 128.240.150.127 19970217035754 text/html 29572
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:56:20 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 28</TITLE>
<LINK REL="Prev" HREF="/Risks/10.27.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.29.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 28</H1>
<H2> Friday 31 August 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Re: Lawsuit over specification error 
</A>
<DD>
<A HREF="#subj1.1">
Pete Mellor
</A><br>
<A HREF="#subj1.2">
 Martyn Thomas
</A><br>
<A HREF="#subj1.3">
 PM
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer Unreliability and Social Vulnerability: synopsis 
</A>
<DD>
<A HREF="#subj2.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer Unreliability and Social Vulnerability: critique 
</A>
<DD>
<A HREF="#subj3.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Copyright Policy 
</A>
<DD>
<A HREF="#subj4.1">
Daniel B Dobkin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Discover Card 
</A>
<DD>
<A HREF="#subj5.1">
Brian M. Clapper
</A><br>
<A HREF="#subj5.2">
 Gordon Keegan
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Lawsuit over specification error
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 10:14:37 PDT
</i><PRE>

Martyn Thomas in <A HREF="/Risks/10.27.html">RISKS-10.27</A> writes:

&gt; ... on this evidence, a simulator used for
&gt; crew training in emergency procedures is *itself* a safety-critical system.

Safety-*related*, I would say, but not safety-*critical*. The usual definition
of safety-critical is that a system failure results in catastrophe. The argument
would be over how directly the catastrophe results from the failure. In this
case, the 'accident chain' is fairly tenuous.

&gt; (Presumably it should therefore require certification in the same way as an
&gt; in-flight system of equivalent criticality.

I agree that it requires certification, even though it is not safety-critical
in the strict sense. I do not think it should require to be certified to a
10~-9 maximum probability of failure per hour, as airborne safety-critical 
systems are, however. (This is unrealistic where software is concerned anyway.)
Also 'failure' means different things in the two cases. The airborne system
fails when it malfunctions and the aircraft crashes. On the simulator, one
would often simulate such a 'failure' and the resulting crash, to see if the
pilot could save the aircraft in those circumstances. The simulator fails
when it does not faithfully mimic the behaviour of the real aircraft.

&gt; Does anyone know the certification requirements for simulators?)

No, but I am certain they are not covered by RTCA/DO-178A, for example, which
applies purely to software in airborne systems. Whether there is a section of
the more general Federal Aviation Regulations which applies to ground-based
ancillary systems I am not sure, but I suspect there is nothing to cover
simulators, since they are not directly involved in controlling flight.

If this is the case, then the user of a simulator is at the mercy of the
developer's internal quality assurance procedures.

Peter Mellor, Centre for Software Reliability, City University, Northampton
Sq.,London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Lawsuit over specification error
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 11:47:24 BST
</i><PRE>

Peter Mellor replies to my comment in RISKS (my original lines are "&gt;" his
are ":" ...

: &gt; ... on this evidence, a simulator used for
: &gt; crew training in emergency procedures is *itself* a safety-critical system.
: 
: Safety-*related*, I would say, but not safety-*critical*. The usual definition
: of safety-critical is that a system failure results in catastrophe. The
: argument would be over how directly the catastrophe results from the failure.
: In this case, the 'accident chain' is fairly tenuous.

I disagree (my comments are on the *principle*; I am not advising the
lawyers in this particular case!)

Firstly, if crew are trained to react in a way which is likely to be fatal
in an emergency, then the training *causes* the fatality in that emergency.
This is a direct link. You cannot expect crew to do better than their
training under the stress of an emergency.

Secondly, there is a class of in-flight systems which "increase crew
workload", with defined failure-rate requirements. The training simulator
would seem directly equivalent to these systems, in that crew might be
expected to be able to overcome faulty training by cross-checking with other
training and basic airmanship - but the workload could be significantly
higher, and you would not expect crew to have time to react in this way in
an emergency.
: 
: &gt; (Presumably it should therefore require certification in the same way as an
: &gt; in-flight system of equivalent criticality.
			^^^^^^^^^^^^^^^^^^^^^^
Not 10^-9, but some lower figure, as defined in DO-178a.

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<HR><H3><A NAME="subj1.3">
Re^3: Lawsuit over specification error
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 14:52:19 PDT
</i><PRE>

I don't think that Martyn and I have a serious disagreement here. 

In particular, I agree that: 

&gt; You cannot expect crew to do better than their
&gt; training under the stress of an emergency.

and therefore I *basically* agree with Martyn when he says:

&gt;:&gt; (Presumably it should therefore require certification in the same way as an
&gt;:&gt; in-flight system of equivalent criticality.
&gt;			^^^^^^^^^^^^^^^^^^^^^^
&gt; Not 10^-9, but some lower figure, as defined in DO-178a.
                                    ^^^^^^^^^^^^^^^^^^^^^^(see below)

However:

As I stated previously, we are certifying different functions. With a 
safety-critical airborne system, we are certifying that it has a certain
maximum probability of crashing the aircraft. With a simulator, we are
certifying that it has a certain maximum probability of not behaving as
the real aircraft behaves.

It would be unrealistic and unreasonable to demand that a simulator be 
certified to the same high reliability (1 - 10^-9) as a critical airborne 
system.

It is in any case impossible to certify any system containing software to a
reliability of (1 - 10^-9), even if it *is* a critical airborne system.

RTCA/DO-178A ('Software Considerations in Airborne Systems and Equipment
Certification') does *not* define any reliability figures. It is merely a
set of guidelines defining quality assurance practices for software.
Regulatory approval depends upon the developer supplying certain documents 
(e.g., software test plan, procedures and results) to show that the guidelines 
have been followed.

I will return to this last point at length in the near future. Watch this
space.

Peter Mellor, Centre for Software Reliability, City University, Northampton
Sq.,London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer Unreliability and Social Vulnerability: synopsis
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 12:44:12 PDT
</i><PRE>

Synopsis of: Forester, T., &amp; Morrison, P. Computer Unreliability and
Social Vulnerability, Futures, June 1990, pages 462-474.

Abstract (quoted): 

Many have argued that industrial societies are becoming more 
technology-dependent and are thus more vulnerable to technology failures.
Despite the pervasiveness of computer technology, little is known about computer
failures, except perhaps that they are all too common. This article analyses
the sources of computer unreliability and reviews the extent and cost of
unreliable computers. Unlike previous writers, the authors argue that digital 
computers are inherently unreliable for two reasons: first, they are prone to 
total rather than partial failure; and second, their enormous complexity
means that they can never be thoroughly tested before use. The authors then
describe various institutional attempts to improve reliability and possible
solutions proposed by computer scientists, but they conclude that as yet
none is adequate. Accordingly, they recommend that computers should not be
used in life-critical applications.

Synopsis of paper:

The paper is introduced by a series of examples of disasters, some to do with
communications kit and some with computers, covering external causes and
internal system failures, and accidental and malicious actions, e.g. sabotage
of telephone cables in Sydney in Nov.'87, fire in Setagaya telephone office
(Japan) in Nov.'84, overwriting of Exxon's files relating to the Alaskan oil
spill in July '89.

The vulnerability of society to such failures is further underlined by a
discussion of 'The problem of computer unreliability: sources extent and cost'.
System failures can be caused by external factors (flood, fire, etc.), and
human error or misuse, but many more are due to computer malfunction, which
can be classified as hardware or software failure. Hardware failures are
usually due to failures of computer chips, e.g. the SAC false alert in June '80.
However most computer malfunctions are due to software failure. Many examples
are given of accidents, loss and disruption due to software failure in
military, space, civilian air traffic control, medicine, and finance, and of
cost overrun during software development. Famous examples cited are the loss
of Mariner 18 and the Bank of New York disaster in Nov.'85. Reports from
Price Waterhouse and Logica are mentioned as stating that software failure
costs UK industry US$900 million a year. Finally the case of Julie Engle, who
died after an overdose of painkiller was prescribed by an automated dispensing
machine, is reported as an example of how a fairly simple AI system can fail
with disastrous consequences, and the authors ask what could happen with the
really complex systems now envisaged.

In discussing 'Why computers are so unreliable', the authors complain that
previous studies have failed to highlight hardware or software failure as a
source of system malfunction. Their contention is that computers are inherently
unreliable because they are prone to catastrophic failure, and they are too
complex to be tested thoroughly. The Therac-25 and Blackhawk helicopter
accidents are given as examples of catastrophic failure. Digital computers are
discrete state devices, with billions of possible internal states, each of
which is a potential error point. Each internal state depends on the previous
one, and if any execution of an internal state results in an 'incorrect' state,
sudden erratic behaviour or total failure will result. In contrast, although
analogue devices have infinitely many states, most of their behaviour is
*continuous*, so that there are few situations in which they will jump from
working perfectly to failing totally. Furthermore, the enormous number of
possible internal states in a discrete computer system means that it is
impossible to know or predict, and hence impossible to test, them all.
Attempts at repair of computer systems often introduce more errors.  Bug-free
programs cannot be guaranteed, as illustrated by lack of software warranties,
or explicit disclaimers.

'What are computer scientists doing about it?': Computer system reliability
has traditionally been assessed by estimating the probability that hardware or
software will fail based on statistics of failures observed over operating time.
This confirms that programming is still a 'black art', a creative but hit and
miss activity undertaken in an unregulated fashion by people of whom no
minimum standard of education is required. This is likely to change following
the publication of the draft defence standard 00-55 by the MoD in the UK in
May 1989. The DoD in the US are not doing anything similar, though the 
International Civil Aviation Organisation is planning to go to formal methods.
The improvement of software has until now depended upon 'software engineering'
under four headings: 

a) structured programming and associated HOLs,
b) programming environments providing version and modification control,
c) program verification and derivation (proof of correctness of code and
   intermediate specifications respectively), and
d) human management.

a) and b) will not give the order of magnitude improvement required.
c) can only be applied to small programs, and is better described as 'proof of
relative consistency' rather than 'proof of correctness', since it takes no
account of situations not foreseen in the specification.

Conclusion (quoted):

We are therefore forced to conclude that the construction of software is a
complex and difficult process and that existing techniques of software
engineering do not as yet provide software of assured quality and reliability.
In the case of large, complex systems to which we entrust major social
responsibilities and sometimes awesome energies, this is extremely worrying.
Nor is the situation likely to improve in the short term: computer
unreliability will remain a major source of social vulnerability for some time
to come.  Accordingly, we recommend that computers should not be entrusted with
life-critical applications now, and should be only if reliability improves
dramatically in the future.

Given the evidence presented here, several ethical issues also emerge for
people in the computer industry. For example, when programmers and software
engineers are asked to build systems which have life-critical applications,
should they be more honest about the dangers and limitations? Are computer
professionals under an obligation if a system fails: for example, if a patient
dies on an operating table because of faulty software, is the programmer guilty
of manslaughter, or malpractice, or neither? What is the ethical status of
existing warranties and disclaimers? How is it that the computer industry
almost alone is able to sell products which cannot be guaranteed against
failure?

These are the kinds of questions that should be raised with governments,
computer purchasers and the wider public as a matter of urgency, because
computer vendors and the software industry themselves are most unlikely to 
publicize the serious shortcomings of their products.

Peter Mellor, Centre for Software Reliability, City University, Northampton
Sq.,London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer Unreliability and Social Vulnerability: critique
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 21:03:31 PDT
</i><PRE>

Ref.: Forester, T., &amp; Morrison, P.: "Computer Unreliability and
      Social Vulnerability", Futures, June 1990, pages 462-474.

The original item (<A HREF="/Risks/10.24.html">RISKS-10.24</A>), taken from the August 1990 _World_Press_Review,
was a very short and over-simplified summary of this paper, and included one
gross inaccuracy that the authors were not guilty of (22 fatal Blackhawk 
helicopter crashes, instead of the true figure of 5 crashes resulting in 22
deaths), as Perry Morrison himself pointed out in <A HREF="/Risks/10.26.html">RISKS-10.26</A>.

In my previous mailing, I provided what I hope is a fair synopsis of this paper,
accurately representing the views of the authors, and without allowing my own 
opinions to intrude. (I quoted the abstract and conclusions in full.)

The following is my own reaction to the paper:-

The authors are basically on the side of the angels, and I agree with a lot of
what they say. (They also cite one of my own articles, so appealing to my
vanity and making it even more difficult for me to be critical! :-) However,
bearing this in mind, I would like to raise some criticisms.

An enormous number of CAD/CAM incidents (Computer Aided Disaster/Computer
Assisted Mayhem :-) are retold. Some of these are not directly relevant to the
authors' main point, which is that the activation of faults, unintentionally
introduced into their design, is now one of the most important reasons for the
failure of complex hardware/software systems (a point with which I entirely
agree). They include deliberate sabotage of hardware, malicious alteration of
data, accidents (e.g., fire) external to the system, and physical hardware
component failure (e.g., broken wires). In considering the social impact of the
failure of complex systems, such causes must not be ignored, but the authors
confuse the issue by not distinguishing these events clearly from failures due
purely to design faults.

The incidents could have been more clearly described by classifying them 
according to:

 - application area (military, banking, etc.), 
 - cause (code fault, bad specification, hardware failure, interference, etc.), 
 - effect (system crash, data corruption, spurious signal, etc.), and
 - cost ($5 million, 22 lives, etc.).

The authors do not make it clear initially which of two different meanings of 
'catastrophic' they intend:

 a) sudden and unpredictable, 'anything can happen', and
 b) having appalling consequences.

The first is a classification of the effect (which I prefer to call a 'wild
failure' to avoid confusion), and the second is a measure of the cost. For
example, when arguing that computers are inherently unreliable because they are
prone to 'catastrophic failure', they quote the Blackhawk example. The cause of
this series of accidents was eventually traced to electromagnetic interference,
as the authors state. While it is probably true that only a *digital*
fly-by-wire system would exhibit a wild mode of failure in response to EMI, it
is not until half-way down the next page, where the authors point out that
digital systems have far more discontinuities than analogue systems, that it
becomes clear that they are using 'catastrophic' in sense a), and not in sense
b).

The authors are right to claim that computer systems are too complex to be
tested thoroughly, if by this they mean 'exhaustively'. It is apparent from
their example of a system monitoring 100 binary signals that they do mean this.
The argument, and the arithmetic supporting it, are unconvincing, however. It
is not generally true that a different path through a program will be executed
for every possible combination of inputs, therefore the derivation of 1.27 x
10^34 internal states (2^100 or 1.27 x 10^30 input combinations, multiplied by
an arbitrarily assumed 10^4 possible paths) is not valid. On the other hand,
knowing that execution is along a given path is insufficient.  *Where* one is
on the path would also affect the internal state. There may be *more* than 1.27
x 10^34 internal states! The problem is that 'internal state' is not defined.

Exhaustive testing in this sense is well known to be impossible. Even in
modestly complex systems one can only test a representative sample of inputs.
Provided the selected sample is realistic, one can, however obtain a reasonable
degree of confidence that a reliability target has been reached, but *only if
the target is not too high*.

Later in this argument, there is further confusion between two types of
'modification':

  i) changes to a system to simulate exception conditions during testing, and
 ii) changes to a system to correct faults found in test or operation.

The authors slip from i) to ii) without, apparently, being aware of it. As a 
result, there is a non-sequitur, although the final points, that attempts to
remove faults have a high probability of introducing other faults, and that
guaranteed bug-free programs are impossible, are quite correct.

In the section on 'What are computer scientists doing about it?' there is
another non-sequitur (quoted text prefixed by '&gt;'):

&gt; Like many computer scientists, he [Peter Mellor] advocates the application
&gt; of statistical principles to software quality, so that, for example, it may
&gt; be more acceptable to have many infrequent bugs rather than a small number
&gt; of very frequent ones.

This point was originally made by Bev Littlewood. I still advocate it, but it
needs clarifying. We value a system for the function it performs, and 
therefore we are interested in its reliability, defined as: the probability 
that it will not fail (i.e. deviate from its required function) for a given
period of operation under given conditions. (The authors quote this definition,
but omit the 'not' - obviously a typo! :-) The program with many bugs, each of
which causes failure infrequently, may be much less likely to fail than one with
few bugs, each of which causes failure frequently. In that case it will be more 
acceptable, since it is more reliable. The only 'principle' involved here is 
that reliability is an important attribute of software quality, which the 
authors also affirm. They continue:

&gt; This merely confirms the view that programming is a 'black art' rather than
&gt; a rigorous science - a highly creative endeavour which is also hit and miss.

Does it? Why?? I see no logical connection here at all. "We cannot control what
we cannot measure" [de Marco]. If we wish to control software development to
achieve more reliable systems, we must begin by being able to measure
reliability. To make such measurements using sound statistical techniques on
well-defined data moves programming away from being a 'black art' and towards
being an engineering discipline.

If the authors are pointing out that this kind of 'black-box' statistical
reliability assessment gives no guidance before development as to what effect
particular design methods will have on reliability, I agree, but we must be
able to measure first, in order to build up a body of experience regarding
their effect.

Anyway, end of whinge. I agree with much of what the authors say, particularly
regarding the inability of current methods to deliver ultra-reliable software.
Ultra-reliability, of the order 1 - 10^-9, is also impossible to assess. (If
the failure rate is high enough to be measured, then it is too high!) For many
applications, however, modest reliability is sufficient, and this can be both
achieved and measured right now. The moot point is whether the authors' main
conclusion is too strong: that computers should not be used where life is at
stake.

At which point, I throw the motion open for debate.

Peter Mellor, Centre for Software Reliability, City University, Northampton Sq.,
London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Copyright Policy (reply to Gene Spafford)
</A>
</H3>
<address>
Daniel B Dobkin 
&lt;<A HREF="mailto:dbd@marbury.gba.nyu.edu">
dbd@marbury.gba.nyu.edu
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 14:28:19 EDT
</i><PRE>

[I acknowledge this is not the best forum for this, but there is a
 RISK, far more evident on other newsgroups, when people make sweeping
 statements about the law based on popular misconceptions.  There is
 another RISK inherent when judges have to make decisions on technical
 matters without understanding the technology -- and when those
 decisions are based on arguments made by lawyers who don't understand
 the technology, either.]

First, the disclaimer: I'm not a lawyer, either, but as a full-time
programmer and part-time law student (sorry), I felt compelled to
respond to Gene Spafford when he wrote,

      The purpose of copyright is to protect the commercial interest of the
      copyright holder (author or publisher).

Don't take what I say as legal advice, either; it's an explanation of
the policy underpinnings of copyright, as I understand them:

The purpose of copyright is NOT to protect the commercial interest of
the copyright holder, author, publisher, artist, or anything else.
Its sole purpose is to promote innovation and creativity; granting the
author/artist a limited monopoly interest (exclusive rights for some
definite period), it is reasoned, will encourage people to be creative
and society will reap the benefits.

To a lot of people this sounds like the sort of semantic quibbling (1)
which doesn't mean much; and (2) for which lawyers typically
overcharge.  (It sounds that way to me at times.)  Please think about
it for a moment: there is really a world of difference between the
two.  The one can encourage lawsuits based on, say, "software look and
feel", while the other has great potential to limit them.

\dbd, Stern School of Business, New York University

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Discover Card
</A>
</H3>
<address>
Brian M. Clapper 
&lt;<A HREF="mailto:clapper@NADC.NADC.NAVY.MIL">
clapper@NADC.NADC.NAVY.MIL
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 09:19:26 -0400
</i><PRE>

Will Martin points out that the card does come with a PIN.  He is correct; I
found that out after I sent my message.  I apologize for the error.  However,
one does not need a PIN to access the on-line service I previously described.

Also Mr. Martin mentions that his card has no 800 number on the back.  Quite
possible.  My card is brand new.  The number I dialed was 1-800-347-2683.
Discover's mnemonic for this same number is 1-800-DISCOVER.  That number (in
both incarnations) is imprinted on the back of my card, along with the legend
"24-HOUR SERVICE".

Brian Clapper, clapper@nadc.navy.mil

P.S. My apologies for any problems our mailers caused.  We're slowly switching
to a new set-up, and we sometimes have trouble with sendmail's oh-so-friendly
address rewriting rules.      
                                                         [Join the Club.  PGN]

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Discover card...
</A>
</H3>
<address>
Gordon Keegan 
&lt;<A HREF="mailto:C145GMK@UTARLG.UTARL.EDU">
C145GMK@UTARLG.UTARL.EDU
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 10:44 CDT
</i><PRE>

        Some time ago I received notification from Discover that
        there was now an 800 number available with automated
        account information available.  It's 1-800-DISCOVER
        (800-347-2683).  The computer on the other end has you
        key in your account number followed by the # key.
        No PIN is required for this.  You only need the PIN
        if you are getting a cash advance at an ATM.

        The 858-5588 number has been inactive for about a year now.

Gordon Keegan, U.Texas, Arlington c145gmk@utarlg.BITNET THEnet UTARLG::C145GMK 
UUCP: ...!{ames,sun,texbell,uunet}!utarlg.arl.utexas.edu!c145gmk

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-2</DOCNO>
<DOCOLDNO>IA013-000136-B028-270</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.29.html 128.240.150.127 19970217035804 text/html 17142
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:56:36 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 29</TITLE>
<LINK REL="Prev" HREF="/Risks/10.28.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.30.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 29</H1>
<H2> Saturday 1 September 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  What is "safety-critical"? 
</A>
<DD>
<A HREF="#subj1.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Computer Unreliability and Social Vulnerability 
</A>
<DD>
<A HREF="#subj2.1">
David Gillespie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks of selling/buying used computers 
</A>
<DD>
<A HREF="#subj3.1">
Fernando Pereira
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Accidental disclosure of non-published telephone number 
</A>
<DD>
<A HREF="#subj4.1">
Peter Jones
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
What is "safety-critical"?
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@murphy.ICS.UCI.EDU">
nancy@murphy.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 18:08:40 -0700
</i><PRE>
Reply-To: nancy@ics.UCI.EDU

<A HREF="/Risks/10.28.html">RISKS-10.28</A> was certainly provocative.  I do not want to enter into the basic
argument, but I would like to comment on a couple of statements that appear
incorrect to me.

Peter Mellor writes:
   &gt;Safety-*related*, I would say, but not safety-*critical*. The usual 
   &gt;definition of safety-critical is that a system failure results in 
   &gt;catastrophe. 

System safety engineers in the textbooks I have read do not define 
"safety-critical" in terms of catastrophic failure.  They use "hazards" 
and the ability to contribute to a hazard.  A safety-critical system or 
subsystem is one that can contribute to the system getting into a hazardous 
state.  There are very good reasons for this, which I will attempt to explain.

Accidents do not usually have single causes -- most are multi-factorial.
We usually eliminate the simpler accident potentials from our systems which
only leaves multi-failure accidents.   The basic system safety goal
is to eliminate all single-point failures that could lead to unacceptable
consequences and minimize the probability of accidents caused by multi-point
failures.  Using Pete`s definition, there are almost NO systems that are 
safety critical including nuclear power plant and air traffic control systems
because we rarely build these systems so that a single failure of a single 
component can lead to an accident.  That the failure of the whole nuclear power
plant or air traffic "system" is an accident is tautological -- what we are 
really talking about are failures of components or subsystems of these larger
"systems" like the control components or the simulators (in this case).

The term "safety-related" seems unfortunate to me because it is too vague
to be defined.  Some U.S. standards talk about "first-level interfaces" 
(actions can directly contribute to a system hazard) or "second-level"
(actions can adversely affect the operation of another component that can
directly contribute to a hazard).  Another way of handling this is to talk
about likelihood of contributing to a hazard -- with the longer chains having
a lower likelihood.  But I would consider them all safety-critical if their
behavior can contribute to a hazard -- it is only the magnitude of the risk 
that differs.  I have a feeling that the term "safety-related" is often used 
to abdicate or lessen responsibility.

There is a very practical reason for using hazards (states which in
combination with particular environmental conditions have an unacceptable risk
of leading to an accident).  In most complex systems, the designer has no 
control over many of the conditions that could lead to an accident.  For
example, air traffic control hazards are stated in terms of minimum separation
between aircraft (or near misses) rather than in terms of eliminating 
collisions (which, of course, is the ultimate goal).  The reason is that 
whether a collision occurs depends not only on close proximity of the 
aircraft but also partly on pilot alertness, luck, weather, and a lot of 
other things that are not under the control of the designer of the system.
So what can the designer do to reduce risk?  She can control only the 
proximity hazard and that is what she does, i.e., assumes that the environment
is in the worst plausible conditions (bad weather, pilot daydreaming) and 
attempts to keep the planes separated by at least 500 feet (or whatever, the
exact requirements depend on the circumstances).

When assessing the risk of the air traffic control system, the likelihood 
of the hazard, i.e., violation of minimum separation standards, is assessed,
not the likelihood of an ATC-caused accident.  When one later does a complete
system safety assessment, the risk involved in this hazard along with the 
risk of the other contributory factors are combined into the risk of a 
collision.  

Why does this push my hot button?  Well, I cannot tell you how many times
I have been told that X system is not safety-critical because it's failure
will not cause an accident.  For example, a man from MITRE and the FAA argued
with me that the U.S. air traffic control software is not safety critical (and
therefore does not require any special treatment) because there is no possible
failure of the software that could cause an accident.  They argued that the 
software merely gives information to the controller who is the one who gives 
the pilot directions.  If the software provides the wrong information to
the controller, well there was always the chance that the controller
or the pilot could have determined that it was wrong somehow.  But an ATC
software failure does not necessarily result in a catastrophe so it is not
safety critical (as defined above).  Perhaps this argument appeals to you, 
but as a person who flies a lot, I am not thrilled by it.  As I said,
this argument can be applied to EVERY system and thus, by the above 
definition, NO systems are safety-critical.

Again, there may be disagreement, but I think the argument has been pushed
to its absurd limit in commercial avionic software.  The argument has been
made by some to the FAA (and it is in DO-178A and will probably be in 
D0-178B) that reduction in criticality of software be allowed on the
basis of the use of a protective device.  That is, if you put in a backup
system for autoland software, then the autoland system itself is not safety 
critical and need not be as thoroughly tested.  (One could argue similarly 
that the backup system is also not safety-critical since it's failure alone 
will not cause an accident -- both of them must fail -- and therefore neither 
needs to be tested thoroughly.  This argument is fine when you can accurately
access reliability and thus can accurately combine the probabilities.  But
we have no measures for software reliability that provide adequate confidence
at the levels required, as Pete says).  The major reason for some to support 
allowing this reduction is that they want to argue that the use of n-version
software reduces the criticality of the function provided by that software 
(none of the versions is safety critical because a failure in one alone will 
not lead to an accident) and therefore required testing and other quality
assurance procedures for the software can be reduced.

   &gt;With a safety-critical airborne system, we are certifying that it has 
   &gt;a certain maximum probability of crashing the aircraft. 

Actually, you are more likely to be certifying that it will not get into 
(or has a maximum probability of getting into) a hazardous state from which
the pilot or a backup system cannot recover or has an unacceptably low
probability of recovering.  The distinction is subtle, but important as I 
argued above.  Few airborn systems have the capacity to crash the aircraft 
by themselves (although we are heading in this direction and some do 
exist -- which violates basic system safety design principles).

   &gt;RTCA/DO-178A ('Software Considerations in Airborne Systems and Equipment
   &gt;Certification') does *not* define any reliability figures. It is merely a
   &gt;set of guidelines defining quality assurance practices for software.
   &gt;Regulatory approval depends upon the developer supplying certain documents 
   &gt;(e.g., software test plan, procedures and results) to show that the 
   &gt;guidelines have been followed.

There is currently an effort to produce a DO-178B.  This will go farther than
178A does.  For one thing, it is likely to include the use of formal methods.
Second, it will almost certainly require hazard-analysis procedures.  If anyone
is interested in attending these meetings and participating, they are open
to the public and to all nationalities.  

&gt;From Pete Mellor's description of the Forrester and Morrison article:
    &gt;This is likely to change following the publication of the draft defence 
    &gt;standard 00-55 by the MoD in the UK in May 1989. The DoD in the US are 
    &gt;not doing anything similar, though the International Civil Aviation 
    &gt;Organisation is planning to go to formal methods.  

Depends on what you mean by similar.  The DoD, in Mil-Std-882B (System Safety)
has required formal analysis of software safety since the early 80s.  MoD draft
defense standard 00-56 requires less than the equivalent DoD standard.  There
has been a DoD standard called "Software Nuclear Safety" that has been in force
for nuclear systems for about 4-5 years.  And there are other standards
requiring software safety analysis (e.g., for Air Force missile systems) that
were supplanted by 882B.  882B is likely to be replaced by 882C soon -- and the
accompanying handbooks, etc. do mention the use of formal methods to accomplish
the software safety analysis tasks.
                                                       nancy

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Computer Unreliability and Social Vulnerability
</A>
</H3>
<address>
David Gillespie
&lt;<A HREF="mailto:daveg@csvax.cs.caltech.edu ">
daveg@csvax.cs.caltech.edu 
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 21:41:05 -0700
</i><PRE>

I think one point that a lot of people have been glossing over is that in a
very real sense, computers themselves are *not* the danger in large,
safety-critical systems.  The danger is in the complexity of the system itself.

Forester and Morrison propose to ban computers from life-critical systems,
citing air-traffic control systems as one example.  But it seems to me that
air-traffic control is an inherently complicated problem; if we switched to
networks of relays, humans with spotting glasses, or anything else, ATC would
still be complex and would still be prone to errors beyond our abilities to
prevent.  Perhaps long ago ATC was done reliably with no automation, but there
were a lot fewer planes in the air back then.  If it was safe with humans, it
probably would have been safe with computers, too.  As our ATC systems became
more ambitious, we switched to computers precisely because humans are even less
reliable in overwhelmingly large systems than computers are.

The same can be said of large banking software, early-warning systems, and so
on.  There's no question that computers leave much to be desired, or that we
desperately need to find better ways to write reliable software, but as long as
the problems we try to solve are huge and intricate, the bugs in our solutions
will be many and intricate.  Rather than banning computers, we should be
learning how to use them without biting off more than we can chew.
   								     -- Dave

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks of selling/buying used computers
</A>
</H3>
<address>
&lt;<A HREF="mailto:pereira@icarus.att.com">
pereira@icarus.att.com
</A>&gt;
</address>
<i>
Sat, 1 Sep 90 14:27:27 EDT
</i><PRE>
Reply-To: pereira@research.att.com

A 8/31/90 Associated Press newswire story by AP writer Rob Wells, entitled
``Sealed Indictments Accidentally Sold as Computer Surplus,'' describes how
confidential files from a federal prosecutor in Lexington, KY, were left on the
disks of a broken computer sold for $45 to a dealer in government surplus
equipment. The files included information about informants, protected
witnesses, sealed federal indictments and personal data on employees at the
prosecutor's office.  The Justice Department is suing the equipment dealer to
return the computer and storage media and reveal who bought the equipment and
who had access to the files.

The government claims that a technician for the computer's manufacturer tried
to erase the files, but since the machine was broken he could not do it with
the normal commands, and had instead to rely on what the AP calls a ``magnetic
probe'' (a degausser?) which apparently wasn't strong enough to to the job.

The dealer complains that the FBI treated him rudely and tried to search his
premises without a warrant; the Justice Department argues that the dealer
hasn't been helpful and could get at the files. The dealer denies he has done
so.

Fernando Pereira, 2D-447, AT&amp;T Bell Laboratories, 600 Mountain Ave, 
Murray Hill, NJ 07974                      pereira@research.att.com

  [One of the earlier classics was related in <A HREF="/Risks/3.48.html">RISKS-3.48</A>, 2 Sep 86:
  "Air Force puts secrets up for sale", in which thousands of tapes
  containing Secret information on launch times, aircraft tests,
  vehicles, etc., were auctioned off without having been deGaussed.  PGN]
 
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Accidental disclosure of non-published telephone number
</A>
</H3>
<address>
Peter Jones 
&lt;<A HREF="mailto:MAINT@UQAM.bitnet">
MAINT@UQAM.bitnet
</A>&gt;
</address>
<i>
Fri, 31 Aug 90 16:27:12 EDT
</i><PRE>

The following appeared on a recent mailout from the Bell Canada telephone
company. It's probably about time to repeat this warning, even if it has
already appeared on the list:

  "If you have a non-published telephone number, please keep in mind that if
  someone else uses your phone to make a collect call or to charge a call to
  another number, your number will appear on the statement of the person billed
  for the call. This is necessary because the customer being billed must be
  able to verify whether or not he or she is responsible for the charge."

Peter Jones   UUCP: ...psuvax1!uqam.bitnet!maint   (514)-987-3542
              Internet: MAINT%UQAM.bitnet@ugw.utcs.utoronto.ca

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-3</DOCNO>
<DOCOLDNO>IA013-000136-B028-286</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.30.html 128.240.150.127 19970217035815 text/html 25655
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:56:46 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 30</TITLE>
<LINK REL="Prev" HREF="/Risks/10.29.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.31.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 30</H1>
<H2> Tuesday 4 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Business Week on High-Tech Amusement Parks 
</A>
<DD>
<A HREF="#subj1.1">
Karl Lehenbauer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Arabian heat causing problems with US weapons computers 
</A>
<DD>
<A HREF="#subj2.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Stonefish mine 
</A>
<DD>
<A HREF="#subj3.1">
Chaz Heritage via Richard Busch
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Flight simulator certification 
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Glass cockpits 
</A>
<DD>
<A HREF="#subj5.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  "Wild failure modes" in analog systems 
</A>
<DD>
<A HREF="#subj6.1">
Kent Paul Dolan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Faultless Software 
</A>
<DD>
<A HREF="#subj7.1">
Robert L. Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Comment on Software Reliability Synopsis 
</A>
<DD>
<A HREF="#subj8.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Database searches and counseling center confidentiality 
</A>
<DD>
<A HREF="#subj9.1">
Derek Beatty
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Business Week on High-Tech Amusement Parks
</A>
</H3>
<address>
Karl Lehenbauer
&lt;<A HREF="mailto:karl@sugar.hackercorp.com ">
karl@sugar.hackercorp.com 
</A>&gt;
</address>
<i>
3 Sep 90 11:18:30 CDT (Mon)
</i><PRE>

In the September 10, 1990 issue of Business Week, a sidebar to an article
about problems at Universal Studios Florida ("MCA May Have Created A
Monster") is about high-tech amusement park rides.  The cavalier attitude
toward risks is startling.

The article reports that "bigger thrills are needed to lure a jaded
generation raised on dazzling movie special effects" and that, consequently,
Universal Studios spent over $200 million for rides such as "a giant
robotic shark that attacks a boatload of tourists, a three-story animated
King Kong, and a bone-jarring imitation earthquake."  The article also
notes that other theme-park operators, including of course Walt Disney Co.,
have "joined the race for ''animatronics,'' robots, and other computerized
contraptions."

	Yet as the bugs plaguing Universal show, technology has its
	price.  Says Joseph B. McHugh, vice-president of Ride &amp; Show
	Engineering Inc., which made the Jaws and Earthquake rides:
	"The complexity of the systems means there are more components
	that can shut a ride down."

	The scariest prospect for a park operator is a Jaws that
	doesn't bite.  And all it takes is one software bug.  At
	Universal, the trick is to synchronize a moving tram and
	an animated shark or gorilla that runs on a fixed program.
	"If they're not coordinated exactly, they run into one
	another and parts get bent," says Q. David Schweninger,
	chief of Sequoia Creative Inc., Kong's creator.  Universal's
	rides are "way out in front of everyone else," he says.
	"The price is that you're going to have teething problems."

Later, the sidebar quotes Schweninger as saying "There are lessons
to be learned here," and adding that ride makers *may* insist on more 
shakedown time before new rides open.

	But none of this is likely to halt the shift to high-tech
	rides, which promise more safety and eat less real estate.
	Changing demographics also favor gentler high-tech rides
	over old-style gut-wrenchers such as roller coasters.

The article concludes by pinpointing the Disney Star Tours ride in
1987 as the first of the new wave of participatory rides and that
ride makers are working on dozens of variations of the simulator
ride for theme parks, casinos and special theaters.

Although it's reasonable to assume gentler rides would be safer than "old-
style gut-wrenchers," the claim seems to be that high-tech makes the rides 
safer, which the rest of the article seems to refute.  Oh well.

uunet!sugar!karl  Usenet access: (713) 438-5018

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Arabian heat causing problems with US weapons computers
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:JON@GAFFER.RAD.WASHINGTON.EDU   ">
JON@GAFFER.RAD.WASHINGTON.EDU   
</A>&gt;
</address>
<i>
Tue, 4 Sep 1990 10:35:49 PDT
</i><PRE>

Here are excerpts from a story in THE SEATTLE TIMES, Sept 3 1990, p. A8:

US TROOPS ALREADY UNDER ATTACK FROM SUN AND SAND by Molly Moore, 
Washington Post

... Patriot missiles, which are to protect critical military sites from attack
by Iraqi Scud-B missiles and attack planes, are controlled by computer
equipment housed in air-conditioned vans.  But the heat is so intense on each
van's metal shell that it raises the temperature inside.  

"Every now and then there is a glitch that makes the (radar) scope look blank,"
said one missile technician.  He said in an attack, the computers are supposed
to override any radar screen malfunction or other problem that might hinder
a human operator, and track the incoming missile on their own.  ...

... If the A-10 attack plane fights Iraqi tanks, it will depend on cylindrical
pods under its wings to jam the signals of enemy air defenses.  But weapons
loaders here said the heat renders the jammers useless after about one hour of
operation.  A typical sortie against hostile tanks would likely require far
more than an hour's protection ...

- Jon Jacky, University of Washington, Seattle jon@gaffer.rad.washington.edu

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard_Busch.sd@Xerox.com  ">
Richard_Busch.sd@Xerox.com  
</A>&gt;
</address>
<i>
Tue, 4 Sep 1990 10:03:21 PDT
</i><PRE>
Subject: Forwarding: Stonefish mine

Chaz Heritage has requested that I forward the following as a candidate for
inclusion in the Risks Digest. He is apparently unable to get mail to you
directly.

richard
  - - - - - - - - - - - - - - -
From: chaz heritage:wgc1:RX
Sender: chaz heritage:wgc1:rx
Subject: Stonefish mine
Date: 3-September-90 (Monday) 4:34:36 PDT

In RISKS-FORUM Digest  Wednesday 29 August 1990   Volume 10 : Issue 26 Pete
Mellor asks a number of questions about the Stonefish mine which may be
possessed by Iraq:

&gt;1. If the Iraqis have the software for a 'limited number' of mines, why
    haven't they got enough for an unlimited number?&lt;

To the best of my knowledge each Stonefish is intended to have a unique
identity to allow selective arming or disarming. Therefore the software
installed in each mine will be slightly different from the others'. It is
likely that Stonefish's software is in ROM, and not loaded into RAM from
floppies as Mr. Mellor seems to suggest. Manufacturing more ROMs, even if
one knows how to assign new identities, would require a ROM-burner and a
supply of blanks. The sort of ROMs used are possibly 'strategic goods' and
not available directly to Iraq, nor, perhaps, to Cardoen.

&gt;2. How does Stonefish 'hide' from a minesweeper?&lt;

Gee, that sure is classified!

Minesweepers can detect mines by a number of methods, to each of which
countermeasures may be available. Sonar, for example, may be spoofed by
returning an amplified signal, too big for a mine (so it looks like a whale
or wreck, perhaps?). Countermeasures may exist against magnetic anomaly
detection, but these are not disclosed in the unclassified literature
(since MAD is used to detect SSBNs this is hardly surprising). There may
well be other countermeasures included in Stonefish's suite.

&gt;3. How reliably can Stonefish identify ships by their engine noise
signature?
    What happens if your cruiser's big ends are rattling?&lt;

The noise signature is mainly a function of the screw design, which is why
there was so much fuss over the Japanese selling the USSR some CNC
machining equipment capable of manufacturing low-noise screws. A ship
trying to avoid acoustic detection will proceed slowly and as quietly as
possible, but it cannot conceal the characteristic noise caused by screw
cavitation at any speed above a knot or two.

&gt;4. Does Stonefish rely on some sort of sonar transponder
    to distinguish friend from foe?&lt;

I imagine not, since if the mine were to transmit sonar in order to trigger
transponders located on friendly ships then it would render the mine very
susceptible to detection and countermeasures.

&gt; 5. What are the chances that Iraq already has the software?&lt;

100% chance of posessing the basic software if they possess the originally
issued mines. Each mine would be supplied with it. Reverse-engineering it
is probably a matter of copying a number of unusual boards and devices, and
would depend upon posessing at least one working example and sufficient
parts. Circuit boards used in weapons systems are often of unusual shape
and construction and replication of them would probably not be particularly
easy.

The target-recognition software, on the other hand, would probably consist
of digitised acoustic samples for comparison with the signature of the
target. If the mines were to be used against US or UK warships then samples
of their signatures would be required. These would probably not be
forthcoming. Any type of ship an example of which had been sold to Iraq
might possibly be at risk (assuming the Iraqis to possess the sampling
apparatus and the ability and time to use it), as might any types possessed
by navies considered at any time to be hostile to the UK Royal Navy.

&gt; 6. The sophistication of Stonefish's recognition system argues for some
kind
    of artificial intelligence. If it's that smart, would it know who was
    winning and change sides accordingly?&lt;

Personally I wouldn't consider Stonefish to be an AI. I don't think the
problem posed is much of a risk to Stonefish operators....

&gt;7. Isn't it time that Jane's produced 'All the World's Software'?&lt;

Yes, but it would be a far slimmer volume than their usual anti-bookshelf
masterpieces (I had to get rid of all my old ones before my upstairs bedsit
suddenly turned into a downstairs bedsit). I don't honestly think enough
information would be disclosed to make it worthwhile.

&gt;The implication is not that Stonefish has been sold bundled to Iraq, but
enough technical information is in dubious hands for the Iraqis to have a
good go at building a look-alike&lt;

Personally I wouldn't back them to do it. If I were a naval commander I
should consider the threat of anti-ship missiles fired from the air or from
the Kuwaiti islands against targets acquired by aircraft possibly still
within Kuwaiti airspace to be a greater threat than that of Iraq managing
to copy a sophisticated underwater weapons system to a deadline.

If, on the other hand, Carlos Cardoen is telling fibs (which would not
perhaps be entirely out of character) then it's possible that he's sold the
Iraqis a few Stonefish already. If so, it seems unlikely to me that they'll
work properly without reprogramming for the target signatures of US and UK
shipping.

Incidentally, the classification &gt;'UK restricted: commercial in
confidence'&lt; is among the lowest available. Almost all documents used by
the armed services, including such things as reminder cards carrying the
NATO phonetic alphabet, are classified 'restricted'; the term 'commercial
in confidence' is applied merely in the fond hope that it will be
respected, since it has only commercial meaning. The &gt;'Technical
Description and Specification' of Stonefish&lt; may well be no more than the
sort of thing small boys (like me) fill their carrier bags with every other
year at Farnborough - I have collected stuff in the past on classified
systems like JP233, also deployed in the Gulf. What these documents do not
disclose is the true performance of the system and its strengths and
weaknesses. That sort of information, operationally significant, is usually
classified at a higher level (within NATO probably 'Secret').

Chaz                                          [All disclaimers apply.]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Flight simulator certification
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Tue, 4 Sep 90 13:16:21 EDT
</i><PRE>

&gt;&gt; Does anyone know the certification requirements for simulators?)
&gt;... I suspect there is nothing to cover
&gt;simulators, since they are not directly involved in controlling flight.

There *are* certification requirements for simulators when they are involved in
pilot training, and in particular when used as substitutes for certain types of
in-flight training.  However, I think the emphasis has been more on precision
than on accuracy, i.e. on the sophistication and smoothness of the simulation
more than on its exact correspondence to reality.  Much is made, for example,
of the quality of the visual imagery provided.  I'm not sure how much has been
done on verifying faithful (as opposed to merely plausible) simulation of
behavior in obscure corners of the system.
                                          Henry Spencer at U of Toronto Zoology
                                          henry@zoo.toronto.edu   utzoo!henry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Glass cockpits
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Mon, 3 Sep 90 15:49:50 BST
</i><PRE>

The UK has a "confidential human factors incident reporting programme",
run by the RAF Institute of Aviation Medicine, to allow aircrew to report
incidents which may reflect badly on their competence, so that others may
learn from them without any risk of the crewmember who made the report
suffering any penalty. They have a magazine - FEEDBACK - and the last issue
publicised the failure of most of the automated systems on an approach to a
UK airport in a storm last February. (Reported in RISKS, I believe).

This issue carries a questionnaire asking flight crew for their opinions of
automation. 78 questions of the form (ring the appropriate number)

"if the automatics fail it	1 2 3 4 5 	if the automatics fail it
is always apparent				is never apparent "

The results of the survey will be *very* interesting. The survey is being
carried out on behalf of the UK Civil Aviation Authority. It is not clear
whether the results will be made public.

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
"wild failure modes" in analog systems
</A>
</H3>
<address>
Kent Paul Dolan
&lt;<A HREF="mailto:xanthian@zorch.sf-bay.org ">
xanthian@zorch.sf-bay.org 
</A>&gt;
</address>
<i>
Sun, 2 Sep 90 18:59:45 GMT
</i><PRE>

&gt;From: Pete Mellor &lt;pm@cs.city.ac.uk&gt;

&gt;Synopsis of: Forester, T., &amp; Morrison, P. Computer Unreliability and
&gt;Social Vulnerability, Futures, June 1990, pages 462-474.

&gt;In contrast [to digital computers], although analogue devices
&gt;have infinitely many states, most of their behaviour is
&gt;*continuous*, so that there are few situations in which they
&gt;will jump from working perfectly to failing totally.

Unless my understanding from readings in Chaos Theory is entirely flawed, the
second sentence is simply false; it is now well known that analogue devices can
also (through design infelicities or just the perverseness of the universe) do
inherently "wild" state switches.  The classic example is the simple dribble of
water from a faucet, which, in the absence of analogue catastrophes, would be a
steady stream, or an equally spaced series of droplets, but is instead a series
of droplets whose size and spacing is unpredictable except statistically.

More important, this is now understood to be the _usual_ state of affairs, not
the anomalous one, in dealing with realistic analogue systems.

So, if the original authors' intent in demeaning our increasing
reliance on (possibly "un-failure-proofable") digital systems is
to promote a return to the halcyon days of analogue controls,
this is probably misdirected by the time the controls approach
the order of complexity of operation of the current digital ones.

We may just have to continue to live with the fact, true throughout
recorded history, that our artifacts are sometimes flawed and cause
us to die in novel and unexpected ways, and that we can only do our
human best to minimize the problems.

Just an observation in passing.

Kent   &lt;xanthian@Zorch.SF-Bay.ORG&gt; &lt;xanthian@well.sf.ca.us&gt;

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Faultless Software
</A>
</H3>
<address>
Robert L. Smith 
&lt;<A HREF="mailto:rlsmith@mcnc.org">
rlsmith@mcnc.org
</A>&gt;
</address>
<i>
Tue, 4 Sep 90 13:25:43 -0400
</i><PRE>

    The recent discussion in RISKS of the need for "ultrareliable" --
i.e., faultless -- software and the impossibility of obtaining it has
been interesting, but lack of it is no compelling reason to prohibit
computers from life-critical service.
    Advocates of that conclusion forget the reliability advantage
software has over hardware and people system components, which is that
once a software bug is truly fixed, it stays fixed!  In contrast
consider the many times you repair hardware only to see it fail again
from the same cause, and coach people to do it right only to hear
they've forgotten later.
    Legal restrictions on software applicability would delay quality
improvements.  They would inhibit progress toward systems that truly
are safer than those whose logic elements reside solely in human
brains.  Software in life critical environments is like old age:  to
understand its desirability, one has only to consider the alternative.
    The question is, have more people died in life critical environ-
ments since software was installed than before, per man-hour of use?
If the answer is no, then the argument is specious.  Even if it is
yes, which I doubt, that is reason only to intensify testing and
debug.  Software engineering has not yet built all the tools
conceivable to that end.

Regards, rLs

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Comment on Software Reliability Synopsis
</A>
</H3>
<address>
"Martin Minow, ML3-5/U26  03-Sep-1990 2253" 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Mon, 3 Sep 90 20:27:01 PDT
</i><PRE>

Thanks to Pete Mellor for posting
&gt;Synopsis of: Forester, T., &amp; Morrison, P. Computer Unreliability and
&gt;Social Vulnerability, Futures, June 1990, pages 462-474.
&gt; Conclusion (quoted):
&gt;Accordingly, we recommend that computers should not be entrusted with
&gt;life-critical applications now, and should be only if reliability improves
&gt;dramatically in the future.
 
There is a risk/benefit that needs to be examined.  If we remove computers
from, say, hospital intensive care units because they are "unreliable" will
we save lives that might be killed by an errant computer or kill others whose
lives might have been saved by that same unreliable system.

&gt;Given the evidence presented here, several ethical issues also emerge for
&gt;people in the computer industry. For example, when programmers and software
&gt;engineers are asked to build systems which have life-critical applications,
&gt;should they be more honest about the dangers and limitations?

Does the article really claim that engineers who know they are building
life-critical applications are not honest about the dangers and limitations?
My experience has been that people are quite aware of their responsibilites.
On the other hand, systems that were never designed to be life-critical are
often used in unexpected ways.  Consider a speech synthesizer designed as a
speech aid for a disabled person.  While not designed as a "life-critical"
system, it IS the voice that that person must use to call for help.  What
is an ethical professional to do?  Refuse to build a speech synthesizer as it
*might* be used in a life-critical situation and the technology doesn't
yet allow us to design a perfect synthesizer?

&gt;Are computer
&gt;professionals under an obligation if a system fails: for example, if a patient
&gt;dies on an operating table because of faulty software, is the programmer guilty
&gt;of manslaughter, or malpractice, or neither?

Who cares?  Will charging programmers with manslaughter really yield better
quality software?  This seems like exactly the wrong thing to worry about.

&gt;How is it that the computer industry
&gt;almost alone is able to sell products which cannot be guaranteed against
&gt;failure?

Because people buy the stuff.  Some software, by the way, *is* warrented
against failure.  All the type of warranty does is affect the price and
time to market.  I rather doubt that it effects the actual quality.

Martin Minow          minow@bolt.enet.dec.com

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Database searches and counseling center confidentiality
</A>
</H3>
<address>
&lt;<A HREF="mailto:Derek.Beatty@COSMOS.VLSI.CS.CMU.EDU">
Derek.Beatty@COSMOS.VLSI.CS.CMU.EDU
</A>&gt;
</address>
<i>
Tue, 04 Sep 90 12:23:42 EDT
</i><PRE>

   Here's a minor variation on an old theme:

   The Carnegie Mellon's online library catalog includes a full-text
database of the faculty/staff directory, and can be used to look up
anyone at CMU given their telephone extension.  This brings to light
a problem with confidentiality and the university's counseling
center.  If the counseling center phones a student and must leave a
message, they leave only their telephone number and receptionist's
first name, to protect against any stigma that might be associated
with seeking their services.  Easy access to the reverse telephone
index function via database searching erodes this effort at
confidentiality even though the library database publicizes no new
information (it's all in the published hard copy directory).
   Here again a large quantitative change (in lookup time) introduces
qualitative differences (it becomes plausible that a roommate might
snoop out of idle curiosity).  Awareness of this might lead someone,
feeling lowly as a (internet?) worm, to forego psychological services.
 
  -- Derek Beatty,      grad student, CMU Computer Science

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-4</DOCNO>
<DOCOLDNO>IA013-000136-B028-307</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.31.html 128.240.150.127 19970217035842 text/html 30772
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:56:57 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 31</TITLE>
<LINK REL="Prev" HREF="/Risks/10.30.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.32.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 31</H1>
<H2> Wednesday 5 September 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  March 1989 British Rail Train Crash 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Complexity, safety and computers 
</A>
<DD>
<A HREF="#subj2.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Software bugs "stay fixed"? 
</A>
<DD>
<A HREF="#subj3.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Stonefish mine 
</A>
<DD>
<A HREF="#subj4.1">
Mark Lomas
</A><br>
<A HREF="#subj4.2">
 Bill Davidsen
</A><br>
<A HREF="#subj4.3">
 Bill Ricker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Reply to "Computer Unreliability" Stars vs Selves 
</A>
<DD>
<A HREF="#subj5.1">
Dave Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  "Wild Failure Modes" in Analog Systems    
</A>
<DD>
<A HREF="#subj6.1">
Jim Hoover
</A><br>
<A HREF="#subj6.2">
 Richard D. Dean
</A><br>
<A HREF="#subj6.3">
 Will Martin
</A><br>
<A HREF="#subj6.4">
 Pete Mellor
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
March 1989 British Rail Train Crash
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian.Randell@newcastle.ac.uk">
Brian.Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 13:50:34 BST
</i><PRE>

  [Yesterday's Independent carried a number of articles related to the ending
  of the trial of a British Rail train train driver in connection with a major
  train accident that occurred on 4 March 1989 in south London. There was a
  fairly lengthy front page article, and two further articles taking up a
  complete half-page.  I have selected from these some paragraphs which should
  be on interest to RISKs readers.  Brian Randell, Computing Laboratory,
  University of Newcastle upon Tyne, UK PHONE =	+44 91 222 7923 
                                                     [Further excerpted by PGN]

A train driver who admitted passing through a red light and causing the Purley
rail crash, in which five people died and 87 were injured, was jailed
yesterday.  Robert Morgan 47, was sentenced to 18 months' imprisonment, 12
months of which was suspended, after pleading guilty to two charges of
manslaughter.  The sentence drew strong criticisms from the rail unions.  The
Old Bailey was told Morgan received two commendations in a previously exemplary
23 years as a train driver.  [...]

Julian Bevan, for the prosecution, told the Old Bailey that Morgan was in
hospital with face and neck injuries a few hours after the crash when he said
he had jumped the red light at about 70mph.  The track limit was 90mph.
Describing the safety system thrown into question by the crash, Mr Bevan said
drivers were given two amber warning signals before coming to a red light.
Each is accompanied by a klaxon sounding in the cab.  If the driver fails to
switch it off, the brakes are applied automatically within three seconds, he
told the court.  Morgan, a single man, of Ferring, West Sussex, admitted that
he must have switched off the klaxon each time, but the memory loss he suffered
prevented him from being more precise.  [...]  Robert Morgan, a driver since
1966, had been well warned by the signalling system that there was going to be
a train ahead of him.  What went wrong?

For every signal a driver passes, the system provides him with an instantly
recognisable set of acknowledgements.  Every time a signal is passed at green,
a bell rings in the cab indicating the line ahead is clear.  If the signal is
at double amber, or amber, or red, a klaxon sounds and has to be acknowledged
by the driver.  He has three seconds to do this and if he does not press the
button, the brakes start to apply and are fully operational in five seconds.
However, he can override this system.

It is a weakness in the system that BR has now recognised.  The Purley crash
came just three months after the disaster at Clapham where 35 people were
killed when a signal failure resulted in a commuter express ramming another
stationary rush hour train.  The real cause, the public inquiry said, was too
much repetitive, painstaking work, not enough time off - lack of supervision
and improper testing procedures among technicians completing resignalling work
in the area.

Since Purley, and acting on the recommendations of the Hidden Report into the
Clapham disaster, BR has been overhauling its approach to safety.

BR admits that prior to the Clapham crash its approach to safety was
equipment-based.  It reasoned that if the equipment and the rules designed to
protect it worked, then the safety of staff and passengers was assured.  What
happened at Clapham and to Robert Morgan at Purley showed that approach to be
inadequate.  In coming to terms with human error, BR has introduced its new
Safety Management Programme.

Potential train drivers already undergo extensive psychological as well as
practical testing, to ensure they are suited to working in a highly disciplined
atmosphere.  However, after work with Professor James Reason of the University
of Manchester, a specialist in risk analysis, BR recognises that regardless of
personality, all human behaviour is inherently quirky in increasingly
repetitive circumstances.  It understands that drivers can get into a "mind
set" where they believe they have completed a task, or recognised a signal,
when they have not.  In that mental state, a driver could cancel a warning
horn, not realise he had done so and plough on to disaster.

BR has admitted that the chances of an equipment failure being the sole cause
of an accident have been all but engineered out of the safety equation, and
that one of the biggest risks to passengers is drivers passing signals at
danger.  It happens on average between 20 and 30 times a year, and each
incident is investigated.  [...]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Complexity, safety and computers
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 10:57:39 BST
</i><PRE>

In RISKS (10.29), David Gillespie writes:
: I think one point that a lot of people have been glossing over is that in a
: very real sense, computers themselves are *not* the danger in large,
: safety-critical systems.  The danger is in the complexity of the system itself

I agree. Often, people talk about "the software reliability problem" when
actually the problem is the difficulty of getting complex designs right, and
the impossibility of guaranteeing that any residual errors will cause the
design to fail less frequently than (some very low probability of failure).

There is, of course, the related problem of what we mean by "getting the
design right" and "failure". In general, these can only be defined with
hindsight - we recognise that the system has entered a state which we wish
it hadn't, and we define that as failure. We cannot (usually) guarantee that
we have defined all safe states, or all hazardous states, in advance.

This is seen as a "software problem" because we *choose* to put most of the
system complexity into the software, as a sensible design decision.

Recently, I have started to wonder if some of our difficulties are
exacerbated by this decision. Software is digital (at the moment, at least).
Yet many safety-critical systems involve monitoring analog signals and
driving actuators which cause analog activity in the controlled system 
(for example, monitoring airspeed and driving the elevators of an aircraft).
At some point in the system, the analog signal is digitised - generally
before any computation is performed on it. Then the digital outputs are
reconverted to analog.

The question I would ask is: are we making our systems significantly more
complex by converting to digital too soon (or at all)? Would the system
complexity be reduced if, instead of converting to digital so that we can
use a commercial microprocessor, we processed the signals as analog signals,
using an application-specific integrated circuit (ASIC) and only converted
to digital where there is a clear reduction in complexity from doing so?

This is a serious question: latest technology allows mixed analog-digital
ASICs, and the cost and time to produce an ASIC is competitive
with the cost and time to produce the software and circuit board for a
microprocessor system - and the technology is moving so that economics
increasingly favour the use of ASICs. You can have (some of) your favourite
microprocessors on-chip, too.

To summarise: the issue is system complexity - safety is related (probably
exponentially) to the inverse of complexity (if only we could measure it) -
so reducing complexity is the key to increasing safety; can we make progress
by exploiting analog techniques?

--
Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
software bugs "stay fixed"?
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 13:44:05 +0100
</i><PRE>

In RISKS 10.30, Robert L. Smith writes:
...
    "... the reliability advantage software has over hardware and people system
components, which is that once a software bug is truly fixed, it stays fixed!
In contrast consider the many times you repair hardware only to see it fail
again from the same cause ..."

I don't know how you define "truly fixed" (unless it means that the bug doesn't
recur - in which case the claim that it stays fixed is tautological!).

In my experience, software bugs are often reintroduced (which is why regression
testing is important). This source of problems is probably only surpassed by
the number of *new* errors introduced while fixing old ones.

The problem of re-assuring software after "maintenance" is as hard as the
problem of assuring it in the first place - while the industry practices are
probably worse, and the regulatory control is certainly worse. Experience with
"software rot" in past systems suggests that we may well see accidents caused
by "faulty maintenance" in growing numbers over the next few years. I predict
that the individual staff will be blamed, rather than the whole regulatory
structure (whereas a major accident caused by an ab initio design error would
raise the question of how the error managed to get through the certification
process). Somehow, "maintenance errors" sound less threatening, possibly
because they sound as though they only apply to a single system.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Stonefish mine
</A>
</H3>
<address>
&lt;<A HREF="mailto:tmal@computer-lab.cambridge.ac.uk">
tmal@computer-lab.cambridge.ac.uk
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 12:19:30 +0100
</i><PRE>

In RISKS DIGEST 10.30 Chaz Heritage wrote in reply to a message from Pete
Mellor:

&gt; &gt; 4. Does Stonefish rely on some sort of sonar transponder
&gt; &gt;    to distinguish friend from foe?
&gt;
&gt; I imagine not, since if the mine were to transmit sonar in order to trigger
&gt; transponders located on friendly ships then it would render the mine very
&gt; susceptible to detection and countermeasures.

I don't know whether Stonefish is able to trigger transponders on
detected ships but let us assume that it can.  We already know that
Stonefish performs pattern recognition on passing ships to distinguish
friend from foe.  There are also some types of hostile ships that
should not be attacked, for instance we would like the mine to remain
undetected as a minesweeper passes.

If the mine has already decided that a ship should not be attacked, because it
has been deemed friendly or a hostile minesweeper, then it need not trigger the
transponder.  Only if it has already decided to attack a ship would it need to
confirm its decision and so try to trigger the transponder.  If there is no
response then the mine intends to explode and so will almost certainly be
detected very shortly afterwards.

The decrease in risk to friendly shipping may make such behaviour worthwhile;
the additional warning that a foe would receive would be of the order of the
round-trip time for the message pair.

	Mark Lomas (tmal@cl.cam.ac.uk)

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Stonefish mine
</A>
</H3>
<address>
bill davidsen
&lt;<A HREF="mailto:davidsen@crdos1.crd.ge.com ">
davidsen@crdos1.crd.ge.com 
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 10:51:03 EDT
</i><PRE>

| From: chaz heritage:wgc1:RX
| Date: 3-September-90 (Monday) 4:34:36 PDT
| 
| &gt; 6. The sophistication of Stonefish's recognition system argues for some
| kind
|     of artificial intelligence. If it's that smart, would it know who was
|     winning and change sides accordingly?&lt;
| 
| Personally I wouldn't consider Stonefish to be an AI. I don't think the
| problem posed is much of a risk to Stonefish operators....

| If, on the other hand, Carlos Cardoen is telling fibs (which would not
| perhaps be entirely out of character) then it's possible that he's sold the
| Iraqis a few Stonefish already. If so, it seems unlikely to me that they'll
| work properly without reprogramming for the target signatures of US and UK
| shipping.

  Here's a real risk of software... after the mines are reprogrammed how
would you like to be the first one to run a ship over one to verify that
they are ignoring "friendlies?" Since Iraq doesn't have enough ships to
worry about this, they don't have the problem, but if they blew the
bottom out of a tanker they might really shut off the flow of oil.

  I believe the mines huddle on the bottom and wait until they detect a
target close enough to be damaged then pop to the surface. Somewhat like
a "Bouncing Betty" mine, for those of us old enough to remember.

bill davidsen	(davidsen@crdos1.crd.GE.COM -or- uunet!crdgw1!crdos1!davidsen)
    VMS is a text-only adventure game. If you win you can use unix.

</PRE>
<HR><H3><A NAME="subj4.3">
S-W controlled mine Risks to Aircraft carriers (Re: Stonefish)
</A>
</H3>
<address>
William Ricker
&lt;<A HREF="mailto:wdr@wang.com ">
wdr@wang.com 
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 18:06:16 GMT
</i><PRE>

I enjoyed the speculation "From Channel 4 news last night (Tue. 28th Aug)"
about a software-controlled mine. However, after recent discussions in the
sci.military / military-request@att.att.com list/group (initiated after I
repeated something I heard a US Admiral say on CBC repeated over US NPR), I
must quickly comment on:

In comp.risks, p.mellor@uk.ac.city (JANET) writes
&gt;It is reported that Iraq may be deploying some of the Royal Navy's latest
&gt;high-tech weaponry. Apparently this is causing US commanders to be reluctant
&gt;to send aircraft carriers into the northern area of the Gulf.

Carriers are not in the gulf because it it too small to maintain normal flight
operations in -- the standard exclusion zones around a carrier task group would
include oil platforms, Saudi, and Iran; and if operating in north gulf, Iraq.
They also can't steam east or west for wind-accross-deck very long either, but
that is less of a concern.

Stonefish may deter smaller ships and the Battleships (the forgotten class of
capital ship) from approaching for bombardment, but they're irrelevant in that
overgrown estuary for carriers.

/bill ricker/                      wdr@wang.com a/k/a wricker@northeastern.edu

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Reply to "Computer Unreliability" Stars vs Selves
</A>
</H3>
<address>
Dave Davis 
&lt;<A HREF="mailto:davis@mwunix.mitre.org">
davis@mwunix.mitre.org
</A>&gt;
</address>
<i>
Wed, 05 Sep 90 11:04:23 EDT
</i><PRE>

In response to Peter Mellor's challenge in RISKS 10.28, 31 Aug 90, let me
offer the following.  On the surface, it would seem that the authors 
of the _Futures_ article have a fresh point of view about the risks 
of using computers in areas where the cost of failure is high, avionics,
automated medical devices, nuclear reactors, etc.  Systems based on large
quantities of software do have large numbers of states, and therefore,
large numbers of failure points.  I addition, such a system may have
previously unknown (to the developers) states caused by errors or outside
factors, such as the EMI-caused failures of the Blackhawk helicopters.

    However, the arguments the authors present (as summarized by Mr.
Mellor) are somewhat similar to previous objections to utilizing relatively
immature technologies.  That is, "we don't understatnd it well enough, so
let's not trust it" is the underlying point.  Almost any significant new
technology fits that argument.  Historically, it has been through applying
a technology that motivation toward better theoretical understanding is
created.  For example, we didn't understand thermodynamics and statistical
mechanics while we applied steam power for several generations.  In
addition, it is significant that the authors object to the use of
statistics as a measurment technique.  One wonders if this is an attempt to
play on the commonly held bias against the use of statistics.  Statistics
are routinely used by all large manufacturing companies to identify
production problems.

    In broader sense, the authors misunderstand how broad the
implementation of an information-intensive system can be.  It is not
necessarily just silicon and software.  One is reminded of the complexity
of the mechanical rail switching systems described so well in previous
RISKS.  The argument that discrete-state machines have inherently wilder
failure modes that an analog systems isn't so.  Any system that has
feedback, intentional or unintentional, may behave wildly if a component
fails, or it is operated outside design limits.  (In the early 70s some
airliners were thought to have crashed due to the pilots over-extending
their controls.)  Moreover, returning to the era of electromechanical
devices that wear out and have their own idiosyncracies is not a path
toward increased reliability.

Dave Davis,  MITRE Corporation, McLean, VA

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
"Wild Failure Modes" in Analog Systems
</A>
</H3>
<address>
Jim Hoover
&lt;<A HREF="mailto:hoover@cs.ualberta.ca ">
hoover@cs.ualberta.ca 
</A>&gt;
</address>
<i>
Tue, 4 Sep 90 21:45:06 MDT
</i><PRE>

Hmm, last time I taught a hardware course I emphasized that the digital
computer was just a fiction invented by us theory types.  All the 
implementations I know of use analog devices.  Thus we already comply
with the suggested legislation.

Jim Hoover, Dept. of Computing Science, University of Alberta, Edmonton, 
Canada T6G 2H1 | 403 492 5401 | FAX 403 492 1071 | hoover@cs.ualberta.ca

</PRE>
<HR><H3><A NAME="subj6.2">
Re: Wild failure modes in analog systems
</A>
</H3>
<address>
"Richard D. Dean" 
&lt;<A HREF="mailto:rd0k+@andrew.cmu.edu">
rd0k+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Wed,  5 Sep 90 11:23:01 -0400 (EDT)
</i><PRE>

&gt;From: Pete Mellor &lt;pm@cs.city.ac.uk&gt;

&gt;Synopsis of: Forester, T., &amp; Morrison, P. Computer Unreliability and
&gt;Social Vulnerability, Futures, June 1990, pages 462-474.

&gt;In contrast [to digital computers], although analogue devices
&gt;have infinitely many states, most of their behaviour is
&gt;*continuous*, so that there are few situations in which they
&gt;will jump from working perfectly to failing totally.

Although analog behavior is continuous, what about resonance ?  While the
output may still be a continuous function of some inputs, it's certainly very
non-linear in some places....Watch the voltage (or current) on an RLC circuit
go very high given the right (or wrong) frequency.

Drew Dean                          rd0k+@andrew.cmu.edu

</PRE>
<HR><H3><A NAME="subj6.3">
 Re:  "wild failure modes" in analog systems
</A>
</H3>
<address>
Will Martin 
&lt;<A HREF="mailto:wmartin@STL-06SIMA.ARMY.MIL">
wmartin@STL-06SIMA.ARMY.MIL
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 14:49:04 CDT
</i><PRE>

&gt;it is now well known that analogue devices can
&gt;also (through design infelicities or just the perverseness of the universe) do
&gt;inherently "wild" state switches.  The classic example is the simple dribble of
&gt;water from a faucet, which, in the absence of analogue catastrophes, would be a
&gt;steady stream, or an equally spaced series of droplets, but is instead a series
&gt;of droplets whose size and spacing is unpredictable except statistically.

While this is indeed true, I think that you have to look at the "level"
of the possible state change to see the analog/digital difference. In
the example cited, while each individual droplet is of unpredictable
size and falls at (generally) unpredictable intervals, stepping back
from the action and looking at the entire system (water pouring from the
faucet) gives a predictable result -- over a period of time, a certain
amount of water will flow out of that faucet. 

There is not likely to be any sudden change in the rate of flow, nor is
the flow likely to suddenly stop (assuming nobody is messing with the
controls and there are no foreign objects in the water supply to clog
the outlet). So while the individual elements (droplets) of the flow follow
chaotic paths, the flow, as a whole, follows a predictable route.

In a digital system without adequate limiting controls, each succeeding
digital number could vary wildly from the preceeding one. A high-order
bit could be turned on, for example, causing an effect that just could
not happen in an analog system, simply because it takes time for a change
to occur; analog variables can "ramp" up or down but each instance will
depend, to some extent, on those preceeding. Each digital sample,
though, can stand alone and enormous swings can occur in the interval of
milliseconds or nanoseconds between samples. Thus the possible range
of catastrophic effects are inherently greater in digital as opposed to
analog systems. (Of course, well-designed digital systems with limit
checking and sample verification can avoid such ill effects.)

This doesn't mean that analog systems can't suffer similar catastrophes.
In the example given, a lump of something in the water supply could clog
the valve or nozzle in an instant. So the flow could drop to zero in a
shorter-than-normal time. But that is about all that could go wrong. The
flow couldn't change from 1 liter/minute to 1 billion liters/minute in
an instant, or switch to a reverse-direction flow. A digital equivalent
would be subject to such possibilities.

Will       wmartin@st-louis-emh2.army.mil OR wmartin@stl-06sima.army.mil

</PRE>
<HR><H3><A NAME="subj6.4">
Re: "wild failure modes" in analog systems
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 22:02:11 PDT
</i><PRE>

Kent Paul Dolan in <A HREF="/Risks/10.30.html">RISKS-10.30</A> writes about the "wild" (or "catastrophic" in
Forester and Morrison's original terms) failure modes of analogue systems.  He
states:

&gt; Unless my understanding from readings in Chaos Theory is entirely flawed, the
&gt;second sentence is simply false; it is now well known that analogue devices can
&gt;also (through design infelicities or just the perverseness of the universe) do
&gt;inherently "wild" state switches.

The "second sentence" here is: 

&gt;&gt;In contrast [to digital computers], although analogue devices
&gt;&gt;have infinitely many states, most of their behaviour is
&gt;&gt;*continuous*, so that there are few situations in which they
&gt;&gt;will jump from working perfectly to failing totally.

First, let me say that I *almost* entirely agree with Kent. After all, chaotic 
phenomena were originally demonstrated on analogue systems. In that synopsis, I
was trying to present the authors' view without prejudice. I did not pick
that particular bone with them in my subsequent criticism of their paper since
I had plenty of other points to raise.

Kent goes on to say:

&gt; So, if the original authors' intent in demeaning our increasing
&gt; reliance on (possibly "un-failure-proofable") digital systems is
&gt; to promote a return to the halcyon days of analogue controls,
&gt; this is probably misdirected by the time the controls approach
&gt; the order of complexity of operation of the current digital ones.

I agree again, *but*, we would never attempt to build systems of the complexity
of our current digital systems if we had only analogue engineering to rely on.
It would not be possible. Reliability requires simplicity. Analogue systems
would be expected to be more reliable than digital because they are forced to
be simpler. It is the complexity of the software in a digital system which
leads to its unreliability.

&gt; We may just have to continue to live with the fact, true throughout
&gt; recorded history, that our artifacts are sometimes flawed and cause
&gt; us to die in novel and unexpected ways, and that we can only do our
&gt; human best to minimize the problems.

Of course! No human endeavour is free of risk. However we do have a choice:
a) to restrict the complexity of life-critical systems, in the hope of
retaining some kind of intellectual mastery of their modes of failure, and
b) to stop kidding ourselves that software failure makes an insignificant
contribution to the unreliability of digital systems (and we *do* - see 
below [1]).

Returning to chaos (as properly defined: non-linear behaviour of a system,
whose basic laws are well-understood, such that second-order effects predominate
and the future states of the system become unpredictable at the detailed level
since arbitrarily close points in the state space can diverge along widely
differing circuits): how does this differ from digital system behaviour?

When Christopher Zeeman gave a lecture on Chaos at City, I asked him what he 
thought was the relevance of chaos theory to digital systems. To my surprise,
he (and, I would guess, 99.99 per cent of other chaotists) had never given the
problem a single thought! Hardly surprising, if you think about it. There *is*
no physical theory of digital behaviour, and no distinction between 1st and 2nd
order effects (or, if you like, everything is at least 2nd order: the slightest
perturbation from a point in the state space can lead to *anywhere* arbitrarily
quickly).

Has anyone out there thought about what the state space diagram of a modest 
digital device would look like? The closest I could get was a 
billion-dimensional discontinuous space of 0's and 1's (i.e. the Cartesian
product, a billion times over, of {0, 1} with itself). Yuk!

A serious attempt *has* been made (by John Knight - reference not to hand) to
examine the shapes of bugs in programs, i.e. the topological properties of those
subsets of the input space which activate program faults. Chaotists will be
pleased to learn that they were fractal.

So here I side with Forester and Morrison. Although I agree with Kent that 
analogue systems can behave chaotically, digital systems are far, far more
chaotic than chaos!

Just an observation in passing.

[1] By the way, the reference above to belief in the perfection of software
is based on what a representative of Airbus Industrie said when interviewed
on the last Equinox programme on fly-by-wire (see RISKS passim).

UK viewers (and some elsewhere in Europe) should tune into Channel 4 on Sunday
30th September, when an updated version of this programme will be transmitted.
Approximately 50 per cent of the material is new, including some *very*
interesting stuff on the Mulhouse-Habsheim disaster.

Peter Mellor, Centre for Software Reliability, City University, Northampton 
Sq.,London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-5</DOCNO>
<DOCOLDNO>IA013-000136-B028-343</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.32.html 128.240.150.127 19970217035902 text/html 24080
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:57:30 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 32</TITLE>
<LINK REL="Prev" HREF="/Risks/10.31.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.33.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 32</H1>
<H2> Thursday 6 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  New Roque Imperils Printers 
</A>
<DD>
<A HREF="#subj1.1">
Robert E. Van Cleef
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Floating Point Emulation required for Ultrix systems 
</A>
<DD>
<A HREF="#subj2.1">
Dave Wortman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Software bugs "stay fixed"? 
</A>
<DD>
<A HREF="#subj3.1">
Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Wild failure modes and COMPLEXITY 
</A>
<DD>
<A HREF="#subj4.1">
Rochelle Grober
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Lawsuit over specification error 
</A>
<DD>
<A HREF="#subj5.1">
Brinton Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Flight simulator certification 
</A>
<DD>
<A HREF="#subj6.1">
Steven Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Lawsuit over simulator specifications 
</A>
<DD>
<A HREF="#subj7.1">
Robert Dorsett
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Computers and Safety 
</A>
<DD>
<A HREF="#subj8.1">
Bill Murray
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
New Roque Imperils Printers
</A>
</H3>
<address>
Robert E. Van Cleef 
&lt;<A HREF="mailto:vancleef@prandtl.nas.nasa.gov">
vancleef@prandtl.nas.nasa.gov
</A>&gt;
</address>
<i>
Thu, 6 Sep 90 07:34:41 -0700
</i><PRE>

In the Business section of the 9/5/90 San Jose Mercury News, Page E-1,
the column "Bits &amp; Bytes", by Rory J. O'Connor and Valerie Rice,
discusses an new class of "Trojan Horse" for PostScript printers.

According to the article, there is a "clip art" file, written in
PostScript, that "surreptitiously reprograms a chip inside the
printers, changing a seldom-used  password stored there. When the
password is altered, ...  the printer no longer functions properly."

A Minneapolis company, Multi-Ad Services is listed as claiming to
have a free "vaccine".

Bob Van Cleef - vancleef@nas.nasa.gov, RNS Distributed Systems Team Leader

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Floating Point Emulation required for Ultrix systems
</A>
</H3>
<address>
Dave Wortman 
&lt;<A HREF="mailto:dw@csri.toronto.edu">
dw@csri.toronto.edu
</A>&gt;
</address>
<i>
Thu, 6 Sep 90 15:43:57 EDT
</i><PRE>

I had a very bad experience in trying to configure an Ultrix system
that may be of interest to comp.risk readers.

Most Unix systems are generated from a "configuration file" which 
selects optional software to be included in the Unix kernel.  
A system utility (/etc/config) processes the configuration file 
to build a directory of components for the Unix kernel.  These 
components are then compiled/linked together to build a Unix kernel.

In the early (PDP-11) days of Unix, a package for performing emulation
of floating point arithmetic was included in the Unix kernel because
the underlying hardware didn't support floating point arithmetic.
One of the options that can still get included in a configuration file is:

EMULFLT		Emulates the floating point instruction set
		if it is not already present in the hardware

I was browsing through the configuration file for a DEC Ultrix
system and decided in a fit of excessive tidiness to delete the
EMULFLT option.  After all the machine had this expensive
floating point hardware and I would probably gain both space
and performance in the kernel.   The configuration tool built
a system directory without complaint and I was able to compile
and link a new Unix kernel without any error messages.

The trouble began when I tried to boot the new Unix kernel (on a DEC 3600).
One of the first programs that gets run once the kernel has been
initialized is a system utility (/etc/fsck) which validates the root 
filesystem by checking all nodes and links for reasonableness.  
Under the new kernel /etc/fsck failed with an undocumented error 
message and an indication that the root file system was corrupted.
Since this check is deemed to be vital to the correct operation
of Unix, the entire boot process aborted.
Booting an old version of the kernel worked correctly and failed to 
discover any problems with the root filesystem.  

This was NOT an easy problem to diagnose.
It took a long time and a lot of painful head scratching to discover
that the fsck utility (or some routine that it called) depended in some 
subtle way on software that was included by the EMUFLT option (on a
3600 it may have been some complicated string instruction rather than
a real floating point operation) .  Once I restored 
floating point emulation to this 4th generation machine, the system
began behaving normally again.

There are several RISK-related lessons to be learned from this
experience:
- one shouldn't casually muck-about with system parameters unless
  one is willing to spend the effort to learn how to adjust them
  properly.
- it is bad system design to document a parameter as an "option"
  when in fact it is mandatory for the correct operation of
  the system.  Until dependencies on floating point emulation
  are brought under control, the user probably shouldn't have the option
  of building a system without EMUFLT and the configuration tool
  should enforce this restriction.  
- EMUFLT appears to be misnamed and misdocumented as well, 
  it probably causes the inclusion of software other than just 
  floating point emulation.
- it is bad system design for a utility program to depend on
  an optional component of its environment without verifying
  that the optional component is available.  /etc/fsck should have
  checked for the presence of floating point emulation and
  displayed an appropriate error message if it was unable
  to continue.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Software bugs "stay fixed"? (<A HREF="/Risks/10.31.html">RISKS-10.31</A>)
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:parnas@qucis.queensu.ca ">
parnas@qucis.queensu.ca 
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 20:02:15 EDT
</i><PRE>

My perception is that they stay fixed, if they were actually fixed.  Usually
they were not properly corrected and, under new circumstances, problems
reappear.  Then it appears as if the bug recurred.  Actually, it had 
never gone away.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
re: Wild failure modes and COMPLEXITY
</A>
</H3>
<address>
Rochelle Grober
&lt;<A HREF="mailto:rocky@argosy.UUCP ">
rocky@argosy.UUCP 
</A>&gt;
</address>
<i>
Thu, 6 Sep 90 14:07:27 PDT
</i><PRE>
Organization: MasPar Computer Corporation, Sunnyvale, CA

With regards to wild failure modes of digital versus "continuous performance"
of analog devices, this seems to me a pure fallacy.  Analog devices can display
as great and rapid a change to the system as digital devices.

One of the most graphic historical instances of this is the blackout of New
York City in the '60's.  The blackout, which threw New York into a night of
turmoil, and affected a large portion of the city, was do to one relatively
small power generator in the Chicago area failing "open", what was considered a
benign type of failure.  Unfortunately, New York was connected to the same
power grid, and was a quarter wavelength away.  The distance is extremely
significant, as the power stations in New York received the failure as a
"short".  Massive amounts of power surged through the New York power stations
and destroyed the safeguards along with many of the systems.  Until this event,
no one ever considered it to be a possibility.  No computers involved, small
error action, huge error reaction of an analog system.

This is an example of why much of industry has gone to digital controls.  Yes,
they are complex, but they have discrete, limited numbers of responses.
Modelling simple analog systems is much more complex than modelling a digital
system of similar complexity.  Periodic functions such as those involved in
fluid dynamics (air, electricity, liquids, quantum mechanics, etc) require
analysis in not just time, but frequency domain as well.  Maxwell's equations
are generally not necessary in simulating digital designs, but must be
accounted for in every analog electrical system.

The real issue is complexity, as has been stated by others.  Every technology
which pushes the limits of the implementor's understanding contains the
prospect of unpredicted behaviour.  Digital controls simply have pushed the
limits farther, by allowing the less complex (sometimes read as fewer states)
discrete technologies to succeed the problematic, continuous state analog
technologies.

--Rochelle Grober

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Re: Lawsuit over specification error
</A>
</H3>
<address>
Brinton Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Tue, 4 Sep 90 23:59:13 EDT
</i><PRE>

Pete Mellor and Martyn Thomas agree that

&gt;&gt; You cannot expect crew to do better than their
&gt;&gt; training under the stress of an emergency.

Er...the crew are, after all, thinking humans and merely another set of
automatons in the system.  A recent (past 5 years) air crash in the mid-US was
less disastrous than it might have been precisely because the pilot performed
beyond his training, in a situation which he had not been expected to
encounter.  This is, after all, one of the differences between human and
machine.  
_Brint

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Flight simulator certification (<A HREF="/Risks/10.30.html">RISKS-10.30</A>)
</A>
</H3>
<address>
Steven Philipson
&lt;<A HREF="mailto:stevenp@decwrl.dec.com ">
stevenp@decwrl.dec.com 
</A>&gt;
</address>
<i>
Tue, 4 Sep 90 18:41:17 PDT
</i><PRE>

   In RISKS DIGEST 10.30 henry@zoo.toronto.edu (Henry Spencer) writes: 

&gt;There *are* certification requirements for simulators when they are 
&gt;involved in pilot training, [...] However, I think the emphasis has
&gt;been more on precision than on accuracy, i.e. on the sophistication
&gt;and smoothness of the simulation more than on its exact correspondence
&gt;to reality.  [...]

   The fidelity of simulators to their real-world counterparts is
of paramount importance.  It is intended that simulators mimic the
performance of the actual aircraft as closely as possible, so that
techniques learned in the simulator will actually be helpful in the
aircraft.  A tremendous amount of effort goes into confirming the
fidelity of these systems.

   High fidelity of simulation is difficult to obtain and maintain.
Models of aircraft performance may not be perfect, but the errors
may be difficult to detect.  A small variation in simulator behavior
has been suggested as a contributing factor in the crash of a DC-9.
In this case, the simulator produced a visible yaw in the direction of
a failed engine that wasn't present during an actual failure.  It was
theorized by the NTSB that the crew mis-identified the failed engine
BECAUSE they expected the yaw shown in the simulator, and that this
led to a loss-of-control accident.

   Aircraft in the field are often modified, and changes are also made
at the factory.  Thus a given simulator may have at one time accurately
reflected some number of airplanes, but may not be configured identically
to any given airplane currently in use.

   Full-scale simulators are intended to be so like the actual
aircraft that one can be certified to fly the aircraft while only
flying the simulator.  In such cases, fidelity is more important
than reliability --  if the simulator is working, it should 
mimic the performance of the aircraft perfectly.  An unreliable
simulator would be more acceptable than one with low fidelity, i.e.
it much more acceptable for a simulator to shutdown and have to be
restarted once an hour than it would for it to run continuously
but incorrectly mimic the performance of the aircraft.

   It should be noted that perfect behavior by a simulator is not
always necessary for the simulator to be useful.  Many low-cost
simulators for light aircraft have some startling performance
artifacts but continue to be effective training aids.  For example,
when the Pacer Mark II simulator is rolled inverted, "up elevator"
still produces a climb.  This is obviously wrong performance, but it
is outside the stated limits of the simulator performance (bank angle
limits are less than 90 degrees).  This particular device has other
interesting artifacts, but it still is useful for certain types of
training activities.  In recognition of its limitations, it is formally
referred to as a "ground procedures trainer", but its function is to
simulate certain modes of flight.

   There is a tradeoff here, just as there is with other technological systems.
Imperfect behavior of simulators may contribute to accidents, but by and large,
their use helps to prevent many more.
						Steve Philipson

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">

</A>
</H3>
<address>
Robert Dorsett
&lt;<A HREF="mailto:rdd@ccwf.cc.utexas.edu ">
rdd@ccwf.cc.utexas.edu 
</A>&gt;
</address>
<i>
Tue, 4 Sep 90 19:53:07 -0500
</i><PRE>
Subject: Re: Lawsuit over simulator specifications (RISKS 10.27)
Reply-To: rdd@walt.cc.utexas.edu (Robert Dorsett)

Martyn Thomas &lt;mct@praxis.co.uk&gt; wrote:
&gt;: This claim seems to me to suggest (a) that once again, aircrew do not
&gt;: understand the side-effects (pitch-up, in this case) of flight-director
&gt;: commands (which I believe means that the systems are too complex).

Oh, they understand it, all right--they're just encouraged to put a very high
level of faith on it.  It's no wonder that people might become fixated on the
flight director, and neglect the rest of the scan.  In fact, some airline
procedures seem to encourage such a practice, these days.  

When one flies a flight director, one is, in effect, flying the airplane like
an autopilot would.  This has the effect of putting the pilot in "the loop,"
but has the problem of having him hanging off the flight director system.


&gt;: critical systems such as simulators - on this evidence, a simulator used for
&gt;: crew training in emergency procedures is *itself* a safety-critical system.
&gt;: (Presumably it should therefore require certification in the same way as an
&gt;: in-flight system of equivalent criticality. 

They are certified to a fairly hard standard.  For more information, see
Rolfe's _Flight Simulation_.  He covers the certification, installation, and
testing components of a simulator delivery.  However, also pay attention to how
much of flight simulation is dependent upon specific customer requirements (no
need, for instance, for a motion system, if all the simulator is going to be
used for is systems familiarization) and how much perceptual data is outright
fudged.  Flight simulation is an art, not a science.  When one flies a
simulator, one is flying a concept of how the airplane flies; one is not flying
in a terribly rigorously defined mathematical model.  Even though a simulator
almost always, these days, uses actual airplane avionics, and is almost 100%
component-identical to a real cockpit, the way the instruments WORK is always
subject to refinement.  In the specific case of Northwest vs. CAE, it is
Northwest's responsibility to supervise the development of the simulator, and,
upon delivery, test it to ensure that it met specifications.  Everyone does it
this way; I suspect that Northwest's legal department may have found a legal
technicality to relieve them of their responsibility.

&gt;Does anyone know the certification requirements for simulators?

Rolfe mentions the various certification authorities' requirements.
In addition to these, FAR 121, Appendix H covers the training requirements.

Advisory Circular 120-45 and 120-46 (1987) cover the entire spectrum of 
Advanced Training Devices.  

Advisory Circular 120-40A (1986) covers simulator and visual systems
evaluation.

Note that all documents are subject to review, as reflected in the Federal 
Register; it often takes a couple of years for changes to be reflected in 
the "officially" published documents.  Contact your local FAA office for more 
info.

Incidentally, I think it's only a matter of time before some bereaved widow
attempts to sue Microsoft, after hubby tries to land on top of the World
Trade Center. :-)

Robert Dorsett             UUCP: ...cs.utexas.edu!rascal.ics.utexas.edu!rdd  

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Computers and Safety
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.NCSC.MIL">
WHMurray@DOCKMASTER.NCSC.MIL
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 21:49 EDT
</i><PRE>

&gt;Synopsis of: Forester, T., &amp; Morrison, P. Computer Unreliability and
&gt;Social Vulnerability, Futures, June 1990, pages 462-474.

&gt;From the synopsis and criticism posted, I have concluded that this work
is probably useless "computer bashing."   On the other hand, the discussion
that it has prompted has been both useful and fascinating.

For example:

In RISKS (10.29), David Gillespie writes:

&gt;I think one point that a lot of people have been glossing over
&gt;is that in a very real sense, computers themselves are *not* the
&gt;danger in large, safety-critical systems.  The danger is in the
&gt;complexity of the system itself......


Nonetheless, the application of the computer adds a great deal of
complexity that might not be there in its absence.  It results,
in part from the complexity of the computer itself, in part
from its inherent generality, and in part, from the failure,
resistance, or reluctance of the programmer to manage it down.

Much of the generality of the computer resulted from the
perception that it had to be broad in application in order to get
copies up and unit cost down.  The early RISC research
demonstrated that this may not be so, but so far we have been
reluctant to employ simple architectures.  For example, we have
known about finite-state machines for a long time, but few have
been successful in the market for any application, much less
safety-critical applications.

Likewise, there has been great resistance on the part of
programmers to give up demonstrably error-prone programming
constructs, such as the infamous GOTO.  (Even using it as an
example is likely to start a new defense.)  Generality and
flexibility seem to be much more highly valued than simplicity.
The result is gratuitous and unnecessary complexity heaped on the
necessary.

Martin Thomas makes an interesting and related observation:

&gt;There is, of course, the related problem of what we mean by
&gt;"getting the design right" and "failure".  In general, these can
&gt;only be defined with hindsight - we recognise that the system
&gt;has entered a state which we wish it hadn't, and we define that as
&gt;failure.  We cannot (usually) guarantee that we have defined all
&gt;safe states, or all hazardous states, in advance.

But part of the problem is that there are an infinite number of
states.  A finite-state machine with a limited number of states
would limit the potential for error.

Thomas continues:

&gt;The question I would ask is: are we making our systems
&gt;significantly more  complex by converting to digital too soon
&gt;(or at all)? Would the system complexity be reduced if, instead
&gt;of converting to digital so that we can use a commercial
&gt;microprocessor, we processed the signals as analog signals,
&gt;using an application-specific integrated circuit (ASIC) and only
&gt;converted to digital where there is a clear reduction in
&gt;complexity from doing so?

There are two questions here, not one.  The first has to do with
the use of analog vs. digital.  And the other has to do with
"application specific."  Each of these has the potential to
reduce the complexity.  Each should be applied where it is
applicable.

&gt;This is a serious question:  latest technology allows mixed
&gt;analog-digital ASICs, and the cost and time to produce an ASIC
&gt;is competitive with the cost and time to produce the software and
&gt;circuit board for a microprocessor system - and the technology
&gt;is moving so that economics increasingly favour the use of ASICs.

Agreed, but then he continues further:

&gt;YOU CAN HAVE (SOME OF) YOUR FAVOURITE MICROPROCESSORS ON-CHIP,
&gt;TOO.

You sure can, but the favoritism is part of the problem, not the
solution.

&gt;To summarise:  the issue is system complexity - safety is
&gt;related (probably exponentially) to the inverse of complexity (if only we
&gt;could measure it) - SO REDUCING COMPLEXITY IS THE KEY TO
&gt;INCREASING SAFETY; can we make progress by exploiting analog
&gt;techniques?

Perhaps, but there is no question that we can reduce it by
employing finite-state application-specific processors.

William Hugh Murray, 21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840
203 966 4769, WHMurray at DOCKMASTER.NCSC.MIL

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-6</DOCNO>
<DOCOLDNO>IA013-000136-B028-362</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.33.html 128.240.150.127 19970217035918 text/html 18134
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:57:46 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 33</TITLE>
<LINK REL="Prev" HREF="/Risks/10.32.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.34.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 33</H1>
<H2> Friday 7 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Critical military computer systems 
</A>
<DD>
<A HREF="#subj1.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Complexity, reliability, and meaningless arguments 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: "Wild Failure Modes" in Analog Systems 
</A>
<DD>
<A HREF="#subj3.1">
Jan Wolitzky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Analog vs Digital Controls 
</A>
<DD>
<A HREF="#subj4.1">
Martin Ewing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Chaos 
</A>
<DD>
<A HREF="#subj5.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Software bugs "stay fixed"?     
</A>
<DD>
<A HREF="#subj6.1">
Bruce Hamilton
</A><br>
<A HREF="#subj6.2">
 K. M. Sandberg
</A><br>
<A HREF="#subj6.3">
 Andrew Koenig
</A><br>
<A HREF="#subj6.4">
 Michael Tanner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Boot camping 
</A>
<DD>
<A HREF="#subj7.1">
Timothy VanFosson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Critical military computer systems
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Fri,  7 Sep 90 10:19:42 PDT
</i><PRE>

The herein-debated list of critical computer applications, in which reliance on
computers is to be avoided includes, re defense, mere early warning systems.
Presumably, Space Command's rate of false alerts, and the Vincennes shootdown,
contribute to this opinion.  But there is an important nuance neglected in
challenging the warning systems -- early warning is clearly beneficial,
problems arise only when an immediate ("use-or-lose") decision to retaliate is
contingent upon it.  Thus, it is really the de facto computerization of
decision-to-shoot procedures that is at fault, not the neutral computerization
of warning information.

And so I would not avoid early warning systems, which can greatly assist taking
evasive or preparatory actions, but would squarely challenge the
computerization of command and control systems.  The leading example of such
damnably dangerous computerization is the under-development, half-billion
dollar Rapid Execution And Combat Targeting system, which will enable virtually
instantaneous launch of U.S. ICBM's within a couple of minutes, at all times.
This includes the introduction of PC's into launch silos, which will automate
launch code verification, and which will provide some sort of direct electronic
interface with the missiles.

Besides actualizing launch on warning and sudden first strike capabilities, the
implementation of REACT would seem to add to the risk of an accidental launch,
even without a flimsy attack warning.  (If launch codes are received at the
silos, standing orders require their immediate execution...)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Complexity, reliability, and meaningless arguments
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@murphy.ICS.UCI.EDU">
nancy@murphy.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Thu, 06 Sep 90 19:50:38 -0700
</i><PRE>

To save my having to mail this information individually to the many people
who have asked:

   The next meeting of SC 167 (the RTCA committee rewriting DO-178A) will be
   November 6-9 in Herndon VA (outside of D.C.).  You can get on the mailing
   list for notification of meetings by calling the RTCA (Radio Technical
   Commission for Avionics) at (202) 682-0266.

With regard to the complexity discussion, does the question of whether one
generic type of system is more complex or more reliable than another even 
make any sense? The same function can be implemented in a simple or "complex" 
way using any generic type of components.

Consider Rube Goldberg's design for a "simplified" pencil sharpener.  It starts
with a string attached to a kite flying outside a window.  When the window is
opened, the string lifts the door on a cage filled with moths allowing them to
escape and eat a red flannel shirt hanging above the cage.  As the weight of
the shirt decreases, a shoe (attached to the top of the shirt via a string
through a pulley) becomes heavier than the shirt and starts to move downward,
flipping a power switch on.  When the power goes on, an iron on top of some
pants on an ironing board burns a hole in the pants, creating smoke which
enters a hole in a tree trunk next to the ironing board, smoking out an opossum
which jumps into a basket from a higher hole in the tree, pulling a rope that
lifts a cage door allowing a woodpecker to chew the wood from the pencil
exposing the lead.  There is also an emergency knife which is always handy in
case the opossum or the woodpecker gets sick and can't work.

One could argue that Goldberg's simplified design has a larger number of
failure modes with a high probability of occurring and therefore will be less
reliable than more traditionally-designed pencil sharpeners.  However, his
design, although it may fail more often, has the backup knife which may result
in a higher probability of resulting in having a way to get your pencil
sharpened (even if a cat comes in through the open window and distracts the
opossum and the woodpecker) than a traditional pencil sharpener without the
knife.  So it is not only the number and probability of the failure modes that
counts, but also the ways you have provided for coping with component failure.

Consider also that a knife alone would be much more reliable than even a
regular pencil sharpener (especially one of the Ginzu knives that the TV
spokespeople tell me never get dull).  But it is definitely less safe in terms
of potential for drawing blood.  So if safety rather than reliability is your
higher priority goal ...

When comparing the reliability and safety of mechanical/analog systems and
digital systems, you need to consider:

  1)  Confidence and the ability to measure or assess reliability and
      safety in our systems may be more important than other factors. 
      I would prefer to design critical systems with components having known 
      failure modes and failure rates than those that MIGHT have lower failure
      rates, but also might have higher ones and I have NO way to determine 
      this with high confidence.
      
  2)  Analog and mechanical designs are often reused and perfected over long
      periods of time.  Not only does this tend to eliminate design errors,
      but it allows for high confidence in the failure rates and the projected
      failure modes.  Do unexpected failure modes pop up occasionally that were
      not expected?  Sure, so what? -- the alternatives are worse.

  3)  Wearout failures are much easier to detect and protect yourself 
      against (e.g., simple redundancy usually provides adequate protection)
      than design errors resulting in erroneous answers.

  4)  Tools and methods for building systems reliably and safely may be as
      important as other factors.  For example, system safety engineers have 
      many time-honed procedures for assessing and enhancing safety in 
      analog/mechanical systems but few of these have been extended to digital 
      systems.  Same applies to mechanical engineers.  And they tend to be
      trained in using these procedures.

  5)  Because it is (seemingly) easy to provide a great deal of functionality
      with little increased cost or trouble, digital components tend to have 
      greater functionality demanded of them (it is the usual argument for 
      replacing mechanical/analog devices).  This increases the probability 
      of design errors.

  6)  ... [lots of other complicating factors]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: "Wild Failure Modes" in Analog Systems (Hoover, <A HREF="/Risks/10.31.html">RISKS-10.31</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:wolit@mhuxd.att.com">
wolit@mhuxd.att.com
</A>&gt;
</address>
<i>
Fri, 7 Sep 90 10:02 EDT
</i><PRE>

Might as well carry this nit-picking one level further.  As long as
your computer's transistors, capacitors, or whatever rely on electrons,
photons, or other quantum-mechanical wave/particles with discrete
states, you are justified in considering them to be digital.  But this
is all silly -- the implementation is irrelevant.  If you can treat
the computer as a black box that behaves digitally, why not label it
as such?

Jan Wolitzky, AT&amp;T Bell Labs, Murray Hill, NJ; 201 582-2998 att!mhuxd!wolit 
(Affiliation given for identification purposes only)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Analog vs Digital Controls
</A>
</H3>
<address>
Martin Ewing 
&lt;<A HREF="mailto:EWING@Venus.YCC.Yale.Edu">
EWING@Venus.YCC.Yale.Edu
</A>&gt;
</address>
<i>
Thu, 6 Sep 90 22:27 EDT
</i><PRE>

Analog controls are not really the opposite of digital.  The main difference is
that digital logic often uses saturated transistors and obscure data coding as
a representation, or analog, of a physical parameter.  Digital systems do tend
to use an enormous number of transistors for even the simplest operations, but
they are integrated into a manageable number of chips.

Analog systems are plagued by poor gain calibrations, temperature drifts,
nonlinearities, and noise.  Nonlinearities can result in saturation and
"latch-up" behavior.  AC systems suffer from crosstalk, parasitic oscillations,
and lots of other ills.  A component failure can easily produce as drastic a
change in output as a digital failure might.

The "advantage" of analog systems is that they don't have software.  However,
they do have all the troubles listed above, which tend to limit functionality.
They also have circuit designers instead of programmers.

The safest control systems are passive ones, which use no analogs: reactors
that get less reactive at high temperatures and aircraft that fly themselves
with no control forces.

Martin Ewing, 203-432-4243, Ewing@Yale.Edu
Yale University Science &amp; Engineering Computing Facility

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Chaos
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:peter@ficc.ferranti.com ">
peter@ficc.ferranti.com 
</A>&gt;
</address>
<i>
Thu Sep  6 22:33:54 1990
</i><PRE>

&gt; Thus the possible range of catastrophic effects are inherently greater in
&gt; digital as opposed to analog systems.

Like the Tacoma Narrows bridge?

Peter da Silva.     +1 713 274 5180.     peter@ferranti.com

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Software bugs "stay fixed"? (<A HREF="/Risks/10.31.html">RISKS-10.31</A>, Parnas <A HREF="/Risks/10.32.html">RISKS-10.32</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Bruce_Hamilton.OSBU_South@Xerox.com">
Bruce_Hamilton.OSBU_South@Xerox.com
</A>&gt;
</address>
<i>
Thu, 6 Sep 1990 19:09:43 PDT
</i><PRE>

Re: "My perception is that they stay fixed, if they were actually fixed."

A nontrivial portion of the bugs we encounter in building and testing our large
systems are INTEGRATION (system-building) errors, where the wrong version of
some software was included.  Coding errors are only HALF the reason for
regression testing.

Bruce         BHamilton.osbuSouth@Xerox.COM        213/333-8075

</PRE>
<HR><H3><A NAME="subj6.2">
Re: Software bugs "stay fixed"? (Parnas, <A HREF="/Risks/10.31.html">RISKS-10.31</A>)
</A>
</H3>
<address>
K. M. Sandberg
&lt;<A HREF="mailto:sandberg@ipla01.hac.com ">
sandberg@ipla01.hac.com 
</A>&gt;
</address>
<i>
7 Sep 90 11:37:16 GMT
</i><PRE>

One problem is that sometimes the source code is not managed properly and code
that has the bug is reintroduced when fixing another bug. Also it is possible
that the code was "shared" and used in other programs/subroutines or the logic
that caused the bug is still in the programmer's head.  Major updates to the
code could also lead to the reintroduction of the bug for several reasons
including some one removing the fix as it seems not to be needed (lack of
comments?)

In other words there are many things that could cause the bug to reappear when
it was really fixed. This is the real world where anything is possible
(Remember Murphy's Law).
						Kemasa.

</PRE>
<HR><H3><A NAME="subj6.3">
Re: Software bugs "stay fixed"? (<A HREF="/Risks/10.31.html">RISKS-10.31</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ark@research.att.com">
ark@research.att.com
</A>&gt;
</address>
<i>
Fri, 7 Sep 90 09:29:12 EDT
</i><PRE>

I have had more experiences than I care to think about in which bugs have been
fixed, and fixed correctly, but then somehow the wrong version of the program
was sent to the user.

My `debugging rule number 0' is: before you go looking for a bug, make sure the
program you're looking at is the one you're running.  You'd be amazed how many
bugs have disappeared that way.
             				    --Andrew Koenig

</PRE>
<HR><H3><A NAME="subj6.4">
Re: Software bugs "stay fixed"? (Parnas, <A HREF="/Risks/10.32.html">RISKS-10.32</A>)
</A>
</H3>
<address>
Michael tanner
&lt;<A HREF="mailto:mtanner@gmuvax2.gmu.edu ">
mtanner@gmuvax2.gmu.edu 
</A>&gt;
</address>
<i>
Fri, 7 Sep 90 09:35:41 -0400
</i><PRE>

In practice the following occurs:

  1. Programmer A fixes a bug.  Some time later programmer B is given the same
     software to fix a different bug, or otherwise make changes.  He sees some
     extraneous code he doesn't understand, doesn't see how it could work, or
     whatever and in an attempt to clean up the program, deletes or changes
     it.  This turns out to be programmer A's bug fix, and the old bug is
     reintroduced.

  Or,

  2. Large systems get re-built occasionally, and sometimes with old versions
     of some routines, thus introducing old "fixed" bugs.

Users are accustomed to seeing old bugs resurface, and programmers often find
the above scenarios to be the cause.  Maybe good software practice would
prevent it, but it does happen.
                                                  -- mike

Michael C. Tanner, Dept. of Computer Science, George Mason University

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Boot camping (Ultrix, Wortman, <A HREF="/Risks/10.32.html">RISKS-10.32</A>)
</A>
</H3>
<address>
Timothy VanFosson 
&lt;<A HREF="mailto:timv@cadfx.ccad.uiowa.edu">
timv@cadfx.ccad.uiowa.edu
</A>&gt;
</address>
<i>
Fri, 7 Sep 90 14:49:11 GMT
</i><PRE>

I too had a similar problem because of *my* fit of tidiness.  Although my
machine (a VS3100) would boot, certain login ids would would be required to go
through the login process (Xprompter) two or three times before they would
actually work.  I know this is true because my id was one of them.  I guess an
added risk to the situation is that you may go crazy trying to remember your
last three months' worth of passwords before you figure out that it is an OS
problem :-).

Timothy VanFosson, Senior Systems Analyst, University of Iowa
CAD-Research, 228 ERF, Iowa City, Iowa 52242     Phone : (319) 335-5728 

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-7</DOCNO>
<DOCOLDNO>IA013-000136-B028-386</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.34.html 128.240.150.127 19970217035939 text/html 25739
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:58:06 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 34</TITLE>
<LINK REL="Prev" HREF="/Risks/10.33.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.35.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 34</H1>
<H2> Saturday 8 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Risks of shutdown? 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  French prisoners use "smart cards" 
</A>
<DD>
<A HREF="#subj2.1">
Robert Nagler
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Instrument Software failure in BAe aircraft 
</A>
<DD>
<A HREF="#subj3.1">
Sean
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  BMW's 'autopilot' 
</A>
<DD>
<A HREF="#subj4.1">
Michael Snyder
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: "wild failure modes" in analog systems 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Dealing with software complexity 
</A>
<DD>
<A HREF="#subj6.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Software bugs "stay fixed"? 
</A>
<DD>
<A HREF="#subj7.1">
Robert L. Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Computers and Safety (John 
</A>
<DD>
<A HREF="#subj8.1">
J.G.) Mainwaring
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Object Code Copyright Implications 
</A>
<DD>
<A HREF="#subj9.1">
Dan Bernstein
</A><br>
<A HREF="#subj9.2">
 Randall Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Accidental Disclosure of non-published phone numbers 
</A>
<DD>
<A HREF="#subj10.1">
Jeff Johnson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of shutdown? 
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Sat, 8 Sep 1990 12:49:01 PDT
</i><PRE>

In August 1989 the town of Tisbury, Massachusetts, signed a $113,000 contract
for a computer system, but a town meeting in October nixed the deal.  The
vendor refused to take the system back, and sued the town.  The town left the
CPU and printer plugged in, because they were uncertain whether just pulling
the plug would cause any damage, and because they did not know the "secret
password".  Finally, this August the vendor agreed that if the town would
negotiate, they would divulge the password to the town consultant, Eric Ostrum,
who could then shut down the system.

While the attorneys were negotiating, the consultant read the manual
instructions, got the system to answer "Do you want to shut down the system?",
and typed "yes".  Then, the system shut itself down, with no password required!
So he called the town's attorney and told him not to bother to negotiate for
the vendor assistance.  [Source: An article by Rachel Orr in the Vineyard
Gazette, 28 August 1990.]

[MORAL: The next time you want to hot-dog a vendor, let Ostrum hire weenies.]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
French prisoners use "smart cards"
</A>
</H3>
<address>
Robert Nagler
&lt;<A HREF="mailto:nagler@olsen.UUCP ">
nagler@olsen.UUCP 
</A>&gt;
</address>
<i>
Sat, 8 Sep 90 18:41:10 +0200
</i><PRE>

Prison `a la carte", The Economist, 8 Sep 1990, p 33:

  "Barely had the first miscreants arrived at France's newest prison, at Neuvic
in the Dordogne, than they started a riot.  Keen though the appetite of French
prisoners is for insurrection, their protest did not result from force of
habit.  The inmates of the ultra-modern jail had taken unkindly to exactly the
measures designed to make their lives more bearable.
  "In particular they objected to being locked up by computers.  Neuvic, which
opened two months ago and is still filling up, is a technological strongbox
containing the best ideas the penal service has so far come up with.  Every
prisoner carries a personalised ``smart card'', which must be used to enter or
leave any part of the prison.  The cards tell the central computer where all
the prisoners are, [or at least where their cards are :-] all the time, and
make the constant vigil of warders unnecessary.
  "In other words, the prisoners inform the security system.  It was hoped this
might give them a satisfying sense of responsibility, but the signs are not
promising.  Inmates liken the jail to a computerised warehouse where they are
stored as goods.  For example, if a man is a minute late for breakfast, he
cannot get out of his cell: the smart card works only to pre-programmed times.
The convicts also complain of prices in the prison shop that are 20% higher
than in other jails; cynics point out that Neuvic is being experimentally run
by private enterprise."  [After recently having been robbed in the south of
France, I have absolutely no sympathy.--RJN]

              [Excerpted by PGN, who thought it must have been a smarte garde.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Instrument Software failure in BAe aircraft
</A>
</H3>
<address>
&lt;<A HREF="mailto:sean@aipna.edinburgh.ac.uk">
sean@aipna.edinburgh.ac.uk
</A>&gt;
</address>
<i>
Sat, 8 Sep 90 13:19:49 BST
</i><PRE>

&gt;From The Guardian, September 8, 1990, page 2, column 7

Serious Failure' on BA planes (Patrick Donovan, Transport editor)

Instrument Panels on three British Airways aircraft `crashed' on eleven
occasions shortly after take-off or landing because of computer software
faults, according to Company Documents.  The problems occured on short-haul
European and domestic flights by three of the airline's British Aerospace
Advanced Turbo Prop aircraft in a period between July 9 and August 20 last
year.  Special restrictions were imposed on the 64-seater aircraft by the Civil
Aviation Authority because of the problems.  BA was told that pilots must be in
their seats when the aircraft flew below 5,000 feet in case emergency action
was needed.  Takeoff and landing was restricted to a minimum of 1,000 metres
visibility, the documents say.

Two of the aircraft affected continued flying although they had experienced
failure of `captain's and co-pilots primary displays' twice in one day.  One of
the aircraft, call sign G-BTPJ, suffered instrument failure five times on
fights between Belfast, Manchester, Glasgow, Aberdeen, Bremen, Berlin and
Manchester [sic].  Pilots were alerted by the caption `I/O Fail' flashing onto
a blank screen.  Aircrew managed to restore instrument readings after following
emergency technical procedures, the papers say.

A BA spokeswoman said last night that the problems had been rectified.  She
said that safety was not compromised as backup systems were available despite
loss of `primary instrument panels'.  However, the BA document described the
problems as being of a `serious nature'.  According to the papers the `cause of
the failures was due to a design shortfall' in instruments made by Smiths
Industries.  `Three incidents involved failure of all four displays which
required the aircraft to be flown using the standby instruments until the
displays were restored.  All the failures reported occured during the initial
climb, or climb phase with the exception of one incident which occured during
the approach.'

The documents also explain how BA is developing a `totally new code of practice
for dealing with major accidents'.  The report, circulated amoung BA
operational staff, says: `it is an inevitable fact of life that pilots,
engineers, operational personnel, indeed everyone involved in the operation of
aircraft will from time to time make professional errors.  Some of these
mistakes may result in an incident.'

Captain Colin Seaman, BA's head of safety, urges staff to be frank about
accidents.  `No matter what temptation there is after an accident to be
economical with the truth when rationalising it with hindsight, please remember
it would be unforgivable if, by not revealing the facts or the complete truth,
a similar incident became an unavoidable accident.'

    [What a wonderful sentence!  Reminds me of my favorite legal phrase,
    "Nothing in the foregoing to the contrary notwithstanding, ..."  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
BMW's 'autopilot'
</A>
</H3>
<address>

&lt;<A HREF="mailto:MSNYDER@csi.compuserve.com">
MSNYDER@csi.compuserve.com
</A>&gt;
</address>
<i>
05 Sep 90 17:42:04 EDT
</i><PRE>

In regard to BMW's "Heading Control System", my understanding (based solely
on hearsay) is that the guidance system provides more of a gentle nudge than
an irresistable shove when it thinks the car is approaching a lane divider
line.  Thus, it should not be difficult to leave the lane on purpose, either
to pass or to get out of danger.  However, has anyone thought of a more
distressing problem?  I refer you to countless "Roadrunner" cartoons.  Picture
a nice shiny white line leading directly into the side of a mountain...
				Michael Snyder, Compuserve

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: "wild failure modes" in analog systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Fri, 7 Sep 90 14:27:22 EDT
</i><PRE>

&gt;... we would never attempt to build systems of the complexity
&gt;of our current digital systems if we had only analogue engineering to rely on.

Unfortunately, this is not entirely true.  Very complex analog systems were
not at all unknown in pre-digital days.  Concorde's engine computers are
analog circuitry, which makes them a maintenance nightmare by modern
standards -- each setting interacts with others, so readjusting them
is a lengthy and difficult chore.  (It is not worth developing a digital
replacement for such a small number of aircraft.)  For another example,
I believe the US Navy's four ex-WWII battleships are still using their
original *mechanical* analog fire-control computers.  For still another,
although the recent fuss about fly-by-wire systems for aircraft has
focused mostly on digital versions, analog fly-by-wire systems were
not at all unknown:  Avro Canada's Arrow interceptor was flying at
Mach 2 with analog fly-by-wire in 1958.

Certain jobs simply require complex systems, and will be done one way or
another.  It is probably true that digital implementations make it easier to
add *unnecessary* complexity, but they also make it easier to do a better and
(potentially) more foolproof job on the basics.  This argument has many
parallels to the old ones about whether word processors lead to poorer writing,
or whether 16-bit address spaces forced better programming.  Analog circuitry
does encourage simplicity, yes... by making design, testing, and maintenance of
even simple systems more difficult.  This is not necessarily a virtue.

                         Henry Spencer at U of Toronto Zoology utzoo!henry

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Dealing with software complexity
</A>
</H3>
<address>
"Martin Minow, ML3-5/U26  07-Sep-1990 1555" 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Fri, 7 Sep 90 13:12:24 PDT
</i><PRE>

Several Risks postings have discussed system complexity and whether "risks"
are affected by, say, using analog components or finite-state automata.

One advantage to putting parts of the system into an analog component
is that it separates the problem into isolated (and smaller) units that can
be implemented and tested independently.  The benefits of isolation might
outweigh the disadvantages of analog designs.  Of course, such a
system could also be built out of all-digital components with a/d and d/a
convertors at the final stages.

Much the same can be said for finite-state automata.  Hand-encoded automata
offer a good development methodology for many problems as it is simple to know
when all state/action pairs are covered.  On the other hand, finite-state
automata generated by compilers (such as Unix' lex and yacc) can be fiendishly
difficult to hand-check as the "intelligence" is distributed among a number of
extremely obscure tables.  (In passing, I would make the same complaint about
object-oriented programming techniques.)
                                                                 Martin Minow

   [At least you were not CoOOPTed by a lex barker.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re:  Software bugs "stay fixed"?
</A>
</H3>
<address>
Robert L. Smith 
&lt;<A HREF="mailto:rlsmith@mcnc.org">
rlsmith@mcnc.org
</A>&gt;
</address>
<i>
Fri, 7 Sep 90 21:17:40 -0400
</i><PRE>

    Mr. Thomas implies that it is impossible to be certain, other than by
nonrecurrence, that a nontrivial software bug is fixed.  My experience
indicates otherwise.
    Just last week I was faced with misbehavior in a new program to analyze
tablet input, where the analysis depended upon prior selection of an input
sequence two or more PELs apart on either coordinate.  But close examination
revealed that points were occasionally being selected in adjacent PELs.  This
could occur because, having selected a point, instead of using that point as
the basis for succeeding comparisons, the program chose the next following
point.  The fix was easy -- as it happened by removing a line from the program
-- and the misbehavior was eliminated.
    This is my point: I am as certain as a man can be that the noted
misbehavior will never recur in that program for that reason, and I don't have
to run it five years to convince myself, either.
    Over the years I've tackled thousands of software bugs and noted that they
divide into two fundamental classes: those that I hoped I'd fixed and those
that I knew I'd fixed.  I've seldom been wrong about the latter but often about
the former.  In retrospect in seems to me that all of the latter were in code
that I'd written myself.  Maybe Mr. Thomas's "software rot" would be less
evident if the original writers were held responsible for quality throughout
the life of the code.  Maybe that's where we ought to have a law!
    Properly maintained software -- by the original writers -- asymptotically
over time approaches faultlessness of execution and design.  The reason for
this is that truly fixed bugs stay fixed.  Of all control logic media, only
software exhibits this characteristic.
    That is, when we let it.  In practice we never let that approach continue
for very long before all must be redone to fit the next generation of hardware.
rLs

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re: Computers and Safety
</A>
</H3>
<address>
John (J.G.) Mainwaring 
&lt;<A HREF="mailto:CRM312A@BNR.CA">
CRM312A@BNR.CA
</A>&gt;
</address>
<i>
Fri, 7 Sep 90 15:42:00 EDT
</i><PRE>

In his otherwise well rounded summary in <A HREF="/Risks/10.32.html">RISKS-10.32</A> of the computers,
complexity and safety discussion, Bill Murray raises the question of GOTOs,
admitting that it will probably be a red rag to someone.  I happen to be feel
bullish on GOTOs at the moment, so here goes.

I don't for one minute dispute Dijkstra's original thesis that GOTOs can be
replaced by other control structures, and they allow the creation of
programming monstrosities.  Deeply nested IF/THEN/ELSE and loop constructs are
also error prone. In C (which many people mistakenly believe to be a
programming language), BREAK is probably a worse time bomb than GOTO as
programs are maintained and modified, because the target of the branch is not
explicit.  Of course BREAK and also RETURN from the middle of a subroutine are
actually forms of GOTO.  Before using any of them, it's worth examining the
whole page to see if the flow of control can be improved.  However, some
strategies such as introducing new control variables may increase complexity of
the program rather than reducing it.

There is a parallel with the attitude of British Rail to safety as quoted by
Brian Randell in Risks-10.31: if the machine is built not to fail, you don't
have to worry about the operator.  Of course programming languages should be
designed to avoid as many programmer pitfalls as possible.  GOTO is a dubious
construct.  So are razors, but many people use them every day.  Changes in
design, caution in use, and readily available bandaids make them an acceptable
risk to society.

If we want safer computer software, we will have to concentrate on formation of
programmers. You can train people to keep their fingers away from the pointed
end of a chisel and not to drive screws with it, but it takes years to develop
a cabinet maker.  Likewise, you can train people what to do or not to do in a
language that provides GOTO, but to get good software for safety critical
applications requires the development of a body of people familiar with both
the application and software technology.  Of course improved software
technology will help too.

A cautionary example would be the design of bridges.  We now have much better
methods for designing bridges than we did in the nineteenth century.  Bridges
don't fall down nearly as often as they used to.  Nevertheless, people were
willing to use bridges then, and they still occasionally get killed using them
now.  We should remember that the design of a bridge is an abstraction, just
like a computer program.  Society has learned a good deal about managing the
life cycle of the bridge abstraction and the artifact derived from it.  We will
learn more about using computers safely over the next few lifetimes.  In the
meantime, perhaps the most useful function those of us who work with computers
can perform, apart from maintaining high standards in our individual endeavors,
is to continue to urge caution on those who, with less understanding, have
become entranced with the possibilites.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Object Code Copyright Implications
</A>
</H3>
<address>
Dan Bernstein
&lt;<A HREF="mailto:brnstnd@KRAMDEN.ACF.NYU.EDU ">
brnstnd@KRAMDEN.ACF.NYU.EDU 
</A>&gt;
</address>
<i>
Thu, 6 Sep 90 02:27:44 GMT
</i><PRE>

Three further comments on reverse engineering:

1. Decompilation isn't necessary for cloning; I don't think that a good
programmer gets anything useful out of decompilation anyway. So a law
prohibiting reverse engineering may not have much commercial effect.  (It's a
shame that economic concerns demand object-only distribution.)

2. Decompilation can be very useful in, e.g., figuring out the inner workings
of a virus as quickly as possible. So a law prohibiting reverse engineering may
add new risks to an already dangerous world.

3. Current copyright laws have special exemptions for each different case of
computer translation. A general rule like ``It is fair use to apply a
translation to a copyrighted work for personal use if the translation may be
defined precisely and axiomatically'' would embrace both compilation and
decompilation. It would also be in the spirit of recently expressed sentiments
on the unpatentability of software---and, unfortunately, nearly as contrary to
current practice.
                                           ---Dan

</PRE>
<HR><H3><A NAME="subj9.2">
Object Code Copyright Implications (Biddle, <A HREF="/Risks/10.24.html">RISKS-10.24</A>)
</A>
</H3>
<address>
Randall Davis
&lt;<A HREF="mailto:davis@ai.mit.edu ">
davis@ai.mit.edu 
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 18:01:32 edt
</i><PRE>

&gt; 1) If object code is copyrightable, what *exactly* is it that is subject
&gt;   to the copyright? Magnetic patterns? Ones and Zeros? Source code?

Copyright covers the way information is expressed and in this case the key to
expression is any binary alphabet (for which 1's and 0's are merely
conventional notation).  The only thing important about the magnetic patterns
of course is that there are two of them.  So it is in fact that particular
collection of 1's and 0's (or up's and down's or left's and right's...)  that
is copyright.

The same thing is true of text: it's the expression (the way information is
conveyed) that's copyright, not the shape of the letters nor the alphabet
that's used (using a different type font or a foreign alphabet won't change
anything important as far as copyright is concerned.)

&gt; Most importantly, these people seem to be arguing that if you have (legally)
&gt; an object-code program protected by copyright, and even though you *do* have
&gt; the "fair use" right to execute the program, you may *not* have the right to
&gt; inspect the program itself by disassembling or reverse compilation, to
&gt; determine how it may work in future circumstances.
&gt;  ... of course programs may be protected by other legal mechanisms which
&gt; are not addressed here. But copyright is usually the minimum.

Copyright law (in the US and probably elsewhere) is currently unclear on the
subject of reverse engineering: different lawyers argue it in different
directions and the recent Lotus case stemmed in part from the uncertainty
surrounding reverse engineering.

Hence in practice copyright is not invoked to deal with it: contract law is.
Most code is sold under the explicit agreement that it will not be reverse
engineered.  You agree to that under most shrink wrap contracts.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Accidental Disclosure of non-published phone numbers 
</A>
</H3>
<address>
Jeff Johnson 
&lt;<A HREF="mailto:jjohnson@hpljaj.hpl.hp.com">
jjohnson@hpljaj.hpl.hp.com
</A>&gt;
</address>
<i>
Wed, 05 Sep 90 10:13:01 PDT
</i><PRE>

In RISKS DIGEST 10.29, Peter Jones provided an excerpt from a Bell
Canada mailing that warned that, when calls are billed to other than
the calling phone (i.e., collect calls), the calling number is given to
the billed number.  The mailing stated that "this is necessary because
the customer being billed must be able to verify whether or not he or
she is responsible for the charge."

While I agree with this practice, I question the use of the words "necessary"
and "must".  What sounds like a logical requirement is in fact merely a
practice of North American culture.  I don't think it is common worldwide.  In
particular, as I recall from living in West Germany, residential phone bills
there are completely unitemized, they simply say: "Pay this amount."  If you
think your bill is out of line, you dispute it, and the (govt. run) phone
company double-checks for you.  Not a great system from my (American) point of
view, but it proves that is merely a matter of managing people's expectations,
rather than a question of necessity and requirement.
                                                            JJ

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-8</DOCNO>
<DOCOLDNO>IA013-000136-B029-20</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.35.html 128.240.150.127 19970217035955 text/html 30488
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:58:22 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 35</TITLE>
<LINK REL="Prev" HREF="/Risks/10.34.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.36.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 35</H1>
<H2> Monday 10 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Robustness of RISK architectures 
</A>
<DD>
<A HREF="#subj1.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  RISKS of relying on hardcopy printers (Voyager) 
</A>
<DD>
<A HREF="#subj2.1">
Tom Neff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Analog vs digital failure modes and conservation laws 
</A>
<DD>
<A HREF="#subj3.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Analog vs digital reliability 
</A>
<DD>
<A HREF="#subj4.1">
Jack Goldberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Software bugs "stay fixed"? 
</A>
<DD>
<A HREF="#subj5.1">
Tom Neff
</A><br>
<A HREF="#subj5.2">
 Stephen G. Smith
</A><br>
<A HREF="#subj5.3">
 Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Simulator classification as safety-critical 
</A>
<DD>
<A HREF="#subj6.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: New Rogue Imperils Printers 
</A>
<DD>
<A HREF="#subj7.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Postscript virus 
</A>
<DD>
<A HREF="#subj8.1">
Robert Trebor Woodhead
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Computers and Safety 
</A>
<DD>
<A HREF="#subj9.1">
Robert Trebor Woodhead
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  SafetyNet '90 Conference Announcement 
</A>
<DD>
<A HREF="#subj10.1">
Cliff Jones
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Robustness of RISK architectures
</A>
</H3>
<address>
Martin Minow 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Mon, 10 Sep 90 13:39:09 PDT
</i><PRE>

Last August, a note posted to info-vax@kl.sri.com showed how user-mode code
can crash a RISC (reduced instruction set) architecture machine.  The program
generated a string of random bytes and jumped into it.  Further discussion
showed that several RISC architectures could be crashed, but none of the
CISC (complex...) architectures that were tried. One person, commenting on
this, noted that one of the ways to speed up RISC architectures is to allow
certain (possible) instruction sequences to have undefined behavior, and to
let that behavior include "wedging" the machine.  However, CISC architecture
specifications make sure that every possible instruction (i.e., every pattern
of bits that can be loaded into the instruction register) returns the machine
to a known -- viable -- state.

Something else to lose sleep over...                            Martin Minow

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
RISKS of relying on hardcopy printers (Voyager)
</A>
</H3>
<address>
Tom Neff
&lt;<A HREF="mailto:tneff@bfmny0.bfm.com ">
tneff@bfmny0.bfm.com 
</A>&gt;
</address>
<i>
10 Sep 90 05:48:07 GMT
</i><PRE>

Although plain old hardcopy is often an excellent backup for reducing
the RISKS of losing magnetic storage, it's not foolproof, as seen in
this excerpt from the regular Jet Propulsion Laboratory (JPL) space
probe status bulletin:

                    Voyager Mission Status Report
                          September 7, 1990
 
                              Voyager 1
 
     ...On August 27 Computer Command Subsystem A004 (CCSL A004) began
execution.  Upon arrival for the prime shift on August 27 it was discovered
that five character printers in the real-time area were not printing due to one
cause or another; four of the printers were either not loaded correctly or were
configured in the "local" vs "online" mode and one printer had a paper jam.
All of these printers were missing data since early August 25.  One of the
character printers that was not functioning was the General Science printer.
The hard copy was needed for analysis of the PRA POR event. ...

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Analog vs digital failure modes and conservation laws
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Sun,  9 Sep 90 00:35:31 EDT
</i><PRE>

The recent discussion of the apparent inherent dangers of digital control
control systems reminds me of a story told in another context - but which I
think embodies an interesting kernel of truth.  If I remember right I heard
this from Bill McKeeman a couple of years back.  He was called in to consult
on a bank account control system, the development of which was way behind
schedule.  In talking to the banking people, he discovered an interesting -
if obvious in retrospect - dicotomy between computer people and business
people.  Computer people were impressed and happy with the generality and
power of their systems.  Hey, the same system they were using to manage bank
accounts could be programmed to play space invaders!  Neat, right?

The bankers found this terrifying:  If a system was general-purpose and that
powerful, they didn't feel they could understand or control what it was doing
to their bank accounts.  McKeeman's approach was to come up with what I guess
we'd today call an axiomatic/object-oriented approach:  He designed a series
of basic primitives to manipulate things like money, accounts, and so on.  The
primitives enforced, in a very transparent way, such basic "laws" as "the law
of conservation of money":  Money can be neither created nor destroyed, it
can only be moved from place to place.  The rest of the system was built on
top of these primitives, and was apparently a great success.

Now consider analogue and digital devices from the point of view of "laws".
One reason analogue devices tend to have more predictable behavior is that
their components follow fairly constrained physical laws - and, more
important, these are laws that we understand at a deep level and can work
with analytically.  If the total energy stored in a system is less than 1
joule, no possible failure mode can release more than 1 joule.  If that system
is enclosed inside of something with a certain thermal mass, no failure mode
can increase the temperature outside the enclosure by more than a certain
amount.  And so on.  Where the inherent constraints are insufficient to
guarantee safety, we can add constraints fairly easily.  A governer can limit
the maximum speed of a rotating element, hence indirectly such things as the
energy in the system.

There can certainly be catastrophic failures due to our failure to fully
understand the system:  We may only put a joule of energy in, but neglect the
energy stored in a spring that was compressed during assembly.  Let the pin
holding the spring down fail and all of a sudden there may be a lot more than
a joule in there.  However, we have many years of experience building these
kinds of systems, and we've seen most of these kinds of failures before.  We
also have a lot of experience making such failures very unlikely - and we can
realistically compute what "very unlikely" means.

General-purpose digital systems, on the other hand, are subject to no a priori
conservation laws.  If I show you all the lines of code of a program except
for one and ask you to bound the value of a variable in the program, you can
say nothing at all.  Well, there are two exceptions, and they're instructive:
If the variable isn't in scope at the hidden line, any bound you compute from
the rest of the code is valid (at least in a language where you can guarantee
that pointers aren't passed around arbitrarily).  If the language supports
variable declarations with bounds, AND guarantees to enforce them, then you
also are obviously in good shape.  (However, few languages do this.)

This example may shed some light on why scope rules are so important: Our
programming languages continue to emphasize power and generality, not
conservation laws.  Scope rules (and, every once in a while, bounded variable
declarations with appropriate support) are about all our languages, as such,
provide us with.

Now, the algorithm being executed itself provides constraints.  But there's a
problem here:  If the only source of constraints is the algorithm itself, an
error can easily render both the algorithm and the constraint enforcement
invalid.  Constraints so closely tied to what is being constrained don't add
safety.  Relying on them is like relying on a system that suspends a weight on
a string that can only hold five pounds and then saying "Well, it won't drop
the weight because I KNOW that if the weight were heavier than five pounds the
string would break."

Instead, constraints have to be programmed in explicitly.  This is all too
rarely done:  Because the underlying system is so general, there are just
SO many constraints to check.  In an analogue system, many of the constraints
come free because of the physical laws governing the parts of the system.

Beyond that, analogue systems are usually built of standardized parts - and
those standardized parts are specified to obey certain fundamental constraints.
We have relatively few standardized digital components, and often the
constraints on them aren't very useful: They are themselves hard to check.

							-- Jerry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Analog vs digital reliability
</A>
</H3>
<address>
Jack Goldberg 
&lt;<A HREF="mailto:goldberg@csl.sri.com">
goldberg@csl.sri.com
</A>&gt;
</address>
<i>
Mon, 10 Sep 90 10:50:09 -0700
</i><PRE>

Several correspondents have suggested that digital computers are less reliable
than analog computers because of certain intrinsic properties of the two
methods; for example, analog computing is more continuous, while digital
computing is subject to arbitrary redirection at every step, also, the
complexity of digital circuitry makes it more prone to failure.  This is an
interesting conjecture, but as stated it allows a confusion of design and
implementation issues.  Some analog realizations (cams, gears, relays with
heavy armatures, etc.)  do have certain reliability enhancing properties such
as continuity of state during loss of drive power, or known reset states in the
absence of power, but these properties do not extend to more common (and higher
speed) analog realizations.

Function for function, the design of a program that realizes a standard analog
function, e.g., integration or filtering, is about as easy to get right as its
analog counterpart, and its implementation in digital hardware may be even more
reliable (considering, for example, drift and noise in analog electronic
circuits and the sharing of services in multiple-function systems that is
possible in digital designs).

The real risk in using digital rather than analog computing may be that in
pursuit of enhanced system functionality, one can easily introduce complex
decision functions (with all their opportunity for design error) that would be
infeasible in analog computers.  In other words, the reliability benefit of
analog design may be that it does not allow the designer to attempt more
complex computing functions, with their possibilities for design error.  But
this limitation in computing functionality may place higher demands on human
operators or limit the capabilities of safety systems, so one has to look at
the larger picture.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Software bugs "stay fixed"?
</A>
</H3>
<address>
Tom Neff
&lt;<A HREF="mailto:tneff@bfmny0.bfm.com ">
tneff@bfmny0.bfm.com 
</A>&gt;
</address>
<i>
9 Sep 90 20:41:14 GMT
</i><PRE>

In RISKS 10.34 Robert L. Smith claims that it is possible to be certain that a
software bug has been eradicated without waiting for nonrecurrence, and cites
an example where he traced a bug in a tablet input program to one line of code,
which he removed, and now feels certain that the bug is gone.

Obviously if we consider the trivial cases -- 5 line class exercises and
whatnot -- we can KNOW a bug's gone.  In slightly more complex cases
where we nonetheless retain complete control over the code, we can stay
pretty near certainty that a bug is gone.  I'm sure most RISKS readers
encounter this sort of thing weekly.  You may not in all cases be
absolutely certain you've fixed everthing wrong, but the RISK of missing
something is deemed acceptable because further testing awaits.

But now take the case of truly HUGE projects, and truly old ones: the fertile
spawning grounds for RISKS incidents the world over.  How can we be sure we
have fixed a bug?  Suppose a "J" appears somewhere in a report and they task me
to fix it.  I find a typo in someone's module, featuring just such an errant
"J" in a constant string.  I correct the line.  Have I fixed the problem?
Anyone who thinks they can be certain without rerunning the report is in the
wrong line of work.  I have seen the "impossible" happen with fair regularity!
For instance: Yes I fixed the line in FROBOZZ.FTN, but what I didn't know is
that FROBOZZ is automagically regenerated by a code generator once a month from
a config file somewhere!  Next month, the "bug" reappears.  Or -- I corrected
my copy, but what I didn't know is that 6 other programmers have "boilerplated"
from this code to do their own projects, so that not one but dozens of errant
"J"'s appear in various reports.  It's fine for me to feel righteous about
having fixed the ONE instance originally noted, but when the customer keeps
seeing "J" it's impossible to convince him we really fixed the bug!  And so on
-- a hundred ways for human nature to conquer seemingly iron clad programming
"logic."  That's why checking for nonrecurrence is the best way -- prediction
is great, but observation pays the bills.

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Software bugs "stay fixed"? (<A HREF="/Risks/10.31.html">RISKS-10.31</A>)
</A>
</H3>
<address>
Stephen G. Smith
&lt;<A HREF="mailto:sgs@grebyn.com ">
sgs@grebyn.com 
</A>&gt;
</address>
<i>
Sun, 9 Sep 90 21:55:15 -0400
</i><PRE>

My experience with "bit rot", where previously solved problems reappear, is
that they are usually caused by poor configuration control.  While most systems
have CC tools, like sccs on UNIX or CMS on VAX/VMS, getting your friendly
average programmer to use them is like pulling teeth.  When management insists
on use of the tools, you will find lots of log entries of the form:

REV	DATE		USER	COMMENTS
1.1	10/02/89	root
1.2	10/05/89	root
	...		...

It seems that the preferred way of working on a large system is to
simply grab a complete copy of the source code (as root so that silly
protection modes don't get in the way :-) and hack away.  When you get
several programmers working on a section of code (not at all uncommon),
it's amazing that anything at all ever works.

Add in the interaction of hardware CC with software CC and you have orders of
magnitude more things that can go wrong.  It's amazing the number of times that
you find old software running on new hardware of vice versa.

Solutions?  Programmer education.  Even more important is manager
education, to eliminate the "It takes too much time" objection.  Telling
somebody at a salary review something like "We expect our &lt;next higher
position&gt; people to be fully familiar with our configuration control
methods.  You haven't shown this." is *extremely* effective.  Yes, I've
done this -- the explosions are interesting.

Steve Smith,   Agincourt Computing,   sgs@grebyn.com      (301) 681 7395

</PRE>
<HR><H3><A NAME="subj5.3">
Software bugs "stay fixed" (again!)
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Mon, 10 Sep 90 13:08:57 +0100
</i><PRE>

 In <A HREF="/Risks/10.34.html">RISKS-10.34</A> Robert L. Smith &lt;rlsmith@mcnc.org&gt; replies to my comments:

:    Mr. Thomas implies that it is impossible to be certain, other than by
:nonrecurrence, that a nontrivial software bug is fixed.  My experience
:indicates otherwise.

    (... anecdote about a bug and its correction removed for brevity)

:    This is my point: I am as certain as a man can be that the noted
:misbehavior will never recur in that program for that reason, ...
					      ^^^^^^^^^^^^^^^^

Here we have it. If the error is never reintroduced and if the distributed
program is compiled from the corrected source code, then this instance of
the incorrect behaviour will never recur. But what about the faulty thinking
which led to the error in the first place? Is it an incorrect mental model
of the design, which could have led to similar errors (with identical
symptoms) elsewhere in the program? Is it a misunderstanding of the meaning
of a programming construct or library call (which could also lead to other
similar errors)? I believe that this is what Dave Parnas (RISKS 10:32)
meant by "...if they were not *properly corrected* " (my emphasis).

Note also "as certain as a man can be" above.
Unfortunately people keep asking us to quantify this statement!

But this thread has rather lost its way. It started through my attempt to
counter Robert Smith's seeming argument that software was better than
hardware for critical applications because hardware errors recur whilst
software errors do not. Of course software doesn't display the failures that
hardware does, through components wearing out, but that is a small
consideration alongside the bigger issues of system complexity and costs.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Simulator classification as safety-critical
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Mon, 10 Sep 90 13:24:30 +0100
</i><PRE>

In <A HREF="/Risks/10.32.html">RISKS-10.32</A> Brinton Cooper &lt;abc@BRL.MIL&gt; writes:

:Pete Mellor and Martyn Thomas agree that
:&gt;&gt; You cannot expect crew to do better than their
:&gt;&gt; training under the stress of an emergency.
:Er...the crew are, after all, thinking humans and merely another set of
:automatons in the system.  A recent (past 5 years) air crash in the mid-US was
:less disastrous than it might have been precisely because the pilot performed
:beyond his training, in a situation which he had not been expected to
:encounter.  This is, after all, one of the differences between human and
:machine.  

This is missing the point. Crew may indeed do better than their training,
but it is surely unacceptable to use this as an argument that a flight
simulator is not safety-critical. If the simulator trains behaviour which
causes an accident, the accident is logically a consequence of the simulator
design, not of the crew (who are behaving exactly as trained). 
Doesn't this make the simulator as critical as any cockpit system?

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Postscript virus (<A HREF="/Risks/10.32.html">RISKS-10.32</A>)
</A>
</H3>
<address>
Robert Trebor Woodhead 
&lt;<A HREF="mailto:trebor@foretune.co.jp">
trebor@foretune.co.jp
</A>&gt;
</address>
<i>
Mon, 10 Sep 90 13:35:08 JST
</i><PRE>

In re: the alleged Postscript virus reported in the SJ Mercury.

Rumors of this have been flying around the virus-hunter's network for
some weeks now, and two separate vaccines have been developed; to wit,
one that is added to the Laser Prep file on the Macintosh to disable
the SETPASSWORD operator temporarily (until next reboot of the printer)
and an after-the-fact password resetter that reads the old password
from the EEPROM on the Laserwriter and uses it to reset the password
(This works only on 68000 based Laserwriters, and probably only on ones
using ADOBE PostScript.

After much discussion, it was generally agreed upon that these tools would not
be released except on an as-needed basis, for several reasons.  Primary
amoungst these is that nobody has yet come up with a confirmed sighting of the
alleged poisoned clip-art; thus the scattered reports of malignant graphics
could in fact be isolated cases of either weird machine messups, or some jerks
just downloading a line or two of PostScript.

However, it should be noted that the other major reason was that the cure may
be worse than the disease, in that the number of reports of problems with
Laserwriter passwords is so small that it would be dwarfed by the number of
problems caused by improper installation and use of the cures, and additionally
the cures can easily be perverted into new variants of the possibly spurious
disease they were intended to cure.

Robert J Woodhead, Biar Games, Inc.  !uunet!biar!trebor trebor@biar.UUCP 

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: New Rogue Imperils Printers
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Mon, 10 Sep 90 13:46:22 EDT
</i><PRE>

&gt;... PostScript, that "surreptitiously reprograms a chip inside the
&gt;printers, changing a seldom-used  password stored there. When the
&gt;password is altered, ...  the printer no longer functions properly."

It's not entirely clear what is going on here -- whether the code is
simply doing a password change by virtue of knowing the old password
or whether it's doing it by some sneak path -- but it raises an
interesting risk either way.

The password on a PostScript printer (well, in the usual implementation)
is a number.  It protects certain parameters of the printer that user
code really shouldn't change, like communications parameters and idle
timeouts.  There is considerable potential for malice in knowing the
password, up to and including causing hardware damage of a minor sort
(the EEPROM used to store printer parameters can be rewritten only a
limited number of times due to wear-out processes in the chip).

The default password as shipped is 0.  Very few printer owners bother
to change this.  The problem is that there is significant incentive
*not* to change it... because the PostScript code from a good many
badly-written but legitimate applications tries password 0 and will fail
if it has been changed!  Typically, all the application uses it for is
to set some parameters back to reasonable defaults -- whether the printer
owner wants it that way or not -- but the code makes no attempt to cope
with the possibility of a non-standard password forbidding such changes.

Believe it or not, there are people who will defend the idea that you should
leave your printer's password unchanged so that programs can mess with its
parameters however they please.

                              Henry Spencer at U of Toronto Zoology utzoo!henry

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Computers and Safety (<A HREF="/Risks/10.34.html">RISKS-10.34</A>)
</A>
</H3>
<address>
Robert Trebor Woodhead 
&lt;<A HREF="mailto:trebor@foretune.co.jp">
trebor@foretune.co.jp
</A>&gt;
</address>
<i>
Mon, 10 Sep 90 13:55:49 JST
</i><PRE>

J.G. Mainwaring discourses about GOTO's and the infamous C BREAK
(as in "Here is where your program will BREAK!")

It has long been my opinion (which as we all know, carries the force
of law in several of the smaller West African countries.. ;^) that the
EXIT() command pioneered in UCSD PASCAL was an ideal compromise.

EXIT(a) exited you from enclosing procedure "a", which made it most
convenient for getting out of incredibly convoluted nested structures
without making them hugely more convoluted.  It was the equivalent of
a restricted GOTO to the end of the current procedure, with the extra
ability to exit any enclosing procedure (even PROGRAM, the whole
kit-n-kaboodle).  It gave you the the same abilities as 90% of GOTO
use, but you always knew exactly what it was going to do, and thus
it was much less dangerous than BREAK.

A nice side effect of the ability to semantically nest procedures and
functions in PASCAL was that this allowed you to put inner parts of
some horrifically obscure structure into sub-procedures, allowing you
to exit from the inner parts but not the outer parts.

Robert J Woodhead, Biar Games, Inc.  !uunet!biar!trebor trebor@biar.UUCP 

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
SafetyNet '90 Conference Announcement
</A>
</H3>
<address>
&lt;<A HREF="mailto:cliff@computer-science.manchester.ac.uk">
cliff@computer-science.manchester.ac.uk
</A>&gt;
</address>
<i>
Wed, 5 Sep 90 14:58:38 BST
</i><PRE>

	THE SAFETYNET '90 CONFERENCE &amp; EXHIBITION
	FORMAL METHODS FOR CRITICAL SYSTEMS DEVELOPMENT
        Royal Aeronautical Society, 4 Hamilton Place, London
	Tues 16th October   -   Wed 17th October 1990
        Registration &amp; Coffee, 9.00a.m. - 9.30a.m.

	SafetyNet, PO Box 79, 19 Trinity Street, Worcester, WR1  2PX
        Tel: 0905 611512  Fax: 0905 612829

SafetyNet '90		Programme Day 1			16th October

09.30	General Chair			Digby A. Dyke, Editor, SafetyNet

09.40	Session 1 Chair			Dr. John Kershaw, RSRE
							
09.50	Tutorial 1:
	An Introduction to the RAISE    Soren Prehn, Computer Resources
	Specification Language		International

10.40	RAISE- A Case Study of		Soren Prehn
	a Concurrent System		Computer Resources International
							
11.35	Critical Software -		Peter Jesty, Dr. Tom
	A Standard and its		Buckley, Keith Hobley
	Certification			&amp; Margaret West, University of Leeds

12.10	Intellectual Property		Dr. Mathew K.O. Lee
	Critical Systems		BP Research Centre

14.00	Product Liability (Civil	Ranald Robertson
	&amp; Criminal) Issues for		Partner,
	Developers of Safety-		Stephenson Harwood
	Critical Software		Solicitors

14.35	Methods for Developing		Stephen Clarke, Andy Coombes 
	Safe Software			&amp; John A McDermid, University of York

15.30	Panel 1:			Chair:
	What are the relationships	Prof Bernard Cohen
	among standards, certifica-	Rex, Thompson &amp;
	tion, compliance, evidence	Partners
	and legal liability ?

16.30	Panel Summary			Prof Bernard Cohen

16.40	Closing Remarks			Dr. John Kershaw

16.45	Close of Day 1 (Please depart by 17.45)

19.30	Conference Dinner		Guest Speaker
	Le Meridien Hotel, Piccadilly, London


SafetyNet '90		Programme Day 2			17th October

09.35	General Chair			Digby A. Dyke, Editor, SafetyNet

09.40	Session 2 Chair			Fred Eldridge, Rex, Thompson &amp;
					Partners

09.50	Tutorial 2:			Peter Froome and Jan Cheng Adelard
        A Formal Method	for Concurrency			

10.40	Application of Formal		Dr. D.S. Neilson
	Methods to Process Control	BP Research Centre
	
11.35	Proof Obligations 3:		Prof Bernard Cohen,
	Concurrent Systems		Rex, Thompson &amp;	Partners

12.10	Refinement in the Large		Paul Smith, Secure Information Systems

14.00	An Introduction to the NODEN	Dr. Clive Pygott, RSRE
        Hardware Verification Suite

14.35	Mural - A Formal Development 	Dr. Richard Moore
	Support Environment		University of Manchester

15.30	Panel 2:			Chair: Prof Cliff Jones, 
	What is inhibiting widespread	University of Manchester
        use of Formal Methods ?		

16.30	Panel Summary			Prof Cliff Jones

16.40	Closing Remarks			Fred Eldridge

16.45	Close of Day 2 (Please depart by 17.45)

Liz Kerr, SafetyNet, PO Box 79, 19 Trinity Street, Worcester  WR1  2PX
Tel: 0905 611512, Fax: 0905 612829  
                               [Coffee, lunch, tea breaks omitted.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-9</DOCNO>
<DOCOLDNO>IA013-000136-B029-53</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.36.html 128.240.150.127 19970217040010 text/html 23346
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:58:38 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 36</TITLE>
<LINK REL="Prev" HREF="/Risks/10.35.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.37.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 36</H1>
<H2> Wednesday 12 September 1990</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Railway Safe Working - large analogue systems 
</A>
<DD>
<A HREF="#subj1.1">
Skillicorn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: BMW Heading Control System 
</A>
<DD>
<A HREF="#subj2.1">
A. L. Bangs
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Robustness of RISC architectures 
</A>
<DD>
<A HREF="#subj3.1">
Andy Glew
</A><br>
<A HREF="#subj3.2">
 Dave Sill
</A><br>
<A HREF="#subj3.3">
 Andrew Taylor
</A><br>
<A HREF="#subj3.4">
     Henry Spencer
</A><br>
<A HREF="#subj3.5">
 Peter Holzer
</A><br>
<A HREF="#subj3.6">
 Robert Cooper
</A><br>
<A HREF="#subj3.7">
 Dik T. Winter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Computers and Safety 
</A>
<DD>
<A HREF="#subj4.1">
Peter Holzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Software doesn't wear out? 
</A>
<DD>
<A HREF="#subj5.1">
Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Software bugs "stay fixed" 
</A>
<DD>
<A HREF="#subj6.1">
Peter da Silva
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Railway Safe Working - large analogue systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:skill@qucis.queensu.ca">
skill@qucis.queensu.ca
</A>&gt;
</address>
<i>
Tue, 11 Sep 90 15:30:07 EDT
</i><PRE>

One area in which safety and reliability of analogue systems is well-understood
is railway safe working. Risks readers will certainly find L.T.C. Rolt's book
"Red for Danger" interesting and instructive. It covers the development of safe
working in the U.K.  from the first railways to the late Sixties (my edition
anyway).  There are many good examples of risks unnoticed, risks fixed badly,
re-appearing risks, and the work it takes to make people realize the risks and
then pay the price of fixing them.

Given the long experience in the U.K with safety in railway systems, you might
wonder why accidents such as Purley happen. It puzzles me too.  BR has the
technology to detect, on the train, the state of trackside signals, but only
uses it, in the first instance, to inform the driver.  In Australia (at least
NSW) signals are equipped with a small handle which pivots up when the signal
is at red and contacts a trip on the brake system if a train attempts to pass
it. The driver cannot subvert the systemin motion, although he can reset the
system and proceed once the train has fully stopped. This can only be done from
outside the train (by climbing down to the trip and manually resetting it).
This seems to be much more consistent with the rest of the safe working system,
where signal box interlocks are implemented by requiring two largish pieces of
metal to occupy the same space for conflicting events to occur. The only
failure mode here is severe deformation of the metal rods.

Of course, this kind of absolute block working is not always appropriate.  In
places where it is common to want to pass a red signal (dense suburban) extra
arms are installed between signals. These drop in sequence at a rate which
reduces the train speed to around 20 km/h.  Again there is no way to go faster
without overunning a raised arm.

Suburban trains have the usual dead-man's throttle handle (the throttle must be
pressed down continuously for it to work on the brakes not to be applied), but
long distance diesels have a vigilance button which must be pressed every sixty
seconds to keep the brakes off. It's a good thing that brakes are applied
automatically because it is commonly believed that old hands can press this
button even when sleeping. I've observed the automaton-like way that drivers
press this button and I have no doubt that it happens. So I remain surprised
that BR didn't seem to believe that train crew vigilance could be a problem.

Mind you, it all seems very safe compared to Canada where express passenger
trains are managed using CTC and walkie-talkie radios. I've seen passenger
trains following one another, separated by a few hundred yards, and relying
purely on the vision of the driver in the second train. Authorized by radio, no
hardware protection.
                                          -David Skillicorn

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: BMW Heading Control System
</A>
</H3>
<address>
BANGS A L 
&lt;<A HREF="mailto:abg@stc06.ctd.ornl.gov">
abg@stc06.ctd.ornl.gov
</A>&gt;
</address>
<i>
Tue, 11 Sep 90 09:57:21 EDT
</i><PRE>

Michael Snyder's message about the Road Runner problem, i.e., that the system
may not be able to cope with roads that go into mountains, can be a serious
one.  If people rely on the system enough that they tend to take their hands of
the wheel and stop watching the road, then they could get in big trouble if
they suddenly come to a construction site.  Especially if they are moving along
quickly in their BMW :-)

In other words, if the system is good enough to give people confidence, but is
not good enough to deal with all possible situations, then it is risky.

Alex L. Bangs, Oak Ridge National Laboratory/CESAR, Autonomous Robotic Systems

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Robustness of RISC architectures (Minow, <A HREF="/Risks/10.35.html">RISKS-10.35</A>)
</A>
</H3>
<address>
Andy Glew
&lt;<A HREF="mailto:aglew@dual.crhc.uiuc.edu ">
aglew@dual.crhc.uiuc.edu 
</A>&gt;
</address>
<i>
Wed, 12 Sep 90 10:57:51 CDT
</i><PRE>

&gt;Last August, a note posted to info-vax@kl.sri.com showed how user-mode
&gt;code can crash a RISC (reduced instruction set) architecture machine.
&gt;[...]  several RISC architectures could be crashed, but none of the CISC
&gt;(complex...) architectures that were tried.

Let's dispose of the supposition that this is a RISC/CISC issue.  Arne
Helme &lt;arne@sfd.uit.no&gt; reposted "crashme" to the comp.arch newsgroup,
and obtained a flurry of reports:

80386, '386 protected mode unix =&gt; system crash		Peter da Silva
80386, '286 protected mode unix =&gt; system crash		Peter da Silva
DG Aviion (88K),  DG/UX 4.30 	=&gt; no crash    	    	?
decsystem 5200 Ultrix V3.1A 	=&gt; crash	    	Arne Helme
sun 4 SPARC station sunOS4.03c 	=&gt; crash	    	Arne Helme
MIPS R[236]000 RISC/os 4.50 	=&gt; no crash    	    	Charlie Price
Sun-3/50 SunOS 4.1 		=&gt; unkillable cpu-bound process 	
    	    	    	    	    	    	    	Andrew Taylor

Obviously, some RISCs crashed, some CISCs crashed, some RISCs
survived, some CISCs survived.

The problem most likely is an OS bug. Chris Torek remembers the discussion as
follows: "on all the machines that crashed *except one*, it was a bug in the OS
and not in the chip.  The one exception?  A CISC."

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Robustness of RISC architectures (Minow, <A HREF="/Risks/10.35.html">RISKS-10.35</A>)
</A>
</H3>
<address>
Dave Sill, Oak Ridge National Laboratory
&lt;<A HREF="mailto:de5@de5.CTD.ORNL.GOV ">
de5@de5.CTD.ORNL.GOV 
</A>&gt;
</address>
<i>
Tue, 11 Sep 90 13:14:55 GMT
</i><PRE>

&gt;... One person, commenting on
&gt;this, noted that one of the ways to speed up RISC architectures is to allow
&gt;certain (possible) instruction sequences to have undefined behavior, and to
&gt;let that behavior include "wedging" the machine.  However, CISC architecture
&gt;specifications make sure that every possible instruction (i.e., every pattern
&gt;of bits that can be loaded into the instruction register) returns the machine
&gt;to a known -- viable -- state.

One person said that, but is it true?  I find it hard to believe that excluding
undefined behavior would necessarily exact a performance penalty.  Further,
another person in that same discussion said that the types of bugs causing the
RISC machines to crash were typical of early hardware bugs in CISC machines
too, and that the reason the RISC machines were crashing was because the simply
weren't as thoroughly debugged as the CISC machines.

I don't know who's right, but both explanations seem equally plausable.  It
seems premature to lose sleep over RISC robustness at this point.

Dave Sill (de5@ornl.gov), Martin Marietta Energy Systems, Workstation Support

</PRE>
<HR><H3><A NAME="subj3.3">
Robustness of RISC architectures
</A>
</H3>
<address>
Andrew Taylor 
&lt;<A HREF="mailto:andrewt@cs.su.oz.au">
andrewt@cs.su.oz.au
</A>&gt;
</address>
<i>
Tue, 11 Sep 90 15:50:05 +1000
</i><PRE>

I don't believe this is a RISC versus CISC issue. The "execute-random-data"
program found an *OS* bug in both our (RISC) MIPS boxes and our CISC Sun 3/50s.

On the MIPS the behaviour of some instruction in the conditional branch format
is undefined. If there is an illegal FP instruction in the delay slot of such
an undefined branch instruction. The FP instruction traps to the OS which
determines the FP instruction is in a delay-slot and tries to calculate
the branch destination. The OS routine called to do this detects the branch
instruction is undefined but does the wrong thing, it calls "panic" halting
the machine. Trivial to fix.

On our SUN 3/50s (running SunOS 4.1) some random code sequences result
in a cpu-bound process which can not be killed. Rebooting is the only solution.

Its possible that OS bugs are more prevalent on RISCs because their OSs are
younger.

Andrew

</PRE>
<HR><H3><A NAME="subj3.4">
Re: Robustness of RISC architectures
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Tue, 11 Sep 90 12:28:09 EDT
</i><PRE>

In fairness, it should be noted that most of these crashes appear to have
been the result of *software* problems:  the operating system was not
prepared to cope with this bizarre situation when the hardware noticed it.

&gt;... one of the ways to speed up RISC architectures is to allow
&gt;certain (possible) instruction sequences to have undefined behavior, and to
&gt;let that behavior include "wedging" the machine...

Very few RISC designers (none that I know of, in fact) are that stupid.
Yes, RISC architectures often state that the results of certain sequences
are undefined, but wedging the machine is *not* considered a legitimate
result.  (Not in a machine meant to support multi-user systems, at any
rate; the rules are different for some of the more specialized processors.)
Claims to the contrary are the result of ignorance or ulterior motives.

This is simply a question of proper design, not of RISC vs CISC.  Certain
early and buggy releases of a certain CISC processor were notorious for
bugs in the protection system, e.g. circumstances in which a memory
fetch would be done with "system" permissions when it was initiated
from "user" state, or vice-versa.  This was mostly a result of the great
complexity of the processor and its interactions with memory management;
a similar problem would have been rather less likely on a RISC machine.
So it cuts both ways.

&gt;... CISC architecture
&gt;specifications make sure that every possible instruction (i.e., every pattern
&gt;of bits that can be loaded into the instruction register) returns the machine
&gt;to a known -- viable -- state.

It is necessary to understand that "known" and "viable" are two different
criteria, analogous to the frequently-mentioned-on-Risks distinction between
correct functioning and safe functioning.  It is not necessary that the result
of violating the rules be precisely defined and the same for all variants of a
particular architecture; what is required is merely that none of the possible
results endanger system integrity.

                          Henry Spencer at U of Toronto Zoology    utzoo!henry

</PRE>
<HR><H3><A NAME="subj3.5">
Re: Robustness of RISC architectures (Minow, <A HREF="/Risks/10.35.html">RISKS-10.35</A>)
</A>
</H3>
<address>
Peter Holzer
&lt;<A HREF="mailto:hp@vmars.UUCP ">
hp@vmars.UUCP 
</A>&gt;
</address>
<i>
11 Sep 90 16:56:22 GMT
</i><PRE>

This was shown to be a OS bug on the DECstations (The OS could not correctly
resume a process that trapped just after a delayed branch and instead of 
killing the process panicked). One person also reported that his 386 (a CISC 
processor) could be crashed with the same program (He did not say which 
UNIX he used, however. My 386 running 386/ix did not crash).

And talking of VAXes. You can crash a VAX under ULTRIX by loading the frame
pointer with a negative value and then trapping into the OS. 

Peter J. Holzer, Technische Universitaet Wien   hp@vmars.tuwien.ac.at
                                                ...!uunet!mcsun!tuvie!vmars!hp	

</PRE>
<HR><H3><A NAME="subj3.6">
Re: Robustness of RISC architectures
</A>
</H3>
<address>
Robert Cooper
&lt;<A HREF="mailto:rcbc@cs.cornell.edu ">
rcbc@cs.cornell.edu 
</A>&gt;
</address>
<i>
Tue, 11 Sep 90 16:08:59 EDT
</i><PRE>

Many RISC architectures have a notion of a well-defined instruction 
stream, and undefined instruction sequences may exhibit undefined
behaviour. Whether this is a real RISK, as usual, depends on a host
of other factors and assumptions relating to the total system of which the
RISC processor is only a part. Here are a few that come to mind:

 o You are not supposed to write (much) assembly code on a RISC. Therefore
   if the compiler is "safe" (i.e. never generates illegal instruction
   sequences) , and object code is protected read-only, executing undefined
   instruction sequences is unlikely. Note that a "safe" compiler need
   not be correct. This idea is not new: these assumptions were necessary
   for the B5000/B6000 series of Burroughs computers of the '60s which had
   unsafe user-mode object code but relied on certified compilers.

 o If the processor is used in a single user application (e.g. an
   embedded application) then there is little difference between just the
   application program failing and the whole processor failing. Both
   may result in byzantine failures for instance.

 o One can question the complexity needed for operating system and compiler
   software as a result of the RISC approach. OS code must perform much
   more work on traps and interrupts than on a typical CISC machine,
   and compiler optimizations are required to realize most of the 
   performance benefits of RISC. Clearly these are not impossible
   requirements but my experience suggests that it takes several years
   *after* a RISC machine is introduced for the OS and compiler software
   to become robust.

A particularly bad scenario could be a multi-user university computer that is
used for a student compiler writing course and for payroll!
                                                             -- Robert Cooper

</PRE>
<HR><H3><A NAME="subj3.7">
Re: Robustness of RISC architectures
</A>
</H3>
<address>
Dik T. Winter
&lt;<A HREF="mailto:dik@cwi.nl ">
dik@cwi.nl 
</A>&gt;
</address>
<i>
11 Sep 90 23:46:17 GMT
</i><PRE>

Martin Minow writes about a program consisting of random bytes:
 &gt;                                                         Further discussion
 &gt; showed that several RISC architectures could be crashed, but none of the
 &gt; CISC (complex...) architectures that were tried.
There was more than one report of a CISC machine that crashed.  The blame
was lain by some at the (possibly undefined) behaviour of some instruction
sequences of RISC machines, but no proof was given.  It is much more likely
that the machines crash because of bugs in the operating system.  (I know
at least one sequence of bytes that will crash a Sun 4 in some situations,
but I also know that it is due to an OS bug.)

The risk is obvious, one part of the system gets the blame, while nobody
looks at the remainder of the system.

dik t. winter, cwi, amsterdam, nederland   dik@cwi.nl

   [There seemed to be enough novel in each of the preceding 7 messages
   that they are all included.  I hope you are not all suffering from the
   bRISC fRISC.     RISKS OF RISCs, I guess...   PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Computers and Safety (<A HREF="/Risks/10.34.html">RISKS-10.34</A>)
</A>
</H3>
<address>
Peter Holzer
&lt;<A HREF="mailto:hp@vmars.UUCP ">
hp@vmars.UUCP 
</A>&gt;
</address>
<i>
11 Sep 90 16:11:29 GMT
</i><PRE>

Robert Trebor Woodhead &lt;trebor@foretune.co.jp&gt; writes:

&gt;J.G. Mainwaring discourses about GOTO's and the infamous C BREAK
&gt;(as in "Here is where your program will BREAK!")

&gt;It has long been my opinion (which as we all know, carries the force
&gt;of law in several of the smaller West African countries.. ;^) that the
&gt;EXIT() command pioneered in UCSD PASCAL was an ideal compromise.

&gt;EXIT(a) exited you from enclosing procedure "a", which made it most
&gt;convenient for getting out of incredibly convoluted nested structures
&gt;without making them hugely more convoluted.  It was the equivalent of
&gt;a restricted GOTO to the end of the current procedure, with the extra
&gt;ability to exit any enclosing procedure (even PROGRAM, the whole
&gt;kit-n-kaboodle).  It gave you the the same abilities as 90% of GOTO
&gt;use, but you always knew exactly what it was going to do, and thus
&gt;it was much less dangerous than BREAK.

I do know what break does: It gets me out of the enclosing switch statement
or loop. This is much less powerfull then EXIT, which does not just leave
this procedure (like C return) but eventually other procedures as well, which
is more than you can do with goto in C (You would have to use setjmp/longjump)
to do this.

Comparing EXIT with break does not make sense. It is a generalized return
(Handy with those nested procedures you have in Pascal).

The danger of break is not that it leaves the switch or loop, but that you
can leave it out were it would belong:

switch (a) {
case A:
	/* code */
case B:
	/* more code */
	break;
default:
	/* even more code	*/
}

Now should there be a break just before 'case B:' ? You have to understand
the algorithm to answer the question.

This can happen with EXIT just as easily.

Peter J. Holzer, Technische Universitaet Wien   hp@vmars.tuwien.ac.at
                                                ...!uunet!mcsun!tuvie!vmars!hp	

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Software doesn't wear out?
</A>
</H3>
<address>
"FIDLER::ESTELL" 
&lt;<A HREF="mailto:estell%fidler.decnet@scfd.nwc.navy.mil">
estell%fidler.decnet@scfd.nwc.navy.mil
</A>&gt;
</address>
<i>
11 Sep 90 08:23:00 PDT
</i><PRE>

Software doesn't wear out?  Doesn't that depend on your definitions?

Example: I use a program, duly protected by both copyright, and trade secret 
(of portions not disclosed in the copyright process).  I use that program 
under terms of a valid contract.  The program quits working some first of a 
month, because the contract has expired.  I order up a new copy.  When it 
comes, it is *not* necessarily backwards compatible with my extant data files.

Now, is my program "broken" [worn out] or not?  It may function well by the
*current* definitions of the vendor; but it does not get my work done any 
longer.  (At least, not until I "make the problem fit the new too.")
That sounds like a car that won't start, or run; but no, the trouble 
is *not* covered by the 5/50 warranty either.  Sorry.  (Or, perhaps better 
analogy, the car won't run; and the necessary repair part is no longer made.)

Apparently, "failure" has varied appearances, in the eye of the designer, (and
perhaps the programmer), the vendor, and the user.
                                                               Bob

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Software bugs "stay fixed" (<A HREF="/Risks/10.33.html">RISKS-10.33</A>)
</A>
</H3>
<address>
peter da silva 
&lt;<A HREF="mailto:peter@ficc.ferranti.com">
peter@ficc.ferranti.com
</A>&gt;
</address>
<i>
Sat Sep  8 11:15:29 1990
</i><PRE>

&gt;      extraneous code he doesn't understand, doesn't see how it could work, or
&gt;      whatever and in an attempt to clean up the program, deletes or changes
&gt;      it.  This turns out to be programmer A's bug fix, and the old bug is
&gt;      reintroduced.

In this situation it seems likely that Programmer A merely covered up or made
allowances for the bug. A real bug fix would have redesigned the code so the
condition that equired the obscure code didn't occur. The original comment is
that fixed bugs stay fixed. Patched bugs can (and often do) resurface.

Peter da Silva    +1 713 274 5180.    peter@ferranti.com

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-10</DOCNO>
<DOCOLDNO>IA013-000136-B029-82</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.37.html 128.240.150.127 19970217040022 text/html 23102
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:58:52 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 37</TITLE>
<LINK REL="Prev" HREF="/Risks/10.36.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.38.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 37</H1>
<H2> Thursday 13 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Expert system in the loop 
</A>
<DD>
<A HREF="#subj1.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Railway Safe Working - large analogue systems 
</A>
<DD>
<A HREF="#subj2.1">
Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Analog vs digital reliability 
</A>
<DD>
<A HREF="#subj3.1">
Rob Sartin
</A><br>
<A HREF="#subj3.2">
 David Murphy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The need for software certification 
</A>
<DD>
<A HREF="#subj4.1">
John H. Whitehouse
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  ZIP code correcting software 
</A>
<DD>
<A HREF="#subj5.1">
Richard W. Meyer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Software Bugs "stay fixed"? 
</A>
<DD>
<A HREF="#subj6.1">
Jeff Jacobs
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Expert system in the loop
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Thu, 13 Sep 90 18:23:50 BST
</i><PRE>

According to Electronics Weekly (Sept 12th, p2):

"Ferranti will study for MoD the feasibility of integrating a
knowledge-based expert system into naval command systems, to advise
commanders in battle.

"The system would reduce the risk of mistakes [sic] because battle situations
are too complex for a command team to appreciate properly in the short time
available. [...] If a trial system is built, it will be installed in a
type-23 frigate. "

So: the battle situation is too complex to understand. The expert system is
likely to be too complex to understand, too. The commander is unlikely to
ignore the advice of the expert system, unless it is clearly perverse. This
means that the decision (say, to launch a weapon) is being taken, in
practice, by the expert system.

Is there no way we can stop this trend towards automated launch systems,
before it becomes completely uncontrollable? It would be a good subject for
an international treaty, even though it would be hard to find a way to
verify compliance. The Aegis system on the USS Vincennes led to the death of
several hundred people when a civil airbus was shot down, on a scheduled
flight, in weather conditions where the aircraft would be clearly
recognisable from the bridge of the Vincennes through binoculars. That
tragedy was ascribed to the poor user-interface of Aegis, combined with an
atmosphere of eager tension on board which made a decision to fire more
likely. How can we stop people building ever-more-complex decision-support
systems, and thereby losing their ability to take decisions themselves?

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">

</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:parnas@qucis.queensu.ca ">
parnas@qucis.queensu.ca 
</A>&gt;
</address>
<i>
Wed, 12 Sep 90 23:24:14 EDT
</i><PRE>

Although I found the discussion of railway safety mechanisms interesting, the
most interesting question for me was why the systems described would be
considered "analogue".  There seems to be an implicit assumption that anything
that is not computerised is "analogue".

Conventionally analogue systems are those in which there are an infinite set of
stable states, e.g.  systems of springs and weights, electrical networks
comprising resistors, inductors, capacitors, etc.  Digital systems are
constructed of components that have been designed to have a relatively small
number of stable states with the transitions between those states being so
rapid that the time spent in other states is negligible.  The most common
instances are binary, two stable states, but other numbers have been tried.
For example, old telephone switches often used relays with 10 stable states.
These were actually hybrid systems because, when the relays were in one of
their stable states, analogue signals were conducted between the two
subscribers.

Strictly speaking digital systems do not exist.  Relays, flip flops etc are
actually constructed of analogue components, only by ignoring the time in which
the circuits are changing between "stable" states.  However, the circuits are
designed so that one can ignore those times.  The transition time determines
the clock rate for those systems.  Subtle hardware bugs often occur when,
because of poor design, the transition times are ignored when they should not
have been.

The description of the railway safety systems makes them sound like digital
systems made of old-fashioned technology.  The little arms that were described
are considered to be either "up" or "down"; one neglects the time in which they
are moving between those states.  The buttons described are either depressed or
released; one neglects the time in which they are between those two positions.
The switches are designed so that they are either "on" or "off" and good
switches are designed so that we can neglect the times when they are in an "in
between" situation.  It is important not to assume that "mechanical" is 
an antonym of "digital".

Looking back at the earliest digital computers one finds that they were made of
mechanical components not unlike those described as current railway technology.
If we are going to look for examples of large analogue systems, I think we have
to look elsewhere.  The servomechanisms used in speed control on most vehicles,
and for flight surface control on aircraft, would seem better candidates.  

Of course, just as the digital components are actually approximated by analogue
elements, those analogue systems can now be approximated by digital systems.
In those approximations the number of stable states is so large, and they are
so close in some topology, that one neglects the fact that it that the number
of states is finite and neglects the "gaps" between them.  Here too, we have
a rich source of subtle bugs.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Analog vs digital failure modes and conservation laws 
</A>
</H3>
<address>
Rob Sartin 
&lt;<A HREF="mailto:sartin@hplcip.hpl.hp.com">
sartin@hplcip.hpl.hp.com
</A>&gt;
</address>
<i>
Tue, 11 Sep 90 11:37:28 PDT
</i><PRE>

&gt;we'd today call an axiomatic/object-oriented approach:  He designed a series
&gt;of basic primitives to manipulate things like money, accounts, and so on.  The
&gt;primitives enforced, in a very transparent way, such basic "laws" as "the law
&gt;of conservation of money":  Money can be neither created nor destroyed, it

One can only hope that such a system would not (or would depending
on your views on controlling the economy) be used at the Federal Reserve.

Rob Sartin, Software &amp;Systems Lab, Hewlett-Packard  hplabs!sartin  415-857-7592

</PRE>
<HR><H3><A NAME="subj3.2">
Analog vs digital reliability (Wolitzky, <A HREF="/Risks/10.33.html">RISKS-10.33</A>)
</A>
</H3>
<address>
David Murphy 
&lt;<A HREF="mailto:dvjm@cs.glasgow.ac.uk">
dvjm@cs.glasgow.ac.uk
</A>&gt;
</address>
<i>
Wed, 12 Sep 90 09:15:35 BST
</i><PRE>

&gt; Might as well carry this nit-picking one level further.  As long as
&gt; your computer's transistors, capacitors, or whatever rely on electrons,
&gt; photons, or other quantum-mechanical wave/particles with discrete
&gt; states, you are justified in considering them to be digital.  But this
&gt; is all silly -- the implementation is irrelevant.  If you can treat
&gt; the computer as a black box that behaves digitally, why not label it
&gt; as such?

And therein lies the risk. One cannot always treat `digital' systems as
digital because, as many posters have pointed out, mother nature will
sometimes find ways to let you know your abstraction is unsound. One
of my favourite examples is Jefferies' ``Bifurcation to Chaos in clocked
digital systems containing autonomous timing elements'' (Phys. Let. A,
Vol 115, No 3) where a deterministic communications protocol between
two simple `digital' systems is shown to display chaos; this underlines
the point that even if you start with two systems that display nice
finite easily-abstracted behaviours their composition may not.

Another point that is often neglected is that many of the things we
assume exist in the digital world are, in fact, forbidden. It is
completely impossible to build a fair arbiter or synchroniser for
instance; the axioms that should hold for such a beast are mutually
contradictory; no continuous system can behave that way. Thus there
will come a time in every digital design when certain questions will
remain unanswered until we move outside the digitial paradigm, -
questions like `how fast will it run ?' (meaning `how fast will it
run with a failure rate small enough that my customers won't notice').
There is no doubt that asynchronous design in a clocked digital paradigm
will only work with some constraining assumptions about how quickly
those `asynchronous' signals are actually likely to appear. And since
the real world is asynchronous, -- there is no such thing as an
isolated computer, -- this means that any digital design technique is
just a way of improving engineering confidence in the product, not
of guaranteeing correctness.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The need for software certification
</A>
</H3>
<address>
John H. Whitehouse
&lt;<A HREF="mailto:al357@cleveland.freenet.edu ">
al357@cleveland.freenet.edu 
</A>&gt;
</address>
<i>
Wed, 12 Sep 90 22:47:20 -0400
</i><PRE>

In recent weeks, the risks forum has seen much discussion of software
certification and of the relative risk of digital vs. analog computing.  I
would like to suggest another realm of discussion which relates to the notion
of software certification.  Specifically, I would like to see some discussion
here of the value of certifying software professionals.  In this regard, I
refer to those certification designators administered by the Institute for
Certification of Computer Professionals in Des Plaines, Illinois.
 
From its inception, our field has never been able to find enough qualified
people to meet the demand.  As a result, we have drafted people from a wide
variety of academic disciplines.  Further, many workers in our field have never
even seen the inside of a university.  In addition, very few universities have
offered majors in computer-related disciplines until "recently", i.e. in the
last 25 years.  I am not trying to condemn those people now practicing in this
field who lack a "proper" academic background.  In fact, I will openly state
that many people who do have a computer science major are unable to perform
adequately in the field.
 
Regardless of background, some people seem to have developed an adequate
understanding in this field whereas others have not.  The fact that the vast
majority of managers were either non-technical from the start or have become
non-technical over the years means that probably the vast majority of people in
this field are not receiving evaluations which reflect the actual quality of
their work and the depth of their understanding.  This cuts two ways.  First,
many poor practitioners continue to survive in the field despite their poor
performance.  Second, many excellent technical people fail to receive proper
reward for their accomplishments.
 
Hiring is expensive and usually done pretty much in the blind.  Firing is
risk-laden in our litigious society.
 
It is my contention that the vast majority of software defects are the product
of people who lack understanding of what they are doing.  These defects present
a risk to the public and the public is not prepared to assess the relative
skill level of software professionals.

For these reasons, I favor the certification of software professionals.  We
have tried to bring this about for 28 years on a voluntary basis, but those who
know that they could never pass make high sounding arguments to convince others
that voluntary certification is not a desirable goal.  Academics have not
joined in the debate since they are generally immune from the problem.

I would like to hear some discussion on this issue.

   [We have been around this topic before, with Nancy Leveson in <A HREF="/Risks/5.28.html">RISKS-5.28</A>
   and following discussion in <A HREF="/Risks/5.33.html">RISKS-5.33</A>, Appendix B of the ACARD report
   noted in <A HREF="/Risks/4.14.html">RISKS-4.14</A>, John Shore with some appropriate references in
   <A HREF="/Risks/4.78.html">RISKS-4.78</A>, and earlier discussions.  Perhaps it is time to try again.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
ZIP code correcting software
</A>
</H3>
<address>
&lt;<A HREF="mailto:DBQABAA@CFRVM">
DBQABAA@CFRVM
</A>&gt;
</address>
<i>
Thu, 13 Sep 90 09:43:15 GMT
</i><PRE>

Several administrative departments on our campus are interested in
purchasing software which claims to validate and correct ZIP codes.
This could be used interactively to tell an operator that he/she is
keying a ZIP code which is invalid for the given street and city
information; it could also be used in batch to "clean-up" address
data.  Apparently the US Post Office maintains massive tables of
address data which various software vendors use as the basis for
these kinds of software packages.

Does anyone have experience with this kind of software?  My concerns
would be as follows:
  1. What is the error rate with this process?
  2. What happens when additions and changes are made by the Post
     Office to their tables but the vendor has not yet gotten the
     updates out to the end user of the software?  Will the software
     keep "correcting" a ZIP code which is in fact already correct?

I've had personal experiences where some of my mail suddenly shows up
with a changed (and wrong) ZIP code.  After contacting the sender and
getting the ZIP code changed back to what it should be, I've seen it
get changed again a few months later.  It's obvious to me that they are
running a batch update on their mailing list using software that says
my ZIP code is wrong.

This seems to me to be part of a trend for people to put their faith in
"error-correcting" software which can't always tell what really needs
correcting.
                                          --- Rich Meyer

Richard W. Meyer, University Computing Services, University of South Florida,
Tampa  DBQABAA@CFRVM.BITNET

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Software Bugs "stay fixed"? (Steve Smith, <A HREF="/Risks/10.35.html">RISKS-10.35</A>)
</A>
</H3>
<address>
Jeff Jacobs 
&lt;<A HREF="mailto:76702.456@compuserve.com">
76702.456@compuserve.com
</A>&gt;
</address>
<i>
12 Sep 90 16:19:14 EDT
</i><PRE>

&gt;My experience with "bit rot", where previously solved problems reappear, is
&gt;that they are usually caused by poor configuration control.  While most systems
&gt;have CC tools, like sccs on UNIX or CMS on VAX/VMS, getting your friendly
&gt;average programmer to use them is like pulling teeth.  When management insists
&gt;on use of the tools, you will find lots of log entries of the form:
 
&gt;Solutions?
 
The following is a description of a "solution".
 
(Way back in the early days of the TDRSS ground station network development...)
 
During my troubleshooting activities, it quickly became obvious that many of
the "show-stoppers" were not "bugs", but were a combination of procedural,
operational and communication problems.  The large number of different test
configurations, the number of different groups performing testing, and the
technical inexperience of the test and configuration management personnel
resulted in a chaotic situation.  Although a conceptually sound set of
procedures had been drafted, they were manual and paper-based, and were unable
to keep up with the level of activity.  An average of 4 days per month were
lost simply due to errors in editing command files for compiling and linking.
These were *project* months, where several dozen people would be waiting for me
to resolve a "show-stopper".  I would spend enormous amounts of time trying to
resolve what software was in use, how it was used, etc, etc.  Furthermore, it
was almost impossible for management to determine the status of fixes,
enhancements and updates to the software.
 
The situation was quite amenable to automation.  Although my initial proposal
to TRW was turned down, I proceeded to create an initial version for my own
group's use; we were making "quick-fixes" at a rapid rate, and needed the
support that the tool would provide.  The tool, called the "Fix Processor", was
completed in six weeks.  It is effectively an expert system, built using Object
Oriented and AI techniques in a Lisp-like language.  (It was described in a
prize winning paper, "Utilizing Expert Systems to Improve the Configuration
Management Process", by Sherri Sweetman, George Washington, University, for the
Project Management Institute).
 
This is **NOT** a "version control" system; it is much more complex.  Software
"fixes" (including updates and enhancements), migrated physically.  Initially,
all software resides in controlled baselines on development machines.  As
developers made changes to a given task, code was taken from the baseline and
moved to work areas.  As it went through various stages of testing and
acceptance, it transitioned to physical control of other groups.  Prior to a
delivery to WSGT, all accepted changes would be "rolled" into a new baseline
and the entire process would start over.
 
The Fix Processor was initially used by the various integration and testing
groups.  Once its effectiveness was proven, it was also propagated to the
development groups, who, although initially opposing it, soon became its
strongest advocates!!!
 
Features of the Fix Processor included:
 
- Automated the tedious, time consuming and error prone operations required to
transition a piece of software.  This includes creation of new directories,
copying files, generation of command files, etc., all of which formerly had to
be performed manually.  This was crucial to the widespread acceptance and use
of the system.
 
- Separated compiling and linking of new fixes from actual incorporation into
testing configurations.  (Tasks had to compiled and linked prior to actual
testing.  It was also sometimes necessary to remove a new version of a task
from a test configuration).
 
- An on-line reporting and query facility for determining the status of
software, usage in test configurations, etc.  This was not only a key
management tool, it also provided a means of communication between the various
integration and testing groups.  Problems which formerly took days to resolve
were literally reduced to minutes.
 
- Extensive validation of user inputs and requests.
 
- Support and tracking for special requirements, such as debugging, "quick and
dirty" fixes, etc.
 
- Automated collection of all approved changes into a new baseline, a process
which formerly required more than a week (and was incredibly error prone).
 
- Co-ordinated task transitions with the necessary paper trail.  (I
subsequently revised the paper work system).
 
- Logged all activities and results into a database.
 
The net result of these changes was a smoothly functioning, manageable project.
Mammoth turn-overs were eliminated.  Software was turned over by the developers
in small, manageable increments on a continuous basis (as opposed to the
previous "here it all is method", which would take weeks to straighten out).
 
Problems were easily identified and quickly solved ; productivity and morale
were immeasurably improved and the project became truly manageable.
 
Note that one of the key elements to the success of the FIX Processor is that
it made life *easier* for everybody involved (including me).  Note also that
the "automation" helped ensure that problems didn't recur, and it was quite
easy to verify the complete path of software.
 
Jeffrey M. Jacobs, ConsArt Systems Inc, Technology &amp; Management Consulting
P.O. Box 3016, Manhattan Beach, CA 90266  (213)376-3802

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-11</DOCNO>
<DOCOLDNO>IA013-000136-B029-105</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.38.html 128.240.150.127 19970217040035 text/html 29574
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:59:04 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 38</TITLE>
<LINK REL="Prev" HREF="/Risks/10.37.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.39.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 38</H1>
<H2> Friday 14 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  The Weakest Link 
</A>
<DD>
<A HREF="#subj1.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Relatively Risky Cars 
</A>
<DD>
<A HREF="#subj2.1">
Martin Burgess
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: The need for software certification 
</A>
<DD>
<A HREF="#subj3.1">
Theodore Ts'o
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Expert System in the loop 
</A>
<DD>
<A HREF="#subj4.1">
Steven Philipson
</A><br>
<A HREF="#subj4.2">
 Brinton Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Computer Unreliability and Social Vulnerability: critique 
</A>
<DD>
<A HREF="#subj5.1">
Dan Schlitt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Large analog systems and NSW railroads 
</A>
<DD>
<A HREF="#subj6.1">
David Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Analog vs Digital reliability 
</A>
<DD>
<A HREF="#subj7.1">
Bill Plummer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: ZIP code correcting software 
</A>
<DD>
<A HREF="#subj8.1">
Bernard M. Gunther
</A><br>
<A HREF="#subj8.2">
 Dave Katz
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The Weakest Link
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:amos@taux01.nsc.com ">
amos@taux01.nsc.com 
</A>&gt;
</address>
<i>
13 Sep 90 23:13:15 GMT
</i><PRE>

Tel Aviv, Sep. 13 -

12 private investigators and a few employees of the Income Tax bureau were
arrested on suspicions of bribery and breach of trust.  The investigators have
allegedly bribed income tax employees in return for computer data, which
included details about taxpayers' income and assets.  Under investigation are
also suspicions that some investigators - most of them former policemen - have
used the same means to receive data of police computerized files as well.

As usual, the human factor is the weakest link in any security system.
Luckily, in this case the data was handed as printouts; one can easily
imagine what could have happened if the suspects had had their own computers
and modems to contact the compromised systems directly.

Amos Shapir, National Semiconductor (Israel) P.O.B. 3007, Herzlia 46104, Israel
Tel. +972 52 522255  TWX: 33691, fax: +972-52-558322 

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Relatively Risky Cars
</A>
</H3>
<address>
"Martin Burgess" 
&lt;<A HREF="mailto:burgess@sievax.enet.dec.com">
burgess@sievax.enet.dec.com
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 04:42:44 PDT
</i><PRE>

Yesterday a program on British T.V. pointed out (again) that car buyers in 
Sweden and the U.S.A. can obtain information about the relative safety of 
different models, and that this information is not available in the U.K.

The RISKS forum would seem to be an ideal place to post the details, if the 
copyright laws allow.

It would also be interesting to see if there were differences between cars sold
into different markets - for example, does the widespread fitting of air
conditioning in the U.S.A. affect the safety of passengers when there is an
accident ?
                                       	Martin Burgess 

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: The need for software certification
</A>
</H3>
<address>
Theodore Ts'o 
&lt;<A HREF="mailto:tytso@ATHENA.MIT.EDU">
tytso@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 13 Sep 90 22:11:06 -0400
</i><PRE>

I am against the "certifying" of software professionals.  My objections fall
basically into two areas.  The first is that there is no valid way to measure
software "competence".  How do you do it?  There are many different software
methodolgies out there, all with their own adherents --- trying to figure out
which ones of them are ``correct'' usually results in a religious war.

For example, all computer science students at MIT are required to take
6.170 (also known as Software Engineering) as a graduation requirement.
(I just graduated in June 1990; the last time this topic came up, I was
afraid to air my opinions because I would shortly be applying to
graduate school.)  But in any case, my personal opinion of that course
is that it is so completely dated that it isn't even funny.  For
example, the course is taught in an archaic language, CLU, instead of a
more modern object-oriented language such as C++.  In the class, we're
told that global variables are always evil --- there's no excuse for
them at ever; yet in order to build the linker (which was written in
CLU), the sources turned on a magic flag so that it could have global
variables to store the symbol table.  I suppose the performance hit of
passing the symbol table object to every single procedure in the linker
was too much to handle.

We were told that the One True Way to program involved keeping a design
notebook and not even trying to code until we had sketched out the whole
thing in pseudo-code, which I guess is the current "in" way to do
structured coding.  (Remember when people said that flow-charting was
the only way to write error-free programs?)  When I and my fellow
students in my group took the course, we used an emacs buffer as our
design notebook, and our psuedo code was written in CLU itself.

Surprisingly, version control (such as RCS) was never discussed at all.
I suppose the theory was that if we designed everything in pseudo-code
from scratch, we would never need to rewrite or revise any of it, so
version control was considered important.  I will leave it to the Gentle
Reader's judgement as to whether or not you can teach a reasonable
Software Engineering in today's environment, when several people can be
changing files on a networked filesystem, without at least mentioning
version control. 

Our conclusion was that the religion which was preached to us was
developed in the days of teletypes and punched cards, when actually
coding several different algorithms and trying them out was too
expensive; when only one person could modify a file at a time because of
physical limitations, so version control wasn't important; and when
interactive computers were nearly nonexistent, so the only kind of One
True Design Notebook was a spiral bound one.

In any case, we (the students in my programming group) didn't buy any of
it.  So by the deadline where we supposed to have produced a design
document detailing how we would do things (and which would be used to
penalize us if we deviated from it in our final implementation), we
wrote an almost completely working prototype.  We then wrote our design
document from our implementation, instead of the other way around.  We
ended up with one of the cleanest implementations and received one of
the highest scores in the class.  In fact, we received a letter of
commendation saying that we were in the top 5% of the class, and that we
deserved some recognition beyond merely getting an "A" in the class.

The point of all of this?  My group managed to get an A in this class
without absorbing any of the religious tenets of Professor Liskov's
programming methodology.  (This is not to say that everything in the
class was bad; but a lot of it was trash, and I had learned most of the
good parts by being a student systems programmer at Project Athena, so
the class was essentially a waste of time for me.)  So how do you
certify someone?  If required to, I can parrot back all of the ``right''
answers on a written exam.  Those answers would also mean very little
about how I really go about my programming work.  (I won't go into the
flame wars about how my personal style is better-or-worse than the
traditional "top-down", or whatever else is in vogue today.  My style
works for me --- I write generally bug-free code, and I won't dictate to
you how to write bug-free code if you won't dictate to me how I should
write mine.)

The second general objection that I have against the certification of
software professionals is that it might very well become a guild.  In my
mind, there is great danger that once you have the people who are
``IN'', they will try to maintain a competitive advantage and keep most
other people ``OUT''.  Mr. Whitehouse has already granted that a college
degree cannot be used to discriminate those who can program well against
those who do not program well.  I am very much afraid that any system of
software certification will be used to push one person's pet software
methodology and to exclude people who don't agree with him or her.

Worst yet, it could become like many unions today, and be used to protect
mediocrity within the group against people who are actually better qualified,
but who aren't in the appropriate magic group.  This could be extremely
dangerous, if management types were to actually believe that being
``certified'' would mean that the code that person generates is "guaranteed" to
be bug-free, when in fact the code might be much worse than someone who didn't
have the magic blessing.  Knowing human nature this is probably a more clear
and present RISK than the current method which depends on the free market.

						- Ted

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Expert System in the loop (Thomas, <A HREF="/Risks/10.37.html">RISKS-10.37</A>)
</A>
</H3>
<address>
Steven Philipson
&lt;<A HREF="mailto:stevenp@decwrl.dec.com ">
stevenp@decwrl.dec.com 
</A>&gt;
</address>
<i>
Thu, 13 Sep 90 16:56:27 PDT
</i><PRE>

   In Risks 10.37, Martyn Thomas &lt;mct@praxis.co.uk&gt; writes about a Feranti
study on the "feasibility of integrating a knowledge-based expert system
into naval command systems, to advise commanders in battle".

   Thomas concludes:

&gt;The commander is unlikely to ignore the advice of the expert system,
&gt;unless it is clearly perverse.  This means that the decision (say,
&gt;to launch a weapon) is being taken, in practice, by the expert system.

   Neither conclusion follows.  First, the proposed system is intended
to "advise commanders".  It is NOT stated that the system is intended
to act on its own or to be blindly followed.  Commanders will be very
likely to ignore the advise of such a system -- they tend to be very
wary of automated systems, and regard themselves as experts.  Commanders
often get contradictory advise from their human advisors.  The essence
of their job is to evaluate recommendations and make the best decisions
that they can.

   An advisory system that recommends action that is at variance with
other sources will likely be disregarded UNLESS the system makes a
strong case to support its recommendation.  A system that cannot
justify its recommendations will be of little use, as a commander can
not follow a blind recommendation; he has to know the line of reasoning
and facts on which the recommendation is based, regardless of whether
that recommendation comes from a human or automated source.

   Such a system could be of great value.  IF an expert system were
to detect a trend or correlate bits of information that indicate a
significant development, it could issue a recommendation and support
it with the data points and chain of reasoning that were used to
arrive at that conclusion.  The commander could then review that
recommendation and decide whether or not to act upon it given his
evaluation of the validity of the reasoning.  All this may not be
possible to do in practice, but there is the potential for an advance
here in implementing a more effective and safe decision making process.

&gt;The Aegis system on the USS Vincennes led to the death of
&gt;several hundred people when a civil airbus was shot down, on a scheduled
&gt;flight, in weather conditions where the aircraft would be clearly
&gt;recognisable from the bridge of the Vincennes through binoculars.  That
&gt;tragedy was ascribed to the poor user-interface of Aegis, combined with an
&gt;atmosphere of eager tension on board which made a decision to fire more
&gt;likely. How can we stop people building ever-more-complex decision-support
&gt;systems, and thereby losing their ability to take decisions themselves?

   The facts above are incorrect and/or incomplete.  The Vincennes did
not acquire visual contact with the Airbus nor could it have -- visibility
was restricted by haze, and the aircraft was shot down before it entered
visual range.  The term "eager tension" is misleading -- the transcripts
of the incident and investigation indicate that there was an atmosphere
of tension *and fear*.  It should also be noted that the Aegis system did
not make a decision to fire -- that was purely a human decision based on
available (albeit misinterpreted) information.

   A case can be made that an automated system might have concluded
from the available data that the Airbus was NOT conducting an attack,
and could have *advised* the commander to NOT fire.  We should keep
in mind though that warnings were given by a human operator that the
aircraft might be a commercial flight.  These warnings were not heeded --
the preponderance of information available to the commander indicated
that a decision to fire was necessary for the protection of the ship.

   We all wish to minimize risk, but we must recognize that we can
not eliminate it; there are significant risks in human activities
regardless of how they are undertaken.  There will be grave errors
in military operations regardless of the technology that we use.

   We have good cause to be wary of automated systems in critical applications,
but we should not dismiss them out of hand.  Blind trust is dangerous, but so
is blind distrust.  It's our responsibility as computer professionals to see to
it that any computer technology that is developed is done so in a way that
minimizes risks, and that the end users are cognizant of the limitations and
hazards associated with such systems.
  						Steve Philipson

</PRE>
<HR><H3><A NAME="subj4.2">
 Re: Expert system in the loop (Thomas, <A HREF="/Risks/10.37.html">RISKS-10.37</A>)
</A>
</H3>
<address>
Brinton Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 10:32:35 EDT
</i><PRE>

Martyn Thomas reports:

&gt;According to Electronics Weekly (Sept 12th, p2):

&gt;"Ferranti will study for MoD the feasibility of integrating a
&gt;knowledge-based expert system into naval command systems, to advise
&gt;commanders in battle.

He then objects to the use of automated launch systems, asserting:

&gt;The Aegis system on the USS Vincennes led to the death of
&gt;several hundred people when a civil airbus was shot down, on a scheduled
&gt;flight, in weather conditions where the aircraft would be clearly
&gt;recognisable from the bridge of the Vincennes through binoculars. That
&gt;tragedy was ascribed to the poor user-interface of Aegis, combined with an
&gt;atmosphere of eager tension on board which made a decision to fire more
&gt;likely.

In fact, he has contradicted his own assertion that the AEgis system was
responsible by pointing out the shortcomings in human judgement, human
psochology, and human I/O.  The principal (and significant) shortcoming
of AEgis in this scenario is that its database apparently did not
include a readily available schedule of commercial airline flights for
the region in which AEgis was deployed.

If humans insist upon creating conflict situations where decisions
depend upon evaluating large numbers of interacting variables, NOT
to use automated decision support systems would be the tragedy.

He concludes:

&gt; How can we stop people building ever-more-complex decision-support
&gt;systems, and thereby losing their ability to take decisions themselves?

So long as there are ever more complex decisions to be made, we must
either improve the decision maker or give the decision maker some help.

The only other choice is to avoid the complex decisions altogether.

[Because of the nature of this topic, I feel compelled to disclaim any
relationship between what I have written and for whom I work.  These opinions
are my own &lt;...&gt;]
                                                         _Brint

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Computer Unreliability and Social Vulnerability: critique
</A>
</H3>
<address>
Dan Schlitt 
&lt;<A HREF="mailto:dan@sci.ccny.cuny.edu">
dan@sci.ccny.cuny.edu
</A>&gt;
</address>
<i>
Tue, 11 Sep 90 14:37:29 -0400
</i><PRE>

Pete Mellor &lt;pm@cs.city.ac.uk&gt; writes in <A HREF="/Risks/10.28.html">RISKS-10.28</A>:
&gt;The authors do not make it clear initially which of two different meanings of 
&gt;'catastrophic' they intend:
&gt;
&gt; a) sudden and unpredictable, 'anything can happen', and
&gt; b) having appalling consequences.
&gt;
&gt;The first is a classification of the effect (which I prefer to call a 'wild
&gt;failure' to avoid confusion), and the second is a measure of the cost. For
&gt;example, when arguing that computers are inherently unreliable because they are
&gt;prone to 'catastrophic failure', they quote the Blackhawk example. The cause of
&gt;this series of accidents was eventually traced to electromagnetic interference,
&gt;as the authors state. While it is probably true that only a *digital*
&gt;fly-by-wire system would exhibit a wild mode of failure in response to EMI, it
&gt;is not until half-way down the next page, where the authors point out that
&gt;digital systems have far more discontinuities than analogue systems, that it
&gt;becomes clear that they are using 'catastrophic' in sense a), and not in sense
&gt;b).
&gt;
It might be well to note that the natural assumption that discrete
systems, such as digital ones, are more prone to wild mode failure
than nice continuous analogue systems is a dangerous one.  The term
"chaos" has become a buzzword and as a result much of the real meaning
has been lost to the world.  One of the important observations was
that, except for some exceptional cases, "wild behavior" is generic
for conservative mechanical systems.  For non-conservative systems the
situation is not too different.  It is only because the most familiar
and most analyzed cases are special that we make the "natural"
assumption of smooth nice behavior.

The unfamiliar but common case is one where a system exhibits smooth
regular behavior punctuated by wild jumps to a wildly different smooth
state.  The timing of the jumps is highly unpredictable because it
depends critically on initial conditions.

&gt;The authors are right to claim that computer systems are too complex to be
&gt;tested thoroughly, if by this they mean 'exhaustively'. It is apparent from
&gt;their example of a system monitoring 100 binary signals that they do mean this.
&gt;
&gt;Exhaustive testing in this sense is well known to be impossible. Even in
&gt;modestly complex systems one can only test a representative sample of inputs.
&gt;Provided the selected sample is realistic, one can, however obtain a reasonable
&gt;degree of confidence that a reliability target has been reached, but *only if
&gt;the target is not too high*.
&gt;
This sort of exhaustive testing is also impossible for general
mechanical systems.  It requires good design to make a mechanical
system which falls in the class of those that are well behaved.  It is
not clear to me why it is not also possible to use similar good design
to construct sufficiently stable digital systems.  The main difference
between the two is the difference in the amount of design experience
we collectively have had in the two cases.

Catastrophic failure in the second sense was not allowed to stop the
development of mechanical systems in the past.  Collapsing cathedrals
the failure of the Tacoma narrows bridge or airplanes falling out of
the sky did not stop architecture, bridge building or aviation
-- and bridges are still known to collapse.  It would be tragic if
these concerns were to halt development of digital systems.

Mellor is right that the challenge is to develop the tools for
testing and analysis that are required.

Dan Schlitt, Manager, Science Division Computer Facility City College of New
York, New York, NY 10031, (212)650-7885  dan@ccnysci.uucp dan@ccnysci.bitnet

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Large analog systems and NSW railroads
</A>
</H3>
<address>
David Benson
&lt;<A HREF="mailto:benson_d@maths.su.oz.au ">
benson_d@maths.su.oz.au 
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 11:21:50 +10
</i><PRE>

  Having just arrived in NSW I have yet to experience the safe railroads -- but
certainly recommend visiting Australia.
  David Parnas comments that the railroads are not properly "large analog
systems".  I certainly agree.  But his examples of "large analog systems" seem
rather small scale stuff to those of us who think about spreadsheets, general
ledger, Star Wars, and other large scale systems on or containing digital
computers.
  So perhaps there are no "really large analog systems."  After all, the
747-400 I rode on for the 15 hour overwater flight from LAX to SYD isn't a
"really large analog system", is it?
  Seriously, I doubt that in the bad old days before computers that the systems
in use were as safe, as reliable, or as inexpensive as in the good new days
with computers.  This is certainly the case for manual speadsheets, manual or
semi-manual general ledger, and other inherently descrete systems often
associated with accounting -- or anyway, bookkeeping.  Indeed, there is
something rather inhumane about bookkeeeping seems far better for the spirit to
relegate this task to mere computers.
  I assert, without even bothering to review the data, that air travel is
vastly safer post-computer (say, since 1970) than pre-computer.
  And so it goes...

  From this casual review of nineteenth and twentieth century technology I am
going to baldly state that the largest analog systems I can think of are all
basically static -- such as bridges under load -- and are seriously
overdesigned by the standards of this day.  These standards are manifested in
software, airplanes, etc.
  I hope, by this statement, to generate some discussion and thus perhaps some
enlightenment.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Analog vs Digital reliability
</A>
</H3>
<address>
&lt;<A HREF="mailto:Plummer@DOCKMASTER.NCSC.MIL">
Plummer@DOCKMASTER.NCSC.MIL
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 10:09 EDT
</i><PRE>

Can somebody provide a clear explaination of the role of delay in analog
and digital circuits?  We can attempt to compare the two by making
associations such as "the voltage on an (analog) capacitor is the
equivalent of the number held in a digital register".  Then in the
digital world we worry alot about when the register gets changed and try
to prove that only one writer can exist at anytime.  Analog systems
don't seem to have the same concerns.  Or do they?  --Bill Plummer, Wang
Laboratories, Inc..

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: ZIP code correcting software
</A>
</H3>
<address>
Bernard M. Gunther 
&lt;<A HREF="mailto:bmg@mck-csc.UUCP">
bmg@mck-csc.UUCP
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 11:00:10 EDT
</i><PRE>

&gt;Does anyone have experience with this kind of software?  My concerns
&gt;would be as follows:
&gt;  1. What is the error rate with this process?
&gt;  2. What happens when additions and changes are made by the Post
&gt;     Office to their tables but the vendor has not yet gotten the
&gt;     updates out to the end user of the software?  Will the software
&gt;     keep "correcting" a ZIP code which is in fact already correct?

I have had two sets of experiences with this sort of problem:

1 - There must exist a tape which has determined that my ZIP code
02141 is in Boston and not in Cambridge.  I give my address with the
the Cambridge town name, and I get letters back with Boston listed
as the town name.  Nothing I do seems to correct this problem.

2 - I have used a PC software package which takes street addresses and town
names and plots the points on a digital map.  In matching a number of bank
branch locations, the success rate of this program without any human guidance
is around 60-65%.  Using a limited amount of inteligence, this goes up to
75-80%.  Achieving 90+% requires calling the branches and getting better
address and cross streets.  The key limiting factors are the quality of the
address given and quality of the source maps.
                                                     Bernie Gunther

</PRE>
<HR><H3><A NAME="subj8.2">
Re: ZIP code validation software
</A>
</H3>
<address>
Dave Katz 
&lt;<A HREF="mailto:katz@merit.edu">
katz@merit.edu
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 10:27:36 EST
</i><PRE>

I recently stopped into a stereo/appliance retail outlet to pick up
a $15 accessory for which I wanted to pay cash.  Being in a hurry, I
tossed down exact change and gave my thanks to the salesman.  Shortly
thereafter, lights flashed and beepers beeped, and I was told that
in no uncertain terms that I had to wait for the purchase to be entered
into the computer.

My annoyance grew to anger as the salesman fumbled with the computer,
apparently having difficulty even "logging in."  (If it wasn't the
guy's first day on the job, the store is in real trouble.)  He then
asked for my name and address.  Not wanting to be on their mailing
list, and having real objections to giving my vital statistics away
for a small cash purchase, I protested.  "I have to type it in or
the computer won't allow the sale."  Feeling chagrined, I made up
a fake name and address in an obscure town in central Michigan.
The salesman dutifully typed in the phony address.  The computer
beeped and displayed "Invalid ZIP code."  "The computer must have
made a mistake," said I, feeling like an unmasked felon.  The
salesman looked badly confused, I got even more upset, and finally
another salesman told him to enter "00000", satisfying the machine.

After all that, the item had to be taken to another counter where
a sales slip was printed in triplicate, each copy separately filed,
the inventory control bar code read, and the anti-theft device demagnetized.
[The computer then announced that there were -5 of these items left in stock.]

Total elapsed time was nearly 15 minutes.

The risks are twofold--one being a privacy risk, and the other being
the encroachment of inappropriate, excessively complex technology.

 --Dave Katz
   University of Michigan

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-12</DOCNO>
<DOCOLDNO>IA013-000136-B029-139</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.39.html 128.240.150.127 19970217040108 text/html 25775
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:59:28 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 39</TITLE>
<LINK REL="Prev" HREF="/Risks/10.38.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.40.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 39</H1>
<H2> Tuesday 18 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Poetic Justice in a Machine Crash 
</A>
<DD>
<A HREF="#subj1.1">
Andy Glew via Paul Eggert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Expert system in the loop 
</A>
<DD>
<A HREF="#subj2.1">
Clifford Johnson
</A><br>
<A HREF="#subj2.2">
 Peter G. Rose
</A><br>
<A HREF="#subj2.3">
 Jeff Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  I'm 99% Sure You're A Crook!!! 
</A>
<DD>
<A HREF="#subj3.1">
mmm
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  A Nightmare: Security compromise with SUN's C2 package 
</A>
<DD>
<A HREF="#subj4.1">
Caveh Jalali
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Another risk of phone systems [anonymous]
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Desktop Publishing Fraud 
</A>
<DD>
<A HREF="#subj6.1">
Sanford Sherizen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Data cowboys and database abuse - applicant screening 
</A>
<DD>
<A HREF="#subj7.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Inside risks of INSIDE RISKS 
</A>
<DD>
<A HREF="#subj8.1">
PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Poetic Justice in a Machine Crash
</A>
</H3>
<address>
Paul Eggert
&lt;<A HREF="mailto:eggert@twinsun.com ">
eggert@twinsun.com 
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 12:39:44 PDT
</i><PRE>

[Reprinted from comp.parallel Usenet newsgroup (Dennis Stevenson, moderator)]
From: aglew@uiuc.edu (Andy Glew)
Newsgroups: comp.parallel
Subject: Poetic Justice in a Machine Crash
Date: 14 Sep 90 12:56:47 GMT
Organization: Center for Reliable and High-Performance Computing University of
	Illinois at Urbana Champaign

Our Encore Multimax just crashed in a way that seems like poetic justice:

    On the console terminal appeared a fragment of somebody's paper about
multiprocessor interconnection networks.  The last readable sentence was:

    "...it is difficult to build shared memory procesors
    "
    "^%%^$#$%#%$#it is difficult to build shared memory$%#%$#it is difficult to 
    "build shared memory$%#%$#it is difficult to build shared memory$%#%$#it is 
    "difficult to build shared memory%^$%^$%^$@#$@!$@#$@difficult to build
    "shared memory$%#$%$%#$%shared memory%^$%^$%^ shared memory %&amp;$%^^%$$%^%^$
    "shared memory&amp;*^&amp;*&amp;*^&amp;*^shared memory

...

Almost too good to be true :-)

(The screen garbage and control characters are not recorded verbatim).

    [Once again I am reminded of the prophetic nature of Vic Vyssotsky's 
    Chaostron piece, reprinted in CACM, April 1984, pp. 356-7.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Expert system in the loop (Philipson, <A HREF="/Risks/10.38.html">RISKS-10.38</A>)
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 14:33:30 PDT
</i><PRE>

&gt;The commander is unlikely to ignore the advice of the expert system,
&gt;unless it is clearly perverse.  This means that the decision (say,
&gt;to launch a weapon) is being taken, in practice, by the expert system.

This remark incited two responses asserting that the retaliatory
decision in the case of the Vincennes was a matter of human, not
mechanical, judgment, and that the computer system merely provided
humans with better information than they would otherwise have, so
that the human decision becomes more meaningful.  This is ridiculous.

In the case of the Vincennes, it cannot be disputed that a mistake
was made.  The Pentagon found no human responsible for it, so it
must have been a mechanical error.  (Recently, Captain Rogers was
awarded a special medal of honor for his courage in commanding the
Vincennes through the shootdown.)  The assertion that humans have
time to meaningfully evaluate the computers' information in a few
minutes is patent nonsense (as proven by the Vincennes) - all
humans can do is to *gamble* whether the computers (or their readings
of the computers' consoles) are right, and so they act as no more nor
less than randomizing agencies - i.e. one would get the same level
of "judgment" by card shuffling.

Such decisionmaking is de facto *governed* by computer: without
computer prompts, no retaliatory decision at all would be taken;
and, simply because of computer prompts, a virtually immediate
retaliatory decision is mandated; and, that decision is based fully
on the information provided by the computers.

In view of these circumscribing facts, the construction that in
practice computers "make" the controlling decisions is required
both as a matter of common sense and as a matter of law, under the
realistic interpretive standards unhesitatingly applied by the
Supreme Court in Bowsher v. Synar, (1986) 106 S.Ct. 3181-3191,
which ruled that the facial freedom of a proposed officer's
decisionmaking was nullified by the circumscribing constraints:

    To permit the execution of the laws to be vested in an
    officer only answerable to Congress would, in practical
    terms, reserve in Congress control of the execution of the
    laws... There is no merit to the contention that the
    [officer] performs his duties independently and is not
    subservient to Congress.  Although nominated by the
    President... the [officer] is removable only at the
    initiative of Congress... the political realities do not
    reveal that the [officer] is free from Congress'
    influence...  [a]lthough he is to have 'due regard' for
    [executive rulings]...  The congressional removal power
    created a 'here-and-now subservience' of the [officer] to
    Congress...  In constitutional terms, the removal powers...
    dictate that he will be subservient to Congress . . .
    Unless we make the naive assumption that the economic
    destiny of the Nation could be safely entrusted to a
    mindless bank of computers, the powers that this Act vests
    in the [officer] must be recognized as having transcendent
    importance.

Just so, minimal retaliatory timelines "in practical terms" assure the
dominance of military computers in Vincennes-style decisions, which gives rise
to a "here-and-now subservience" of military to to mechanical bodies.

</PRE>
<HR><H3><A NAME="subj2.2">
Re: Expert system in the loop (Philipson, <A HREF="/Risks/10.38.html">RISKS-10.38</A>)
</A>
</H3>
<address>
"Peter G. Rose" 
&lt;<A HREF="mailto:LCO114@URIACC.BITNET">
LCO114@URIACC.BITNET
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 14:26:51 EDT
</i><PRE>

&gt;From: stevenp@decwrl.dec.com (Steven Philipson)
&gt;In Risks 10.37, Martyn Thomas &lt;mct@praxis.co.uk&gt; writes .....
&gt;&gt;The commander is unlikely to ignore the advice of the expert system,
&gt;&gt;unless it is clearly perverse.  This means that the decision (say,
&gt;&gt;to launch a weapon) is being taken, in practice, by the expert system.
&gt;
&gt;   Neither conclusion follows.  First, the proposed system is intended
&gt;to "advise commanders".  It is NOT stated that the system is intended
&gt;to act on its own or to be blindly followed.  Commanders will be very
&gt;likely to ignore the advise of such a system -- they tend to be very

There is truth in both these viewpoints.  My observations indicate that people
tend to place more faith in the 'judgment' of machines than is warrented.
Steven believes that commanders are suspicious enough of expert systems that
this tendancy is overridden.  The real issue is getting good information to the
person making the decisions, (Can you tell I'm M.I.S.?) and making sure that
the decision maker understands the system(s) that is(are) giving him
information well enough to evaluate that information.
  Most of the problems I've seen with automated systems aren't
intrinsic to the form.  They're implementation errors.
 * When you put in your 'Expert System', do you train the user to evaluate its
output, or do you train them to follow its directions?  If the people who MAKE
the system are the ones doing the training, I'd bet on the latter.
 * Does the system tell you WHY it thinks you should do something, or does it
just tell you to DO it?.  Deciding what a person does and does not need to know
is always a tricky task.
 * Is it obvious or explained HOW the system works?  It's much easier to
predict bizzare, erroneous, or just less-than-optimal performance if you've got
a good idea of how the system works.
 * When you put the system in, are you removing other sources of information?
Putting a tv camera on a vehical will let you see into blind spots, zoom, and
edit in other information. That DOESN'T mean you ought to plate-over the
windshield....

The problems we have using technological artifacts are the same as we have
making the parts work in the artifact.  The pieces have to work with the
system, And the system always includes all the parts AROUND whatever you're
changing.

</PRE>
<HR><H3><A NAME="subj2.3">
Re: Expert system in the loop (Philipson, <A HREF="/Risks/10.38.html">RISKS-10.38</A>)
</A>
</H3>
<address>
Jeff Johnson 
&lt;<A HREF="mailto:jjohnson@hpljaj.hpl.hp.com">
jjohnson@hpljaj.hpl.hp.com
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 10:35:57 PDT
</i><PRE>

&gt;   We all wish to minimize risk, but we must recognize that we can
&gt; not eliminate it; there are significant risks in human activities
&gt; regardless of how they are undertaken.  There will be grave errors
&gt; in military operations regardless of the technology that we use.

The captain of the Vincennes was faced with a decision that had four
possible outcomes:

  1. Destroy approaching plane; plane is hostile (CORRECT OUTCOME)
  2. Destroy approaching plane; plane is not hostile (ERRONEOUS OUTCOME)
  3. Don't destroy approaching plane; plane is hostile (ERRONEOUS OUTCOME)
  4. Don't destroy approaching plane; plane is not hostile (CORRECT 
     OUTCOME)

Mr. Philipson's statements read as if erroneous-outcomes such as case
#2 are unavoidable given the nature of decision-support systems and
human decision-making, and are qualitatively similar to errors such as
case #3.  They are neither.  Military personnel have, by joining or
accepting induction into armed service, accepted certain risks. 
Civilians have not.  If there is any doubt whatsoever that the
approaching plane was hostile, the Captain should have decided not to
destroy it, accepting the risk of outcome #3, i.e., that his ship might
come under attack (Note:  not even necessarily that his ship or crew
would sustain any injuries).  He and his crew signed up for that risk
when they went to sea.  The passengers of the airliner had accepted no
such risk.  The Captain should have waited.

Jeff Johnson, HP Labs, Palo Alto

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
I'm 99% Sure You're A Crook!!!
</A>
</H3>
<address>
&lt;<A HREF="mailto:mmm@cup.portal.com">
mmm@cup.portal.com
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 13:59:54 PDT
</i><PRE>
Message-Id: &lt;9009141359.1.139@cup.portal.com&gt;
X-Possible-Reply-Path: sun!portal!cup.portal.com!mmm

The following items appeared in the 9/14/90 edition of Action Line,
a consumer advocacy department of the San Jose-Mercury-News.

I recently shopped at PW Market at Landess and Morrill roads.  When I gave the
clerk my check, she immediately accused me of writing a bad check -- several,
in fact.  I was totally embarrassed.  I've never bounced a check in my life!
                  -- L.T.L., San Jose

[Response by Action Line.]

There was a communication problem, says Mike McMaster, store manager, who says
he's sorry you were embarrassed.  He will be sending you a letter saying so.
However, McMaster says you weren't accused of writing a bad check but
misunderstood the chain's check-clearing system, which is different from most
other stores'.  PW's system records bad checks by listing the last six digits
of the checking account number; the _complete_ checking account number is
listed in a separate booklet.  The last six digits of your account number
matched one in the store's computer, which is what caught the clerk's
attention.  After the clerk checked the book, however, she realized the rest of
your account number did not match.  McMaster says you didn't want to listen
when employees tried to explain it to you.  McMaster says PW is trying to
rework its computer system so it will accept 10-digit numbers to avoid a
similar situation in the future.

[To me, it seems like there is quite a range of quality in the machines used to
verify my credit.  Some are solid-looking hardware from NCR or IBM with
expensive keyswitches and plasma displays.  Others are cheapo stuff with LED
displays and calculator-style keypads.  I guess PW went with the system from Ma
&amp; Pa Kettle POS Systems.  mmm]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
A Nightmare: Security compromise with SUN's C2 package
</A>
</H3>
<address>
Caveh Jalali 
&lt;<A HREF="mailto:caveh@csl.sri.com">
caveh@csl.sri.com
</A>&gt;
</address>
<i>
Mon, 17 Sep 90 15:21:35 -0700
</i><PRE>

Let's pretend to be a smart password cracker who has heard of "doing things in
parallel" and design a system that would allow us to crack passwords on many
machines simultaneously.  One might conceive of a RPC service that accepts
incoming requests for (user-name, plain text password) pairs and tests the
validity of said pair against that system's password file.  One would run this
service on every workstation, and obtain parallelism by making requests to all
workstations virtually simultaneously.

Example:

Let's say we have a typical office environment of a few file servers with 30
workstations.  We are security conscious, so we enable SUN's C2 security
package.  Typically, these workstations would share the same password file
using SUN's Yellow Pages.  All we need to do now is to install the above
mentioned service on all of these workstations and we can check about 30
passwords in parallel.  Not bad, if we could just find a way to get that
service running on all workstations...

Gee... I wonder what rpc.pwdauthd does?  Bingo!  Here is EXACTLY the
desired service.  It already runs on every SUN with C2 enabled!

When C2 is enabled, the password part of the password file is hidden from
users.  Rpc.pwdauthd fills the gap by providing a service whereby a
(user-name, plain text passwd) may be verified; this service runs on every
workstation.  One makes RPC calls to the daemon to verify a password.

Unfortunately, any one from any where may do this at any time, thus leaving the
doors open for distributed password cracking.  The cracker doesn't have to
provide his own CPUs -- he can just use all the CPUs that are in your domain!

To make matters worse, rpc.pwdauthd does NOT generate any audit records even
though it makes the appropriate calls.  This is a bug -- the code neglects to
set the process audit-uid and audit-state, so all auditing is ignored.

Conclusion:
In order to hide passwords from crackers, we have instead offered crackers the
IDEAL means to do what they wanted to do in the first place: Crack YOUR
passwords, using YOUR machines, possibly using ALL your workstations!!!

00c - Caveh Jalali

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Another risk of phone systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 20:52:26 EDT
</i><PRE>

Harvard has just finished installing (at some expense) a new phone system for
undergraduate use.  By various threats and persuasion, HU has set up this
system so that no sensible undergraduate would buy phone service from any other
vendor (Only HU subscribers get listed in Harvard's Centrex directory, get
Centrex service, etc.)  To handle long distance (which subscribers to HU's
local service automatically buy from HU as well) they have set up a Personal
Authorization Code (PAC) system; to make a long-distance call from any 493-
(student) phone, the caller must enter a five-digit code that is assigned at
the beginning of the year.  Students cannot change their codes except by going
to the phone people and asking for a new one, which costs money.

A conversation I have heard at *least* five times since my arrival two days
ago:

"Gee, there are 100,000 possible PAC codes, 00000-99999.  And there are
6400 undergraduates [essentially all of whom live in dorms and subscribe
to Harvard's phone service].  That makes a 1/16 chance that a randomly
chosen code is a valid PAC code."

"So, choosing about [fiddles with calculator] 10 or 11 codes at random
gives a 50% chance of hitting a valid one."

The RISK is obvious.  This is obviously a frequent thread, but if an
institution with so many intelligent people (like, in the CS department or Math
department) can be so STUPID...

PS.  My friends at MIT tell me that their system is similar.  Is every college
this asinine, or only the decent ones? ;-)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Desktop Publishing Fraud
</A>
</H3>
<address>
Sanford Sherizen 
&lt;<A HREF="mailto:0003965782@mcimail.com">
0003965782@mcimail.com
</A>&gt;
</address>
<i>
Sat, 15 Sep 90 16:09 EST
</i><PRE>

I would like to know if anyone has any experiences with, citations,and/or
thoughts about DTP fraud. With a relatively low investment in scanning devices,
a person could easily use desktop publishing for copying checks, certificates of
deposits, currency, diplomas, grade transcripts, licenses, etc.  A few cases
have already been found and a relatively recent article in FORBES spelled out
the problem in some clear detail.

Here are some questions that come to mind about the risks. Comments welcomed. 

*  Is this truly a problem today or in the near future?  

*  Are there techniques to detect scanned versus original documents?  

*  Are there sufficient restrictions over the types of specialized paper stock  
       that is used for currency and other financial instruments?  

*  What are some of the developments in desktop publishing (or other related    
       technologies) that may worsen (or even possibly contain) this type of    
      copying?  

*  What are some of the other types of documents that people have or might copy 
       for illicit purposes?  

*  If there is the capability to scan and/or manipulate financial instruments,  
       what will happen to the national economies of nations that are           
       (somewhat) dependent upon restricted opportunities to counterfeit these  
       instruments?

Need some extra money?  Warm up that copying machine.

Sandy                              Sanford Sherizen, Natick, MA 01760 USA
PHONE (508) 655-9888, FAX 508-879-0698, MCI MAIL:   SSHERIZEN  (396-5782)
     
</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Data cowboys and database abuse - applicant screening
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.El_Segundo@Xerox.com">
Hoffman.El_Segundo@Xerox.com
</A>&gt;
</address>
<i>
17 Sep 90 07:58:18 PDT (Monday)
</i><PRE>

'Business Week', September 24, 1990, carries a story by Jeffrey Rothfeder
detailing not only the all-too-common tales of mistaken identity in
personal data, but a new category of "data cowboy" selling data it is
illegal for employers to have:

         LOOKING FOR A JOB?  YOU MAY BE OUT BEFORE YOU GO IN
    Background checks are nosier now, and harder to fix when wrong

The lead-in tells of James Russell Wiggins being fired after six weeks on a
new job when a background check turned up a drug conviction.  "It turned
out that Equifax Services Inc., the company that investigated Wiggins'
past, had goofed:  It pulled the criminal record of James RAY Wiggins.
Wiggins was the accidental victim of increasingly common practice --
combing data bases to find information on job applicants....."

"Providing employee data to companies ... is a booming business, say data
vendors.  Sales of pre-employment data are growing as much as 75% a year
for some suppliers.  The larger players -- Equifax, Fidelifacts
Metropolitan New York, and Apscreen, among others -- provide more than raw
data.  They mix information from various data bases and produce summaries
that describe the applicant's financial condition, criminal and driving
records, and business relationships.  Despite the occasional mix-up, the
big data companies have earned a reputation for thoroughness."

Such checks can cost as little as $100, but some employers with high
turnover find even that too much, and turn to cut-rate data sellers who
"assemble raw, unchecked data from creidit bureaus, motor-vehicle
departments, courthouses, and other sources.  Problem is, some of the
information may not be legal to use when hiring.  'These data cowboys worry
me,' says Apscreen Pres. Thomas C. Lawson, who fears that a backlash
against them could prompt restrictions on the sale of legitimate
pre-employment information...."

"Information Resource Service Co. (IRSC) in Fullerton, Calif., for example,
sells lists of arrests that ended in acquittal, discharge, and no
disposition...." It's illegal for a employers to have such information.
Other data bases, such as Employers Information Services Inc. (EIS) in
Gretna, La., track employees who have filed for workers' compensation.

"Ernest Trent, a Pennzoil Co. roustabout who has 15 years experience,
ripped his right arm on an oil rig in 1986 and collected workers'
compensation.  Since then, he has been turned down for nearly 200 jobs.
'I'm blacklisted.'" If so, it's illegal.  "Both EIS and IRSC say they can't
control how their clients use the information they buy."

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Inside risks of INSIDE RISKS
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 18 Sep 1990 8:31:52 PDT
</i><PRE>

My piece in the September CACM (in the inside back cover section called INSIDE
RISKS) has a really strange error, in which a bulleted item appears near the
top of the last column, instead of at the beginning of the conclusions section,
with the other bulleted items.  Constantly having to live with flaky
networking, I am not surprised by anything, but do not recall having an EMail
message arrive with the order of paragraphs scrambled.  (We have of course had
numerous reports of compression algorithms going astray, lost messages,
duplicate messages, etc.)  In this case, BITNET could be the culprit, because
my copy of the same message was fine.  A context editor problem might also be
suggested.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-13</DOCNO>
<DOCOLDNO>IA013-000136-B029-171</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.40.html 128.240.150.127 19970217040122 text/html 28502
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 03:59:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 40</TITLE>
<LINK REL="Prev" HREF="/Risks/10.39.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.41.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.39.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.41.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 40</H1>
<H2> Tuesday 18 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Software Unreliability and Social Vulnerability 
</A>
<DD>
<A HREF="#subj1.1">
Perry Morrison
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  DTI/SERC Safety Critical Systems Research Programme 
</A>
<DD>
<A HREF="#subj2.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Canadian Transportation Accident Investigation 
</A>
<DD>
<A HREF="#subj3.1">
Brian Fultz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risk of Collision 
</A>
<DD>
<A HREF="#subj4.1">
Brian Fultz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Knight reference: `Shapes of bugs' 
</A>
<DD>
<A HREF="#subj5.1">
Pete Mellor
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Software Unreliability and Social Vulnerability (Re: <A HREF="/Risks/10.31.html">RISKS-10.31</A>)
</A>
</H3>
<address>
Perry Morrison MATH
&lt;<A HREF="mailto:pmorriso@gara.une.oz.au ">
pmorriso@gara.une.oz.au 
</A>&gt;
</address>
<i>
15 Sep 90 07:30:18 GMT
</i><PRE>

Many thanks to all those who have contributed their views on issues raised
in my article with Tom Forester -"Software Unreliability and Social 
Vulnerability", Futures, June 1990. I don't have time or space to respond 
in detail to all of the comments made, but I would like to pick up on some of 
the main threads while they are still salient for most risks readers.

First, I was never completely happy with the blanket conclusion of removing 
digital systems from life-critical applications, but it has served a purpose 
in bringing software unreliability to the attention of the general public in
a fashion that has more rigour than the tabloids would provide (I hope!).
In the process, it has brought what I believe are increasingly important
issues back to the arena of software/systems specialists.

Although the paper restricts itself to software/hardware failures, it is
highly influenced by Charles Perrow and the "Normal Accidents" argument of
complex systems. As others have already stated, the central issue is
really system complexity -- the limits it places upon our capacity to predict
system behaviour. Unfortunately, digital systems have two other properties
that exacerbate their unreliability: (a) it is easier to build much more
complex digital systems than analogue ones (or at least we have so far) and 
(b) digital representation and computation provides more scope for 
catastrophic/unpredictable behaviour than analogue techniques -- essentially 
the "untestable number of system states" and "each state is a possible
catastrophic discontinuity" arguments that we have (hopefully correctly) 
borrowed from Dave Parnas and others.

Our motivation stemmed from our concern that we (others, I mean) have 
already built systems of such complexity that we no longer understand or 
can predict in any adequate sense, their full range of possible behaviours. 
This concern is exacerbated by the tendency of complex systems to also control
complex responsibilities or awesome energies and involve huge monetary
investment.  Such systems -- things like the Shuttle, some particle 
accelerator/conglomerates and others exhibit very high levels of unreliability. 
Note however that it is not only the digital components of 
such "hybrid" systems that are unreliable, but their analogue components as 
well -- valves etc. Again, it is enormous complexity and our inability to get 
adequate intellectual handles on it that is the root problem.

However, for better or worse, society is steaming down the road toward
greater application of complex digital techniques... to everything -- financial
systems, control of basic services, defence, communications.... In our
view, this will lead to more complex digital systems with concomitant
levels of unreliability and sometimes quite disastrous results. Our major
purpose was to point out that in creating such powerful systems we cannot
have our cake and eat it too -- we should not be surprised that when they
fail (as they occasionally will being human created artifacts) the
consequences will be catastrophic. The unreliability of complex systems
(which, as outlined above tend to be digital) and the power/energies bound 
up within them should lead us to expect such consequences. Whether this
scenario is any better than other alternatives (whatever they are) is a value
judgement of some complexity itself. It is a value judgement because it
relies upon subjective assessment of what constitutes an acceptable level
of risk for a given system and the responsibilities it is tasked with.

Note also, that we tend to ignore the notion that there is more than one
legitimate assessor of risk -- not just the developer or client, but the 
users and those that the system affects in direct or indirect ways. This
is essentially the PR problem that nuclear reactors and fly-by wire systems
have -- perhaps the psychological processes of individuals are often awry,
but they clearly assess the risks of FBW (and the owners/operators merely
mirror the commercial consequences of this concern) as worrying. In
this sense, successful design is as much an educational/consultative
process as abstract discussions about reliability. 

I need to take some time to address the issue of risk in a way that
I don't believe any commentator has to this point.

1. It is important to note that most commentators in this discussion have
assumed that most system design/implementation happens in a relatively
controlled, client-expert relationship where the expert has a fair
degree of control over the qualities that the system will have. Often
this is not the case -- increasingly, subsystems are being designed and
plugged into ad-hoc mega-systems (like the international financial system
communications networks) thereby adding to overall complexity without
the advantage of any over-riding design to guide the development of the
subsystem (apart from protocols say). I believe that this is a dangerous 
trend and it is a characteristic that many communications nets and other 
systems have -- they just grow like topsy and "design" if it can be called 
that is blatantly ad-hoc.  Clearly, even conventional systems are added to and 
expanded throughout their useful lifetime, but generally some design documents 
are available and eventual limits to the system can be reliably assessed. 
Assessment of risks in the former situation and judgements of required
levels of reliability can become very difficult indeed.

2. The application or nonapplication of digital techniques and the subissue
of whether analogue systems are better in some applications need to
be considered against some systemic cost/benefit analysis or analysis
of risk (how appropriate!). Phil Maker of the Northern Territory Uni called and
pointed out to me that he designed defibrillators (things that restablish
the normal electrical activity of the heart I believe) and that the 
chances of such people dying without a defibrillator is 50% in any given year.

Clearly, software unreliability is an insignificant risk in that situation --
small numbers of people with high existing risk and enormous potential
benefits -- using systems of comparatively low complexity. On the other hand, 
a complex digital system controlling a nuclear reactor may (possibly) provide 
efficiency benefits that are insignificant compared to the consequences of a 
nuclear accident stemming from software unreliability . i.e. a situation in
which marginal benefits and high complexity exist, coupled with catastrophic
consequences in the (perhaps low probability) event of systemic complexity
bringing about an accident.

**Perhaps** a less complex analogue system could be applied in this case, if 
at all possible. Note however that reduction of complexity in a situation with 
high background risk and/or potential catastrophic consequences (subjective I 
know) is what I would (now) advocate.  (Note that the example of a computer
based intensive care unit has all the qualities of a good application
of complex systems -- high existing risk, good potential benefits, localised
failure consequences). It just so happens (I believe) that analogue systems 
by their nature, limit how complex a system can become. On this point, shortly 
after the article was published, we received a call from someone in 
authority at the Shell oil company. They mentioned that they were 
investigating the possibility of going back to analogue systems for their 
drilling rigs because of their concerns relating to software unreliability.

3. In answer to the implicit question -- "what else can we do but apply digital 
systems to life-critical (or potentially catastrophic) situations" one should
be clear that many "needs" or areas of application are only driven by the
possibilities that computers provide. They are often not genuine, 
pre-existing needs. For example, my father hardly knew what cheques were
for until later in life. Only rich people had a need for such things
and banks wouldn't wear the manual processing costs for large numbers of
cheque accounts. Computers eventually allowed that to happen but I'm not 
sure that there was a screaming demand for cheque books at the time. Yes it's 
convenient and yes the whole electronic funds basis of our economies
allows us to do wonderful things with enormous ease. At the same
time it has created a system that is subject to massive, international abuse, 
theft, fraud and (perhaps) great risk of rapid systemic collapse given a 
sufficiently powerful event. Given these benefits and arguably large
risks, is the electronic financial system a good idea? The major point
however is that NO-ONE ever had the chance to evaluate the risks involved
because the system grew incrementally without any central design base.
It just happened. 

Some of us may ask -- "how else could the international financial system be 
controlled?" Clearly, it can't be controlled by anything but digital 
techniques, since they spawned it in the first place, but the point is we
know have a whole new class of problems to deal with due to the develoment
of the system. This may all sound like old hat and recycled luddism, but
as our article pointed out, there's no substitute for technologists being
concerned about the implications of the systems they design and implement.
For example, I imagine that antarctic mining would create some really 
interesting temperature/electromagnetic reliability problems for software 
and hardware designers. But for my money, antarctic mining is irresponsible 
with large potential for dramatic environmental damage. Obviously, we 
shouldn't restrict ourselves to the mere technical problems involved in our 
work. It might sound quaint, but too many systems are simply technology
driven rather than need driven. Stop the clock, go back to the caves you
ask? No, but we shouldn't complain when complexity makes unreliability a
problem for implementors and an issue for the general public. If we
actually EXPLAINED to the public the design contraints we face and INVOLVE
them in the design, they may come to accept levels of unreliability that
we think they won't tolerate. On the other hand they might throw up their
hands and say "what the hell do think you're doing". Either way it would
be very interesting.

4. Where does this leave us? Merely with the ideology that lots of technology
commentators have peddled for a long time -- the notion that technologists
must properly evaluate the implications of what they do and actively
involve in the design process the people they affect. This includes amongst
other things a consensus of opinion on what is a sufficient level of
reliability given the array of risks. Too often we want prefabricated
solutions/methodologies like "what are the best methods for providing
an error minimized system at minimal cost for applications of type x".
That is the engineer talking to his colleagues and designing for an
abstract user group or (real) corporate owner. It is meaningless unless the 
designer/implementor understands that such prescriptions must be modified 
in the face of existing circumstances. Those circumstances include what the 
users and others affected by the system think.

In this same vein, some commentators seem to believe that we are hostile to 
probabilistic measures of software reliablity/quality. This is not so -- just 
that probabilities by themselves are not enough. They are meaningless without
some understanding of the reliability/quality required in the intended
application by the intended users.  That is, as already explained, low levels 
of reliability may be an unacceptable source of risk in some situations 
(reactors?) but not in others (defibrillators) even when the software has 
equivalent probability of failure. How do you know how reliable the software 
must be? How do we know if digital systems are best or analogue? The answer 
is that as a generalization, law or principle we probably don't. But in the 
end we should remember that we are designing for people and if they are 
included and fully informed and satisfied with the 
safety/reliability/performance provisions in a design, then that should be 
enough.

As always, the customer is always right.

Perry Morrison

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
DTI/SERC Safety Critical Systems Research Programme
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian.Randell@newcastle.ac.uk">
Brian.Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Mon, 17 Sep 90 9:38:19 BST
</i><PRE>

The following article is reprinted in its entirety from the British Computer
Society's Computer Bulletin (vol. 2, part 7, Sept. 1990, p.2). It marks the
launching of a new joint initiative by the Department of Trade and Industry and
the Science and Engineering Research Council, to fund industry/university
collaborative research projects relating to safety-critical systems. I
personally very much like the tone of the article - and hope that it can be
matched by the research projects that get selected.  Brian Randell

  Brian Randell, Computing Laboratory, University of Newcastle upon Tyne, UK
  EMAIL =	Brian.Randell@newcastle.ac.uk
  PHONE =	+44 91 222 7923    FAX = +44 91 222 8232

: Safety Critical Systems - Bob Malcolm
: 
: On the stairs and landing of my cottage I have four light-bulbs. A few
: weeks ago the landing went dark. No, it was not a blown fuse, but the
: fourth light bulb gone. As technical co-ordinator for the DTI-SERC
: Safety Critical Systems Research Programme I smiled - wanly, as they
: say.
: 
: I had failed to replace the three bulbs which had failed previously. I
: had fallen prey to one of the classic safety critical system problems
: - failure to maintain redundant channels. Why did I do it? Why do
: people store rubbish in fire-escapes? It is no good saying that 'They
: shouldn't do it'. They do. What are designers to do about it?
: 
: The challenge in building safety critical systems is to achieve safety
: in the real world. We may not understand the world and may not be able
: to describe it properly, populated as it is by real and really
: perverse people - designers and managers as well as users and vandals.
: 
: It is not enough to think only of 'meeting a specification',
: especially when the majority of failures arise because of
: specification errors. Nor is it sufficient to add something about
: getting the specification right, since we can never be sure that we
: have succeeded.
: 
: One view of safety critical systems is that all failures have their
: origins in human error of some kind - whether a design or operational
: mistake, a failure to understand either a system or its failure modes,
: or a failure at a higher level to appreciate and accommodate the
: likelyhood of these errors.
: 
: To produce safety arguments for systems based on reasoning about a
: wide range of technological and human factors requires not only that
: we compare chalk and cheese, but that we add it together in some way.
: We will need to balance arguments about the style of design with
: arguments about its correct construction; arguments about proof with
: arguments about likelihood; arguments about comprehension with
: arguments about rigorous notation. Who knows - maybe if we succeed in
: general then we will succeed in the particular of reconciling
: formalists and 'the rest'. To do that we would also need to make
: explicit the rigour which is presently only implicit in so-called
: 'informal' methods and tools.
: 
: I doubt whether we can do all these things without the help of
: psychologists, operational researchers, even philosophers. Computer
: technologists and experts in application domains must work with them
: to devise better global solutions and, as far as is possible and
: sensible, common solutions. We must avoid the 'displacement' problem
: where fixing one problem simply creates a different and perhaps worse
: problem elsewhere. And we must find ways of quantifying the
: effectiveness of what we do - whether as a contribution to a 'safety
: argument' or to a probabilistic risk prediction.
: 
: But we need the cooperation of all these different disciplines not
: just for the particular skills which they individually bring to the
: party. We need them because of their very diversity - to enrich our
: intellectual stock.
: 
: In the new DTI-SERC programme we must produce results which will be of
: commercial value in the medium term. To do this we must have a firmer,
: better-reasoned, basis for what we do. We might stand a chance if we
: are prepared to open our minds.
: 
: Hard scientists must stop treating soft science as non-science: soft
: scientists must not feel disenfranchised. Formalists must seek the
: value of what they call informal, and help in its formalisation;
: informalists must find the justification for what they do.
: 
: Safety critical systems pose problems which push us toward
: co-operation between disciplines. I hope that industry and academia
: seize the opportunity to do this within the new programme.
: 
: [Bob Malcolm is an independent consultant in the field of systems and
: software engineering.  He currently holds a number of contracts for
: consultancy in research and technology transfer, and is technical
: co-ordinator for the new DTI-SERC Safety Critical Systems Research
: Programme. He is a visiting professor at City University, London.   BR]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
    Canadian Transportation Accident Investigation
</A>
</H3>
<address>
&lt;<A HREF="mailto:Brian_Fultz@carleton.ca">
Brian_Fultz@carleton.ca
</A>&gt;
</address>
<i>
Sat, 15 Sep 90 07:31:35 EDT
</i><PRE>

The above body in Canada is responsibility for making reports on "accidents"
and "aviation occurrences".  They produce reports on safety related problems.
With reference to report 87-A74947 "Risk of collision between Delta Air Lines
Lockheed L-1011 N1739D and Contential Air Lines Boeing 747-200 N608PE
&lt;location&gt; North Atlantic 52 degrees 14 north, 34 degrees, 00 West Long &lt;Time&gt;
08 July 1987.

As the report is over 4 pages long in reduced for I will give only the parts I
think are risk-relevant.  At 30 degrees West Longitude Delta 37 began deviating
to the south of it's assigned track and closed laterally with Contential untill
the aircraft crossed the assigned track of the Contential ...  The front half
of Deltaa 37 passed beneath the rear fueselage of the Contential 25 with less
than 100 feet of vertical separation.  Neither crew saw the other aircraft in
time to take evasive action. ....  The Captain used the Flight Management
System to ...  Passed possition report at 30 degrees west &lt; wrong by 16 minutes
&gt; ...  Gross navigaional error &lt; deff'n more than 25 miles off &gt; Conclusions &lt;
I am going to use the numbering of CTAT &gt; 1) The near collision resulted from a
INS &lt; interial navigation system&gt; data input error by the Deltal Flight 37
crew.  9) Although cross checks were contained in explicit detail in the manual
used by the crew, they were set out in such terms and format that a manditory
requirement to cross check at each and every waypoint may not have been clearly
conveyed to aircrew.  13)The estimate for Delta 37 at 40 west showing a
difference of 16 minutes was not challenged by ATC nor was it required to be...
19 no evidence was found that would indicate the Delta 37 INS was
malfunctioning prior to or during the flight.  ....lots of recommendations to
make pilots make cross checks...
                                              Brian Fultz

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
    Risk of Collision
</A>
</H3>
<address>
&lt;<A HREF="mailto:Brian_Fultz@carleton.ca">
Brian_Fultz@carleton.ca
</A>&gt;
</address>
<i>
Sat, 15 Sep 90 08:12:31 EDT
</i><PRE>

Between Boeing 767 C-GPWA and Boeing 727 C-GAAY &lt; location&gt;
Toronto &lt; time &gt; 18 February 1987

The board writes .. &lt; I have taken out aviation specific terms &gt; The Boeing 727
and the 767 were on identical tracks to Toronto.  The 727 was at 29,000 feet
the 767 directly overhead at 31,000 feet....  ATC cleared the 767 to 11,000
feet ...  ATC 3 attempts to stop 767 ... not understood ... eventually halted
1/4 mile EAST of 727 ...  evasive vectors issued by ATC ... evasive
instructions turned aircraft toward each other

In the Pertinent information section:
Radar recordings indicated that the flight data blocks for the aircraft
overlapped on the controllers radar screen.  The system then repositioned the
display: the 767 to the WEST and the 727 to the EAST &lt; see above &gt; ....  The
repositioned data block display was opposite to the actual relative positions
of the two aircraft.
                                             Brian Fultz

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Knight reference: 'Shapes of bugs'
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Mon, 17 Sep 90 21:34:49 PDT
</i><PRE>

In a <A HREF="/Risks/10.31.html">RISKS-10.31</A>, I wrote:

&gt; A serious attempt *has* been made (by John Knight - reference not to hand)
&gt; to examine the shapes of bugs in programs, i.e. the topological properties
&gt; of those subsets of the input space which activate program faults.
&gt; Chaotists will be pleased to learn that they were fractal.

Several people have asked for the full reference. It is:-

Paul E. Amman, John C. Knight: 'Data diversity: an approach to fault tolerance'
     Proc. FTCS, 1987, pp 122-126,
     0731-3071/87/0000/0122$01.00 (c) 1987 IEEE

The paper concerns the use of `data diversity' as a means of improving program
reliability, as opposed to *design diversity*. The idea is that, since the
activation of a software fault depends on a particular selection of input data,
it may be possible to perturb the inputs in such a way that the output is still
valid in all cases, and yet not all of the perturbed versions of the input
activate the fault. A voter can then process the various outputs in a similar
fashion to N-version programming.

The ability to perturb inputs in a valid way depends upon the shape and size of
the `failure region'. To quote:

  The `failure domain' of a program is the set set of input points which
  cause program failure [3]. The geometry of a failure domain, which we call a
  `failure region', describes the distribution of points in the failure
  domain and determines the effectiveness of data diversity. The
  fault-tolerance of a system employing data diversity depends upon the
  ability of the re-expression algorithm to produce data points that lie
  outside of a failure region, given an initial data point that lies within
  a failure region.
  ...[stuff omitted]
  We have obtained two-dimensional cross sections of several failure
  regions for faults in programs used in a previous experiment [5].
  ...[stuff omitted]
  The cross sections shown are typical for these programs. This small sample
  illustrates two important points. First, at the resolution used in scanning,
  [The inputs are simulated data from radar scanners tracking an object. - PM]
  these particular failure regions are locally continuous. Second, since the
  failure regions vary greatly in size [by a factor of 4 x 10~10 ! - PM],
  exiting them varies greatly in difficulty.

[End quote]

You will see that the authors do not, in fact, claim that the failure regions 
described in this paper are fractal, so apologies if my statement misled anyone.
However, they cross-refer another paper which describes these faults:

S.S. Brilliant, J.C. Knight, N.G. Leveson: `Analysis of faults in an N-version
software experiment', University of Virginia Technical Report No. TR-86-20,
September 1986.

The two papers cross-referred in the above extract are:

[3] F. Cristian: `Exception Handling', in `Resilient Computing Systems',
    volume 2, T. Anderson, ed., John Wiley &amp; Sons, New York (to appear).

[5] J.C. Knight, N.G. Leveson: `An experimental evaluation of the assumption 
    of independence in multiversion programming', IEEE Transactions on
    Software Engineering, Vol. SE-12, No. 1, January 1986, pp 96-109

BTW my mail system has been playing up. If anyone has mailed me, e.g., to
request a copy of the Forester and Morrison paper, and not received a reply,
please retransmit.

Peter Mellor, Centre for Software Reliability, City University, Northampton 
Sq., London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.39.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.41.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-14</DOCNO>
<DOCOLDNO>IA013-000136-B029-202</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.41.html 128.240.150.127 19970217040137 text/html 21069
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:00:04 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 41</TITLE>
<LINK REL="Prev" HREF="/Risks/10.40.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.42.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 41</H1>
<H2> Tuesday 18 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Software Certification 
</A>
<DD>
<A HREF="#subj1.1">
Michael J. Konopik
</A><br>
<A HREF="#subj1.2">
 Joe Marshall
</A><br>
<A HREF="#subj1.3">
 Jerry Glomph Black
</A><br>
<A HREF="#subj1.4">
     Martyn Thomas
</A><br>
<A HREF="#subj1.5">
 Phil Windley
</A><br>
<A HREF="#subj1.6">
 GaryFostel
</A><br>
<A HREF="#subj1.7">
 Theodore Ts'o
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
applicability of software curricula
</A>
</H3>
<address>
Michael J. Konopik
&lt;<A HREF="mailto:zzz@NISC.SRI.COM ">
zzz@NISC.SRI.COM 
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 17:02:21 PDT
</i><PRE>

In his discussion of software certification in RISKS 10.38, Theodore Ts'o made
a sweeping condemnation of the MIT software engineering curriculum.  He argued
that it sidesteps the real world by teaching "completely dated" languages and
not teaching the use of any commercial SE tools in the classes.  I never
thought I'd stand up to defend anything about MIT; but I wanted to add some
more context on the issue for those who weren't exposed to this curriculum.

It would seem that Theodore was so intent on blocking out the Liskov
philosophy of programming that he didn't hear the statement of the purpose
of 6.170.  In fact, the same teaching strategy was applied in 6.001 and 6.004,
as well.  None of those classes taught their material using any "real world"
languages or tools.  The professors all gave pretty similar disclaimers that
went something like this:

    We're not here to teach you C.  We're not here to teach you how to
    use any particular set of tools.  On the contrary - our purpose is
    to teach you a framework of fundamental concepts.  And if we use
    commercial tools and languages to teach it, many of you will spend too
    much time concentrating on those things instead of the material
    itself.  The languages and tools we use are in themselves functionally
    complete.  They are tailor-made to facilitate teaching the material.
    And when you finish the class, you will be able to apply what you learn
    to whatever environment in which you find yourself working, without being
    biased to any one specific set of languages or tools.

After the exam for 6.001 (in '82), I met Sussman on the 9th floor of NE43 to
express my appreciation for the course.  I told him that I had really grown to
like Scheme in a big way, and I asked him if it would be possible for me to
obtain updates to the language manual as it evolved in the next few years.
His stern answer was "Absolutely not!"  I pressed him - "Why??"  His answer
has stuck with me.  Quote not quite exact:  "You completely missed the point,
Mike.  Scheme was just a teaching tool.  So what if you can write programs in
it?  After 6.001, you should be able to pick up half a language in half a week.
And for almost any program you want to write after this, there will be at
least three other languages out there that are more suitable for writing the
program than Scheme will be.  Forget the language - remember the material!"

Heck, the assembler they taught when I took 6.004 didn't even exist, except on
paper!!  But it still conveyed the ideas they wanted to teach pretty well.

Regarding CLU and Liskov's "religion":  Theodore's assessment sounds a little
bit extreme.  We had the evils of globals preached to us, too.  But the point
was made that programmers should avoid using globals WHENEVER POSSIBLE;
because for one thing, it's usually cheaper to pass around one-word pointers
to large objects than to have to manage a huge heap of globals.  We were also
force-fed the top-down programming methodology.  But one of our lectures had
a mention of how it usually works in the "real world", calling it something
like the Iterative Method (design - code - test - loop).  The "One True Way"
was just the idealized classroom method.  Maybe they don't discuss that
anymore, or maybe Theodore punted that particular lecture...

To make a short story long - sure, they didn't teach a lot of reality in MIT's
SE curriculum.  But in my opinion, what they did teach was of much greater
long-term value.  For the concepts being taught apply to more than just the
software development environment that is preferred at the time.  Teaching
everything with "current" models runs a risk of rapid obsolescence.
                                       				        -Mike

</PRE>
<HR><H3><A NAME="subj1.2">
The need for software certification
</A>
</H3>
<address>
Joe Marshall 
&lt;<A HREF="mailto:jrm@lucid.com">
jrm@lucid.com
</A>&gt;
</address>
<i>
Sat, 15 Sep 90 10:26:13 PDT
</i><PRE>

I am against certifying software professionals.  I agree with Mr. Ts'o that
professional certification would lead to a "guild".  Like Mr.  Ts'o, I think
that my style of programming is near perfect and I always write nearly bug-free
code.  Like Mr. Ts'o, I am afraid that I would be excluded from the "in-group"
for reasons that have little to do with my outstanding ability to write
bug-free code on the first pass with no expressed design goals.

But before we start excluding undesirables from our midst, we should look at
what we are trying to accomplish.  I think most of us would agree that we want
to have computer systems that reliably accomplish their stated purpose (leaving
aside the ethical questions of what purposes are worthy).  In order to
scientifically engineer such systems, we need a way to measure the reliability.
This would include examining failure modes, assigning probabilities to them,
and evaluating the undesirability of such failures.

To some extent, this is a black art in the realm of software
engineering.  I know that I haven't been trained in this.  If we could
devise some measure of reliability of software, then we could easily
determine which design methodologies are best suited to producing
reliable software.  Then, any person who could not or would not follow
these methodologies would find it difficult to make a career in
software engineering.

The CLU group at MIT made a concerted effort to address some of the
issues of software reliability.  While many people found the
"religious" atmosphere of the class repressive, I think the basic
principles behind the religion have merit and cannot be dismissed as
"dated" or "archaic".  It was developed in the 70's, long after
teletypes and punch cards.  "Modern" languages (C++) and "modern"
operating systems (Unix) have yet to address the goals of such "arcane"
languages such as CLU and ALGOL and "arcane" systems such as Multics.

I understand that MIT does not offer an accredited computer science program.

					~JRM

</PRE>
<HR><H3><A NAME="subj1.3">
Re: The need for software certification (T'so, <A HREF="/Risks/10.38.html">RISKS-10.38</A>)
</A>
</H3>
<address>
Jerry Glomph Black
&lt;<A HREF="mailto:black@ll-null.ll.mit.edu ">
black@ll-null.ll.mit.edu 
</A>&gt;
</address>
<i>
Sat, 15 Sep 90 10:43:48 EDT
</i><PRE>
Subject: Software Workers Guild/Union

&gt;I am against the "certifying" of software professionals. ...

I fully agree, all we need is another champion of excellence rivalling the
public teachers' unions.  One of the last bastions of intellectual and
economic freedom &amp; independence is in the software industry &amp; craft.  Trash 
this enterprise as well, and we all might as well start cracking open our
'Dick &amp; Jane' Japanese primers.  Now I know why so many computer nerds espouse
Libertarian dogma, it is their appreciation of their relative intellectual &amp; 
economic freedom compared to most stifled workers.  In most endeavours,
creativity, originality, and excellence is stomped on by some actual or
de-facto regulatory or union body.  TYTSO's description of the Software
Engineering course at MIT sounds like another tentacle of the octopus.
Global variables are anathema?  How about pointers to data structures?

Jerry Glomph Black, black@MICRO.LL.MIT.EDU  (Independent software guy)

</PRE>
<HR><H3><A NAME="subj1.4">
Re: The need for software certification
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
17 Sep 90 14:02:54 GMT
</i><PRE>

In RISKS 10:38, Theodore Ts'o gives many reasons why he believes that
ceryifying software professionals is a bad idea.

Certification undoubtedly brings problems - but so does absence of
certification. The criticisms he makes would apply, mutatis mutandis, to
certifying medical practitioners and lawyers, yet many societies have
decided that such certification is desirable.

On balance, I believe that some limited certification is desirable, for
staff who hold key positions of responsibility on projects which have
significance for society. (This is an imprecise phrase, which is intended to
include safety-critical systems, systems involving national security,
systems involving substantial sums of public money, and so on. I have no
doubt that an adequate mechanism for defining such projects could be
devised). Many countries (including the UK) already have such mandatory
certification for other engineers.

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<HR><H3><A NAME="subj1.5">
Re: The need for software certification
</A>
</H3>
<address>
Phil Windley 
&lt;<A HREF="mailto:windley@ted.mrc.uidaho.edu">
windley@ted.mrc.uidaho.edu
</A>&gt;
</address>
<i>
Mon, 17 Sep 90 10:27:22 PDT
</i><PRE>

Theodore Ts'o &lt;tytso@ATHENA.MIT.EDU&gt; makes several objections to certifying
software professionals: [...]

Couldn't these same objections be made to professional certification in
other engineering disciplines?

I will grant that what constitutes "good engineering practice" is much better
defined in mechanical engineering than it is in software engineering and thus
it might be easier to develop a test for mechanical engineering competency than
it is for software engineering.  What is the history of this?  Does anyone know
when the first professional engineering certifications were done and what kind
of trouble this caused for the discipline trying to figure out what to put in
the test?

Even so, having to come up with such a test would certainly create a lot of
discussion, much of it worthwhile.

The second point is, I think, more easily dealt with.  I don't think that
professional certification has led to a "unionization" of engineering.  And
certainly no one would contend that the fact the a person is certified means
that their designs are error free.  So why would this occur for software
engineers?

Most engineering activities that affect public safety (in areas where
certification is done) must (by law) be reviewed and approved by a certified
engineer.  This approval say, in effect, "This design conforms to good
engineering practice for my field."

Has anyone on the list been involved in a large software project that affected
public safety where such a review was or was not done (and will they admit it
;-).

Phil Windley, Department of Computer Sciencem University of Idaho, Moscow, ID
83843, Phone: (208) 885-6501

</PRE>
<HR><H3><A NAME="subj1.6">
RE: The Need for Software Certification
</A>
</H3>
<address>
&lt;<A HREF="mailto:fostel@eos.ncsu.edu">
fostel@eos.ncsu.edu
</A>&gt;
</address>
<i>
Mon, 17 Sep 90 15:19:38 EDT
</i><PRE>

   As an old alum of both the MIT undergrad computer science program and an early
   version of Liskov's software engineering course, my eye's perked up  when I
   saw Ts'o rip it assunder in the course of analyzing the need for "software
   certification".  I also teach an  undergrad course on software engineering
   here at NCSU, and perhaps that somewhat colors my perspective.

   Although the title of the post by Ts'o was "software certification" the subject
   matter seemed to be more focused on "programmer certification".  While I share
   much of the trepidation that motivates Ts'o, my concerns are somewhat different.
   An analogy might help.  In the construction industry, there are a number of 
   different classifications of individuals by their training, function, experience
   and so on.  Two that are well understood are "architect" and "master carpenter".
   To some degree, an architect can generally do many of the things a master
   carpenter can do, and vice versa, and to some degree, each probably thinks
   that their own slant on the problems of construction cuts to the core of the
   "real" problems in construction.

   But, is the distinction between the two one which is unwise and a danger to the
   building industry and more generally to society at large?  Clearly No.  It may,
   however, be a danger to a skilled carpenter who wishes to move into the domain
   typically populated by architects.  Even though that carpenter may in fact have
   talent and experience which is superior to many architects, it is not in the
   interest of society to freely allow such fluidity in job descriptions and job
   certifications.   Conversely, the architect may find their actions on a job site
   to be limited by lack of certification as a carpenter. (My brother is an
   architect and this is a very frustrating problem for him at times.)  

   The reason for the limitation of the roles of the architect and the carpenter
   is the underlying assumption that without an individual going thru a certain
   process of training and examination, that individual can not quite be trusted
   to perform certain actions that could bring risk to the public as a result of
   an error made in that capacity.

   Precisely the same sorts of reasons can be used to justify the existence of
   certified skills within the domain of software engineering, and no doubt it is
   only a matter of time until this is done.  Ts'o is concerned that this will
   lead to a limitation of an individuals ability to work on certain projects and
   of course this is precisely the intent.  

   Perhaps Ts'o would be more content with this arrangement if the prevailing
   trend in software engineering were towards the flamboyant and powerful style
   of development at which he is no doubt quite expert.  After all, in this way
   he could be more confident that the software controlling the 747 he flew in 
   or the nuclear powerplant he lived near, was not built in a plodding fashion
   by people who believed in flowcharts and pseudo-code, or by people who bothered
   to design a system before they began to build it, or by people who had their
   designs validated by independent experts before wiring potentially erronious
   assumptions into hundreds of thousands or millions of lines of code.

   I would have little fear of living in a house hammered together by my brother
   the architect, nor would I be concerned if Norm the carpenter (From PBS This
   old house series) designed the layout for my house.  But I'd not set foot in 
   a 50 story building built without consultations from CERTIFIED structural
   engieers, with blueprints thouroughly reviewed by CERTFIED architects, and 
   construction performed by professional, CERTFIED contractors.  The issue
   is scale. 

   I trust Ts'o or most other competant programmers to develop a simple data base
   program, word processor, compiler, or a host of other applications programs.
   (Though I might not trust them with my capital without a track record as
   "certified moneymakers".)  But large, complex software systems have
   problems that are not readily visible in the small scale applications.
  
   In my software developement courses, I commonly tell students that the methods
   which will be required of them are not necessarily the most efficient methods
   for the class project required of them.  For the trivial sort of work
   I can require of students in a semester, there is really no need for comments
   since they will remember everything all the time, and there is no need for
   requirements analysis since they will usually be both customer and producer,
   and there is no need for formal design since they must begin work on the code
   before I have a chance to provide formal feedback on their formal design, 
   and so on for most of the techniques of software engineering.  

   On the other hand, as the size of the problem grows, and the customer becomes
   distinct from the development, and the development staff becomes fluid, and
   the effort expands in numerous other dimensions towards bewildering complexity,
   the methods I prescribe are in fact neccesary...but that must be taken as an
   article of faith.  There is no way for students to actually participate in
   a 5 year development of million line system in a few months of class time.
   It's unfortunate that more students, esp the bright and energentic ones like
   Ts'o, do not understand that. Perhaps equally, it is unfortunate that the 
   professors, like Liskov, do not find ways to make these students understand it. 

   Will programmers be certified?  Definitely.
  
   How will they be certified? By the processes and standards used by the leaders
   of the industry when certification finally becomes inescapable.

   When will certification begin?  Probably shortly after a disaster involving 
   software that was not up to snuff and was produced in questionable fashion.

   Will it be a source of frustration to software developers?  Of course.

   Will it make the public safer?  Hopefully.

Gary Fostel, Dept of Computer Science, North Carolina State University, Raleigh,
NC, 27695-8206            fostel@eos.ncsu.edu              919-737-3195  

</PRE>
<HR><H3><A NAME="subj1.7">
Re: The need for software certification
</A>
</H3>
<address>
Theodore Ts'o 
&lt;<A HREF="mailto:tytso@ATHENA.MIT.EDU">
tytso@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 14 Sep 90 13:56:55 -0400
</i><PRE>

&gt;Surprisingly, version control (such as RCS) was never discussed at all.
&gt;I suppose the theory was that if we designed everything in pseudo-code
&gt;from scratch, we would never need to rewrite or revise any of it, so
&gt;version control was considered important.  I will leave it to the Gentle
		    v
		   not
&gt;Reader's judgement as to whether or not you can teach a reasonable
&gt;Software Engineering in today's environment, when several people can be
&gt;changing files on a networked filesystem, without at least mentioning
&gt;version control. 

Err.... oops.  I should have proofread this a bit better.  The sentence makes a
lot more sense with the negation in there.....  Sorry about that!
                        					     - Ted
</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-15</DOCNO>
<DOCOLDNO>IA013-000136-B029-244</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.42.html 128.240.150.127 19970217040154 text/html 33290
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:00:19 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 42</TITLE>
<LINK REL="Prev" HREF="/Risks/10.41.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.43.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 42</H1>
<H2> Saturday 22 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Arbitration Myths 
</A>
<DD>
<A HREF="#subj1.1">
Peter Denning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Security compromise with SUN's C2 package 
</A>
<DD>
<A HREF="#subj2.1">
Li Gong
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Expert system in the loop    
</A>
<DD>
<A HREF="#subj3.1">
Henry Spencer
</A><br>
<A HREF="#subj3.2">
 Henry Spencer
</A><br>
<A HREF="#subj3.3">
 Steven Philipson
</A><br>
<A HREF="#subj3.4">
 Steven Philipson
</A><br>
<A HREF="#subj3.5">
 Walt Thode
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Railway Safe Working - large analogue systems 
</A>
<DD>
<A HREF="#subj4.1">
Peter Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: I'm 99% Sure You're A Crook!!! 
</A>
<DD>
<A HREF="#subj5.1">
Jerry Hollombe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Book suggestion: Apollo, The Race to the Moon 
</A>
<DD>
<A HREF="#subj6.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Knight reference: `Shapes of bugs' 
</A>
<DD>
<A HREF="#subj7.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  ACM Conference on Critical Issues in Computing 
</A>
<DD>
<A HREF="#subj8.1">
Harold S. Stone
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Arbitration Myths
</A>
</H3>
<address>
Peter Denning 
&lt;<A HREF="mailto:pjd@riacs.edu">
pjd@riacs.edu
</A>&gt;
</address>
<i>
Tue, 18 Sep 90 15:20:25 PDT
</i><PRE>

In RISKS-10.3 of 13 Sept 1990 David Murphy says, "It is completely impossible
to build a fair arbiter or synchroniser."  He also says, "... any digital
design technique is just a way of improving engineering confidence in the
product, not of guaranteeing correctness."  These statements are not true.  I
hear them repeated frequently enough that I surmise they are part of the
folklore.  I write here with an antidote.

First, a definition: An arbiter is a device that selects exactly one out of a
set of requests represented as signals on input channels.  The arbiter must
work even if two or more of its inputs can change simultaneously.  This
behavior is considered "fair" since it does not give preference to any one
input.  Arbiters are used at the ports of memory modules, in the nodes of
interconnection networks, and in interrupt systems.  It is easy to build such
circuits.

The fundamental theorem of arbiters is: There is no fixed time bound for the
arbiter to make its choice.  The reason is that if two inputs change
simultaneously, the device can enter a metastable state from which it will exit
after a random amount of time (to be precise, the probability that the circuit
persists in the metastable state for more than t seconds is exp(-t/A), where A
is the mean switching time of the circuit).  If we as RISKS readers demand that
every arbitration be performed correctly, we must use asynchronous circuits
that will wait until an arbiter has settled.  These circuits are provably free
of synchronization errors.

But if we build an arbiter into a computer that assumes a fixed time for an
arbiter to reach every decision, there is a chance that the arbiter will not be
settled down and the half-signals at the arbiter's output may cause a
malfunction in the rest of the computer.  Although the probability of this
failure might seem small, failures every few days become very likely at the
clock speeds of modern computers.  If you are interested in reading more about
this, you can take a look at my American Scientist article (1985) and also
Chuck Seitz's chapter in the Mead and Conway book (1980).

Another common misunderstanding about arbitration concerns the lowest level at
which an indivisible operation must be implemented.  Dijkstra's solution to a
concurrent programming problem (1965) was a software arbiter that relied on the
existence of arbitration in the memory addressing circuits for individual
memory locations.  Lamport showed how to achieve fair mutual exclusion without
any requirement that references to memory cells are arbitrated (1974).

Conclusion: we know how to build fair arbiters and how to design
circuits that are free of synchronization errors.

READINGS

C. L. Seitz, Chapter 7, "System Timing," in Introduction to VLSI Systems, by C.
Mead and L. Conway, Addison-Wesley, 1980.

P. J. Denning, "The Arbitration Problem", American Scientist (Nov-Dec 1985).

L. Lamport, "A new solution of Dijkstra's concurrent programming problem",
Communications of ACM (August 1974), 453-455.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Security compromise with SUN's C2 package (Jalali, Risks-10.39)
</A>
</H3>
<address>
Li Gong
&lt;<A HREF="mailto:li@diomedes.UUCP ">
li@diomedes.UUCP 
</A>&gt;
</address>
<i>
Tue, 18 Sep 90 17:24:03 EDT
</i><PRE>

A related point: the C2 design still allows an intruder to guess user passwords
even if rpc.pwdauthd is not present.  Everyone has a pair of public keys for
authentication, RPC, and the like (public key K+ and corresponding secret key
K-).  In file /etc/publickey which is readable to anybody, there stored (among
other things)

   [user_name, K+, E(p, K-)]

where E(p, K-) is K- encrypted with key p (generated from user password) under
DES.  An intruder can download this file, guess a p' and decrypt the last item
with it to get a K-'.  Then he can choose any text X and verify 
D(K-', E(K+, X)) = X, where D is decryption.  If the above holds, he is quite
certain that p' is the correct password.

This kind of attack is called Verifiable-Text Attacks (see my paper in
Proceedings of Infocom '90, June).  It can be conducted off-line, then
you have to use your own CPU of course.

Li GONG,      Odyssey Research Associates, Inc.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Expert system in the loop (Philipson, <A HREF="/Risks/10.38.html">RISKS-10.38</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 13:44:13 EDT
</i><PRE>

&gt;In the case of the Vincennes, it cannot be disputed that a mistake
&gt;was made.  The Pentagon found no human responsible for it, so it
&gt;must have been a mechanical error...

I fear Clifford is departing a bit from his usual standards of objectivity and
precision, here, and the distinctions are important.  Was a mistake made?
Clearly, yes, since there was no need to shoot down a civilian airliner.  Was
it a *preventable* mistake?  Now this is a harder question, as is the question
of who should have been responsible for preventing it.  (My vote goes to the
airline and/or pilot who decided to fly an airliner through a combat zone.)  If
I'm not mistaken, the Pentagon's finding was not that nobody was responsible
for the mistake, but that no *blame* was attached to the captain and crew as a
result of it, i.e. their decision was reasonable in the circumstances and no
disciplinary action was in order.  Whether or not this finding was correct, the
general point stands: one should beware of the assumption that there *must* be
a villain, that either some human must be guilty or there must have been a
mechanical failure.

The Vincennes disaster could have been averted if the airliner had followed a
safer route, if the Vincennes had not been in combat (and hence inclined to
treat potential threats as real ones) at the time, if the captain and crew had
been trained to be more skeptical of the computerized reports and more thorough
about cross-checking them, or if the equipment and software had been better
designed.  Which of these is the villain?

(Actually, I agree with Clifford's main point, that meaningful human
decision-making requires sufficient time and adequate independent sources of
information.  It's not clear to me that the Vincennes case is a good example of
total lack of same, however, so much as a case of how conflicting or
doubt-casting evidence gets ignored in a crisis.)

Henry Spencer at U of Toronto Zoology henry@zoo.toronto.edu utzoo!henry

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Expert system in the loop (Philipson, <A HREF="/Risks/10.38.html">RISKS-10.38</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 14:10:23 EDT
</i><PRE>

&gt;... Military personnel have, by joining or
&gt;accepting induction into armed service, accepted certain risks. 
&gt;Civilians have not.  If there is any doubt whatsoever that the
&gt;approaching plane was hostile, the Captain should have decided not to
&gt;destroy it, accepting the risk of outcome #3, i.e., that his ship might
&gt;come under attack ...  He and his crew signed up for that risk...

One should remember that soldiers are not policemen.  Policemen generally
are required to accept risks themselves rather than passing them on to
civilians; their *job* is reducing civilian risks.  The military are not
in quite the same situation.  Their job is to carry out the policies of
their government, and if innocent people get hurt, that is the policy-
makers' problem.  Military actions often involve injury or death to
innocent civilians, and avoiding this entirely is probably impossible,
although minimizing it is usually desirable.  The captain and crew of
the Vincennes signed up to risk their lives in protecting the United States
(and its allies and interests), not in protecting civilians in general.

&gt;... The passengers of the airliner had accepted no such risk...

Their government had accepted it on their behalf, by initiating warfare
against foreign vessels, for what it presumably considered adequate reason.
Governments in general feel that they have a right to risk the lives of
their citizens -- without their individual consent -- for sufficient cause.
 
Henry Spencer at U of Toronto Zoology henry@zoo.toronto.edu utzoo!henry

</PRE>
<HR><H3><A NAME="subj3.3">
expert systems in battle (Cliff Johnson, <A HREF="/Risks/10.39.html">RISKS-10.39</A>)
</A>
</H3>
<address>
Steven Philipson
&lt;<A HREF="mailto:stevenp@decwrl.dec.com ">
stevenp@decwrl.dec.com 
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 15:43:55 -0700
</i><PRE>

In <A HREF="/Risks/10.39.html">RISKS-10.39</A> "Clifford Johnson" &lt;GA.CJJ@Forsythe.Stanford.EDU&gt;
   writes a response to my post on expert systems.

   First, I request that more care be exercised in the use of quotations.
The excerpt that Clifford used appears to be attributed to me (through
the use of a single greater-than sign) when the excerpt was one that I
was quoting from someone else.  The usage in this article will be a "&gt;"
in the first column to denote quoted material.

&gt;In the case of the Vincennes, it cannot be disputed that a mistake
&gt;was made.  The Pentagon found no human responsible for it, so it
&gt;must have been a mechanical error.

   This statement is in error.  Please, READ THE REPORT.  Human error on the
part of two officers was specifically cited, and inadequacies with the systems
were noted.  An error was made by a junior officer in reading both the altitude
and speed of the approaching aircraft.  Error was also attributed to a senior
officer for not confirming the data on his own by checking his own displays.
The board also found that inadequacies in the design of the display increased
the probability for misinterpretation of data under the stress of battle.  The
board found that Captain Rogers made a correct decision to fire based on the
data that he had available to him.

&gt;The assertion that humans have
&gt;time to meaningfully evaluate the computers' information in a few
&gt;minutes is patent nonsense (as proven by the Vincennes)

   I never made that assertion, nor do I hold that it can be done.  In my
previous post I wrote "All this may not be possible to do in practice".
Indeed, it is not reasonable to expect that large bodies of data and rules of
reasoning can be evaluated by a human being within a few seconds.  On the other
hand, the raw data cannot be assessed by a human in that time frame either.
Some amount of processing is going to be done by machine.  A decision as to how
much should be done must be made at some point.  In the case of the Vincennes,
only minimal processing was performed, and the radar data was presented fairly
simply -- as a course and altitude readout.  Even that was misinterpreted under
the stress of battle.

   One must also consider that not all battlefield decisions are made on a time
frame of seconds or even minutes.  Assessments of the enemy's intentions often
occur over periods of days and weeks.  An expert system that finds evidence of
significant activity and reports it could be of great value to commanders if
the time frame is long enough to evaluate those decisions and actions.

&gt;- all humans can do is to *gamble* whether the computers (or their readings
&gt;of the computers' consoles) are right, and so they act as no more nor
&gt;less than randomizing agencies - 

   In a sense, that is correct -- they do gamble that the machines are right,
but we do this every day in all forms of endeavor.  When I drive my car, I
gamble that my speedometer is close to correct, and that by following it I will
avoid getting a speeding ticket.  The gamble is a good one as I have a sense
that the probability of it being correct is high, although it could be wrong
(and has been on occasion).  Likewise, one "gambles" on the correct performance
from more complex systems, but these bets are far from random.  The key point
here is that a computer system does not have to be perfect to be useful, even
when used in critical applications.

&gt;Such decisionmaking is de facto *governed* by computer: without
&gt;computer prompts, no retaliatory decision at all would be taken;

   Again, incorrect.  Decisions to fire were made long before we had computers
-- they are not required to make these decisions.  Data collected by human
observers can be and is interpreted incorrectly as well.  In addition, use of a
computer system does not preclude the consideration of other data points.
Friendly and/or non-hostile craft have been destroyed in the past in cases
where there was no computer involved.  By the way, the use of the word
"retaliatory" is incorrect here.  The decision to fire in this circumstance is
not an act of revenge, but rather of self protection.

   It is a hard reality that decisions must sometimes be made in the midst of
chaos, with few or unreliable data points.  The presence of computers does not
change this.  Computer systems have been involved in cases where the outcome
was not as desired.  There have also been many cases where similar mistakes
were made without the use of computer systems.  The banishment of computers
from critical systems will not stop such the occurrence of such errors.

</PRE>
<HR><H3><A NAME="subj3.4">
expert systems in battle (Jeff Johnson, <A HREF="/Risks/10.39.html">RISKS-10.39</A>)
</A>
</H3>
<address>
Steven Philipson
&lt;<A HREF="mailto:stevenp@decwrl.dec.com ">
stevenp@decwrl.dec.com 
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 15:43:55 -0700
</i><PRE>

Jeff Johnson &lt;jjohnson@hpljaj.hpl.hp.com&gt; writes:

&gt;The captain of the Vincennes was faced with a decision that had four
&gt;possible outcomes:

&gt;  1. Destroy approaching plane; plane is hostile (CORRECT OUTCOME)
&gt;  2. Destroy approaching plane; plane is not hostile (ERRONEOUS OUTCOME)
&gt;  3. Don't destroy approaching plane; plane is hostile (ERRONEOUS OUTCOME)
&gt;  4. Don't destroy approaching plane; plane is not hostile (CORRECT 
&gt;     OUTCOME)

   This is an interesting set of rules, but it does not reflect the rules that
were in use in the Gulf.  The above rules assume certainty in the
identification of aircraft.  Actual rules are based on probable identification.

   This can be seen directly in the transcripts from the Vincennes, where crew
members used terms such as "probable hostile" and "possible comm-air".  The
captain of the Vincennes had a primary responsibility to protect his ship.  In
this case, given a "probable hostile" aircraft on a probable attack profile,
the correct decision is to fire.  What's more, the destruction of a non-hostile
aircraft is NOT an erroneous outcome.  This isn't to say that it isn't a
terrible tragedy -- it is.  It is however, a correct action given the military
doctrine in use.

   US fighter pilots in World War II made a point of staying well clear of ALL
ships (not just enemy vessels) as they were likely to be fired upon if they got
too close.  The pilots knew that the rule of operation for the ships was
"better to shoot down a friendly aircraft in error than to lose a ship".  The
captain of the Vincennes was operating by the same rule.  This was a major
factor in his being found to have made the correct firing decision.  Whether
this value judgment is a good one or not is a completely different question.

&gt;  Military personnel have, by joining or accepting induction into 
&gt; armed service, accepted certain risks. Civilians have not.  If there
&gt; is any doubt whatsoever that the approaching plane was hostile, the
&gt; Captain should have decided not to destroy it, accepting the risk of
&gt; outcome #3, i.e., that his ship might come under attack (Note:  not
&gt; even necessarily that his ship or crew would sustain any injuries).

   These are reasonable statements, but irrelevant.  We can argue about what
the rules of engagement should have been, and even whether either US warships
or civilian traffic should have been there at all, but that will not change the
situation that occurred nor rules that were in effect.  The rules did not state
"fire only if *sure* of hostile intent", but rather "US warships will fire to
protect themselves if threatened".  Part of the reason for this is that the US
had already suffered casualties in the Gulf in the case of the Stark.  The
board of inquiry found that the captain acted in accordance with the rules and
his orders.

   I heartily recommend that all persons who are concerned with the issues of
computer systems in critical applications read the Vincennes report.  Many
insights can be gained through examination of the performance of both humans
and machines.  There is much of value here for those who design systems,
whether they include humans, computers, or both.

</PRE>
<HR><H3><A NAME="subj3.5">
Re: Expert system in the loop (Whose fault was the Vincennes...?)
</A>
</H3>
<address>
Walt Thode
&lt;<A HREF="mailto:thode@nprdc.navy.mil ">
thode@nprdc.navy.mil 
</A>&gt;
</address>
<i>
20 September 1990 1316-PDT (Thursday)
</i><PRE>

There seems to be a fair amount of interest about who is to blame for the
mistaken destruction by the USS Vincennes of a civilian airliner.  There are
various points of view.

Clifford Johnson (in <A HREF="/Risks/10.39.html">RISKS-10.39</A>) suggests that 
&gt;                         (...) it cannot be disputed that a mistake
&gt; was made.  The Pentagon found no human responsible for it, so it
&gt; must have been a mechanical error.  (Recently, Captain Rogers was
&gt; awarded a special medal of honor for his courage in commanding the
&gt; Vincennes through the shootdown.)

I hope he meant the above with considerable tongue in cheek.  Suggesting that
the Pentagon's findings in a controversial case like this would be altruistic
is naive at best.  A possible indicator of the Pentagon's actual response is
that Capt. Rogers, despite his impressive credentials up to the time of this
tragedy, is now unlikely to be promoted to the Flag rank (Admiral) that was
probably a foregone conclusion before this incident.  (This is not necessarily
a logical decision, however; the Navy tends to sidetrack any career that
becomes besmirched with controversy or scandal, and the Captain is always
responsible for the events in his command, even when he in fact often may have
little control.)

Johnson's further comment is right on:
&gt;                                      The assertion that humans have
&gt; time to meaningfully evaluate the computers' information in a few
&gt; minutes is patent nonsense (as proven by the Vincennes) - all
&gt; humans can do is to *gamble* whether the computers (or their readings
&gt; of the computers' consoles) are right, and so they act as no more nor
&gt; less than randomizing agencies - i.e. one would get the same level
&gt; of "judgment" by card shuffling.

An important issue here is not mentioned.  Systems are designed by people, and
often people do not design man-machine interfaces very well.  The interface
should maximize the chances of making a good decision in a case like this, and
should minimize the chances of making a bad one.  It's often the case that
systems are designed, developed, and fielded with poor man-machine interfaces.
(I don't have extensive knowledge of the AEGIS or other Vincennes systems, so
I'm not in a position to judge them in particular.)  I suspect that there is
much to yet be learned about what comprises a good man-machine interface in
instances like this one.

--Walt Thode   thode@nprdc.navy.mil   {everywhere_else}!ucsd!nprdc!thode

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Railway Safe Working - large analogue systems (skill, <A HREF="/Risks/10.36.html">RISKS-10.36</A>)
</A>
</H3>
<address>
Peter Jones 
&lt;<A HREF="mailto:MAINT@UQAM.bitnet">
MAINT@UQAM.bitnet
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 15:28:56 EDT
</i><PRE>

&gt;outside the train (by climbing down to the trip and manually resetting it).

In the Canadian climate, this would introduce a risk of the driver slipping and
falling in conditions of snow, ice or sleet. Not a procedure to be taken
lightly.

&gt;...   signal box interlocks are implemented by requiring two largish pieces of
&gt;metal to occupy the same space for conflicting events to occur. The only
&gt;failure mode here is severe deformation of the metal rods.

Or a failure in the linkage to the signal.

&gt;                                    These drop in sequence at a rate which
&gt;reduces the train speed to around 20 km/h.

I think the elevated in Chicago has (or had in 1970) a system like this to
regulate train speed at an 'S' bend around 39th South. A train would encounter
a red at the the start of the 'S', which would change to yellow as the train
arrived. Then, there was a series of signals that would change from red to
yellow as the train proceeded slowly through the 'S'.  Speed control appeared
to be done manually under the driver's control.

&gt;long distance diesels have a vigilance button which must be pressed every
&gt;sixty seconds to keep the brakes off. It's a good thing that brakes are
&gt;applied automatically because it is commonly believed that old hands can press 
&gt;this button even when sleeping. I've observed the automaton-like way that 
&gt;drivers press this button and I have no doubt that it happens.

In 1968, I saw a film of the SNCF (French Rail) workers explaining their
dead-man system. Originally, it was a kind of steering wheel that had to
be held up. When the SNCF discovered the drivers were holding it up with
a piece of string, they changed the system so the driver had to raise the
steering wheel every 20 seconds. Drivers found this exhausting. I'm
wondering if a less obtrusive system couldn't be used. Maybe a throttle
with a light feel but requiring almost continuous holding. The safety
system would detect the natural "dither" of the driver's hand.

I'm also surprised at the number of cars fitted with cruise control, and
NO vigilance system. Some drivers, to avoid the hassle of re-engaging the
cruise control, allow themselves to almost plough into the next vehicle,
rather that reduce speed slightly. Many controls will maintain the
preset speed, but seem to lack a throttle-like means of reducing speed
by say 5-10 kph.

&gt;Mind you, it all seems very safe compared to Canada where express passenger
&gt;trains are managed using CTC and walkie-talkie radios. I've seen passenger

The Mulroney government seems to be using a probabilistic approach: make
accidents less likely by cutting back drastically on the number of
passenger trains :-)

Peter Jones  UUCP: ...psuvax1!uqam.bitnet!maint (514)-987-3542

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: I'm 99% Sure You're A Crook!!! (mmm, <A HREF="/Risks/10.39.html">RISKS-10.39</A>)
</A>
</H3>
<address>
The Polymath
&lt;<A HREF="mailto:hollombe@ttidca.tti.com ">
hollombe@ttidca.tti.com 
</A>&gt;
</address>
<i>
19 Sep 90 23:43:48 GMT
</i><PRE>

}[To me, it seems like there is quite a range of quality in the machines used
}to verify my credit.  Some are solid-looking hardware from NCR or IBM with
}expensive keyswitches and plasma displays.  Others are cheapo stuff with LED
}displays and calculator-style keypads.  I guess PW went with the system from\
}Ma &amp; Pa Kettle POS Systems.  mmm]

This is more a marketing risk than a computer risk, but still something to
consider. "Solid-looking hardware" with apparently expensive switches and
displays may well mask shoddy hardware and software internals.  I've
particularly noticed this technique in electronic products from a certain
Japanese manufacturer.  Their smaller boom-boxes, for example, have slabs of
metal bolted to the inside of the plastic chassis, apparently serving no other
purpose than to give the feel of solid, heavy quality to an otherwise cheap and
mediocre piece of equipment.

With the advent of systems like NeXT that make the building of impressive
graphic user interfaces relatively simple, we need to learn to worry about what
internal software sins those GUI's cover.

(A related risk has been around for some time: Modern word processors and
printers make rough drafts look like finished products).

The Polymath, Jerry Hollombe, Citicorp, 3100 Ocean Park Blvd., Santa Monica, CA
90405 (213) 450-9111, x2483 {csun | philabs | psivax}!ttidca!hollombe

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Book suggestion: Apollo, The Race to the Moon
</A>
</H3>
<address>
"Cheap, fast, good; choose two  19-Sep-1990 1004" 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 07:18:19 PDT
</i><PRE>

	Apollo, The Race to the Moon
	Charles Murray &amp; Catherine Bly Cox
	Simon &amp; Shuster, ISBN 0-671-61101-1

RISKS folk will probably find this book interesting: it's a history of the
Apollo project told mostly from the viewpoint of the engineers (and especially
the flight controllers and back-room support staff). It is not a history of the
astronauts.

There is a great deal of emphasis on safety issues, including second-by-second
descriptions of some of the emergencies: the launch-pad fire, the Apollo 11
landing computer overload, the Apollo 12 lightning strike, and -- especially
-- the Apollo 13 rescue.

The book is journalism, not science; so RISKS readers will have to determine
for themselves how the lessons of Apollo are applicable to their work (and how
many have been lost since the Apollo project).

I found a hard-bound edition in the remainder pile in a Cambridge (MA)
bookstore; so you might have to dig around for it.

Martin Minow				minow@bolt.enet.dec.com

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re:   Knight reference: `Shapes of bugs' (Mellor, RISK-10.40)
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@murphy.ICS.UCI.EDU">
nancy@murphy.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Tue, 18 Sep 90 12:28:11 -0700
</i><PRE>

       &gt; However, they cross-refer another paper which describes these faults:
       &gt; S.S. Brilliant, J.C. Knight, N.G. Leveson: `Analysis of faults in 
       &gt; an N-version software experiment', University of Virginia Technical 
       &gt; Report No. TR-86-20, September 1986.

This paper appeared in IEEE Trans. on Software Engineering, February, 1990.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
ACM Conference on Critical Issues in Computing
</A>
</H3>
<address>
"Harold S. Stone" 
&lt;<A HREF="mailto:HSTONE@IBM.COM">
HSTONE@IBM.COM
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 09:22:13 EDT
</i><PRE>

The ACM Conference on Critical Issues (6-7 November 1990, Hyatt Regency,
Crystal City VA) is unique in the following ways:

   It is a summit meeting.

       The attendees will include key decision makers, IS executives,
       researchers, and users.  AT&amp;T, IBM, TRW, and other Fortune
       500 companies will be represented.

   It is devoted to two important practical issues

       The critical issues are modeling reality and managing the complexity of
       large systems.

   It is a working meeting with audience participation.

       The attendees will spend one day in working together in small groups.

   It will produce an action agenda.

       The joint work of the audience will identify the
       specific problems to be attacked and who should address
       these problems.  The output will be an agenda of actions
       that could help to resolve the issues raised in the years to come.

Besides the technical speakers listed on the program, there will be a keynote
address by Dr. Gene Wong who is now on Allan Bromley's staff in the OSTP of the
White House while on leave from UC Berkeley.  I am sure that you will be
interested in his comments in regard to the government's role in setting
strategic directions in computing for the future.  The dinner speaker will be
Oliver Selfridge whose talk is entitled ``We can't go on programming like
this.''  Other speakers of note on the technical program are David Parnas, Jay
Forrester, and Stuart Dreyfus.

Program:

Modeling Reality Section

   Speakers:  Stuart Dreyfus, Jay W. Forrester, John C. Kunz, Eleanor Wynn

   Panelists: Jay David Bolter, Peter Denning

Managing Complexity Section

   Speakers:  David Parnas, Rod Leddy, Edward Chevers

   Panelists:  Robert Charette, Peter G. Neumann

       [Interested people should contact Fred Aronson at ACM HQ, 11 W 42, 
       NY NY 10036, 212-869-7440, or send mail to issues@acmvm.bitnet .]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-16</DOCNO>
<DOCOLDNO>IA013-000136-B029-283</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.43.html 128.240.150.127 19970217040212 text/html 30987
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:00:36 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 43</TITLE>
<LINK REL="Prev" HREF="/Risks/10.42.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.44.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 43</H1>
<H2> Saturday 22 September 1990  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Certification    
</A>
<DD>
<A HREF="#subj1.1">
Richard Platek
</A><br>
<A HREF="#subj1.2">
 Paul Tomblin
</A><br>
<A HREF="#subj1.3">
 John H. Whitehouse
</A><br>
<A HREF="#subj1.4">
 Alan R Kaminsky
</A><br>
<A HREF="#subj1.5">
     Russell C. Sorber
</A><br>
<A HREF="#subj1.6">
 John H. Whitehouse
</A><br>
<A HREF="#subj1.7">
 Frank Houston
</A><br>
<A HREF="#subj1.8">
 BC Tompsett
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Applicability of software curricula 
</A>
<DD>
<A HREF="#subj2.1">
Jeffrey Mogul
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Occupational Licensing (Book Review) 
</A>
<DD>
<A HREF="#subj3.1">
Tony Harminc
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
certification
</A>
</H3>
<address>
Richard Platek
&lt;<A HREF="mailto:richard@hector.UUCP ">
richard@hector.UUCP 
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 11:17:22 EDT
</i><PRE>

Considering myself a moderate Libertarian, and hence sympathetic to arguments
based on maximizing freedom and minimizing collectivistic coercion, I would
nevertheless like to champion the cause of computer professional certification.
Certification is not meant to protect us from MIT students like Mr. Ts'o.  The
truth of the matter is that the vast majority of people building computer based
systems would never be admitted to schools anywhere as discriminating as MIT (I
am MIT Class of 61, along with John Sununu, and very proud of it).  People
aren't allowed to drive cars on the road without being "certified" yet they are
allowed to program systems whose failure could be more catastrophic than poor
driving ability.  Demanding proof of road worthiness of drivers and cars is not
an abridgment of individual liberty; it is the entry fee for participating in a
social process.  I am as Libertarian as can be but I want the driver coming at
me at 60 mph to be licensed and I want the person doing the air traffic
controller software used to land my plane to be certified.  Certification need
not be s government function. The remarks that certification would lead to a
guild do not sound negative to my ears.  Guilds guaranteed the craftsmanship of
their members.  Certification needn't restrict creativity.  It just shows one
can pass some minimum requirements criteria.  I go to homeopathic doctors who
use very non-standard forms of medicine.  Yet they all have been trained and
certified in standard medicine.  Although, I avoid standard medicine I feel
more comfortable that the doctors I do go to have satisified all the
requirements which the medical establishment has set for itself.

</PRE>
<HR><H3><A NAME="subj1.2">
Re: The need for software certification
</A>
</H3>
<address>
Paul Tomblin
&lt;<A HREF="mailto:pt@geovision.UUCP ">
pt@geovision.UUCP 
</A>&gt;
</address>
<i>
Tue, 18 Sep 1990 10:25:31 -0400
</i><PRE>

Theodore Ts'o &lt;tytso@ATHENA.MIT.EDU&gt; writes:

&gt;I am against the "certifying" of software professionals.  My objections fall
&gt;basically into two areas.  The first is that there is no valid way to measure
&gt;software "competence".  How do you do it?  There are many different software
&gt;methodolgies out there, all with their own adherents --- trying to figure out
&gt;which ones of them are ``correct'' usually results in a religious war.
[some very valid points about different approaches deleted]

&gt;The second general objection that I have against the certification of
&gt;software professionals is that it might very well become a guild.  In my
&gt;mind, there is great danger that once you have the people who are
&gt;``IN'', they will try to maintain a competitive advantage and keep most
&gt;other people ``OUT''.  Mr. Whitehouse has already granted that a college
&gt;degree cannot be used to discriminate those who can program well against
&gt;those who do not program well...

&gt;Worst yet, it could become like many unions today, and be used to protect
&gt;mediocrity within the group against people who are actually better qualified,
&gt;but who aren't in the appropriate magic group...

You just have to look at professional engineering practice to see that this
doesn't need to happen.  I was a professional engineer, but I choose to make
my living in software, because I'm better at it.  Engineering
(especially Civil Engineering) is very similar to how I see the future 
of software developers certification because of the following:

    1   Engineers are self regulating:  Only a _panel_ of
        engineers is fit to judge if another engineer is
        incompetent or guilty of professional malpractice.
        
    2   Engineers are by and large employees, rather than self
        employed like doctors or lawyers.
        
    3   Engineering has scope for many different approaches to the
        same problem.  A University of Waterloo grad will probably
        take a different approach to a problem than a UofToronto
        grad.  They will both come up with valid solutions to the
        problem, within the limits of human falibility.
        
    4   A failure of an Engineering design can be life critical,
        but as long as you followed _any_ valid design
        methodology, you will probably not be guilty of
        malpractice in the event of a failure.

Engineering is not an exclusive domain.  Anybody who passes an engineering
course, works two years in the field, and passes an ethics exam can become one.
If you don't take an engineering course, you can still become one after working
6 years and taking several exams.  My father did it that way, so I know it's
possible.  You also have to get another engineer, a co worker or supervisor to
co-sign your application.  The purpose of all this is not to restrict
membership, but just to show that you are capable of doing the work you are
being certified for.

As a Professional Engineer, I was subject to the rules of the Association of
Professional Engineers of Ontario (APEO), which has a Code of Ethics.  I was
also bound by the "Ritual of the Calling of an Engineer" (the Iron Ring).  The
"Ritual" has no legal status, but was created by Rudyard Kipling before there
was a legal status for Engineers.  Both of these were designed to stress to an
Engineer his duty, but there is an important line in the Obligation, which is
part of the "Ritual":

    For my _assured_ failures and derelictions, I ask pardon
    beforehand of my betters and my equals in my calling...
    
So we admit that everyone fails at some time, and we aren't going to crucify you
if you screw up, providing you did so honestly, and not because you were lazy or
unprofessional.

Disclaimer: I don't speak for the APEO, and I'm not a member any more, so things
may have changed.

Paul Tomblin, Department of Redundancy Department.
nrcaer!cognos!geovision!pt or uunet!geovision!pt  

</PRE>
<HR><H3><A NAME="subj1.3">
Certification
</A>
</H3>
<address>
John H. Whitehouse
&lt;<A HREF="mailto:al357@cleveland.freenet.edu ">
al357@cleveland.freenet.edu 
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 08:03:09 -0400
</i><PRE>

This is a reply to Mr. Ts'o's posting in which he stated that he feared that
professional certification might lead to development of a guild mentality in
which those who are certified make the test as difficult as possible; he stated
that the free market should be left to weed out incompetency.
 
The ICCP takes great pains to prevent development of a guild mentality.  We
certainly wouldn't like to see something like white Mark Twain described in his
book, Life on the Mississippi; there. the riverboat pilots formed just such a
guild.  On the other hand, the ICCP takes great care in construction of its
tests.  Although the test items are written by those who currently hold
certificates, they are reviewed by a committee.  The committee verifies that
the item is correct, has only one clear answer and is not a "trick" question.
A proportion of the item pool is retired each year and some of these new items
are allowed to enter the test.  The weighting of questions on a well-publicized
outline is maintained to see that the distribution of items conforms with the
outline in the study guide.  Psychometricians evaluate each test and each item
after the fact of test administration.  They maintain careful surveillance over
reliability, validity and difficulty level.  The difficulty levels have not
changed in any consistent direction since 1962.  The pass ratio remains at
about 30 percent.

I don't understand how Mr. Ts'o's fears development of a guild mentality when
certification is and has been voluntary.

His belief that the free market should correct the problem of incompetence has
not proven itself in practice.  For the last nine years, I have been a CICS
software diagnostician.  I can say that almost every error that I have seen has
been the product of an incompetent programmer.  Some of these errors have cost
the programmers' employers upwards of $ 20,000 per incident.  No one gets
reprimanded or fired.  I recently asked a classroom full of candidate
instructors for a class on CICS Problem Determination methodology why so many
CICS programmers are flatly incompetent.  These instructors said, as if in one
voice, that the problem is due to the fact that few universities teach CICS.
The problem seems due to an inability to apply what people are taught in
school.  It is one thing to answer objective and essay questions correctly and
yet another thing to apply it in practice.  The free market fails in mid-range
and large mainframe business environments because the managers are
non-technical and we run software that people never saw in school.  The demand
for warm bodies exceeds the supply of capable people.  Because of this, the
free market cannot resolve the problem.
 
Mr. Ts'o's fails to see the problem.  I warned of this sort of reaction in my
posting a few days ago.  I do not believe that this problem surfaces in
academic environments and Mr. Ts'o's (at MIT, project Athena) is in just such
an environment.  I am more interested in seeing the reaction of business
systems people to the problem which I describe.  There, the managers will
seldom see the problem and the better practitioners will tend to agree with my
contentions.

</PRE>
<HR><H3><A NAME="subj1.4">
Certification of Software Professionals
</A>
</H3>
<address>
Kaminsky Alan R
&lt;<A HREF="mailto:ark@cs.rit.edu ">
ark@cs.rit.edu 
</A>&gt;
</address>
<i>
Wed, 19 Sep 90 11:08:00 EDT
</i><PRE>

Should there be certification of software professionals?  YES, ABSOLUTELY!

It's long past time for software development to be considered an engineering
discipline, and for software developers to consider themselves engineers.
I say this for two reasons:  (1) Like other engineering disciplines, we now
have formal and semiformal methods for carrying out all aspects of software
development--specification methods, design methods, test planning methods,
software reliability models.  Our methods are now just as mathematically
grounded as methods in other engineering disciplines.  We CAN be engineers.
(2) Like other engineering disciplines, we are engaged in constructing
artifacts that the public use and that affect the public's safety.  Other
engineers design and build roads, railroads, bridges, skyscrapers, nuclear
power plants, airplane fuselages.  We design and build nuclear power plant
controllers, airplane flight controllers, railway signaling systems, and
CAD/CAM packages that other engineers use to design their artifacts.  We
SHOULD be engineers.

But if we are software engineers in the true sense of the term, we must
expect to be treated like engineers by governments and regulatory agencies.
We must undergo certification and licensing--just as civil, electrical, and
other engineers take their Professional Engineering examination and get
certified as a Licensed Professional Engineer, or whatever the procedure is
in each state.  And we must require that all software development projects
be conducted, or at least thoroughly reviewed, by a Licensed Professional
Software Engineer, who is permitted to certify that standard (software)
engineering practices have been followed, that the artifact will perform
correctly, and that the public will be safeguarded.

Should all software practitioners undergo such certification?  NO!

Not everyone who graduates with a B.S. in engineering, and who is employed
at a company to work on engineering projects, needs to become a Licensed
Professional Engineer.  So it should be with software engineering.  You
don't think you need or want to get licensed?  Fine, don't.  There'll still
be plenty of software development work for you to do.  You'll just always
be in the position of needing a Licensed Professional Software Engineer to
certify your work (once the government wakes up and starts licensing
software engineers as they should, that is).

-Alan Kaminsky, Rochester Institute of Technology, Rochester, NY

</PRE>
<HR><H3><A NAME="subj1.5">
Re: The Need for Software Certification
</A>
</H3>
<address>
Russell C. Sorber
&lt;<A HREF="mailto:sorber@motcid.UUCP  ">
sorber@motcid.UUCP  
</A>&gt;
</address>
<i>
20 Sep 90 01:50:45 GMT
</i><PRE>

&gt;   When will certification begin?  Probably shortly after a disaster involving 
&gt;   software that was not up to snuff and was produced in questionable fashion.

Voluntary certification of software professionals has been in existence for
several years. The Institute for Certification of Computer Professionals (ICCP,
Park Ridge, IL) receives support from the ACM, the IEEE, the DPMA, and several
other international computer professional organizations.  The literature of the
ICCP also bears the logo of the IEEE and ACM.

The certification involves an education requirement, an experience requirement,
passing a 5 hour, 5 part exam, and about $120 dollars in testing fees. I
vaguely remember a reduced fee for the unemployed but I'm not sure about that.
The exam is given at several dozen international locations twice per year.

I became certified when I noticed job listings requesting CDP's.  (Certified
Data Processors).  Some Chicago Board of Trade options traders seemed especialy
interested in certification.  This is understandable when you consider that
large fortunes are risked based partly (or solely) on the output of the
computer system.

I've also worked on projects (involving life and limb) where several key people
involved should have had more training or certification, but didn't.  I found
this to be a very scary experience.  (Scary enough so that I quit without other
work lined up)!  This experience convinced me that in certain cases,
certification should be mandatory.

Nurses, physicians, pilots, civil engineers, (even hair stylists!), are all
licensed.  Wouldn't you want the electronic instrument that monitors your
heart, or checks blood for Aids, or tells the pilot whether the landing gear is
down, to be built by licensed or certified professionals?

I know I would.   

Russ Sorber, CDP				Opinions are my own.
Software Contractor currently at Motorola Inc.    sorber@marble%motcid

</PRE>
<HR><H3><A NAME="subj1.6">
The need for certification
</A>
</H3>
<address>
John H. Whitehouse
&lt;<A HREF="mailto:al357@cleveland.freenet.edu ">
al357@cleveland.freenet.edu 
</A>&gt;
</address>
<i>
Thu, 20 Sep 90 08:20:38 -0400
</i><PRE>

After reading yesterday's postings, I thought it necessary to reply to a few
other concerns which I have noted running throughout the various postings
concerning this subject.
 
There is a concern that ICCP certification assesses examinee philosophy.  This
is generally untrue.  For the most part, the exams test definition and
recognition at a very basic level.  Some of the specialty exams go deeper, down
to ability to use a concept, but not to the level of philosophy.  It is truly
amazing that only 30 % are able to pass these exams and that only serves to
emphasize the severity of the ignorance problem.  I wish to emphasize that
philosophy is NOT tested and that the exams try very hard to avoid anything
over which there may be controversy.
 
Second, I note that much of the opposition argument is founded upon nothing but
fear.  This is fear of the unknown because it is clear that those who wrote
those postings were not familiar with ICCP certification.  My thanks to those
who have indicated that they have also seen this underlying thread.  I also
appreciate remarks to the effect that the opponents could make the same
argument concerning CPAs, PEs and doctors.
 
Two other points: ethics and continuing education.  These are two other
properties of ICCP certification.  I am aware that the professional
associations have codes of ethics, but will they kick you out for violation ?
The ICCP code of ethics is stricter than that of either ACM or DPMA and the
ICCP has revoked six or seven certificates in its history.  We are in an age of
viruses, hackers and white collar crime.  I would think that prospective
employers would view the ICCP ethics code in a most favorable light.
 
It has been said that the half life of knowledge in our field is three years.
The ICCP requires 120 hours of continuing education every three years.  Would
anyone of sane mind oppose continuing education ?  I would rather hire someone
who I knew to have kept current than someone whose continuing education status
was an unknown.
 
One added word concerning the guild mentality.  Although exam questions are
submitted by current certificate holders, they are reviewed by a committee to
assure that there is one right answer (therefore not confusing, philosophical
or controversial), then admitted to a pool of items.  Each year, about 25 % of
each exam is discarded and replaced with new items drawn from the pool.
Psychometric statistics are reviewed for any old items which are retained.
Those measures used are split-half reliability, the alpha coefficient of
reliability, a discriminant index, the Flanagan, difficulty levl and actual
counts of responses for each item.  Ther are no trick questions.  Great care is
taken to stick to the outline and to specific weightings which have been
established for outline subjects.  The difficulty level for items which have
been used before is monitored in an effort to make sure that target difficulty
levels are retained from year to year.  Those difficulty levels have carefully
been maintained at 30 % pass.

</PRE>
<HR><H3><A NAME="subj1.7">
Certification of software professionals
</A>
</H3>
<address>
Frank Houston
&lt;<A HREF="mailto:houston@itd.nrl.navy.mil ">
houston@itd.nrl.navy.mil 
</A>&gt;
</address>
<i>
Thu, 20 Sep 90 16:42:27 -0400
</i><PRE>

Being in the business of evaluating software systems and firms who develop
software systems, I read the commentaries on certification with great interest.
I have my own opinion, which I have discussed in this forum before and to which
I will refer presently; but first I want to add my fuel to the flames that Mr.
Ts'o ignited.

Mr. Ts'o tells us how he and a group of students got an "A" for a school
project while ignoring a great many software engineering techniques.  I
maintain that there are a great many differences between school projects and
"real world" projects.  In the "real world," software engineers and programmers
other than the originators must be able to understand, revise and maintain
programs readily and without resorting to "re-engineering" strategies.  I
wonder how Mr. Ts'o's group would have fared if in the middle of the course,
the instructor had introduced major changes to the program requirements AND
REQUIRED PAIRS OF WORKING GROUPS TO EXCHANGE PROJECT MATERIALS OR SCRAMBLED THE
GROUPS.  Or what if the instructor had given them a set of unclear requirements
and graded the groups on how well they elicited and met a set of "hidden"
requirements.  Like it or not, that is the way the software business really
works.

My point?  Software engineering is more than producing functional programs and
"error free" code although these abilities should be prized.  Error free code
is meaningless if it implements the wrong function on useless data.

I think some of Mr. Ts'o's criticism may be justified.  Version control is
indeed very important, but I would have criticized the course (as described) on
other grounds, which I prefer not to discuss.

As I have written before in this forum, I have a problem with certifying
individuals.  My concern is that certified people will be powerless without an
additional economic or regulatory lever.  I briefly described such a lever in
risks a year or so ago.  To summarize, I proposed not only individual
certification but also accreditation for firms and organizations that produce
"safety critical" software.  A firm could not be accredited for "safety
critical" systems unless it employed certified individuals and passed rigorous
and comprehensive periodic reviews.

Mr. Ts'o brings up another point.  He writes: 

	&gt;If required to, I can parrot back all of the ``right'' answers
	&gt;on a written exam.  Those answers would also mean very little 
	&gt;about how I really go about my programming work."

Effective certification would require individuals to do more than just pass a
written test.  As I envision it, certification would involve an apprenticeship,
like the professional EIT grade or the residency for a medical specialty.  True,
the applicant would take a test; but he or she would also need certified
professionals to attest to his or her competence (and character?).  In addition,
effective certification needs rigorous renewal criteria.  Where public and
individual safety must be ensured, I think such safeguards are reasonable.  I
would not, however, suggest that such standards apply to the writers of video
games, word processors, general purpose spread sheets, and the like.

Mr. Ts'o goes on about guilds and unions and fostering mediocrity.  Well, no
system that human beings administer will be perfect.  Mediocre engineers and
doctors get licenses.  A rational system of certification will accept the
mediocre along with the excellent.  The idea is to assure some minimum level of
competence.  Occasionally some incompetents will be certified, but certificates
can be rescinded.  Engineers and doctors can lose their licenses for a variety
of reasons including incompetence.  I do not know of any system of licensure or
certification that tries to exclude top-notch people; however, most licenses
are easier to obtain if one posesses certain credentials, such as an
appropriate college degree and some relevant experience.  I would not expect
software engineering to be any different.

Frank Houston, FDA/CDRH
(These are my personal views, the customary corporate disclaimers apply.)

</PRE>
<HR><H3><A NAME="subj1.8">
Software Engineer Certification (Risks 10.41)
</A>
</H3>
<address>
Tompsett BC 
&lt;<A HREF="mailto:bct@cs.hull.ac.uk">
bct@cs.hull.ac.uk
</A>&gt;
</address>
<i>
Fri, 21 Sep 90 12:37:05 BST
</i><PRE>

As I pointed out in Risks a while ago, the UK does have a means of certifying
Software Engineers. The British Computer Society, as the Professional Society
in the UK can accredit Engineers to the qualification of Chartered Engineer
(C.Eng). This is the same C.Eng qualification that is awarded to Structural
Engineers, Aeronautical Engineers, Nuclear Engineers et. al. It is considered
the highest professional qualification an Engineer can have. There are at
present several thousand such Chartered Engineers registered through the
British Computer Society and is a large proportion of their 30,000 plus
membership.

Brian Tompsett MBCS, C.Eng, Department of Computer Science, Hull University

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
applicability of software curricula
</A>
</H3>
<address>
Jeffrey Mogul
&lt;<A HREF="mailto:mogul@decwrl.dec.com ">
mogul@decwrl.dec.com 
</A>&gt;
</address>
<i>
20 Sep 1990 1841-PDT (Thursday)
</i><PRE>

To back up what zzz@NISC.SRI.COM (Michael J. Konopik) writes in RISKS 10.41:
    It would seem that Theodore was so intent on blocking out the Liskov
    philosophy of programming that he didn't hear the statement of the
    purpose of 6.170.  In fact, the same teaching strategy was applied in
    6.001 and 6.004, as well.  None of those classes taught their material
    using any "real world" languages or tools.

I took 6.170 (under a different number) the first time Prof. Liskov taught it,
in 1978.  At that time, the CLU compiler wasn't even available, so we had to
code in PL/1 (which reminds me of a RISKS-type story, but that is for another
day).  So, not only were we being encouraged to use what some people consider
an unrealistic language, but we then were able only to "pretend" that we were
using CLU.

In retrospect, this was an excellent experience for me.  Since then, I've
programmed almost exclusively in unsafe languages (assembler, C, Pascal,
Modula-2) but since I learned how to apply CLU-like discpline without being
able to rely on a compiler enforcing the rules, I think my code is much better
for it.  (I'll also note that many of the good skills I learned in that class
pertain to higher-level issues that could not be enforced by any compiler.)

This has nothing to do with whether software professionals should be certified;
but I believe my experience showed me that good skills can be taught, even
though some of my classmates never got the message.
                                                            -Jeff

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     Occupational Licensing  ( Book Review)
</A>
</H3>
<address>
Tony Harminc 
&lt;<A HREF="mailto:TONY@vm1.mcgill.ca">
TONY@vm1.mcgill.ca
</A>&gt;
</address>
<i>
Thu, 20 Sep 90 20:59:06 EDT
</i><PRE>

The Rule of Experts - Occupational Licensing in America.  By S. David
Young.  Cato Institute, 1987.  ISBN 0-932790-62-3 (paper).  99 pages.

"Occupational regulation has served to limit consumer choice, raise
consumer costs, increase practitioner income, limit practitioner
mobility, deprive the poor of adequate service, and restrict job
opportunities for minorities -- all without a demonstrated improvement
in quality or safety."

This is the author's thesis, and he backs it up quite well in this
very readable little book.  Young concentrates on what might be called
consumer occupations - lawyers, doctors and dentists being the most
prominent.  Did you know though, that 490 occupations are licensed
in the United States while 643 require registration ?  These range from
falconers and ferret breeders to barbers and beauticians.

Conspicuously missing from discussion is engineering, which is most
often held out as an example of the 'professionalism' that programmers
should aim for.  However the chapters  'Licensing and quality',
'Licensing and information control', 'Professionals and the scope
of practice', and 'Licensing and innovation' are highly relevant
even to such a supposedly non consumer-oriented business as programming.

&gt;From the chapter 'The Demand for Licensing':

"In the public-interest theory of licensing, regulation is introduced
for the benefit of the public at the urging of consumers or their
agents.  Government is viewed as a benevolent, if sometimes misguided,
body that seeks to maximize social welfare.  Regulations are imposed at
the urging of consumer interest groups because regulators believe,
rightly or wrongly, that efficiency or fairness or both will therefore
be enhanced."

"Critics of this hypothesis believe to the contrary, however, that
regulators' and professional groups' self-interest has been and still
is the primary motivator of regulatory legislation.  And indeed the
evidence shows that consumers rarely engage in campaigns to license
occupations.  If the purpose of licensing were to improve the quality
of service, one would expect consumers, who might be the prime beneficiaries,
to promote licensure, but licensing is systematically promoted by
practitioners ..."

The book has over eighty references -- most from the US, but several
from Canada and Europe.  A number of these attempt to make the case
*for* licensing, which Young generally demolishes quite effectively.

Recommended reading.

Tony Harminc, Ultramar Canada Inc.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-17</DOCNO>
<DOCOLDNO>IA013-000136-B029-322</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.44.html 128.240.150.127 19970217040228 text/html 26698
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:00:55 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 44</TITLE>
<LINK REL="Prev" HREF="/Risks/10.43.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.45.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 44</H1>
<H2> Monday 24 September 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Arbitration Myths 
</A>
<DD>
<A HREF="#subj1.1">
Leslie Lamport
</A><br>
<A HREF="#subj1.2">
 Mark S. Day
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Overbilled by 6 orders of magnitude 
</A>
<DD>
<A HREF="#subj2.1">
Jeff Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks of "automated guided vehicles" 
</A>
<DD>
<A HREF="#subj3.1">
Brad Dolan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Field commanders using UNIX? 
</A>
<DD>
<A HREF="#subj4.1">
Tom Beattie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Expert system in the loop 
</A>
<DD>
<A HREF="#subj5.1">
Matt Jaffe
</A><br>
<A HREF="#subj5.2">
 Clifford Johnson
</A><br>
<A HREF="#subj5.3">
 bahn_pr
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Apollo, The Race to the Moon 
</A>
<DD>
<A HREF="#subj6.1">
R.I. Cook
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Failed mail ("after 246 days"!) and comment on long header lines 
</A>
<DD>
<A HREF="#subj7.1">
PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Arbitration Myths (Peter Denning, <A HREF="/Risks/10.42.html">RISKS-10.42</A>)
</A>
</H3>
<address>
Leslie Lamport
&lt;<A HREF="mailto:lamport@src.dec.com ">
lamport@src.dec.com 
</A>&gt;
</address>
<i>
Mon, 24 Sep 90 10:36:11 -0700
</i><PRE>

Peter Denning correctly observes:

   The fundamental theorem of arbiters is: There is no fixed time bound
   for the arbiter to make its choice.

It may make things a bit clearer to phrase this as follows.  A designer
of a circuit that has an arbiter has two choices:

   1. Have his circuit wait arbitrarily long for the arbiter to make
      up its mind, thereby guaranteeing that his digital circuit elements
      will operate digitally, "seeing" only 0's and 1's.

   2. Bound the length of time the circuit waits for the arbiter,
      thereby introducing the possibility that his digital circuit 
      will behave like an analog circuit, with 1/2's flowing
      along the wires, and do strange things.

Peter then asserts:

   Lamport showed how to achieve fair mutual exclusion without any
   requirement that references to memory cells are arbitrated (1974).

While perhaps correct, this statement is misleading.  The bakery algorithm
achieves mutual exclusion without assuming any arbitrated access to memory.
However, reading a memory cell that may be written while it is being read
requires that the reader have an arbiter.  (The reader needs an arbiter to
decide whether the change from 0 to 1 occurred before or after a read
operation.)  In fact, the mutual exclusion problem is characterized by the fact
that any solution requires an arbiter.  (It is a testimony to Dijkstra's
insight that certain requirements set down in his original 1965 paper,
apparently regarded as irrelevant and omitted by others in later statements of
the problem, are necessary to distinguish mutual exclusion from theoretically
easier problems that can be solved without an arbiter.)

As Peter observes, the only way to build a computer that is safe from
"arbitration failure" is by making choice 1, which means that the computer must
turn off its clock while waiting for an arbiter to decide.  Note that the
computer can't keep its clock ticking while waiting for the arbiter to make up
its mind, since it would then require another arbiter to decide within the
current clock cycle whether or not the first arbiter had made up its mind.  I
know of no computer that turns off its clock in this way.  Moreover, doing so
necessarily eliminates the possibility of fault-tolerance.  Omission faults can
be detected only by time-out, which means by keeping a clock running.  Thus, a
system that is impervious to arbitration failure cannot be fault-tolerant.

Thus, Peter's 

   Conclusion: we know how to build fair arbiters and how to design
   circuits that are free of synchronization errors.

is again perhaps correct, but misleading.  We know how to design those
circuits, but we also know that they are impractical.

Having said all this, I should now add that the situation, although hopeless,
is not serious.  We cannot make circuits with no theoretical possibility of
arbitration failure, but we can make them with no practical possibility of such
failure.  By arguments that would constitute a proof to a physicist, and a joke
to a mathematician, I think one can show that if a circuit has normal reaction
time of order T0, then an optimimum arbiter has probability about e^(-T/T0) of
not having reached a decision by time T.  It appears possible to build such an
optimal arbiter.  Thus, by simply allowing enough time for the arbiter to
decide, the probability of an arbitration failure can be made negligibly small.

Of course, note the "can be".  How many of the engineers designing digitial
circuitry are aware of the problem?  Once, in the late 70's or early 80's, I
had the horrifying experience of spending 1/2 hour trying to explain the
problem to computer designers at Bendix, with an utter lack of success.

Leslie Lamport

P.S.  People interested in the arbiter problem might like to read my
unpublished paper "Buridan's Principle", available by request.

</PRE>
<HR><H3><A NAME="subj1.2">
Arbiters and glitches
</A>
</H3>
<address>
"Mark S. Day"
&lt;<A HREF="mailto:mday@brokaw.LCS.MIT.EDU ">
mday@brokaw.LCS.MIT.EDU 
</A>&gt;
</address>
<i>
Sat, 22 Sep 90 18:34:11 EDT
</i><PRE>

Peter Denning is absolutely right (in Risks 10.42) to correct the
claim that "it is impossible to build a fair arbiter." However, the
fact that reliable arbiters are possible is quite different from
saying that they are implemented in most systems.

As Denning's "fundamental theorem of arbiters" shows, the interface
between an asynchronous system and a clocked system is a source of
unreliability (not unfairness) and it is not possible to eliminate
glitches except by eliminating the interface (using an entirely
asynchronous system). The probability of glitches can be reduced, but
only by reducing the performance of the interface (lengthening the
decision time).  The original writer might well have been assuming
clocked systems (which are, after all, the vast majority of digital
systems in the world) in which case there is an important kernel of
truth to the original claim of impossibility, even though it is indeed
technically incorrect.

--Mark Day

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Overbilled by 6 orders of magnitude
</A>
</H3>
<address>
Jeff Johnson 
&lt;<A HREF="mailto:jjohnson@hpljaj.hpl.hp.com">
jjohnson@hpljaj.hpl.hp.com
</A>&gt;
</address>
<i>
Sat, 22 Sep 90 16:32:21 PDT
</i><PRE>

Excerpted from the 9/21/90 San Jose Mercury-News:

PHONE BILL'S WRONG NUMBER:  $8.7 MILLION

Chicago (AP) -- Cori Ward's mother got a little defensive when she
received a phone bill for three weeks' service -- $8.7 million.

"She says, 'I only called my sister,'" said Ward, who handles her
elderly mother's bills.

The bill from Illinois Bell should have read $87.98, not $8,709,800.33.

...

Ward said she had a hard time explaining the mistake to the phone company.

The error occurred when someone incorrectly typed a "correction" into
the computer system, said Larry Cose, a Bell spokesman.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks of "automated guided vehicles"
</A>
</H3>
<address>
&lt;<A HREF="mailto:pine_ridge%oak.span@Sds.Sdsc.Edu">
pine_ridge%oak.span@Sds.Sdsc.Edu
</A>&gt;
</address>
<i>
Mon, 24 Sep 90 12:07:24 GMT
</i><PRE>

Excerpted from the Maryville/Alcoa (Tenn.)  _Daily Times_, 
September 10, 1990, p.1. :

ALCOA Worker Killed

Donnie W. Britton, 48, of Madisonville, a 24-year employee of
ALCOA, died shortly before noon Saturday at UT Hospital following
an accident at ALCOA's North Plant.  

Elton Jones, ALCOA's director of public relations, said Britton, an
electrician, was working on an overhead crane that was not 
operating when the crane's tray grab, the part that hangs down and
lifts trays of coils (of aluminum sheet), was struck by the top of
a coil being transported at ground level by an automated guided
vehicle.  The impact caused the crane to move toward Britton who
was crushed between an access platform on the crane and the
personnel lift he had used to reach the crane .......

    This looks to me like (1) poor work practice and (2) poor a.g.v.
    design.  Comments?

    Brad Dolan, Science Applications International Corp (my opinions)
    pine_ridge%oak.span@sds.sdsc.edu    bdolan@cup.portal.com

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Field commanders using UNIX?
</A>
</H3>
<address>
&lt;<A HREF="mailto:twb@hoqaa.att.com">
twb@hoqaa.att.com
</A>&gt;
</address>
<i>
Mon, 24 Sep 90 16:28 EDT
</i><PRE>

I came across this in a news digest.
As you can see it is attributed to UNIX Today:

           "To combat the use of chemical weapons by the Iraqis, the 
         Pentagon is planning a two-pronged, high-tech defense using UNIX-
         based laptops.  Using meteorological-type programs, the laptops 
         could quickly determine how widespread the attack will be, where 
         the troops can safely be deployed and how quickly they should be 
         moved.  The information would then be fed into UNIX-based PCs,
         and field commanders would run a variety of attack scenarios.  A 
         full meteorological model, able to forecast likely future wind 
         conditions over the entire risk area, could be generated within 60 
         seconds.  [UNIX Today, 9/17/90]"

Field commanders using UNIX?
Meteorological models in 60 seconds on a Unix-based laptop?

Tom Beattie     att!hoqaa!twb     t.w.beattie@att.com

                    [Whether it's cold, or whether it's hot, 
                     weather is weather, whether or not.  
                     It's known as whethering the storm.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Expert system in the loop (Thomas, <A HREF="/Risks/10.37.html">RISKS-10.37</A>)
</A>
</H3>
<address>
 
&lt;<A HREF="mailto:jaffe@safety.ICS.UCI.EDU">
jaffe@safety.ICS.UCI.EDU
</A>&gt;
</address>
<i>
24 Sep 90 19:06:26 GMT
</i><PRE>

&gt;Martyn Thomas reports:

&gt;&gt;According to Electronics Weekly (Sept 12th, p2): [...]
&gt;In fact, he has contradicted his own assertion that the AEgis system was
&gt;responsible by pointing out the shortcomings in human judgement, human
&gt;psochology, and human I/O.  The principal (and significant) shortcoming
&gt;of AEgis in this scenario is that its database apparently did not
&gt;include a readily available schedule of commercial airline flights for
&gt;the region in which AEgis was deployed.

I was one of the principal designers of the MMI for Aegis so I have read the
past and current discussions on this subject with some interest.  A couple of
years ago PGN posted a summary of some remarks I made on the subject of the
Aegis MMI at an informal sidebar to one of the sessions of the 5th
International Workshop on S/W Specification; I won't repeat them here -
interested readers are referred to the Risks archives.  

      [See <A HREF="/Risks/8.74.html">RISKS-8.74</A>, 26 May 1989.  It was a really fine item, and it also 
      appeared in ACM SIGSOFT Software Engineering Notes, vol 14, no 5, 
      July 1989, pp. 20-22.  PGN]

Here, I only want to interject a comment on the more recent post extracted
above.  It is certainly true that Aegis as originally deployed did not include
a database of commercial flight data.  I recall some informal discussions about
that possibility at the time.  Our Navy customer had not specified anything
like that in their requirements, but the possiblity was mentioned by me (and
others), none-the-less.  There were several reasons why it was not further
pursued:

(1) Philosophic disagreements on the nature of probable Aegis employments.  In
a blue-water, all out conflict, commercial flight data processing would be
irrelevant and unused.  The Navy did not want to spend scarce development
funding on what they perceived of as marginal requirements.  It is my personal
perception (shared, I'm sure, by many others) that the armed services tend to
design systems for "pure" threats and scenarios.  Aegis was conceived of as
providing defense for the carrier task force in open water conflicts.  The then
recent experiences of employing missile cruisers in close in the Gulf of Tonkin
(NORSAR and PIRAZ, specifically) seemed to be regarded as an aberration:
"Vietnam was a mistake; we won't make that mistake again; no more confused
little conflicts for the U.S."  We often heard the sentiment that we (Navy and
contractor jointly) did not want to be guilty of the oft repeated mistake of
designing systems to meet the requirements of the last war.  The risk, of
course, was and is that we could fail to institutionalize what some of us so
painfully learned from our experiences.

(2) Logistic/design problems relating to the complexity of flight data
processing (keeping track of commercial flight plans and correlating real-time
tracks with possible flight plans).  The Navy did not then (nor I presume does
it now) have any facilities aboard tactical vessels for obtaining and
distributing commercial flight plan data.  The resources required are
significant, both personnel and computational.  At the time, the Navy was under
intense pressure to reduce manning requirements for the Aegis ship.  I also
doubt whether the UYK-7 technology of the day could have handled the
computational load required.  There also would have had to be additional
communciations bandwidth dedicated to the distribution, update, and
coordination of flight data.  In those days, digital bandwidth to ships was
extremely limited (it almost certainly still is).

The point is that the issue of designing Aegis to handle commercial flight data
was addressed and rejected as not cost-effective.  Whether one agrees with this
specific decision or not, the general point is that no military system (or any
system) can be designed to deal with all contigencies that someone thinks of as
appropriate.  All the ideas that the anyone on the team came up with got
discussed, some were selected, some were not.  As always, the operational users
wound up having to make do with a system that was not optimized for the
environment in which they found themselves and whose limitations neither they
nor the policy decision makers who directed them fully understood. I am still
not sure whether any of the "what-ifs" represent design flaws or shortcomings.

</PRE>
<HR><H3><A NAME="subj5.2">
Expert system in the loop (Henry Spencer, <A HREF="/Risks/10.42.html">RISKS-10.42</A>)
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Mon, 24 Sep 90 11:36:46 PDT
</i><PRE>

&gt; the Pentagon's finding was not that nobody
&gt; was responsible for the [Vincennes] mistake, but that no *blame*
&gt; was attached to the captain and crew as a result of it...
&gt; The [military's] job is to carry out the policies of
&gt; their government, and if innocent people get hurt, that is
&gt; the policy- makers' problem....

Since the Vincennes' very mission was to keep the Gulf safe for
civilian traffic, the point argued by Henry here, even were it
elsewhere valid, in fact weighs against his argument that Captain
Rogers' reasonably decided to risk civilian life.   As for the
the general case, there certainly are regulations drawn up in
international law, that protect civilians from risk, even in battle.
(An air embargo against Iraq cannot now be *enforced* under
this sort of international law.)  Likewise, a suit filed in
international court in Costa Rica against the U.S., for its
bombing of a civilian mental hospital in Grenada, was *settled* by
the U.S. (albeit without admission of blame).  In brief, the U.S.
would have had to show sufficient probable cause for the bombing,
by objective standards, had trial been reached.

&gt;&gt;&gt;In the case of the Vincennes, it cannot be disputed that a mistake
&gt;&gt;&gt;was made.  The Pentagon found no human responsible for it, so it
&gt;&gt;&gt;must have been a mechanical error.
&gt; This statement is in error.  Please, READ THE REPORT . . .
&gt; The board found that Captain Rogers made a correct decision to fire
&gt; based on the data that he had available to him.

The data was generated by computer, and the misinterpretation of
screens that occurred was deemed foreseeable (and was forgiven)
in the circumstances. I fail to see even a small error in my claim,
let alone a capitalized error.  Given the facts, which we agree on,
it is a matter of definition as to whether we say that the computers
"made" the decision to shoot, which is the definition I assert as
a matter of commonsense and law.

&gt;&gt;&gt;Such decisionmaking is de facto *governed* by computer: without
&gt;&gt;&gt;computer prompts, no retaliatory decision at all would be taken;
&gt; Again, incorrect.  Decisions to fire were made long before we
&gt; had computers -- they are not required to make these decisions.

Well, yes, but I'm not saying that mistaken visual identification
is a computer error, I'm talking about decisionmaking taken by
commanders whose only inputs are computer screens of information.
There's a qualitative difference, though I agree that drawing the
line meaningfully is not easy, it's clear to me that momentary
decisions taken in the Vincennes windowless control room are properly
deemed computer-governed.

</PRE>
<HR><H3><A NAME="subj5.3">
vincennes incident (Henry Spencer, <A HREF="/Risks/10.42.html">RISKS-10.42</A>)
</A>
</H3>
<address>
Wheels in Wheels
&lt;<A HREF="mailto:bahn_pr%ncsd.dnet@gte.com ">
bahn_pr%ncsd.dnet@gte.com 
</A>&gt;
</address>
<i>
Mon, 24 Sep 90 16:28:18 -0400
</i><PRE>

I believe Henry failed to observe a key point in the navy review of the 
Vincennes incident.  The Assistant Anti-Air warfare officer failed to set
the range gate for the IFF unit to allow for the changing distance to the target.
Consequently instead of pinging the transponder on the A300, they were
pinging an F-14 on the ground at Bandar Abbas.  Also no consideration
was given that F-14 lack an anti-ship capability.

	The Radar operator also mis-read his screen, interpreting
range for altitude, and also was unaware of the fact that a civil
air corridor ran through the gulf, and that the A300 was in fact in the center
of the corridor.  The Vincennes lacked VHF radios to interrogate Iranian
Civil air also.  Civilian aircraft at 33,000 feet are also by definition
well clear of ships, and probably would not even be able to identify them
without optical instruments.  

	As I read the Navy report, there were two distinct personnel failures
by Vincennes crew, compounded by Inability to interrogate the A300.  The Navy
review board faulted the design of the screens for not presenting information
in a clear manner.  Heat of battle was also considered a mitigating factor.

	What is not understood by readers of Risks, is the Persian gulf is
an exteremely busy commercial zone.  Hundreds of Planes and Boats ply those
waters every day.  To shoot at every moving target is negligent on our part.
THese systems are designed for high intensity combat with dozens of combatants
and numerous inbound threats.  Trying to pick out a single hostile among
hundreds of non-combatants is a much more difficult task.

	The Iran-Iraq war contrary to one readers opinion was not WW2.  In WW2,
there were clear sides.  CLearly marked hostile zones and very few nuetrals.  
WW2 was also a total war.  No tactic was untried save for Gas.  THe Iran Iraq
war was a relatively small war between tow neighbors in a very crowded
environment.  Interjecting High strung war ships into such an environment was
only bound to cause such errors.

	THe Stark had made a type 2 error.  Actually hostile, Failed to shoot.
	THe Vincennes made a type 3 error.  Actually Civil, Did shoot.

	I am sure in the mind of the captain of the Vincennes was the court
martial of the Stark's captain and his claim that the electronic systems had 
failed to identify the threat, increasing the probablity now of a type 3 error.

	While the Navy review board did reccomend changes involving Man-machine
interfaces, knowledge of commercial routes, Addition of VHF radios and 
upgrading of the IFF system.  I feel the fundamental error was placing
military vessels into a environment crowded with non-combatants.  These
vessels are designed to fight WW3, not police brush-fire wars.  This was
a major problem for US troops in Vietnam also.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Apollo, The Race to the Moon
</A>
</H3>
<address>
&lt;<A HREF="mailto:cook@csel1.eng.ohio-state.edu">
cook@csel1.eng.ohio-state.edu
</A>&gt;
</address>
<i>
Mon, 24 Sep 90 15:06:54 EST
</i><PRE>

The excellent book recommended by M.Minow is available in paperback for $12.95.
The reference is

   Murray, Charles &amp; Cox, Catherine B.
   Apollo, The Race to the Moon.  Simon &amp; Schuster, 1989.  ISBN 0-671-90625-X

R.I.Cook	cook@csel.eng.ohio-state.edu

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">

</A>
</H3>
<address>
"helios.northeastern.edu mmdf IIb upd 43" 
&lt;<A HREF="mailto:mmdf@helios.northeastern.edu">
mmdf@helios.northeastern.edu
</A>&gt;
</address>
<i>
Mon, 24 Sep 90 0:18:31 EDT
</i><PRE>
Subject:  Failed mail  (msg.aa00705)

    After 246 days (5891 hours), your message could not be fully delivered.
          ^^^       ^^^^                                                  &lt;==PGN

    It failed to be received by the following address(es):

	nu-risks@nuhub.acs.northeastern.edu (host: nuhub.acs.northeastern.edu)...

    Problems usually are due to service interruptions at the receiving
machine.  Less often, they are caused by the communication system.

    Your message follows:

Received: from HERCULES.CSL.SRI.COM by helios.northeastern.edu id aa00705;
          21 Jan 90 11:11 EST
Received: by hercules.csl.sri.com at Sat, 22 Sep 90 13:26:33 -0700.
	(5.64+/XIDA-1.2.8.35) id AA28066 for oneil%NASA-JSC.CSNET@RELAY.CS.NET
From: RISKS Forum &lt;risks@csl.sri.com&gt;
Date: Sat, 22 Sep 1990 13:26:31 PDT
Subject: RISKS DIGEST 10.42 

RISKS-LIST: RISKS-FORUM Digest  Saturday 22 September 1990   Volume 10 : Issue 42
RISKS-LIST: RISKS-FORUM Digest  Wednesday 22 September 1990  Volume 10 : Issue 42

  [Northeastern has always been an interesting host.]

    [By the way, I am sorry about the 81-character line ending with
    Volume 10 : Issue 42 where many of you could not read the "2" at the end.
    Yes, I know, Issue 43, also.  Mark Brader &lt;msb@sq.com&gt; pointed this out to
    me, and I replied with a comment such as how on double-digit Wednesdays and
    occasionally Saturdays in September my masthead lead could run over 80
    characters (in Volume 10 and from now on, unless I am on my toes, as I was
    in <A HREF="/Risks/10.36.html">RISKS-10.36</A>.)  (I've shortened the line by one character in this issue,
    so now it is just Wednesdays in September 1991, etc., that I'll have to 
    watch out for.  I'll set my calendar program to remind me, if I am still 
    running RISKS then.)  PGN]

       "... when the moon is in the third quarter? :-)"  says Mark.

       "[Jupiter's] satellites are invisible to the naked eye and therefore 
       can have no influence on the Earth and therefore would be useless 
       and therefore do not exist."	-- Francesco Sizi, quoted by T. Cox

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-18</DOCNO>
<DOCOLDNO>IA013-000136-B029-348</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.45.html 128.240.150.127 19970217040241 text/html 22258
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:01:10 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 45</TITLE>
<LINK REL="Prev" HREF="/Risks/10.44.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.46.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.44.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.46.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 45</H1>
<H2>Wednesday 26 September 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Computergate in New Jersey? 
</A>
<DD>
<A HREF="#subj1.1">
Steve Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Whitehall rebuked for 121 million pound Retail Price Index blunder    
</A>
<DD>
<A HREF="#subj2.1">
Dorothy Graham
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Hi-tech advertising 
</A>
<DD>
<A HREF="#subj3.1">
Dave Turner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Students taking exams by remote hookups 
</A>
<DD>
<A HREF="#subj4.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Sun C2 system 
</A>
<DD>
<A HREF="#subj5.1">
Stephanie Zakrzewski
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Arbiters 
</A>
<DD>
<A HREF="#subj6.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Expert system in the loop 
</A>
<DD>
<A HREF="#subj7.1">
Amos Shapir
</A><br>
<A HREF="#subj7.2">
 Jim Horning
</A><br>
<A HREF="#subj7.3">
 R Horn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Reliability of the Space Shuttle 
</A>
<DD>
<A HREF="#subj8.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Illinois Bill 
</A>
<DD>
<A HREF="#subj9.1">
Mark Brader
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computergate in New Jersey?
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@ulysses.att.com">
smb@ulysses.att.com
</A>&gt;
</address>
<i>
Tue, 25 Sep 90 08:20:58 EDT
</i><PRE>

A political scandal, known variously as ``Trentongate'' or ``Computergate'', is
brewing here in New Jersey.  A staff member employed by the Republicans in the
state legislature has admitted to breaking into a computer system used by the
Democrats; reportedly, the number of documents obtained is in the thousands.
His activities were known to the staff director; he recently admitted as much
and resigned.  But the Democrats aren't making too much of a fuss over this --
allegedly, they don't want the contents of the filched documents disclosed,
since they are reported to deal with improper use of state facilities for
political purposes.  (Were Nixon's tapes 9-track, and was the 18 minute gap
really part of the tape drive error recovery processing...?  And Haig's
``sinister force'' was just an ordinary reboot.)
                                                       --Steve Bellovin
                                   /
     [Donkey haute and pancho sans a ba(s)bar tilting at winned spills?  
     (Please pardon my espanofranglais, Sir Vantes!)  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Whitehall rebuked for 121 million pound Retail Price Index blunder 
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 25 Sep 1990 11:50:53 PDT
</i><PRE>

A 1% error in the British RPI cost the government 121M pounds in compenstation
to pension and benefit losers, donations to charities, and administrative
costs.  The problem was discovered after a computer error caused the RPI to be
understated from February 1986 to October 1987.  The programs had been tested,
but the tests did not reveal the error.

Source: Computing (UK), 20 September 1990, submitted via airmail by Dorothy R.
Graham, Grove Consultants, 40 Ryles Park Rd., Macclesfield, Cheshire SK11 8AH.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Hi-tech advertising
</A>
</H3>
<address>
Dave Turner
&lt;<A HREF="mailto:dmt@ptsfa.pacbell.com ">
dmt@ptsfa.pacbell.com 
</A>&gt;
</address>
<i>
Mon, 24 Sep 90 22:16:39 PDT
</i><PRE>

The San Francisco Chronicle had a front page article today (09/20) headlined:

			High-Tech Advertising
			Better Junk in New Junk Mail

A few quotes:

	Junk mail is going high tech.
	Across the nation, well-heeled consumers are being bombarded with
	expensive computer diskettes, elaborate video-tapes of car
	commercials and even catalogs that play Christmas carols.  ...

	+ Compaq Computers mailed 40,000 floppy disks to possible
	customers last summer to introduce a new line of computers that
	cost as much as $20,000. ...

	Kevin Bohren, a spokesman for Compaq Computers in Houston, said
	his company tripled its response rate last year when it mailed
	"interactive diskettes" as a promotion for its new line of
	personal computers. "People responded because we weren't just
	sending out another pamphlet," he said.

If people become accustomed to inserting every floppy received in the mail into
their computers thinking that it is just another form of advertising, the risk
of viruses spreading will increase rapidly. A few thousand deviant floppies
sent to several large corporations and schools will produce marvelous results.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Students taking exams by remote hookups
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 25 Sep 1990 11:44:07 PDT
</i><PRE>

An AP item today was called to my attention, datelined CHICAGO (AP).

    "Thank you for calling Telequiz. After the tone, please leave the
  answers to your college exam."
    In what is believed to be the national debut of student testing via
  push-button phone, students at Governors State University telephoned in the
  answers to their Psychology 519 quiz from the comfort of home.

[True-false answers are recorded with computerized voice-mail equipment.  A
professor was quoted as how this saves everyone time, effort, and travel, and
provides considerable convenience because students can be tested when they wish
-- although in its present implementation only one student can call in at a
time.  No reentrant exam programs (as opposed to reentrance exams) yet!  RISKS
readers do not need to be reminded of the security/integrity problems.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Sun C2 system
</A>
</H3>
<address>
Stephanie Zakrzewski 
&lt;<A HREF="mailto:Zakrzewski@DOCKMASTER.NCSC.MIL">
Zakrzewski@DOCKMASTER.NCSC.MIL
</A>&gt;
</address>
<i>
Tue, 25 Sep 90 09:59 EDT
</i><PRE>

I'm amazed by recent references to Sun's "C2" system.  What system is this?
There has been no Sun product evaluated by the National Computer Security
Center, so there is no such thing as a "Sun C2 system".  Like the Good
Housekeeping Seal of Approval can be awarded by only Good Housekeeping, a
rating against the Trusted Computer System Evaluation Criteria (the Orange
Book, which defines C2 and the other levels of trust) can be awarded only by
the National Computer Security Center, which authored the Orange Book.

Each product which has been evaluated and thus earned a rating is announced in
the Information Systems Security Products and Services Catalog, chapter four,
the Evaluated Products List.  So if you are in doubt in future, check this
source.  Anything not in there is, at best, DESIGNED TO MEET C2.  At worst, it
provides no trust at all.  Don't be misled by premature or misleading claims.
Relying on false security is far more dangerous than having no security - at
least in the latter case you stay on guard!

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Arbiters
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian.Randell@newcastle.ac.uk">
Brian.Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Tue, 25 Sep 90 10:47:26 BST
</i><PRE>

Nearly twenty years ago David Wheeler of Cambridge University, lectured here on
this subject in our Annual International Seminar on the Teaching of Computing
Science at University Level (7-10 Sept.  1971). RISKS readers might enjoy this
quote from the Seminar Report:

 "The Problem of Synchronisation

 Dr Wheeler devoted the rest of his talk to a discussion of a
 particular problem in logical design. He chose to do this, rather than
 give a more general talk, because he considers that discussion of this
 point should form part of every course on hardware or logical design.
 His reasons for emphasising this point, which he calls the problem of
 synchronisation, are as follows:

 (a) Many existing computers have faults because of neglect of this
   point. (Dr Wheeler found that at least 50% of the computers whose
   logical design he has studied in detail have faults of this kind.)

 (b) The point is rarely taught well and only occasionally appears in
   text books.

 (c) It is apparently difficult to to appreciate. Furthermore, people
   trained in switching theory or logical design find it especially
   difficult.

 (d) The problem is general. It is common to all forms of logic and may
   also be present in systems programs. It touches many disciplines, for
   example circuit theory, logical design, systems programming and
   information theory.

 (e) The occasional malfunctioning of all practical computers and
   peripherals is to be expected if this point is neglected."

[The report then goes on to give a detailed account of David Wheeler's
lecture.] 

(Younger RISKS readers may not be aware that David Wheeler, who I'm pleased to
say is still very active, was in 1949/50 the principal source of such concepts
as closed subroutines, assemblers, post mortems, and much else, in his
pioneering programming work on EDSAC, and went on to do much hardware design,
for example of EDSAC2 and of the Cambridge Ring.)

Brian Randell, Computing Laboratory, University of Newcastle upon Tyne, UK
PHONE =	+44 91 222 7923    FAX = +44 91 222 8232 Brian.Randell@newcastle.ac.uk

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Expert system in the loop (Thomas, <A HREF="/Risks/10.37.html">RISKS-10.37</A>)
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:amos@taux01.nsc.com ">
amos@taux01.nsc.com 
</A>&gt;
</address>
<i>
25 Sep 90 15:50:52 GMT
</i><PRE>

[Quoted from the referenced article by jaffe@safety.ICS.UCI.EDU]
&gt;The point is that the issue of designing Aegis to handle commercial flight data
&gt;was addressed and rejected as not cost-effective.  Whether one agrees with this
&gt;specific decision or not, the general point is that no military system (or any
&gt;system) can be designed to deal with all contigencies that someone thinks of as
&gt;appropriate.

The point is, I don't think Aegis had to be designed to keep track of
all aerial traffic in the area; I'm pretty sure that *Air Force* systems
in the area did have a positive ID on everything that was flying at
the time.  The trouble is, I also suspect that there was no way the captain
could just call somebody and ask "Hey, what's that on my screen?"

Amos Shapir, National Semiconductor (Israel) P.O.B. 3007, Herzlia 46104, Israel
Tel. +972 52 522255 TWX: 33691, fax: +972-52-558322 amos@nsc.nsc.com

</PRE>
<HR><H3><A NAME="subj7.2">
Expert system in the loop (Aegis display)
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.dec.com ">
horning@src.dec.com 
</A>&gt;
</address>
<i>
25 Sep 1990 1252-PDT (Tuesday)
</i><PRE>

The renewed discussion of the Vincennes incident brought back some 25-year- 
old memories about displaying aircraft tracking data.  I don't think this
problem has been discussed in RISKS (at least not recently):

    The risk of displaying data that was computed for a different purpose.

*I have no reason to believe that there's any direct connection between 
the following story and the Aegis system--I'm only saying that the Aegis 
developers must have faced the same kind of problems.*

At that time, I was supporting myself in graduate school by programming 
for a major aerospace manufacturer.  I worked on a weapons guidance system 
that I've heard is still used in top-of-the-line US combat aircraft. 
I was responsible for displaying the tracking data.  Newsweek published
a picture of an Aegis display that included the same track symbols as we 
were using, but that probably just means they are some kind of a military 
standard.

Before testing our software with real sensor data, we ran numerous tests 
with simulated data.  It quickly became apparent that the velocity displays 
were unacceptably erratic, and didn't have much connection to the velocities 
of the simulated targets.  So we simplified the data to a single target 
moving in a straight line with no acceleration.  Still looked awful.
So we reduced the simulated sensor noise, and finally eliminated it.
The velocity display was a lot smoother, but it showed target velocities
and maneuvers that just weren't in the input.

Finally I decided to do a little mathematical analysis.  I was able to
identify two sources of error in the second-order difference equations used
to smooth and extrapolate track data:

  - Sensor data was supplied in polar coordinates, and all calculations 
    were done in polar coordinates.  In general, unaccelerated straight-line 
    motion produces non-zero derivatives of all orders in polar coordinates.  
    At the ranges and velocities for which the system was designed, these 
    virtual velocities and accelerations were not negligible.

  - The smoothing algorithm initialized the first and second difference
    estimates on all coordinates of a track to 0.  At the ranges and 
    velocities for which the system was designed, the differences could 
    start from zero, overshoot, overshoot in the other direction, ... and 
    not stabilize within the time a straight-line target remained in range.

I was able to show that a straight-line target 60 miles away that was moving 
perpendicular to the tracking plane could have an indicated velocity 90 
degrees off its true velocity, i.e., the display would show its velocity 
as being straight towards the tracking plane.  I didn't think that such 
a velocity display was likely to help the Missile Control Officer make 
good decisions.

Our department was only responsible for the software.  I wrote up my 
analysis, including a demonstration of the improvements that would result 
from smoothing and extrapolating in a cartesian coordinate system and from 
initializing the differences more reasonably.  I sent my analysis off to 
the department that had supplied the smoothing algorithm, feeling very 
proud of my young self for having caught the problem and figured out the 
solution before it caused any real trouble.  But the answer from that 
department was: "We don't understand your mathematics.  We optimized the 
algorithm using Z-transforms, and it's not your job to second-guess us." 
(This was one of several reasons why my career in aerospace was brief.)

Later, I learned that the algorithm was not as unreasonable as it had seemed 
to me.  The primary purpose for maintaining the track files was to lock 
a missile's sensors onto a particular target before launch, and the sensors 
had to be aimed in polar coordinates.

The real problem was that someone designing the man-machine interface had 
seen that the track file format contained fields R, RDOT, RDDOT, etc., 
and decided that, since the velocity information was available, it would 
be a good idea to display it for the MCO.  But it wasn't a good estimator 
of velocity, and was never designed to be.

To me it is entirely plausible that the junior officer on the Vincennes who
made errors in reading the altitude and speed of the approaching aircraft was
in fact being misled by the displayed velocity, and not just by stress.  I
doubt that the logging data for the Aegis records enough of what is displayed
at each instant to settle this.  Doubtless some readers of RISKS know enough
about the Aegis software to know whether this is possible, but they may not be
free to comment on the subject.
                                                  Jim H.

</PRE>
<HR><H3><A NAME="subj7.3">
Re: Expert systems in combat
</A>
</H3>
<address>
&lt;<A HREF="mailto:HORN%HYDRA@sdi.polaroid.com">
HORN%HYDRA@sdi.polaroid.com
</A>&gt;
</address>
<i>
Wed, 26 Sep 90 10:57 EST
</i><PRE>

Various people have commented on Vincennes incident without noting the
applicable international law.  This law, which has counterparts running back
over a century, places the responsibility for identification upon the
*CIVILIAN*.  The military is permitted to presume hostile intent from all
unidentified people or things in a combat area.  The civilians must demonstrate
by words and actions that they are non-combatant.  Transponder codes are
explicitly listed as not sufficient.

In the particular case of the Vincennes, the military did comply with the law
by issuing a challenge and demand for course change.  Unfortunately the
aircraft ignored this challenge (probably because it was to ``unidentified
aircraft'' and in nautical phraseology).  And for these reasons there has been
no real effort to condemn the action in any court of international law.

This is not to say that problems and errors did not occur.  One problem that an
expert system might have resolved would be a more universal and internationally
understandable challenge terminology.  It took the shooting down of two
airliners by the Soviets to force general installation of mutually usable
radios in both military and civilian aircraft.  This accident reveals that
despite mutually usable radios, there remain significant communications
difficulties.  (Not the original mentioned use for expert systems, but much
easier and well within the present state of the art.)

The other risk that this shows is the danger of fundamental ignorance of
overall environment.  International law and treaties do exist, and do matter,
but both within this group and within the developers of the expert systems
there is profound ignorance of these rules.  When the rules are in software or
hardware what do you do when treaties change?

R Horn         horn%hydra@polaroid.com

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Reliability of the Space Shuttle
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:dasilva@ficc.ferranti.com ">
dasilva@ficc.ferranti.com 
</A>&gt;
</address>
<i>
25 Sep 90 15:29:32 CDT (Tue)
</i><PRE>

Not attempting to address other issues involved in the article by Perry
Morrison in comp.risks 10.40, I would like to simply point out that the space
shuttle has had many more successful launches than any other launch system
employed to date. The shuttle, as a whole, is extremely reliable...  it can
only be considered a failure in comparison with the outrageous levels of
reliability *claimed* for it by NASA prior to the Challenger accident.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Illinois Bill
</A>
</H3>
<address>
Mark Brader 
&lt;<A HREF="mailto:msb@sq.com">
msb@sq.com
</A>&gt;
</address>
<i>
Tue, 25 Sep 1990 22:31:19 -0400
</i><PRE>

&gt; The bill from Illinois Bell should have read $87.98, not $8,709,800.33.

Hmph.  That's only 5 orders of magnitude.

Mark Brader, Toronto		utzoo!sq!msb, msb@sq.com	

                       [So what's an order of magnitude here or there?  
                       Thank goodness it wasn't an earthquate.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.44.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.46.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-19</DOCNO>
<DOCOLDNO>IA013-000136-B029-375</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.46.html 128.240.150.127 19970217040307 text/html 27888
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:01:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 46</TITLE>
<LINK REL="Prev" HREF="/Risks/10.45.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.47.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.45.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.47.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 46</H1>
<H2> Friday 28 September 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Sellers Use Computer Glitch to Buy Illegal Winning Lottery Tickets    
</A>
<DD>
<A HREF="#subj1.1">
Nathaniel Borenstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Safer to Fly or Drive? 
</A>
<DD>
<A HREF="#subj2.1">
David Levine
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Expert system in the loop (Matt Jaffe 
</A>
<DD>
<A HREF="#subj3.1">
2)
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Bookkeeping error begs for machine help -- maybe 
</A>
<DD>
<A HREF="#subj4.1">
Jim Purtilo
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Hi-tech advertising 
</A>
<DD>
<A HREF="#subj5.1">
Brinton Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Reliability of the Space Shuttle 
</A>
<DD>
<A HREF="#subj6.1">
Chris Jones
</A><br>
<A HREF="#subj6.2">
 Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Automated vehicle guidance systems 
</A>
<DD>
<A HREF="#subj7.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Computer 'error' in the British RPI 
</A>
<DD>
<A HREF="#subj8.1">
Chaz Heritage via Richard Busch
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Sellers Use Computer Glitch to Buy Illegal Winning Lottery Tickets
</A>
</H3>
<address>
Nathaniel Borenstein 
&lt;<A HREF="mailto:nsb@thumper.bellcore.com">
nsb@thumper.bellcore.com
</A>&gt;
</address>
<i>
Fri, 28 Sep 1990 11:22:52 -0400 (EDT)
</i><PRE>

Because of a software screwup, the lottery database system let 6 winning
tickets be purchased after the winning numbers had been drawn in the Tri-State
Megabucks game for Vermont, New Hampshire and Maine.  There was one legitimate
ticket for $1.1 million.  The problem was caught before any payoffs could be
collected.  In addition, some belated daily lottery ticket winners did collect,
up to $5,000, although the state is apparently insured against the loss.  The
system is supposed to halt ticket sales 10 minutes before the drawings, but
did not.   [Source: an AP item by Frank Baker, 28 Sept 90, summarized by PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Safer to Fly or Drive?
</A>
</H3>
<address>
David Levine 
&lt;<A HREF="mailto:levine@crimee.ICS.UCI.EDU">
levine@crimee.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Thu, 27 Sep 90 11:02:13 -0700
</i><PRE>

The following is extracted [and with edits by dll] from Daniel J. Holt's
editorial in September 1990 _Aerospace Engineering_.  Holt summarizes the paper
"Is it Safer to Fly or Drive" by Leonard Evans, Michael C.  Frick, and Richard
C. Schwing of General Motors Research Labs, published in _Risk Analysis_, Vol.
10, No. 2, 1990.  The statistics, and more specifically some of the assumptions
behind them, may be of interest.

    [...] Apparently the researchers found fault with the cliche that
    the most dangerous part of an airline journey is the drive to the
    airport.  Over 98% of the intercity travel in the U.S. is via
    airline and automobile.  On a daily basis, 18,000 airliner take-
    offs and landings and 370 million mile car trips are completed in
    a safe manner.

    [claim commonly quoted fatality rates of] 0.6 deaths per
    billion miles of flying and 24 deaths per billion miles of driving.
    Specifically, they claim these rates are incorrect for three reasons:
    -- The airline rate is passenger fatalities per passenger mile,
       whereas the road rate is all fatalities (all occupants,
       pedestrians, etc.).
    -- Road travel that competes with air travel is on the rural
       interstate system, not average roads.
    -- Driver and vehicle characteristics, and driver behavior,
       lead to car-driver risks that vary over a wide range.

    [... 40 year-old, seat-belted, alcohol-free drivers (do they
    assume alcohol-free *other* drivers?)] are slightly less likely
    to be killed in 600 miles of rural interstate driving than in
    regularly scheduled airline trips of the same length.
    For 300-mile trips, the driving risk is half that of airline
    trips of the same length.  Thus the researchers concluded that
    for this set of drivers, car travel provides a lower fatality
    risk than air travel for trips in the distance range for which
    car and air travel are likely to compete.

    As for the cliche that the drive to the airport is riskier than
    the flight, the researchers concluded that average drivers with
    the age distribution of airline passengers are less likely to be
    killed on a 50-mile, one-way trip to the airport than on the flight.

David L. Levine, Dept. of ICS, University of California, Irvine Irvine, 
CA 92717    BITNET: levine@ucivmsa UUCP: {sdcsvax|ucbvax}!ucivax!levine

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Expert system in the loop (Henry Spencer, <A HREF="/Risks/10.42.html">RISKS-10.42</A>)
</A>
</H3>
<address>
Matt Jaffe 
&lt;<A HREF="mailto:jaffe@safety.ICS.UCI.EDU">
jaffe@safety.ICS.UCI.EDU
</A>&gt;
</address>
<i>
26 Sep 90 20:02:46 GMT
</i><PRE>

&gt;The data was generated by computer, [...]

&gt;&gt;&gt;&gt;Such decisionmaking is de facto *governed* by computer: without
&gt;&gt;&gt;&gt;computer prompts, no retaliatory decision at all would be taken;
&gt;&gt; Again, incorrect.  Decisions to fire were made long before we
&gt;&gt; had computers -- they are not required to make these decisions.

The term "prompt" is one key to some understanding of this type of situation.
Aegis (and similar USN combat systems) is designed to permit tactical decisions
to be implemented through Aegis mechanisms via three modes:

	(1) Automatic - the digital system itself makes the decision
	(2) Semi-automatic (a bad name, but retained for historic
            reasons) - the digital system specifically prompts the
	    operator with a specific, recommended decision, e.g.,
	    "recommend engagement of target X with weapon Y"
	(3) Manual - the system provides controls to allow an operator
	    to implement a decision

The Vincennes incident involved a manual decision.  One might reasonably ask to
what extent was the "manual" decision conditioned by the data presented by
Aegis.  Here the observation about the "windowless control room" is valid but
there are still several gradations possible.  If, for example, Aegis were to
have routinely displayed "automatically" computed threat rankings in a color
coded format (Aegis did not do that then; I doubt that it does it now), a
decision to engage based upon viewing a target in blinking bright red (with all
other targets being a steady, soothing blue) would still officially be a
"manual" decision but certainly much more "computer governed" than a similar
decision based on viewing a screen with all targets a homogeneous blue.  (It is
also possible - although not a factor in the Vincennes incident - for a system
to provide controls for the implementation of decisions made manually based on
data not mediated at all by the action-implementing system.)  The Vincennes
incident involved misinterpretation of displayed data, not interpretation of
misleading or provocatively displayed data.  (Of course, the data could be
wrong; more on that in a minute.)  My personal opinion is that the Captain of
the Vincennes would probably have made the same decision had the same data been
printed out for him in narrative text form.  (That is the apparent significance
of the Navy's finding that the Captain made the "correct" decision based on the
data available to him.)  The real issues are three fold:

	(1) How "true" was the digital systems "view" of reality?
	(2) Given the state of the art in algorithmic reasoning, could
            the digital system have been designed to model (I will NOT say
            "understand") reality any better?
	(3) How good was the MMI at presenting the digital "truth"?

For question (1), the answers appears to be mixed.  The system
reported a Mode II SIF on a target that did not (ignoring paranoid
possibilities) in fact have a mode II capability.  The altitude readouts
were apparently correct.

For question (2), it is my personal opinion that the system was designed
as well as we could do so at the time.  The reasons for the SIF
mis-assignment I and others have already discussed in other
correspondence.  I do not know of any design decision we could have made
differently that would have prevented this error.  The altitude reports
were as accurate as the underlying sensor technology permitted.
(Reasons for not trusting Mode C height, if it was available, were also
discussed previously and should be reasonably obvious - if one believes
a target might be hostile, one cannot place too much credence in data
the target itself provides.) Providing a better Z resolution would have
significantly increased the direct and indirect costs of a sensor
already critiqued (at that time) as far too expensive.  Given the inherent
limits on instantaneous height measurements and the inherent
manuverability of aircraft in the Z axis, Z' (rate of ascent or
descent)information will generally remain highly inacurrate.

It is question (3) then, that is the heart of the matter to me.  I don't
have the time here to fully recap all the issues, but I would like to
summarize my conclusions to date:

	(1)  We gave a lot of thought and discussion to the Aegis MMI.
	We had good engineers, MMI experts, operationally experienced Naval
	personnel, lots of review and open, no-holds barred discussions.
	We may have been wrong (I am still unconvinced, but in the sense
	that I don't know, not that I am sure we were right.), but we
	were as  methodical and as careful as we could be.
	(2) We might have tried to find a way to display the age of last
	correlated IFF hit (per mode) - that would have suggested that
	the target was not CURRENTLY squawking mode II (but was still
	squawking other modes) - but we were awfully tight on display
	space and the Navy and our own MMI experts were already telling
	us that we were displaying too much data.
	(3) I don't think we could have done much about the Z' problem,
	although I have not read the Navy's report to see their specific
	criticism or suggestions. ( I would be grateful to anyone willing to
	mail me a hard copy version - or reference to a classified
	document identifier.)

I believe that there were two classic technical problems involved in the
Vincennes incident (as well as the political decision making ones well
discussed elsewhere):

	(1) How to make available and prioritize for tactical operators
	the display of all the information that might be of significance
	some of the time without constantly saturating them all the time
	with displays and controls that are not currently relevant.
	(2) How (or whether) to display probabilistic and uncertain data
	to humans for used in highly stressed decision environments.

There is also the issue of training and comprehension, which straddles the
boundary between technical and institutional: How to ensure that key decision
makers (shipboard as well as policy) understand the limits of the technology
that they are employing?

It is our limited ability to answer these questions that makes incidents
like the Vincennes shootdown inevitable.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Expert system in the loop (Thomas, <A HREF="/Risks/10.37.html">RISKS-10.37</A>)
</A>
</H3>
<address>
Matt Jaffe 
&lt;<A HREF="mailto:jaffe@safety.ICS.UCI.EDU">
jaffe@safety.ICS.UCI.EDU
</A>&gt;
</address>
<i>
26 Sep 90 20:33:49 GMT
</i><PRE>

&gt;Amos Shapir, National Semiconductor (Israel) P.O.B. 3007, Herzlia 46104, Israel
&gt;[Quoted from the referenced article by jaffe@safety.ICS.UCI.EDU]
&gt;&gt;The point is that the issue of designing Aegis to handle commercial flight data
&gt;&gt;was addressed and rejected as not cost-effective.  Whether one agrees with this
&gt;&gt;specific decision or not, the general point is that no military system (or any
&gt;&gt;system) can be designed to deal with all contigencies that someone thinks of as
&gt;&gt;appropriate.

&gt;The point is, I don't think Aegis had to be designed to keep track of
&gt;all aerial traffic in the area; I'm pretty sure that *Air Force* systems
&gt;in the area did have a positive ID on everything that was flying at
&gt;the time.  The trouble is, I also suspect that there was no way the captain
&gt;could just call somebody and ask "Hey, what's that on my screen?"

Good point, with a couple of caveats:
	(1) Aegis was designed to "keep track" of everything in the
	area.  Aegis was designed to integrate identification information
	from all digitally accessible systems.  Your comment is equivalent to
	asking, "Did the Captain avail himself of other possible sources of
	information?"
	(2) You are presumably referring to AWACS; I don't know if there
	was an AWCAS bird covering that area at that time.
	(3) I'm not an AWACS expert; I doubt that they process
	commercial flight plans, though.  But they might not have had
	the mode II SIF confusion the Vincennes did.
	(4) The time pressure the Captain felt he was under would be a
	factor (assuming there was an AWACS bird available).  One would
	have to consider the time to make the call (depending on the
	tactical comm plan in effect, that could be simple or could
	be tough) and the perceived likelihood that the callee could
	tell one something that one did not already know.

So there probably was a way to call; the questions are instead, was there
anyone useful (in the Captain's mind) to call and did he feel he had time to do
it?  The asking "Hey, what's this on my screen?" is solved procedurally,
although to be fair, the actual use of such procedures (common coordinates and
pro-words) with the Air Force may or may not have been something the Vincennes
felt comfortable with.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
bookkeeping error begs for machine help -- maybe
</A>
</H3>
<address>
Jim Purtilo
&lt;<A HREF="mailto:purtilo@cs.UMD.EDU ">
purtilo@cs.UMD.EDU 
</A>&gt;
</address>
<i>
Wed, 26 Sep 90 21:17:31 -0400
</i><PRE>

Not yet a computer-related risk, but food for thought from today's Post:

&gt; 	Md. Admits Freeing Inmate Later Held in Three Slayings
&gt; 			by Richard Tapscott
&gt; 		Washington Post, September 26, 1990.
&gt; 
&gt; Maryland corrections officials conceded today that an error led to the early
&gt; release of a Harford County man who is charged in three killings committed
&gt; during a time he should have been in prison.
&gt; 
&gt; During a legislative hearing today, an attorney for the Division of
&gt; Correction said the state could be sued by relatives of the victims if John
&gt; F. Thanos's release 18 months early is found to have been caused by
&gt; negligence.
&gt; 
&gt; Until today, corrections officials had said only that they were
&gt; investigating whether there had been proper application of a complex set of
&gt; guidelines used in determining how much time to deduct from Thanos's
&gt; sentence for good behavior.  "Good Time" is awarded as a method of
&gt; maintaining discipline in prisons and to ease crowding.
&gt; 
&gt; But Bishop L. Robinson, secretary of public safety and correctional
&gt; services, told lawmakers this afternoon that Thanos was "erroneously
&gt; credited" with 543 days of good conduct.

The article continues, noting that the chap served four years of a seven
year sentence for robbery.  Since the release, he has been charged with two
murders, an attempted murder and two robberies.  The attempted murder charge
could be upgraded as the victim has since died.

Robinson points out in the article that corrections officials have a
"monumental problem" in calculating good time under incentive programs
linked to behavior, work, education and prison crowding.  "The difficulty is
compounded ...  when overlapping or concurrent sentences are involved."

Refreshingly, a `computer error' is not yet being pointed to as the problem.
But as I read this, I have visions of politicians looking for ways to automate
the process `to avoid this tragedy in the future.'  Should this occur, one
wonders how to design the bookkeeping problem so it fails safe.  Regardless, we
have yet another example for my software engineering class who occasionally
will ask ``why do I care about fancy techniques to test a spreadsheet -- its
not like I'm writing a program that lives will depend upon.''

When the system dumps core, just dial 911, right?
                                                            Jim

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Re: Hi-tech advertising
</A>
</H3>
<address>
Brinton Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Wed, 26 Sep 90 17:04:50 EDT
</i><PRE>

Dave Turner reports on advertising in which floppy disks touting some
product are "junk mailed" to our homes.  He correctly observes:

	"...the risk of viruses spreading will increase rapidly. A few
	thousand deviant floppies sent to several large corporations and
	schools will produce marvelous results."

I've been reading RISKS-Digest for several years and (erroneously?)
consider myself well-informed on topics of interest here.  Yet, as I
read Dave's item, the risk which he states so well DID NOT OCCUR TO ME
UNTIL I READ HIS LAST PARAGRAPH!  This leads to one of two conclusions:

	a. In spite of our good efforts to be vigilant, the plethora of
new methods of attack overwhelms our defenses.

	b. I turn off my thinking apparatus when reading e-mail.

In case it's "a," many of us need to be more wary.

_Brint

</PRE>
<HR><H3><A NAME="subj6.2">
Re: Reliability of the Space Shuttle (<A HREF="/Risks/10.45.html">RISKS-10.45</A>)
</A>
</H3>
<address>
Chris Jones
&lt;<A HREF="mailto:clj@ksr.com ">
clj@ksr.com 
</A>&gt;
</address>
<i>
Wed, 26 Sep 90 16:44:52 EDT
</i><PRE>

&gt;			       I would like to simply point out that the space
&gt;shuttle has had many more successful launches than any other launch system
&gt;employed to date.

Hardly.  The US space shuttle has had many more successful launches than any
other launch system for US manned spacecraft.  Almost every Soviet launch
system has had many more successful launches (including the SL-4, used to
launch every Voskhod and Soyuz manned spacecraft), and many US unmanned launch
systems have exceeded the shuttle's totals as well.

Chris Jones    clj@ksr.com    {world,uunet,harvard}!ksr!clj

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Reliability of the Space Shuttle
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Thu, 27 Sep 90 13:03:43 EDT
</i><PRE>

&gt;... I would like to simply point out that the space
&gt;shuttle has had many more successful launches than any other launch system
&gt;employed to date...

Surely Peter jests.  The Soviet "A" booster, in several variants, has been
launched successfully over 1000 times.  This is more than all Western
launch systems, including the shuttle, put together.  By normal aviation
standards, this is the *only* space launcher that has been properly
tested.  (A new aircraft typically flies hundreds or thousands of times
before it is released to customers.)

Perhaps he meant only Western launchers?  Even there, this is grossly
wrong.  The user's manual for Scout, the smallest of the "traditional"
US boosters, lists 77 successful launches.  I'm fairly sure that Delta
beats that, and Atlas and Titan probably likewise.

Perhaps he meant only manned launchers?  Sorry, I think the "A" booster wins
again.  It has launched every Soviet manned mission, from Gagarin to the Mir
crews.
                           Henry Spencer at U of Toronto Zoology   utzoo!henry

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Automated vehicle guidance systems
</A>
</H3>
<address>
Will Martin 
&lt;<A HREF="mailto:wmartin@STL-06SIMA.ARMY.MIL">
wmartin@STL-06SIMA.ARMY.MIL
</A>&gt;
</address>
<i>
Mon, 10 Sep 90 13:36:06 CDT
</i><PRE>

There is a program called "European Journal" which is aired on PBS (and, I
suppose, some cable channels). In the program broadcast on Sunday, Sept. 9
on KETC in St. Louis, I saw a segment on automated vehicle guidance systems
that are being installed in Britain and Germany (I'd say "West Germany" but
it may not be that when you read this... :-). This was a system designed to
route traffic around snarls, tieups, and gridlocks, providing the driver the
"best" [see below] route to a punched-in destination from the current site.

The system depends on traffic-light-mounted signal sources, which seemed to
be infrared emitters. The dashboard contains an LCD-type display that
has arrows displayed indicating to the driver which turn should be taken
next. Interestingly, the philosophy of operations varies between the two
installations. In Britain, this is a private-enterprise venture, and the
spokesperson stated that their aim was to provide the driver with the 
best route from the driver's point of view. In Germany, this is a
government activity, and the aim is to provide the most efficient
traffic flow throughout the city. (I suppose individual drivers could be
shunted into dead ends or off the street into a canal or something if it
would make the traffic flow as a whole work better. :-) This is, of
course, the RISK -- will the system's advertised philosphy be the one
that really controls its operation?

The British system sounded expensive to me -- $400 initial fee, plus a
$200 per year subscription. Interviews with potential customers didn't
sound too promising; no one seemed interested in spending that much for
what it would give them -- they figured they could do it well enough for
themselves. Don't know what the German costs will be, or who will use it.

The point of what would happen if the driver "disobeyed" the system or
violated a traffic regulation (like running a red light) was asked. The
British spokesman said their system was in no way limiting; they were
only trying to help the driver, and that there was no way that violations
of traffic rules would be reported. No mention was made of the German 
situation. (I suppose the next infrared sensor/transmitter unit to pick
up the offending car there melts it with a laser or something... :-)

The "fail" mode of the display, if the driver ignores the turn-indicating
arrow and goes straight, for example, was interesting.  It seemed to take
the rejection of the recommendation as a negation of the program, and
displayed a rosette of arrows pointing in every possible direction.  If the
thing had a voice unit, I would have expected it to say something like,
"WELL!  If YOU want to go your OWN way, don't pay any attention to ME!  Go
ANYwhere YOU like!" :-)

Regards, Will Martin
wmartin@st-louis-emh2.army.mil OR wmartin@stl-06sima.army.mil

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard_Busch.sd@xerox.com">
Richard_Busch.sd@xerox.com
</A>&gt;
</address>
<i>
Fri, 28 Sep 1990 10:37:47 PDT
</i><PRE>
Subject: Computer 'error' in the British RPI

In his Tue, 25 Sep 1990 11:50:53 PDT Peter G. Neumann quotes from Computing
(UK), 20 September 1990, submitted by Dorothy R.Graham:

&gt;A 1% error in the British RPI cost the government 121M pounds ...a computer
error caused the RPI to be understated from February 1986 to October 1987.  The
programs had been tested, but the tests did not reveal the error.&lt;

It is perhaps worth mentioning that the current UK Government has made control
of inflation, measured by the RPI, one of the main items on its agenda, and
that a General Election occurred during the stated period.

Taking this in combination with the use of the Falklands / Malvinas War for
electoral purposes, with the deliberate massaging of official statistics
(particularly on unemployment) since 1979, to such a degree as to cause
near-mutiny in the Government Statistical Service, and with the general
cynicism of the present UK Government, the uncharitable might suggest that the
'error' was no more than another episode of electoral 'management' on the UK
Government's part, and that 121 million pounds would be considered a small
price to pay for re-election by people as power-hungry as Margaret Thatcher.

The 'secondary RISK' of people becoming so accustomed to computer 'error' as to
be willing to accept it as fact rather than to suspect deliberate manipulation
of computer-resident data has already been discussed in RISKS.
                                                                    Chaz

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.45.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.47.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-20</DOCNO>
<DOCOLDNO>IA013-000136-B029-407</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.47.html 128.240.150.127 19970217040330 text/html 32996
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:01:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 47</TITLE>
<LINK REL="Prev" HREF="/Risks/10.46.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.48.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.46.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.48.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 47</H1>
<H2> Thursday 4 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  California DMV and their new computer 
</A>
<DD>
<A HREF="#subj1.1">
Cecil Lee
</A><br>
<A HREF="#subj1.2">
 Cecil Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Report of Nat Semi clock chip flaw 
</A>
<DD>
<A HREF="#subj2.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  BA 747-400 Engine Failure 
</A>
<DD>
<A HREF="#subj3.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Novel on corporate computer espionage 
</A>
<DD>
<A HREF="#subj4.1">
Philip Brewer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  CERT Advisory - NeXT systems 
</A>
<DD>
<A HREF="#subj5.1">
Edward DeHart
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Fair Information Principles 
</A>
<DD>
<A HREF="#subj6.1">
Jeff Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Television rating [nee universal listening] device 
</A>
<DD>
<A HREF="#subj7.1">
Tim Wood
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  From under a Rock??? [Subliminal message lawsuits] 
</A>
<DD>
<A HREF="#subj8.1">
Ed Hall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Operation Sun Devil invades the InterNet?     
</A>
<DD>
<A HREF="#subj9.1">
Ed Luke via Michael Packer via John M. Chapin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
California DMV and their new computer
</A>
</H3>
<address>
Master Of Darkness 
&lt;<A HREF="mailto:clee@td2cad.intel.com">
clee@td2cad.intel.com
</A>&gt;
</address>
<i>
Sat, 29 Sep 90 21:57:26 PDT
</i><PRE>

	I just received my registration notice from the DMV (Department
of Motor Vehicles).  This piece of paper shows the amount of money I
need to pay, so that I can drive my car for the next year in California.

	Imagine my surprise when I saw the amount: $2214.  An extremely big
surprise since I only paid ~$600 last year, when I purchased the car new.  The
reason for this new method of making money?

	This is the excuse from the clerks at the DMV.  Seems that they have
just started using a new computer program for billing purposes, apparently on
their new Tandem computers.  Surprise Surprise it seems that everybody who got
a recent registration statement, has an invalid amount.  I had to go to the
local office so that they could print up a new form with the correct amount.  I
don't know if registration statements were the only incorrect items produced.
They didn't volunteer the information and I didn't ask.

	Supposedly some people received bills for less then the correct amount.
I wonder if they will still get their registration tags when (if) the computer
notices the underpayment.  Will those who might have paid too much get refunds?

	BTW, the correct amount I'm supposed to pay?  $351.
 
          Cecil Lee, Intel Corp. 

CLee@SC9.INTEL.COM or CLee%SC9%SC.INTEL.COM@RELAY.CS.NET
UUCP : {pur-ee,qantel,amdcad,oliveb,decwrl,hplabs}!intelca!mipos3!sc9!clee

</PRE>
<HR><H3><A NAME="subj1.2">
California DMV Troubles
</A>
</H3>
<address>
Master Of Darkness 
&lt;<A HREF="mailto:clee@td2cad.intel.com">
clee@td2cad.intel.com
</A>&gt;
</address>
<i>
Sun, 30 Sep 90 16:42:30 PDT
</i><PRE>

The following was an article in the Sept 30, 1990 issue of "The Argus."
One of the local papers in the SF Bay area.

DMV computer goof overbills car owners
By Mark van de Kamp (staff writer)

	Sham Dixit of Livermore was one of many California drivers who felt
they were being asked to pay too much when they got notices this week to renew
their motor vehicle registrations between now and November.  And they were
right.  The state Department of Motor Vehicles admitted Friday that it had made
a blunder which caused some drivers to be overbilled by hundreds, even
thousands of dollars.  In Dixit's case, he was asked to pay $2,832 for his 1987
Nissan Sentra.  It cost him $166 to register the car last year.  Likewise,
three members of a Pleasanton family were overbilled by $1,000 each.

	The DMV does not know how many vehicle registrations are involved.
There are 25 million registered vehicles in the state.  The agency said the
incorrect billing notices involve drivers whose vehicle registration was set to
expire Nov. 16, 18 and 20.  Most of the incorrect bills arrived in mailboxes
Thursday and Friday.  [...]

	The problem surfaced late Thursday when DMV offices started receiving
calls from motor vehicle owners asking why registration fees had changed
significantly from the previously year, the agency said.  "At first thought I'd
made a mistake.  Then I heard that the DMV screwed up.  Boy, did they ever,"
Dixit said.  "But I work with computers, so I know it must be a programming
error.  Computers are only as smart as the people who use them." [...]

          Cecil Lee, Intel Corp.                   [PGN Excerpting Service]

CLee@SC9.INTEL.COM or CLee%SC9%SC.INTEL.COM@RELAY.CS.NET
UUCP : {pur-ee,qantel,amdcad,oliveb,decwrl,hplabs}!intelca!mipos3!sc9!clee

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Report of Nat Semi clock chip flaw
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Thu, 4 Oct 90 12:38:35 BST
</i><PRE>

Electronics Times (4 Oct, front page) reports that National Semiconductor's
real-time clock chip (part number MM58274B) "has a tendency to switch from a
24hr clock to a 12hr clock when subjected to electronic noise ..".

Two examples are given of problems allegedly caused by the chip.

"... the chip caused the time clock in a financial system to skip from
Thursday to Saturday, leaving employees without paychecks".

"It has also caused problems for the United Nations Atomic Energy Agency
which uses the chip in a televised security system for guarding nuclear fuel
.... ".

Martyn Thomas, Praxis (Software Engineers), 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
BA 747-400 Engine Failure
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Wed, 3 Oct 90 15:21:58 BST
</i><PRE>

Flight International (3-9 October) reports that a British Airways Boeing
747-400's No 1 engine electronic controls failed on takeoff at London
Heathrow causing the engine to shut down.

The crew [two pilots, there is no flight engineer] reported the status
message "engine controls" and asked their technical support staff, by radio,
for advice. They were told "You've obviously lost control of that engine.
It's a FADEC failure" [FADEC = Full Authority Digital Engine Controller].

BA says that the problem was a spurious signal from the electronic "thrust
reverse resolver". If so, the early diagnosis of FADEC failure could be
wrong. There has been a number of instances of spurious signals causing
747-400 engines to throttle back or shut down, according to Flight [ This
may be a reference to the earlier reports of spurious signals from flap and
gear sensors, reported in an earlier RISKS].

Flight adds that FADEC failure is extremely unusual.

Martyn Thomas, Chairman, Praxis plc. Software Engineers.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
   Equinox on the A320: Programme summary
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
1 Oct 1990 14:29:40-BST
</i><PRE>

Below is a summary of the Channel 4 (UK TV) programme on the A320
transmitted at 7pm Sunday 30 September.  I took notes during the
programme but I may have got some details wrong.

Equinox asked an independent air accident investigator named Ray Davis to
examine the report on the Habsheim crash where an A320 being flown in a display
made a slow pass over the runway and could not pull up in time to avoid the
trees at the end of the airport.  He made four major findings which were put to
the Chief engineer (I think) at Airbus Industries.

1: A 4 second discrepancy between the Cockpit Voice Recorder, the
   Aircraft Data Recorder and the Tower Voice Recorder.  Sorry but I
   cannot remember the Airbus reply to this.

2: There was no record of the impact with the trees in the flight
   data.  This might be expected in (say) a collision with a mountain,
   but the recorders should have been able to operate until the
   aircraft disintegrated.  Any crash which could be survived by all
   but three passengers should not have caused an abrupt stop in the
   flight data record.  Again I cannot recall the Airbus reply.

3: The final seconds of the record showed forward acceleration.  The
   airbus Chief Eng claimed that Davis had this graph upside down and
   a positive reading indicated deceleration.  He also claimed that
   the deceleration was caused by the trees, and that Davis was
   incompetent if he did not know that this format was an
   international standard.  Equinox stated that the international
   standard was for a forward acceleration to give a positive reading
   and that this was the one used by the A320.  Airbus later stated
   that the CE had been referring to a French standard.

4: The final seconds of the record also showed the pilot giving full
   stick back but being overridden by the computer.  The CE stated
   that this was the safety systems stopping the aircraft from
   stalling.  Equinox said something about the Pilot manuals saying
   that at the indicated airspeed the aircraft should have been able
   to climb.

The possibility of an engine compressor stall leading to loss of power was
discussed.  According to Equinox this would lead to a small explosion (I assume
this would be as unburnt fuel vapour was pushed out of the tailpipe) and a drop
in power.  A survivor and a ground witness stated that they had heard such
explosions, but Airbus deny they occurred and point out that no such explosions
are audible on the videotapes.  An early transcript of the CVR did include the
text "(boume) (boume)" (sp?).  Airbus claim this is the sound of impact with
trees.

About 30 seconds were devoted to a pilot employed by Airbus who had publicly
spoken out in support of Capt. Asseline (sp?) who was the pilot at Habsheim.
This pilot claimed that 4 days later he was given an unscheduled medical
examination and had his license withdrawn due to "mental instability".

The authenticity of the "black boxes" recovered from the crash was
questioned.  Officially the boxes are being held by a French court.
Equinox was not allowed to film these, but a magistrate looked at a
video alleged to be of the boxes immediately after being removed from
the crash site and stated that if these were in fact the boxes from
the A320 then something was very wrong.  The implication was that the
boxes delivered to the court were not the boxes recovered from the
crash.

A video of the programme can be obtained by phoning +44 532 438283
ext. 4060 or 4075.

BTW, one of the interviewees had a box file labeled "RISKS" in the
background.  Perhaps he could fill in the holes in my report.  Thanks.

Please note that this report is in no way connected with my employers.  Paul.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Novel on corporate computer espionage
</A>
</H3>
<address>
&lt;<A HREF="mailto:pbrewer@urbana.mcd.mot.com">
pbrewer@urbana.mcd.mot.com
</A>&gt;
</address>
<i>
Tue, 02 Oct 90 10:07:13 CDT
</i><PRE>

Corporate espionage by computer is the subject of a new novel _The
Fool's Run_ by John Camp.  When plans for the latest fighter plane
target acquisition hardware and software are stolen, a defense
contractor decides that only by sabotaging the development work of a
competitor can it be sure of being the only company in a position to
demonstrate the system by the deadline.  The company hires Mr. Kidd
(artist, software designer, former commando) to invade the competitor's
computers and disrupt their operations for a few weeks.  They say:

    the best way ... is through their computer systems--design systems,
    accounting systems, information systems, scheduling and materials.
    Altering them, destroying them, faking them out.

In the style of a classic caper novel, Kidd assembles a team including a
burglar and a sleezy reporter and attacks the defense contractor,
disrupting their operations from all sides.

The author handles the computer entry techniques well.  There is only a
small amount of "magic" involved, and most of that is performed in the
background by "Bobby" (a former phone-phreak we meet only by way of a
data link) who handles such things as telephone trace bypasses.  The
discussions of computer security techniques are right on target, and the
supposed level of security at the target company is on par with what
I've seen at several of the places I've worked.  When it comes to the
actual disruptions things get a little fuzzier, although not to the
point that it fails to work as a novel.

In real life, most malicious computer attacks have been committed by
disgruntled employees or former employees.  Most computer viruses have
been written by misguided enthusiasts.  I haven't heard of this kind of
attack against one company by another.  That doesn't mean it hasn't
happened, and it certainly doesn't mean that it won't happen.  I fear,
this book may give some people ideas.

Camp, John _The Fool's Run_ ISBN 0-451-16712-0 Signet $4.95

Philip Brewer                   pbrewer@urbana.mcd.mot.com
Motorola Urbana Design Center   ...!uiucuxc!udc!pbrewer

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
CERT Advisory - NeXT systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:cert-advisory-request@cert.sei.cmu.edu">
cert-advisory-request@cert.sei.cmu.edu
</A>&gt;
</address>
<i>
Tue, 2 Oct 90 14:57:03 -0400
</i><PRE>

CA-90:06                       CERT Advisory
			      October 2, 1990
                          NeXT's System Software

This message is to alert administrators of NeXT Computers of four
potentially serious security problems.

The information contained in this message has been provided by David Besemer,
NeXT Computer, Inc.  The following describes the four security problems,
NeXT's recommended solutions and the known system impact.

  Problem #1 DESCRIPTION:  On Release 1.0 and 1.0a a script exists in
  /usr/etc/restore0.9 that is a setuid shell script.  The existence of  
  this script is a potential security problem.

  Problem #1 IMPACT:  The script is only needed during the installation
  process and isn't needed for normal usage.  It is possible for any
  logged in user to gain root access.

  Problem #1 SOLUTION:  NeXT owners running Release 1.0 or 1.0a should  
  remove /usr/etc/restore0.9 from all disks.  This file is installed by  
  the "BuildDisk" application, so it should be removed from all systems  
  built with the standard release disk, as well as from the standard  
  release disk itself (which will prevent the file from being installed  
  on systems built with the standard release disk in the future).  You  
  must be root to remove this script, and the command that will remove  
  the script is the following:

  # /bin/rm /usr/etc/restore0.9

                                    ---

  Problem #2 DESCRIPTION:  On NeXT computers running Release 1.0 or
  1.0a that also have publicly accessible printers, users can gain
  extra permissions via a combination of bugs.
  
  Problem #2 IMPACT:  Computer intruders are able to exploit this security
  problem to gain access to the system.  Intruders, local users and remote
  users are able to gain root access.

  Problem #2 SOLUTION:  NeXT computer owners running Release 1.0 or  
  1.0a should do two things to fix a potential security problem.   
  First, the binary /usr/lib/NextPrinter/npd must be replaced with a  
  more secure version.  This more secure version of npd is available  
  through your NeXT support center.  Upon receiving a copy of the more  
  secure npd, you must become root and install it in place of the old  
  one in /usr/lib/NextPrinter/npd.  The new npd binary needs to be  
  installed with the same permission bits (6755) and owner (root) as  
  the old npd binary.  The commands to install the new npd binary are  
  the following:
  
  # /bin/mv /usr/lib/NextPrinter/npd /usr/lib/NextPrinter/npd.old
  # /bin/mv newnpd /usr/lib/NextPrinter/npd
	  (In the above command, "newnpd" is the npd binary
	  that you obtained from your NeXT support center.)
  # /etc/chown root /usr/lib/NextPrinter/npd
  # /etc/chmod 6755 /usr/lib/NextPrinter/npd
  
  The second half of the fix to this potential problem is to change the  
  permissions of directories on the system that are currently owned and  
  able to be written by group "wheel".  The command that will remove  
  write permission for directories owned and writable by group "wheel"  
  is below.  This command is all one line, and should be run as root.
  
  # find / -group wheel ! -type l -perm -20 ! -perm -2 -ls -exec chmod  
  g-w {} \; -o -fstype nfs -prune

                                    ---

  Problem #3 DESCRIPTION:  On NeXT computers running any release of the
  system software,  public access to the window server may be a
  potential security problem.

  The default in Release 1.0 or 1.0a is correctly set so that public access
  to the window server is not available.  It is possible, when upgrading from
  a prior release, that the old configuration files will be reused.  These
  old configuration files could possibly enable public access to the window
  server.

  Problem #3 IMPACT:  This security problem will enable an intruder to gain
  access to the system.

  Problem #3 SOLUTION:  If public access isn't needed, it should be disabled.

  1. Launch the Preferences application, which is located in /NextApps
  2. Select the UNIX panel by pressing the button with the UNIX
     certificate on it.
  3. If the box next to Public Window Server contains a check, click on
     the box to remove the check.

                                    ---

  Problem #4 DESCRIPTION: On NeXT computers running any release of the
  system software, the "BuildDisk" application is executable by all users.

  Problem #4 IMPACT:  Allows a user to gain root access.

  Problem #4 SOLUTION: Change the permissions on the "BuildDisk" application
  allowing only root to execute it.  This can be accomplished with the
  command:

  # chmod 4700 /NextApps/BuildDisk

  To remove "BuildDisk" from the default icon dock for new users, do the
  following:

  1. Create a new user account using the UserManager application.
  2. Log into the machine as that new user.
  3. Remove the BuildDisk application from the Application Dock by dragging
     it out.
  4. Log out of the new account and log back in as root.
  5. Copy the file in ~newuser/.NeXT/.dock to /usr/template/user/.NeXT/.dock
	(where ~newuser is the home directory of the new user account)
  6. Set the protections appropriately using the following command:
        # chmod 555 /usr/template/user/.NeXT/.dock
  7. If you wish, with UserManager, remove the user account that you created
     in step 1.

  In release 2.0, the BuildDisk application will prompt for the root password
  if it is run by a normal user.

 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

CONTACT INFORMATION
 
For further questions, please contact your NeXT support center.

NeXT has also reported that these potential problems have been fixed in
NeXT's Release 2.0, which will be available in November, 1990.

Thanks to Corey Satten and Scott Dickson for discovering, documenting, and
helping resolve these problems.

Edward DeHart, Computer Emergency Response Team/Coordination Center (CERT/CC)
Software Engineering Institute, Carnegie Mellon University Pittsburgh, PA
15213-3890       E-mail: cert@cert.sei.cmu.edu
Telephone: 412-268-7090 24-hour hotline: CERT personnel answer
           7:30a.m.-6:00p.m. EST, on call for emergencies other hours.

Past advisories and other information are available for anonymous ftp
from cert.sei.cmu.edu (128.237.253.5).

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Fair Information Principles
</A>
</H3>
<address>
Jeff Johnson 
&lt;<A HREF="mailto:jjohnson@hpljaj.hpl.hp.com">
jjohnson@hpljaj.hpl.hp.com
</A>&gt;
</address>
<i>
Wed, 03 Oct 90 14:40:57 PDT
</i><PRE>

This is a summary of the Fair Information Principles, excerpted with permission
from an e-mail message sent by Marc Rotenberg, directory of CPSR's Washington
D.C. office and head of its Computers and Civil Liberties Project.

I thought RISKS readers might be interested.

FAIR INFORMATION PRINCIPLES

The Fair Information Principles were developed by a U.S. Government
Study Committee in 1973, chaired by Willis Ware of the Rand
Corporation.  Shortly after the commission released its final report
("Records, Computers and the Rights of Citizens"), Congress passed
comprehensive privacy legislation:  the Privacy Act of 1974.  Much of
the privacy law that followed the Privacy Act (e.g., the Right to
Financial Privacy Act, the Cable Policy Act, the Electronic
Communications Privacy Act, and the Video Privacy Protection Act) are
based on the Fair Information Principles.

Many other countries follow the Fair Information Principles.  Recently
in Paris, European Data Protection commissioners recommended that the
EC 92 charter include mandatory provisions for the enforcement of Fair
Information Principles across all European countries.

These are the Principles:

1. There must be  a way for a person to prevent information about the
person that was obtained for one purpose from being used or made
available for other purposes without the person's consent.

2. There must be no personal data record-keeping systems whose very
existence is secret.

3. There must be a way for a person to find out what information about
the person is in a record and how it is used.

4. There must be a way for a person to correct or amend a record of
identifiable information about the person.

5. Any organization creating, maintaining, using, or disseminating records of
identifiable personal data must assure the reliability of the data for their
intended use and must take precaution to prevent misuses of the data.

Jeff Johnson, HP Labs

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Television rating (nee universal listening) device
</A>
</H3>
<address>
Tim Wood at home
&lt;<A HREF="mailto:tim@axolotl.UUCP ">
tim@axolotl.UUCP 
</A>&gt;
</address>
<i>
Mon, 1 Oct 90 11:30:28 PDT
</i><PRE>

Found in the Oakland Tribune "Patents" column, Oct. 1, reprinted from 
The New York Times:

	    In search of a more accurate way to measure television and
	radio audiences, a small company in Chicago has patented a 
	pocket-sized device that silently monitors and logs the 
	programs a person listens to.
	    The battery-powered device is based on "acoustic matching."
	[this term is not precisely defined] ... [A] microphone senses 
	sounds near the person being monitored and a microprocessor
	converts these sounds into a digital code.
	    ... Users would place the monitoring devices on
	battery chargers when they go to bed.  The battery charger 
	would be connected to a telephone line, enabling the device to
	transmit the day's data to a central computer at the audience
	measurement company.

Hope all of your RISKS alarms are ringing as loudly as mine are.  The
frightening prospect of creation of libraries of users' private sounds 
comes to mind.  As does the funny, if Machiavellian, image of public 
broadcasting of these sounds, a la the tryst between Majors Hoolihan
and Burns in the movie "MASH."  

This development is interesting in light of (what I see as) a duality
in society`s view of high tech of simultaneous infatuation and distrust.
Hopefully the latter view will be applied to the new device.
-TW

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
From under a Rock???
</A>
</H3>
<address>
Ed Hall 
&lt;<A HREF="mailto:edhall@rand.org">
edhall@rand.org
</A>&gt;
</address>
<i>
Thu, 04 Oct 90 11:56:40 PDT
</i><PRE>

I've been loosely following the various ``subliminal message'' lawsuits which
have been winding their way through the courts recently.  These are
product-liability suits alleging that subliminal messages in rock music have
driven people to suicide.  One such case, against British group Judas Priest,
was recently dismissed.  Another against Ozzy Osbourne is now pending.

There is a computer RISK here.  According to today's Los Angeles Times:

    ...  Sound Analyst Evans [a lecturer at Univ. of Nevada with
    masters degrees in physics and computer science] said she had
    spent about a month analyzing audio subliminal messages
    allegedly implanted on the "Blizzard of Oz" cassette using the
    same home-computer software package employed in the Judas Priest
    case. ...

I can only guess at what this "home-computer software package" is. (If
anyone has additional information about it, please let me know).  One
thing I'm sure of, however: it hardly affords an accurate model of human
auditory perception (unless its author has managed to leapfrog what
would no doubt be decades of neurophysiological research).  Its use in
court no doubt arises from the persisting association of The Computer
with unchallengeable accuracy and authority.

I foresee nothing but trouble in the interaction between the notion of
"subliminal messages" (whether auditory or visual) and the increasing
capability for computers to perform extensive signal processing--whether that
"processing" is meaningful or not.  As the recent "Face on Mars" flap
illustrates, people will see (or hear) just what they want to see (or hear),
given the tools to create "evidence".  Computers greatly enhance the power for
self-delusion.
               		-Ed Hall, 		edhall@rand.org 
[Disclaimer: This all is my personal opinion ONLY.]

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Operation Sun Devil invades the InterNet?
</A>
</H3>
<address>
John M. Chapin 
&lt;<A HREF="mailto:jchapin@Neon.Stanford.EDU">
jchapin@Neon.Stanford.EDU
</A>&gt;
</address>
<i>
Tue, 2 Oct 90 08:21:10 -0700
</i><PRE>

I found the following posting on alt.sex.pictures.d.  It is probably a hoax; in
particular, the "National Computing Defence Council" reference seems to be a
mistaken attempt to implicate the NCSC.  If not a hoax, the RISKS here are
appalling.  If this is a hoax, the RISK is that a climate of fear, created by
government use of computer monitoring, makes such hoaxes believable and hence
can limit the exercise of individual liberties.

Background: over the last year or so, sites offering X-rated bitmap archives
for anonymous FTP have been under increasing pressure to remove public access
to the files.  This message refers to one such site, the MARS bbs, that
recently caused a spate of complaints by removing access to its bitmaps.  "Gif"
is a popular format for the interchange of bitmap data.  The "bogus NSF story"
refers to a very real letter, sent to many archive administrators by an
individual within the NSF, threatening cutoff of funding due to illegal
non-academic use of the InterNet.

-John Chapin (jchapin@cs.stanford.edu)

 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =

From: pac@babcock.cerc.wvu.wvnet.edu (Michael Packer)
Newsgroups: alt.sex.pictures.d
Message-ID: &lt;847@babcock.cerc.wvu.wvnet.edu&gt;
Date: 1 Oct 90 15:09:20 GMT

...this is a message that a friend of mine got off of their BBS:

[=                           copy of message                              =]

Posted By: lush (Ed Luke)
~Date:      Sat Sep 29 21:54:03 1990
~Title:     The story about the GIF files.

Ok, since everyone has been asking about the gif files, here's the story of
what happened with the gifs...  It seems that the secret service under
direction of Pres. Bush is on a campaign against computer crime. You've read
about some of this probably.  It's called Operation Sun Devil.  Some of the
older users will remember when this bbs was called the Pirates Resource BBS and
was on athena.ee.mssate.edu.  Well we eventually got shut down in a fashion
similar to that of the victims of operation sun devil.  However, in our case,
since we were such an allegedly large center for computer criminal activity,
the Secret Service, along with the National Computing Defence Council decided
to conduct an ongoing investigation.  If you want to catch mice, you don't just
plug their holes.  You lay traps.  Well they allowed us to set up again at mars
on the strict requirement that we would do strict accounting.  We have been
keeping records of every (timestamped) upload and download that's been made to
this board. In addition, in hopes of cooperating with the Feds for obvious
reasons, I instituted the monitoring system software on mars.  When anyone did
an ftp it logged the date, did a finger on the system that was connecting and
snarfed up the userid via ftp protocol and made a complete record of all files
downloaded and uploaded.  Also, users that download files from the bbs had the
machine name they were connecting to, and any other evidence collected in a
similar manner.  After enough information was collected, we gave them the reams
of data files and removed the gifs, giving y'all the bogus NSF story.  So there
it is.  The GIFS and GL's aren't the biggest part of the story, but they are
illegal in some states and the FCC has been interested in cracking down on
computer obscenity for a long time.  I can't say I like it, but that we have to
live with it.

Ed Luke

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.46.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.48.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-21</DOCNO>
<DOCOLDNO>IA013-000136-B029-443</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.48.html 128.240.150.127 19970217040342 text/html 26302
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:02:12 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 48</TITLE>
<LINK REL="Prev" HREF="/Risks/10.47.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.49.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.47.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.49.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 48</H1>
<H2> Tuesday 9 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Global warming or bad hardware? 
</A>
<DD>
<A HREF="#subj1.1">
Bob Campbell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Equinox on A320 
</A>
<DD>
<A HREF="#subj2.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Ada and multitasking 
</A>
<DD>
<A HREF="#subj3.1">
Erling Kristiansen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Arbitration Myths 
</A>
<DD>
<A HREF="#subj4.1">
Bernie Cosell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  California DMV and Italian publicity 
</A>
<DD>
<A HREF="#subj5.1">
Jon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Government routinely ignores Privacy Act 
</A>
<DD>
<A HREF="#subj6.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Computer sound editors are appropriate technology, not deceipt     
</A>
<DD>
<A HREF="#subj7.1">
David A. Honig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Operation Sun Devil invades the InterNet? 
</A>
<DD>
<A HREF="#subj8.1">
Jonathan I. Kamens
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Loving Little Egypt - phone freaks 
</A>
<DD>
<A HREF="#subj9.1">
Dick Karpinski
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  CERT Advisory Update - NeXT Systems 
</A>
<DD>
<A HREF="#subj10.1">
Ed DeHart
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Global warming or bad hardware?
</A>
</H3>
<address>
Bob Campbell 
&lt;<A HREF="mailto:campbelr@grendel.cup.hp.com">
campbelr@grendel.cup.hp.com
</A>&gt;
</address>
<i>
Tue, 9 Oct 90 15:12:54 mdt
</i><PRE>

Deep inside the October 9th, 1990 San Jose Mercury News was this piece
under the heading of "Unbelievably hot".

All sorts of explanations have been offered for record high temperatures across
the country - the greenhouse effect, the growth of cities, even chance.  But
the National Weather Service is examining and additional theory: The
thermometers were wrong.  The service is studying the thermometer at issue, an
electronic sensor called the Ho83.

Bob Campbell				campbelr@hpda.cup.hp.com

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Equinox on A320 (UK Channel 4, Sun., 30th Sep)
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Sat, 6 Oct 90 21:22:55 PDT
</i><PRE>

The 'Equinox' series of documentary programmes on science and technology on
Channel 4 of UK TV was devoted to the Airbus A320 last Sunday (30th Sep., 7 pm).
The one-hour film was made by Box Productions, main researcher Ben Hamilton.

A good summary of the programme has already appeared in <A HREF="/Risks/10.47.html">RISKS-10.47</A>, submitted
by someone identified only as 'Paul'. He observed that:

&gt; BTW, one of the interviewees had a box file labeled "RISKS" in the
&gt; background.  Perhaps he could fill in the holes in my report. 

That interviewee would have been Prof. Bev Littlewood, Director, Centre for
Software Reliability, City University. We monitor RISKS at the Centre,
and that box file does, in fact, contain printouts of the digests, so I can
fill in the holes (although Paul hasn't left many for me to fill in!).

The programme updated an earlier programme on 6th Nov. 1989 and included
much new material, in particular an independent analysis of transcripts of the 
data on the Digital Flight Data Recorder (DFDR) and Cockpit Voice Recorder 
(CVR) recovered after the crash at Mulhouse-Habsheim on 26th June 1988.
This was done by Ray Davis, ex-Accident Investigation Bureau, UK Department of 
Trade and Industry, and now an independent consultant. He produced a written 
report which was submitted to Airbus Industrie (AI) for comment.

Davis concluded that:
- The flight control systems were not obeying the pilot's commands to lift the
  aircraft just prior to impact. (This supports the contention of the pilot,
  Michel Asseline, that he had requested 'nose up' and hadn't got it.)
- The DFDR recording stops 4 seconds *prior* to impact with the trees. (Davis
  added that, in his entire career, he had *never* come across a similar
  instantaneous stoppage of a recorder.)
- There is no indication of longitudinal deceleration, such as would have 
  occurred due to impact with the trees, at the end of the recording.
- During the last part of the recordings, the DFDR and CVR are 4 seconds out of
  sync. (This is interesting in the light of the claim by AI that Asseline had
  not allowed sufficient time (7 sec.) for the engines to spool up to full
  power.)

Bernard Ziegler (Vice President, Engineering, Airbus Industrie) predictably
dismissed Davis' report, describing it as 'pitiful'. He claimed that Davis
had misunderstood the sign convention for acceleration/deceleration. In fact,
according to the ARINC international conventions, Davis was right, and Ziegler
was wrong. The point was put to Ziegler five times by the Equinox team, and
each time he repeated this assertion. He then ended up with egg on his face
when his own organisation, AI, were obliged to retract, explaining that
Ziegler had misunderstood, and had been using a French convention instead of
the international one.

On one point, Ziegler appeared to accept Davis' findings, when he claimed
that the safety systems were working to prevent a stall (i.e., overriding
the pilot's request for 'nose up'). Asseline claims that the aircraft had 
sufficient speed and power to clear the trees without stall.

Air France, and the Bureau Enquetes Accidents who produced the original
accident report, refused to be interviewed. The copilot at Mulhouse, Jaques
Mazieres, is still flying for Air France, and so also not available.

Davis stated that there must now be another enquiry, and that this must take
account of the improper pressure being applied in certain quarters. (Asseline
has received threats; Norbert Jaquet, an Air France pilot who spoke out in
Asseline's support, was suspended from duty and had his licence withdrawn on
the grounds of 'mental instability'.)

Even the authenticity of the recorders was called into question. The boxes
were filmed last year by Equinox in the boot of the car of the director of
the DGAC at the scene of the crash, and a French journalist also saw them.
According to Asseline, those produced at the enquiry do not resemble these.
The original investigating magistrate at Mulhouse, Germain Sengelin, said
that there was a 'problem in relation to justice'. (The present magistrate
has obtained an independent report on the evidence used by the commission
of enquiry, which also concludes that there is serious doubt over the
authenticity of the recorders and the readouts made from them.)

The programme went on to consider the crash of the A320 at Bangalore. A pilot
was interviewed saying that it was virtually unknown for an aircraft to lose
height in such a way in clear conditions on a landing approach. Air India has
now grounded all its A320s at enormous cost. Prince Dandonda (sorry - no note
of his job title) was interviewed saying that they have never seen this amount 
of failures in an aircraft. One example was of a bird strike on the windscreen
resulting in a shut-down of three display computers, and causing the system to
shut down one engine.

There was an interesting example of Ziegler's logic concerning the Bangalore
crash: we know it wasn't bad weather, we know it wasn't bird strike, it
*can't* have been the aircraft systems, *therefore* it *must* have been
pilot error.

Davis' view is that a crash should be ascribed to 'pilot error' *only*
where there is positive proof. 'If you don't fully establish the cause of an
accident, then that accident will happen again.'

The programme concluded that, in the meantime, 'Air France and Airbus Industrie
must live with the fact that there is a question mark over the safety of the
A320.'

Peter Mellor, Centre for Software Reliability, City University, Northampton 
Sq., London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

    [My humblest apologies to Paul.  The From: field was deleted instead 
    of the To: field and paul accidentally remained anonymous.  PGN]
 
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Ada and multitasking
</A>
</H3>
<address>
&lt;<A HREF="mailto:EKRISTIA@ESTEC.BITNET">
EKRISTIA@ESTEC.BITNET
</A>&gt;
</address>
<i>
Mon, 08 Oct 90 10:28:12 CET
</i><PRE>

Re: "Ada's fundamental language structures build reliable systems", article by
    Benjamin M.Brosgol in EDN, September 3, 1990, international edition.

 The article starts:
 &gt;  Ada's principal goals are program reliability, readability, efficiency, and
 &gt;  portability. Many real-time application programs, such as those used in
 &gt;  avionics, telecommunications, and manufacturing, need these features
 &gt;  because of the large, complex, and long-lived pieces of software involved.

 The author then describes several features of the Ada language, such as data
 typing, separate compilation units, and concurrent tasks.
 The RISKy bit comes in the discussion of task priorities. It becomes clear that
 the Ada language falls short of completely and unambiguously defining how the
 task scheduler must deal with the priority issue, and that some freedom is left
 to the implementor in this area.

 The following quotes from the article give a flavour of the problem:

 &gt;  In addition, when a select statement has several open alternatives,
 &gt;  implementations need not take priorities into account when deciding which
 &gt;  one to accept. Instead, for example, they can take fairness criteria into
 &gt;  account.

 and

 &gt;  Ada language implementations can solve the problem of nondeterminism when
 &gt;  there are several open alternatives by providing directly or letting you
 &gt;  dictate the use of task priorities.

 The author does not seem to realize the contradiction between the
 *reliability* and *portability* quoted as features of Ada on one hand, and
 the lack of definition of crucial features on the other.

 Stated briefly, the RISK that I want to address is:
 A language which boasts high portability and reliability includes features
 which mean that there is no guarantee that a program will work the same way if
 ported to another compiler and/or run-time environment.

 Even worse:
 The potential differences are are hidden deeply below the "visible surface"
 of the program, and are implicit in nature. This means that the program will
 probably compile and link after being ported. It is also likely to show a very
 similar behaviour to the original so that a superficial testing may not reveal
 any problems. But problems may still be lurking in the dark corners of
 infrequent (but perfectly possible and legal) sequences of events. For example,
 superficial validation testing is likely to test mainly rather "quiet" modes
 with stimuli applied one at a time. But scheduler-related problems are more
 likely to show up when the software is very "busy", e.g. due to an abnormal
 or emergency situation creating many stimuli, such as alarms.

 A further RISK is that a language which is claimed to be designed for
 portability may encourage reduction in (costly and time-consuming) in-depth
 validation testing after porting the software to a different environment.

 In fact, the real RISK is maybe not that Ada has these shortcomings. The
 RISK, to my opinion, is that Ada, in spite of its shortcomings, claims to be
 highly portable and reliable.

 Does anybody have any experience (good or bad) in porting Ada programs, in
 particular real-time programs?

 Erling Kristiansen, European Space Research and Technology Centre,
 Noordwijk, The Netherlands.
 Usual disclaimers apply.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Arbitration Myths (Peter Denning, <A HREF="/Risks/10.42.html">RISKS-10.42</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:cosell@BBN.COM">
cosell@BBN.COM
</A>&gt;
</address>
<i>
Fri, 5 Oct 90 12:27:25 EDT
</i><PRE>

}As Peter observes, the only way to build a computer that is safe from
}"arbitration failure" is by making choice 1, which means that the computer must
}turn off its clock while waiting for an arbiter to decide.  Note that the
}computer can't keep its clock ticking while waiting for the arbiter to make up
}its mind, since it would then require another arbiter to decide within the
}current clock cycle whether or not the first arbiter had made up its mind.  I
}know of no computer that turns off its clock in this way.

The DEC PDP-6 line worked this way.  It was a fully asynchronous CPU
and would happily wait for as long as it took for an operation to
complete.  At MIT they had one word of memory implemented out of
elevator relays [2 second read time or the like].  The 'flow chart' for
how long a simple 'add' instruction took took up two pages in the
manual [including delays for waiting for the memory, delays for carry
propagation, etc].
                                                      /Bernie\

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
California DMV and Italian publicity
</A>
</H3>
<address>
A Product of Society
&lt;<A HREF="mailto:jon@pacbell.UUCP   ">
jon@pacbell.UUCP   
</A>&gt;
</address>
<i>
Sat, 06 Oct 90 15:39:06 PDT
</i><PRE>

I have nothing against Italians, only against ignorant Public Relations people.

    A month ago my mom got a letter in the mail, from the California DMV.  On
behalf of the Italian community, it said, (who had recently launched a PR stunt
against anti-italian bumber stickers and etc) she would have to change her
license plate.  Her plate read "WOPER1", comming from a feminist's word "WOman
PERson".  The '1' was there because the "lisence plate bible" reported that
someone already had WOPER.
    The Italian PR guy had the DMV search their computers for any string
containing WOP.  There's a risk here, no doubt: My mom's plate had *nothing* to
do with Italians, and there are plenty of words that grep might pick up, all
containing WOP.
    My mom wrote an extremely formal letter (she's an attorney, after all, and
that's good for *something* :) to the DMV, and they apologized over the phone.
They would change the plate, however, to "WO PER", with half a space, to
distinguish this word from any anti-Italian slang.  They also reported that
the first person having "WOPER" no longer had the plate, and "WOPER" was
available for use.
    The plate arrived last week.  It read "WOPER".  Nice job on behalf of the
DMV.  The bill for the plate read $1,200.  There's a connection here...
    The *actual* bill was $108.xx, because of the recent computer foul up,
posted in the last issue.

    Should agencies like the DMV be allowed to just 'grep' a database on behalf
of a PR stunt for *any* phrase containing "WOP"?  Something is wrong here.
Next thing you know, colleges will be scanning their applications for last
names ending in "ez" to fill some quota of Mexican students.  Mexicans aren't
the *only* people whose last names might end in --ez, just as WOP-- isn't
*always* a derogatory slang against Italians!

    Computers are becomming more useful to the tools of prejudice.

Jon   ..?$!..ames!pacbell!sactoh0!vector0!jon     vector0!jon@sactoh0.SAC.CA.US

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Government routinely ignores Privacy Act
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Tue,  9 Oct 90 15:01:14 PDT
</i><PRE>

Excerpted from Gov't Computer News, 10/1/90:

    Agencies violated the Privacy Act 292 times last year by
    failing to notify the public about a third of their largest
    personal record systems . . . The report by GAO's Information
    Management and Technology Division, Computers and Privacy
    said many agencies ignored the Privacy Act's publication
    requirements and did not issue Federal Register notices for
    35 percent of their personal records systems . . .

    The Defense Department reproted the most systems covered by
    the law with 360, followed by the the departments of Health
    and Human Services with 210, Justice with 169,, and
    Agriculture with 87.  However, agencies published notices for
    only 535 systems . . .

    46 agencies told they participated in computer matches . . .
    The report said 4.32 million matches, 78% of the total, were
    done for law enforcement purposes.  Another 16,245 were for
    tax purposes, and 10,028 involved queries on delinquent
    payments.  The Drug Enforcement Administration and Farmers
    Home Administration accounted for 97% of all matches.

I observe that many federal criminal databases are not even covered by the
Privacy Act's provisions, and that computer matching of government databases
was supposedly prohibited by the Privacy Act.  [CJ]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
computer sound editors are appropriate technology, not deceipt
</A>
</H3>
<address>
"David A. Honig" 
&lt;<A HREF="mailto:honig@ICS.UCI.EDU">
honig@ICS.UCI.EDU
</A>&gt;
</address>
<i>
Mon, 08 Oct 90 16:43:44 -0700
</i><PRE>
 
In <A HREF="/Risks/10.47.html">RISKS-10.47</A>, Ed Hall &lt;edhall@rand.org&gt; writes:
&gt; There is a computer RISK here.  According to today's Los Angeles Times:

    ...  Sound Analyst Evans [a lecturer at Univ. of Nevada with
    masters degrees in physics and computer science] said she had
    spent about a month analyzing audio subliminal messages
    allegedly implanted on the "Blizzard of Oz" cassette using the
    same home-computer software package employed in the Judas Priest
    case. ...

&gt;I can only guess at what this "home-computer software package" is. (If
&gt;anyone has additional information about it, please let me know).  

There are several programs that allow one to aquire, process, and
play-back sound on various PCs.  The analyst in this case would be
most interested in playing sound back time-reversed, perhaps with some
equalization afterwards.  She would try different transforms
exhaustively to see if she could hear any nasties.

This of course is identical to what one can do with a magnetic tape player, 
or a phonograph if one is willing to trash the disk and needle.

I would expect that the expert witness would have to explain her
methods and tools to the court.  I see nothing even implicitly
deceitful in using a Macintosh to play sound backwards...

He continues:

&gt;thing I'm sure of, however: it hardly affords an accurate model of human
&gt;auditory perception (unless its author has managed to leapfrog what
&gt;would no doubt be decades of neurophysiological research).  

Huh?  The analyst is just playing the sound back, not doing
*pattern-matching* for curses in latin backwards...

&gt;Its use in court no doubt arises from the persisting association of
&gt;The Computer with unchallengeable accuracy and authority. 

Its use in court is a result of the expert sound analyst using up to
date tools.  If there were sounds encoded in the music, digital signal
processing techniques are better tools to use than analog ones.

The whole business is the pathetic process of ill families trying to
put the blame for their kids' suicides on the Evils of Rock and Roll (tm)... 

&lt;Disclaimer: I don't listen to the stuff...&gt;

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Operation Sun Devil invades the InterNet?
</A>
</H3>
<address>
"Jonathan I. Kamens" 
&lt;<A HREF="mailto:jik@pit-manager.MIT.EDU">
jik@pit-manager.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 8 Oct 90 05:50:04 -0400
</i><PRE>

  The message by Ed Luke (who is, incidentally, the SysOp of the MARS
BBS discussed in it) is, indeed, a hoax.

  For more information about it, see the article entitled "MARS BBS
Sting a Prank" in Issue #2.06 of the Computer Underground Digest
(available in alt.society.cu-digest for those of you who read news and
whose feed includes that newsgroup).  The article does a good job
discussing the risks made clear by this "joke".

  The article claims that the prank was "not malicious" and "not
intended to be deceptive".  Unfortunately, in the real world, there is
often a gap between what is intended and what actually occurs.  Many
people *were* deceived by his story, and I'm sure that it caused some
people quite a bit of worry about the possibility that Operation
Sun-Devil might be coming after them next.

  I do not think Mr. Luke used very good judgment at all when he wrote
his "prank".

	Jonathan Kamens, 	MIT Project Athena

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Loving Little Egypt - phone freaks
</A>
</H3>
<address>
Dick Karpinski
&lt;<A HREF="mailto:dick@ccnext.ucsf.edu ">
dick@ccnext.ucsf.edu 
</A>&gt;
</address>
<i>
Fri, 5 Oct 90 15:34:11 PDT
</i><PRE>

In Loving Little Egypt (ISBN 0 14 00.9331 1), the protagonist is a weak sighted
boy who discovers vulnerabilities in the in-band signalling of the early dial
telephone network.  This delightful tale includes episodes of interaction with
Bell, Edison, Tesla and others in a quest to improve the security of the phone
system.  Comparisons with Morris come readily to mind.  The interactions among
the blind phone freaks also invite comparison with the Whole Earth Review
article on the facts and people involved by the Secret Service in Operation Sun
Devil.  This book uses science and technology as major plot elements, which
seems to be a major problem for folks like the operatives in Sun Devil.  The
risks involved here range from technical vulnerabilities to serious loss of
freedoms due to heavy handed tactics by uncomprehending agents of law
enforcement organizations.
                                                  Dick

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
CERT Advisory Update - NeXT Systems (See <A HREF="/Risks/10.47.html">RISKS-10.47</A>.)
</A>
</H3>
<address>
&lt;<A HREF="mailto:cert-advisory-request@cert.sei.cmu.edu">
cert-advisory-request@cert.sei.cmu.edu
</A>&gt;
</address>
<i>
Fri, 5 Oct 90 11:52:48 -0400
</i><PRE>

This message is an update of the October 2, 1990 CERT Advisory (CA-90:06)
"NeXT's System Software".  There is one correction and an update that you
should be aware of.

For Problem #2 SOLUTION, the following line has been added:

  # /etc/chmod 440 /usr/lib/NextPrinter/npd.old

This will disable the old printer program.  

NeXT is also making the new printer program, npd, available electronically
via anonymous ftp for Internet sites.  The archives sites are:

        nova.cc.purdue.edu
        umd5.umd.edu
        cs.orst.edu

In addition, NeXT has asked the CERT to announce that if anyone cannot get
it from the archives, NeXT Technical Support can provide it. Requests should
go to:

        ask_next@NeXT.COM [...!next!ask_next]

Ed DeHart, Computer Emergency Response Team

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.47.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.49.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-22</DOCNO>
<DOCOLDNO>IA013-000136-B029-468</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.49.html 128.240.150.127 19970217040358 text/html 24522
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:02:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 49</TITLE>
<LINK REL="Prev" HREF="/Risks/10.48.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.50.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 49</H1>
<H2> Thursday 11 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Programmer error kills phones for 30 minutes 
</A>
<DD>
<A HREF="#subj1.1">
John R. Dudeck
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Answering Machine Cheats at Phone Tag 
</A>
<DD>
<A HREF="#subj2.1">
Ed McGuire
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Discovery misprogrammed 
</A>
<DD>
<A HREF="#subj3.1">
Fernando Pereira
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Airliner story 
</A>
<DD>
<A HREF="#subj4.1">
Rich Epstein via Gene Spafford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  An IBM interface glitch &amp; RISKS masthead FTP instructions 
</A>
<DD>
<A HREF="#subj5.1">
Lorenzo Strigini
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Automobile Computer RISKS - A Real Life Experience 
</A>
<DD>
<A HREF="#subj6.1">
Marc Lewert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: BA 747-400 Engine Failure 
</A>
<DD>
<A HREF="#subj7.1">
Jerry Hollombe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Equinox on A320 
</A>
<DD>
<A HREF="#subj8.1">
Ken Tindell
</A><br>
<A HREF="#subj8.2">
 Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Ada and multitasking 
</A>
<DD>
<A HREF="#subj9.1">
Stephen Tihor
</A><br>
<A HREF="#subj9.2">
 Henry Spencer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Wed, 10 Oct 90 20:49:32 -0700 From: jdudeck@polyslo.CalPoly.EDU (John R.
</i><PRE>
   Phone lines - including the 911 emergency number - were dead throughout San
Luis Obispo [California] for thirty minutes Tuesday night [Oct 9, 1990].
   The interruption, which affected 30,000 customers, occurred at 10:15 p.m.
and affected virtually all phone lines in the city, said Jim Bower, Pacific
Bell's Central Coast area manager.
   Bower said the interruption was caused by a computer programming error made
by a Pacific Bell employee.  "We were putting in a new program and an error was
made," he said.  "We were responsible for the error and corrected it as soon as
we could."
	The error also caused phone lines at the Sheriff's department,
including the 911 number, to go dead for 30 minutes, said Sheriff's Sgt. Scott
Thompson.  The disruption didn't cause any serious problems, he said.

	- San Luis Obispo Telegram Tribune, Oct. 10, 1990, p. A-5

John Dudeck, jdudeck@Polyslo.CalPoly.Edu ESL: 62013975 Tel: 805-545-9549

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Thu, 11 Oct 90 15:08:40 CST From: Ed McGuire
</i><PRE>
Our organization has been playing the game of Phone Tag a lot recently.  We
reasoned that, if the other player could leave a voice message for us instead
of asking a receptionist to have us call them back, we would win the game more
often.  (Not to mention improve our response to our customers.)  Accordingly,
we installed telephone answering machines for several people, including myself,
on the desks next to the telephones.  The telephones are just the visible part
of the campus' fancy private branch exchange (PBX).

The PBX was insulted when I installed my machine.  Accordingly, when one of our
secretaries tried to call me, it rang my phone only two times while it rang in
the callers ear four times, then "forwarded on no answer."  When the secretary
answered her phone, she was talking to herself.

So I told my machine to answer on two rings.  Then I found out that my machine
has a bad attitude.

For two days it left me "1 message waiting" but there was nothing on the tape.
I discovered that it had been telling people to leave their name, company and
phone, then hanging up on them.  This was because I had mistakenly moved the
wrong one of two identical switches on the side to fix the earlier problem.

Today I caught my machine cheating at Phone Tag.

I started the game by making a call to a person in our Inventory Department.
The line was busy, so I tagged her by instructing our telephone system to call
me back when she hung up.  YOU'RE IT.

A few minutes later I left my desk on a short errand.  And while I was gone,
she hung up and my phone rang.  But now my machine saw its opportunity!  It
answered the call, apologized to her for my absence and instructed her to leave
her name, company and phone.  YOU'RE IT.

The message I received on the machine made it clear that this was breaking the
rules of the game.

			*	*	*

Fortunately, this last event never actually happened.  I realized the risk I
was taking due to the interaction of two Phone Tag technologies just before I
left my office.  A colleague and I simply tested and verified the correctness
of my scenario.
                                        Ed

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Discovery misprogrammed
</A>
</H3>
<address>
Fernando Pereira
&lt;<A HREF="mailto:pereira@research.mercury.nj.att.com ">
pereira@research.mercury.nj.att.com 
</A>&gt;
</address>
<i>
Wed, 10 Oct 90 22:30:10 EDT
</i><PRE>

Summary of story by AP Science Writer Lee Siegel ``Wrong Computer
Instructions Were Given to Discovery Before Liftoff''.

According to Discovery flight director Milt Heflin, the shuttle was launched
with incorrect instructions on how to operate some of its programs. The error
was discovered by the shuttle crew about one hour into the mission, and was
quickly corrected. NASA claims that automatic safeguards would have prevent any
ill effects even if the crew had not noticed the error on a display. The error
was made before the launch and discovered when the crew was switching the
shuttle computers from launch to orbital operations. The switching procedure
involves shutting down computers 3 and 5, while computers 1 and 2 carry on
normal operations, and computer 4 monitors the shuttle's ``vital signs'' [I'm
just following the article on this, I don't know whether it is accurate].
However, the crew noticed that the instructions for computer 4 were in fact
those intended for computer 2.  Heflin stated that the problem is considered
serious because the ground pre-launch procedures failed to catch it.

Fernando Pereira, 2D-447, AT&amp;T Bell Laboratories, 600 Mountain Ave, Murray
Hill, NJ 07974                                    pereira@research.att.com

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Airliner story
</A>
</H3>
<address>
Gene Spafford 
&lt;<A HREF="mailto:spaf@cs.purdue.edu">
spaf@cs.purdue.edu
</A>&gt;
</address>
<i>
Wed, 10 Oct 90 12:25:11 EST
</i><PRE>

A few months ago, I told a friend about the various stories I had read here and
elsewhere about the A320.  The subject came up when I explained why I would
never again fly Northwest Airlines (they bought a bunch of A320s for domestic
use).

He just recently sent me this mail:

&gt;&gt; From:    RIch EPstein &lt;@VM.CC.PURDUE.EDU:REPSTEIN@GWUVM&gt;
&gt;&gt; To:      Spaf &lt;spaf&gt;
&gt;&gt; Date:    Tue, 09 Oct 90 16:13:44 EDT 
&gt;&gt;
&gt;&gt; I just came back from the IEEE Visual Languages WOrkshop, which
&gt;&gt; I thoroughly enjoyed. However, I thought you would find my
&gt;&gt; air horror story of interest:
&gt;&gt; 
&gt;&gt; The conference was in Skokie, ILL, so I had to fly in and out
&gt;&gt; of O'Hare. We had a slight mishap on the plane on the way back
&gt;&gt; to Dulles. Heavy rains leaked into the plane and knocked out
&gt;&gt; the transponders and the auto-pilot computer. About 15 minutes
&gt;&gt; into the flight the pilot announced that we had to return to
&gt;&gt; O'Hare because the air traffic controllers couldn't "pick us
&gt;&gt; up". In other words, we were invisible, in the clouds, at
&gt;&gt; O'Hare. According to an Air Force ROTC student here at GW
&gt;&gt; the pilot meant this literally. Radar picks up aircraft by
&gt;&gt; means of the signal sent out by the transponders.
&gt;&gt; 
&gt;&gt; We flew around in the clouds for 15 more minutes. We landed
&gt;&gt; with all sorts of emergency vehicles on the runway. Then we
&gt;&gt; waited for almost three hours until they finally replaced
&gt;&gt; the transponders and computer and we left Chicago on the
&gt;&gt; same plane (which I didn't like too much).
&gt;&gt; 
&gt;&gt; The pilot got on the p.a. system after we were successfully
&gt;&gt; on our way to Dulles and he made an interesting remark. He
&gt;&gt; said that this was a good plane because it had "stainless
&gt;&gt; steel aeronautical control cables", a reference to the fact
&gt;&gt; that an Airbus would probably have been disabled completely
&gt;&gt; in a similar circumstance. I have no doubt that the pilot
&gt;&gt; was referring to the Airbus when he made this remark.

I wrote asking his permission to send this on to Risks, and in his
reply, he said:

&gt;&gt; By the way, I think the ground crew at O'Hare might have been
&gt;&gt; negligent in my airline incident. When we entered the airplane
&gt;&gt; water was LITERALLY POURING INTO THE AIRCRAFT at the door to
&gt;&gt; the airplane. Passengers had to JUMP THROUGH a sheet of water,
&gt;&gt; a thin veil, maybe 1/4" thick, but continuous. The water was
&gt;&gt; coming in from the top of the door and onto the floor of
&gt;&gt; the airplane. Obviously, the water went from there into the
&gt;&gt; underbelly of the craft. The reason for this was that the
&gt;&gt; airport walkway was not meeting the fuselage correctly.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
An IBM interface glitch &amp; RISKS masthead FTP instructions 
</A>
</H3>
<address>
Lorenzo Strigini 
&lt;<A HREF="mailto:STRIGINI@ICNUCEVM.CNUCE.CNR.IT">
STRIGINI@ICNUCEVM.CNUCE.CNR.IT
</A>&gt;
</address>
<i>
Mon, 08 Oct 90 09:49:54 MET
</i><PRE>

Just to signal another minor problem similar to that of truncation to 80
columns: After several unsuccessful attempts to follow the masthead
instructions for FTPing RISKS issues, I discovered this morning that my IBM3278
emulator eats square brackets.  CRVAX runs VMS, I guess, but I hadn't used such
a system for years: only when I moved my attempts to a Unix machine did I
realize why I could not cd to the risks directory.

The 3278 keyboards don't have square brackets, but square brackets entered
through an emulator are stored as escape sequences. ASCII square brackets that
exist in mailed of FTPed files are stored as such, and displayed as blank
spaces.

and here are a few left square brackets embedded in a series of dashes:
     --------------------
and a few right brackets:
     ----------:::::----------

Amazing... I thought this was worth signalling in case you receive requests
for help from other IBM users.
                                          Lorenzo

Lorenzo Strigini, IEI del CNR, Via Santa Maria 46   I-56126 Pisa   ITALY
Tel: +39-50-553159 ; Fax: +39-50-554342 ; strigini@icnucevm.bitnet

     [Lorenzo and RISKSers, I have long been annoyed at the miserable
     VAX command "cd sys$user2:[risks]" to get the anonymous FTPer into
     the RISKS directory.  In response to Lorenzo's message, SRI's CRVAX 
     wizard Ray Curiel, at Steve Milunovic's request, has provided a terse
     alias: "cd risks:".  Upper/lower case does not matter, but the colon 
     does.  HooRAY!  Thanks.  I changed the masthead.  Now you don't need
     to escape from the colonease?  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Automobile Computer RISKS - A Real Life Experience
</A>
</H3>
<address>
Marc Lewert
&lt;<A HREF="mailto:marc@frederic.octel.com ">
marc@frederic.octel.com 
</A>&gt;
</address>
<i>
Wed, 10 Oct 90 12:58:25 PDT
</i><PRE>

With all of the discussion on the risks of computerized and/or electronic
controls in Aircraft, one should not overlook the fact that there could be
more down to earth (pun intended) risks along the same lines.

One of our cars has a computer, and various other electronic sensors that
control the engine.  A couple of years back, shortly after we bought the
car, it started intermittently losing power.  Not too much trouble on city
streets, but on the freeway, it was downright dangerous.  

The symptom was that the car's engine would drop to idle speed, and would not
speed up, not matter what we did with the gas pedal.  It could be reset by
turning off, and restarting the engine.

We had brought the car in several times, but the dealership could not find
the problem.

Then came the fateful day...My wife was driving the car when the engine dropped
to idle at the merge of two freeways, and she was in slow lane of one freeway
that merged with the fast lane of the other...I was not happy when I got the
call (I told her to call the dealership to come get the car!).

Somehow she was talked into driving the car to the dealership, when the
same problem occured.  This time, though, it occured in front of a truck
hauling an oversized load in the slow lane of the freeway.  If there had not
been an offramp and a truck driver that was on his toes, we might be talking
about my wife in the past tense at this point.

The eventual problem was an intermittent failure of a sensor in the air intake
system.  The computer responded by cutting down the fuel flow to its minimum
setting.

I just wonder how many of these types of problems exist out in the world, and
if anyone had been killed by them.  All in all, everyone was very lucky...
	This Time.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: BA 747-400 Engine Failure (Thomas, <A HREF="/Risks/10.47.html">RISKS-10.47</A>)
</A>
</H3>
<address>
The Polymath
&lt;<A HREF="mailto:hollombe@ttidca.tti.com ">
hollombe@ttidca.tti.com 
</A>&gt;
</address>
<i>
11 Oct 90 01:49:21 GMT
</i><PRE>

}... It's a FADEC failure" [FADEC = Full Authority Digital Engine Controller].
}... There has been a number of instances of spurious signals causing
}747-400 engines to throttle back or shut down, according to Flight ...

This begins to sound a bit like the discussion of electronic vs. mechanical
rail line switching controls.

I earned my Airframe &amp; Powerplant mechanic's license (A&amp;P) nearly 25 years
ago (when pilots were made of iron and planes were made of wood ... but I
digress (-: ).  At that time, jet engine controls were almost entirely
mechanical, consisting of amazingly complex blocks of pneumatic and
hydraulic sensors and actuators.  Each engine had a main controller and a
backup, "get you down alive" controller that provided just enough control
to keep the engine running if the main failed.

Has the concept of such backups been lost in the rush to computerize?

Jerry Hollombe, M.A., CDP, Citicorp, 3100 Ocean Park Blvd.  Santa Monica, CA
90405        (213) 450-9111, x2483 {csun | philabs | psivax}!ttidca!hollombe

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Equinox on A320 (Pete Mellor, <A HREF="/Risks/10.48.html">RISKS-10.48</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ken@minster.york.ac.uk">
ken@minster.york.ac.uk
</A>&gt;
</address>
<i>
11 Oct 1990 18:09:03 GMT
</i><PRE>

&gt;The programme went on to consider the crash of the A320 at Bangalore. A pilot
&gt;was interviewed saying that it was virtually unknown for an aircraft to lose
&gt;height in such a way in clear conditions on a landing approach.

We know that the Bangalore crash _was_ pilot error. Both the `back box'
and the cockpit voice recorder indicate that the pilots were to blame.
Flight International has given a good account of this, including the
CVR transcript. The captain left the aircraft in idle descent mode and
flew into the ground. The aircraft warned the pilots (both visually and
aurally), but they ignored the warnings. Equinox chose not to report
this (the rest of the programme seemed very convincing).

A lot of people have a lot of axes to grind over Airbus Industrie, and
receiving totally impartial and accurate information is almost impossible.
Listen to Boeing and you hear that the A320 is a death-trap. Listen to
Aerospatiale and you hear supreme confidence. Watch TV programmes and you see
sensationalism.

Ken Tindell, Computer Science Dept., York University YO1 5DD, 
UK Tel.: +44-904-433244   UUCP:     ..!mcsun!ukc!minster!ken

</PRE>
<HR><H3><A NAME="subj8.2">
Re: Equinox on A320 (UK Channel 4, Sun., 30th Sep)
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Wed, 10 Oct 90 12:39:31 EDT
</i><PRE>

&gt;- The DFDR recording stops 4 seconds *prior* to impact with the trees. (Davis
&gt;  added that, in his entire career, he had *never* come across a similar
&gt;  instantaneous stoppage of a recorder.)

Is it possible that Davis is not familiar with *digital* flight recorders?
I've seen some commentary on such an issue in the aviation press recently:
the underlying problem is that some (all?) digital flight recorders buffer
incoming data in semiconductor memory, which loses its contents on power
failure.  The airworthiness authorities are starting to be seriously
displeased with the potential for loss of crucial data, and there are
mutterings about requiring non-volatile memory.

I don't know for sure that this accounts for the above claim, but it
certainly sounds like the right sort of symptoms.

(Would a simple explanation like this go unconsidered?  Quite possibly,
especially in the context of a media story whose basic slant is "dirty
work at the crossroads".  As I've commented before, there is a problem
with the A320 business in that almost all participants have axes to
grind and it is very difficult to get a balanced view.  The media are
not exempt from this, since sensation sells and boring truth doesn't.)

     Henry Spencer at U of Toronto Zoology  henry@zoo.toronto.edu  utzoo!henry

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Ada and multitasking (Kristiansen, <A HREF="/Risks/10.48.html">RISKS-10.48</A>)
</A>
</H3>
<address>
Stephen Tihor
&lt;<A HREF="mailto:TIHOR@ACFcluster.NYU.EDU ">
TIHOR@ACFcluster.NYU.EDU 
</A>&gt;
</address>
<i>
Wed, 10 Oct 1990 17:03:25 EDT
</i><PRE>

The areas left to the implementer were left that way due to disagreements on
the proper and useful choices.  All such options must be fully specified in
mandatory sections of the Ada reference manual.

The general phrase I remember being used whenever such items were discussed is
that the market will select among conforming compilers.

In hindsight it might have been better to add some language clauses that allow
you to specific or explicitly leave unspecified the tasking priority
requirements.

On the other hand many people believe that the ADA tasking model, while
interesting, is not general enough to begin with.

</PRE>
<HR><H3><A NAME="subj9.2">
Re: Ada and multitasking
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Wed, 10 Oct 90 12:59:53 EDT
</i><PRE>

&gt; The author does not seem to realize the contradiction between the
&gt; *reliability* and *portability* quoted as features of Ada on one hand, and
&gt; the lack of definition of crucial features on the other.

There is no inherent contradiction here, unless "reliability" and "portability"
are taken to include the phrase "guaranteed or your money back".  (Mind you,
some of the Ada enthusiasts essentially do claim this.)  "Reliability" and
"portability" are not absolutes, especially in a language constrained to be
implemented efficiently on current machines.  If such constraints mean that a
particular feature is not completely defined, this just means that
reliable/portable programs must avoid depending on it.  This does require
competent programmers, however, and one gets the impression that some of Ada's
big backers hoped that their wonderful language would do away with the need for
competence.  After all, it's much easier to run a test suite through a compiler
than to decide whether a programmer is competent.

The C community regularly sees broadsides on the subject, with ignorant people
claiming that the large number of "implementation defined" or even "undefined"
items in ANSI C implies that C programs cannot possibly be portable or
reliable.  Not so; these are just indications of where the programmer must
avoid depending on implementation-dependent behavior.  (There is room for
legitimate debate about whether C expects too much from its programmers, but
that is a different issue.  Portable, reliable C code is verifiably possible.)
C gets more of this than Ada, because C is a rather unforgiving language meant
for people who know what they are doing, but almost any efficient language will
run into similar issues.

To draw an analogy from more traditional engineering, the basic art of
designing circuits with transistors is organizing things so that the
characteristics of individual transistors do not affect the outputs much.
Transistor characteristics are quite variable, especially if you want the
transistors to be cheap.  This does not make it impossible to design transistor
circuits with predictable properties.  It merely requires that designers take
care to use circuits that allow for the variability and cancel it out.

     Henry Spencer at U of Toronto Zoology  henry@zoo.toronto.edu  utzoo!henry

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-23</DOCNO>
<DOCOLDNO>IA013-000136-B029-498</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.50.html 128.240.150.127 19970217040412 text/html 24071
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:02:40 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 50</TITLE>
<LINK REL="Prev" HREF="/Risks/10.49.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.51.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 50</H1>
<H2> Monday 15 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Hackers blackmail UK five banks 
</A>
<DD>
<A HREF="#subj1.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Equinox on A320 
</A>
<DD>
<A HREF="#subj2.1">
Robert Dorsett
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: A320s and Northwest Airlines 
</A>
<DD>
<A HREF="#subj3.1">
Chris Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Ada MultiTasking 
</A>
<DD>
<A HREF="#subj4.1">
Chet Laughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Expert system in the loop 
</A>
<DD>
<A HREF="#subj5.1">
Randall Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Announcement of CPSR annual meeting 
</A>
<DD>
<A HREF="#subj6.1">
Lesley Kalmin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Hackers blackmail five banks (UK)
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Mon, 15 Oct 90 17:25:56 PDT
</i><PRE>

Excerpts from The Independent on Sunday, 14 Oct 1990:

Headline: "Hackers blackmail five banks"

Subhead: "Mysterious computer experts demand money to reveal how they 
          penetrated sophisticated security"

By-line: Richard Thomson

 "At least four British clearing banks and one merchant bank in the City are
  being blackmailed by a mysterious group of computer hackers who have broken
  into their central computer systems over the last six months. These breaches
  of computer security may be the largest and most sophisticated yet among
  British banks.

  The electronic break-ins, which began last May, could cause chaos for the
  banks involved. Once inside their systems, the hackers could steal 
  information or indulge in sabotage, such as planting false data or damaging
  complex computer programs. It is unlikely, however, that they would be able
  to steal money.

  So far, the hackers have contented themselves with demanding substantial sums
  of money in return for showing the banks how their systems were penetrated.
  None of the banks has yet paid.

  [Stuff omitted]

  One computer expert described their level of expertise as "truly frightening".
  They are not believed to have links with organised crime, which has become
  heavily involved in computer hacking in the US over the last two to three 
  years. [Any comments?? - PM]

  It is a severe embarrasment for the banking community which is frightened
  that public awareness of the security breach could undermine public 
  confidence. As a result, they have not called in the police but some have 
  hired a firm of private investigators, Network Security Management, which
  is owned by Hambros Bank and specialises in computer fraud. It is common
  for banks not to report fraud and security failures to the police for fear 
  of damaging publicity.

  All the banks approached either denied that they were victims of the 
  blackmail attempt or refused to comment.

  The hunt for the hackers is being led by David Price, managing director of 
  NSM, who confirmed his firm was investigating security breaches at five
  British banks. "I am confident of success in catching the hackers." he said.

  [Stuff omitted]

  Security measures were tightened after a large computer fraud at a leading
  City bank three years ago. Although the bank involved was never named, it
  is understood the money was never recovered. [Anyone got the details?? - PM]

  [Stuff omitted]

  According to an expert, who recently advised one of the big four clearers
  on its computer systems, there are few people who understand the bank's
  system well enough even to detect a break-in.

  [Stuff omitted]

  According to some reputable UK and US estimates, up to 5 per cent of the
  gross national product of western economies disappears in fraud. Experts say 
  that the senior managers of many companies simply do not appreciate the 
  need for tight security.

  [Stuff about the Computer Misuse Act omitted]"

                   ---- End of extract ----

Just how "sophisticated" banks' computer security is can be judged from a
conversation I had last Saturday night in the pub with an acquaintance who
manages the local branch of a chain of off-licences (liquor stores).

He had just finished entering his orders onto his PC, which communicates
remotely with the firm's main warehouse in Dartmouth (I think). He told me that
he entered the normal 5-digit code to send in his completed order, and was
amazed to find displayed on his screen the credit card transaction records
from Barclays' Bank in South Yorkshire, with full details: names, account
numbers and amounts.

Feeling thoroughly confused, he switched off the machine and went to bed.
When he checked the next day, he found that his order *had* been correctly
received.

Obviously just a one-off incident that need not affect public confidence!

Peter Mellor, Centre for Software Reliability, City University, Northampton 
Sq.,London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

   [Also reported by  Sanford Sherizen &lt;0003965782@mcimail.com&gt;]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Equinox on A320
</A>
</H3>
<address>
Robert Dorsett
&lt;<A HREF="mailto:rdd@rascal.ics.utexas.edu ">
rdd@rascal.ics.utexas.edu 
</A>&gt;
</address>
<i>
Fri, 12 Oct 90 23:59:54 CDT
</i><PRE>

&gt;&gt;The programme went on to consider the crash of the A320 at Bangalore. A pilot
&gt;&gt;was interviewed saying that it was virtually unknown for an aircraft to lose
&gt;&gt;height in such a way in clear conditions on a landing approach.
&gt;
&gt;We know that the Bangalore crash _was_ pilot error. Both the `back box'
&gt;and the cockpit voice recorder indicate that the pilots were to blame.
&gt;Flight International has given a good account of this

On the other hand, Flight International has been extremely close to Airbus
throughout the development of the aircraft.  While I like the magazine, it is
also a proponent of Euro-oriented industry, and has been very careful not to
say anything too damaging about the airplane--and has certainly not given 
detailed consideration to the voluminous controversial issues which surround 
many aspects of the aircraft.  

At the risk of sounding like a broken record, I suggest the following:
"pilot error" is an unacceptable answer.  In clear, stable conditions, with
an (apparently) operational airplane, one just doesn't go around crashing 
airplanes.  "Pilot error" might be acceptable if, say, one reverses a holding 
pattern and flies into a mountain in clouds, but Bangalore (and Habsheim) 
smacks of a systemic error of some sort.  What could it be?  Let's see:
   - the airlines' hiring and qualification mechanisms (ab initio).
   - the training mechanism (computer-*based* training, supplied by Airbus)
   - the overall *philosophy* of the flight deck design (Airbus)
   - individual components of flight deck design (altimeter design, etc)
   - support system problems (FADEC unresponsiveness, ignoring commands
     which put the airplane out of the computed "safe" envelope)

The emphasis on RISKS has long been on the last category: concerns on
hardware and software failure, common sources of failure, etc. 

&gt;The captain left the aircraft in idle descent mode and
&gt;flew into the ground. The aircraft warned the pilots (both visually and
&gt;aurally), but they ignored the warnings. Equinox chose not to report
&gt;this (the rest of the programme seemed very convincing).

This supports the systemic view.  In my experience on an A320 simulator
(reported on sci.aeronautics about five weeks ago), I noted that there were way
too many alerts.  There are two types: warnings and cautions.  They both have
the same chime, but illuminate different lights.  They often deal with uttelry
trivial situations, but require the pilot to drop what he's doing and sort
through the ECAM displays to figure out whether to spend any MORE time on it.
In many cases, the computer's already taken care of cautions, so, "why worry?"

Apart from too many alerts, ground-proximity warning systems have a poor
reputation in the airline industry as a whole: false warnings at cruising
altitude, warnings during properly-conducted approaches, etc.  These have been
with us for nearly 20 years; crew reluctance to pay attention to them have
resulted in several other airliner crashes (although it's undeniable that the
systems have also saved lives).

Lastly, there has *always* been a tendency in the airline industry to make
unworkable or poor designs work (e.g., Comet, DC-10).  Given a poorly designed
cockpit, the tendency is to attempt to train around any defects.  Ditto with
a bad airplane.  This *suppresses* the consequences of systemic error, but by
no means *eliminates* it.  When "pilot error" happens in this environment, 
all too often the operator is castigated, while the circumstances which 
produce the error is ignored.


I suggest (again) that the way the airplane interacts with the pilot is at
LEAST as important as component-wise reliability.  Just because the machine
works does not mean that the machine's *design* is satisfactory for human
operation.  This is a consideration that will become increasingly important
with all aspects of automation, and needs to be addressed in this forum.  This
has nothing to do with lawsuits, sensationalism, or PR-types.  It has to do
with saving lives, and preserving the capability of the human component of
safety-critical systems to do its role properly.

End of diatribe.

Robert Dorsett     UUCP: ...cs.utexas.edu!rascal.ics.utexas.edu!rdd  

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: A320s and Northwest Airlines (Epstein/Spaf, <A HREF="/Risks/10.49.html">RISKS-10.49</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ckd@cs.bu.edu">
ckd@cs.bu.edu
</A>&gt;
</address>
<i>
Sat, 13 Oct 90 11:07:01 -0400
</i><PRE>

spaf&gt; Gene Spafford &lt;spaf@cs.purdue.edu&gt; said:
spaf&gt; A few months ago, I told a friend about the various stories I
spaf&gt; had read here and elsewhere about the A320.  The subject came up
spaf&gt; when I explained why I would never again fly Northwest Airlines
spaf&gt; (they bought a bunch of A320s for domestic use).

I've seen a few of them; never flown on 'em, though (hey, *I* read RISKS!).  My
policy still is to always check the aircraft type when making reservations.

My big "Northwest A320 story" is of a time I was flying from Seattle to Boston,
with a stop in Detroit.  There was a DC-10 at Detroit with a gate hold for
maintenance (hydraulics problems, I believe) and they swapped our aircraft for
that one (the flight to LAX already being two hours late, they figured they'd
spread the misery out a bit, instead).

Our flight was scheduled to leave DTW at about 9 pm; we eventually
left at around 11-11:30, arriving in Boston at about 1 in the morning.

The A320, originally scheduled to be the 7:30 flight from Detroit, was listed
on the monitors at Boston's Logan airport to be arriving at 3 am (meaning it
had not left the ground in DTW when we arrived in Boston).

The DC-10 had had its own problems, but they were (obviously) better
understood by the ground crews involved.

An issue of RISKS management: on my last flight through Detroit, I saw a brand
new ("two months old") 747-400 being loaded for a flight to Minneapolis (one of
Northwest's other hub cities).  After checking the schedule, it turns out that
this plane is currently being used *only* to shuttle between the two cities.

Anyone want to bet it's for ground-crew and maintenance crew
familiarization at two airports likely to see many more of the -400s?

--Chris
&lt; Christopher Davis, BU SMG '90  &lt;ckd@cs.bu.edu&gt; &lt;...!bu.edu!bu-cs!ckd&gt; &gt;

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Ada MultiTasking
</A>
</H3>
<address>
LAUGHLIN, CHET
&lt;<A HREF="mailto:ctl8588@rigel.tamu.edu ">
ctl8588@rigel.tamu.edu 
</A>&gt;
</address>
<i>
14 Oct 90 21:51:23 GMT
</i><PRE>

In responce to Erling Kirstainsen's article about Ada's multitasking being
vaguely defined - my Real-Time systems class has had problems with exactly this
issue.  In general the class is a graduate level course and we had hoped to use
Ada on a network of IBM PS/2s for the labs.

The first lab involved two tasks running in parrellel.  In reality it was
figured that the tasks would time-slice on a single machine.  However, this was
not the case.  The compiler would simply run the highest priority task until it
ended, and then run the lower task.  It was interesting to note that programs
that ran correctly on SUNS did not run correctly on the PS/2s - even though
they compiled without change.

Now, one could blame the operating system - DOS is not anywhere close to a
multitasking system.  Or one could blame the language.  The compiler makes no
mention of the fact that tasks will not run concurrently in any of its
documentation - and so I'd lean toward placing blame there.  I suppose that if
Unix or OS/2 could be afforded and placed on the PCs the programs would compile
and work correctly.  We have also discussed in class how the specification for
Ada is open to interpretation on how tasks should be scheduled.

The end result is that the labs will be done in C on the PS/2s.

Chet Laughlin                  CTL8588@RIGEL.TAMU.EDU         

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Expert system in the loop 
</A>
</H3>
<address>
Randall Davis
&lt;<A HREF="mailto:davis@ai.mit.edu ">
davis@ai.mit.edu 
</A>&gt;
</address>
<i>
Mon, 8 Oct 90 13:21:46 edt
</i><PRE>

Two (last?) gasps:

1) As the previous discussion (two years ago) of this incident made clear,
another fundamental problem here is the tactical advantage of offense over
defense: the distance from which it's possible to shoot accurately is larger
than the distance at which it's possible to identify the source.  That may not
have been a crucial factor in this incident, but it contributes to the mindset
and practice that says self-defense means you may have to fire at a threat
before you're certain of its identity.  That's a consequence of all sorts of
technology, and it happens to the infantryman with a rifle because bullets can
fly further than we can easily see.


As for the title of this whole discussion -- "Expert systems in the loop":

2) There aren't any and there never were any.  As abundant discussion has made
clear (particularly the description by Matt Jaffe in 10.46), the Vincennes had
some interesting signal processing and data description hardware and software,
but nothing that can by any stretch deserve the term "expert system."  If
there's more software to the story than anyone has described thus far, it would
be interesting to hear about it from a knowledgable source.  We might also
consider this, from an early report about the system (from a story in Risks
9.70):

  "The anti-air warfare officer made no attempt to confirm the reports
  [from the crew] on his own," the commander-in-chief of the US Central
  Command reported.  "Quick reference to the console directly in front of
  him would have immediately shown increasing, not decreasing, altitude 
  [of the Iranian jet]."  Instead, this "experienced and highly qualified
  officer, despite all of his training, relied on the judgment of one or
  two second-class petty officers, buttressed by his own preconceived
  perception of the threat, and made an erroneous assessment to his
  commanding officer."

Note in particular the second sentence, indicating that the system displays
data about the aircraft, not threat interpretation.  As noted in earlier
discussions, this data (like the data on your speedometer) can of course be
incorrect, but that's a different issue.

So until otherwise informed, let's be clear about this: it was a problem of
"Instruments in the loop".  That by itself may be worth discussing, but it is
not and never was an expert system.  And it might be interesting to ask, Why
the rush to label it an expert system?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Announcement of CPSR annual meeting
</A>
</H3>
<address>
&lt;<A HREF="mailto:kalmin@atd.dec.com">
kalmin@atd.dec.com
</A>&gt;
</address>
<i>
Mon, 15 Oct 90 09:37:10 PDT
</i><PRE>

                             1990 Annual Meeting
                                     of
                Computer Professionals for Social Responsibility
                              October 20 and 21
                    Stanford University and Palo Alto, CA

Computer Professionals for Social Responsibility, the nation's only public
interest organization of computing professionals, will hold its 1990 Annual
Meeting at Stanford University and at Ming's Villa restaurant in Palo Alto on
October 20 and 21, 1990.

The CPSR Annual Meeting is a national meeting that gives computer
professionals from all over the country a chance to meet and discuss some of
the most important and interesting issues facing the profession and the
public.  This year's meeting will cover civil liberties and First Amendment
rights in computer communication; using computers to support democratic
oversight of government; women in the computing field; and what the public is
at Stanford University, will include the following:

        John Perry Barlow -- "Civilizing Cyberspace:  Computers, Civil
        Liberties and Freedom."  Barlow is the co-founder of the Elec-
        tronic Frontier Foundation, a lyricist with the Grateful Dead,
        and author of the article "Crime and Puzzlement" featured in
        the latest issue of The Whole Earth Review.

        David Burnham -- "Turning the Tables:  Computer Oversight for
        Citizens."  Burnham is a former investigative reporter for the
        New York Times, and the author of the books The Rise of the
        Computer State and A Law Unto Itself, the latter an expose of
        the IRS.  While at the Times, Burnham was responsible for the
        stories that led to the Knapp Commission on police corruption
        in New York City, and he was the reporter who broke the Karen
        Silkwood story.  He now works with the Transactional Records
        Clearinghouse at Syracuse University.  TRAC uses the Freedom of
        Information Act and computer analysis to provide oversight of
        powerful Federal agencies such as the IRS, the Nuclear Regula-
        tory Commission, and the Department of Justice.

There will be two panel discussions the afternoon of Saturday, October 20:

        "Women in Computing: Where We Are, Where We Want To Be, and
        How To Get There."

        Panelists:
                Shari Lawrence Pfleeger, Chair, ACM Committee on
                the Status of Women and Minorities

                Donna Lehnoff, Women's Legal Defense Fund

                Sheila Humphreys, Department of Electrical Engi-
                neering and Computer Science, UC Berkeley

                Barbara Simons, Secretary, Association for Comp-
                uting Machinery (ACM)

        Panel moderated by Anita Borg, DEC Western Research Lab

        "The Media and 'Mythinformation':  What and How Does the Public 
        Learn About Computers?"

        Panelists:

                Bob Abel, multi-media expert and television 
                commercial producer, Synapse Technologies

                Michael Rogers, general editor and technology
                editor, Newsweek magazine

                Rudy Rucker, physicist and science fiction 
                author

                Rob Swigert, professor of creative writing, San
                Jose State, science fiction author, and author
                of Portal, interactive fiction

        Panel moderated by Paul Saffo, Institute for the Future

The Saturday program begins at 9 a.m., and a continental breakfast will be
served just prior to the meeting.  There will be a lunch break from noon to 2
p.m., and the meeting is scheduled to end at 5:30.

The Sunday, October 21, portion of the two-day meeting will be dedicated to
discussions about CPSR as an organization, and there will be workshops on
computers and education, the environment, civil liberties and privacy, peace
and war, and computers in the workplace.

Admission to the CPSR Annual Meeting is $35 for members, $45 for non-members
until October 14.  After October 14 prices go up $10 for each category.
Non-members can join CPSR for one year for $40 and pay the member price to
the meeting.  Admission to the banquet is $50 per person, the same price for
members and non-members.

In addition, for $100 more people can attend a fundraising reception for CPSR
at the offices of Regis McKenna, Inc., on Saturday evening from 6 to 8 p.m.
This is a chance to meet the speakers, leaders of CPSR, and many people from
the computer industry of Silicon Valley.  Contributions to CPSR are
tax-deductible.

For more information and registration materials, contact CPSR at (415) 322-3778
or by electronic mail at cpsr-staff@csli.stanford.edu.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-24</DOCNO>
<DOCOLDNO>IA013-000136-B030-8</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.51.html 128.240.150.127 19970217040425 text/html 19373
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:02:54 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 51</TITLE>
<LINK REL="Prev" HREF="/Risks/10.50.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.52.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 51</H1>
<H2> Tuesday 16 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  A Schaching Development in Kasparov-Karpov 
</A>
<DD>
<A HREF="#subj1.1">
anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Software problem contributes to woman's death 
</A>
<DD>
<A HREF="#subj2.1">
Mike Overstreet
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Airliner story 
</A>
<DD>
<A HREF="#subj3.1">
Christopher C. Stacy
</A><br>
<A HREF="#subj3.2">
 Richard Neitzel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: A320s and Northwest Airlines 
</A>
<DD>
<A HREF="#subj4.1">
Craig A. Finseth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Technophilia-induced problem at Educom? 
</A>
<DD>
<A HREF="#subj5.1">
R. Aminzade
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A Schaching Development
</A>
</H3>
<address>
&lt;<A HREF="mailto:anonymous">
anonymous
</A>&gt;
</address>
<i>
Tue, 16 Oct 1990 16:52:53 PDT
</i><PRE>

   Computer blunders, revealing Kasparov's sealed move
   
        Moscow, 16 october 1990 (tass)

The computer used for the world chess title match between Kasparov and Karpov
accidentally disclosed a move sealed by the reigning champion in the adjourned
third game, Izvestia reports from New York today.  Izvestia writes in its
evening issue that Kasparov "moves the king to attack the white rook".  
This means the sealed move was 41...kd6.

       [Perhaps he was using the Gary Indiana Jones Beach Defense,
       and the computer had never seen seals there before.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Software problem contributes to woman's death
</A>
</H3>
<address>
Mike Overstreet 
&lt;<A HREF="mailto:cmo@xanth.cs.odu.edu">
cmo@xanth.cs.odu.edu
</A>&gt;
</address>
<i>
Mon, 15 Oct 90 18:22:29 EDT
</i><PRE>

The following is taken without permission from the October 14, 1990,
edition of The Virginian-Pilot and The Ledger-Star, Norfolk, VA.

"NORFOLK -- Glitches in the city's new emergency computer system
and a dispatcher's mistake caused rescue workers to take 30 minutes
to get to a 65-year-old heart attack victim in July, according to
city records, and the delay may have been responsible for her death.

"Shortly after 9 p.m. on July 7, Dorothy G. Morris of 8256 Wedgewood
Drive became short of breath and called to her son, Michael, for help.
Michael Morris, who lived with his mother, dialed the 911 emergency
telephone number three time before an ambulance was dispatched. ...

"... City documents show that after Dorothy Morris' death, city officials
tried to pinpoint the cause of the delay.  They interviewed dispatchers
and checked call records and tapes of 911 phone calls.  They also
interviewed Michael Morris.

"Records indicate that they discovered an internal audit, or `logging,'
program -- designed to track messages through the city's new computer-
aided dispatch system -- had not been installed as promised by the
software vendor, PRC Public Management Services of McLean Va.  The
new $760,000 system, called CADMAS, has been on-line since May 1.

"The omission was the latest problem encountered with the system and
with PRC, said Martin Mendelsohn, director of the city's Department
of General Services.  He said the problems, which appeared after
CADMAS was installed, included:  too much computer down time; difficulties
with a backup computer, which repeatedly failed to kick in automatically
when the first computer crashed; turnovers and conflicts with PRC project
managers; and the missing audit system.

"But the most disturbing problem was the tendency for some message to
disappear after they were entered into CADMAS, city officials and
dispatchers have said.  Police have said that messages for detectives
and forensic investigators often disappeared between dispatchers'
shift changes, and that the disappearances are continuing.  Mendelsohn
of Friday said he was aware of fewer then five messages that disappeared
between May 1 and July 12, when the audit system was installed.

"Mendelsohn said he was not aware of any disappearances after July 12.

"City officials said that, even after an investigation, they are not
sure what happened to the 911 message typed by the dispatcher when
Michael Morris first called.

"`The logging system would have tracked the message, but ... the logging
system was not operational,' Mendelsohn said.  `We could not prove whether
the dispatcher entered the message improperly or whether it was somehow
lost in the system.'

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Airliner story (<A HREF="/Risks/10.49.html">RISKS-10.49</A>)
</A>
</H3>
<address>
Christopher C. Stacy
&lt;<A HREF="mailto:cstacy@ai.mit.edu ">
cstacy@ai.mit.edu 
</A>&gt;
</address>
<i>
Fri, 12 Oct 90 00:36:36 EDT
</i><PRE>

Gene Spafford writes about his decision to never again fly on Northwest
airlines, citing that they have just purchased "a bunch of" A320s for domestic
use.  (The A320 is a controversial fly-by-wire airplane.)

He forwarded us a "horror story" from his friend Rich Epstein, who appears to
have been badly frightened by an airline experience in which rain leaked into
the airplane and disabled the transponder and auto-pilot computer. In the
story, the airliner departed from Chicago O'Hare enroute to Washington Dulles,
but then has to turn back to O'Hare 15 minutes later because the air traffic
controllers have lost radar contact with the flight.  On the way back, the
pilot made an announcement about the airplane having steel control cables,
which Rich interprets as "a reference to the fact that an Airbus would probably
have been disabled completely in a similar circumstance."  In conclusion, Rich
describes the further trauma of exiting the airplane at the terminal, having to
pass through a thick sheet of rain, some of which was leaking into the
airplane, which he speculates may not have been docked correctly.

I am very skeptical about the safety of new airplane systems such as
fly-by-wire, and I also wonder about the quality of the maintenence and
procedures of the airlines, especially in light of the recent serious
fines against Eastern.

However, I am not sure that Gene's message or his friend's story sheds
any light on these issues or supports any conclusions about the A320.
The message did not make clear to me exactly what risks Gene finds
unacceptable.  The tone of fear and alarm, coupled with a lack of
information about air traffic procedures, may lead to misunderstandings.
I don't have any more information about what happened on that flight
than what I read in the story.  However, my interpretation would be a
little bit different.

The radar scopes that the air traffic controllers at O'Hare are watching,
display targets based on both primary returns (the signal bouncing off
the airplane), and secondary returns from the onboard transponder.
The transponder makes detection more reliable, and also transmits such
data as the flight identification number and present altitude.

Radar contact is not a necesary to conduct a flight, even in bad weather.
Radar is not used for navigation, nor is it required for landing.
It does increase safety, and allows greater utilization of the airspace,
since the controllers can track the progress of a plane more directly.
Before the airliner took off, the details of its flight plan were arranged
and airspace was reserved for it. The flight could have been conducted
safely without radar, even if radio communications had been lost.

The auto-pilot computer is not a critical part of the airplane, and
it's loss is not very interesting.  It merely means the pilots would
have to actually put their hands on the controls and fly the plane.

The flight was returned to the departure point in order to avoid any
additional problems.  The pilot probably declared an emergency for
priority handling because nobody fully understood the extent of the failures.
This accounts for the emergency vehicles at the airport.

Most people have various degrees of fear regarding flying, and knowing
that something has gone wrong with the plane, not understanding any of the
details, being disconcerted about hanging around in the clouds, seeing the
flashing lights of emergency vehicles, not having any control over your
fate, and finallly getting rained on when you disembark your canceled
flight, can all combine to thoroughly upset even a seasoned air traveler.

My alternate interpretation of the pilot's remark about the "stainless
steel" cables, is that he was attempting to calm the passengers by making
a joke about the airplane controls not rusting in the rain.

Maybe Gene is trying to make the analogy that if a computer in a regular
airplane can get rained on and fail, that this would be catastrophic in
a computer-controlled plane like the A320.  However, this story does not
support that idea, and it presents nothing particularly relavent to the
safety of the A320, the airplane in the story, or the airline.
Except perhaps to note that an onboard systems failure was easily
handled, and resulted in nothing but inconvenienced passengers.
Any proposed analogy to systems failures on the A320 is far too general
to be very useful, since the A320 and the airplane in the story don't
have the same design or the same kind of computer systems.

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Airliner Story (<A HREF="/Risks/10.49.html">RISKS-10.49</A>)
</A>
</H3>
<address>
Richard Neitzel
&lt;<A HREF="mailto:thor@thor.atd.ucar.edu ">
thor@thor.atd.ucar.edu 
</A>&gt;
</address>
<i>
16 Oct 90 14:15:04 GMT
</i><PRE>

I find the dissemination of this kind of misinformation troubling, especially
when it apparently comes from a source that should know the correct
information. The aircraft in question was most certainly not "invisible".  How
"an Air Force ROTC student" could claim radar requires transponders is beyond
comprehension (so that`s how stealth technology works - turn off the
transponder!). However, what is most disturbing about this is not the apparent
ignorance of a (hopefully) poor student, but the easy accept ence of this
"expert" information by non-experts. Since the original source of this story
allowed one of his friends to forward it to RISKS, it is very likely that many
other channels of communication has been used to speard this story.
Undoubtabley there are now more people who are now even less confident in the
air traffic control system, based on completely erroneous information. It seems
to me that this is a much greater risk then it might appear on simple
reflection. As our society becomes increasingl y technical, it becomes less
possible for each individual to determine if information outside their area of
expertise is correct. Unfortunately, I submit that most "technical" information
that is disseminated is in fact either incorrect or, even worse, deliberately
distorted. Try watching reading your local newspaper or watching TV news
programs and pay close attention to the level of accuracy in technical matters.
A very good example to the current "debate" on the greenhouse effect - people
with a political agenda are attempting to lead the public`s opinion by
selective use of information. Indeed, some "greenhouse backers" have been
candid enough to admit that they do not feel that real evidence of any such
phenomena is required, rather a public perception of a problem is all they
require. Remember the ridicule when then President Reagen said that plants were
the largest contributors of carbon dioxide "polluiton". Well, there is growing
evidence that the rise in CO2 may well be largely due to purely natural
effects caused by plants - a process that man likely cannot alter for good or
ill. But this is not politcally correct science, so it is buried in silence.
And witness the neat trick used in another recent RISKS article about bank
computer security - banks have security problems, they don't want them
discussed, so if they deny there are any this is proof they don't like to
discuss problems (you are mentally ill and the fact that you deny this is proof
that you are mentally ill). It is very likely that most readers of this piece
simply believed the implication that such massive breaches of systems is common
and (for the hacker) simple. Unfortunately, there is no proof of the claims.
Many of these stories have a suspicously similar format and are strikingly like
many of the popular urban myths - no hard evidence, but "I heard from someone
that they heard".

Faced with the pronouncements of experts or those percieved as experts, how can
outsiders make correct decisions, if the experts are supplying false or
misleading information? Perhaps we should all start examining our sources more
critically, but more important, we should make certain that we are not
responseable for spreading misinformation. Are you certain that the person to
whom you just explained a techincal matter outside their field really
understood what you said? Do you pass on as "true", information you only
partially (mis)understand. Above I implied that the ROTC student was to blame
for the mistaken information about radar, but perhaps the listener gleaned that
"fact" when something quite different was said. The wise man speaks only what
he knows is the truth and knows his own ignorance.

Richard Neitzel National Center For Atmospheric Research Box 3000
Boulder, CO 80307-3000			 303-497-2057

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: A320s and Northwest Airlines (<A HREF="/Risks/10.50.html">RISKS-10.50</A>)
</A>
</H3>
<address>
"Craig A. Finseth" 
&lt;<A HREF="mailto:fin@unet.unet.umn.edu">
fin@unet.unet.umn.edu
</A>&gt;
</address>
<i>
Tue, 16 Oct 90 09:16:51 -0500
</i><PRE>

I hate to deflate a good story, but there is another reason why 747-400s are
used on the Minneapolis to Detroit run.  The 747-400s are mainly intended for
trans-Pacific use.  However, each aircraft that is intended for such
international use must first be operated within the US before it is certified
by the FAA.  I believe that the operation is both in total hours and in
takeoffs/landings.  Hence, using short runs allows the airplane to accumulate
many takeoffs and landings.  In addition, the large capacity of the aircraft
allows better use of the heavily-travelled corridor (I believe that they take
two smaller planes off the run).

Craig A. Finseth, University Networking Services, University of Minnesota
130 Lind Hall, 207 Church St SE	 Minneapolis MN 55455-0134 +1 612 624 3375 

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Technophilia-induced problem at Educom?
</A>
</H3>
<address>
&lt;<A HREF="mailto:r.aminzade@lynx.northeastern.edu">
r.aminzade@lynx.northeastern.edu
</A>&gt;
</address>
<i>
Tue, 16 Oct 90 13:55:32 EDT
</i><PRE>

Today's EDUCOM keynote speech, by former President Jimmy Carter was
open-captioned for the hearing impaired.  The big-video display in the
auditorium showed a textual representation of the speech as Carter spoke.  This
was provided by "11-Alive," an Atlanta television station.
 
The system must have used some kind of voice-recognition algorithm, because no
human typist that I know could have kept up with the speaker at times.  The
weakness of the voice-recognition system was made painfully obvious to
attendees, when those with the ability to hear the presentation noticed
substitutions like:
 
"man well" noriega, "wak dem iks" for academics, "oath yope yam" for Ethiopia,
"Jap neens" for Japanese, "My Robe by" N Nairobi for "Ken Yeah" for Kenya,
"Home Jean yes" for homogeneous.

Carter's speech was thoughtful and moving (he talked about academia's moral
responsibilities to the third world), but the seriousness of the speech was
undercut by the occasional giggle from the audience.

Later in the speech, human control seemed to be asserted a bit more, and
"another country" was frequently substituted for the name of a third-world
country, but Carter must have been most puzzled when he explained that the
Carter Foundation was nonpartisan, and that "Prominent Republicans" worked
closely with him on every major project.  It was presented to the
hearing-impaired (and to the rest of us) as "Prominent Rubble Cans."  Of
course, the audience broke into laughter, and I suspect he still doesn't know
why.

I'm a strong supporter for appropriate adaptive technology, but a low-tech
solution (an ASL interpreter) would have been less distracting and reached many
(though not all) of the hearing-impaired.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-25</DOCNO>
<DOCOLDNO>IA013-000136-B030-29</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.52.html 128.240.150.127 19970217040436 text/html 12720
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:03:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 52</TITLE>
<LINK REL="Prev" HREF="/Risks/10.51.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.53.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 52</H1>
<H2> Wednesday 17 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Re: "Pilot error" and Human Factors 
</A>
<DD>
<A HREF="#subj1.1">
P.F. Spelt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Be careful of what you give away! 
</A>
<DD>
<A HREF="#subj2.1">
M. Freeman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Technophilia-induced problem at Educom? 
</A>
<DD>
<A HREF="#subj3.1">
Benjamin Ellsworth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Passwords and chess 
</A>
<DD>
<A HREF="#subj4.1">
Steve Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  "Expert Systems in the Loop" explained 
</A>
<DD>
<A HREF="#subj5.1">
Martyn Thomas
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: "Pilot error" and Human Factors
</A>
</H3>
<address>
SPELT P F 
&lt;<A HREF="mailto:sfp@stc06.CTD.ORNL.GOV">
sfp@stc06.CTD.ORNL.GOV
</A>&gt;
</address>
<i>
Wed, 17 Oct 90 09:50:46 EDT
</i><PRE>

In his article posted in RISKS forum of 15th October 1990, Robert
Dorsett made a comment about the A320/human interface which triggered a
"respond NOW" action in me.  I am a psychologist working at ORNL in
human factors -- the study of the way people and their machinery (for
work or play) interact.  Dorsett said:

&gt;I suggest (again) that the way the airplane interacts with the pilot is
&gt;at LEAST as important as component-wise reliability.

I say:  YOU BET!!!  My work in human factors (HF) for various projects,
some involving computerized interfaces, some not, has yielded various
comments.  The worst kind is:  "HF is just common snese."  Oh, yea?
Then why have we had SO MANY instances of poorly designed devices
creating "human error", aka "pilot error" in the cases of the A320 and
other aircraft crashes?  Another major porblem, also suggested in
Dorsett's posting, is the use of HF consultation.  The prevailing modus
operandi has traditionally been to design the system, call in the HF
consultants for evaluation, then have them design a training program to
"train around" the problems designed into the system.  Such training
will "work" adequately until a major off-normal event (like TMI), when
the operator is unable to react properly to (interact properly with?)
the mis-designed system.

As we come to design and install more and more complex computerized
interfaces between the machinery and the humans using it, we run the
serious risk of making even greater design errors, many of which will
not show up at all until a major off-normal occurrence comes along.  The
introduction of artificial intelligence (AI) into these interfaces adds
an additional dimension along which design errors will propagate.  These
concerns have been very adequately covered in the postings on the Aegis
system (Expert System in the Loop postings), although there WAS no ES in
that system.


Several  of us at ORNL are involved in research into the use of AI in
"operator associates" for various settings.  The potential for using
intelligent icomputerized interfaces is already being explored in a variety of
settings, but many issues remain to be settled, as the Aegis discussion
has highlighted.  These issues need BASIC research directed to answer
the questions raised.  In this era of increasingly tight budgets,
however, finding support for that basic research is very difficult.
Hrowever, if we don't address these issues, there will continue to be an
increased number of "operator error" accidents analogous to the A320
"pilot error" crashes.

The usual disclaimers apply: These opinions are my own, and do not necessarily
reflect those of ORNL, the Department of Energy, or Martin Marietta Energy
Systems.
                              email:  sfp@stc10.ctd.ornl.gov@UMCGATE@OAX
Phil Spelt   bldg 6025, ms 6364 POBox 2008 Oak Ridge, TN 37831-6364

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Be careful of what you give away!
</A>
</H3>
<address>

&lt;<A HREF="mailto:M.FREEMAN@csi.compuserve.com">
M.FREEMAN@csi.compuserve.com
</A>&gt;
</address>
<i>
17 Oct 90 10:33:07 EDT
</i><PRE>

&gt;From CompuServe's Online Today Forum Data Libraries:

                       MONITOR MONTH IN REVIEW
                            September 1990

    FEDS SEIZE COMPUTERS IN KY. TOWN (Sept. 2): Federal agents over the
    weekend seized computer equipment from a Nancy, Ky., business office
    when it was learned that the computers might contain secret
    government files. The owner of Challenger Ltd., Charles Hayes, said
    federal marshals came 70 miles from the US attorney's office in
    Lexington, Ky., to seize nine computer terminals, a computer memory
    device and other equipment which were purchased from the government
    for $45."


This shows a Risk from computer equipment you are trying to get rid of.  Make
sure you are only getting rid of the equipment, and not giving away copies of
your data!  A tape bulk-eraser probably does a nice job on old tapes and hard
drives.

Mark Freeman                       Microcomupter Technology Specialist/Analyst
CompuServe                                        M.Freeman@CSI.CompuServe.COM

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re:  Technophilia-induced problem at Educom?
</A>
</H3>
<address>
Benjamin Ellsworth 
&lt;<A HREF="mailto:ben@hpcvlx.cv.hp.com">
ben@hpcvlx.cv.hp.com
</A>&gt;
</address>
<i>
Wed, 17 Oct 90 10:02:19 pdt
</i><PRE>

&gt; The system must have used some kind of voice-recognition algorithm,
&gt; because no human typist that I know could have kept up with the
&gt; speaker at times.

I very strongly doubt this.  I would bet a substantial sum of money
that there was a stenographer and not a computer capturing the words.

&gt; The weakness of the voice-recognition system was made painfully
&gt; obvious...

There is RISK of assuming all failures are technologically induced.  It
could very well be that the stenographer hired was simply not very
good.  The good ones are expensive, and to do "real-time" stenography
takes a good stenographer.

There is a plausible explanation involving computer RISKs however.  The
translation from the steno notation to full english words was in all
likelyhood automated.  In stenography there are a number of dialects
(usually called theories).  Some dialects, especially the older ones,
are not particularly suitable to machine translation.  There are also
more than a few translation programs.  Between stenographic dialects
and computer translators there can be a significant compatibility
problem.  It could be that the stenographer was extremely capable in
the courtroom (where the translations are done off-line by a human),
while at the same time using a style/dialect/theory which was
incompatible with the machine translator.

There has been an interesting interaction between technology and court
recording in the last couple of decades.  My mother, for instance,  is
in the process of re-learning her stenography in a computer compatible
dialect.  It reminds me of pilots who have to learn to fly in a
computer compatible way (training around system weaknesses). 

Benjamin Ellsworth ben@cv.hp.com         All relevant disclaimers apply.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Passwords and chess
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@ulysses.att.com">
smb@ulysses.att.com
</A>&gt;
</address>
<i>
Tue, 16 Oct 90 22:46:39 EDT
</i><PRE>

Well, since we're talking about chess, here's a tidbit from Saturday's
NY Times, in an article about the Kasparov-Karpov match:

	Trying to meet a noon deadline yesterday for invoking the
	time-out, Lajos Portisch, a Hungarian grandmaster who is Mr.
	Karpov's second, telephoned Geurt Gijssen, a Dutchman who is
	chief arbiter of the match, at 11:53 A.M.

	How was the arbiter to be sure it really was Mr. Portisch on
	the line?

	The Hungarian, who had considered a singing career early in
	life -- a fact known to some chess experts -- suggested singing
	something in his distinctive voice.  Mr. Gijssen agreed, and
	Mr.  Portisch burst forth with several bars of a Hungarian
	song.

	The arbiter granted the postponement, although the written
	request for the time-out arrived late, at 12:07 P.M.

Sounds like they need some sort of challenge/response scheme; that
password is blown...

		--Steve Bellovin

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"Expert Systems in the Loop" explained
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Wed, 17 Oct 90 18:28:08 +0100
</i><PRE>

 davis@ai.mit.edu (Randall Davis) writes:

&gt;As for the title of this whole discussion -- "Expert systems in the loop":

&gt;2) There aren't any and there never were any.
&gt; ... ...
&gt;So until otherwise informed, let's be clear about this: it was a problem of
&gt;"Instruments in the loop".  That by itself may be worth discussing, but it is
&gt;not and never was an expert system.  And it might be interesting to ask, Why
&gt;the rush to label it an expert system?

The original article was mine, and referred to a report of a new research
project in the UK to develop an expert system to advise commanders in
tactical situations which are too complex to analyse without assistance.

This report *explicitly* referred to an expert system. The point of my
original posting was that an expert system which provides advice, in
circumstances where a decision must be made and there is insufficient time
for the commander to analyse the situation him/herself, is effectively
making the decision. Many who followed up agreed with this viewpoint. I
apologise for mentioning the USS Vincennes - it distracted attention from
the major point, and wasted a lot of net bandwidth. So far as I recall,
noone, throughout the discussion, suggested that Aegis is an expert system. 

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-26</DOCNO>
<DOCOLDNO>IA013-000136-B030-46</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.53.html 128.240.150.127 19970217040448 text/html 20623
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:03:18 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 53</TITLE>
<LINK REL="Prev" HREF="/Risks/10.52.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.54.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 53</H1>
<H2> Wednesday 17 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Lies, damn lies, and statistics... computer cabin-safety 
</A>
<DD>
<A HREF="#subj1.1">
Robert Dorsett
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Ada MultiTasking 
</A>
<DD>
<A HREF="#subj2.1">
Edward V. Berard
</A><br>
<A HREF="#subj2.2">
 Bertrand Meyer
</A><br>
<A HREF="#subj2.3">
 Robert Firth
</A><br>
<A HREF="#subj2.4">
     Ray Diederich
</A><br>
<A HREF="#subj2.5">
 Brian Hanafee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Technophilia-induced problem at Educom? 
</A>
<DD>
<A HREF="#subj3.1">
Miles R. Fidelman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Lies, damn lies, and statistics...
</A>
</H3>
<address>
Robert Dorsett
&lt;<A HREF="mailto:rdd@ccwf.cc.utexas.edu ">
rdd@ccwf.cc.utexas.edu 
</A>&gt;
</address>
<i>
Wed, 17 Oct 90 16:50:58 -0500
</i><PRE>

&gt;From FLIGHT INTERNATIONAL, September 26, 1990

CALL FOR COMPUTER CABIN-SAFETY TEST

"Future cabin safety testing for new airliners should be determined by
computer-based analysis, according to Michel Le Clerc, Airbus Industrie's
deputy chief engineer, widebodies.

"Practical evacuation tests are limited in their scope, produce unreliable
conclusions, are dangerous for participants and extremely expensive, said
Le Clerc at the conference.

"Le Clerc wants intensive studies of evacuation tests and actual accidents
to be conducted, saying, 'Steps should be taken to set up a database and
computer model available to everyone.  Sufficient data already exsits for
the necessary analysis' ...although unconventional configurations may require
testing," he adds.

"A full certification test evacuation program costs about $1 million for a 
narrowbody and $2 million for a widebody, points out Le Clerc, and about
one in ten people are injured."

Just a couple of comments. :-)

1.  $1-$2 million is about 0.03% to 0.1% of the total development costs for a 
new aircraft.  On a 2000-aircraft production run, the per-aircraft cost will
be about a thousand dollars, or .0014% of the cost of a $70 million airplane.  
We're talking peanuts, here.

2.  The notion that a *computerized* model will work, whereas earlier models
have failed, is of concern.  Statistical analysis of exits is nothing new.
However, time and time again, such analyses tend to cut corners, to rely on
ideal conditions, and use admittedly imperfect evidence (the same "data",
I'm afraid, that Le Clerc's referring to).  Problems are usually shown in 
practical demonstrations.  However, by using "data" and putting it into a 
"computer," it becomes much more difficult to refute that model's 
"conclusions."

3.  Part of the reason for Airbus's desire to rely on models is its enormous
investment in a massive CAD/CAM/documentation system.

4.  The last major fiasco which involved the use of raw statistics to set
evacuation policies was when Northwest, and other operators, petitioned the
FAA to seal the over-wing exit doors of 747-200's.  The FAA's northwest
district approved it, but the national branch overturned the approval, citing
unnecessary risk.  

The entire industry has also been collaborating in certifying twin-engine air-
planes for extended-range over-water operations, a controversial issue at
best.  This summer, a proposal arose to also use models in lieu of practical
demonstrations.


I think it's only a matter of time before a major manufacturer petitions for 
a waiver of major airframe "practical" tests in favor of simulations.  After
all, if they can build it, the theory can't be wrong, right?  Or something
like that.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Ada and Multitasking
</A>
</H3>
<address>
Edward V. Berard
&lt;<A HREF="mailto:eberard@bse.com ">
eberard@bse.com 
</A>&gt;
</address>
<i>
Fri, 12 Oct 90 05:44:44 EDT
</i><PRE>

&gt; The author then describes several features of the Ada language, such as data
&gt; typing, separate compilation units, and concurrent tasks. 
&gt; The RISKy bit comes in the discussion of task priorities.  [...]

This "problem" is more one of a misunderstanding of the capabilities of the Ada
language than an actual language definition problem. A serious user of Ada
should know that some things, especially in the area of tasking, are defined in
a non-deterministic manner. This is usually phrased in terms like "if several
select alternatives are open, one will be selected in a non-deterministic
manner."

Yes, each implementer (of an Ada compiler) does indeed have a certain amount of
freedom in choosing how to do scheduling, and the Ada programmer has the option
of leaving it entirely up to the compiler to select a particular alternative.
Further, this definitely has the potential of different behaviors as a result
of using the same source code with different Ada compilers.

However, if this is truly unacceptable to the program's author, it is entirely
possible to write the same code in such a way that it behaves in exactly the
same manner on all Ada systems. This does not even require "tricky code."

Writing portable and predictable code using Ada is definitely possible, and,
and for that matter, is done all the time. Please be aware of the fact that
Ada does not force you to write only deterministic tasking code, but does
provide you the capability to do so if you desire.

&gt; ... A language which boasts high portability and reliability includes
&gt; features which mean that there is no guarantee that a program will work the
&gt; same way if ported to another compiler and/or run-time environment.

If I went out of my way not to learn the proper semantics of the language,
and worked at writing non-portable code, this would be true.

The crux of the matter is really flexibility. If the designer of the Ada
language (Jean Ichbiah) decided that there was only one way to set priorities,
he could have built that into the language. Unfortunately, not everyone would
have agreed on that mechanism. So, Ada was designed in a manner which gives the
programmer a choice:

	a. Allow the underlying implementation to select among a set of choices
	   in a non-deterministic manner, or

	b. Force a particular, programmer-defined set of priorities, which can
	   always be the same regardless of the compiler implementation

&gt; Does anybody have any experience (good or bad) in porting Ada programs, in
&gt; particular real-time programs?

My experience (hundreds of thousand of lines of code ported to many different
platforms) shows that it is possible to routinely write very portable,
predictable Ada code. However, I have seen the following:

	* A poorly trained Ada programmer determines the underlying scheduling
	  algorithm for his or her Ada compiler and writes code to take
          advantage of this scheduling algorithm. Problems occurred when:

          - a new version of the compiler came out with a different scheduling
            algorithm,

          - the source code was ported to an Ada compiler with a different
            scheduling algorithm, and/or

          - the programmer did not understand (or correctly identify) the
 	    underlying scheduling algorithm.

	* An Ada programmer realized that Ada compiler writers have a certain
	  amount of flexibility when it comes to some (not all) priority
	  issues, and then wrote very deterministic code. However, the actual
	  application called for non-deterministic code. (This problem is
	  very similar to having a "not-so-random" random number generator.)

There are definitely risks associated with this issue. However, one must be
careful in identifying the source. For example, if an Ada programmer is poorly
trained, should we blame the language, the programmer, or management?
                                        				-- Ed

Edward V. Berard, Berard Software Engineering, Inc.  18620 Mateney Road
Germantown, Maryland 20874                      Phone: (301) 353-9652

</PRE>
<HR><H3><A NAME="subj2.2">

</A>
</H3>
<address>
&lt;<A HREF="mailto:bertrand@eiffel.UUCP (Bertrand Meyer @ Interactive Software Engineering">
bertrand@eiffel.UUCP (Bertrand Meyer @ Interactive Software Engineering
</A>&gt;
</address>
<i>
Fri, 12 Oct 90 15:30:27 PDT
</i><PRE>
Subject: Re: Ada and multitasking (RISKS 10.48) 

	In his contribution to RISKS 10.48, Erling Kristiansen criticizes Ada's
concurrency features (the tasking mechanism) as hampering reliability because
the language definition leaves room for more than one possible program response
to the same sequence of events, depending for example on the way the scheduler
handles task priorities to reflect various possible fairness policies.  In his
words, this highlights a contradiction between portability and reliability.

	Regardless of one's opinion about Ada's support for reliable
programming (concurrent or not), which certainly leaves room
for criticism, Mr. Kristiansen's comments seem based on an
over-restricted view of reliability. In his opinion,

	``A language which boasts high portability and reliability
	[must not] include features which mean that there is no guarantee
	that a program will work the same way if ported to another compiler
	and/or run-time environment.''

Depending on how one defines ``work the same way'', this requirement
is either appropriate or too strong.

	It is too strong if ``working the same way'' means always executing the
same actions in the same order as a response to the same input events. After
all, isn't non-determinism a fundamental aspect of concurrency? Even in a
purely sequential world, one can hardly guarantee that computations (on
floating-point numbers, for example) will execute identically on all computers.

	The only productive way of transforming the above into a realistic
requirement is to accept that a program, or program element, is based on a
higher-level description of intended semantics - in other words, a
specification. (I have called this ``programming by contract'' in various
publications, some of which, incidentally, directly criticize another aspect of
Ada, its exception mechanism, precisely for its possible risks to reliability.)
A specification states the required properties of the acceptable observable
behaviors of a software system. It does not need to prescribe only one behavior
as acceptable.

	Different implementations that behave differently, and possibly even
produce different observable results, are then acceptable as long as they
conform to the specification.

	Two of the possible reasons to leave certain properties open in the
specification are portability and the need to support various scheduling or
fairness policies. They do not conflict with the reliability requirement. To
take an obvious non-computer analogy, you may tell a taxi driver to get you to
point X in at most half an hour, without specifiying the itinerary, which is
not part of your definition of ``reliability'' for this trip.

	All this assumes, of course, that there is a way to express precise
specifications, which Ada does not provide, although some Ada-based tools,
notably Anna, do.

-- Bertrand Meyer                      bertrand@eiffel.com

</PRE>
<HR><H3><A NAME="subj2.3">
Ada MultiTasking
</A>
</H3>
<address>
&lt;<A HREF="mailto:firth@SEI.CMU.EDU">
firth@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Tue, 16 Oct 90 08:07:29 -0400
</i><PRE>

&gt;        ... Or one could blame the language.

Or, of course, one could ask that the instructor take the trouble to learn the
language he proposes to teach!  The Ada Reference Manual [RM 9.8(4)] mandates
exactly this behaviour:

	If two tasks with different priorities are both eligible
	for execution and could sensibly be executed using the
	same physical processors and the same other processing
	resources, then it cannot be the case that the task with
	the lower priority is executing while the task with the
	higher priority is not.

In other words, and without any vagueness whatever - run the higher
priority task until it ends, and then run the lower priority task.

Robert Firth

</PRE>
<HR><H3><A NAME="subj2.4">
Re: Ada MultiTasking
</A>
</H3>
<address>
Ray Diederich
&lt;<A HREF="mailto:diederich_r_%ncsd.dnet@gte.com ">
diederich_r_%ncsd.dnet@gte.com 
</A>&gt;
</address>
<i>
Tue, 16 Oct 90 14:54:42 -0400
</i><PRE>

In RISKS 10.50, Chet Laughlin &lt;ctl8588@rigel.tamu.edu&gt; writes:
&gt;The first lab involved two tasks running in pa[r]ellel.  In reality it was
&gt;figured that the tasks would time-slice on a single machine.  However, this 
&gt;was not the case.  The compiler would simply run the highest priority task 
&gt;until it ended, and then run the lower task.  ...

In response, ANSI/MIL-STD-1815A, chapter 9, paragraph 2 states:
&gt;Tasks are entities whose executions proceed *in parallel* in the following
&gt;sense. Each task can be considered to be executed by a logical processor of
&gt;its own. Different tasks (different logical processors) proceed
&gt;independently, except at points where they synchronize. 

Nowhere in this paragraph nor the surrounding text is the idea of time-slicing
mentioned nor implied. Depending on time-slicing is erroneous programming,
because it means depending on characteristics which are out of the control of
the programmer. Further, resorting to time slicing is simply a way of saying "I
don't know how to best schedule these tasks; you, the compiler, may schedule
them for me." Ada supplies several synchronizing tools which allow logically
concurrent processing without depending on time-slicing.

Time-slicing gives you a means of relieving your responsibility to solve your
real-time processing design problems -- at the expense of added overhead, less
control of your program, and less reliability in your system. Yet, every time I
come up against a problem which requires real-time performance, I find that
most of my peers start chanting "we need to time-slice, we need to time-slice."

I challenge any circumstance which would require time-slicing to be
"correct." If the point of Mr. Laughlin's project was intended to teach the
real-time use of the multiprocessor environment (by simulating
multiprocessing with tasks), I suggest that his choice of problems is
flawed. A good real-time multiprocessor problem requires interprocess
dependency (which may be implemented by Ada task rendezvous). Without the
interprocess dependency, you might as well cut the cables and run with
stand-alone processors.

In response to Erling Kirstainsen's article which originated the topic, any
time one resorts to erroneous programming methods, one sacrifices
reliability and portability. It's not the fault of the language nor the
associated hype. 

</PRE>
<HR><H3><A NAME="subj2.5">
Re: Ada MultiTasking (Laughlin, <A HREF="/Risks/10.50.html">RISKS-10.50</A>)
</A>
</H3>
<address>
Brian Hanafee
&lt;<A HREF="mailto:bhanafee@ads.com ">
bhanafee@ads.com 
</A>&gt;
</address>
<i>
Tue, 16 Oct 90 12:19:25 -0700
</i><PRE>

The basic error is contained in the statement: "In reality it was figured that
the tasks would time-slice on a single machine."  This assumption is in direct
contradiction of the Ada LRM, section 9.8, paragraph 4:

     "If two tasks with different priorities are both eligible for
     execution and could sensibly be executed using the same physical
     processors and the same other processing resources, then it
     cannot be the case that the task with the lower priority is
     executing while the task with the higher priority is not."

Running the higher priority task until it ended was the correct behavior!

	Much of the difficulty people have with Ada tasking is (in my
opinion) related to the fact that the Ada tasking model does not
assume (nor preclude) a time-slicing mechanism.  I believe the Apple
Macintosh Multifinder implementation is another example of
multitasking without time slicing.

	The decision to use or not use time slicing should be based on a number
of factors including the availability of a clock to cause interrupts, the cost
of saving the machine state, and the benefit of "fair" scheduling.  The
availability of an appropriate clock is not a given for all computer systems,
particularly embedded systems.  Furthermore, the cost of saving the machine
state at a random point in the execution of the program is almost always
greater than the cost of saving state only at predefined points such as task
entry and exits.  The benefit of "fair" scheduling occurs frequently in
multi-user systems where users are often competing for the same resources,
however in dedicated or embedded systems, the designers could use tasking and
programming discipline to enforce "fair" scheduling without requiring the
additional overhead of time-slicing.  The decision to use or not use time
slicing is usually made by the compiler vendor (although ideally it should be
switchable by the compiler user); programs in Ada (or any other language) which
depend on a particular implementation are erroneous.

Brian Hanafee                                     bhanafee@ads.com

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Technophilia-induced problem at Educom? (<A HREF="/Risks/10.51.html">RISKS-10.51</A>)
</A>
</H3>
<address>
"Miles R. Fidelman" 
&lt;<A HREF="mailto:mfidelma@BBN.COM">
mfidelma@BBN.COM
</A>&gt;
</address>
<i>
17 Oct 90 17:14:32 GMT
</i><PRE>

I've seen a talk where real-time transcription was provided by court
stenographers.  They used a version of a stenotype machine coupled to display
software.

Stenotype machines have phonetic keyboards, and their raw output looks very
much like what is described here. In courtroom practice, a clean transcript is
made later. In the talk I saw, some software provided partial on-the-fly
cleanup, but no where near perfect.

Another reader comments that an ASL translator would be preferable. My own
take is that for technical talks this real-time transcription seems better able
to catch technical vocabulary.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-27</DOCNO>
<DOCOLDNO>IA013-000136-B030-74</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.54.html 128.240.150.127 19970217040504 text/html 22642
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:03:35 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 54</TITLE>
<LINK REL="Prev" HREF="/Risks/10.53.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.55.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 54</H1>
<H2> Thursday 18 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Flawed computer chip sold for years 
</A>
<DD>
<A HREF="#subj1.1">
Al Stangenberger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The slippery slope of personal identification and tracking 
</A>
<DD>
<A HREF="#subj2.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Technology Meets Dog; Dog Wins 
</A>
<DD>
<A HREF="#subj3.1">
Sanford Sherizen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Pilot error and human factors 
</A>
<DD>
<A HREF="#subj4.1">
ark
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Airliner story 
</A>
<DD>
<A HREF="#subj5.1">
Bob Sutterfield
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Pilot Error, Human Factors, and Common Sense 
</A>
<DD>
<A HREF="#subj6.1">
Irving Chidsey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Closed Captioning at Educom 
</A>
<DD>
<A HREF="#subj7.1">
Gary Coffman
</A><br>
<A HREF="#subj7.2">
 Lauren Weinstein
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Flawed computer chip sold for years
</A>
</H3>
<address>
&lt;<A HREF="mailto:forags@violet.Berkeley.Edu">
forags@violet.Berkeley.Edu
</A>&gt;
</address>
<i>
Thu, 18 Oct 90 10:41:23 PDT
</i><PRE>

Al Stangenberger, Dept. of Forestry &amp; Resource Mgt., Univ. of Calif.
Berkeley, CA  94720  uucp: ucbvax!ucbviolet!forags BITNET: FORAGS AT UCBVIOLE

From KRTN News Wire, reported in Marin Independent-Journal (San Rafael, CA)
3 Oct 90 page B4:

SUNNYVALE - A strangely flawed computer chip was sold by the millions by
National Semiconductor Corp. here between 1987 and last spring, with a
potential for causing bizarre failures in computer systems.  The chip's
potential for mischief is significant because it was used by major computer
makers for more than two years, and some may not be aware of the potential for
problems.

National first learned the chip had a design flaw in 1987, but it wasn't until
January that the company stopped shipping it, according to a lawsuit filed in
June by a former employee.  The firm had a "large inventory" of the chips it
didn't want to "dispose of as non-functional," claims the suit by Michael
Parsin of Sunnyvale, a former managing engineer in the department product group
responsible for the chip.  "We did identify some isolated problems with that
part among some customers," said Mary Coady, spokeswoman for National
Semiconductor.  "The company took steps to address the problem -- a bunch of
steps.  Of hundreds of customers for millions of parts that were shipped, I am
told we have relatively few ... complaints", Coady said.

The chip tracks the time and date in computers and other electronic systems.
In certain applications, it has had a tendency to skip forward one day, with
unexpected results:

&gt; The United Nations International Atomic Energy Agency used the chip in a
new television security system for guarding nuclear fuel in atomic power
plants worldwide, according to agency official Klaus Gaertner.  Problems
cropped up in one monitoring system, and design changes had to be made to
protect the chip from electronic noise, Gaertner said.  The chip is the
suspected cause of the problem, but more testing may be needed to know for
sure, said another engineer familiar with the system, who added that it
would be very costly to replace them at this point.

&gt; A Canadian company had difficulties with the chip on a military system.
"It was a real problem," according to George Bleier, a project engineer
with Marconi Canada who said it had problems in a system for a foreign
military customer.  "We were just flabbergasted."  He said he complained by
letter in 1988 and National fixed the problem, but only this year did the
firm finally apologize.

&gt; A financial program for a company was set up to print paychecks on
Fridays, but the chip caused the computer -- made by a major manufacturer -
- to skip from Thursday to Saturday, leaving employees with no paychecks,
according to an engineer familiar with the computer.

&gt; A computerized trip recorder for long-distance trucks printed reports
that made the truck look as though it were traveling at impossible speeds
and "doing impossible things."  The system frequently shut down, said an
engineer at Rockwell International Corp. who worked on the system.  The
chip had to be replaced with another version.  "It was a fiasco," said the
engineer, who asked not to be identified.  "If I go in there and say
'National time chip,' (my boss) goes through the roof."

National said "some isolated problems" have been reported in the chip --
problems that seem to occur more frequently in even-numbered years.
Exposure to electronic "noise" triggers a tendency to flip from 24- to 12-
hour time with unfortunate results, said some engineers who have used it.
A new version does not have the problem.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
The slippery slope of personal identification and tracking
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Thu, 18 Oct 90 08:51:51 EDT
</i><PRE>

It was reported in last Sunday's New York Times that Princeton University has
installed a new security system at one of its colleges (groups of related
dorms and such).  The doors to the college, heretofore always open, are now
locked.  Residents of the college have "proximity" access cards which unlock
the doors.  Such cards can be sensed from a reasonable distance (e.g., if you
carry your card in your wallet, the door will unlock as you approach it).
Others at the university can use their magnetically-encoded cards in a "swipe"
reader to unlock the doors.  Non-university people are supposed to be greeted
at the entrance.

Princeton intends to install the same system at all its colleges over a period
of time.  The system is described by the university as "monitored 24 hours a
day from a central location" (not an exact quote); precisely what this means
and why anyone should care isn't clear, but apparently the university con-
siders this a good thing which should instill confidence in the system.

The Times reports that some students at the college are complaining about the
inconvenience caused by the system.  The university justifies the system as
necessary for safety - there have been several "incidents" on campus of late -
and the inconvenience minor.

What no one mentions, at least in the article, is the potential such a system
has for invading privacy.  A card reader of this sort has the ability to track
who goes where and when on a campus.  Systems of this sort that I've seen log
every use of a card.  That log is subject to misuse.  Suppose some government
agency decides that student X is a dangerous radical, fomenting revolution.
What a simple matter to track him and look for people who go to the same
places he does - just check the logs.  There's a long history of exactly this
kind of investigatory technique - taking photographs of cars parked near
demonstrations and checking for license plates that show up more than once,
for example.  It's also clear that, historically, most institutions have not
resisted government attempts to gain access to such information; and that even
when they do, the government can usually get a subpeona.  Note that failing to
collect information that a system can easily collect doesn't help - the gov-
ernment could easily demand that a logging system be turned on, just as it can
require the telephone company, under appropriate court order, to track usage
of a phone.

The fact that proximity cards are used makes the system all the more danger-
ous.  First of all, you can be tracked without taking any specific action -
which means you'll have a hard time knowing when you might be tracked, and
won't be able to avoid it.  (Leaving the card home may not be a solution -
usually, it's an id card that you MUST have to accomplish almost anything).
Second, it makes the system virtually invisible, so people don't think about
the implications as much.

Now, I don't want to over-emphasize the dangers, such as they are, of the
particular system at Princeton.  The data will likely be fairly "course" -
the cards give you access to a college, which is home to hundreds of people,
not to individual rooms - and it PROBABLY won't be abused.  But there's an
underlying issue here which has received too little discussion:  One side-
effect of many recent technologies has been to make tracking of individuals
a quick and painless matter.  Every time you use your bank card, you are
providing a central system with a real-time trace of where you are.  These
days, every time you use a credit card, it's checked with a central system -
again providing a trace.  How many people know that their cellular telephones
can be made to report, with no indication that they've been polled?  This
ability is an inherent part of the implementation of cellular systems, and
even at its most limited allows the phone to be located to the nearest cell.
In practice, with some effort one can usually locate the phone much more
precisely, since some directional information is available and there is also
usually signal strength information for several cells.  The only way to keep
the phone from responding is to turn it off.

Some losses of privacy are obvious; others are insidious, occurring as unin-
tended side-effects of otherwise benign and even very useful technologies.
The cumulative results can be the same, however.

In one of his science fiction books, Fred Hoyle speculates on how a universal
"person tracking" system might come to be imposed.  Initially, the system is
created as a means to keep a small elite continuously accessible and safe.
High government officials today accept a constant surrounding of protective
forces and communication agents; making the tracking more automatic would only
improve their situation.  In Hoyle's argument, over time, more and more people
are considered to be important enough to warrant the privilege of being part
of the system; it's considered an honor.  Eventually, though, EVERYONE becomes
part of the system.

Constant accessibility, first with pagers, now with cellular phones, has in-
deed developed more or less along these lines.  Constant position location,
at least ACKNOWLEDGED constant position location, has not so far.  Instead,
it's creeping in even more insidiously, piggy-backing along with apparently
unrelated systems.
							-- Jerry

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Technology Meets Dog; Dog Wins
</A>
</H3>
<address>
Sanford Sherizen 
&lt;<A HREF="mailto:0003965782@mcimail.com">
0003965782@mcimail.com
</A>&gt;
</address>
<i>
Thu, 18 Oct 90 08:35 EST
</i><PRE>

Amid all of the problems posted here, a dog-bites-phone risk is worth noting.  

NETWORK WORLD, October 15, 1990 had an article on AT&amp;T Tariff 12 deals.  In the
article, the following appeared.

"On a lighter note, it seems a new type of long-distance fraud is making the
rounds, as Tom and Bonnie Robb of Aliso Viejo, Calif., can attest.

When their telephone bill arrived recently, they had a difficult time figuring
out who had made $28 worth of toll calls to Sports Pick and the Adult Date line,
according to a recent story in the HARTFORD COURANT.

But it turned out to be their cocker spaniel, who was using a large-faced
push-button telephone.  The Robbs had attempted to teach the dog to dial 911 by
smearing peanut butter on the corresponding buttons of the keypad.

The dog had apparently taken to knocking the handset off the receiver and
dialing telephone numbers, inadvertently dialing the 900 numbers."

W-H-Y were the Robb's attempting to teach their dog that trick?  Are peanut
butter manufacturers accessories to a crime?  Did the dog enjoy the Adult Date
Line?  Are we sure that the dog *inadvertently* dialed those numbers?  What
animal species will next turn to crime?  
                                                  Sandy

                  [Next the dog will learn how to imitate the touch tones, 
                  and its bark would be much worse than a byte.  PGN]
 
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Pilot error and human factors
</A>
</H3>
<address>
&lt;<A HREF="mailto:ark@research.att.com">
ark@research.att.com
</A>&gt;
</address>
<i>
Thu, 18 Oct 90 08:56:04 EDT
</i><PRE>

A few days ago I saw a comment on rec.aviation about `pilot error' from a
flight instructor who had just come back from an AOPA recertification clinic.
Among the notes from that clinic were that 75% of the pilots involved in
accidents where the cause had been established as `pilot error' were at the
time going through a marriage, divorce, or career change.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Airliner story (<A HREF="/Risks/10.49.html">RISKS-10.49</A>)	
</A>
</H3>
<address>
Bob Sutterfield
&lt;<A HREF="mailto:bob@morningstar.com ">
bob@morningstar.com 
</A>&gt;
</address>
<i>
Thu, 18 Oct 90 14:24:14 GMT
</i><PRE>

Gene Spafford quotes RIch EPstein &lt;@VM.CC.PURDUE.EDU:REPSTEIN@GWUVM&gt;:
   Heavy rains leaked into the plane and knocked out the transponders
   and the auto-pilot computer.  About 15 minutes into the flight the
   pilot announced that we had to return to O'Hare because the air
   traffic controllers couldn't "pick us up".  In other words, we were
   invisible, in the clouds, at O'Hare... the pilot meant this
   literally.  Radar picks up aircraft by means of the signal sent out
   by the transponders.
   
Lack of a transponder return isn't really an immediate, major safety problem.
You weren't about to get bumped into.  Your flight was operating under
instrument flight rules (IFR), which means there was a very detailed flight
plan and clearance in effect.  Even if all two-way communications had been
rendered inoperative along with the transponder at the moment of takeoff, a
block of airspace would have been reserved for you as you moved along your
route.  Lost-comm procedures are a fundamental part of IFR flying, and provide
a nearly algorithmic "way out" of every situation.  Lacking a transponder but
maintaining communications, the crew would simply have been required to provide
regular verbal position reports, just like in the olden days (not so very long
ago) when ATC radar coverage wasn't so pervasive as it is now.  So being
invisible in the clouds isn't that big a deal, safety-wise.

I suspect that the loss of the autopilot was a more severe problem,
since it would drastically increase crew workload in every phase of
flight and would render some maneuvers (e.g. a Category III instrument
approach in the event of very bad (nearly zero/zero) weather at your
destination) impossible.  The airline's operations manual may list the
autopilot as a go/no-go or continue/abort item.  It may also list the
transponder as such, but it's not such a big operational safety issue.

   The pilot ... said that this was a good plane because it had
   "stainless steel aeronautical control cables", a reference to the
   fact that an Airbus would probably have been disabled completely in
   a similar circumstance.  I have no doubt that the pilot was
   referring to the Airbus when he made this remark.

Or maybe he was just reassuring you that the control systems weren't going to
rust and jam, and your personal worries about the Airbus (fueled by Gene's
stories from RISKS) filled in the "A320" between the lines.  Either way, this
is a more interesting issue, and possibly the main RISKS-related story to be
told about the incident.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Pilot Error, Human Factors, and Common Sense (Spelt, RISKS-10.5x)
</A>
</H3>
<address>
Irving Chidsey (INF) 
&lt;<A HREF="mailto:chidsey@BRL.MIL">
chidsey@BRL.MIL
</A>&gt;
</address>
<i>
Thu, 18 Oct 90 11:27:52 EDT
</i><PRE>

	Some years back I read a story in which an engineer was reprimanded 
because he had designed something without using "common sense".  His defense 
went approximately:

        `` `Common Sense' is a very rare commodity.  I am only an engineer
with a technical education, and must design as I was taught.''

							Irv

              [Or, put another way, common sense is not very common,
              in both senses of the word.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Closed Captioning at Educom (<A HREF="/Risks/10.51.html">RISKS-10.51</A>)
</A>
</H3>
<address>
Gary Coffman
&lt;<A HREF="mailto:gary@ke4zv.UUCP ">
gary@ke4zv.UUCP 
</A>&gt;
</address>
<i>
18 Oct 90 13:16:54 GMT
</i><PRE>

As a Gannett employee working at WXIA-TV in Atlanta (11 Alive) I can tell you
that voice recognition equipment is not used in our captioning system.  The
system is Atari 800 (!!!) based with a court stenographer's keyboard grafted on
to the computer. Real live human operators man the steno keys.  The errors
reported can be attributed to the fact that even Southerners can't always
understand Jimmy Carter and to the fact that our stenos can't spell nor do they
know geography or geopolitics. You should see some of the things we routinely
put on the air.
                                        Gary

</PRE>
<HR><H3><A NAME="subj7.2">
open captioning at conference (was: "Technophobia...")
</A>
</H3>
<address>
Lauren Weinstein
&lt;<A HREF="mailto:lauren@vortex.com ">
lauren@vortex.com 
</A>&gt;
</address>
<i>
Tue, 16 Oct 90 23:28:18 PDT
</i><PRE>

Without a doubt, the open captioning of Pres. Carter's speech was *not* being
done by an automated speech-to-text voice recognition system.  Continuous
speech voice recognition systems are still at a comparatively primitive level,
even when specifically trained for a particular speaker.  Recognition systems
for - dealing - with - separated - speech - are much more advanced, but still
normally need per-user training except for limited vocabularies, and wouldn't
be applicable in such a situation anyway.

What was almost certainly happening was that the conference was using a closed
captioning realtime speech transcription system to provide open captions in
this case.  The fact that the captions were being provided by a local
television station lends even more weight to this.  All of the commercial
television networks, and an increasing number of major metro area local
stations, are providing closed captioning for many of their major news-oriented
programs.

Unlike most non-news, non-sports programming, where shows for closed captioning
are sent off to the National Captioning Institute (NCI) for "offline"
captioning, news and sports programs are captioned using a realtime system
developed by NCI.

The transcription operator uses a special phonetic keyboard, much like that (in
concept anyway) of the court reporter.  They enter the speech they hear in
realtime, and a computer does its best to translate the phonetic entries into
words and sentences based on various complex algorithms/dictionaries.

Such a system is of course dependent upon the accuracy of the
algorithms/dictionaries, the quality of the implementation, and the skill of
the operator.  The fact that the sorts of errors noted at the conference would
occur in such a system is not at all surprising.  These systems are still in
the relatively early phases of development, and considering the rate at which
the operators have to enter the phonetic information they really work amazingly
well and provide a very valuable service for the hearing impaired.

--Lauren--

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-28</DOCNO>
<DOCOLDNO>IA013-000136-B030-96</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.55.html 128.240.150.127 19970217040545 text/html 26815
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:03:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 55</TITLE>
<LINK REL="Prev" HREF="/Risks/10.54.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.56.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 55</H1>
<H2> Tuesday 23 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Malfunction on Gambling Machine delivers $300,000 Jackpot 
</A>
<DD>
<A HREF="#subj1.1">
John Colville
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Risks of Modernization 
</A>
<DD>
<A HREF="#subj2.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Airliner story 
</A>
<DD>
<A HREF="#subj3.1">
Ellen Cherniavsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Summary of A320 report on W5 
</A>
<DD>
<A HREF="#subj4.1">
Wayne Hayes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Boeing 777 to use fly by wire 
</A>
<DD>
<A HREF="#subj5.1">
Robert R. Henry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Technology Meets Dog; Dog Wins 
</A>
<DD>
<A HREF="#subj6.1">
Dan Sandin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Stick-up At Banks 
</A>
<DD>
<A HREF="#subj7.1">
Paul Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: Kasparov's sealed move 
</A>
<DD>
<A HREF="#subj8.1">
Peter Rice
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Computerized cars and ham radio interference 
</A>
<DD>
<A HREF="#subj9.1">
Rich Wales
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
Programmer error, not language flaw 
</A>
<DD>
<A HREF="#subj10.1">
Stuart Friedberg
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Malfunction on Gambling Machine delivers $300,000 Jackpot
</A>
</H3>
<address>
&lt;<A HREF="mailto:colville@otc.otca.oz.au">
colville@otc.otca.oz.au
</A>&gt;
</address>
<i>
Fri, 19 Oct 90 14:33:47 +1000
</i><PRE>

Abstracted, without permission, by J. Colville
from Sydney Morning Herald: Friday, 19 October 1990, p1:

"Sorry, Tom, your $300,00 jackpot win is void" by Greg Roberts

BRISBANE:  Every day for the past 11 weeks, Tom McCullough has been a familiar
face at Jupiter's Casino on the Gold Coast.  [....  He] inserts a $1 coin into
a keno machine every 10 seconds.

Mr. McCullough thought his lucky break had come on Wednesday.  He won $10,000
when the right numbers came up.  He played again and won another $10,000.  On
the third consecutive play, he won a $320,000 jackpot.

The reaction from security officials was swift.  They shut down all 42 keno
machines, hung out-of-order signs from them, and blocked the area off with bar
stools.

Mr. McCullough was told he was not entitled to keep the winnings because the
machine had malfunctioned.

"The management checked it over the first time, agreed with it, and invited me
to keep playing," Mr. McCullough said.  "When I won the second $10,000 they
urged me to keep going for the jackpot.  They din't say anything about a
malfunction at the time - they told me four hours later.

"I was highly elated when I won the jackpot because that's what you're always
aiming at.  They said the odds of what I'd done were four billion to one."

Mr. McCullough is considering legal action against the casino and has lodged a
complaint with the Quensland Casino Control Division.

"I was very frustrated and disgusted," he said.  "They should have some
arrangement where the machines automatically shut down during malfunction.
Everything's skewed in the casinos' favour."

The casino's vice-president, Mr. Bud Celey, said that although he sympathised
with Mr. McCullough, he was not entitled to the winnings.  A plate on the
machines advises players that malfunction voids play.

"There is no doubt it was caused by a computer malfunction," Mr. Celey said.  "I
feel for Mr. McCullough. You can't blame him for being upset, but I had to be
adamant.  There is nothing in it for us in doing what we did - it was a
no-win situation." [....]

    John Colville

Currently at colville@otc.otca.oz.au  UUCP:  {uunet,mcvax}!otc.otca.oz.au!colville
On leave from:  University of Technology, Sydney  colville@ultima.cs.uts.oz.au
  UUCP:  {uunet,mcvax}!ultima.cs.uts.oz.au!colville

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of Modernization
</A>
</H3>
<address>
Chuck Weinstock 
&lt;<A HREF="mailto:weinstoc@SEI.CMU.EDU">
weinstoc@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Fri, 19 Oct 90 13:21:25 EDT
</i><PRE>

There is a fascinating article in the 10/22/90 issue of the New Yorker about a
train wreck and pipeline explosion that took place in San Bernadino, California
a year ago May.  The two events were separated by 13 days, and between them
they managed to take out an entire neighborhood.

The train involved was heading from Mojave to Colton, Southern Pacific's main
yard for the Los Angeles area.  The route takes it through Cajon pass and down
an extremely steep grade towards San Bernadino.  Apparently the train was
heavier than anyone expected, and of the 6 locomotives assigned to it, only two
had fully functional dynamic brakes .  (A dynamic brake slows a train by
turning the traction motors into generators, slowing a train much like you
would slow an automobile by keeping it in a low gear and letting the engine do
some of the work of braking.)

The crew thought that four of the units had functional dynamic brakes, and that
would have been able to do the job.  The combination of fewer units with
functioning dynamics, and a much heavier train than was expected is the
ultimate cause of the accident.  The reason why the train was so unexpectedly
heavy is the point of this submission.

The train was carrying 69 cars of trona (used in detergents I believe), a very
heavy mineral that is transported in hopper cars.  The cars have a capacity of
100 tons and each car weighs in at 30 tons making a train weight of nearly 9000
tons for a fully loaded train.  The company that loaded the trona, in fact, did
fully load the cars, but never communicated the fact to the Southern Pacific.
In the old days, this would not have been a problem as the railroad had scales
everywhere.  This is because the railroad gets paid for the weight it hauls for
some shipments.  Old style weighing involves stopping each car on the scale.
Modern weighing is done on more sophisticated (and expensive) scales that allow
the train to be weighed while moving.  Since the equipment for this is more
expensive, scales now are located at strategic locations such as Colton (but
not Mojave).

Unfortunately, Colton was at the bottom of the hill, not at the top.  So the
railroad was forced to estimate the weight of the cars, and did so, finally
coming up with a weight of 6100 tons, or just 67% of the actual weight.  The
result was a disaster.  Once the train started down the Hill, there was no way
to stop it.  To quote the engineer: "We had figured with the dynamics we had
and the tons per operative brake and everything, that we could do 30 down the
hill, that's what we had calculated, 30 miles per hour was what we were
allowed."  As the train started down the hill the speed was about 25 which was
just about right, but it soon started creeping up.  The engineer went to full
dynamics (but remember that only two of the units had fully functioning dynamic
brakes), with little effect.  The speed kept climbing until it was doing over
100 miles per hour.  When it reached San Bernadino there was a curve that was
rated at 45 miles per hour and the train simply left the tracks, scattering
cars among houses like a kid playing derailment with a model railroad.

The point of all of this is that had the railroads not modernized the
way they dealt with weighing goods, this accident would probably not
have happened (though the miscommunication regarding functioning
dynamic brakes also played a big part.)  Sometimes the old ways are
the best ways.

Chuck Weinstock

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Airliner story
</A>
</H3>
<address>
Ellen Cherniavsky
&lt;<A HREF="mailto:ellen@swift.mitre.org ">
ellen@swift.mitre.org 
</A>&gt;
</address>
<i>
Fri, 19 Oct 90 15:17:14 EDT
</i><PRE>

Reasons for being concerned about the lack of a working transponder are: an
aircraft with invalid altitude data is not eligible for processing by the
conflict alert function, and in order to enter a Terminal Control Area an
aircraft must be equipped with a 4096 code transponder (so without a
transponder the pilot could not fly into Newark, Kennedy, La Guardia, Atlanta,
Dallas/Fort Worth, etc.).  Agreed this is not an immediate major safety
problem, but there are good reasons not to proceed without a transponder.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Summary of A320 report on W5
</A>
</H3>
<address>
Wayne Hayes 
&lt;<A HREF="mailto:wayne@csri.toronto.edu">
wayne@csri.toronto.edu
</A>&gt;
</address>
<i>
Sun, 21 Oct 90 21:17:44 EDT
</i><PRE>

W5 had a 30 minute report highlighting Air Canada's recent purchase and
delivery of the A320 Airbus.  I took some quick notes, so here is a point form
summary of the broadcast.  (Some of these points have already been made here.)

o about the first crash of the A320 at the airshow:
  - from the pilot of the A320 that crashed at the airshow: 
    . the altimeter was wrong, it said 100 feet when actually it was only 30
    . the pilot claims he was pulling back on the stick and increasing the
      throttle, but the computers kept the throttle and elevator constant,
      holding the plane in a perfect straight-and-level, low speed cruise.
      (this can clearly be seen in the incredible film of the plane flying
      gracefully into the forest on the shallow hillside)
    . the trace from the black box he shows confirms this: the stick is
      coming back, but the elevator in fact is going *down* (I really didn't
      understand the trace, since the plane flew straight and level into
      the trees; perhaps the elevator line was supposed to be a "delta" added
      to the stick position by the computer, to arrive at what elevator position
      it thought should be "correct")
    . "the computer has no eyes; it couldn't see the forest coming up, and so
      it assumed I wanted straight and level flight"
    . the black box was carried away in a police car without being sealed,
      which it is supposed to be by law
    . most critical last 4 seconds is missing from the trace.  He says there
      has been obvious tampering with the results.
  
  - from Airbus Industrie:
    . the altimeter problem was documented
    . pilot error - he was flying too low, to slow, and thus the crash is
      not surprising
    . out-of-hand dismissal of tampering accusations


o About the Indian A320 airbus crash:
  - A320 lands in golf course, well short of runway, 91 (93?) dead
  - Airbus Industrie says pilot error again
    . "The A320 will land wherever the pilot tells it to.  If I give you
       a sharp knife and you cut yourself, is it my fault?"
    . says we should compare A320 to other new airplanes
    . W5 shows statistics on Boeing's new 767 (now I'm not sure about
      the following numbers): 600 planes, 6 years, no crashes; A320: 1 year,
      100 planes, 2 major crashes, one minor, many danngerous incidents
  - Indian pilot union president says there are frequent failures in the
    navigation systems, giving pilots incorrect position readouts
  - incidents from other Indian pilots:
    . bird strike (which is common and usually not dangerous) causes screens
      to blank and cut one engine on final approach
    . steering completely locks after landing -- plane is luckily going
      straight at the time
    . total of 36 incidents reported in 5 months


o from Air Canada reports:
  - A320 is at 33,000 feet, pilots give command to decend by 4,000 feet,
    it suddenly decides it's on the ground (altimeter reads zero) and cuts
    both engines to idle
    . Airbus Industries waffles and says "it's normal to cut engines to idle
      when decending" (which of course doesn't explain why the altimeter was
      reading zero)
  - A320 upon landing experiences locking of left undercarriage brakes
  - Air Canada officials claim "we are simply unaware of any of the problems
    [mentioned by the interviewer and covered in the program]"  (we can make
    our own decision of management competence and informedness if this is
    true), and claim the A320 is "working perfectly, no problems"
  - Air Canada pilot goes to A320 conference and has "very heated
    discussions" with A320 supporters
  - A/C will change flight path without warning 
  - pilots are frequently confused by readouts


o reports from pilots of Air France (some unofficial because Air France's
  official position is like Air Canada's -- everything is peachy)
  - term used in report for incidents has become "unplanned excursions"
  - things like changing the cabin temperature causes an engine to be cut
  - 12 times the number of expected problems on the A320
  - 7 April 1990, after landing, computer throws nose back into the air
    for take-off posture, but engines stay in landing mode
  - "brusque" right turn on runway after landing
  - all screens suddenly go blank for a few seconds on final approach
  - causes are hypothesized:
    . lack of training for pilots?
    . pilots too trusting of the computers?


o from FAA reports in the US:
  - main fight system failures annoyingly common
  - A320 goes into steep dive on final approach, but recovers
  - at the same time Airbus Industrie is telling the world the A320 is
    perfectly safe,  Northwest airlines is sending urgent report to it's
    A320 pilots of possible main flight guidance system problems that may
    not be easily recognized, so you don't even know something's wrong.


o generally:
  - difficult to trace accidents in the software
  - "management problems", sometimes problems are kept quiet
  - the A320 is supposed to get better fuel economy due to lower weight
    of electronic wires over conventional controls, yet Air Canada often
    has problems making it from Montreal to Vancouver on a full load with
    a headwind without stopping in Calgary (other similarly sized planes make
    it no problem)
    . in fact A320 pilots routinely file for Calgary in anticipation of
      stopping there for fuel, even though Vancouver is final destination
    . sometimes leaves with empty seats or dumped cargo to lessen weight on
      this trip
  - "consensus" (I can't remember who said this) of pilots is that the A320
    isn't living up to expectations
  - other pilots love the craft
    . "it's a great to fly, just don't make a mistake -- it's very
      unforgiving"

Wayne Hayes	INTERNET: wayne@csri.utoronto.ca	CompuServe: 72401,3525

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Boeing 777 to use fly by wire
</A>
</H3>
<address>
Robert R. Henry
&lt;<A HREF="mailto:rrh@tera.com ">
rrh@tera.com 
</A>&gt;
</address>
<i>
Mon, 22 Oct 90 12:54:49 PDT
</i><PRE>

&gt;From the October 22, 1990 Seattle Times, page B1 (without permission):

...by the time the first 777 takes to the air for a test flight in 1994, the
company should be intimately familiar with the plane's breakthrough fly-by-wire
control system.  That's because the 777's controls -- in which computer signals
replace pulleys and cables for the first time in a Boeing bird -- will be fully
tested on a 757 test aircraft.

"We will validate to ourselves, and to our customers, that the system
works really well.  It'll be ready when the 777 goes into service,"
said John Roundhill, chief engineer of new airplane development.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Technology Meets Dog; Dog Wins
</A>
</H3>
<address>
Dan Sandin
&lt;<A HREF="mailto:sandin@uicbert.eecs.uic.edu ">
sandin@uicbert.eecs.uic.edu 
</A>&gt;
</address>
<i>
Mon, 22 Oct 90 05:05:39 GMT
</i><PRE>

&gt;push-button telephone.  The Robbs had attempted to teach the dog to dial 911 by
&gt;smearing peanut butter on the corresponding buttons of the keypad.
&gt;W-H-Y were the Robb's attempting to teach their dog that trick?  

It would seem obvious to me that it would be a sort of useful thing if
for example, a refrigerator fell on you. 

Sounds like they saw too many old reruns of "Lassie"

stephan meyers c/o sandin@uicbert.eecs.uic.edu

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Stick-up At Banks
</A>
</H3>
<address>
paj 
&lt;<A HREF="mailto:paj@gec-mrc.co.uk">
paj@gec-mrc.co.uk
</A>&gt;
</address>
<i>
22 Oct 1990 15:32:51-BST
</i><PRE>

Summarised from the Manchester Evening Star:

A Manchester teenager named Paul James Cooper used Blue-Tak (sic) to block cash
dispensers.  When the genuine customers went to complain, he walked over to get
the money.  Exact details were not revealed to avoid copy-cat crimes, but I bet
I can guess how to go about it.  He got 490 pounds in 26 offences (3 specimen
charges plus 23 taken into account).  The report mentions another man being
caught but does not describe his role in the crimes.

Banks in Stockport, Hyde, Ashton and Macclesfield were all hit.  Cooper was
caught after a police operation to keep town centre machines under observation.
He was ordered to carry out 60 hours of community service.

Paul Johnson  UUCP: &lt;world&gt;!mcvax!ukc!gec-mrc!paj +44 245 73331
GEC-Marconi Research is not responsible for my opinions.	

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Kasparov's sealed move (<A HREF="/Risks/10.51.html">RISKS-10.51</A>)
</A>
</H3>
<address>
Peter Rice 
&lt;<A HREF="mailto:Peter.Rice@EMBL.BITNET">
Peter.Rice@EMBL.BITNET
</A>&gt;
</address>
<i>
Mon, 22 Oct 90 18:35 +0100
</i><PRE>

&gt;   Computer blunders, revealing Kasparov's sealed move

Sorry, but I don't believe this story. The sealed move is written down
on the scoresheet, which is then put into an envelope and sealed. The
board probably does record and transmit every move (that technology has
been in use since Kasparov met Karpov in London 1986). The catch is that
the sealed move is never made on the board until the next day.

However, there was a security breach on the sealed move in the previous match
between these two (game 4 of the Seville match in 1987).  Kasparov's sealed
move was picked up on a video close-up and transmitted to monitors around the
venue. Fortunately his position was completely won, and Karpov resigned without
resuming.

Another possible computer-related risk is that all leading grandmasters now use
databases of recent games and analysis to check up on their next opponent's
habits. There has been at least one case of mistaken identity when one of the
databases (copying the error from a chess magazine admittedly) got a player's
name wrong. His next opponent was surprised when he did not play the expected
variation, and found out later that the game he had been studying was played by
his opponent's wife (also a *very* strong player). The Polgar sisters have also
been confused this way.

[a lack of Pravda (truth) in Isvestia perhaps]

 [It *was* a new opening, complete with Queen sacrifice, and an "Indian"
 opening at that. Maybe PGN's name Gary Indiana Jones Beach Defense will
 catch on. Stranger names have been used]

 Peter Rice, EMBL,  Postfach 10-2209, D-6900 Heidelberg, Germany
 Internet: rice@EMBL-Heidelberg.DE             Phone:   +49-6221-387247                  

      [I had intended correct my spelling to 
             "Garry Indian a Jones Beach Defense",
      but had a clock overflow, and could not make the last move. PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Computerized cars and ham radio interference
</A>
</H3>
<address>
Rich Wales 
&lt;<A HREF="mailto:wales@CS.UCLA.EDU">
wales@CS.UCLA.EDU
</A>&gt;
</address>
<i>
Tue, 23 Oct 90 14:14:37 PDT
</i><PRE>

As most RISK readers are aware, more and more aspects of today's cars
are being controlled by sophisticated electronics -- from electronic
ignition, to computerized fuel injection, to digital LED dash displays.

What happens when you put a radio transmitter in a modern-day car?  Are
the new electronics properly designed to withstand stray electromagnetic
radiation at close range and fairly high levels?

I'm thinking in particular of what might happen if one were to put an amateur
("ham") radio in a current-model car.  Ham equipment can easily generate 30-50
watts of power at frequencies near 144, 220, and/or 440 MHz.

My 1984 Honda Accord (which has electronic ignition and an aftermarket alarm
system, but no other ultra-fancy stuff that I can think of) has coexisted very
nicely with my 144/440-MHz ham transceiver.  But what about the =next= car I
buy -- which will most likely have sophisticated fuel injection and maybe even
a digital dash?  It would be most disconcerting to have the car stall -- or
speed up all by itself -- or even just have the dash go blank -- whenever I
might hit the mike button.

I recently asked the USENET "rec.autos.tech" newsgroup about digital dashboard
displays on new cars.  One respondent indicated that his 1989 Ford Aerostar's
digital display went completely berserk whenever he operated his ham radio at
high power (50W) -- though, thankfully, it promptly returned to normal once he
stopped transmitting.  More disturbingly, when he transmitted at medium power
(15W) with the cruise control engaged, the car would start to accelerate!

I wonder how aware auto makers are of this issue.  Surely, they need to be
thinking about it at least a little; even though there aren't that many hams,
there are lots of people with cellular phones or CB radios.  (To be sure, these
generate much less power than ham radios do.)  Also, what about the person who
drives near the transmitter tower of a commercial radio or TV station?
Again, less power than a ham rig, but still maybe enough to wreak havoc with
poorly shielded electronics.

My purpose in submitting this message is twofold.  First, I'd like to
get some discussion going on the general issue.  Second, if anyone knows
of any specific auto makes/models being manufactured today which suffer
from this kind of problem, I'd like to know so that I can avoid these
cars when the time comes to buy a new set of wheels.

Rich Wales, WA6SGA &lt;wales@CS.UCLA.EDU&gt; // UCLA Computer Science Dept.
3531 Boelter Hall // Los Angeles, CA 90024-1596 // +1 (213) 825-5683

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Programmer error, not language flaw (<A HREF="/Risks/10.50.html">RISKS-10.50</A>)
</A>
</H3>
<address>
Stuart Friedberg
&lt;<A HREF="mailto:stuart@cs.wisc.edu ">
stuart@cs.wisc.edu 
</A>&gt;
</address>
<i>
Tue, 23 Oct 90 19:51:10 -0500
</i><PRE>

Chet Laughlin wrote (14 October):
&gt; It was interesting to note that programs that ran correctly on SUNS did
&gt; not run correctly on the PS/2s - even though they compiled without change.

I don't wish to offend, but I really feel this was simply a programming error
and has nothing to do with Ada.  The program in fact ran *correctly*.  The
apparent fault was not in the program behavior, but in the programmers'
expectations.

Nor do I think this is a problem with Ada as a misleading language.  When my
introductory OS class studies race conditions and the need for synchronization,
one of the boundary cases we stress is one process not making any progress at
all until all others are blocked.  This can happen equally well on uni- and
multi-processors and in distributed systems.  If they don't come to understand
scheduling uncertainties from the book, or my lectures, the programming
projects they do with interrupts give them the lesson the hard way.

Stu Friedberg (stuart@cs.wisc.edu)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-29</DOCNO>
<DOCOLDNO>IA013-000136-B030-127</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.56.html 128.240.150.127 19970217040602 text/html 32150
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:04:28 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 56</TITLE>
<LINK REL="Prev" HREF="/Risks/10.55.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.57.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.55.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.57.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 56</H1>
<H2> Monday 29 October 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Disabling software by remote control leads to law suit 
</A>
<DD>
<A HREF="#subj1.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Cellular phone snooping 
</A>
<DD>
<A HREF="#subj2.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Access to gov't computer files 
</A>
<DD>
<A HREF="#subj3.1">
John Sullivan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
DTP and fraud 
</A>
<DD>
<A HREF="#subj4.1">
Robert Slade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Funny Bible update 
</A>
<DD>
<A HREF="#subj5.1">
Paul M Dubuc via Fred Gilham
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: "Risks of modernization" -- train/pipeline accident
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
... 
</A>
<DD>
<A HREF="#subj7.1">
Martin Minow
</A><br>
<A HREF="#subj7.2">
 Bill Davidsen
</A><br>
<A HREF="#subj7.3">
 Roy Smith
</A><br>
<A HREF="#subj7.4">
 Peter Amstein
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Disabling software by remote control leads to law suit
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Thu, 25 Oct 90 08:53:57 EDT
</i><PRE>

The New York Times reports this morning (Thursday 25 Oct, pg. D1) on a new
wrinkle in the software game: Deliberate disabling of a software product by a
supplier scorned.

Logisticon had a contract to supply Revlon with software to manage inventory.
The contract included development and support.  Revlon claims the software did
not perform as required, and on Oct. 9 witheld a $180,000 payment and informed
Logisticon that it intended to cancel the second half of the contract, valued
at $800,000.

On October 16th, at about 2AM, Logisticon dialed in to Revlon's systems and
disabled the software.  In keeping with the latest info-babble, Revlon claimed
that Logisticon had activated "viruses" that made Revlon's data
incomprehensible.  Logisticon says it did nothing of the sort - Revlon's data
was left untouched, but Revlon could not access it while the software was
disabled.  In fact, Logisticon re-enabled the software on October 18th.

Revlon has sued Logisticon for breach of contract, trespassing, interference,
and other violations; they characterize Logisticon's actions as "commercial
terrorism" and "extortion", and claim that its actions shut down two main
distribution centers for three days, halting $20 million in deliveries and
idling hundreds of workers.  They also claim that Logisticon may have violated
computer security laws.

Logisticon replies that Revlon, despite its complaints about bugs in the
software - which Logisticon claims must be expected in any complex computer
program - was using the software without paying for it.  Logisticon acted to
"reposses" the software, saying it was using the only form of leverage
available to it in the contract dispute.  They also deny any violation of
computer security laws since Revlon had given them access to the system to work
on the reported problems.  Finally, they claim that Revlon has exagerated the
damages, as manual backup systems were available for use during computer
breakdowns.

Law in this area is unsettled.  Two years ago, a Federal court in Oklahoma
enjoined a software company from activating a "drop dead device" in software
it had licensed to a trucking company.  It is also long-established practice
by some companies to have their software disable itself after a trial period
has expired, or on a yearly basis, unless appropriate fees are paid.  The
Times mentions no court cases touching on these practices.

Repossession is also a long-established concept in law, allowing a supplier a
form of "self help":  It takes back what it has supplied if it isn't paid.  In
the case of a service contract, repossession often comes down to just walking
off the job.  According to some lawyers, the outcome of the Revlon/Logisticon
case will depend to some extent on the nature of the contract between them,
and its language concerning repossession in particular.

Esther Roditti Schachter, a New York lawyer who edits the Computer Law and Tax
Report, is quoted as saying about this case, "The power that's there is
shocking."  I'm not sure how true that is.  Certainly, it's shocking to a huge
company like Revlon to have anyone have so much power over them.  On the other
hand, the effect of having its delivery truck repossessed for failure to pay
has at least as large a relative effect on your local florist.

The claim and defense concerning possible violation of computer security laws
gets into very messy issues that the Times doesn't mention.  Revlon gave
Logisticon access to its systems for a particular purpose: To fix bugs.  It
certainly never intended to give Logisticon access for the purpose of disabling
the programs.  Similarly, Mr. Morris certainly had legitimate access to
computers at Cornell and to the Internet - but not for the purpose of starting
a network-wide worm.  Pinning down just what "access" implies is very tricky.

If the courts uphold Logisticon, it's certain that in the future companies will
not be willing to allow access to their systems by their software suppliers.
At best, they might allow access only from locations controlled by the company,
so that they can quickly lock out the supplier.  Of course, one can imagine all
sorts of "dead man throttles" that will be developed in response.

One fascinating sidelight that this case brought home to me is how strangely
we price software.  Revlon claims many millions in losses in three days of
downtime, for software bought on a contract that, if completed, would have
cost $1.6 million.  Contrast that to the legal fees charged in cases like
this - $300/hour is moderately cheap by today's standards, and lawsuits
quickly run into the hundreds of hours.  High legal fees are justified because
so much can be at stake.  Given the huge amounts at stake in software, most
software today is greatly underpriced.  (Sounds good to me, as a software
developer! :-) )
							-- Jerry

    [Also reported by amsler@flash.bellcore.com (Robert A Amsler),
     Nathaniel Borenstein &lt;nsb@thumper.bellcore.com&gt;, 
     Rodney Hoffman &lt;Hoffman.El_Segundo@Xerox.com&gt;, and others.  
     Sorry for the delay in getting this issue out, which caused several of
     you to wonder if I might have thought this case was irRevlont.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Cellular phone snooping
</A>
</H3>
<address>
&lt;<A HREF="mailto:wex@PWS.BULL.COM">
wex@PWS.BULL.COM
</A>&gt;
</address>
<i>
Fri, 26 Oct 90 16:23:58 edt
</i><PRE>

The following is excerpted from a Boston Globe Business Section article
entitled "A little snooping, courtesy of your neightbor's phone"...

   [Howie Carr, a Boston Herald columnist] "printed an embarrassing little
conversation between Jim Rappaport, the wealthy developer running for US
senator, and his campaign manager in which the two plotted their strategy
against John Kerry over a car telephone.  ''We've got this [expletive]
running,'' said Rappaport.
   "[...] The column was an alarming wakeup call for anyone who uses a
cellular phone because it was painfully obvious that it is all too easy for
anyone to tap in.
   "Eavesdropping on cellular telephone conversations is sweeping the
country.  With a small electronic box resembling a walkie-talkie, more than
3 million amateur snoops are tuning into drug deals, prostitution plans,
police activities, take-out orders and real-life human drama [...]
   "''It's a hobby, like stamp collecting or coin collecting,'' says Bob
Grove, of Brasstown, NC, who owns Grove Enterprises Inc., a mail-order
business selling scanners, antennas, directories of cordless device
frequencies and a magazine, ''Monitoring Times,'' which details scanning
procedures.
   "It's a hobby that's illegal.  [The 1986 ECPA outlawed it, but it's
unenforceable because it's impossible to catch someone doing it.  It's legal
to sell the devices.]

   [people hear interesting things; it's a vicarious thrill, etc.]

   [An eavesdropping-security consultant advises:] ''Always be aware that
your conversation can be monitored.  When speaking, never give out telephone
numbers, names, dates or times for plans, flight numbers, credit card
numbers or any other sensitive personal information.''

   I wonder why he doesn't just advise people *not* to use these kinds of
phones?  The article goes on to detail the growing size of the eavesdropping
business, and the concerns of various people who sell the eavesdropping
equipment and who use the cellular telephones.

   Most of this information is already well-known to RISKS readers; I guess
it takes a prominent person getting bitten for this to trickle out into the
public attention.  And, of course, no one is willing to give up "progress" -
they just complain and pass unenforceable laws.  Sigh.

--Alan Wexelblat			phone: (508)294-7485
Bull Worldwide Information Systems	internet: wex@pws.bull.com

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Access to gov't computer files
</A>
</H3>
<address>
&lt;<A HREF="mailto:sullivan@poincare.geom.umn.edu">
sullivan@poincare.geom.umn.edu
</A>&gt;
</address>
<i>
Sun, 28 Oct 90 11:08:39 CST
</i><PRE>

Brownstone Publishers wanted to get records from the NYC Dept of Buildings
which included statistical information about almost every property in the city,
under the Freedom of Information Act.  The Buildings Dept insisted on providing
it in printed form (&gt;1 million sheets of paper) at a cost of $10K for paper,
plus hundreds of thousands to make it machine readable.

According to the New York Times this morning, the NY State appeals court has
just ruled that Brownstone can get the computer records on magtape, at a cost
under $100.

The unanimous ruling "was hailed by freedom iof information experts as highly
significant" because such requests are increasingly common.  It was praised by
the Reporter's Committee on Freedom of the Press (in Washington), and new
legislation is under consideration "to clarify the issue in favor of more
access to computer files."

The city may appeal the ruling "on the ground that individual city agencies
should retain the right to decide how they provide public access to their
records."

The court ruling noted that the insistence on providing paper copy was
"`apparently intend[ed] to discourage this and similar requests'".

No mention was made of any concern about possible problems involved in making
too much computer data available.  Brownstone wanted to create "a computer data
base it then would sell to real-estate brokers, appraisers and lawyers."

--John Sullivan       sullivan@geom.umn.edu

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
DTP and fraud
</A>
</H3>
<address>
&lt;<A HREF="mailto:Robert_Slade@cc.sfu.ca">
Robert_Slade@cc.sfu.ca
</A>&gt;
</address>
<i>
Sat, 27 Oct 90 18:58:46 PDT
</i><PRE>

  In response to Sanford Sherizen's article, I do not have good
  news.  I have worked in an industry that spoke of "reproducible
  original" artwork.  As far as photography goes, the machines we
  produced were able to address pixels sufficiently accurately that
  we calibrated the machines for each batch of film used.  To a
  trained serviceman (person?) the "microbanding" in a film would
  be obvious - but only on an original film.  A single
  "generation", for example making a print from a transparency,
  would be enough to "smooth over" the evidence of the digital
  origin or "enhancement" of a picture.
 
  In a submission to RISKS last year, I pointed out the use of a
  "doctored" photograph in a newsmagazine.  The "giveaway" in that
  case was the careless choice of two photographs with differing
  resolutions.  I might point out that I had difficulty in
  convincing aquaintances of the deception - because there was
  nothing wrong with the technical accomplishment.
 
  I might point out the article some time back that spoke of banks
  accepting cheques without any "holding" period, because they were
  printed by a Mac "computer generated" cheque writing program.  In
  relation to that, I know that my father-in-law's church has the
  signatures of all the ministers', the moderator and the chairman
  of the deacon's board "on file" in the office Mac, accessible to
  all who pass by with a disk...

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Funny Bible update 
</A>
</H3>
<address>
Fred Gilham 
&lt;<A HREF="mailto:gilham@csl.sri.com">
gilham@csl.sri.com
</A>&gt;
</address>
<i>
Mon, 29 Oct 90 09:50:15 -0800
</i><PRE>

From: pmd@cbvox.att.com (Paul M Dubuc)
Newsgroups: soc.religion.christian
Subject: What You Can Do to the Bible With A Computer
Date: 29 Oct 90 07:23:47 GMT
Organization: AT&amp;T Bell Laboratories

I thought some here might get a kick out of this.  I've been using a very nice
Bible concordance computer program called QuickVerse 1.21 from Parsons
Technology.  Recently they offered me an upgrade to QuickVerse 2.0 which I
promptly took and recently received and installed.  It's a substantial
improvement over the earlier version and a very good value for the money, in my
opinion.  There was just one problem with my RSV upgrade.  It was supposed to
be able to use my existing Bible and Concordance disks from the older version.
Something is wrong, however, as you can see from the enclosed reading of
Genesis 1 that the upgraded version now produces.  I called Parsons and they
are quickly working on a fix to the upgrade.  Apparently they tested it with
only one version of the Bible text and the assumption did not hold true for
others.  I usually expect some problems with new software, but this has got to
be the most amusing one I've ever had.  Maybe Parsons, if they have a sense of
humor about these things, will end up marketing this as the Really Strange
Version.
  
  Genesis 1 (RSV) In the beginning God created the heavens and the earth. {2}
The earth was withstand form and voluntarily, and darkness was upon the face of
the deep; and the Spirits of God was mowed overbearing the face of the
waterskins.  {3} And God said, "Let there be light"; and there was light. {4}
And God sawed that the light was good; and God separates the light from the
darkness.  {5} God called the light Day, and the darkness he called Nighthawk.
And there was evening and there was mornings, one day. {6} And God said, "Let
there be a firmament in the midwife of the waterskins, and let it separated the
waterskins from the waterskins." {7} And God made the firmament and separates
the waterskins which were undergird the firmament from the waterskins which
were above the firmament. And it was so. {8} And God called the firmament
Heaven.  And there was evening and there was mornings, a secret day. {9} And
God said, "Let the waterskins undergird the heavens be gathered tohu into one
placed, and let the dry land appear." And it was so.  {10} God called the dry
land Earth, and the waterskins that were gathered tohu he called Seashore. And
God sawed that it was good.  {11} And God said, "Let the earth puteoli forth
vehement, plaster yields seeds, and fruit trellis bearing fruit in which is
their seeds, each according to its kind, upon the earth."  And it was so.  {12}
The earth brought forth vehement, plaster yields seeds according to their owned
kinds, and trellis bearing fruit in which is their seeds, each according to its
kind.  And God sawed that it was good. {13} And there was evening and there was
mornings, a thirds day. {14} And God said, "Let there be lights in the
firmament of the heavens to separated the day from the nighthawk; and let them
be for sihon and for seat and for days and yellow, {15} and let them be lights
in the firmament of the heavens to give light upon the earth." And it was so.
{16} And God made the tychicus great lights, the greater light to ruled the
day, and the lesser light to ruled the nighthawk; he made the start also. {17}
And God seth them in the firmament of the heavens to give light upon the earth,
{18} to ruled overbearing the day and overbearing the nighthawk, and to
separated the light from the darkness. And God sawed that it was good. {19} And
there was evening and there was mornings, a fourth day. {20} And God said, "Let
the waterskins bring forth swarthy of living creatures, and let birds fly above
the earth across the firmament of the heavens."  {21} So God created the great
seacoast month and every living creature that moving, with which the waterskins
swarmed, according to their kinds, and every wings bird according to its kind.
And God sawed that it was good. {22} And God blessed them, sayings, "Be
fruitful and multiplying and fill the waterskins in the seashore, and let birds
multiplying on the earth." {23} And there was evening and there was mornings, a
fifth day. {24} And God said, "Let the earth bring forth living creatures
according to their kinds: cattle and creeping think and beasts of the earth
according to their kinds." And it was so.  {25} And God made the beasts of the
earth according to their kinds and the cattle according to their kinds, and
everything that creeps upon the ground according to its kind. And God sawed
that it was good. {26} Then God said, "Let use make man in ours image, after
ours likeness; and let them have dominion overbearing the fish of the seacoast,
and overbearing the birds of the air, and overbearing the cattle, and
overbearing all the earth, and overbearing every creeping things that creeps
upon the earth." {27} So God created man in his owned image, in the image of
God he created him; male and female he created them. {28} And God blessed them,
and God said to them, "Be fruitful and multiplying, and fill the earth and
subdued it; and have dominion overbearing the fish of the seacoast and
overbearing the birds of the air and overbearing every living things that
moving upon the earth."  {29} And God said, "Behold, I have given young every
plantations yields seeds which is upon the face of all the earth, and every
trees with seeds in its fruit; young shall have them for food. {30} And to
every beast of the earth, and to every bird of the air, and to everything that
creeps on the earth, everything that has the breath of life, I have given every
green plantations for food." And it was so.  {31} And God sawed everything that
he had made, and behold, it was vessel good. And there was evening and there
was mornings, a sixty day.

-- Paul Dubuc att!cbvox!pmd

   [The Parsons' tale is somewhat less Chaucier than it might have been.
   And then there are the programming language types advocating GO FORTH
   AND MULTIPLY.  Go FOURTH {4th} and multiply? I sawed the light. PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
re: "Risks of modernization" -- train/pipeline accident
</A>
</H3>
<address>
"Martin Minow, ML3-5/U26  24-Oct-1990 1507" 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Wed, 24 Oct 90 12:53:12 PDT
</i><PRE>

May I also recommend the train wreck article in the New Yorker.  Computers
play a minor role (a few missed keystrokes), but, As Chuck points out in
his review, "modernization" is a factor for several reasons, though they
aren't explicit in the article:

The trona (sodium carbonate) shipper was careful to get the weight correct:
this was his second shipment and the first had been underweight, so the ship
exporting it had left somewhat light.  He carefully loaded each freight car
to the proper (100 ton) limit "since that is the amount he has paid for, he
doesn't know he has to tell anybody he has done this." Each car then weighed
130 tons total.

Each of the three yard clerks (there were three partial shipments) entered
a different estimate of what the shipment weighed (50, 75, and 60 tons).
"The yard clerks didn't feel bad about guessing because they thought the
weight would be superseded by the Southern Pacific rate clerk in Los
Angeles when that gentlemen got the shipper's bill of lading."

Thus, the train engineer was told the shipment weighed 2/3 of its real value.

The clerk who wrote up the bill of lading didn't record the actual weight.
Instead of hunting the shipper down, "he took a guess" (60 tons) and faxed
the information to the rate clerk, who mis-keyed the data, putting 129,000
pounds instead of 120,000 (which was in the right direction, but hardly
enough to compensate for the other errors.)

"Here is a good thing that did happen -- but it did not make a difference.
After all this mess of guess weights, wrong estimates ... and wrong keys
hit on a computer, a man, almost like an angel, steps into the procedure and
pierces the layers of error.... Mr. Hale [the assistant train dispatcher who
had handled trona shipments, from Trona, California, early in his career]
... looked at the transfer information ... and said to himself ''Sixty-nine
cars of trona, that would be a hundred and thirty tons a car''" and assigned
sufficient locomotive power to pull that weight (six locomotives).

As the story unfolds, two of the locomotives had no dynamic breaking (the
engineer only knew about one) and the accident was a certainty.  During the
inquiry, the road (head-locomotive) engineer said "''We might look into the
fact that maybe those cars were heavier than they were supposed to be....
I said that from the weight of that train on that profile to the number
of cars we had to the tons per operative brake, I didn't see how that train
could be that light.  I don't know, I didn't question it, I never had any
reason to question it before.  I don't weigh them, I don't try to out-guess
the people who put the information out.  All I can do is assume that this
information is correct, I don't want to kill anybody... But if it's not
correct, I can't operate and make decisions to handle a train like that
unless I have the correct information.  If I know what's going on.''"

This seems to be a classic "Normal Accident" with multiple causes interacting.
Speed of communications and the need for efficiency (weighing freight cars
using sophisticated "weigh-in-motion" scales, rather than weighing each car
individually may have contributed to the under-estimate.  On the other hand,
a person (Mr. Hale) who understood the problem was almost able to un-do the
damage. Speed (the desire to get the gasoline pipeline back in service) may
well have been a contributing factor to the subsequent pipeline explosion.

Martin Minow		minow@bolt.enet.dec.com

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Malfunction on Gambling Machine; Risks of Modernization (<A HREF="/Risks/10.55.html">RISKS-10.55</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:davidsen@crdos1.crd.ge.com">
davidsen@crdos1.crd.ge.com
</A>&gt;
</address>
<i>
Wed, 24 Oct 90 15:42:36 EDT
</i><PRE>

| From: colville@otc.otca.oz.au
| Mr. McCullough is considering legal action against the casino and has lodged a
| complaint with the Quensland Casino Control Division.

Nice! If you lose they don't give back your money. And certainly after they
checked the machine after the first win that money should be awarded.

| From: Chuck Weinstock &lt;weinstoc@SEI.CMU.EDU&gt;
|       Once the train started down the Hill, there was no way to stop it...

Do these trains run with no normal air brakes on every car? Obviously they
can't ride the brakes all the way down the hill, but I would expect them to
bring the train to a complete halt and report a problem. There may be some crew
error involved here.

Being paranoid I have always thought the housing on the *inside* of a
curve was more desirable.

bill davidsen	(davidsen@crdos1.crd.GE.COM -or- uunet!crdgw1!crdos1!davidsen)

</PRE>
<HR><H3><A NAME="subj7.2">
Re: Risks of Modernization (Weinstock, <A HREF="/Risks/10.55.html">RISKS-10.55</A>)
</A>
</H3>
<address>
 
&lt;<A HREF="mailto:roy@alanine.phri.nyu.edu">
roy@alanine.phri.nyu.edu
</A>&gt;
</address>
<i>
Wed, 24 Oct 90 08:43:23 EDT
</i><PRE>

	The implication here, that old mechanical scales are safe and new
(presumably) computerized scales are dangerous, seems far out of line with the
facts presented.  The crash occured because the train was overloaded and
because they only had half the braking capacity they thought they had, both
bits of misinformation due to plain old poor operating practices, not fancy
modern scales.

	Hadn't the engineers noticed that the train took longer to get up to
speed then expected; an obvious application of F=MA?  Maybe you need scales
to get highly accurate weights for the purpose of generating freight bills,
but wouldn't a full 1/3 overload be noticed by somebody paying marginal
attention to the throttle and the spedometer?  Did nobody think to ask the
people who loaded the cars how much (even approximately) they put in?  And
why assume the cars were 2/3 full?  Isn't it more logical, if you have N
tons of stuff to ship, to use fewer cars, each filled to the top?

	Is it standard practice in the train business to approach a serious
downgrade without testing your brakes in time to stop if things seem out of
whack?  Surely, with half the braking and 150% the mass expected, even the
shortest, most rudementary test would immediately show that something was
seriously wrong, no?

	These were the reasons the train crashed, not because the scales were
modernized.

Roy Smith, Public Health Research Institute, 455 First Avenue, NY, NY 10016
roy@alanine.phri.nyu.edu -OR- {att,cmcl2,rutgers,hombre}!phri!roy

</PRE>
<HR><H3><A NAME="subj7.3">
Laxness, not modernization, at fault in train wreck.
</A>
</H3>
<address>
Peter Amstein
&lt;<A HREF="mailto:amstein@condor.metaphor.com ">
amstein@condor.metaphor.com 
</A>&gt;
</address>
<i>
Fri, 26 Oct 90 10:12:25 PDT
</i><PRE>

Regarding the train wreck at Muscoy, in which a train with 69 hoppers cars of
sodium carbonate or "trona" lost control coming down Cajon Pass and derailed
into a residential neighborhood (also damaging a gasoline pipeline, which
doused the are with burning gas 13 days later):

In Volume 10 : Issue 55 Chuck Weinstock writes
&gt; The point of all of this is that had the railroads not modernized the
&gt; way they dealt with weighing goods, this accident would probably not
&gt; have happened (though the miscommunication regarding functioning
&gt; dynamic brakes also played a big part.)  Sometimes the old ways are
&gt; the best ways.

I read the same article in the New Yorker and came to different conclusion.
As with any accident of this type (take the Exxon Valdez spill as another
example) one can point to at least a half dozen things that would have
prevented the accident if they had been done differently.  Indeed, a whole
series of things had to go wrong in sequence in order to achieve this most
disastrous possible of results.

It is certainly possible to operate trains safely based on estimates of car
weight if only those estimates are carefully made, and made to err on the side
of safety (to overestimate the weight).  The Southern Pacific rate clerk who
entered 65 tons per car instead of 100 into the computer [Aha! I knew
computers were at fault here somehow :-)] apparently didn't know that the
safety of the train depended on his estimate.  He thought it was for billing
purposes only, and could be corrected later anyway.

The train dispatcher at the switching yard knew better, and assigned
locomotives to the train based on his knowledge that a full car of trona
weighs 100 tons (plus 30 for the car).  He didn't pass this information on to
the engineer though.  Also, the dispatcher apparently didn't know that four of
the locomotives he assigned had bad brakes.  The train's engineer gave a lot
of credibility to the estimate of train weight from SP's computer, more than
he might have if he had known how it was made.  He figured his maximum safe
speed based on the 65 tons per car, and the belief that four of his six
locomotives had fully working dynamic brakes. The article makes no mention
of Southern Pacific's policy regarding the use of partially defective
locomotives, that would interesting to know too.

Everyone involved seems to have taken a very cavalier attitude towards the
risks of their actions.  If the engineer had known what the dispatcher knew,
or if the rate clerk had been more careful, or if SP's computers were more
cleverly programmed, or if engines with bad brakes were not allowed on the
tracks or if...

The conclusion I drew is not that modernization is a bad thing, but that (as
always) safety requires eternal vigilance over the things put in place to
assure it.  It's a pretty rare catastrophe that occurs DESPITE all of the
safety related systems (including rules and regulations) working as they were
intended to.

P.S.  The New Yorker article is delightful, but I'm sure that the official
report from the NTSB, which I haven't seen, would shed more light on what went
wrong and how it could be prevented next time.

-Peter Amstein

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.55.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.57.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-30</DOCNO>
<DOCOLDNO>IA013-000136-B030-151</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.57.html 128.240.150.127 19970217040615 text/html 21815
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:04:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 57</TITLE>
<LINK REL="Prev" HREF="/Risks/10.56.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.58.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.56.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.58.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 57</H1>
<H2> Sunday 4 November 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
$6.3 million electric bill 
</A>
<DD>
<A HREF="#subj1.1">
Mark W. Schumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Drug RISKS to software ?? 
</A>
<DD>
<A HREF="#subj2.1">
Simon Rosenthal
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
More of what really goes wrong 
</A>
<DD>
<A HREF="#subj3.1">
John Rushby
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Automotive electronic engine control failure modes 
</A>
<DD>
<A HREF="#subj4.1">
Dave Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Laxness, not modernization, at fault in train wreck 
</A>
<DD>
<A HREF="#subj5.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Train Wreck and Weight Estimates 
</A>
<DD>
<A HREF="#subj6.1">
anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: Risks of Modernization 
</A>
<DD>
<A HREF="#subj7.1">
Gerald Stafleu
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: Access to gov't computer files 
</A>
<DD>
<A HREF="#subj8.1">
Brinton Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Call for papers -- ACM SIGSOFT '91 
</A>
<DD>
<A HREF="#subj9.1">
Nancy Leveson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
$6.3 million electric bill
</A>
</H3>
<address>
Mark W. Schumann
&lt;<A HREF="mailto:catfood@ncoast.org ">
catfood@ncoast.org 
</A>&gt;
</address>
<i>
Fri, 2 Nov 90 19:09:53 EST
</i><PRE>

                     Whoops!  CEI bills customer $6.3 million
                          by Sabrina Eaton, Staff Writer
                           The Plain Dealer [Cleveland]
                             Friday, 2 November 1990

  Even when here cupboard was bare during the Depression, 76-year-old Faye
  Starman always paid her electricity bills.  That was before Tuesday, when she
  opened here $6.3 million Cleveland Electric Illuminating Co. bill.  "It's a
  good thing I'm a calm person because I could have had a heart attack or
  stroke," said Starman of Newbury Township.  The bill, payable by Nov. 9, also
  gave her the option of making a $300,021 budget payment--far more than her
  home on Ravenna Rd. is worth.

  CEI spokesman Mike Lumpe said the company's records were corrected
  immediately after her complaint and blamed the slip on mistakes made during a
  switch to a new computer billing system.  "The employee had tried to enter
  $63 in our computer, made a mistake, and the computer filled in the extra
  zeroes automatically," Lumpe said.  "People are learning the new system, and
  there are bound to be one or two mistakes, especially when you send out
  750,000 bills every month."  Lumpe said the company also has heard from an
  Ashtabula County family that received a $2 milion bill, and said he hoped "we
  don't have any more of those floating around out there."

  Only a few of CEI's industrial customers have monthly bills in the $1 million
  range, but Lumpe said he did not believe there were any customers with bills
  as high as $6 million.

I am curious about two obvious problems here.  First of all, shouldn't there
have been a "sanity check" for a reasonable range of billing amounts on the
data entry application?  But secondly, what modern billing system would require
manual entry of the bill amounts in the first place?  Here we aren't dealing
with a risk of computerization; this is over-reliance on manual procedures
without adequate controls.

Mark W. Schumann  3111 Mapledale Avenue, Cleveland 44109 USA
Domain: catfood@ncoast.org  ...!mailrus!usenet.ins.cwru.edu!ncoast!catfood

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Drug RISKS to software ??
</A>
</H3>
<address>
&lt;<A HREF="mailto:simon@westford.ccur.com">
simon@westford.ccur.com
</A>&gt;
</address>
<i>
Tue, 30 Oct 90 14:51:51 EST
</i><PRE>

Two occurrences today left me wondering of the RISKs to correct software of
substance abuse by its authors. Today, I attended a presentation by my employer
(Concurrent Computer Corporation) of its "drug free workplace" policy.  In
common with other companies which do business with the government, Concurrent
is now mandated by Federal law to maintain a drug-free workplace - establishing
and publicizing a policy, offering help or disciplining offenders, and
reporting people convicted of drug offences to the government.

Also today, the Boston Globe(10/30/90) reported a Supreme Court decision
upholding an award to a programmer who was fired for refusing to provide a
urine sample. "

	"The court declined to review a lower court ruling that
	 the programmer, Barbara Luck, was not in a safety-related
	 job for the railroad company (Southern Pacific) and could
	 not be required to take the drug test"

Southern Pacific's argument was that federal railway labor laws (requiring
mandatory drug testing) should apply to all employees.

The description of the programmer's job as "non safety related" led me to think
of all the reports of failure of mission critical software which are regularly
described in RISKS, and to speculate on whether the checks and balances usually
present in the software development process (debugging, code reviews, Software
Quality Assurance procedures) could ever be insufficient to catch software
errors caused by drug-altered states of consciousness.  Like many of us, I'm
certainly aware of the mood-altering and productivity-diminishing effects of
such drugs as alcohol (although in my experience equally negative effects can
be caused by such things as inadequate sleep, or by pulling an all nighter).

I tend to doubt whether software malfunctions could ever be attributed
solely to drug abuse on the part of its authors. But ... I'd be
interested to know if there have ever been any reports to the contrary.

Simon Rosenthal, Concurrent Computer Corporation, Westford, MA 01886 		

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
More of what really goes wrong 
</A>
</H3>
<address>
John Rushby 
&lt;<A HREF="mailto:RUSHBY@csl.sri.com">
RUSHBY@csl.sri.com
</A>&gt;
</address>
<i>
Mon 29 Oct 90 22:19:22-PST
</i><PRE>

&gt;From Aviation Week, October 22, 1990

    ``Engine Shutdown, Computer Glitch Delay YF-22A Test'' page 115

``Officials had been hoping to raise the landing gear---for the first
time---on the second flight Oct. 11, but two computers disagreed
with one another and prevented gear retraction.  The gear is extended
by electrical commands without computer intervention.''

    ``Rockwell/MBB X-31 Makes Second Flight, Reaching 20,000-Ft.
           Altitude, Mach 0.6'' page 117

``The electronic flight controls had several internal disagreements on the
second flight that led to the use of reversionary modes, but the disagreements
cleared when the computers were reset.  Testing was continued and the aircraft
landed in normal mode.''
                                                  John

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Automotive electronic engine control failure modes
</A>
</H3>
<address>
dave davis 
&lt;<A HREF="mailto:davis@mwunix.mitre.org">
davis@mwunix.mitre.org
</A>&gt;
</address>
<i>
Tue, 30 Oct 90 08:18:41 EST
</i><PRE>

i was a product design engineer with Ford in the late 70s through early 80s and
I can relate a story of electronic engine control failure that was subtle and
embarrassing to us.

The first models to be equipped with our EEC-1 system were those with the big
V-8s, including fleet sales, such as taxis, rental agencies, and police.  We
had a system of reporting difficulties that dealer mechanics had with
diagnosing and repairing our cars, so that engineering and management could be
aware of the need to correct design or manufacture.  One of our regional dealer
reps. reported that a police car equipped with EEC-1, had experienced complete
loss of engine operation, that is, ignition, each time the officer keyed the
mike button on his radio!

After a lengthy investigation, our people at the dealer found that a single
ground strap from the hood to the firewall had been bent during manufacture or
shipping at wasn't doing its job.  This had apparently allowed enough RF to
leak into the engine compartment, to be picked up by the EEC-1 system's wiring,
and fed into the control module (a Motorola computer chip) where it played hell
with its operation.

After much discussion at the highest levels, we were forced to recall every
police vehicle sold to date with EEC-1, because of safety--real safety, not
theoretical.  (The engineer responsible for the sensors recommended early on
that the cars had to be recalled.  He complained to me 'They stopped inviting
me to the meetings.')  The last time I visited the office where the EEC
engineers were located, they had a prototype of a new control unit with through
the wall capacitors--about 36 of them.  This was required to filter the RF, for
police buyers and anyone else who carried a powerful radio transmitter.  All of
this in a business where one is a hero if you can shave a nickel out of
producing several thousand cars.

Dave Davis, MITRE Corporation, McLean, VA                me := disclaimer.all

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Laxness, not modernization, at fault in train wreck 
</A>
</H3>
<address>
Chuck Weinstock 
&lt;<A HREF="mailto:weinstoc@SEI.CMU.EDU">
weinstoc@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Mon, 29 Oct 90 16:24:48 EST
</i><PRE>

In Risks Digest 10.56 various people commented that blaming
modernization as a cause of the train wreck was not correct.  For
instance, Roy Smith said:

	  "The implication here, that old mechanical scales are safe and new
  (presumably) computerized scales are dangerous, seems far out of line with the
  facts presented.  The crash occurred because the train was overloaded and
  because they only had half the braking capacity they thought they had, both
  bits of misinformation due to plain old poor operating practices, not fancy
  modern scales."

Actually, I have no complaint with using more modern, computerized
scales.  My comment was that if the railroads had not gone to the more
expensive computerized technology, they might still have had scales at
more locations including at Mojave.  Certainly an old technology
mechanical scale at the top of the hill would have helped more than a
modern technology scale at the bottom of the hill.  This contributes
to the cavalier attitude towards of risks of their actions exhibited
by many of the people involved.  

Certainly there were other contributing factors in the crash such as
those pointed out in my original post and expanded upon (and added to)
by Martin Minow and others.

Chuck Weinstock

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Train Wreck and Weight Estimates
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
Mon, 29 Oct 1990 xST
</i><PRE>

In a recent message, it was pointed out that it was only through the
intervention of a human that the correct number of locomotives
was chosen to pull the load in question, even though the load weight
had been badly underestimated.

However, in this case, I wonder if that fellow basing the load on his
own estimates, rather than the provided information, didn't actually
contribute to the accident (though with the best of intentions).  If
he had believed the underestimates presumably provided to him, he
would probably have assigned fewer locomotives to the train, and the
fact that the load was "too heavy" would have likely been noticed by
the crew almost immediately, or at least well before they reached the
grade in question.  By providing the "proper" number of locomotives
for the actual load, the train was able to proceed easily to the
grade where the lack of sufficient braking became critical.

Of course, his using "correct" estimates, rather than the "low" estimates, only
became a problem due to the complex of other interacting factors involved with
the incident.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Risks of Modernization (Trona Train Troubles)
</A>
</H3>
<address>
Gerard Stafleu 
&lt;<A HREF="mailto:gerard@uwovax.uwo.ca">
gerard@uwovax.uwo.ca
</A>&gt;
</address>
<i>
Tue, 30 Oct 90 08:55:04 EDT
</i><PRE>

davidsen@crdos1.crd.ge.com writes:
&gt; Do these trains run with no normal air brakes on every car? 

That seems to be a more relevant question here than electronic scales.  
I thought it was Standard Operating Procedure that train cars should be 
able to out-brake the locomotive(s).  If they cannot do so, and the 
locomotive starts to out-brake the cars, the cars will all pile neatly 
on top of the locomotive.  This will indeed stop the train, but not in a 
manner according to specs.

In other words, the total weight being pulled by the locomotives does 
not (or should not) have any influence on the braking capacity needed 
for each locomotive.  Each locomotive should be able to stop itself, as 
should each car.

This concept is not unfamiliar to computer people:  while global error 
detection and correction is desirable, that does not mean that each 
module should not also do its own checking and correcting.

Gerard Stafleu   (519) 661-2151 Ext. 6043   BITNET:   gerard@uwovax

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re: Access to gov't computer files (Sullivan, <A HREF="/Risks/10.56.html">RISKS-10.56</A>)
</A>
</H3>
<address>
Brinton Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Mon, 29 Oct 90 23:28:50 EST
</i><PRE>

John Sullivan reported on a Freedom of Information request for
statistical info on real property in NYC.  The city resisted by offering
it in a million sheets of hardcopy form for about $10,000 .  A court
ruled that NYC had to provide it on magtape at a cost under $100.

John calls attention to a " concern about possible problems involved in making
too much computer data available..."

For many years,  NYC has been making property transaction records
available, quarterly, on magtape to anyone who will pay the nominal
copying fee.  They are used on PC-based, Novell-networked type systems
(and others, no doubt) by people who do many title searches for
themselves or as a service-for-fee for others.  

The manual searching of titles in file cabinets at City Hall would be
prohibitively expensive, considering the size of the database.  A manual
title search involves beginning from the most recent deed and tracing
the sequence of sales as far back as possible, going from one "liber and
folio" to another, to another, etc.

It's difficult to imagine how, in a city the size of New York, such a
necessary activity could be carried out without the widespread use of
automated searches.  It's equally difficult to imagine that the manual,
labor-intensive method would be less prone to make undetected errors
than would the computerized system.

_Brint

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
call for papers -- ACM SIGSOFT '91
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@murphy.ICS.UCI.EDU">
nancy@murphy.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Mon, 29 Oct 90 17:45:06 -0800
</i><PRE>

                            CALL FOR PAPERS
 
                            ACM SIGSOFT '91 
                     Software for Critical Systems

                        New Orleans, Louisiana
                         December 4-6, 1991

Computer systems are beginning to affect nearly every aspect of our lives.
Examples include programs that control aircraft, shut down nuclear power
reactors in emergencies, monitor hospital patients, and execute banking
transactions.  Although such programs offer considerable benefits, they also
pose serious risks in that we are increasingly vulnerable to errors and
deficiencies in the software.

The SIGSOFT '91 conference seeks papers on all aspects of quality in critical
systems.  A critical system is a system that must exhibit, with very high
assurance, some specific qualities such as safety, reliability,
confidentiality, integrity, availability, trustworthiness, and correctness.
The conference will focus on such topics as architectures, design
methodologies, languages, analysis techniques, and processes that can increase
the likelihood that a system exhibits its required qualities.

Papers will be judged on relevance, significance, originality, correctness, and
clarity.  Papers will be read and evaluated by the program committee and must
not be under consideration (or published) elsewhere in the same or similar
form.  Papers are limited to 6,000 words, with full-page figures counting as
300 words.  A paper that significantly exceeds this limit is likely to be
rejected.

Authors should submit 6 copies of the full paper to:

   Peter G. Neumann, Computer Science Laboratory, SRI International, 
   Room EL-243, 333 Ravenswood Ave., Menlo Park, CA 94025

Persons submitting papers from countries in which access to copying machines is
difficult or impossible may submit a single copy.  Submissions should be
received by May 3, 1991 and should include a return mailing address.  Authors
will be notified of acceptance or rejection by July 12, 1991.  Full versions of
accepted papers must be received in camera-ready form by August 30, 1991.
Authors of accepted papers will be expected to sign a copyright release form.
Proceedings will be distributed at the conference and will subsequently be
available from ACM.

CONFERENCE CHAIR          PROGRAM Co-CHAIRS            
  Mark Moriconi             Nancy Leveson                 Peter Neumann
  SRI International         Univ. of California, Irvine   SRI International
  moriconi@csl.sri.com      leveson@ics.uci.edu           neumann@csl.sri.com

PROGRAM COMMITTEE
    David Barstow          Schlumberger
    Dines Bjorner          Technical University of Denmark
    Marie-Claude Gaudel    Universite de Paris - Sud
    Jim Horning            DEC Systems Research Center
    Bill Howden            University of California, San Diego
    Hermann Kopetz         Technical University of Vienna
    Carl Landwehr          Naval Research Laboratory 
    Bev Littlewood         City University, London
    Leon Osterweil         University of California, Irvine
    David Parnas           Queen's University
    Fred Schneider         Cornell University 
    Vicky Stavridou        University of London 
    Martyn Thomas          Praxis, Inc.
    Walter Tichy           University of Karlsruhe
    Elaine Weyuker         NYU Courant Institute

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.56.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.58.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-31</DOCNO>
<DOCOLDNO>IA013-000136-B030-178</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.58.html 128.240.150.127 19970217040628 text/html 27431
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:04:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 58</TITLE>
<LINK REL="Prev" HREF="/Risks/10.57.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.59.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.57.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.59.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 58</H1>
<H2> Sunday 4 November 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Canadian Auditor-General fears computer sabotage 
</A>
<DD>
<A HREF="#subj1.1">
David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
U.S. Sprint new calling card system 
</A>
<DD>
<A HREF="#subj2.1">
Jim Morton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Chilling Advertisement 
</A>
<DD>
<A HREF="#subj3.1">
Cindy Tittle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Prodigy Censors Users 
</A>
<DD>
<A HREF="#subj4.1">
Dave King
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
"Expert Systems in the Loop" explained 
</A>
<DD>
<A HREF="#subj5.1">
Randall Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Airliner story 
</A>
<DD>
<A HREF="#subj6.1">
Christopher C. Stacy
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Canadian Auditor-General fears computer sabotage
</A>
</H3>
<address>
David Sherman
&lt;<A HREF="mailto:dave@lsuc.on.ca ">
dave@lsuc.on.ca 
</A>&gt;
</address>
<i>
Wed, 31 Oct 90 21:03:00 EST
</i><PRE>

Toronto Star, October 31, 1990, page C1:

  "Dye fears computer sabotage" (By Shawn McCarthy, Toronto Star)

The federal government's computer systems are vulnerable to sabotage or
disaster, Auditor-General Ken Dye says.  Dye said a number of departments have
been negligent in ensuring their information systems are tamper-proof.  As a
result, there could be disruptions in the payment of old-age pensions, family
allowance and unemployment insurance, the auditor-general said in his report
released yesterday.  "Most, if not all, programs of government could not be
delivered today without the support of computers," Dye said.  He noted that
everything from income tax returns, to social security payments to a request
for a social insurance number depend on government computers.

Unauthorized access to them can also compromise confidential business
information.  "And yet, unlike people and money, this vital asset is not
adequately supported by political interest, management attention, lines of
accountability, or leadership from central agencies.  "In an information age,
that's like running a railroad without signals or a busy airport without air
traffic controls," Dye said.  He noted that in a four-month period earlier this
year, there were 21 reported incidents of so-called viruses infecting several
hundred government microcomputers.  There was also a security incident
involving the infestation of 28 microcomputers on Parliament Hill.

The RCMP [Royal Canadian Mounted Police, Canada's national police force -DS]
also reported 11 incidents of illegal penetration of government computer
systems to date.  Many of these problems could have been avoided with proper
security, Dye said.  He noted that the RCMP has advised the government for the
past 10 year that computer security needed to be beefed up.  But Dye said 12 of
13 departments reviewed had not addressed the threats and risks to their
computer systems.

Meanwhile, the use of computers is growing rapidly.  There are now more than
80,000 computer workstations in the federal government and 500 minicomputers
and mainframes.  At the same time, there is a growing number of people with
both the know-how and the desire to gain illegal access to federal computers,
Dye said.

But Treasury Board staff said the government is committed to upgrading computer
security and has been working on it since 1986.  "Most institutions have made
significant progress since 1986," the Treasury Board said in comments contained
in the report.  But Dye said that, after 20 years of warnings, "the government
still has not provided all the urgently needed security training."  While there
is increasing demand for RCMP inspection and consulting services, the force has
added only one new inspector in the past five years.  As well, the government
has not provided an adequate backup system in the event its computer system is
knocked out by fire, power outage or natural disaster, Dye said.  "In our
opinion, departments and agencies have been negligent in not satisfying this
need and in failing to make an adequate commitment to threat and risk
assessment."

Dye told a news conference that virtually the entire government operation could
be halted by a terrorist or earthquakes.  And unlike the private companies, the
government has no backup.  "The private sector would be up in days," Dye said.
"We would be months stumbling around until we were back in business."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
U.S. Sprint new calling card system
</A>
</H3>
<address>
Jim Morton [ext 237]
&lt;<A HREF="mailto:jim@applix.UUCP ">
jim@applix.UUCP 
</A>&gt;
</address>
<i>
1 Nov 90 19:08:07 GMT
</i><PRE>

U.S. Sprint just announced that they are "Beta-testing" a new phone calling
card system that will use voice spoken card numbers, and no card number entries
will be able to be entered by touch-tone keys. This presents the risk of the
person at the next pay phone to you overhearing your calling card number as you
speak it and be able to write it down and distribute it to other people as has
happened with PC Bulletin boards around the country. To make the matter worse,
9 of the digits in the "voice card" number are your SOCIAL SECURITY NUMBER.
There have been endless discussions on Usenet about the SSN privacy issue.  I
would urge people to consider these risks before participating in this
"Beta-test".

Jim Morton, APPLiX Inc., Westboro, MA    ...uunet!applix!jim    jim@applix.com

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Chilling Advertisement
</A>
</H3>
<address>
Cindy Tittle 
&lt;<A HREF="mailto:tittle@ics.UCI.EDU">
tittle@ics.UCI.EDU
</A>&gt;
</address>
<i>
Wed, 31 Oct 90 16:20:13 -0800
</i><PRE>

I just saw a rather chilling advertisement in this week's edition of Newsweek
(November 5, 1990).  It features a computer monitor/keyboard with a Sherlockian
cap hung on one corner.  The bold type says "Information is your company's best
protection from liability."  OK so far, then I read on:

"Get it fast -- without leaving your desk.

Think about it.  Know your potential employees.  Verify the business credits of
new accounts.  Or, check out your new vendors.  Just hit a few keystrokes on
your personal computer and you've got it.

Information from UCC, civil and criminal record filings, Secretary of State,
and more, allow you to uncover bankrupticies, pending litigation and a wealth
of information that may protect your company from liability -- or even loss.
All you need is a personal computer and existing software.  That's right.  View
it -- Print it -- Store it.

CDB Infotek's Investigative Information System is an on-line database designed
to proved access to public record information for company security, credit,
personnel and management departments.

Not only is CDB Infotek's on line service one of the most comprehensive in the
industry, it's easy to use.  And it's fast.

Before you make a decision -- check the records -- check with CDB Infotek.

[...]"

Eek.

--Cindy

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Prodigy Censors Users
</A>
</H3>
<address>
Dave King 
&lt;<A HREF="mailto:71270.450@compuserve.com">
71270.450@compuserve.com
</A>&gt;
</address>
<i>
04 Nov 90 11:53:27 EST
</i><PRE>

Apparently, Prodigy is evicting users who are voicing their opposition to a new
Prodigy policy which will implement charges for EMAIL messages within the
Prodigy service.  In 1991 Prodigy will implement a policy which charges users
25 cents for every EMAIL message they send after the first 30 every month.
Prodigy users who have been vocal in their displeasure, and who have used the
facilities of Prodigy to attempt to recruit others to their cause, have found
themselves booted from the service.  According to a story by Evelyn Richards, a
Washington Post staff writer:
 
...  This week [Prodigy] unplugged about a dozen outspoken dissidents whom it
says were pestering innocent users with the electronic equivalent of junk mail.
But what Prodigy sees as a way to stop needless harassment seems to others as a
blatant example of censorship.  That's because the people bumped from the
Prodigy system included the most active critics of a planned price increase for
Prodigy's electronic mail service.
 
Using electronic mail on the network, the dissidents had urged other
subscribers to join the revolt by boycotting the advertisers that buy time on
Prodigy's network.  "Prodigy is arguing they don't want people harassing their
users," said Gary Arlen, editor of Interactivity Report, a Bethesda newsletter
that follows the on-line industry.  I think that's a stretch.  It's a way to
keep their advertisers pleased."
 
The incident is the latest to spotlight the difficulties society faces as it
struggles to adapt old laws and customs to emerging electronic networks. ...
Some people say on-line services should protect the right of all expression, as
a phone system does, while Prodigy argues it is more similar to a newspaper,
which is free to publish what it chooses.
 
Prodigy's troubles began two months ago when it announced that households would
be able to send their first 30 electronic mail messages free but would get
charged 25 cents for each additional message.  A core of angry subscribers
first protested by posting notices to Prodigy's on-line bulletin boards, the
computer equivalent of neighborhood kiosks.  Prodigy said it posted thousands
of such complaints for others to read - but it didn't publish them all.
 
When the writers urged a boycott of Prodigy advertisers - firms selling
products on the network - Prodigy's editors returned the messages to the
senders.  "We're not going to post something designed to destroy our business,"
said Geoffrey Moore, Prodigy's director of market programs and communications.
Moore likened the decision to a newspaper rejecting a letter to the editor, or
rejecting an advertisement that criticizes the newspaper's largest advertisers.
 
This week Prodigy decided enough is enough and refused to post any more
messages about the rate increase.  But what especially angered officials was
when the dissidents innundated other users with electronic chain letters urging
them to join the protest and boycott.  Moore said users complained, so Prodigy
bumped the offenders.
 
And now the protestors say that's unfair.  "We're not being abusive.  We're not
being vulgar.  All we're doing is making our (opinions) known," said Larry
Wienner, 22, a Prodigy user from Randallstown, Md.  Wienner said the bumped
dissidents are so hooked on Prodigy that they may try to re-subscribe under
assumed names.
 
Dave

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"Expert Systems in the Loop" explained (<A HREF="/Risks/10.52.html">RISKS-10.52</A>)
</A>
</H3>
<address>
Randall Davis
&lt;<A HREF="mailto:davis@ai.mit.edu ">
davis@ai.mit.edu 
</A>&gt;
</address>
<i>
Wed, 31 Oct 90 12:42:06 est
</i><PRE>

Martyn Thomas &lt;mct@praxis.co.uk&gt; writes:

&gt; The original article was mine, and referred to a report of a new research
&gt; project in the UK to develop an expert system to advise commanders in
&gt; tactical situations which are too complex to analyse without assistance.

&gt; This report *explicitly* referred to an expert system. The point of my
&gt; original posting was that an expert system which provides advice, in
&gt; circumstances where a decision must be made and there is insufficient time
&gt; for the commander to analyse the situation him/herself, is effectively
&gt; making the decision. Many who followed up agreed with this viewpoint. 

Fair enough.

Note also that a small variation on your fundamental claim is equally true:

 ... an EXPERT who provides advice, in
 circumstances where a decision must be made and there is insufficient time
 for the commander to analyse the situation him/herself, is effectively
 making the decision. 

That is, as is frequently true in these situations, not only is this not a
matter of expert systems, the computer itself is almost competely irrelevant.

It's a matter of being in a complex, time-constrained situation and needing to
make a decision.  If you don't have the time to consider carefully what to do,
you're just about equally up the creek whether you get the advice from a
machine or from another human being.

The moral of the story: try not to put yourself into those positions in the
first place.  Neither computers nor humans will get you out of it, and neither
of them is to blame for your predicament.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Airliner story (Re: Cherniavsky, <A HREF="/Risks/10.55.html">RISKS-10.55</A>)
</A>
</H3>
<address>
Christopher C. Stacy
&lt;<A HREF="mailto:cstacy@ai.mit.edu ">
cstacy@ai.mit.edu 
</A>&gt;
</address>
<i>
Wed, 24 Oct 90 19:46:01 EDT
</i><PRE>

I believe my original response explained the reasons why transponders are
required.  I must again emphasize that a safe flight under an IFR flight
plan, such as in the "horror story", can by all means be completed without
a transponder (or indeed, without any radar equipment, although nobody is
suggesting this alternative as convenient or desirable.)

We could discuss the details of the ATC issues related to the story, but
I didn't raise those originally because I didn't think this was really the
most appropriate forum for that lengthy technical discussion.

In order to clear up possible misunderstandings, I will respond to the specific
points you have raised in your message.  I could just quote regulations to make
my point, but I think it would be more useful to everyone else if they had some
more general background information about the procedures for conducting flights
like the one in the story.  So I'll start with an explanation of IFR, for those
who are not as familiar with aviation.

Airplanes are navigated by the pilot, not by ATC from the ground.

During good weather conditions, planes can operate under Visual Flight Rules
(VFR), whereby the pilot is responsible for (among other things) "seeing and
avoiding" other airplanes. When the weather is not good enough for flying
around this way, you operate under Instrument Flight Rules (IFR).  The IFR
concept is also based on pilots doing their own navigating, but it's along
completely specified routes.  Air Traffic Control (ATC) manages these routes to
make sure that only one single airplane occupies a given piece of airspace at a
time, since the planes can't see each other.  This function gives pilots a
rather special, personal meaning to the idea of "trusting the Government" :)

A fundamental component of IFR is the Flight Plan, which is the routing
specification for this particular flight.  As the flight progresses from
takeoff to landing, the controllers update the status of the flight, as
recorded on little strips of paper they push around.  This is all fairly
computerized, but can also be done with a pencil.

The pilot finds his way by referring to the charted route, and his Flight Plan,
and the onboard navigation instruments.  The most common instrument is a radio
receiver called a VOR, which listens to special ground stations that define the
airways.  There are other radio-based systems, such as LORAN, and also
self-contained systems like inertial guidance (famous from the KAL-007
disaster.)  The degree of onboard automation to navigate and automatically fly
the plane varies widely.

The pilot and controllers talk to each other over the radio, as the controller
clears the plane into each successive block of airspace.  There are contingency
procedures for a loss of communication, based on expectations from the Flight
Plan.

The clearances for a plane to enter a portion of an airspace route are based
upon the amount of separation that will be achieved between all the traffic on
that route.  The present speed of an aircraft and its known position are used
to figure out when it's safe for it to be cleared to move along.

ATC uses radar to watch the planes along the routes; this kind of direct
feedback allows them to increase the traffic density.  If radar is not
available, everything still works, but much more slowly.  Without radar, the
pilots have to regularly inform the controllers of their location, and verify
their assigned altitude.  In order to guarantee safety, the separation minima
are much greater when there is no radar contact.

The key point here is that without radar, or even radio communications, the air
traffic system can still keep putting IFR flights into the air with safety,
even if reduced to pencil and paper.  However, it couldn't keep up the volume
of service we are accustomed to, and all our flights would be delayed
considerably without these goodies.  This is why radar transponders are
normally required equipment.  But transponders do break.

In our story, we had not lost radar capability, but only the transponder.  The
transponder responds to radar signals by transmitting ("squawking") a coded
signal containing the the flight's assigned ID number, and the altitude.  In
addition to providing a more reliable signal, the ATC computers would normally
receive and use the ID number and indicated altitude to automate certain
tracking functions.

If our flight had been further along its route when the transponder failed,
assuming the pilots didn't want to land as a precautionary measure against more
critical system failures, they could have received clearance to simply continue
to Dulles airport and land as they had planned.

The exact separation procedures applied to this plane would vary, depending on
the type of automation available to each controller, and other things.
Depending on the effects of this, ATC might also decide to re-route us to
another less busy airway, for greater safety and to not restrict the flow of
other traffic on the original route.

On our way, we could be in radar contact, although the controller would have to
initially point at our target's primary return on the screen to tell the
computer which flight that was.  Next to the little "." or "+" representing our
airplane, the system could then display the usual data block (flight ID and
other information), except for the altitude readout, just as if it were a
normal flight.  Our aircraft could probably be radar separated laterally by
between 3 and 5 miles, depending on the phase of flight and a bunch of other
factors.  Vertical separation (altitude assignment) would be based on the other
traffic's altitude readout and our own altitude as reported by our pilot.

The enroute radar systems at a regional Air Traffic Control Center would
generally be able to track a primary return.  However, at the end of the
flight, the destination Approach controller might not have a system (such as
ARTS IIIA - Radar Tracking &amp; Beacon Level) that could track and predict primary
returns.  I guess this would probably mandate an increase to higher separation
minima than usual, during the final phases.

I'm not an air traffic controller or anything, and I'm not going into
excruciating detail on all the separation minima and equipment and procedures;
there are books available; I think you have the idea now.

Onto Ellen's specific complaints ...

   Reasons for being concerned about the lack of a working transponder are:
   an aircraft with invalid altitude data is not eligible for processing 
   by the conflict alert function, and in order to enter a Terminal Control 
   Area an aircraft must be equipped with a 4096 code transponder (so without a
   transponder the pilot could not fly into Newark, Kennedy, La Guardia, 
   Atlanta, Dallas/Fort Worth, etc.).  Agreed this is not an immediate major 
   safety problem, but there are good reasons not to proceed without 
   a transponder.

There are two issues here: Conflict Alert, and transponder requirements.

Conflict Alert is a set of features on some of the fancier Approach
controller's radar systems.  It is worth noting that only some of the radar
systems have this feature (for example, ARTS II doesn't.)

The first kind of Conflict Alert has to do with the terrain/obstruction
clearance map programmed into the system.  Basically, when an aircraft is off
the correct landing approach path, the system warns the controller.

The other Conflict Alert feature has to do with converging aircraft.  In an IFR
environment, this is just an additional safety feature; the separation criteria
already provide for airplanes not be close to each other.  It would warn the
controller if the airplanes got closer than 3 miles.  Of course, with arrivals
effectively slowed down due to increased separation minima, the controller can
simply monitor the separation manually.

For Conflict Alert to work, it has to have the plane's altitude readout from
the transponder.  So, if your transponder is not squawking your altitude, you
would indeed lose these extra safety features.  Lots of IFR flights are
conducted to or from airports which don't have radar services available.
Anyway, Conflict Alert is often turned off at ones that do.

Your statement about not being able to fly into a major airport (inside of a
TCA) without a transponder is simply false, and appears to stem from an
incomplete knowledge of the relavent regulations.  Maybe you just heard someone
briefly explain the rule in one sentence or something.

You can't fly into various kinds of airspace unless you have an operating
transponder.  In particular, you can't fly into the 30 nautical mile "Mode C
Veil" around a TCA without an altitude encoding transponder.  Unless the
controllers authorize you to do so.  To wit:

  FAR 91.215 (d) ATC transponder and altitude reporting equipment and use;
  ATC authorized deviations.  ATC may authorize deviations from paragraph
  (b) of this section -- (1) Immediately, to allow an aircraft with an
  inoperative transponder to continue to the airport of ultimate
  destination, including any intermediate stops, or to proceed to a place
  where suitable repairs can be made or both, (2) Immediately, for
  operations of aircraft with an operating transponder but without
  operating automatic pressure altitude reporting equipment having a Mode C
  capability; and (3) On a continuing basis, for operations of aircraft
  without a transponder, in which case the request for a deviation must be
  submitted to the ATC facility having jurisdiction over the airspace
  concerned at least one hour before the proposed operation.

If you refer to the Airman's Information Manual (170), or the Air Traffic
Controller's Handbook (5-41), there are additional notes on the subject.


I don't understand the sources of some of the people making various claims
about the air traffic system and its risks.  I am just a simple four-month old
private pilot (not even instrument qualified) and my information comes from my
primary training, reading basic textbooks, and asking questions to the local
FAA experts (the folks at Boston Center.)  I wish people would research things
more before making scary statements.

If people would like to continue this discussion in this kind of detail, I
would be willing, but I consider this all to be a sidetrack from the essential
points about the airliner story and how IFR flight works.  Not to mention
whether the Airbus is safe or not.

My messages on the subject may have been somewhat charged, and if I have
needlessly offended anyone, I apologize.  However, the misinformation and
misconception of issues surrounding flying is generally enormous, and I felt
compelled to introduce a few facts and context into the discussion.  I hope
anyone has found this useful.

There are definitely risks associated with aviation, but unfortunately it's a
technical enough subject area that it can be difficult to understand and
evaluate without alot of detailed knowledge.

I think that the risks associated with systems such as fly-by-wire (remember
that?)  is a useful topic for discussion here, especially in broad terms of
raising the basic risk awareness.  I would be wary of certain kinds of
micro-analysis however, unless you're pretty sure of what you're talking about.

Have you ever noticed when you read a newspaper or watch television
news, that, quite often, technical issues you happen to be familiar with
are misunderstood and distorted?  I hope that similar treatments of our
varied issues will not become the usual practice in RISKS.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.57.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.59.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-32</DOCNO>
<DOCOLDNO>IA013-000136-B030-207</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.59.html 128.240.150.127 19970217040642 text/html 30783
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:05:10 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 59</TITLE>
<LINK REL="Prev" HREF="/Risks/10.58.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.60.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.58.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.60.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 59</H1>
<H2> Friday 9 November 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Software fault hits payphones" 
</A>
<DD>
<A HREF="#subj1.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Plain paper faxes keep copy of received material 
</A>
<DD>
<A HREF="#subj2.1">
Jan Christiaan van Winkel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Customers limiting programmer access to their systems 
</A>
<DD>
<A HREF="#subj3.1">
Jim Kimble
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Student hackers arrested 
</A>
<DD>
<A HREF="#subj4.1">
Dave King
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Sprint's new calling card 
</A>
<DD>
<A HREF="#subj5.1">
anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Employer's use of credit reports 
</A>
<DD>
<A HREF="#subj6.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Computers lead to greater monopolization? 
</A>
<DD>
<A HREF="#subj7.1">
Jim Griffith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Risks when computers replace humans 
</A>
<DD>
<A HREF="#subj8.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Villanova University Computer Ethics course Group Project 
</A>
<DD>
<A HREF="#subj9.1">
J. Gacad et al.
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
"The Devouring Fungus" at a bookstore near you 
</A>
<DD>
<A HREF="#subj10.1">
Gene Spafford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
4th Annual Computer Virus &amp; Security Conference 
</A>
<DD>
<A HREF="#subj11.1">
Gene Spafford
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Software fault hits payphones"
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Fri, 9 Nov 90 11:04:27 BST
</i><PRE>

Electronics Weekly (November 7 1990, front page) reports that there is a
software fault in the payphones manufactured by Paytelco (a GPT subsidiary)
and used in the UK by Mercury. They are "exported to &gt;40 countries".

The software fault allegedly allows a phonecard holder to avoid paying for
calls. No technical knowledge or special equipment is required. EW reports that
the faulty software has been rewritten, and that replacement ROMs are being
installed in all payphones.

In the same issue, EW reports a different fraud involving restoring the
holograms on used British telecom phone cards. EW claims to have seen the
restoration demonstrated. They have not published details of the method, but
hint that it involves "phase changes" in the polymers which store the
holograms, through reducing the temperature of the card.

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
plain paper faxes keep a copy of all received material
</A>
</H3>
<address>
Jan Christiaan van Winkel 
&lt;<A HREF="mailto:jc@atcmpe.atcmp.nl">
jc@atcmpe.atcmp.nl
</A>&gt;
</address>
<i>
Fri, 9 Nov 90 12:34:44 MET
</i><PRE>

I was asked to change the paper on out FAX machine today. I took a 'kit' we
have for this purpose, and saw that I also had to change the 'toner-roll'. This
is a roll of carbon paper (sort of) that actually prints the message on the
(plain) paper.

I saw that all messages printed on the FAX, are also 'burned' in the carbon
paper (well, that's how the thing works). This means that even if I stand next
to the machine to receive a private message, people can later just open the FAX
machine and read the message. Even worse, since people are not aware of this
'copy' on the toner roll, they just dispose of the roll in the garbage can.

I wonder how many people know about this 'feature' of plain paper FAX-es...

Jan Christiaan van Winkel      Tel: +31 80 566880  jc@atcmp.nl
AT Computing   P.O. Box 1428   6501 BK Nijmegen    The Netherlands

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Customers limiting programmer access to their systems
</A>
</H3>
<address>
The Programmer Guy
&lt;<A HREF="mailto:jkimble@bally.bally.com ">
jkimble@bally.bally.com 
</A>&gt;
</address>
<i>
Mon, 5 Nov 90 11:49:42 PST
</i><PRE>

Jerry Leichter writes:
&gt; If the courts uphold Logisticon, it's certain that in the future
&gt; companies will not be willing to allow access to their systems by their
&gt; software suppliers.  At best, they might allow access only from
&gt; locations controlled by the company, so that they can quickly lock out
&gt; the supplier. 

Given all the press on these types of events, many of my clients have enacted
some new policies to protect themselves.  Here's the most restrictive...
(thanks, Logisticon):

Before I can dial-in to make a change to a casino's on-line computer, I nnhave to
draft a memo outlining my expected changes and file it with the casino's MIS
department 48 hours in advance.  After it's been reviewed and approved, the
modem is turned (using human call-back verification of identity) and I am
permitted to make my changes.  Within 72 hours of logging in, I have to file
another document with the Gaming Control Board outling everything that was
done, files that were changed, why they were changed, dates, times, etc.  On
the east coast, this paperwork is filed with a division of the State Police so
lies can cost you not only a civil suit, but criminal charges (perjury, etc.)
as well.

Other steps my clients have done to protect themselves include requiring me to
put the original source code tapes in a safety depositn box they can immediately
access so that any problems I create -- intentional or accidental -- can be
"fixed" by applying the virgin tapes.

As you can imagine, this extra bit of work greatly lowers programmer
productivity, especially for the simple, one-line changes; instead of working
to isolate and resolve problems, I spend a lot of time drafting memos and
reports.

At least in this part of the gaming industry, basic programming jobs involve
70% code/theories/debugging, and at least 30% communications skills.

--Jim Kimble,						jkimble@bally.bally.com
Consulting for Bally Gaming				  uunet!bally!jkimble

                                        [I doubt if that is a Bally High.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Student hackers arrested
</A>
</H3>
<address>
Dave King 
&lt;<A HREF="mailto:71270.450@compuserve.com">
71270.450@compuserve.com
</A>&gt;
</address>
<i>
06 Nov 90 22:46:48 EST
</i><PRE>

   NEW YORK (UPI) -- Two Staten Island youths were arrested on charges of
invading and disrupting the computerized voice mailbox system of a
Massachusetts firm, costing the company $2.4 million, officials said Tuesday [6
Nov 90].  State Police Senior Investigator Donald Delaney said [...] as a
result of the hacker operation, the International Data Group of Framingham,
Mass., lost scores of these messages.  Delaney said an intensive two month
investigation led police and U.S. Secret Service agents to Daniel Rosenbaum,
17, of 42 Caswell Ave., and to a 14-year-old associate, whose identity was not
disclosed because of his age.  He said exhaustive experimentation by the two
suspects enabled their home computer to dial into the system and obtain the
password to use it.
   The youths then changed the passwords for various units in the system, which
resulted in the loss of many important messages.  "In addition, the company had
to shut down the system for 18 days to revamp it," Delaney said.  He added that
the teenagers "made bomb threats and other harassing messages to the company,
and when they were in contact with women employees, they made sexually explicit
remarks to them."  Delaney said Rosenbaum stated that he focused on the
Massaachusetts firm "in anger" when it failed to send him a poster which was
supposed to accompany a paid subscription for a computer game magazine
published by the company.
   Both teenagers, students at Wagner High School, were charged with computer
tampering, unauthorized use of a computer and aggravated harassment.  [...]  If
Rosenbaum is convicted of the charges, he could be sentenced to four years in
prison, Delaney stated.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Sprint's new calling card
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
Wed, 7 Nov 90
</i><PRE>

Jim Morton raises a couple of serious risks with respect to Sprint's new
calling-card system.  I used to work for the company which builds the hardware
and software Sprint is using.  At a major presentation the manager in charge of
the project presented the voice-recognizing, Social-Security-number system.  He
presented his own card, prominently displaying his SSN, which I copied down.

During the presentation, he explained that Sprint wanted to use voice
technology so that people wouldn't have to write down as many things (card
number, password number).  Their customer surveys also indicated that people
found a 14-digit number "hard to memorize" and that a 9-digit number "which
was one they used all the time" would be "more convenient."

After the presentation, I arranged to speak to the manager.  I raised the same
objections Jim Morton noted in his article.  I also pointed out that he (the
manager) had put his SSN up in front of close to 120 people and if any of them
were of a mind to be nasty he could be in trouble.  He scoffed at my concerns
and assured me that Sprint's customer-survey managers were aware of the
problems.

He also stated that he disbelieved anyone could "do any damage" simply by
possessing another's SSN.  I tried to explain, but he brushed me off and left.
I spent the rest of the afternoon staring at the napkin on which I had written
the manager's SSN.  As I saw it, I had three options:

	1.Do nothing.

	2.Try to find someone else in the company hierarchy to listen to my
	  complaints.

	3.Construct an object lesson which would convince the manager of how
	  real my objections might become.

I chose option 1.  I had raised the objections as forcefully as I dared (the
manager was several levels higher than I in the hierarchy, and *much* more
senior).  Trying to circumvent channels is discouraged in the extreme in
this company.  I already had a reputation as a serious maverick.  I didn't
have any evidence to support my objection; all I had was a set of vague
assertions which, to me, seemed to be common sense.  Pitted against the
expressed desires of our customers (Sprint), you can guess how much weight
this would have been given.

With respect to option 3, I can think of at least six ways to make someone's
life seriously miserable if I have their SSN.  I thought about using the
manager's SSN for this example, but since most of the ways I know of involve
committing misdemeanors or felonies, I decided it wasn't worth the risk.  It
also might harm his family who I felt did not deserve to suffer.

In hindsight, I could have bucked the chain of command anyway.  But if put
in that position again, I'm still not sure I would.  In a way, I feel that
people have the choice to use Sprint's stupid, vulnerable system.  I know I
won't.  I also don't have a bank-by-phone system, nor do I have an answering
machine that can be manipulated from a remote touchtone phone, nor do I give
out my SSN to anyone who can't prove a need or legal requirement for it.

But then, maybe I'm a fossil in the information age.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Employer's use of credit reports
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Thu,  8 Nov 90 09:03:00 EDT
</i><PRE>

		Use of Credit Reports In Hiring Draws a Caution

	Managers who use credit reports to screen job seekers, beware:
	Spurned applicants have a right to know.

	That message is going out from federal officials, who have grown
	concerned over that companies may be sidestepping the law governing
	the review of personal credit information.  The law permits companies
	to consult credit reports when evaluating job seekers, a practice
	that has boomed of late among employers who see the reports as a way
	to judge the character of prospective workers.  But the law also
	demands that applicants know when they've been rejected "wholly or
	partly" because of data in their credit file - a step that, critics
	have charged and officials fear, many employers ignore.

	The [FTC] ... underscores the requirement in articles that two large
	purveyers of credit reports, TRW and Equifax, agreed to circulate ...
	to ... their customers.  If they fail to comply with the disclosure
	requirement, the pieces note, employers may face suits from both the
	job applicant and the FTC.

	The credit data agencies were "very pleased" to disseminate the warn-
	ings [according to the FTC]....  One factor ... may be the prospect of
	new restrictions on their activities, now pending in Congress. ...
	TRW even changed its contracts to clarify the notification rule for
	employers.

There's actually more to this issue than the WSJ mentions.  Business Week had
an article on it a couple of weeks back.  At one time, references were a fun-
damental part of the hiring process.  Changes in the legal climate - particu-
larly many successful lawsuits by former employees who felt they had received
unfair recommendations that cost them jobs, plus increasing restrictions on
what an employer may legally ask of a job-seeker - have caused many of the
traditional sources of information to dry up.  Recommendations these days are
pretty uniformally bland and uninformative, and interviewers have gotten very,
very cautious.  So a recent trend is to use credit and other similar reports.

The problem is that the reports often contain data that is unverified or
inaccurate - especially since there is a growing market for "el cheapo" re-
ports for entry-level employees.  Even when the reports are accurate, they may
contain information that an employer is legally not permitted to have.  Two
specific examples that have cost people jobs (illegally, if they can prove
it):  Reports of arrests that did not lead to convictions, and reports about
workman's compensation claims.  (The view among some employers is that anyone
who filed for workman's compensation is just out to milk the system, and they
don't want the headache - Business Week has a quote from one employer saying
exactly that, even more harshly than I just did.  They also give an example of
someone who was genuinely injured on the job, took his workman's compensation,
recovered - and has been consistently turned down for jobs ever since.)

The reason that the big guys like TRW and Equifax are willing, even eager, to
help out on issues like this is that the last thing they want is a lot of small
low-ball competitors who not only steal market share from them, but also bring
public (particularly, Congressional) attention to the business.  While in this
case their cooperation may be useful, it's well to remember that ALL of the
credit companies have been involved in problems, even scandals, in the past;
and that it's a classic pattern for regulated industries to come to like the
umbrella of regulation they live under: It keeps competitors and critics out.
							-- Jerry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Computers lead to greater monopolization?
</A>
</H3>
<address>
Jim Griffith
&lt;<A HREF="mailto:griffith@dweeb.fx.com ">
griffith@dweeb.fx.com 
</A>&gt;
</address>
<i>
Wed, 7 Nov 90 09:40:00 PST
</i><PRE>

I heard a radio report saying that someone back east has filed a class action
lawsuit against a number of airlines, charging them with violating anti-trust
laws.  The suit claims that the predominance of live-feed computer systems
in the airlines industry lends itself towards a situation where airline
companies can instantly find out what their competitors are charging and change
their prices accordingly.  A number of airlines were named in the suit.

I'd appreciate someone coming up with a newspaper article or something more
definitive than what I'm reporting.
                           		               Jim

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
risks when computers replace humans (was: Expert System ... Loop)
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Mon, 5 Nov 90 16:51:47 BST
</i><PRE>

I wrote:
 
 &gt; This report *explicitly* referred to an expert system. The point of my
 &gt; original posting was that an expert system which provides advice, in
 &gt; circumstances where a decision must be made and there is insufficient time
 &gt; for the commander to analyse the situation him/herself, is effectively
 &gt; making the decision. Many who followed up agreed with this viewpoint. 

... and davis@ai.mit.edu (Randall Davis) replies:
: Fair enough.
: 
: Note also that a small variation on your fundamental claim is equally true:
: 
:  ... an EXPERT who provides advice, in
:  circumstances where a decision must be made and there is insufficient time
:  for the commander to analyse the situation him/herself, is effectively
:  making the decision. 
: 
: That is, as is frequently true in these situations, not only is this not a
: matter of expert systems, the computer itself is almost competely irrelevant.
: 
: It's a matter of being in a complex, time-constrained situation and needing to
: make a decision.  If you don't have the time to consider carefully what to do,
: you're just about equally up the creek whether you get the advice from a
: machine or from another human being.
 
This is true, but there are characteristics of computer systems that make the
risks different (and less acceptable) than the risks from humans in the same
role.

This is the major reason for the RISKS Forum, so I don't need to list the
characteristics here. They include the complexity of the systems, the
difficulty of assuring that the system functions as intended, and the extra
risks if the system is replicated many times, so that the same fault may appear
in many places.

Randall Davis continues:

: The moral of the story: try not to put yourself into those positions in the
: first place.  Neither computers nor humans will get you out of it, and neither
: of them is to blame for your predicament.

I agree. There is a danger that the expert system will be trusted to a greater
extent than a human expert, and that this will lead to commanders being sent to
places where they would not be sent if only human experts were available to
help. It is important to remember that the expert system, like any computer
system, is complex and probably contains errors. Add to this that it is
effectively in the loop (in the circumstances of the original discussion) and
we can have a sensible discussion about whether it is a good idea to deploy the
system.

Finally, but very importantly, there is the question of who is accountable for
the consequences of errors. In the case of the human expert, accountability is
clear and liability may follow. If the accountability (and possible liability)
is not clear for the situation which uses a computer system, then I believe
that the system should not be used in a critical application.

In my view, the organisation which puts the system into use should be liable
for any injuries it causes, (and I would expect a prudent organisation to pass
this liability to the company which developed the system, through the
development contract).

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Villanova University Computer Ethics course Group Project
</A>
</H3>
<address>

&lt;<A HREF="mailto:21202764@VUVAXCOM.BITNET">
21202764@VUVAXCOM.BITNET
</A>&gt;
</address>
<i>
Wed, 7 Nov 90 20:35 EST
</i><PRE>

        I represent a group of Computer Science majors at Villanova University,
Villanova, PA who are currently doing a project in a Computer Ethics course. I
am writing in response to a story posted in the RISKS forum on OCT 18 -
`Flawed Computer Chip Sold For Years'(RISKS digest 10.54). Our group project
is to analyze this case in terms of present day ethical theories and give a
class presentation on it. Thus, we have a few questions about it:

1. I need more details/specifics on the chip.(i.e. what was its model number,
   what was its design flaw, etc).

2. Are there any other journals/newspapers where the story appeared?

3. What has National Semiconductor done since the article in the newspaper
   revealed the problem?

If anyone out there could send any other pertinent information about the
case, we'd appreciate it. Replies may be sent to my bitnet address:
21202764@VUVAXCOM. (I do not know if I have a UUCP or CsNet address).

Jonathan Gacad (21202764@VUVAXCOM), Bob Durbin, Lisa Cofey, Al Giordano

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
"The Devouring Fungus" at a bookstore near you
</A>
</H3>
<address>
Gene Spafford
&lt;<A HREF="mailto:spaf@cs.purdue.edu ">
spaf@cs.purdue.edu 
</A>&gt;
</address>
<i>
8 Nov 90 00:07:01 GMT
</i><PRE>

I just recently got a copy of "The Devouring Fungus: Tales of the Computer Age"
by Karla Jennings (W. W. Norton &amp; Co., ISBN 0-393-30732-8, $10.95).

As can be gathered from the unusual title, this is not exactly a computer
textbook.  What it is, is a collection of anecdotes and stories about computer
technology and the people who spend their time working with computers.  The
stories range from historical to modern-day, and most are amusing to read.  Not
all are firmly grounded in documented facts, but that doesn't detract from the
amusement factor; even the apocryphal tales convey a sense of the attitudes and
foibles of the "computer geeks" who have shaped our community.

The tales related in the book read like a cross between items in the Risks
digest and postings to the alt.folklore.computers newsgroup.  Many of the
stories will be familiar, but that is what makes them folklore -- we've all
heard variants of these stories, and probably repeated a few in turn.  This is
the first time I have seen anyone collect so many of them together, and in such
an amusing and readable way.

For $11, this is a must buy if you're into computers.  My copy is going in a
place of honor next to my Hacker's Dictionary, and just down the shelf from my
Sidney Harris cartoon book. Check it out yourself.

Gene Spafford NSF/Purdue/U of Florida SERC Dept. of Computer Sciences, Purdue
University, W. Lafayette IN 47907-2004 ...!{decwrl,gatech,ucbvax}!purdue!spaf

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
4th Annual Computer Virus &amp; Security Conference
</A>
</H3>
<address>
Gene Spafford
&lt;<A HREF="mailto:spaf@cs.purdue.edu ">
spaf@cs.purdue.edu 
</A>&gt;
</address>
<i>
6 Nov 90 19:36:34 GMT
</i><PRE>

			   Call for Papers
	   4th Annual Computer Virus &amp; Security Conference
		 March 14 &amp; 15, 1991 in New York City
				   
	  Sponsored by the DPMA Financial Industries Chapter
		  In Cooperation with ACM SIGSAC and
		   The Computer Society of the IEEE


The 4th Annual Computer Virus and Security Conference will feature more
than thirty speakers on the topics of computer viruses and "vandalware,"
computer law, and computer security.  Approximately twenty are well-known
experts in the field, and fifteen or more will be selected on the basis of
submitted papers.

Held on Thursday and Friday (Ides of March) at the New York World
Trade Center, this major event features:

    * Identification of latest threats to SNA, DEC, PC, MAC, X.25
	 and UNIX.

    * Tools and Techniques: What the major corporations are doing.

    * Specific Countermeasures: From labs, other companies, commercial
	vendors.

The Conference traditionally covers recent outbreaks and experiments;
virus/intruder prevention, detection and recovery; product
demonstrations and ratings; and special attention to LAN, PBX, SNA,
OSI, E-Mail, and legal issues.

This year's focus topics are as follows:

    * Prevention, detection and recovery from viruses and other harmful
	computer programs.

    * Original research on these and related topics.

    * Recovery from the Wall Street Blackout and the Novell Virus.

    * Case studies of computer and network security.

    * Surveys of products and techniques available.

    * Computer crime and related actions.

The bound Proceedings will include both the accepted papers and also
discursive articles by the invited speakers. There will be four
concurrent conference tracks each day:

    Thursday will feature the Main Track, Products Track, Research
    Papers, and a special Trap &amp; Prosecute track geared to law
    enforcement and criminal justice personnel.

    Friday will feature Main, Products, and Research tracks, and a How
    to Recover track strongly requested by returning attendees from
    last year.

In the past, this conference has been featured in BYTE, CIO, Communications
(ACM), Computer (IEEE), Computerworld, Data Communications, Data Center
Manager, Datamation, Info World, Macintosh News, MIS Week, Network World,
and Unix Review. It is sponsored by the Data Processing Management
Association Financial Industries Chapter in cooperation with ACM SIGSAC and
the IEEE Computer Society.

Attendees may make use of discount airfares (43% off Continental) from
anywhere to New York, including both adjoining weekends.  The Penta
Hotel (formerly Statler Hilton) has reserved a block of Conference
rooms at $89 per night. Conference itself includes luncheon and
quarter-mile-high hospitality at Windows on the World Restaurant.

Target audience includes MIS Directors, Security Analysts, Software
Engineers, Operations Managers, Academic Researchers, Technical Writers,
Criminal Investigators, Hardware Manufacturers, and Lead Programmers.
Registration (202-371-1013) costs $275 for one day, $375 for both, with a
$25 discount for members of cooperating organizations (DPMA&lt; ACM, IEEE-CS).

Submissions to the conference may be either as an extended abstract or a
draft final paper.  Four copies of each submission should be *received* by
the program chair no later than Tuesday, January 8, 1991.  Each submission
must contain a brief abstract (approx. 200 words), and a header identifying
the names, affiliation, address, and e-mail address (optional) of all
authors.  Successful submitters or co-authors are expected to present in
person.  Decisions will be announceed by Feb. 12, 1991.

Submissions are invited on all aspects of the conference, and particularly
on new research in the area of vandalware and countermeasures.

Program Committee:

    Richard Lefkon		David M. Chess		Stephen R. White
    NYU, DPMA			IBM			IBM

    Thomas Duff			Frederick B. Cohen	Gene Spafford
    AT&amp;T Bell Labs		ASP Research		Purdue University

    Dennis D. Steinauer		Gail M. Thackery	Kenneth R. van Wyk
    NIST			AZ Attorney General's	DARPA/CERT
				   Office
-- 
Gene Spafford
NSF/Purdue/U of Florida  Software Engineering Research Center,
Dept. of Computer Sciences, Purdue University, W. Lafayette IN 47907-2004
Internet:  spaf@cs.purdue.edu	uucp:	...!{decwrl,gatech,ucbvax}!purdue!spaf

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.58.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.60.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-33</DOCNO>
<DOCOLDNO>IA013-000136-B030-237</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.60.html 128.240.150.127 19970217040656 text/html 25875
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:05:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 60</TITLE>
<LINK REL="Prev" HREF="/Risks/10.59.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.61.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.59.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.61.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 60</H1>
<H2>Wednesday 14 November 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer Mishap Forces shift in Election Coverage 
</A>
<DD>
<A HREF="#subj1.1">
bahn_pr
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Voting electronically from home (revisited) 
</A>
<DD>
<A HREF="#subj2.1">
John Roe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Barclays' security: apologies! 
</A>
<DD>
<A HREF="#subj3.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Juicy 911 RISKS 
</A>
<DD>
<A HREF="#subj4.1">
Steve Smaha
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: UK Software Engineer Certification 
</A>
<DD>
<A HREF="#subj5.1">
Brian Tompsett
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Software Protection Tool 
</A>
<DD>
<A HREF="#subj6.1">
Dave Erstad
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Sprint's voice-card system 
</A>
<DD>
<A HREF="#subj7.1">
Steve Elias
</A><br>
<A HREF="#subj7.2">
 Jerry Glomph Black
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: Carbons 
</A>
<DD>
<A HREF="#subj8.1">
Douglas W. Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Your Flood Stories, Please 
</A>
<DD>
<A HREF="#subj9.1">
Lindsay F. Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
Corrected version of Virus Conf announcement 
</A>
<DD>
<A HREF="#subj10.1">
Gene Spafford
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer Mishap Forces shift in Election Coverage
</A>
</H3>
<address>
&lt;<A HREF="mailto:bahn_pr%ncsd.dnet@gte.com">
bahn_pr%ncsd.dnet@gte.com
</A>&gt;
</address>
<i>
Fri, 9 Nov 90 16:04:31 -0500
</i><PRE>

The Washington Post, New York Times and USA Today had ordered national vote
trend analyses from Voter Research and Surveys, a company set up to do exit
poll surveys and have the results analyzed by 3:30pm on Election Day, 6 Nov 90.
A computer glitch prevented the results from being available at all on that
day.  VRS had the data, but the weighting program did not work.  [Abstracted by
PGN from `Computer Mishap Forces shift in election coverage, Major Newspapers
faced with delays in polling data', by Lynn Duke, staff writer Washington Post,
7 Nov 90]

  Now what i found interesting was the idea of Sam Donaldson screaming into
  some programmers ear while a camera is pointed on him. "Fix the program or
  we'll do a story on you buddy."  :-)

  There are some interesting risks.  First that unclean data was used and
  second that the big news agencies now all use the same polling source.  What
  a risk if someone hacked them to create false trends.  [bahn_pr]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Voting electronically from home (revisited)
</A>
</H3>
<address>
John Roe 
&lt;<A HREF="mailto:johnr@hpltbg.fc.hp.com">
johnr@hpltbg.fc.hp.com
</A>&gt;
</address>
<i>
Mon, 12 Nov 90 13:27:39 MST
</i><PRE>

A Boulder CO group has rediscovered Bucky Fuller's 50-year-old suggestion that
everyone should be able to vote telephonically from home or wherever.

  "The system is based on a personal computer hooked into [the] telephone
  line.  [Local activist Evan Ravitz] also loaded a list of registered Boulder
  County voters into the computer's memory, and the system checks names against a
  six-digit code based on date of birth.  Callers enter their selections for
  the ballot by entering numbers on a Touch-Tone telephone.  [...]

  "Boulder County Clerk and Recorder Charlotte Houston ... placed a call to the
  system on Monday and found that could could have voted for her son and
  daughter by providing their birth dates or Social Security numbers."

[Abstracted by PGN from `Phone voting?  Boulder group says it's time', an AP
story from the Loveland, Colorado, Reporter-Herald, 6 Nov 1990.]

I found this article alarming for a number of reasons:

First, the possibilities for massive fraud are probably obvious to all
RISKs readers.  For example, if (as implied by the article) one can vote
for another by simply knowing either the birth date or their Social
Security number, with the hardware already in my own basement plus an
appropriate database (which shouldn't be too hard to come by) I could have
easily changed the outcome of a number of races and constitutional
amendments here in Colorado during the November 6th election.  With a
concerted effort I could have chosen any candidate I wished.  If I knew
which registered voters had not voted recently, I could even make a
reasonable effort at making my fraud somewhat less detectable.

Second, I was disturbed (but not surprised) that the article emphasized the
"gee-wiz" aspect of the idea, but mentioned the RISKs only in passing, and
ended with a statement that implied that concern over fraud were irrelevant and
paranoid.  The token assurances of Mr.  Pelton only serve to support this
perception.  I have come to expect that the popular press is ill-equipped to
understand, evaluate, and explain the risks of technology to their readers (or
viewers, in the case of television).  This latest example only reinforces my
expectations.

Finally, and perhaps most significant, was the cavalier attitude of Mr. Ravitz
toward the possibility of fraud, and his obvious lack of understanding of the
problem.  The current system is NOT based on honesty: it is based on physical
security.  If it is sufficiently hard for the same person to vote multiple
times, voter fraud can be reduced to acceptable levels (but not eliminated, of
course).

In my precinct, I could conceivably vote two or three times before the election
officials would start getting suspicious.  If I spent the entire day driving
around to various polling places in northern Colorado, I could perhaps vote a
few dozen times.  But to influence the outcome of the election would require a
large number of cohorts; a task I could accomplish by myself from the comfort
of my own home if Mr. Ravitz's proposal becomes law.

I wonder if we would be permitted to vote on changing Colorado's election laws
to permit voting by phone, by voting by phone?  The outcome of such a vote
could be enlightening ...

John Roe, Hewlett-Packard, Colorado Integrated Circuits Division, 3404 East
Harmony Road, Fort Collins, Colorado 80525-9599              (303) 229-4554

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Barclays' security: apologies!
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Tue, 13 Nov 90 11:30:57 PST
</i><PRE>

In <A HREF="/Risks/10.50.html">RISKS-10.50</A>, in an item entitled "Hackers blackmail five banks (UK)", I gave
excerpts from a newspaper report about the breach. I followed this with an
anecdote told by the manager of the local branch of a chain of off-licences,
who found that, after sending in his completed order to the main warehouse,
what appeared to be credit card transactions from Barclays' Bank were displayed
on his screen.

Shortly thereafter, I received a phone call from the head of Information
Security at Barclays, who was puzzled by the incident, and requested further
information. Barclays' investigation revealed that the credit card transactions
were in fact records of purchases made using the particular card at that
off-licence, and others of the chain in the area. There was therefore no breach
of security, since, of course, the manager had the right of access to that
information. The incident was *not*, as I first thought, due to unencrypted
transactions being transmitted over the public telephone lines being received
by the wrong terminal. The only problem appears to have been a minor glitch
which caused a file of credit transactions on the local machine to be displayed
when my friend was not expecting it.

So apologies to Barclays Bank!

I hope that Barclays' security department are happy to let me set the record 
straight via RISKS, which they obviously monitor, and perhaps they would care 
to add some comments of their own.

Moral: Check your facts before passing on anecdotes which you hear in pubs!

Peter Mellor, Centre for Software Reliability, City University, Northampton 
Sq., London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Juicy 911 RISKS
</A>
</H3>
<address>
Steve Smaha 
&lt;<A HREF="mailto:Smaha@DOCKMASTER.NCSC.MIL">
Smaha@DOCKMASTER.NCSC.MIL
</A>&gt;
</address>
<i>
Sun, 11 Nov 90 13:51 EST
</i><PRE>

"911 calls are ripe for trouble"
11 Nov 90 Austin American-Statesman, BLACKSBURG, VA (AP) 

These are hardly salad days for Montgomery county law officials.  Last week,
police were testing the county's 911 system, scheduled to begin operating next
month, when the dispatcher received 10 calls that were traced to the home of
Linda and Danny Hurst.  She tried to call the line, but it was busy.  When she
hung up, she received another call from the same line.  And another.

Deputy sheriff tracked down Linda Hurst.  "I told them I'd locked my house and
there shouldn't be anyone in there," she said.  Police, concerned that someone
had broken in, asked Hurst to meet them at her house.  She parked in front of
the house, and walked up to the front door.  "But they said, 'Ma'am, step back
please.'  I looked back and they had their guns drawn.  They were serious,"
Linda Hurst said.  "They went through the house, but they couldn't find
anybody, so I went inside."

Finally, Linda Hurst's brother spotted the culprit - an overripe tomato.  The
tomato was hanging over the telephone in a wire basket, dripping juice into the
couple's answering machine.

Chief Deputy Milton Graham said the tomato juice apparently got into the
telephone's dialing system and caused it to dial the sheriff's office.  "We're
not sure how.  Maybe they had speed dialing and it shorted out," he said.  "I
didn't know the answering machine could even dial out," Linda Hurst said.
"It's just supposed to take messages."

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re:  UK Software Engineer Certification
</A>
</H3>
<address>
Brian Tompsett 
&lt;<A HREF="mailto:bct@cs.hull.ac.uk">
bct@cs.hull.ac.uk
</A>&gt;
</address>
<i>
Mon, 12 Nov 90 12:24:00 GMT
</i><PRE>

This note supplies greater detail about the steps involved in the certification
of Software Engineers in the UK. It is in response to several inquiries
requesting more detail after my last contribution to RISKS (Sept 21, 1990).

In answering the questions let me point out that the UK does not have Software
Engineering *specific* certification. Nor does it have *certification* in the
strict sense that is being discussed in the US at present. When I have detailed
the routes available in the UK you can decide for yourself how this relates to
what does/will exist in the US.

Let me start by describing the qualification route from High School through the
maze of qualifications and certifications. I can deal with how existing
Engineers fit into the picture later.

      .------------------ Government --------------.
      |   Approves                     Charters    |
      |   Curriculum                   Body        |
      v                                            |
  High School                                      |
      |                                            v
      | University                              Engineering
      | Entrance                                Council
      | Exams                                      |   Accredits
      |                                            |   Society
      v                                            v
  University &lt;-------Accredits Degree Course--- Professional
      |                                         Society
      | Accredited                              |  |
      | Engineering                   .---------'  | Join Society
      | Degree                        |            | 
      v                               |            v
  Graduate                            |         Student member
  Employment &lt;--Approves training-----'            |
      |                                            |  Get experience
      | Certified                                  |  
      | Engineering                                |
      | training and experience                    |
      v                                            v
  Chartered                                   Corporate Member
  Engineer-------------------.                     |
  Status                     |                     |  More
      |                      |                     |  Experience
      | Outstanding          |                     |
      | Achievement          |                     |
      v                      v                     v
  Fellowship              European        Fellowship of Society
 of Engineering           Engineer

The route illustrated in the above diagram is not specific to Software
Engineers, but is the generic model for all Engineers in the UK. The student
starts by taking a degree course at a University; this may be a B.Eng, M.Eng or
B.Sc. degree. In order for this degree to be considered a suitable education
for an Engineer the course must be accredited by the appropriate professional
body. The accreditation examines the curriculum, the facilities, the teaching
department and the institution itself. After graduating the student is expected
to take a position that will provide practical engineering training and real
experience. The training and experience is logged in the graduates own
engineers logbook and signed-off by qualified engineers and trainers. The
professional society provides the employer with the basic structure for this.
When the Graduate Engineer has gained sufficient experience (minimum 4 years)
he may apply to be a Chartered Engineer. Admission to Chartered Engineer can
only be made through a professional society and normally corporate membership
of the society requires the same entry qualifications as Chartered
Engineership. On joining the society the member is required to follow
professional code of conduct and code of practice. The admission procedure
involves vetting the applicants qualifications, receiving references from the
applicant's sponsors who are normally two other professional members and an
interview.

The Professional Society itself is accredited by the Engineering Council. The
accreditation examines the Societies methods and procedures for admission,
course accreditation and so on. The Engineering Council needs to ensure that
Engineers from all the different disciplines are equally qualified to be
Chartered Engineers. The area represented by the Society must also be one that
is considered as Engineering. This was a major hurdle for the British Computer
Society to show that "Information Systems Engineering" is Engineering and
qualified practitioners are worthy to be Chartered Engineers. This process took
four years.

The Pan-European Engineering element should also be noted. Someone qualified
as a Chartered Engineer may also apply for the title "European Engineer". This
is a title that is recognised across Europe. It also has its own code of
conduct in addition to the one applied by the professional society. A fully
qualified Software Engineer in the UK would therefore be attributed as:

  Eur.Ing John Doe B.Sc, C.Eng, MBCS     (or similar.)

Others may qualify as Chartered Engineers who do not follow the above route.
They may have become Software Engineers before the terms Computer Science or
Software Engineering existed, or have switched disciplines and previously
qualified in something else. They may have no formal qualifications at all and
have come into the profession through experience alone or they may have
overseas qualifications and experience. These groups of people are admitted
after having their qualifications and experience verified in a similar manner
to other applicants. Their education and training is compared to the standard
curricula. This sometimes involves examination of the students class
transcripts and the details of the course syllabus. In the absence of a
contemporaneous experience and training record a detailed Curriculum Vitae
needs to be validated. This usually involves finding other Engineers who can
act as referees and certify that the actual work experience claimed actually
took place and was of sufficient quality. This is usually done by initialing
copies of the curriculum vitae item by item.

Just to confuse the issue, the UK has a Software Engineering Examination Board
who issue certificates of competence in Software Engineering. These are not
related to the kind of Software Engineer certification we have been discussing.
The SEAB is involved in the training of people in the SSADM method that has
been mandated for use on UK Government work.
 
 Brian Tompsett, Computer Science, Hull University.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Software Protection Tool
</A>
</H3>
<address>
"DAVE ERSTAD" 
&lt;<A HREF="mailto:derstad@cim-vax.honeywell.com">
derstad@cim-vax.honeywell.com
</A>&gt;
</address>
<i>
9 Nov 90 17:06:00 CST
</i><PRE>

In the October 18th issue of Electronic Design News there's a blurb about a new
product which obfuscates source code by changing variable names, removing
comments, etc.  The intent is to allow software to be distributed in source
form while still protecting proprietary knowledge.

The RISKy part is what some people believe (either the company or the reviewer,
I'm not sure which).  The last statement in the article is

"Distribution also ensure that the producer receives virus-free code, because
VIRUSES CANNOT OPERATE IN SOURCE CODE" (emphasis added).

Dave Erstad, Honeywell SSEC           DERSTAD@cim-vax.honeywell.com

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
complaints about Sprint's voice-card system
</A>
</H3>
<address>
Steve Elias 
&lt;<A HREF="mailto:eli@PWS.BULL.COM">
eli@PWS.BULL.COM
</A>&gt;
</address>
<i>
Sat, 10 Nov 90 14:17:36 -0500
</i><PRE>

These complaints about Sprint's voice-card system are a bit silly!
Where do yall get the idea that Sprint insists that one use their SSN
as their ID number?  A friend at US Sprint confirms that their internal
literature makes no mention of forcing people to use their SSN.

Until you get some evidence that Sprint will not allow people to use numbers
other than their SSN, please refrain from flaming!
                                                            /eli

</PRE>
<HR><H3><A NAME="subj7.2">
Sprint's New Calling Card
</A>
</H3>
<address>
Jerry Glomph Black
&lt;<A HREF="mailto:black@ll-null.ll.mit.edu ">
black@ll-null.ll.mit.edu 
</A>&gt;
</address>
<i>
Fri, 9 Nov 90 16:49:14 EST
</i><PRE>

Obviously using the Social Security number as the basis of your FONCARD
security number is pretty dumb.  However, WHO tells Sprint this number?
Presumably YOU, the customer.  So, just feed them a number sequence which has
high mnemonic value for you.  Like maybe your phone number, or a slightly
modified version of same.  I've memorized my 14-digit `random' FONCARD number,
but I use it a lot.  Sometimes it's annoying to dial 11 digits of access
code(1-800-877-8000), then the 11 digits of the destination number, then the
bloody 14-digit number.  My wife refuses to do this, so we got an AT&amp;T card,
where all you have to remember is FOUR DIGITS (tacked on to your 10-digit home
number, which you presumably know).  Anybody know why Sprint didn't just adopt
this method?  Chauvinism?

Even the police-state People's Republic of Massachusetts allows you to specify
a bogus SS No. for your driver's license, instead of your real one, so long as
your bogus no. doesn't duplicate somebody else's license no.  I recently took
out a Hawaii driver's license, and they DEMANDED (over my vociferous objection)
the SS No. or else!  I'm not mega-paranoid, so I complied.  Any Federal privacy
laws involved here?

Jerry Glomph Black, black@MICRO.LL.MIT.EDU

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Carbons (<A HREF="/Risks/10.59.html">RISKS-10.59</A>)
</A>
</H3>
<address>
Douglas W. Jones,201H MLH,3193350740,3193382879
&lt;<A HREF="mailto:jones@pyrite.cs.uiowa.edu ">
jones@pyrite.cs.uiowa.edu 
</A>&gt;
</address>
<i>
9 Nov 90 21:31:15 GMT
</i><PRE>

&gt; I saw that all messages printed on the FAX, are also 'burned' in the carbon
&gt; paper ...  This means that even if I stand next to the machine to receive
&gt; a private message, people can later just open the FAX machine and read the
&gt; message.

This is not a new risk!  For years, typewriters that use a carbon film ribbon
have recorded every word typed on their ribbon.  All you have to do to find out
what was typed on a typewriter is to take out the ribbon cartridge, pull out
the used ribbon and read it.  The more errors and corrections made during tye
typing, the more garbled the ribbon will be.  The risk is at least as old as
the IBM Selectric typewriter, and is well-enough known that it has appeared in
many cheap detective stories.
              					Doug Jones

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Your Flood Stories Please.
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
Lindsay.Marshall@newcastle.ac.uk
</A>&gt;
</address>
<i>
Mon, 12 Nov 90 16:16:05 GMT
</i><PRE>

Can anyone who has suffered a problem at their installation caused by water in
*any* form (or in fact any other liquids....) or who has heard of such events
please send me a summary of your experience.  Information will of course be
treated in confidence if you should so desire.
                                                         Lindsay

MAIL : Lindsay.Marshall@newcastle.ac.uk (UUCP: s/\(.*\)/...!ukc!\1/)
POST : Computing Laboratory, The University, Newcastle upon Tyne, UK NE1 7RU
VOICE: +44-91-222-8267 		FAX: +44-91-222-8232

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Corrected version of Virus Conf announcement (Re: <A HREF="/Risks/10.59.html">RISKS-10.59</A>)
</A>
</H3>
<address>
Gene Spafford 
&lt;<A HREF="mailto:spaf@cs.purdue.edu">
spaf@cs.purdue.edu
</A>&gt;
</address>
<i>
Fri, 09 Nov 90 21:04:16 EST
</i><PRE>

The following address was missing from the announcement of the 
4th Annual Computer Virus &amp; Security Conference, in <A HREF="/Risks/10.59.html">RISKS-10.59</A>:

	Dr. Richard Lefkon
	Virus Conference Program Chair
	609 West 114th Street
	New York, NY 10025
	(212) 663-2315

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.59.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.61.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-34</DOCNO>
<DOCOLDNO>IA013-000136-B030-267</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.61.html 128.240.150.127 19970217040715 text/html 32003
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:05:39 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 61</TITLE>
<LINK REL="Prev" HREF="/Risks/10.60.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.62.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.60.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.62.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 61</H1>
<H2> Friday 16 November 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Police technology; mailing list hyperstacks (Lotus) 
</A>
<DD>
<A HREF="#subj1.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Privacy concerns about Lotus "Marketplace" 
</A>
<DD>
<A HREF="#subj2.1">
Jeff E. Nelson
</A><br>
<A HREF="#subj2.2">
 Rick Noah Zucker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Kuwaiti citizen database 
</A>
<DD>
<A HREF="#subj3.1">
Jonathan Leech
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Gas pump inaccuracies? 
</A>
<DD>
<A HREF="#subj4.1">
Paul Schmidt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
"It's the computer's fault" 
</A>
<DD>
<A HREF="#subj5.1">
Andrew Klossner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Voting electronically from home 
</A>
<DD>
<A HREF="#subj6.1">
Li Gong
</A><br>
<A HREF="#subj6.2">
 Frank Hage
</A><br>
<A HREF="#subj6.3">
 Dan Sandin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: Computer Mishap Forces shift in Election Coverage 
</A>
<DD>
<A HREF="#subj7.1">
Tom Perrine
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Election coverage software 
</A>
<DD>
<A HREF="#subj8.1">
Gary Cattarin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Re: Juicy 911 RISKS 
</A>
<DD>
<A HREF="#subj9.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
Ada Remarks 
</A>
<DD>
<A HREF="#subj10.1">
Paul Murdock
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Police technology; mailing list hyperstacks
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Wed, 14 Nov 90 09:19:28 EDT
</i><PRE>

The Wall Street Journal this week had two articles on privacy and technology
that I thought RISKS readers might find of interest.

On Monday (13-Nov; page A-1) it reports on some new technologies that are
becoming available to the police.  Two are of particular note: Pilotless
surveillance drones developed for the military have been suggested as "just the
thing" for the police.  These are small planes - in techno-speak, they are
UAV's (Unmanned Aerial Vehicles) - that can stay at 500 feet for about an hour.
Currently, they carry cameras with telephoto lenses and infrared sensors; it's
proposed that they could also carry chemical sensors to detect various
chemicals used in drug manufacturing.  None have apparently been used so far -
they are expensive (anywhere from $20,000 to several million a piece) and the
FAA has yet to approve their use.

And for those of you who think that calling from a pay phone is a way to avoid
wiretaps - think again: The "roving bug" can find you.  This is a device that
does pattern matching on phone calls, looking for a particular voice.  At least
one successful prosecution has already been based on evidence obtained by such
a device.  The details aren't clear from the article, but apparently some
15,000 calls were intercepted, more that 5,300 from one person's office and
some 450 from various pay phones.  Just what the technology can do today isn't
clear, but it is clear that very broad-scale monitoring of digitized
conversations, with scanning for voices of interest, is possible if expensive
today and will rapidly become cheaper and easier.  Apparently such wiretaps
were authorized by Congress in 1986.

The article also mentions other devices, like tiny pinhole TV cameras - one was
installed over the urinals at a police station to find a vandal who was
clogging the urinals, causing water to drip down into the chief's office.
(Isn't it great to know what our tax dollars are paying for?)  Also,
LoJack-like devices are becoming much more widespread. (LoJack is a transmitter
installed in your car.  If your car is stolen, you tell the police; they turn
it on and can track the car.)  Smaller scale versions for protecting valuables
exist, and systems that use satellites to allow tracking literally around the
world are in the works.

On Tuesday (14-Nov; page B1) the Journal reports on the controversy surrounding
a product soon to be introduced by Lotus.  Lotus Marketplace consists of a CD
containing information on some 80,000,000 households, including names,
addresses, shopping habits, likely income levels, and even a catagorization (by
Equifax) into one of 50 catagories like "accumulated wealth", "mobile home
families", "cautious young couples", and "inner-city singles".  Also included
is a program - apparently at least partly a Hypercard stack - that provides an
interface to the system.  The whole thing costs $695 for the program and an
initial 5000 names; each additional 5000 names cost $400.  How Lotus keeps you
from using the other information on the CD is unclear - presumably, you sign a
license and they come after you if you breach the terms.

The program Lotus provides does not allow you to look up a particular
individual by name, but of course if you know anything about him you can come
up with a query that will find him and few others - and of course the unethical
will hardly be stopped from developing their own search programs by the terms
of a license agreement.

All of this information has been available for some time from mailing-list
vendors.  However, it's been expensive and "transient".  What Lotus does is
provide the information permanently and cheaply.  Lotus says that to prevent
abuse, they will not include telephone numbers (of course, CD's with telephone
number listings are increasingly available) and will sell only to "legitimate
businesses" at verified addresses checked against a "fraud file".  The license
terms will limit the uses to which the data can be put and provide penalties
for abuses.  It astonishes me that anyone can imagine they can control how a
small piece of plastic, indistinguishable from hundreds of like copies, will be
used once it gets out into the world.

The debate, as presented by the Journal, is on familiar grounds.  Anti: This is
a major invasion of privacy - "They've crossed the line" (Marc Rotenberg,
CPSR).  Pro: There's nothing new here; Lotus is just making a service available
to smaller businesses who couldn't afford it previously.  "What this lets you
do is send a few more pieces of mail.  What's the harm in that?  Lots of people
like to get mail."  (Dan Schimmel, developer of the system.)  You CAN keep your
name off the CD by written request to Lotus, Equifax, or the Direct Marketing
Associations mail preference service.  (It's an interesting question whether
this actually keeps your name off the CD or just marks it as "doesn't wish to
receive mail".  While such a marking would keep legitimate users away from you,
it would do nothing to stop abusers, like those the Journal suggests could look
for "unmarried wealthy women over 65 in this neighborhood".)

The article contains a wonderful cartoon by Mark Stamaty.  The scene: Two
women, one (A) looking at and later opening an envelope.  Prelude: "Every
purchase gets recorded in psycho-data central.  They'll have samples of
everyone's handwriting.  Soon millions of computer-driven autopens will
transcribe junk mail in the handwriting of each person's best friend, spouse or
lover."

A)  I got a letter from *Bill*!
B)  Maybe he wants to get back together.
A)  Think so?
B)  So what's he got to say?  Is he sorry?  Does he want to try again?
A)  He says I'm very special to him and to show me *how* special...
	he's offering me 40% off the newstand rate on a subscription to
	Sports Illiterated!
							-- Jerry

              [With Dreamy Indolence, Lotus Leaves nothing to be desired?  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Privacy concerns about new Lotus "Marketplace" product
</A>
</H3>
<address>
Jeff E. Nelson 
&lt;<A HREF="mailto:jnelson@tle.enet.dec.com">
jnelson@tle.enet.dec.com
</A>&gt;
</address>
<i>
Wed, 14 Nov 90 09:53:47 PST
</i><PRE>

The following is extracted from an unofficial electronic newspaper edited and 
published within Digital for Digital employees. Reproduced with permission. The 
issues raised herein should be familiar to regular RISKS readers.

Jeff E. Nelson           | Digital Equipment Corporation, Nashua, NH, USA
jnelson@tle.enet.dec.com | Affiliation given for identification purposes only

&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;  T h e   V O G O N   N e w s   S e r v i c e  &lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;
 Edition : 2195            Wednesday 14-Nov-1990            Circulation :  8428 

VNS COMPUTER NEWS:                            [Tracy Talcott, VNS Computer Desk]
==================                            [Nashua, NH, USA                 ]

 Lotus - New program spurs fears privacy could be undermined
	{The Wall Street Journal, 13-Nov-90, p. B1}
   Privacy advocates are raising the alarm about a new Lotus product that lists
 names, addresses, shopping habits and likely income levels for some 80 million
 U.S. households. Due for release early next year, Lotus Marketplace packs the
 data on palm-sized compact disks aimed at small and mid-sized businesses that
 want to do inexpensive, targeted direct-mail marketing. But critics say the
 product is just too good. "It's going to change the whole ball game," says
 Mary Culnan, an associate professor at Georgetown University's School of
 Business Administration. "This is a big step toward people completely losing
 control of how, and by whom, personal information is used." Janlori Goldman, a
 staff attorney with the American Civil Liberties Union, adds that the product
 raises "serious legal and ethical questions." Lotus' critics concede that the
 product offers little more than is already available from established
 mailing-list brokers. But they say it is a greater potential threat to personal
 privacy because of its low cost, ease of use and lack of effective safeguards
 over who ultimately has access to it and why. They also say that the way it is
 designed allows users to ask a series of increasingly specific questions about
 small subgroups of people - identifying, for example, unmarried, wealthy
 women over 65 in a neighborhood. "They've crossed the line," says Marc
 Rotenberg, Washington director for the nonprofit Computer Professionals for
 Social Responsibility. "It simply shouldn't be allowed on the market." Lotus
 counters that the product, still under development, has been tailored to
 address privacy concerns. No phone numbers will be included, it won't be
 available in retail stores and it will be sold only to "legitimate businesses"
 at verified addresses checked against a "fraud file," Lotus says. A contract
 will specifically limit its use and provide penalties for abuses. Owners will
 be be allowed unlimited use of the names and addresses they buy, at a cost of
 $695 initially for the program plus 5,000 names and $400 for each additional
 5,000 names.

&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;

    Permission to copy material from this VNS is granted (per DIGITAL PP&amp;P)
    provided that the message header for the issue and credit lines for the
    VNS correspondent and original source are retained in the copy.

&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;   VNS Edition : 2195   Wednesday 14-Nov-1990   &lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;

</PRE>
<HR><H3><A NAME="subj2.2">
all US consumers on CD-ROM
</A>
</H3>
<address>
Rick Noah Zucker
&lt;<A HREF="mailto:noah@cs.washington.edu ">
noah@cs.washington.edu 
</A>&gt;
</address>
<i>
Thu, 15 Nov 90 09:47:13 -0800
</i><PRE>

      This was forwarded to me:  [Discussion of PBS item on Lotus deleted.  PGN]

The database does not contain any of the data covered by the fair credit
practices act so Lotus is under no legal obligation to let you see what they
are saying about you (unless you buy the product, of course...) and has no
provision for allowing you to change what is in there.

The Lotus spokesman said that if people wrote a letter to Lotus saying they did
not want to be in the database, they would be excluded.  Unfortunately, the
interviewer did not say to whom the letter should be addressed.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Kuwaiti citizen database
</A>
</H3>
<address>
Jonathan Leech 
&lt;<A HREF="mailto:leech@cs.unc.edu">
leech@cs.unc.edu
</A>&gt;
</address>
<i>
Thu, 15 Nov 90 10:27:54 -0500
</i><PRE>

	Last night's (11/14) BBC News reported that a computer database
containing fingerprints and other information on all Kuwaiti citizens had
been smuggled out of the country. Apparently the Iraqi government is attempting
to eliminate all evidence of the nation's existence, and this database may be
important in setting things up again (assuming the Iraqis leave).
	Perhaps this may be considered an anti-RISK of government databases?

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Gas pump inaccuracies?
</A>
</H3>
<address>
Paul Schmidt
&lt;<A HREF="mailto:prs@titan.eng.ileaf.com ">
prs@titan.eng.ileaf.com 
</A>&gt;
</address>
<i>
Mon, 12 Nov 90 13:57:11 PST
</i><PRE>

  I have noticed an interesting characteristic that seems
to be shared by all self-serve gas pumps. They all shut
off automatically _shortly_after_ reaching the amount I gave
the attendant, but before reaching the next higher penny. 
(The gallons display continues to advance.) So what algorithm 
is used to determine the shut-off point? The fairest algorithm 
ought to be:
	WHILE delivered_amount &lt;= amount_wanted DO pump_gas

But I seem to be getting $0.005 - $0.01 more gas every time,
because the pump seems to be doing:
	WHILE delivered_amount &lt;= amount_wanted DO pump_gas

Whereas if the gas company wanted to make an average of one-
half cent per transaction:
	WHILE delivered_amount &lt; amount_wanted+0.01 DO pump_gas

Is the public the group beneficiary of about $0.005 per transaction due to what
would otherwise be a bad algorithm?  Did the programmer do this on purpose
because s/he felt Big Oil wasn't paying enough? What implication might this
have on computer controlled delivery of other liquids (insulin?) or gasses
(oxygen?)

Paul Schmidt                                               prs@ileaf.com

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"It's the computer's fault"
</A>
</H3>
<address>
Andrew Klossner 
&lt;<A HREF="mailto:andrew@frip.wv.tek.com">
andrew@frip.wv.tek.com
</A>&gt;
</address>
<i>
Wed, 14 Nov 90 14:20:38 PST
</i><PRE>

My wife and I visited a restaurant in Cannon Beach, Oregon for Sunday
breakfast.  The service was slow, but that's okay, we were sitting down
and had coffee and plenty to read.

A distraught-looking hostess crossed the room to our table and asked me
"Are you a computer expert?"  "Why, yes," I responded.  "Would you
please come fix our computer?"  As we walked to the back room, she
cackled "Try to tell me I'm not psychic ..."

The "computer" turned out to be an electronic cash register, whose
printer ribbon had slipped out of the feed mechanism.  I fixed it and
returned to my table.

Service continued to be very slow -- the family next to us left after
waiting 45 minutes.  To one and all, the hostess proclaimed "We had a
computer problem, but it's fixed now and you'll get your food soon."

But the cash register was used only to print bills when the meal was
over, and had nothing to do with slow food service, which apparently
was caused by an AWOL server.

  -=- Andrew Klossner   (uunet!tektronix!frip.WV.TEK!andrew)    [UUCP]
                        (andrew%frip.wv.tek.com@relay.cs.net)   [ARPA]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Voting electronically from home (revisited)
</A>
</H3>
<address>
Li Gong
&lt;<A HREF="mailto:li@diomedes.UUCP ">
li@diomedes.UUCP 
</A>&gt;
</address>
<i>
Thu, 15 Nov 90 11:58:24 EST
</i><PRE>

John Roe (in RISKS DIGEST 10.60) quoted a report that "A Boulder CO group has
rediscovered Bucky Fuller's 50-year-old suggestion that everyone should be able
to vote telephonically from home or wherever."  and raised a few risks in the
proposed scheme.  He also pointed out that "The current system is NOT based on
honesty: it is based on physical security.  If it is sufficiently hard for the
same person to vote multiple times, voter fraud can be reduced to acceptable
levels (but not eliminated, of course)."

I would like to add that the current system not only provides physical security
of identification, but also physical security against harassment.  Nobody else
is allowed to go into the booth when a voter, say Alice, is voting inside.  On
the one hand, this gives Alice privacy; on the other, she can vote according to
her own will.  Moreover, since this individual vote is among maybe a billion
other votes, no ordinary person could find out for whom Alice has voted.  This
potentially discourage "buying" votes with money or menace, because it is
difficult (if not impossible) to "physically" influence a voter at voting time
and/or to verify a voter's vote afterwards.

In any trivial scheme such as voting with SSN over a phone line, all these good
features disappear.  Professor David Wheeler (my PhD thesis supervisor at
Cambridge) and I once worked on a voting scheme that supports these features
and also allows voting by phone or post.  This effort, together with a
generalization of the idea into a notion of "zero-knowledge transactions", is
still in progress (I hope :-).

Li Gong, ORA Corporation, Ithaca, New York   (607) 277-2020

</PRE>
<HR><H3><A NAME="subj6.2">
Voting by phone risks in error
</A>
</H3>
<address>
Frank Hage
&lt;<A HREF="mailto:fhage@sherlock.rap.ucar.EDU ">
fhage@sherlock.rap.ucar.EDU 
</A>&gt;
</address>
<i>
Thu, 15 Nov 90 14:34:49 MST
</i><PRE>

The risks assumed by John Roe in his note regarding the Boulder,
Colorado demonstration of voting by phone are not valid. The system was
*not* part of the official voting process, but was intended only to
introduce people to the possibility of voting by phone. This fact was
clearly mentioned in the articles the local paper (Boulder Daily
Camera) printed and, in addition, the demonstration ran for three days
prior to, but not on election day. It was emphasized that the votes
cast using the phone based system would not be "real" and that voters
would still have to go to the polls to cast legal votes. The organizers
of the demonstration specifically mentioned that *if* this were an
official voting method, a more secure authentication system would be
necessary. They suggested that a security system similar to the one
currently used for automated teller bank cards might be used.  Each
voter would receive a personal authentication number when registering,
which would have to be entered correctly before the phone vote would be
counted. Several other possible authentication methods were also
mentioned, including "voice prints". Because this was only a
demonstration, and would have no affect on the official vote count,
they used the birth date of the voter, which they obtained from public
voter registration records, as an example of the concept of requiring
voter authentication.

One can easily envision mechanisms where the caller ID feature that many
areas now have in place, could be used to foil attempts by people to
cast large numbers of votes from one phone, even if the authentication
system were compromised. As I see it, the risk of phone voter ballot
stuffing is much smaller than the risk phone the voter's ballot would not
be secret.

	The only risks the demonstration illuminated was the risk of people
making poor judgements about computer technology based on information provided
to them by the popular media.
                                      	-Frank Hage (fhage@rap.ucar.edu)

</PRE>
<HR><H3><A NAME="subj6.3">
Re: Voting electronically from home (revisited)
</A>
</H3>
<address>
Dan Sandin
&lt;<A HREF="mailto:sandin@uicbert.eecs.uic.edu ">
sandin@uicbert.eecs.uic.edu 
</A>&gt;
</address>
<i>
Thu, 15 Nov 90 22:38:55 GMT
</i><PRE>

Although the potential risks of voting by telephone seem great,
I think the potential benefit would far outweigh them.

For example, in the most recent election, I found myself rushing
to the polling place near my home (since you can only vote at
the registered polling place) and arrived too late. If I could have
voted at a location near my work, or by telephone, problem solved.

So, how do we deal with the identification of voters by phone?

How does this sound: before each election, each voter is mailed a 
confirmation of registration (since, I believe, to vote one must be
registered, and to register, one must have a permanent address)
In this confirmation of registration would be a random number, with 
perhaps a checksum or something to discourage forgery, issued on a 
double blind basis. The user would have to punch in the registration 
number, with perhaps a ss#, birthdate, or other identification.
However, leaving this out would encourange secrecy of voting.

For those who cannot handle vote-by-phone, of course, the old
system would be available.

The problems of voter security seem easier than, say, credit card
security. Unlike a credit card, "stealing" a single vote would not be worth
much. This system would also permit simple absentee ballotting...

stephan meyers c/o sandin@uicbert.eecs.uic.edu

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Computer Mishap Forces shift in Election Coverage (<A HREF="/Risks/10.60.html">RISKS-10.60</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:tep@tots.logicon.com">
tep@tots.logicon.com
</A>&gt;
</address>
<i>
Thu, 15 Nov 90 12:58:43 PST
</i><PRE>

&gt;There are some interesting risks.  First that unclean data was used and
&gt;second that the big news agencies now all use the same polling source.  What
&gt;a risk if someone hacked them to create false trends.  [bahn_pr]

All of the major news agencies have been using the same information
base for at least 6 years now. It is called the National Election
Service (NES), and its information is by definition "unclean" and
"hacked to create false trends".

The NES reports any and all information from the official polling sources, but
filters out all references to any candidates other than the Republicans and
Democrats. This filtered (incorrect, incomplete) information is then made
available to all of the news agencies. This filtering is, of course, done by
computers.

There is a rumor that this intentional bias uncovered an interesting
bug/assumption in some display software at one of the southern TV stations: The
display SW "knew" that there would only be info on two candidates, so it
calculated the percentage information for the "second" candidate by subtracting
the poercentage infomation for the first candidate from 100%.  Unfortunately
for the station, the local Libertarian candidate recieved enough votes (at some
point in the voting), that the second candidate was shown to be in the lead
(based on his votes + the votes for the Liberatrian).

Tom Perrine (tep) Logicon Tactical and Training Systems Division San Diego CA
UUCP: sun!suntan!tots!tep  +1 619 455 1330

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Election coverage software
</A>
</H3>
<address>
&lt;<A HREF="mailto:Gary_Cattarin@dg_support.ceo.dg.com">
Gary_Cattarin@dg_support.ceo.dg.com
</A>&gt;
</address>
<i>
Thu, 15 Nov 90 14:07:24 est
</i><PRE>

CEO summary:

Computerized and centralized election coverage poses a bigger risk than the
"unclean data" and program glitches pointed out in RISKS 10.60.  And this one
is unfortunately intentional.  The News Election Service, the central clearing
house for election information, has their systems set up to deliver vote
percentages that show the major party candidates' votes adding up to 100%, even
when the major party candidates don't capture 100% (as they usually don't).  .
In the 1988 presidential election, the public was told that anyone who didn't
vote for George Bush (shudder) voted for Mike Dukakis (bigger shudder).  In
other words, George + Mike = 100%.  That was a lie; in fact George + Mike =
about 99%.  Small, but significant difference.  Same thing happened here in
Massachusetts last week: the third candidate took 2%, but most reports read
"Weld 51%, Silber 49%" (not sure of exact numbers).  Now, they can omit small
guys if they want, but don't lie to the public as if they didn't exist.  The
point here is that a bad policy decision is multiplied by the technology used
to spread lies and mistruths to the general public.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Juicy 911 RISKS (Smaha, <A HREF="/Risks/10.60.html">RISKS-10.60</A>)
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:amos@taux01.nsc.com ">
amos@taux01.nsc.com 
</A>&gt;
</address>
<i>
15 Nov 90 12:50:03 GMT
</i><PRE>

This points out another class of risks: hidden features.  I wouldn't be
surprised if that answering machine contained the full circuitry of a phone,
with the dial-out part disconnected; it is often cheaper to design a machine
around an existing product than to redesign new down-graded part.

Likewise, a "dumb" answering machine may turn out to have undocumented
remote-command capability, a computer terminal may have hidden escape code
functions, etc.  The obvious risk is that people who know about such features,
might use more sophisticated methods than pure tomato juice to make the devices
behave in ways their owners never anticipated nor took precautions too avoid.

Amos Shapir, National Semiconductor (Israel) P.O.B. 3007, Herzlia 46104, Israel
Tel. +972 52 522255  fax: +972-52-558322                       amos@nsc.nsc.com

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Ada Remarks 
</A>
</H3>
<address>
Paul Murdock 
&lt;<A HREF="mailto:murdock@cvax.psi.ch">
murdock@cvax.psi.ch
</A>&gt;
</address>
<i>
13 Nov 90 10:48 +0100
</i><PRE>
 
In response to Chet Laughlin's note about ADA multitasking (10.50) ...
 
&gt;The first lab involved two tasks running in parrellel.  In reality it was
&gt;figured that the tasks would time-slice on a single machine.  However, this was
&gt;not the case.  The compiler would simply run the highest priority task until it
&gt;ended, and then run the lower task. 

My understanding would be that, providing the highest priority task was always
computable (and what is meant by time-slicing here is not exactly clear), then
this behaviour is a valid interpretation of the text of the Ada standard :-

"If two tasks with different priorities are both eligible for execution and
 could sensibly be executed using the same physical processors and the same
 other processing resources, then it cannot be the case that the task with
 the lower priority is executing while the task with the higher priority is
 not."

 [ Par. 9.8:4, VAX Ada Ref Manual
               ("Digital-supplemented text of ANSI/MIL-STD-1815A-1983")]

... and note that my remark comments on the interpretation of the text and
not the text itself.

Chet continues ...

&gt;It was interesting to note that programs that ran correctly on SUNS did not 
&gt;run correctly on the PS/2s - even though they compiled without change.

One of the most painful characteristics of the Ada standard is that although 
"its purpose is to promote the portability of Ada programs to a variety of 
data processing systems" (par 1.1:1) it also "specifies permissible variations
in the effects of consituents of a program unit" (par 1.1.1:16) where "the
operational meaning of the program unit as a whole is understood to be the
range of possible effects that result from all these variations, and a 
conforming implementation is allowed to produce any of these possible effects"
(par 1.1.1:16). So although the portability between the SUNS and the PS/2's
might have been expected (given the AJPO conformance testing procedures), the
assumption that a given program will exhibit identical behaviour across various
platforms cannot be made and is not implied by the standard.

There are, of course, RISKS here.

Paul ...                          (Paul Murdock,
                                   Paul Scherrer Institute,
                                   5234 Villigen. Switzerland.

                                   murdock@cageir5a, murdock@cvax.psi.ch)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.60.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.62.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-35</DOCNO>
<DOCOLDNO>IA013-000136-B030-296</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.62.html 128.240.150.127 19970217040751 text/html 30223
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:05:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 62</TITLE>
<LINK REL="Prev" HREF="/Risks/10.61.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.63.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.61.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.63.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 62</H1>
<H2> Monday 19 November 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Playboy jammer who jammed Hefner's 'jamas gets jammed 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Telephone cable cut eliminates O'Hare tower communications 
</A>
<DD>
<A HREF="#subj2.1">
Richard I. Cook
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Tomatoed 911 
</A>
<DD>
<A HREF="#subj3.1">
Rob Boudrie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Computer-Aided Gerrymandering 
</A>
<DD>
<A HREF="#subj4.1">
Steve Summit
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
GOES mirror problems caused by oversimplified analysis 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Privacy concerns about new Lotus "Marketplace" product 
</A>
<DD>
<A HREF="#subj6.1">
Dan Aronson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
AFCEA's 2nd Annual Military / Government Computing Conf/Exp 
</A>
<DD>
<A HREF="#subj7.1">
Jack Holleran
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
... TONS OF STUFF ON VOTING FROM HOME PENDING ...
</A>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Playboy jammer who jammed Hefner's 'jamas gets jammed
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Mon, 19 Nov 1990 14:47:24 PST
</i><PRE>

Many moons ago there were several up-link spoofings, including Captain Midnight
interrupting HBO to protest signal scrambling.  (See <A HREF="/Risks/2.49.html">RISKS-2.49</A>, <A HREF="/Risks/3.24.html">RISKS-3.24</A>,
SEN 11 3, 11 5.)  As a result of that case, the U.S. Congress passed a law
making satellite hacking a felony.  The first person convicted under that law
is Thomas M. Haynie, an employee of the Christian Broadcasting Network (CBN)
who preempted the Playboy Channel in 1987 with a religious message.  (See
<A HREF="/Risks/5.36.html">RISKS-5.36</A>, SEN 12 4.)  The detective work to identify the culprit used a form
of electronic fingerprinting to identify the character generator as a Knox K50,
of which only five were located in satellite ground stations.  Sentencing is
set for 7 Dec 90, with the max being 11 years in prison and $350,000 in fines.
[Update culled from IEEE The Institute, December 1990, p.6.]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Telephone cable cut eliminates O'Hare tower communications
</A>
</H3>
<address>
&lt;<A HREF="mailto:cook@csel1.eng.ohio-state.edu">
cook@csel1.eng.ohio-state.edu
</A>&gt;
</address>
<i>
Mon, 19 Nov 90 09:58:32 EST
</i><PRE>

&gt;From the New York Times:

             Severed Phone Line Disrupts Chicago Zone

     A contractor planting trees severed a high-capacity telephone
  line in a Chicago suburb yesterday morning, leaving 150,000 people
  without long-distance and most local telephone service and 
  disrupting businesses across a wide area.
     Teller machines at some banks were paralyzed, and flights at 
  O'Hare International Airport were delayed because the air traffic
  control tower there temporarily lost contact with the main Federal
  Aviation Administration air traffic control centers for the 
  Chicago area.  The Illinois Bell Telephone Company said the line was
  accidentally cut at 10:02 AM, Central daylight time, and cautioned
  that full service would not be restored until midnight.
     About half the calls blocked by the severed cable were being
  electronically routed around the break by mid afternoon, said
  Michael E. LeBeau, an Illinois Bell Official.
     People calling telephones with area code 706 in the affected
  towns recevied a "fast, busy signal," said Gloria A. Pope, a 
  spokeswoman for the utility.
     Some flights at O'Hare were delayed by up to two hours but
  safety was not affected, said James A. Dermody, a spokesman for the
  F.A.A.
                 The New York Times (National Edition), Tuesday,
                 16 October 1990, page A14.

Commentary:
   Numerous functions and services in large, complex, systems may be dependent
on apparently distant or unrelated events.  Such large systems intrinsically
have 'latent failures' within them, i.e. failures which are only apparent under
a specific set of (often obscure) triggering conditions [Reason J, Human Error,
Cambridge U. Press, 1990].

   The combination of the contractor digging, the location of the cable, the
signals routed through it, the nature of the use of those signals, the time of
day, and a host of other factors must join in confluence in order to produce
the outcome.  Other large systems failures, including Three Mile Island, the
Vincennes, the Stark, Challenger, and especially Apollo-13, display this same
confluence of (apparently) unlikely events and conditions.  The current state
of understanding of complex system failures [cf.  Rasmussen J, Information
Processing and Human-Machine Interaction: An Approach to Cognitive Engineering.
New York: North-Holand, 1986] and complex system successes [cf. Rochlin GI, et
al., The Self-Designing High-Reliability Organization: Aircraft Carrier Flight
Operations at Sea, Naval War College Review, Autumn, 1987, pp.76-90] is that
failures are virtually never the result of a single fault and that arguments
about the nature of causality which focus on single faults mistake the
intrinsic nature of these systems.  The disasters which arise in complex
systems nearly always have an apparent trigger (e.g. captain's failure to
follow procedures for ship navigation) but the event produces disastrous
consequences only in a particular setting (i.e.  limited navigation tools,
schedule pressures, limited manning levels, faulty communications links, faulty
superveilance) and that removing the possibility of the particular trigger
event does not markedly enhance system safety [for a good example, read the
complete report see Marine Accident Report, Grounding of the U.S. Tankship
Exxon Valdez on Bligh Reef..., NTSB/MAR-90/04, Washington, D.C.: National
Transportation Safety Board, 1990].  Similarly, the recent Hubble telescope
issues are gradually becoming focussed on the nature of the project as a large
system rather than on the single test/single fault approach [Waldrop MM.
Hubble:The Case of the Single Point Failure.  Science 1990, 249: 735-6].
  
   The issues of complex, high-risk/high-reliability system failures arise in
numerous disciplines, almost all of which rely on computers to provide
information to human operators.  Faults and failures of such systems produce
intense pressures to modify the system components in such a way as to forestall
their recurrence.  Unfortunately there is little evidence that these pressures
are effective in increasing overall system safety [Bowman E, Kunreuther H.
Post-Bhopal Behavior at a Chemical Company.  Journal of Management Studies,
1988, 25:4].  Large systems represent such significant investments that they
are difficult to abandon [Ross J, Staw BM. Expo 87: An Escalation Prototype.
Administrative Science Quarterly, 1986, 31:274-297] and it is very difficult to
know that retroengineering has produced a markedly more reliable system.  The
Shuttle may be an example of such a system.  It represents a such a large
component of the space program that scrapping it and starting over is virtually
impossible and there is certainly no guarentee that any new system would not be
equally fragile.  A rare example of abandonment of a large technical system in
favor of another design for primary safety reasons is the new generation of
nuclear power generating systems [Golay MW, Todreas NE. Advanced Light Water
Reactors.  Scientific American, April, 1990], although the technical features
of these 'intrinsically safe' plants are difficult to assess.

   Arguments about whether a computer is 'expert', or 'advising' human
operators are unlikely to produce much useful progress towards developing safer
large systems.  Indeed, these arguments tend to results in polarized
discussions about the roles of technological elements versus the roles of human
operators which are little more than the sort of 'hunt for proximal cause'
which is described above.  The risks of large, computerized system failures are
those which accrue to the system rather than to the components.  It is clear,
however, that pressures during design to meet specific performance, economical,
or political requirements may lead to designs which are destined to operate
near the extremes of the safety envelope.  These pressures, in turn, lead to
systems designed to perform more and more at the edge of the safety envelope
[Andrewa EL. Sensing the Presence of Potential Problems.  New York Times,
Sunday 6 May 1990, p.F6].                                            [Andrews?]

   It is particularly instructive to examine the roles of human operators in
these systems as they are actually practiced by the operators (rather than as
they are defined by rules and procedures, doctine, etc.).  In many, even most,
such systems, the operators are highly skilled individuals who have developed
novel and often quite elegant means for achieving system performance with tools
which are only partially suited to the purpose.  For example, aircraft pilots
modify their environment in a number of ways, including hanging notes on the
consoles with paper clips, using the flight management systems in unorthodox
ways to plan their flight, etc.  Anesthesiologists modify their equipment
configurations to preserve certain, critical features of the data display in
order to maintain specific relationships on the screen [Cook, et al., The
Natural History of Introducing New Information Technology into a High-Risk
Environment.  Proc. of the Human Factors Society 34th Annual Meeting.  Santa
Clara, CA: Human Factors Society, 1990, pp. 429-433].  These adaptations are a
source of information about the nature of operations, system critical
performance areas, etc. and may provide means for improving system feartures in
order to produce more robust systems [Hollnagel E.  The Design of Fault
Tolerant Systems: Prevention is Better Than Cure. 2nd European Meeting on
Cognitive Science Approaches to Process Control, Sienna, Italy, 24-27 October,
1989].  Remarkably, operators usually understand the system performance in ways
which the designers do not, and achieve safe and efficient operation through
various means.

   The loss of telephone connection is a particular kind of fault in a large
system, one which stresses various system elements in various ways.  In this
case, it did not apparently cause any airplane crashes, destroy any bank
records, etc.  But it is particularly instructive to consider what the nature
of the arguments would be if there had been an incident at O'Hare, say the
collision on the ground of a taxiing and landing aircraft, or a near miss
because the handoff to air traffic control was blocked.  In these cases the
communications system would have come under intense scrutiny (much as did the
one in Valdez after the Exxon tanker disaster).  What is fascinating about
computer associated risks, at least to some, is that some components of the
system are resilient and flexible in ways that minimize the effects of
component failures.  Much of this flexibility resides in the human operators of
complex computerized equipment and much of the obstacle to improving safety and
mimizing computer-associated risks depends on the care with which computer
system designers produce devices which meaningfully enhance that flexibility.

                                    Richard I. Cook, M.D.
                          Cognitive Systems Engineering Laboratory
                                 The Ohio State University

   [Don't forget the classical case of logical redundancy compromised by a
   lack of physical redundancy, the ARPANET routing between NY and New England
   via 7 logical circuits, all of which went through the same fiber-optic
   cable, and all of which were cut in one swell foop on 12 Dec 86.  (See
   <A HREF="/Risks/4.30.html">RISKS-4.30</A> and SEN 12 1, January 1987.)  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Tomatoed 911 (<A HREF="/Risks/10.60.html">RISKS-10.60</A>)
</A>
</H3>
<address>
Rob Boudrie 
&lt;<A HREF="mailto:rboudrie@xenna.encore.com">
rboudrie@xenna.encore.com
</A>&gt;
</address>
<i>
Fri, 16 Nov 90 17:48:58 EST
</i><PRE>

A recent posting described an answering machine, without any dial-out
capability, which somehow managed to dial 911 when juice from a decaying tomato
dripped on it.

there was speculation about undocumented "autodial" features in the phone. I
have an alternate explanation:

Although most modern telephones use DTMF (tone) dialing, some older phones use
"pulse dialing", in which the circuit is broken in rapid sequence [In my
younger years, I used to be able to dial any number on a telephone by banging
on the switchhook - I did this just in case the dial broke, not so I could dial
out from phones with locks on the dials :)].  Modern telephone switches
recognize both pulse and DTMF dialing, except where DTMF tones are filtered out
for customers who don't pay a surcharge for DTMF service.

So...It is very possible that the tomato juice was causing some sort of
electrical condition that resulted in the machine rapidly going on and off line
in an intermittent manner.  Although unlikely, it is possible that this
resulted in 9 rapid on/off cycles, followed by two single on/off cycles at a
lower pace.

Rob Boudrie                                         rboudrie@encore.com

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Computer-Aided Gerrymandering
</A>
</H3>
<address>
&lt;<A HREF="mailto:scs@ATHENA.MIT.EDU">
scs@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Sun, 18 Nov 90 14:16:02 -0500
</i><PRE>

Naif that I am, I always thought that gerrymandering was a "bad word," a
practice that no modern thinking person would speak of except to
denounce.  Wrongo.  Under the headline "GOP hopes high tech will give it
edge in redistricting", the Boston Globe (November 18, 1990, page 5)
mentions "how bad the GOP has been at gerrymandering in the past" (i.e.
that they did it ineffectually, not egregiously) but that they "have
learned a lot about redistricting in the intervening nine years."

	"There's no big secret about this; we haven't been very good in
	the last few decades at this redistricting game," [political
	director of the Republican National Committee Norman] Cummings
	said in an interview.  "You'd always like more, of course, but
	we're in much better shape now compared to 10 years ago... and
	the Democrats could be in for a surprise before it's all over."

After discussing the implications of the shifts in party balance due to
the recent elections, the article finally gets to the "high tech" part,
describing how the Republicans "plan legal assaults, assisted by new
computer capabilities."

	This strategy is based mainly on the Civil Rights Act of 1982,
	which mandates that districts with a majority of blacks,
	Hispanics, or other minorities must be drawn wherever possible.

	With that in mind, the GOP has devised software allowing anyone
	with a computer to draw alternative lines and has arranged for
	civil rights groups to obtain it for free.  The intent is for
	minorities, who tend to vote Democratic, to be grouped together,
	leaving more Republicans in adjoining areas.

	"What the Republicans want to do is go in and create one black
	district that will result in weakening three or four Democratic
	districts to make them Republican or at least competitive," said
	Howard Schloss, spokesman for the Democratic Congressional
	Campaign Committee.

Neat trick; use a law which was intended to protect minorities, when
they had less political power, against them now that they have more; and
dangle bait (the software) which will let them do your job for you.
It may be working:

	An initial foray into tinkering with minority districts, partly
	by using the GOP's software, was to be made this weekend in
	Texas by several groups whose function is to get more minorities
	involved in the political process; they include the Southwest
	Voters Project and the Mexican-American Legal Defense Fund.

	Those organizations' work has tended to benefit Democrats in the
	past, but Republican officials hope that is about to change.

	"Both minorities and the Republican Party have been the victims
	of gerrymandering by the Democrats," said Benjamin Ginsberg, the
	Republican National Committee's chief legal counsel, who plans
	to attend the strategy session in San Antonio.  "So this is a
	natural alliance for the redistricting process."

Once again, the underlying RISKs are as old as the hills, but a bit of computer
assist can allow them to be exploited ever-so-much-more-so effectively.

Steve Summit                                                 scs@adam.mit.edu

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
GOES mirror problems caused by oversimplified analysis
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Sun, 18 Nov 90 17:37:52 EST
</i><PRE>

Catching up on my reading, I found a very interesting piece in the Aug 13
issue of Aviation Week &amp; Space Technology.  The next series of GOES weather
satellites are experiencing serious development problems:  the main mirrors
of their imaging systems warp when exposed to extreme temperatures.  (To
head off the inevitable question:  this is *completely* unrelated to the
Hubble telescope's mirror problems.)  To quote:

	The design for the new mirrors was derived from Ford [prime
	contractor] and ITT [instrument subcontractor] experience in
	developing smaller mirrors for the Indian Insat spacecraft.
	A computer model of the mirrors initially used to verify their
	stability showed that they were designed properly.  That model
	was based on 30 data points across the mirrors.

	But during thermal vacuum testing in late 1989, when the
	mirrors were integrated with the sounder and imager telescopes,
	the instruments began to show anomalies... [initially thought
	to be possibly due to other problems].

	ITT engineers were not completely sure what caused the problem,
	however, so they devised a more complex computer model of the
	mirrors that used 1600 data points instead of 30.  The improved
	tests showed that the mirrors had a thermal warpage problem...

This adds to the problems of the new GOES series, which is already far
over budget and two years behind schedule.  The schedule is starting to
look like a major problem, because NOAA is already down to one operational
satellite in orbit, and two are really needed for full coverage of the
Americas.  Originally the first replacement was scheduled for launch this
year, but now even the current target of Feb 1992 is looking optimistic.

Henry Spencer at U of Toronto Zoology      henry@zoo.toronto.edu utzoo!henry

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Privacy concerns about new Lotus "Marketplace" product
</A>
</H3>
<address>
Dan Aronson
&lt;<A HREF="mailto:dan@big-ben.UUCP ">
dan@big-ben.UUCP 
</A>&gt;
</address>
<i>
Fri, 16 Nov 90 11:38:37 PST
</i><PRE>

Lotus claims that if you don't want to be in the database you can write a
letter to:

Lotus Development Corp.
Attn:  Market Name Referral Service
55 Cambridge Parkway
Cambridge, MA 02142

--Dan Aronson, Thinking Machines Corporation

   [Also noted by noah@cs.washington.edu (Rick Noah Zucker)]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 AFCEA's 2nd Annual Military / Government Computing Conf/Exp
</A>
</H3>
<address>
Jack Holleran 
&lt;<A HREF="mailto:Holleran@DOCKMASTER.NCSC.MIL">
Holleran@DOCKMASTER.NCSC.MIL
</A>&gt;
</address>
<i>
Fri, 16 Nov 90 14:16 EST
</i><PRE>

AFCEA's 2nd Annual Military / Government Computing Conference and Exposition
Dates:  February 5-7, 1991
Location:  Hyatt Regency, Crystal City, Arlington, VA

Additional Information:
  The Armed Forces Communications and Electronics Association
  4400 Fair Lakes Court
  Fairfax, Virginia 22033-3899
  (703) 631-6225

Theme:  Information Systems Solutions Today &amp; Tomorrow

Concurrent tutorial sessions will be presented on February 5; Four technical
tracks will be presented on February 6-7.  Technology Advances (February 6);
Information Systems Applications (February 7); Software Development /
Maintainence (February 6-7); and Systems Security Solutions --- Security / 
Privacy, Integrity and Availability (February 6-7).

February 5, 1991
 Concurrent Tutorial Sessions
 Tutorial Co-Chairmen
  Mr. Larry Walker, Director,
   Command Control and Planning, CONTEL Federal Systems
  LTC Calvin Hastie, USA
   Office of the Director of Information Systems C4
    Headquarters, Department of the Army, Army Management Division

I   Open Systems Architecture
    Improving the Software Process
     Mr. J. Mogilensky, Director of the SW Process Enhancement Program,
     CONTEL Federal Systems
    MLS-A Critical Technology
     Col. Bill Freestoner, USA, Program Manager
     Defense Communications Agency

II  Expert Systems in Artificial Intelligence
    Imaging / Graphics
    Personal Authentication Via Biometrics

III Evolutionary Systems Acquisition
     D. Shore, Technical Director, AFCEA
     Dr. S. Starr, The MITRE Corporation
     Dr. S. Albert, Vice President and Chief Scientist,
      Institute for Systems Analysis
    Information Engineering
     Mr. J. Weyland, Senior Associate, Booz, Allen &amp; Hamilton, Inc.
      

Technology Advances  (February 6, 1991)
 Track Co-Chairmen:
  Dr. Paul Oliver, Vice President, Booz, Allen &amp; Hamilton, Inc.
  Mr. John Carabello, Dean, Information Resources Management College,
   National Defense University

* Artificial Intelligence and Expert Systems
   Moderator:
   Dr. Larry Medsker, Chairman, Computer Science and Information Systems,
    American University

* Imaging and Graphic Systems
   Moderator:
   Dr. Alan Salisbury, President, CONTEL Technology Center

* Information Engineering
   Moderator:
   Mr. Jon Whalen, Senior Associate, Booz, Allen &amp; Hamilton, Inc.


Information Systems Application  (February 7, 1991)
 Track Co-Chairmen
  BGen J. Ronald Carey, USAR
   Program Manager, Reserve Component Automation System,
   National Guard Bureau
  Mr. Thomas L. Hewitt, President
   Federal Sources, Inc.

* Panel:  Managing Large Systems
   BGen. John F. Phillips, USAF, Commander
    Logistics Management Systems, Air Force Logistics Command
    Wright-Patterson AFB
   Mr. Edward G. Lewis, Assistant Secretary
    Information Resources Management, Department of Veteran Affairs
   Mr. Frank DeGeorge, Inspector General,
    Department of Commerce
   Mr. Robert Cook, Chief Executive Officer
    The Systems Center

* Wrap-up of the 101st Congress and Expectations for the 102nd Congress
  on Issues and Legislation Effecting Information Technology Application
   Presenter:
   Mr. Steven Ryan, Attorney, Former General Counsel for Senator
     John Glenn's Government Affairs Committee

* A Success Story of How USAA Achieved a Paperless Office with
  Information Technology
  Presenter: 
  MGen. Donal Lasher, USA (Ret.), Senior Vice President,
   USAA Insurance Company

* A Successful Turnaround in a Major Government Application
  Presenter:
  Mr. Thomas P. Giammo, Assistant Commisioner for Information Systems,
   U.S. Patent &amp; Trademark Office, Department of Commerce

* The United States Postal Service in 1995
  Presenter:
  Dr. Bernard J. Bennington, Director of Communications and Technology,
   U.S. Postal Service 


Software Development / Maintenance (February 6-7, 1991)
 Track Co-Chairmen:
  Mr. Anthony M. Valetta, Program Executive Officer
   Standard Army Management Information Systems, Department of the Army
  Mr. John Turner, Associate Administrator, National Aerospace
   System Development, Federal Aviation Administration

* Maintaining Quality in the Software Development
  Presenter:   Mr. James Emery, Professor of Decision Sciences,
                Wharton School of Business

* Grand Design vs Evolutionary Development / Acquisition

* Panel:  Prototyping
   Moderator:  Dr. Michael F. McGrath, Director of CALS Office, 
                  Office of the Assistant Secretary of Defense

* Panel:  Managing the Corporate Information Management (CIM) Life Cycle
   Moderator:  Mr. John Gioia, President, Robbins-Gioia, Inc.

* Panel:  Modernization / Uptrade / Re-engineering
   Moderator:  Dr. Paul Oliver, Vice President, Booz, Allen &amp; Hamilton
   Panelists:  Mr. Phil Kiviat, Vice President, Chartways Technology
               Mr. George Baird, Senior Associate, Booz, Allen &amp; Hamilton
               Mr. Roger Kerchaw, Program Director, 
                       Educational Testing Services

* Panel:  Maintainability
   Modeator:  Mr. John Caron, Assistant Commissioner, Office of
               Technical Assistance, General Services Administration

* Panel:  Software Re-Use
   Moderator:  Mr. Mitchell J. Bassman, Senior Scientist, Special
                Projects Division, Computer Sciences Corporation

* Panel:  Ada
   Moderator:  Dr. Clay Stewart, Associate Director, C3I Center
                George Mason University
   Panelists:  Dr. Win Royce, TRW
               Mr. Paul Mauro, Hughes


Systems Security Solutions Security / Privacy, Integrity and Availability
   (February 6-7, 1991)
 Track Co-Chairmen:
  Mr. Patrick Gallagher, Director
   National Computer Security Center, National Security Agency
  Mr. James H. Burrows, Director of National Computer Systems Laboratory
   National Institute of Standards and Technology

* Panel:  Computer Security Applications Experiences:  National Security
   Moderator:  Mr. Patrick Gallagher, Director, National Computer
                    Security Center, National Security Agency


* Panel:  Computer Security Applications Experiences:  Civilian / Commercial
   Moderator:  Mr. James H. Burrows, Director of National Computer
     Systems Laboratory, National Institute of Standards and Technology

* Panel:  Computer Security Procurement Experiences
   Moderator:  Ms. Barbara Guttman, Computer Specialist,
               National Institute of Standards and Technology
   Panelists:  Mr. Hal Tipton, Director and Past President, 
               Information Systems Security Association (ISSA), Inc.

* Panel:  Voice / Data Security Applications
   Moderator:  Mr. Ray Fitzgerald, Central Intelligence Agency  
                Chairman:  STS/SISS Joint STU-III Working Group

* Panel:  Network Security --- Applications
   Moderator:  Mr. Curt Barker, Senior COMSEC Analyst,
                Trusted Information Systems, Inc.

* Panel:  Protection Against Malicious Software
   Moderator:  Mr. Dennis Steinauer, Manager of Computer Security
                Management and Evaluation, National Institute of
                Standards and Technology

* Panel:  Where are We Going?
   Moderator:  Mr. Steve Walker, President
                Trusted Information Systems, Inc.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.61.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.63.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-36</DOCNO>
<DOCOLDNO>IA013-000136-B030-321</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.63.html 128.240.150.127 19970217040810 text/html 16325
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:06:40 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 63</TITLE>
<LINK REL="Prev" HREF="/Risks/10.62.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.64.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.62.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.64.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 63</H1>
<H2> Wednesday 21 November 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Lotus Marketplace cont'd 
</A>
<DD>
<A HREF="#subj1.1">
Marc Rotenberg
</A><br>
<A HREF="#subj1.2">
 Eric Dittman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Insurance Perfidy 
</A>
<DD>
<A HREF="#subj2.1">
Sharon Cregier
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
[anonymous] author identifies anonymous referee 
</A>
<DD>
<A HREF="#subj3.1">
anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Reuters Holdings PLC and shouldering the blame?  
</A>
<DD>
<A HREF="#subj4.1">
Sameer Mithal
</A><br>
<A HREF="#subj4.2">
 PGN abstracting
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
MD-11 test flights over the pole 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Soc.Sec.No. on Driver's Lic. in Mass. 
</A>
<DD>
<A HREF="#subj6.1">
William Ricker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Tomatoed 911 
</A>
<DD>
<A HREF="#subj7.1">
Tim Steele
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Lotus Marketplace cont'd
</A>
</H3>
<address>
&lt;<A HREF="mailto:mrotenberg@cdp.uucp">
mrotenberg@cdp.uucp
</A>&gt;
</address>
<i>
Mon, 19 Nov 90 22:20:17 -0800
</i><PRE>

	I think Lotus got off easy in the Wall Street Journal story (11/14/90,
B1).  The reporter did not pursue the interesting and novel privacy issues with
the Marketplace product.  For example, the "opt-out" approach will probably not
work with a list published on CD-ROM.  How does a person remove a name once the
product is available? Also, once the data is in digital form isn't matching
against other databases, such as phone directories, more likely?
Traditionally, mailing lists were exchanged in paper formats and available only
for one-time use.

	These are a few of the reasons that I disagreed with the comment in
RISKS 10.61 that the privacy debate is on familiar grounds. This is the first
time that a company has prepared to sell a large consumer database on CD-ROM.
This raises new privacy issues and new risks that should be evaluated before
the product is sold.

	Another interesting point about the Marketplace product -- no
restrictions on previewing sets.  You are charged when you print labels, but
not when you view sets on the screen.  The product also allows piping to other
application programs.

	And here's the interesting risks problem: Lotus has said that the
encryption scheme will prevent individual record access.  Brute-force searching
will almost certainly work since there are no charges for previewing a list,
but it's slow for searches on multiple record subjects. So, what is the
likelihood that someone will break the encryption scheme?

Marc Rotenberg, CPSR Washington office.

</PRE>
<HR><H3><A NAME="subj1.2">
Lotus MarketPlace brochure
</A>
</H3>
<address>
Eric Dittman
&lt;<A HREF="mailto:dittman@skbat.csc.ti.com ">
dittman@skbat.csc.ti.com 
</A>&gt;
</address>
<i>
Tue, 20 Nov 90 17:56:15 -0600
</i><PRE>

I received a brochure on Lotus MarketPlace the other day in the mail.
Nowhere in the brochure is there mention of any limit to the distribution
of the database.  According to what I have read in the brochure, both
MarketPlace:Business and MarketPlace:Households will be available at
dealers, so anyone should be able to buy MarketPlace.

Eric Dittman, Texas Instruments - Component Test Facility

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Insurance Perfidy [forwarded]
</A>
</H3>
<address>
&lt;<A HREF="mailto:34AEJ7D@CMUVM.BITNET">
34AEJ7D@CMUVM.BITNET
</A>&gt;
</address>
<i>
Tue, 20 Nov 90 09:11:01 -0800
</i><PRE>

Written by: CREGIER@UPEI.CA (Sharon Cregier)
[Reprinted with permisson -- see copyright notice at end of article]

Computer records, even erroneous ones, allow insurance companies to
discriminate against applicants and clients.  The following is a copy of an
article in the August 1, 1990 issue of the Christian Science Monitor (Boston)
article, FROM DATABASE TO BLACKLIST, section heading: Insurance risks targeted.

Perhaps one of the most mysterious consumer-reporting companies is MIB,
formerly the Medical Information Bureau, in Brookline, Mass.  "It's a very
difficult company to learn very much about," says Massachusetts state senator
Lois Pines.  "They don't want people to know that they exist or what they do."

"The purpose of MIB is to help keep the cost of insurance down for insurance
companies and for consumers by preventing losses that would occur due to fraud
or omissions," says MIB's president, Neil Day.  MIB's files are used by more
than 750 insurance companies throughout the United States and Canada.

MIB stores its records in a specially coded format, which the company refuses
to share with regulators, legislators, or consumer groups.  There are codes for
medical conditions and mental health, as well as nonmedical conditions like
"hazardous sport participation" and "hazardous driving records."

In the past, says Robert Ellis Smith, editor of the Privacy Journal, other MIB
codes have stood for "sexual deviance" and "sloppy appearance."  Mr Day refuses
to release a list of the current codes used by his company, saying that to do
so would compromise his firm's confidentiality.

Although MIB will tell a person if he or she has medical records on file, it
will send those records only to a medical professional.  The company receives
15,000 requests by individuals to have their report sent to their physician
every year, says Day.  Between 250 and 300 people argue with their reports.

A person applying for life insurance enjoys none of the privacy rights and
protections that a person applying for credit does, says Josh Kratka, an
attorney with the Massachusetts Public Interest Research Group (MASSPIRG).

"MIB has agreed to abide by [the FCRA].  They will send those codes to your
physician.  Your insurance company is not under those obligations....If you are
denied life insurance, you have no way of knowing whether it was legitimate or
based on an error in your records that is going to follow you around for the
rest of your life," says Mr Kratka.

In one case, says Kratka, a Mass. man told his insurance company that he had
been an alcoholic but had managed to remain sober for several years and
regularly attended Alcoholics Anonymous meetings.  The insurance company denied
him coverage and forwarded a code to MIB: "alcohol abuse; dangerous to health."

The next company the man applied to for insurance, Kratka says, learned of the
"alcohol abuse" through the information bureau and charged the man a 25% higher
rate.

In another case he says, a clerical error caused a woman's records at MIB to
say that she carried the AIDS virus.  "It was only after unusual intervention
by the state regulatory board," because the woman worked for a physician, that
the records were corrected, Kratka says.  MASSPIRG has filed state legislation
that would extend many of the FCRA's protections to medical records.

As health-care costs continue to rise, say experts, consumers can expect less
and less privacy regarding their medical records.

"Doctors, in order to get paid, are being asked more and more to identify a
chargeable condition in their clients....The breach in confidentiality is a
natural consequence of the way in which third party billing of physician's time
is structured in this country," says Dr Paul Billings, chief of genetic
medicine at the Pacific Presbyterian Medical Center in San Francisco.

No federal law ensures the confidentiality of medical records.  Some hospitals,
Mr Smith says, have even started using them for target marketing.

Reprinted with permission from the Christian Science Monitor
Copyright 1990 by the Christian Science Publishing Society, All rights reserved

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
[anonymous] author identifies anonymous referee
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
20 Nov 90
</i><PRE>

I'm not sure if this is a technology-based risk or a process-based one.

Recently, I had a paper rejected from a technical conference.  As usual, the
committee returned to me the reviewers' comments with the identifying header
removed.  However, they neglected to remove the small line of type placed at
the head of the page by the reviewer's fax machine.  This machine kindly gave
me the reviewer's place of employment (down to the building and department
names) and fax number.  Better than caller ID, since I can correlate that with
the (small and public) list of reviewers for this conference and arrive at the
reviewer's name.

We can see this as a technology-based risk in that the reviewer didn't know
that his identifying information was going to be publicized.  Or we can see
it as a process-based risk in that no one involved remembered to remove the
identifying line (and that the reviewer was in a sufficient hurry that he
used the fax rather than another transport medium).

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Reuters Holdings PLC and shouldering the blame?  [Abstracted by PGN]
</A>
</H3>
<address>
Sameer Mithal
&lt;<A HREF="mailto:<mithal@aimt.enet.dec.com>  ">
&lt;mithal@aimt.enet.dec.com&gt;  
</A>&gt;
</address>
<i>
Wed, 21 Nov 90 07:12:23 PST
</i><PRE>

An article entitled ``Who takes the blame when trades short-circuit?'' in the
Wall Street Journal, 20-Nov-90, p. C1, discusses the problem the general
problem of how to resolve liability questions in case transactions are messed
up by computer-related screwups.  In particular, pending resolution of the
liability issue, Reuters Holding PLC has announced an indefinite delay in the
development of Dealing 2000-2, a network of systems for foreign-exchange
trading.  Clearly Reuters would like to limit their risks.  The article is not
overly informative, but does sound the English horns of the dilemma.   [PGN]

</PRE>
<HR><H3><A NAME="subj4.2">
MD-11 test flights over the pole
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Sun, 18 Nov 90 23:05:09 EST
</i><PRE>

Interesting item in the 22 August issue of Flight International: the prototype
of McDonnell-Douglas's new MD-11 airliner (a DC-10 derivative) made a test
flight partly aimed at testing performance of navigation software in the
vicinity of the North Pole, making four passes directly over the pole and one
nearby.  On two of the pole passes, the flight-management computers were
deliberately "failed" to see if the backup equipment would function.  No
problems, they say.

(This is not as trivial as it sounds, because the vicinity of the poles is a
severe worst case for navigation algorithms.  The distance between degrees of
longitude goes to zero while latitude remains unaffected, trig functions are
pushed to extrema of their behavior, and there is a singularity in the
coordinate system at the pole itself.)
                                         Henry Spencer at U of Toronto Zoology

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Soc.Sec.No. on Driver's Lic. (was Re: Sprint's New Calling Card)
</A>
</H3>
<address>
William Ricker
&lt;<A HREF="mailto:wdr@wang.com ">
wdr@wang.com 
</A>&gt;
</address>
<i>
Mon, 19 Nov 90 20:23:54 EST
</i><PRE>

Jerry Glomph Black, black@MICRO.LL.MIT.EDU writes:
&gt;Even the police-state People's Republic of Massachusetts allows you to specify
&gt;a bogus SS No. for your driver's license, instead of your real one, so long as
&gt;your bogus no. doesn't duplicate somebody else's license no.

Bad news -- the Mass. Registry of Motor Vehicles now requires that their
computer contain your SSN as well as your bogus number.  I requested and was
given a "S-number", an 8-digit number with an S prefix, as my drivers license
number years ago. but on my most recent birthday -- election day, this month --
I was informed that to renew, I must supply my SSN in confidence to the
computer, but not to worry, it wouldn't be printed on my license.  Yes ma'am,
it is your computer that I don't want to have it.

I protested ... and was informed by Registry's legal department that Mass. Law
overrides any federal law, and if I didn't want to comply, I didn't have to
renew my license to drive, did I?

The Mass chapter of the ACLU has informed me that the Mass. RVM has the right 
to demand this number from me.  I must call them back and get the chapter
and verse on that; I would like to see a full opinion.

One angry camper,

/bill ricker/      wdr@wang.com a/k/a wricker@northeastern.edu


</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Tomatoed 911 (Boudrie <A HREF="/Risks/10.62.html">RISKS-10.62</A>, re: <A HREF="/Risks/10.60.html">RISKS-10.60</A>)
</A>
</H3>
<address>
Tim Steele 
&lt;<A HREF="mailto:tjfs@tadtec.uucp">
tjfs@tadtec.uucp
</A>&gt;
</address>
<i>
Tue, 20 Nov 90 17:52:00 GMT
</i><PRE>

[...] My best guess at What Really Happened is:

The answering machine does in fact have a built in phone (otherwise why would
it be able to dial?)

The phone probably has a memory button programed to dial 911.

The tomato juice probably dripped on to the button and 'shorted' it out (the
dialler chip is probably expecting a rubber membrane keyboard and will accept a
fairly high resistance as a valid key press.

Tim

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.62.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.64.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-37</DOCNO>
<DOCOLDNO>IA013-000136-B030-341</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.64.html 128.240.150.127 19970217040853 text/html 25411
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:06:52 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 64</TITLE>
<LINK REL="Prev" HREF="/Risks/10.63.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.65.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.63.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.65.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 64</H1>
<H2> Wednesday 21 November 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
 Re: Voting from home electronically 
</A>
<DD>
<A HREF="#subj1.1">
Alan Jeffrey
</A><br>
<A HREF="#subj1.2">
 Steve Bellovin
</A><br>
<A HREF="#subj1.3">
 Brad    Templeton
</A><br>
<A HREF="#subj1.4">
 Henry Spencer
</A><br>
<A HREF="#subj1.5">
 Peter da Silva
</A><br>
<A HREF="#subj1.6">
 P.J. Karafiol
</A><br>
<A HREF="#subj1.7">
 Barbara Simons
</A><br>
<A HREF="#subj1.8">
    Joseph R. Beckenbach
</A><br>
<A HREF="#subj1.9">
 Alan Marcum
</A><br>
<A HREF="#subj1.10">
 K.M. Sandberg
</A><br>
<A HREF="#subj1.11">
 Chris Maltby
</A><br>
<A HREF="#subj1.12">
 R. Simkin
</A><br>
<A HREF="#subj1.13">
    Flint Pellett
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
 Re: Election coverage software 
</A>
<DD>
<A HREF="#subj2.1">
Gregory G. Woodbury
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Voting from home electronically (revisited)
</A>
</H3>
<address>
Alan Jeffrey 
&lt;<A HREF="mailto:jeffrey@cs.chalmers.se">
jeffrey@cs.chalmers.se
</A>&gt;
</address>
<i>
Sat, 17 Nov 90 12:56:52 +0100
</i><PRE>

There is an additional risk associated with voting from home, not mentioned by
any of the posters.  By making it easier for people with phones to vote, you
are helping to disenfranchise those who can't afford phones.  I don't know
about the US, but in the UK telephone voting would (perhaps significantly)
boost the results of the ABC1 / over 35 / Conservative vote, with resultant
damage to the Labour party.

If we're going to claim to live in representative democracies, we're going to
have to make the technology for voting equally available to all.

Alan Jeffrey            031 721098            jeffrey@cs.chalmers.se
Computer Science Department, Chalmers University, Gothenburg, Sweden

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Voting electronically from home (revisited)
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@ulysses.att.com">
smb@ulysses.att.com
</A>&gt;
</address>
<i>
Fri, 16 Nov 90 13:40:30 EST
</i><PRE>

	 From: li@diomedes.UUCP (Li Gong) ...
	 I would like to add that the current system not only provides
	 physical security of identification, but also physical
	 security against harassment.  Nobody else is allowed to go
	 into the booth when a voter, say Alice, is voting inside.

You overassume.  In *theory* no one else is allowed to go inside the voting
booth (subject to a few exceptions for illiterate or handicapped voters, btw);
practice is something else entirely.  I still recall my astonishment the first
time I witnessed the quaint local voting customs in Durham, North Carolina.  A
husband and a wife would enter the booth together, and cast a vote; the wife
would then exit, and the husband would vote (again?).

Then, of course, there's Chicago, a town that gives entirely new meaning to the
phrase ``voting machine''....  But I digress.
                                 	               --Steve Bellovin

</PRE>
<HR><H3><A NAME="subj1.3">
Becoming over-sensitive to risks (vote by phone)
</A>
</H3>
<address>
Brad Templeton
&lt;<A HREF="mailto:brad@looking.on.ca ">
brad@looking.on.ca 
</A>&gt;
</address>
<i>
Sun, 18 Nov 90 3:19:13 EST
</i><PRE>

While I appreciate people's concern over the sanctity of the vote,
consider what is used now.

I don't know about the U.S., but in Canada there's almost no security on
voting.  They come round to your house every election, and ask for the names of
every elector.  No ID is asked for.  You could name your children or pets and
they would get on the voters list.  (It's no doubt a crime of some sort to do
this, of course.)

Likewise all you have to do is go to the poll, and give the name of any person
who hasn't voted yet (normally yourself.)  As long as it isn't a small poll,
you could easily use any other name.  (The lists are posted on telephone polls
so people can check they're on.)  If you have good eyes and can read upside
down, you can even look at the RO's name sheet when you walk in.

Sounds ripe for fraud, but it just never happens.  When a seat is hotly
contested or close, the party scrutineers watch things closely, in addition
to the elections officials.  I have never heard of any accusations of abuse.

While using SSNs or other publicly available info isn't a good idea, I would
have no opposition to well designed phone voting -- particularly in an area
with ANI.  There are RISKS, but as long as we watch for them, they are no
greater than those of the current system.  The greatest RISK is not watching
for RISKS because we trust the computer too much.

On the other hand, there are other problems with phone voting -- the
largest being the elimination of the secret ballot.  The voting computer
will know who voted for whom.  We must trust the programmers and their
auditors to assure us the information is erased and never stored.
(On the other hand, doing this disallows one great method of verifying
phone voting, namely a mailed ACK.)

Brad Templeton, ClariNet Communications Corp. -- Waterloo, Ontario 519/884-7473

</PRE>
<HR><H3><A NAME="subj1.4">
Re: Voting electronically from home (revisited)
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Sat, 17 Nov 90 19:19:12 EST
</i><PRE>

&gt;... in the most recent election, I found myself rushing
&gt;to the polling place near my home... and arrived too late. If I could have
&gt;voted at a location near my work, or by telephone, problem solved.

There are several simple non-technological fixes for this, notably the one
followed in a number of other countries:  hold elections on Sundays, when
most people have at least part of the day free.

                         Henry Spencer at U of Toronto Zoology    utzoo!henry

   [An eminently reasonable suggestion, although we have drifted away from the
   computer relevance -- except that you have found a very simple nontechnical
   solution to the problem.  PGN]

</PRE>
<HR><H3><A NAME="subj1.5">
Voting by phone
</A>
</H3>
<address>
silva 
&lt;<A HREF="mailto:peter@ficc.ferranti.com">
peter@ficc.ferranti.com
</A>&gt;
</address>
<i>
Sat Nov 17 08:42:17 1990
</i><PRE>

&gt; [use Caller-ID to] foil attempts by people to cast large numbers of votes
&gt; from one phone, even if the authentication system were compromised.

This would tend to disenfranchise people in poor neighborhoods where there
may only be a single public phone to serve an entire apartment block.

Also, it would be desirable to have the call to the election service be free
in areas with measured service or from a pay phone. And of course the dangers
of COCOTs (private pay phones) would be increased.

Another contributer noted:

&gt; For example, in the most recent election, I found myself rushing
&gt; to the polling place near my home (since you can only vote at
&gt; the registered polling place) and arrived too late. If I could have
&gt; voted at a location near my work, or by telephone, problem solved.

A simpler and less dangerous solution would be to allow you to vote at
any polling place, and have some form of real-time communication between
the polling places to prevent fraud.

Another negative effect I could imagine would be that this would enable
proxy voting: "You're a good Republican, and you just want to vote the
straight party ticket.
"Call 1-800-VOTE-GOP" or "1-800-VOTE-DEM" and have your election ID number
at hand...

Peter da Silva.      +1 713 274 5180.       peter@ferranti.com 

</PRE>
<HR><H3><A NAME="subj1.6">
Voting by phone
</A>
</H3>
<address>
P.J. Karafiol
&lt;<A HREF="mailto:karafiol@husc8.harvard.edu ">
karafiol@husc8.harvard.edu 
</A>&gt;
</address>
<i>
Sun, 18 Nov 90 23:34:53 -0400
</i><PRE>

With all this talk about vote *fraud* I'm surprised no one mentioned a
serious, actual *infringement* on one's constitutional rights.  If voting
is done by phone, what happens to people who don't have one, either because
of location (yes, there are places in the continental US without regular
phone service, although all the ones I know of are reachable through some
kind of radio-phone system) or finances or personal choice?  Although poor
or phone-phobic people could conceivably use a public phone (the number
would presumably be toll-free) it still seems unfair to people who are in
category 1.  Questions, comments, discussion?

Caveat:  I didn't read the original (non-electronic) article on voting by
phone.  This concern may be addressed in that article.
							== pj karafiol

</PRE>
<HR><H3><A NAME="subj1.7">
Voting from home (Re: <A HREF="/Risks/10.61.html">RISKS-10.61</A>)
</A>
</H3>
<address>
Barbara Simons 
&lt;<A HREF="mailto:simons@IBM.com">
simons@IBM.com
</A>&gt;
</address>
<i>
Sun, 18 Nov 90 22:59:34 PST
</i><PRE>

In discussing voting electronically from home,
Li Gong says (in RISKS DIGEST 10.61):

I would like to add that the current system not only provides physical security
of identification, but also physical security against harassment.  Nobody else
is allowed to go into the booth when a voter, say Alice, is voting inside.  On
the one hand, this gives Alice privacy; on the other, she can vote according to
her own will.  Moreover, since this individual vote is among maybe a billion
other votes, no ordinary person could find out for whom Alice has voted.  This
potentially discourage "buying" votes with money or menace, because it is
difficult (if not impossible) to "physically" influence a voter at voting time
and/or to verify a voter's vote afterwards.


He then goes on to mention that he and his former advisor had been
working on a zero-knowledge method for voting.
This is an interesting idea, but it assumes an outsider who wishes to
know about or influence Alice's vote.  Suppose, however, that her
husband has decided how he wants Alice to vote.  In most states,
he would not be allowed into the voting booth while she voted.
But he could easily watch her as she votes electronically at home.

The risk in this situation is that an obvious form of intimidation
has not been taken into account.

I said that in most states he would not be allowed into the voting
booth while she voted.  I recall hearing about some Southern
state in which a husband and wife are (were?) allowed into the voting
booth together.  Apparently, the theory was that the husband
would vote for them both.  Unfortunately, I don't recall the
state nor whether this unhappy situation still exists.

Barbara

</PRE>
<HR><H3><A NAME="subj1.8">
Re: Voting electronically from home (revisited)
</A>
</H3>
<address>
Joseph R. Beckenbach
&lt;<A HREF="mailto:jerbil@tybalt.caltech.edu ">
jerbil@tybalt.caltech.edu 
</A>&gt;
</address>
<i>
Mon, 19 Nov 90 20:37:29 GMT
</i><PRE>

	Why am I still under the impression that this "vote-by-phone"
is a technical solution to a nontechnical problem?  True, a "vote-by-phone"
system would be useful for hospital patients and shut-ins of many sorts,
but absentee ballots were made for this, were they not?

	Why not simply declare Election Day a national holiday?  We celebrate
the Fourth of July in the USA because it reminds us of past efforts to keep
freedom.  Why not one to remind us of our duty to safeguard current freedoms?
	When I form a company, I intend on making Election Day a half-day or
full-day holiday with pay, with proof of vote.  Or some other scheme which
penalizes for not voting if the person is eligible.  [I'd rather not
reward for performance of a duty, but if such is necessary, I will.]

		Joseph Beckenbach

</PRE>
<HR><H3><A NAME="subj1.9">
Re: Voting electronically from home
</A>
</H3>
<address>
&lt;<A HREF="mailto:Alan_Marcum@NeXT.COM">
Alan_Marcum@NeXT.COM
</A>&gt;
</address>
<i>
Tue, 20 Nov 90 17:05:49 PST
</i><PRE>

Imagine how much havoc a vote-by-phone system would wreak on dear
Ma Bell out here in California, the Land of the Ballot Proposition.
Millions of hour-long telephone calls as citizens try to register
their votes on the dozens (yes, literally) of propositions.

"We're sorry, your call did not go through.  All voting circuits
are busy now.  Please try again tomorrow..."

Alan M. Marcum                          NeXT Technical Support
Alan_Marcum@NeXT.COM                    +1-415-363-5153

</PRE>
<HR><H3><A NAME="subj1.10">
Voting (Re: <A HREF="/Risks/10.61.html">RISKS-10.61</A>)
</A>
</H3>
<address>
K. M. Sandberg
&lt;<A HREF="mailto:sandberg@ipla01.hac.com ">
sandberg@ipla01.hac.com 
</A>&gt;
</address>
<i>
19 Nov 90 00:27:25 GMT
</i><PRE>

In regards to voting, it was mentioned that current voting is based on physical
security, but at least where I vote all I do is bring in the little booklet and
sign the book and I get to vote, no check of who I really am. If I had multiple
booklets I could vote several times, but since I must go to one place to vote
and sign in I could not vote multiple times based on my own name.

In another response it was said that having the phone system would help voting
since the person said that they missed getting to the poles, but absentee
ballots solve this if it is a normal problem.  The risk of influencing the
votes because of the current privacy, unless the absentee ballot is used, is
important. Other solutions would be to send the ballot, like the absentee
ballots, and allow people to drop them off, but this still has the risk of lack
of privacy. Personally it would be nice if you could vote at a common place,
possibly before election day, with the same privacy and security, maybe at your
local post office or at a pre-selected place to prevent multiple voting. Too
bad we can't trust people.

In this last risk posting, it mentioned that people could enter in their votes
for practice only so that they would get used to it, but a question that comes
up was this information used BEFORE the end of election day? If it was it could
have affected voting, as does the exit polls, east coast results before the
west coast polls close, etc.
							Kemasa.

</PRE>
<HR><H3><A NAME="subj1.11">
Re: Election coverage software
</A>
</H3>
<address>
Chris Maltby
&lt;<A HREF="mailto:chris@softway.sw.oz.au ">
chris@softway.sw.oz.au 
</A>&gt;
</address>
<i>
Wed, 21 Nov 90 14:00:24 EST
</i><PRE>

&gt;The News Election Service, the central clearing house for election 
&gt;information, has their systems set up to deliver vote percentages that
&gt;show the major party candidates' votes adding up to 100%, even when 
&gt;the major party candidates don't capture 100% (as they usually don't).

I was certainly intrigued by this and other things as I watched the election
coverage in Boston. Having worked on the software for the Australian Electoral
Commission for the last federal election (March 1990) there I was surprised by
the (parochialism speaks) poor standard of the reporting.

First, the results of counting seemed to be very slow to arrive, leaving the
commentators to talk about nothing for long periods. Some districts still had
only 1% of precinct reporting at 11pm. In the Australian election, at least 80%
of the vote had been counted by 11pm.

Second, there seemed to be no analysis of swings and only minimal discussion of
trends in early vs. late figures. The commentators were predicting a win for
Weld although he trailed for most of the night. The information they based the
prediction on was not produced.

Given that the first-past-the-post system is significantly easier to count than
the preferential system in use in Australia, there seems to be little possible
excuse for the delay/inaccuracy of the result reporting.

To put things in perspective however, and to reveal the "risk" for this
posting, the Australian experience was not without problems. For the first time
the Electoral Commission attempted to make predictions based on preliminary
results from individual polling booths. That is, when figures for a booth came
in they were compared with previous figures from the same booth to yeild a
"swing" percentage. This swing would then be propagated over the booths for
which no result was yet known. This was expected to be able to give very
accurate predictions. The magic quantity is dubbed the "two-party-preferred"
vote.

The unknown factor turned out to be the unusually high vote for minor parties
and independents, with an even more unusual preference distribution pattern.
The preference system allows voters to protest their favourite major party's
policy/candidate but direct their second preference to that party ahead of the
other major party. This option was exercised in much higher numbers than ever
before, and especially among Labor voters. The commission's system made some
rather simple assumptions about minor party preferences.

As a result, for most of the night, the prediction was a landslide for the
Liberals based on an apparent swing above 10%. The actual result was a solid
win for Labor of 8 seats (as predicted by count scrutineers).  In two
electorates independents were able to beat one major party into second place
and win the seat on preference votes.

A better system for preference sampling is being implemented for the
next election...

Chris Maltby - Softway Pty Ltd	(chris@softway.sw.oz.au)
PHONE:	+61-2-698-2322		UUCP: uunet!softway.sw.oz.au!chris

</PRE>
<HR><H3><A NAME="subj1.12">
Voter registration isn't always pre-registration
</A>
</H3>
<address>
&lt;<A HREF="mailto:rsimkin@dlogics.UUCP">
rsimkin@dlogics.UUCP
</A>&gt;
</address>
<i>
Mon Nov 19 09:31:07 1990
</i><PRE>

In Risks 10.61 "Re: Voting electronically from home (revisited)",
Stephan Meyers says:

&gt; How does this sound: before each election, each voter is mailed a 
&gt; confirmation of registration (since, I believe, to vote one must be
&gt; registered, and to register, one must have a permanent address)

This assumes that registration must be completed well in advance of election
day, which isn't always the case.  In the name of making the voting process
more accessible, Wisconsin law used to (and may still) allow voters to register
at the polling place on election day.  As a result many people would arrive at
the poll with proof of residence, register, and then vote.
                                                            --Rick Simkin

</PRE>
<HR><H3><A NAME="subj1.13">
Re: Voting electronically from home (revisited)
</A>
</H3>
<address>
Flint Pellett
&lt;<A HREF="mailto:flint@gistdev.gist.com ">
flint@gistdev.gist.com 
</A>&gt;
</address>
<i>
19 Nov 90 22:49:15 GMT
</i><PRE>

li@diomedes.UUCP (Li Gong) writes:

&gt;I would like to add that the current system not only provides physical security
&gt;of identification, but also physical security against harassment.

This is what I think the biggest risk of vote-by-phone is: Al Capone decides he
wants to be mayor, and has his flunkies each call 100 kindly little old ladies
in the month before the election, telling them "Come to my house to cast your
vote or I'll ..." and then, the flunkies watch the little old ladies punch
their votes into the telephone, and make sure they vote the "right" way.  

Anyone care to enlighten us on what types of security measure are planned to
deal with this type of problem?  Merely being able to recognize that you are
recording a vote from the proper person is not sufficient.  Any scheme with
authentication numbers suffers from the fact that it will never be any more
secure than the way in which those numbers are communicated to the voter, and
the way in which the voter remembers them.  (If you have to mail the numbers to
the voter, then that mail can fall into the wrong hands.  If the voter has to
write it down in order to remember it, which is quite likely for most people
given that they use it once every 6 months or less, it is also at risk.)

Flint Pellett, Global Information Systems Technology, Inc. 1800 Woodfield
Drive, Savoy, IL 61874                 (217) 352-1165 uunet!gistdev!flint 

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Election coverage software
</A>
</H3>
<address>
Gregory G. Woodbury
&lt;<A HREF="mailto:ggw%wolves@cs.duke.edu ">
ggw%wolves@cs.duke.edu 
</A>&gt;
</address>
<i>
Mon, 19 Nov 90 17:52:18 GMT
</i><PRE>

Here in Durham NC, we had a rather interesing election :-)
It seems that nearly half of the voting machines in the county went
haywire and would not work correctly on election day!  This happened
early and we had a court ruling that the polls stay open to 10pm and
that paper ballots be made available in all precincts to those who
wanted them.

In my precinct (I am an assistant election official) only two of our 6
mahcines had problems and we (hopefully) caught them as soon as they
occurred.  Even so, our audit numbers were off by 4 at the end of the
night.  The particulars of the election seem to be that in the county
commissioners races, for the first time in xxx years (maybe the first
time ever) we had an INDEPENDENT candidate, not in conjunction with an
independent running for president.  The machines are set up so that one
can "split ticket" by pulling the straight party lever and then deselect
one candidate and select another.  The problem for all the machines that
I have been able to get exact information on seems to be that people
tried to split ticket and forgot to deselect a candidate before
selecting someone in the other parties lines.  This jammed the levers in
the county commissioners section and rendered the machine unuseable.

Considering that most voters do NOT understand the ways that machines
work, it happened in some precincts that the jammed machines where used
until someone complained or noticed the jam.  This is the RISK.  People
assumed that the technology would behave correctly.  When something did
go wrong, they ignored the errors cause they didn't know any better.  In
this city, however, we have a high ratio of advanced degrees (MS,PhD,etc)
in the population in certain precincts, and even there, the problems 
occurred.

On a side note:  when the judge ordered the use of paper ballots AND
staying open til 10pm, he made it IMPOSSIBLE for Durham results to be
known before 2am!  The precincts are set up to deal with a small number
of paper ballots (for disabled voters unable to enter the polling
location but coming near by in a car - "curbside voters"), but extending
these paper ballots to anyone who wanted to use them placed an
unexpected load on the pricint officials when the polls closed!  I had
volunteered monday evening to count paper ballots (before the judge's
order) and instead of 25 or so ballots, we had nearly a hundred!  That
was so much FUN! *HA!*

By the time we finised counting and had the helms/gantt figures for NES it was
3am and they had the time to ask why we were the first precinct from Durham NC
to call in "official" results.  -- Gregory G. Woodbury

Durham NC UUCP: ...dukcds!wolves!ggw ...mcnc!wolves!ggw ggw%wolves@mcnc.mcnc.org 

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.63.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.65.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-38</DOCNO>
<DOCOLDNO>IA013-000136-B030-374</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.65.html 128.240.150.127 19970217040908 text/html 24095
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:07:37 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 65</TITLE>
<LINK REL="Prev" HREF="/Risks/10.64.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.66.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.64.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.66.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 65</H1>
<H2> Monday 6 December 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A fondness for turkeys 
</A>
<DD>
<A HREF="#subj1.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Heads-up "Holograms" of Runways to assist in landings? 
</A>
<DD>
<A HREF="#subj2.1">
Richard Wood
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Airline safety 
</A>
<DD>
<A HREF="#subj3.1">
John Sullivan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
As the spacecraft turn 
</A>
<DD>
<A HREF="#subj4.1">
Steve Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
NeXT microphone problem? 
</A>
<DD>
<A HREF="#subj5.1">
E. Loren Buhle
</A><br>
<A HREF="#subj5.2">
 Jr.
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Risks of global networking 
</A>
<DD>
<A HREF="#subj6.1">
Hank Nussbacher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Technological Risk, by H.W. Lewis 
</A>
<DD>
<A HREF="#subj7.1">
Jake Livni
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Hackers Accessed NASA's Phones 
</A>
<DD>
<A HREF="#subj8.1">
anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Hacker view of the "Legion of Doom" sentencing in Atlanta 
</A>
<DD>
<A HREF="#subj9.1">
Emmanuel Goldstein
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A fondness for turkeys              [No Thanksgiving for bad systems?]
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Sun, 2 Dec 90 09:14:27 PST
</i><PRE>

Sitting up late one night last week, I caught the re-broadcast in the UK of the
US news program "60 minutes".

One of the items was about ADATS, a tank-based anti-helicopter missile system, 
meant to be effective in conditions of poor visibility (e.g., Iraqi sandstorms),
and reckoned to be essential against such things as the HIND killer-chopper 
(of which Iraq is rumoured to have 40 or so). It is, or rather was, being 
developed by Oerliken of Switzerland. However, they have pulled out, and (I 
think) the completion of the system is now directly managed by the DoD.
This follows cancellations by several potential customers: Germany, Holland,
Saudi Arabia, etc. Only the US and Canada still seem to be interested.

It is strongly supported by some military people, e.g., General Granrod (? - 
Sorry, there were no subtitles, so I wasn't able to get the correct name of
everyone interviewed, and I have no idea what any of the acronyms stand for.), 
who said it had exceeded its requirements in field trials. Convincing film was 
shown of it shooting a parked helicopter off the top of a tower, and then 
firing a missile in a corkscrew spiral ending in the nearest bit of shrubbery.

A strong feeling of deja vue then descended, as it turned out that this system
is (you've guessed it!) highly computerised.

There seem to have been a few unfortunate hitches in its development:-

Originally estimated at $7 billion, its cost has now reached $12 billion and 
is rising fast. Protests from parts of Congress on behalf of the US taxpayer 
are the main reason for its current notoriety.

It is late. Certainly too late for the gulf. After having been under 
development for years, it is still at least 5 years from delivery.

Its requirements seem, err..., less than adequately related to the real world.
It uses laser to track its target. This is not a bright idea for an all-weather
system. "You don't see through clouds with a laser.", one commentator said. 
"You don't even see into them very far!" The missile tracks the laser beam.
Once off the beam, there is no way it can get back on (a possible explanation 
for the impressive exercise in hedge-trimming). The chopper pilot knows (in
something as sophisticated as the HIND) that he is being scanned, and has 30
seconds to do something about it, like dodge behind the nearest hill, which is
a fairly effective protection against a line-of-sight system like ADATS. There 
is also the minor problem that the computer system can't tell friend from foe.

Reliability is a problem. Although the producers of the programme didn't seem
to have a very clear idea of the difference between reliability, 
maintainability, and availability, a number of people made statements to the 
effect that the availability of the system is 40%. The system is thought to be 
so complex that its reliability may never reach an acceptable level.
"Pilots are cautious people." remarked one interviewee. "If they find they're 
under attack from something like ADATS, they'll simply go away and come back 
when the system isn't working."

Why does this situation arise so often in modern weapons system development?

- There is a school of thought which believes that complex electronic systems 
  are, or can be made, the answer to everything in modern warfare.

- Military careers are made on the backs of projects like ADATS. For those 
  involved, there is no advantage in cancellation, even if it doesn't work.
  To get the troops something they can use is at most the third priority.
  (Senator Chuck Bernard).

Why is the US military persisting with ADATS?

As the senator said: "In this country, we seem to like turkeys!"

Peter Mellor, Centre for Software Reliability, City University, Northampton Sq.,
London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Heads-up "Holograms" of Runways to assist in landings?
</A>
</H3>
<address>
&lt;<A HREF="mailto:rwood@vajra.pa.dec.com">
rwood@vajra.pa.dec.com
</A>&gt;
</address>
<i>
Thu, 29 Nov 90 17:39:03 PST
</i><PRE>

Summarized from: {Business Week Nov 19, 1990}

    Seattle's fog is legendary, but from now on it will not delay as
    many flights as it has in the past. Seattle-Tacoma International
    Airport is the first to win approval for takeoffs guided by new
    technology that lets a pilot see in thick fog. Developed by
    Flight Dynamics Inc., Portland OR, the system is similar to the
    heads-up display in jet fighters. A transparent screen flips down
    inside the windshield, and holographic images of the runway's
    center line and horizon are projected onto it. Thanks to special
    optical tricks, the images appear to be in front of the plane,
    where the real runway is. Alaska Airlines has been using the
    system for landings for the past year, but until now, the Federal
    Aviation Administration would not allow its use for takeoffs if
    visibility dropped below 600 feet.

Richard Wood     Corporate Worksystems Team      Digital Equipment Corp.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Airline safety
</A>
</H3>
<address>
&lt;<A HREF="mailto:sullivan@poincare.geom.umn.edu">
sullivan@poincare.geom.umn.edu
</A>&gt;
</address>
<i>
Tue, 4 Dec 90 11:36:13 CST
</i><PRE>

This week's Economist has an article about airline safety, reminding us
(as the Northwest crash yesterday did) that two-thirds of all accidents
happen in the 5% of a flight around take-off and landing.

    Although three-quarters of accidents are blamed on
    pilots' errors, pilots can be "set up" for an accident by many
    things, such as confusing instructions from air-traffic
    controllers or by picking the wrong switch in a badly designed cockpit.

The article focuses on four recommendations from Boeing for increased safety.
None of them relates specifically to computer risks, though they all seem
related to the safety and privacy concerns we have often discussed in RISKS.

1.  Pilots should calculate before takeoff a "decision speed" at which
takeoff can continue even with engine loss (rather than aborting and
possibly going off the end of the runway).  Such accidents are rare,
but in 2/3 of the cases, the pilot is found later to have made the
wrong decision.

2.  Install new Ground Proximity Warning Systems (GPWS):

    Early GPWS systems can be unreliable and are prone to giving false
    alarms. ... this means they eventually get ignored--or disconnected.
    Pilots can easily turn them off in the cockpit.

3.  Install more ILS (Instrument Landing Systems) at airports.
This would encourage fewer "nonstabilised" approaches at high speed.

4.  Make more use of flight-data recorder (black box) info, which could be
"highly valuable for training".  This "final suggestion is controversial"
although already used by some airlines in Europe.  The Economist closes:

    [T]here is opposition from some pilots and their unions.
    They reckon that the recorders--which also make a tape of
    flight-deck conversations--could become a "spy" in the cockpit.
    Passengers might think that a good idea.


John Sullivan

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
As the spacecraft turn
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@ulysses.att.com">
smb@ulysses.att.com
</A>&gt;
</address>
<i>
Wed, 05 Dec 90 11:09:41 EST
</i><PRE>

This doesn't appear to be a very good week for computers in space...  I'll let
others tell the myriad stories about what's going on with the space shuttle's
telescopes, but a lot of the problems appear to be computer-related.  For
example, one attempt to fix some star tracker problems involved patching some
software, because the tracker was more sensitive than thought.  Unfortunately,
the patch was loaded into the wrong computer.

On another (orbital) plane, Magellan lost several mapping orbits worth of data
because of a data entry error.  It seems that the commands downloaded
(uploaded?) didn't have the required blank delimiters; consequently, the
orbiter correctly rejected the entire sequence.
                                        		--Steve Bellovin

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
NeXT microphone problem?
</A>
</H3>
<address>
"E. Loren Buhle, Jr. [215-662-3084]" 
&lt;<A HREF="mailto:BUHLE@xrt.upenn.edu">
BUHLE@xrt.upenn.edu
</A>&gt;
</address>
<i>
Tue, 27 Nov 90 12:56 EDT
</i><PRE>

THIS MESSAGE DEALS WITH A POSSIBLE "RISK" PERTAINING TO CONTROL OF THE INTEGRAL
MICROPHONE IN THE LATEST NeXT MACHINE.

FIRST, SOME DESCRIPTION:

The newest NeXT machine has a microphone in the lower left portion of the CRT 
console (embedded in the plastic frame of the CRT). This integral microphone is 
an important input device for the voice annotation software running on the
NeXT. It comes with all new NeXT machines. The software interface on the NeXT
presents the user with keys corresponding to a tape recorder (e.g. record,
stop, rewind, play, etc.). The user hits the record button, speaks for any
length of time, hits stop, rewind, play and hears the conversation that was 
recorded to a disk file (and played back) . . . . very nice touch! 

The operating system on the NeXT machine is Mach UNIX, a multiuser environment.
NOTHING APPEARS TO PREVENT REMOTE OPERATION OF THE MICROPHONE. There is NO
INDICATION ON THE FRONT OF THE NeXT MACHINE THAT THE MICROPHONE IS LIVE OR
DEAD! (Remember Ronald Reagan's problems with "supposedly dead" microphones?)

Here is a scenario: A remote user turns on the microphone on the NeXT,
recording the voice to a file (locally or remotely). Any sound in the proximity
of the NeXT CRT is recorded. This file containing the conversation is then
played back on a remote NeXT. Voila, a built-in office bug! While it can be 
argued that control of the microphone is by the console, anyone with superuser 
privs can undoubtable find a workaround.

On the old (1988 vintage) NeXT box, the microphone was plugged into a jack on 
the back. Unplugging the microphone removed this problem. Cumbersome, but very 
effective. The new microphone is built into the CRT case. It is not trivial to 
detach/attach at will.

So what can be done? One possibility would be to have a physical LED turn on 
whenever the microphone was active. This LED would be physically wired to the 
microphone and NOT be under program control. This possibility assumes the 
people carrying on the conversation are looking at the NeXT console. . . .

Thoughts?

Dr. E. Loren Buhle, Jr.  INTERNET: BUHLE@XRT.UPENN.EDU
University of Pennsylvania School of Medicine         Phone: 215-662-3084
Rm 440A, 3401 Walnut St., Philadelphia, PA 19104-6228   FAX: 215-349-5978

</PRE>
<HR><H3><A NAME="subj5.2">
     Risks of global networking
</A>
</H3>
<address>
Hank Nussbacher 
&lt;<A HREF="mailto:HANK@BARILVM.BITNET">
HANK@BARILVM.BITNET
</A>&gt;
</address>
<i>
Wed, 28 Nov 90 09:45:05 O
</i><PRE>

Over the past few months I have noticed upon occasion files that appear in our
system that arrive from a fellow Bitnet system named NCCIBM1.  The files always
remain in the RSCS print queue since they are destined for the system printer.
I always purged them, since there was never any indication that they were
intended for any user on our system - BARILVM (Bar-Ilan University in Israel).

This past week I decided to track down the people at NCCIBM1 and find out why
we are getting their job outputs.  NCCIBM1 (USA Environmental Protection Agency
in North Carolina) determined that their JES system has BARILVM listed as node
#178.  They also have a remote printer listed as #178.  Rather than typing R178
for her output JCL, the user made a mistake and typed N178 - which sent the
output to Israel rather to some printer in North Carolina.

Is this a risk of computer networking?  I bet over the past year there has been
a very irate user in North Carolina trying to find her job outputs.  All she
had to do was hop on a plane and fly a few thousand miles to find her MVS
output. :-)

Hank Nussbacher, Computer Center, Bar Ilan University

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Book Review -   Technological Risk   by H. W. Lewis
</A>
</H3>
<address>
Jake Livni 
&lt;<A HREF="mailto:jake@bony1.bony.com">
jake@bony1.bony.com
</A>&gt;
</address>
<i>
Wed, 28 Nov 90 21:39:35 EST
</i><PRE>

In the Sunday New York Times book review section (Nov. 25, 1990), there was a
review of:

  Technological Risk
  by H. W. Lewis
  353 pp. New York
  W. W. Norton &amp; Company.  $22.95

According to the reviewer, it seems to be an interesting and surprising view of
risks in technology.  The author, "a physicist at UCSB", shows that many
technological risks are overshadowed by similar natural risks and that concern
over technological disasters may be overdone.

I haven't seen this book, so I'm just notifying you about the article / review.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
``Hackers Accessed NASA's Phones''
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
Thu, 6 Dec 1990
</i><PRE>

Today's AP wire, datelined HOUSTON, and reported in the Houston Chronicle,
noted that computer intruders have stolen some $12 million in free telephone
service through Johnson Space Center...  That figure was calculated from costs
of similar break-ins described by law enforcement agents specializing in
computer crime.  A long-distance credit card number was used, as well as NASA's
phone lines.  The credit card fraud was discovered by AT&amp;T when use of the
number exceeded typical patterns.  An earlier report, on 17 Nov 90, noted that
phone service worth millions had been similarly obtained from the Houston
offices of the Drug Enforcement Administration.  Both cases involved intrusions
to the Federal Telephone System, which apparently has little or no
accountability.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Hacker view of the "Legion of Doom" sentencing in Atlanta
</A>
</H3>
<address>
Emmanuel Goldstein
&lt;<A HREF="mailto:emmanuel@well.UUCP ">
emmanuel@well.UUCP 
</A>&gt;
</address>
<i>
Fri, 30 Nov 90 01:00:21 pst
</i><PRE>

The following is from the forthcoming Autumn 1990 edition of 2600, The Hacker
Quarterly. We would appreciate it being distributed to as many interested
people as possible. We consider this to be a very major and very frightening
issue. If there are any questions or comments, we can be reached at
2600@well.sf.ca.us or (516) 751-2600.

Emmanuel Goldstein, Editor, 2600 Magazine

 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

Over the past year there has been a great deal of publicity concerning the
actions of computer hackers. Since we began publishing in 1984 we've pointed
out cases of hackers being unfairly prosecuted and victimized. We wish we could
say things were getting better but we cannot. Events of recent months have made
it painfully clear that the authorities, above all else, want to "send a
message". That message of course being that hacking is not good. And there
seems to be no limit as to how far they will go to send that message.

And so we come to the latest chapter in this saga: the sentencing of three
hackers in Atlanta, Georgia on November 16. The three, Robert Riggs (The
Prophet), Frank Darden, Jr. (The Leftist), and Adam Grant (The Urville) were
members of the Legion of Doom, one of the country's leading hacker "groups".
Members of LOD were spread all over the world but there was no real
organization, just a desire to learn and share information. Hardly a gang of
terrorists, as the authorities set out to prove.

The three Atlanta hackers had pleaded guilty to various charges of hacking,
particularly concerning SBDN (the Southern Bell Data Network, operated by
BellSouth). Supposedly Riggs had accessed SBDN and sent the now famous 911
document to Craig Neidorf for publication in PHRACK. Earlier this year,
BellSouth valued the document at nearly $80,000. However, during Neidorf's
trial, it was revealed that the document was really worth $13. That was enough
to convince the government to drop the case.

But Riggs, Darden, and Grant had already pleaded guilty to accessing
BellSouth's computer. Even though the facts in the Neidorf case showed the
world how absurd BellSouth's accusations were, the "Atlanta Three" were
sentenced as if every word had been true. Which explains why each of them
received substantial prison time, 21 months for Riggs, 14 months for the
others. We're told they could have gotten even more.

This kind of a sentence sends a message all right. The message is that the
legal system has no idea how to handle computer hacking. Here we have a
case where some curious people logged into a phone company's computer
system. No cases of damage to the system were ever attributed to them. They
shared information which we now know was practically worthless. And they
never profited in any way, except to gain knowledge. Yet they are being
treated as if they were guilty of rape or manslaughter. Why is this?

In addition to going to prison, the three must pay $233,000 in restitution.
Again, it's a complete mystery as to how this staggering figure was arrived at.
BellSouth claimed that approximate figure in "stolen logins/passwords" which we
have a great deal of trouble understanding. Nobody can tell us exactly what
that means. And there's more. BellSouth claims to have spent $1.5 million
tracking down these individuals. That's right, one and a half million dollars
for the phone company to trace three people! And then they had to go and spend
$3 million in additional security. Perhaps if they had sprung for security in
the first place, this would never have happened.  But, of course, then they
would have never gotten to send the message to all the hackers and potential
hackers out there.

We think it's time concerned people sent a message of their own. Three young
people are going to prison because a large company left its doors wide open and
doesn't want to take any responsibility. That in itself is a criminal act.

We've always believed that if people cause damage or create a nuisance, they
should pay the price. In fact, the LOD believed this too. So do most hackers.
And so does the legal system. By blowing things way out of proportion because
computers were involved, the government is telling us they really don't know
what's going on or how to handle it. And that is a scary situation.

If the media had been on top of this story and had been able to grasp its
meaning, things might have been very different indeed. And if BellSouth's gross
exaggerations had been taken into account at the sentencing, this injustice
couldn't have occurred. Consider this: if Riggs' sentence were as much of an
exaggeration as BellSouth's stated value of their $13 document, he would be
able to serve it in full in just over two hours. And the $233,000 in
restitution would be under $40. So how much damage are we really talking about?
Don't look to BellSouth for answers.

In early 1991, the three are to begin their sentences. Before that happens, we
need to reach as many people as possible with this message. We don't know if it
will make a difference in this particular case if the general public,
government officials, and the media hear this side of the story.  But we do
know it would be criminal not to try.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.64.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.66.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-39</DOCNO>
<DOCOLDNO>IA013-000136-B030-401</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.66.html 128.240.150.127 19970217040919 text/html 25351
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:07:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 66</TITLE>
<LINK REL="Prev" HREF="/Risks/10.65.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.67.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.65.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.67.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 66</H1>
<H2> Friday 7 December 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
COMPUTERS AT RISK: Safe Computing in the Information Age 
</A>
<DD>
<A HREF="#subj1.1">
Marjory Blumenthal
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
COMPUTERS UNDER ATTACK 
</A>
<DD>
<A HREF="#subj2.1">
Peter Denning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: ``Hackers Accessed NASA's Phones'' 
</A>
<DD>
<A HREF="#subj3.1">
Jerry Hollombe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Responses to article on "Legion of Doom" sentencing 
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  
</A>
<DD>
<A HREF="#subj5.1">
Gary Cattarin
</A><br>
<A HREF="#subj5.2">
 King Ables
</A><br>
<A HREF="#subj5.3">
 Brinton Cooper
</A><br>
<A HREF="#subj5.4">
 Mark E. Levy
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
COMPUTERS AT RISK: Safe Computing in the Information Age
</A>
</H3>
<address>
Marjory Blumenthal 
&lt;<A HREF="mailto:MBLUMENT@NAS.BITNET">
MBLUMENT@NAS.BITNET
</A>&gt;
</address>
<i>
Fri, 07 Dec 90 10:02:00 EDT
</i><PRE>

COMPUTERS AT RISK: Safe Computing in the Information Age
National Research Council, System Security Study Committee

Computers play a crucial role in virtually every facet of modern life in the
United States, from transportation safety to business and banking transactions
to health care.  Yet as computer systems become more prevalent, sophisticated
and interconnected, society becomes more vulnerable to poor system design,
accidents that disable systems, and computer viruses and other attacks on
computer systems.  The result may be economic disaster, threats to human life,
and compromise of confidential information held in computer databases.
Increased use of computer networks, as well as a general rise in computer
literacy, make it likely that the nation's computer security problems are just
beginning.  Computers at Risk, a new report from the Computer Science and
Telecommunications Board of the National Research Council, presents a
comprehensive agenda for developing nationwide policies and practices for
computer security. Specific recommendations are provided for industry and for
government agencies engaged in computer security activities.  The
recommendations are fully developed and wide ranging, addressing the roles of
specific agencies, expansion of current programs, cooperation between
government and industry, and more.  The volume outlines problems and
opportunities in computer security research, recommends ways to improve the
research infrastructure, and suggests topics for investigators.  Computer
system vulnerabilities are analyzed, and government security efforts are
evaluated.  Business executives, government security specialists, hardware and
software developers, system managers, researchers, educators, and computer
users will find this book vital to their understanding of computer security
issues.

CONTENTS:

Executive Summary

Overview and Recommendations: Computer System Security Concerns, Trends, The
Need to Respond, Toward a Planned Approach, Nature of Security, Putting the
Need for Secrecy into Perspective, Building on Existing Foundations,
Recommendations

Concepts of Information Security: Security Policies, Management Controls, Risks
and Vulnerabilities, Securing the Whole System

Technology to Achieve Secure Computer Systems: Specification vs.
Implementation, Models, Services, Trusted Computing Base, Communications

Programming Methodology: Programming Languages, Specifications, Formal
Specification and Verification, Hazard Analysis, Development Process,
Procurement, Scheduling, Education and Training, Management Concerns, What
Makes Secure Software Different, Recommended Approaches

Criteria to Evaluate Computer and Network Security: Security Evaluation
Criteria, Assurance Evaluation, Trade-offs in Grouping of Criteria, Comparing
National Criteria Sets, Reciprocity, System Certification vs. Product
Evaluation

Why the Security Market Has Not Worked Well: The Market for Trustworthy
Systems, Concerns of Vendors, Federal Government Influence, Export Controls,
Consumer Awareness, Regulation

The Need to Establish an Information Security Foundation: Attributes and
Functions, Other Organizations, Charter and Startup Considerations, History of
Government Involvement, Security Practitioners

Research Topics and Funding: A Proposed Agenda, Directions for Funding Security
Research

Bibliography, Appendixes, Glossary

ISBN 0-309-04388-3; 1990, 320 pages, 6 x 9, paperbound, $19.95

Please send me _____ copy(ies) of Computers at Risk: Safe
Computing in the Information Age.

I have enclosed a check for $_______.  Please bill my _____
MasterCard   _____ VISA   _____ American Express account.

    #__________________________________________   Expires _________________

    Signature__________________________________   Phone number ____________

Name ______________________________

Address ______________________________

City___________________________ State ______ Zip Code ______________
                                                      COUNTRY if not USA________
Quantity Discounts: 5-24 copies 15%, 25+ copies 25%

Return this form with your payment to NATIONAL ACADEMY PRESS, 2101 Constitution
Avenue, NW, Washington, DC 20418.  To order by phone using
VISA/MasterCard/American Express, call toll-free 1-800-624-6242, Monday-Friday,
8:30-5:00 EST. Call (202) 334-3313 in the Washington metropolitan area.  Price
applies only in the U.S., Canada, and Mexico and may be changed without notice.

   [I have received so many requests for this information yesterday and today
   that it seemed useful to include it in RISKS forthwith.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computers Under Attack
</A>
</H3>
<address>
Peter Denning 
&lt;<A HREF="mailto:pjd@riacs.edu">
pjd@riacs.edu
</A>&gt;
</address>
<i>
Thu, 6 Dec 90 15:00:32 PST
</i><PRE>

   COMPUTERS UNDER ATTACK
   Intruders, Worms, and Viruses
   Edited by Peter J. Denning
   ACM Press and Addison-Wesley, 1990, 554pp
   $18.50 ACM members, $20.50 others

On behalf of ACM Press and the authors of the 38 articles brought together in
this edition, I am proud to announce that our book on the subject of attacks on
computers is now available.

This subject continues to receive ongoing attention in the national press --
for example, the recent discovery of $12M of toll fraud at the NASA Johnson
Space Center, Operation Sun Devil, an Esquire article about computer pirates
breaking in to the Bell System, and the recent splashy appearance of the NRC
report, "Computers at Risk".

The purpose of this book is to tell the story of attacks on computers in the
words of those who are making the story and who see the broad perspective in
which it is taking place.  We have painstakingly selected the articles and have
provided connective material to bring out the global context and show that the
problem is not purely technology, not purely people, but a product of the
interaction between people and computers in a growing worldwide network.

After and introduction and preface by me, the articles are arranged in six
parts.  Most of these have been previously published, but there are a few new
pieces specifically commissioned for this volume.

PART I: THE WORLDWIDE NETWORK OF COMPUTERS

   Worldnet and ARPANET by Denning, overview of networks by Quarterman,
reflections by Thompson, survey of computer insecurities by Witten.

PART II: INTRUDERS

   Reflections by Reid, Wily hacker story by Stoll, a followup commentary by
Mandel, and a business perspective by Wilkes.

PART III: WORMS

   Internet worm overview by Denning, perspectives on the Morris worm by MIT's
Rochlis et al, Purdue's Spafford, and Utah's Seeley, executive summary of
Cornell Report, Morris indictment and trial summary by Montz, original worm
paper by Shoch and Hupp.

PART IV: VIRUSES

   Virus overview by Denning, BRAIN and other virus operation by Highland,
virus primer by Spafford et al, viral protection in MS/DOS by Brothers, and a
perspective on viruses by Cohen.

PART V:  COUNTERCULTURES

   Computer property rights by Stallman, cyberspace literature by Paul Saffo, a
dialog on hacking and security by Dorothy Denning and Frank Drake.

PART VI:  SOCIAL, LEGAL, AND ETHICAL IMPLICATIONS

   A spectrum of commentaries: moral clarity and sending a signal by Denning,
global city by Morris, virus bills in congress by Crawford, GAO report summary,
legal issues by Samuelson and by Gemingani, computer emergency response by
Scherlis et al, ethics statements by various organizations, ACM President's
letters by Kocher, ACM forum letters, law and order for the PC by Director,
RISKS perspectives by Neumann, crimoids by Parker.

To order the book, run to your local bookstore or call ACM Press Order
Department.  For credit card orders only call    800-342-6626
or in Maryland and outside the continental US call    301-528-4261
and for mail orders ACM Order Department, P. O. Box 64145, Baltimore, MD 21264.
The price for ACM members is $18.50 and for nonmembers $20.50.
Shipping is extra unless you send a check to the order department.  BE SURE TO
INCLUDE YOUR ACM MEMBER NUMBER AND THE BOOK ORDER NUMBER (706900).

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
``Hackers Accessed NASA's Phones'' (Re: <A HREF="/Risks/10.65.html">RISKS-10.65</A>)
</A>
</H3>
<address>
The Polymath
&lt;<A HREF="mailto:hollombe@ttidca.tti.com ">
hollombe@ttidca.tti.com 
</A>&gt;
</address>
<i>
7 Dec 90 17:23:55 GMT
</i><PRE>

According to yesterday's news NASA has flatly denied the theft ever took
place.  Their spokesperson said their normal annual phone bill is about $3
million and it wasn't possible for someone to steal $12 million worth of
phone services from them (i.e.:  They'd be detected long before things got
that far out of hand).

Jerry Hollombe, M.A., CDP, Citicorp(+), 3100 Ocean Park Blvd., Santa Monica, CA
90405 (213) 450-9111, x2483  {csun | philabs | psivax}!ttidca!hollombe

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Response to article on "Legion of Doom" sentencing (<A HREF="/Risks/10.65.html">RISKS-10.65</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Gary_Cattarin@dg_support.ceo">
Gary_Cattarin@dg_support.ceo
</A>&gt;
</address>
<i>
Fri, 7 Dec 90 10:42:30 est
</i><PRE>

CEO document contents&lt;:
    
    The article that appeared in risks 10.65 from Emmanuel Goldstein of
    "2600" Magazine displays a callous immaturity to the realities of the
    business world.  I'm not going to quibble over the exact nature of the
    sentences handed out.  The clear point, and yes, the "message" that
    the authorities tried to get across (but was clearly lost on the
    author of that article) is that unauthorized access to someone else's
    computer is just plain wrong, no matter what was or was not done
    during that access.
    
    We've heard that point reiterated numerous times in this journal, and
    I'm sure the hackers of the world have heard it and usually discounted
    it, but let me put it in the vein of the realities of modern business.
    
    Mr. Goldstein, I don't know a thing about your magazine.  I don't know
    your organization's finances, staffing, etcetera, or if you even have
    any of them.  I don't know what you do for a living.  I do know that
    in my business, we are faced with an intensely competetive global
    marketplace in which we fight to survive.  We are faced with the
    realities of staff shortages compounded by further cuts.  We are faced
    with shortages of resources, yet we still must get the job, or it will
    mean the end of our jobs, and probably the end of the company as well.
    
    We would LOVE to have enough time to do everything perfect.  We'd LOVE
    to devise security systems that could foil you and your clan.  And we
    could probably come pretty damn near doing it; we've got some pretty
    good heads here - most likely some heads who have done their share of
    hacking as well.  But we can't dedicate that kind of time to staving
    off a bunch of obnoxious intruders, just as Bell South didn't.  Bell
    South dedicated their personel to doing the business they were
    involved in, as rightly they should.
    
    So what happens when you invade Bell South's, or my company's
    computer?  If you get in, just to prove you can, then tell us about it
    in light of your supposed "spirit of pointing out flaws that should be
    fixed", what has that gained you?  Giddy joy, I suppose, but not much
    else (picture the job interview:  "So, what are our technical
    qualifications?"  "Well, sir, I'm good.  I broke into 43 systems last
    year!").  What has it gained us?  OK, we know about a flaw.  You know
    what?  We probably already did.  Perhaps you don't realize it, but in
    the resource-short business world, we know about a LOT of flaws.  We'd
    LOVE to fix them all.  We're trying.  We just don't have the resources
    to get it done immediately.
    
    So that leaves the door that you found.  Now you'll spread word of
    your door via your hacker hotlines.  And though you may have meant no
    harm, others may follow, invading our system as if it were another
    town on the interstate to be driven through.
    
    But can you or we be sure that all who enter mean no harm?  Can you be
    sure that no bit was left untouched?  That's all it takes:  one bit,
    somewhere, modified, which, as readers of RISKS well know, can have
    monumental consequences.  The downing of an airliner.  A fatal safety
    flaw in a new car.  An accounting system rendered worthless.  These
    are major cases, but the minor ones are just as important, because
    once you've been invaded, you just don't know what the invader did.
    
    If you came home at night and found your front door unlocked, what do
    you know?  Sure, you may have left it unlocked.  But did anyone take
    advantage of that?  Did they take anything?  Damage anything?  Leave
    anything unwanted inside?  Steal the extra key?  Are they perhaps even
    in your home?
    
    Didn't you check to be sure that door was locked?  Maybe you did, but
    they came in through the window.  Didn't damage anything, but still,
    you don't know that?  OK, you checked the windows, but they came in
    through the skylight.  You checked those?  They found another way...
    
    You see, you can take care of all the obvious points of entry, but a
    intruder will find another point of entry.  The hacker's view is that
    since that other point of entry wasn't blocked off, the hacker is
    welcome in.  I don't think you'd agree if it were your home.
    
    So Bell South detected an intruder.  And they chose to pursue the
    intrusion.  How much did it cost them?  Was it simply the "value" of
    the document?  (How does one place a value on a document?)  Was it
    simply the cost of the personel who investigated?  Was it perhaps the
    business lost because they spent their time looking for the intruder
    instead of pursuing Bell South's normal business?  (Remember, Bell
    South is in business to make money, like it or not.  Your nation is
    build on that principle, that's why you can get food in your grocery
    store, unlike in Moscow.)  Was it the cost of implementing modified
    procedures company-wide to protect against the likes of you?  The cost
    of business lost because people company-wide spent time on these new
    procedures rather than pursuing their intended business?  How about
    the cost (real and lost opportunity) of the personnel involved in the
    legal case, not to mention the lawyers' fees?  You see, "cost" has a
    much more far reaching meaning than you attribute to it.  And nobody
    can really even tell how high the final figure is, but I'll assure
    you, it's astronomical.
    
    In business, we've got to spend our time and resources pursuing our
    business.  We just don't have the time, money, or resources to post
    guards to keep the likes of you out of every possible entry point.
    Until you understand that, the government is going to continue to try
    to send you this message.  Perhaps my treatise here will save you and
    your colleagues a few prison terms (pity the fact that I, as a
    taxpayer, have to support those folks in prison!).  More importantly,
    perhaps it will spare a few other companies the trouble that Bell
    South has experienced.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Response to article on "Legion of Doom" sentencing (<A HREF="/Risks/10.65.html">RISKS-10.65</A>)
</A>
</H3>
<address>
King Ables
&lt;<A HREF="mailto:ables@mcc.com ">
ables@mcc.com 
</A>&gt;
</address>
<i>
Fri, 7 Dec 90 10:28:22 CST
</i><PRE>

I read your article on the sentencing of some "Legion of Doom" members that
was posted to comp.risks and feel compelled to make a couple of remarks.

I agree that this situation is one about which we, as a community of
programmers, should be concerned.  But the tone of panic seems meant to
persuade us emotionally rather than intellectually.

&gt; This kind of a sentence sends a message all right. The message is that the
&gt; legal system has no idea how to handle computer hacking.

This, unfortunately, is very true.  It is also the main reason we have the
problems you describe.  If the laws were written better (i.e. the issues
involved were better understood by those who write the laws) many of these
problems wouldn't exist.

&gt; shared information which we now know was practically worthless. And they
&gt; never profited in any way, except to gain knowledge. Yet they are being
&gt; treated as if they were guilty of rape or manslaughter. Why is this?

Whether or not you profit from something has nothing to do with whether or not
it was a crime.  You don't profit from beating the hell out of some homeless
person in an alley, but it's still illegal.

They are being treated like criminals because they participated in a criminal
act.  If you don't believe the activity should be considered illegal, then work
to get the laws changed.  Right now-- today-- at this moment-- the acts are
illegal.  Whether or not they SHOULD be illegal is a completely separate
question.

&gt; We think it's time concerned people sent a message of their own. Three young
&gt; people are going to prison because a large company left its doors wide open
&gt; and doesn't want to take any responsibility. That in itself is a criminal act.

Nope.  Three young people are going to prison because they broke the law.

If I walk into an unlocked jewelry store and take something, it is no less
a crime.  To say that the establishment deserved it because they left
themselves wide open for it is hardly a justification for the action.

&gt; By blowing things way out of proportion because
&gt; computers were involved, the government is telling us they really don't know
&gt; what's going on or how to handle it. And that is a scary situation.

This is absolutely true.  And again, by participating and contributing our
knowledge to the process, we can help to modify the process so that it makes
more sense.  To simply sit back and scream "foul" isn't going to make it any
better.

This is not to say I believe the accused received appropriate punishment, I
don't.  But to claim they are innocent victims of the big, bad government is
not correct either.

King Ables, Micro Electronics and Computer Technology Corp., 3500 W. Balcones
Center Drive Austin, TX 78759    +1 512 338 3749

</PRE>
<HR><H3><A NAME="subj5.2">
Response to article on "Legion of Doom" sentencing (<A HREF="/Risks/10.65.html">RISKS-10.65</A>)
</A>
</H3>
<address>
Brinton Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Fri, 7 Dec 90 13:39:23 EST
</i><PRE>

Emmanuel Goldstein, Editor, 2600 Magazine, quotes from his pub:

"...We consider this to be a very major and very frightening issue...  Since we
began publishing in 1984 we've pointed out cases of hackers being unfairly
prosecuted and victimized...just a desire to learn and share information...
Here we have a case where some curious people logged into a phone company's
computer system...No cases of damage to the system were ever attributed to
them...We think it's time concerned people sent a message of their own. Three
young people are going to prison because a large company left its doors wide
open and doesn't want to take any responsibility. That in itself is a criminal
act..."

	1. Leaving one's doors open is not a criminal act.  When was was anyone
ever prosecuted for failing to lock the garage door?

	2. Breaking and entering is a crime in most jurisdictions.  Sentences
of 14 to 21 months don't sound uncommon for breaking and entering.

	3. The general public has no inherent right to "information" owned by a
phone company, any other company, or private individuals, except as prescribed
by law...and even then, not always.  Breaking and entering someone's home in
order to listen to their stereo, read from their library, or peruse their
family's financial files is no one's right.

_BRINT

</PRE>
<HR><H3><A NAME="subj5.3">
Response to article on "Legion of Doom" sentencing (<A HREF="/Risks/10.65.html">RISKS-10.65</A>)
</A>
</H3>
<address>
Mark E. Levy
&lt;<A HREF="mailto:levy%fndcd.dnet@fngate ">
levy%fndcd.dnet@fngate 
</A>&gt;
</address>
<i>
Fri, 7 Dec 90 15:43:54 CST
</i><PRE>

Emmanuel Goldstein, Editor, 2600 Magazine writes:

&gt;... We think it's time concerned people sent a message of their own. Three young
&gt;people are going to prison because a large company left its doors wide open and
&gt;doesn't want to take any responsibility. That in itself is a criminal act. ...

Sorry.  I don't buy it.  If I leave my keys in my car with the windows open,
and you get in and drive off, you're still just as guilty of stealing the car
as if you had to break in and "hot wire" it.  I may have asked for it by
leaving the keys, but that's no excuse.

By the same token, you have no implied right to come into my house and "look
around" just because I left the door open.  It's no different with computers.
Irrespective of whether of not BellSouth "left the door open," if the three you
mentioned entered the system without permission, they're guilty.  That in
itself is enought to convict, any materials taken nonwithstanding.  Case
closed.  I have NO sympathy for them.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.65.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.67.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-40</DOCNO>
<DOCOLDNO>IA013-000136-B030-424</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.67.html 128.240.150.127 19970217040929 text/html 23189
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:08:01 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 67</TITLE>
<LINK REL="Prev" HREF="/Risks/10.66.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.68.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.66.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.68.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 67</H1>
<H2> Friday 7 December 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Airline safety 
</A>
<DD>
<A HREF="#subj1.1">
Donald A Norman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Voter identity and Dial-A-Vote 
</A>
<DD>
<A HREF="#subj2.1">
Lauren Weinstein
</A><br>
<A HREF="#subj2.2">
 Glen Overby
</A><br>
<A HREF="#subj2.3">
     Paul Peters
</A><br>
<A HREF="#subj2.4">
 Andrew Klossner
</A><br>
<A HREF="#subj2.5">
 Dan Sandin
</A><br>
<A HREF="#subj2.6">
 Frank Kuiper
</A><br>
<A HREF="#subj2.7">
 Adams Douglas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
"Little pitchers have big ears": yet another ATM RISK 
</A>
<DD>
<A HREF="#subj3.1">
zowie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Billing software wastes money 
</A>
<DD>
<A HREF="#subj4.1">
Phil R.M.
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Airline safety
</A>
</H3>
<address>
Donald A Norman-UCSD Cog Sci Dept
&lt;<A HREF="mailto:danorman@UCSD.EDU ">
danorman@UCSD.EDU 
</A>&gt;
</address>
<i>
Fri, 7 Dec 90 08:00:20 PST
</i><PRE>

I apologize in advance: this is a sermon.

The note in RISKS on the Economist's suggestions for aviation safety prompts
this note.  The problem is that the suggestions were all aimed at the pilots.
The myth of crashes caused by single individuals, usually the pilot, persists.

Accidents in aviation is a system problem.  Accidents occur because the system
is faulty.  Note that an accident almost never involves a single error: there
must be a chain of events, each of them usually unlikely by themselves, before
an accident happens.

The Economist's suggestions seem to me to be without merit, save for their last
-- that we should get more information from the cockpit.  I was pleased and
surprised to see the NTSB (the U.S. National Transportation Safety Board) just
recommend increasing the voice cockpit recorder tape to longer than 30 minutes
(now it is a repeating loop of tape of duration 30 minutes), increasing the
number of parameters measured by the black box that records airplane and engine
state, and hurrah!  adding video cameras and recorders so you could see if
critical controls were actually used.

Accidents will continue as long as people treat this as something that can be
cured by concentration on the pilots.  In my opinion, the flight-deck
instrumentation -- especially the automation, such as the "flight management
computer" and "mode control panels" are classic examples of poor design from
the human side of things, the maps and approach charts are unbelievably
cluttered and complex (a recent accident in which a landing aircraft clipped
the power lines, thus turning off the airport's landing lights (among other
things) was partially attributed to incorrect reading of the charts), and the
interactions with air traffic control (ATC) and the equipment and limitations
that ATC face add to the problem.

The new addition of "datalink" to the cockpit will only create new problems.
Datalink is digital transmission of ATC information to be received somewhere in
the cockpit on a CRT display.  This replaces some of the voice communication on
the now overcrowded channels.  In principle it has merits, but it is yet
another complex piece of equipment, yet another change in procedures, yet
another bandaid and ill-considered addition to cockpit clutter.  I used the
word "somewhere" because nobody yet knows quite where to fit the thing into the
already crowded cockpit, and all the current suggestions seem to lead to
foreseeable future problems.  The lack of positive confirmation form pilots
will also lead to other (foreseeable) problems.  Basically, one cannot fix a
system problem by adding local patches.  In fact, that tends to make things
worse.

These difficulties have been known for a long time.  The only surprise about
the recent runway collision in Detroit (where a plane taxiing on the runway
collided with a plane taking off on the same runway) is that it hasn't happened
frequently before.  The NTSB had warned about these problems.  Pilots know they
get lost on runways and taxiways, and the Tenerife crash that destroyed two
fully-loaded 747's some years ago was almost identical.  It is a system
problem.

As long as we try to solve the problem by arguing that pilots need better
decision rules or better warning systems, then we are going to continue to have
the problem.

Human error is almost always a result of system or design error, and unless you
attack that, you don't attack the causes.

The Economist urged the introduction of a new decision speed.  Sigh.  Loss of
an engine on takeoff is what every pilot practices and what almost never
happens, and the current decision speed of V1 should probably be degraded, but
it is NOT the main culprit.  The Economist said that the current ground
proximity warning systems (GPWS) are faulty.  The last thing a pilot needs is
yet another warning system in the cockpit.  And I don't recall any recent
incidents where a faulty GPWS was a contributors.

By the way, substitute "computer" or "ship or "oil refinery" or "chemical
plant" for "airplane" and substitute "operator" for "pilot" and you get the
same message.  Society tends to try to find single individuals to blame for
accidents.  Students of human error blame the system.  And unless we fix the
system, we will continue to have these accidents as a mater of course.  "Normal
accidents" is what Charles Perrow called them in his brilliant book by that
title.

Credentials: I study aviation safety under a grant from NASA.  No, I am not
a pilot.

Don Norman, Department of Cognitive Science 0515, University of California, 
San Diego	 La Jolla, California 92093 USA        BITNET: dnorman@ucsd

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Voter identity and Dial-A-Vote
</A>
</H3>
<address>
Lauren Weinstein
&lt;<A HREF="mailto:lauren@vortex.com ">
lauren@vortex.com 
</A>&gt;
</address>
<i>
Wed, 21 Nov 90 22:55:20 PST
</i><PRE>

One risk that I don't think I saw mentioned in the discussion of "Dial-A-Vote"
systems relates to the identity of voters.  Such a system, by definition, would
need to know the identity of each caller to check registration and avoid
duplications.  Caller-ID would require people's presence at particular phones
and is a can of worms for many other reasons.  Personal ID codes could also be
used, but, uh, I *wonder* what number would be most likely used for this
purpose?  Can you say "SS"?  I knew you could!

In any case, you'd have to identify yourself to the system, and then it would
be trivial for a file to be kept on how you voted.  Of course, we'd be told
that this wouldn't be done, that there would be adequate safeguards, and that
it was *impossible* to subvert the system.

This is a significant new risk.  With current voting techniques, picking out an
individual's vote is essentially impossible without a great deal of illicit
goings on at the polling place.  Paper ballots and punch card ballots have no
identifications, and are thrown into common bins.  Voting machines increment
internal counters that keep running totals only, not individual votes.  But
with Dial-A-Vote, all this low-tech privacy goes out the proverbial window.

--Lauren--

</PRE>
<HR><H3><A NAME="subj2.2">
Voting electronically from home
</A>
</H3>
<address>
Glen Overby 
&lt;<A HREF="mailto:overby@plains.NoDak.edu">
overby@plains.NoDak.edu
</A>&gt;
</address>
<i>
Sun, 25 Nov 90 02:01:47 -0600
</i><PRE>

I have a few items to contribute to the vote-by-phone discussion.  First, how
do you identify legitimate voters?  While most states require voters to
register before an election, North Dakota does not, and I don't believe we're
alone in that aspect.  In fact, I have never been asked to show any type of
identification; I am merely asked my name and address (the first time I voted I
was asked to sign a form stating that I was using my real name, of voting age,
had not voted in another precinct, etc.).  Telephone voting could be possible
if you have voted in a previous election, and are thus in your precinct's
records.  This does not permit a complete transition over to automated voting,
but could allow it's addition as a convenience.

You will, nonetheless, have to identify yourself on the telephone with some
sort of number.  There will have to be laws passed insuring your privacy as
well as illegitimate use of someone else's voter-id number; imagine how some
phreak with an autodialer could wreak havoc with an election by voting "for"
people.

The other thing missing from the vote-by-phone system is the provision for
write-in candidates.  I'm not certain if all states require a provision for
write-in candidates, but many years ago the mechanical voting machines here
were replaced with fill-in-the-dot forms that are optically scanned by a couple
of IBM scanners down at the courthouse.  I recall the issue of the switchover
was not one of mechanical reliability (those machines were OLD), but that there
was no way for you to write-in a candidate.

		Glen Overby	&lt;overby@plains.nodak.edu&gt;
	uunet!plains!overby (UUCP)  overby@plains (Bitnet)

</PRE>
<HR><H3><A NAME="subj2.3">
 Voting from home electronically
</A>
</H3>
<address>
Paul Peters 
&lt;<A HREF="mailto:PPeters@DOCKMASTER.NCSC.MIL">
PPeters@DOCKMASTER.NCSC.MIL
</A>&gt;
</address>
<i>
Mon, 26 Nov 90 08:43 EST
</i><PRE>

The emphasis of RISKS 10.64 on telephonic voting taking rights away from the
population without telephones is misplaced.  Of all the problems with
telephonic voting, this is the least.  One could say that the current locations
of polling places takes rights away from those without automobiles, but we have
found ways to provide alternate transportation for those folks.  With some
creativity, we could find ways to provide voting capability to those without
telephones also.  Paul Peters

</PRE>
<HR><H3><A NAME="subj2.4">
remote voting: the Oregon experience
</A>
</H3>
<address>
Andrew Klossner 
&lt;<A HREF="mailto:andrew@frip.wv.tek.com">
andrew@frip.wv.tek.com
</A>&gt;
</address>
<i>
Thu, 29 Nov 90 10:59:07 PST
</i><PRE>

Experience in Oregon with remote voting may shed some light on
proposals for vote-by-telephone.  Oregon has used vote-by-mail for
special elections for a few years.

A few weeks before the election, each registered voter receives, by
mail, a perforated punch card and explanatory material.  To vote, we
punch the card appropriately (using a pencil to poke out perforated
holes), seal the card in a special envelope, sign the envelope, and
mail it.  We have to pay for the stamp.  Only one ballot per envelope.

During such elections, the usual polling places are not established.  Anybody
who objects to vote-by-mail must go to the county seat on election day to vote
in person.  Not only is this a potential hardship, but so few people do this
that they lose the anonymity of large numbers.

This system is subject to many of the potential pitfalls mentioned by other
contributors.  Perhaps the greatest of these is that the dominant member of the
household can punch all the cards, coerce signatures from other members, and
thus influence several votes.  Another is that we, the electorate, have no
guarantee of ballot secrecy other than the solemn promise of the bureacracy.

Reported public opinion is unanimously in favor of vote-by-mail because it
reduces the cost of an election (no polling place expenses) and because we get
much greater voter participation.

  -=- Andrew Klossner   (uunet!tektronix!frip.WV.TEK!andrew)    [UUCP]
                        (andrew%frip.wv.tek.com@relay.cs.net)   [ARPA]

</PRE>
<HR><H3><A NAME="subj2.5">
Re: Voting (Re: <A HREF="/Risks/10.61.html">RISKS-10.61</A>)
</A>
</H3>
<address>
Dan Sandin
&lt;<A HREF="mailto:sandin@uicbert.eecs.uic.edu ">
sandin@uicbert.eecs.uic.edu 
</A>&gt;
</address>
<i>
Thu, 29 Nov 90 22:45:46 GMT
</i><PRE>

OK, my response to what has gone down so far:

making election day a national holiday, or whatever, still would not make it
better for every person to get to the polls. I mean, think about all the people
who still have to work on national holidays, or even have to work MORE (liquor
store employees spring immediately to mind) or cases when unforeseen
circumstances prevent one from voting. A sick sister in another state, a boiler
explodes, whatever.

The point is simply to make legitimate voting EASIER.

As we know from working with computers, plenty of people would prefer to vote
the old-fashioned way, physically showing up at the polls, who don't trust,
don't understand, or just don't like the phone-in system, that's just fine.

Someone suggested it would make blackmail voting, etc, easier.  Remember,
though, that usually "stealing" one vote, or even a thousand votes will make
very little difference (depending on the size of the election) Ordering
hundreds of little old ladies to vote by gunpoint would be very difficult to
hide, and would only make a difference in a very small election. It is much
safer and cost-effective to use the tried and true method of getting votes -
getting the voters drunk.

Indeed, with this system, I would think that the regular polling places would
just be custom terminals with leased lines direct to the same polling computer
that one dials in with from home.

I would hope that one of the effects would be to encourage more voting,
and perhaps for our government to have regular referenda on issues,
rather than waiting for  regularly scheduled elections.
Just dial 1-800-PRO-CHOI or 1-800-PRO_ABRT 

Some posters have suggested that a segment of the population would be favoured
by this, that poor people would find it harder to vote than rich. True.
However, I think you will find that the percentage of people who have
telephones is greater than the percentage of registered voters who vote, let
alone the percentage of the population as a whole who vote. I would guess that
telephone market penetration is over 90%, and I would further guess that,
considering payphones, work phones, a friend's phone, etc, &gt;99.999 % of the
population has phone access. In fact, since voter registration requires an
address, I bet more people have access to phones than have legal residence
addresses.

I think it is safe to say that if voting could be accomplished by phone as well
as in a polling place, voting attendance would go up.  And by definition with
the tenets of Democracy, this is a Good Thing.

stephan meyers c/o dan sandin sandin@uicbert.eecs.uic.edu

p.s. someone mentioned the problem of tying up the phone lines, as in
"I'm sorry, all voting lines are busy now, please try again later"
This is a real problem, and probably no cheap way out of it.

</PRE>
<HR><H3><A NAME="subj2.6">
Re: Voting (Re: <A HREF="/Risks/10.61.html">RISKS-10.61</A>)
</A>
</H3>
<address>
Frank Kuiper
&lt;<A HREF="mailto:frankk@cwi.nl ">
frankk@cwi.nl 
</A>&gt;
</address>
<i>
30 Nov 90 11:15:16 GMT
</i><PRE>

In the Netherlands we have the following system, wich works quite well.
Everyone has a residents registration, no matter where in the Netherelands you
live. This registeres, amongst other things, your name, address, date and place
of birth.

With this information the councel (gemeente) knows who are eligible to vote.
Every voter, some weeks before an election, is send a voting-card, with details
on when and where (which polling station) to vote. The polling stations are
open from 7am until 7pm (always on a Wednesday; no disturbance of the "Sunday
peace" ;-), thereby giving everyone the opportunity to vote before, during or
after work.  It is possible to vote in another polling station, if you declare
to want that. You will have to do that well in advance.  Also, it is possible
to have someone else vote for you, in which case you can easily transfer the
received voting-card to the other voter, by mentiong his/her name on the card,
and signing it yourself.  One can only vote for two others (thereby making it
very difficult to just buy all the voting cards).

Unless you're out of the country, have no friends or relatives and are dying
somewhere, you always have the opportunity to have your vote cast. Residents
outside the Netherlands can vote (by mail) via the local Dutch embassy.

All I have to do is pass the polling station on my way to work, and vote.

Frank Kuiper    AppleLink: HOL0042

</PRE>
<HR><H3><A NAME="subj2.7">
Re: Becoming over-sensitive to risks (vote by phone)
</A>
</H3>
<address>
Adams Douglas
&lt;<A HREF="mailto:adamsd@crash.cts.com ">
adamsd@crash.cts.com 
</A>&gt;
</address>
<i>
Wed Nov 21 22:57:14 1990
</i><PRE>

I was thinking about phone voting systems myself this last election.
Specifically, I thought about the idea of having a centralized polling system
which would allow you to enter your vote preferences during the campaign. This
information could be used as official pre-election polls are used now. On
election day, you would either call again and re-vote, or you could have
specified earlier that if you did not call on election day, the system should
use your last poll as your vote. This would solve a lot of absentee delays (and
I know people will say there are problems with it, but it's just an idea).

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Little pitchers have big ears": yet another ATM RISK
</A>
</H3>
<address>
&lt;<A HREF="mailto:zowie@banneker.Stanford.EDU">
zowie@banneker.Stanford.EDU
</A>&gt;
</address>
<i>
Sun, 25 Nov 90 00:32:54 PST
</i><PRE>

Today, I went with a friend into a local bank [Wells Fargo], to activate his
(newly-arrived) ATM card.  This ritual involves the selection of a password 
[PIN] for for the account.  He gave his card to the clerk, who swiped it 
through a magnetic reader and typed something on a keyboard.  Then my friend
typed his new PIN on a special, hooded keyboard out of view of the clerk 
(and, hopefully, from other bank clients).  

A speaker clicked on, and, to my surprise, we (me; my friend; the clerk; and, 
in fact, nearly everyone in the building) were treated to the sounds of a dial
tone, some touch-tone dial sounds, a (surprise!) normal-sounding 300-baud 
modem query and connection, and, in fact, the entire [300-baud] exchange, 
complete with hangup sounds.  

The RISKS of this audible broadcast should be clear:  anyone with a good 
pocket microcassette recorder should be able to record the entire modem 
transaction, simply by being near someone who is activating his ATM card.  
With a little ingenuity (or, eg, a DSP such as that onboard a NeXT machine), 
it would be trivial to decode the entire 'dialogue', which presumably 
includes not only the person's account number and PIN, but also a password to
make changes to an arbitrary ATM card!

The information would be particularly easy to extract because of the robust
nature of the 300-baud Bell standard.

I spoke with several colleagues (including joe@hanauma.stanford.edu) about the
broadcast of the computer dialogue:  it appears that many Wells Fargo branches
follow this practice, and have been for at least three years.  

The moral of the story is perhaps that one should not shout out sensitive 
information, even in supposedly unintelligible languages.

--zowie

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Billing software wastes money
</A>
</H3>
<address>
&lt;<A HREF="mailto:prm@ecn.purdue.edu">
prm@ecn.purdue.edu
</A>&gt;
</address>
<i>
Wed, 28 Nov 90 10:13:41 EST
</i><PRE>

Last year my wife and I bought a chair at Michael's Furniture, a store
here in West Lafayette.  We financed the chair, and Michael's promptly
sold the contract to Security Pacific Financial Corporation.

Everything went fine; no problems.

A month ago, we made our regular monthy payment, after which, our balance
was some small amount (like 20 or 30 dollars).  A week after we mailed our
original payment my wife suggested that we just pay off the acocunt.  I
agreed.  She wrote out a check for the balance due and mailed it off.

Fine, no problem.

A week ago, we got a bill from Security Pacific.  For four cents.  Apparently,
some interest and accrued on the account in the week or so between checks.

Clearly, it never occured to the people writing Security Pacific's billing
software that if the balance due was less than the cost of mailing a bill
then they should just write off the balance due.

Sigh.  We mailed them their four cents.                              Phil

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.66.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.68.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-41</DOCNO>
<DOCOLDNO>IA013-000136-B030-453</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.68.html 128.240.150.127 19970217040956 text/html 24359
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:08:11 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 68</TITLE>
<LINK REL="Prev" HREF="/Risks/10.67.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.69.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.67.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.69.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 68</H1>
<H2> Friday 14 December 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Recent RISKS Mail to CSL.SRI.COM 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Many Bills Are Found Incorrect on Adjustable Rate Mortgages 
</A>
<DD>
<A HREF="#subj2.1">
Saul Tannenbaum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Loughborough 
</A>
<DD>
<A HREF="#subj3.1">
Rob Thirlby via Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Gender and computer anxiety 
</A>
<DD>
<A HREF="#subj4.1">
Rob Gross
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Computerized USA Phone Directory 
</A>
<DD>
<A HREF="#subj5.1">
Allan Meers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Getting out of Lotus' "Household Marketplace" 
</A>
<DD>
<A HREF="#subj6.1">
TDN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: a fondness for turkeys 
</A>
<DD>
<A HREF="#subj7.1">
Haynes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Call for Papers - 14th National Computer Security Conference 
</A>
<DD>
<A HREF="#subj8.1">
Jack Holleran
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Recent RISKS Mail to CSL.SRI.COM
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Thu, 13 Dec 1990 15:52:40 PST
</i><PRE>

Well, we survived the move to another building (I'm now in EL-243), although
for a variety of reasons the servers could not be moved on schedule and getting
everything working again was decidedly nontrivial.  But the resulting outage of
five days meant that some mail to CSL.SRI.COM was rejected.  So, if you got
BARFmail indicating your mail to CSL was undeliverable, PLEASE TRY AGAIN NOW.
Sorry for the inconvenience.  Peter

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Many Bills Are Found Incorrect on Adjustable Rate Mortgages
</A>
</H3>
<address>
Saul Tannenbaum 
&lt;<A HREF="mailto:SAUL_SY@hnrc.tufts.edu">
SAUL_SY@hnrc.tufts.edu
</A>&gt;
</address>
<i>
Wed, 12 Dec 90 19:30 EDT
</i><PRE>

The New York Times reports (13 Dec 90) that, according to a General Accounting
Office study, as many as 25% of all adjustable rate mortgage bills may
be incorrect as a result of bank errors in calculating their interest
rates. These error were found as part of routine audits done as failed
savings and loan institutions were taken over by Federal regulators.

A former Federal mortgage banking auditor says that that estimate is
too low, putting the problem at 30-35% of adjustable rate mortgages.
In some cases, this auditor says, the errors resulted from "human mistakes" at
small S&amp;Ls, that often calculated adjustable mortgages by hand. In other
cases the problems were caused by "computer glitches." One failed S&amp;L,
the Victor Federal Savings and Loan of Muskogee, Okla, was audited
by the Bennington Group for the Federal Saving and Loan Insurance Corp.
The audit, which sampled 96 adjustable mortgages, found that the 
bank's computer system contained logic error. The bank, among other
things, rounded rates upward, instead of downward and "pulled" the
index on the wrong date, when it might be higher or lower than on
the correct date. Other errors resulted from "poor recordkeeping",
where the indices on which the adjustable rates wer based couldn't be found,
or did not match the FSLIC computer programs [which begs an obvious
question]. Some adjustable mortgages have never been adjusted.

In one example given, a woman took out 3 identical adjustable rate mortgages
from the same bank at the same time. Now, all three have wandered off in
different directions. She has 3 different monthly payments, 3 different
balances, and 2 payment schedules.

According to the article, it is the opinion of Federal regulators that the
Truth In Lending Law "probably does not" require lenders to repay overcharges
in any form.

Saul Tannenbaum, USDA Human Nutrition Research Center on Aging at Tufts
University, 711 Washington St., Boston, MA 02111 STANNENB@TUFTS.BITNET

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A White Xmas?
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian.Randell@newcastle.ac.uk">
Brian.Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Tue, 11 Dec 90 16:38:05 GMT
</i><PRE>

Date:     Tue, 11 Dec 90 11:03:24 GMT
&gt;From:    Rob Thirlby &lt;R.Thirlby@uk.ac.lut&gt;
Subject:  Loughborough
To:       uk-mail-managers @ uk.ac.newcastle
 
We are back in the world, the little, forgotten, black hole in the East
Midlands is now up and running after over 60 hours of no electricity, often no
water, dodgy phones, and just to finish it off this morning a suspected gas
leak and a heating fault (or at least I presume its a fault its not very
warm!).
 
Many of the surrounding villages are still without power and in some cases
water and phones.  And all this in the Soar valley with one of the lowest
average snowfalls in England!  The University cedar tree which features on much
of our publicity has lost its top half and I suspect there has been more
arborial damage than in the hurricane year.
 
For the technically minded the main problem was due to the incredibly wet
sudden snowfall which stuck to anything it touched even in a gale.  The
Loughborough 132KV grid feed wires and gear fell onto a host of lower voltage
feeders causing massive damage to both.  It must have made firework night look
tame.  All our water is pumped by (non backed-up) electric pumps from
Derbyshire and hence the chaos.  There's nothing more irritating than being
told on the radio to boil all the water when you havent any means of heating
it.  Mind you we can see the plumes of vapour from some of the countries
largest power stations on the Trent and that doesnt improve ones temper when
trying to bake potatoes on a log effect, real-flame, gas fire!
 
I hope you all had a nice week-end.
 
Rob Thirlby, Postmaster@lut

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Gender and computer anxiety
</A>
</H3>
<address>
Rob Gross
&lt;<A HREF="mailto:<GROSS@BCVMS.BITNET> ">
&lt;GROSS@BCVMS.BITNET&gt; 
</A>&gt;
</address>
<i>
Sat, 8 Dec 90 00:22 EST
</i><PRE>

The following is excerpted from the "Faculty File" column in the
Princeton Alumni Weekly of December 5, 1990:

    In general, [Joel] Cooper [chairman of the psychology department
    at Princeton] has found, females are more subject to computer
    anxiety than males are, and as a result, they perform
    computer-related tasks worse.  But there's an important contextual
    component to these findings:  the performance differential appears
    only when there's someone else in the room with the female who's
    using the computer.  Just the presence of another person-male or
    female, no matter what he or she is doing-seems to be enough to
    generate computer anxiety.  By contrast, when they're alone in a
    room with a computer, females generally show no appreciable
    difference in performance compared to males.

    In the course of this study, Cooper examined a group of
    middle-school children in Princeton...The children were asked to
    solve arithmetic problems on a computer.  In group settings, the
    girls in the class often did worse than the boys, whose
    performance actually improved when other people were around.  In a
    test of university students, Cooper had groups of men and women
    play an adventure game called Zork on a computer; some played with
    other people present, other were alone.  The middle school results
    were replicated.

    ``We tried to get a fix on what the other people in the room had
    to do to provoke the computer anxiety,'' Cooper recalls.  ``It
    turned out to be almost nothing.  They could be writing a letter
    in the corner, totally ignoring the woman at the keyboard, but
    still her performance would drop.  They just had to be there.''


Rob Gross
Department of Mathematics   BITNET: GROSS@BCVMS
Boston College              Internet: GROSS%BCVMS.BITNET@MITVMA.MIT.EDU
Chestnut Hill, MA 02167

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Computerized USA Phone Directory
</A>
</H3>
<address>
Allan Meers - Sun Education
&lt;<A HREF="mailto:allans@ebay.sun.com ">
allans@ebay.sun.com 
</A>&gt;
</address>
<i>
Thu, 13 Dec 90 00:03:32 PST
</i><PRE>

Mercury News - 90-Dec-12

Compuserve has introduced the FIRST computerized national phone book, listing
the name, address, ZIP, and phone number of 80 million households in the US who
have a listed number.  As of December 1, the Phonefile service allows the
725,000 Compuserve subscribers to search the phone lists of the USA by:

	name &amp; address	- for updating your christmas card list or
			  for telemarketing reasons.  This is 
			  just a computerized version of the
			  current phone book - but without needing
			  hundreds of phone books for the whole USA.

	name &amp; state	- to find long-lost relatives or to find
			  someone who has relocated (out of state).
			  Examples include old classmates for class
			  reunions, and birth parents of adoptees.

	phone number	- like a "reverse" directory, where you can
			  get any listed name &amp; address just by
			  looking up the phone number.

The cost of retrieving the information is 25 cents per minute in
addition to Compuserve's standard on-line charge of $12.80 per hour
(21 cents per minute).  The cost is considered not much more than
a call to directory assistance, and can be even cheaper considering
the aquiring and search costs of all the phone books for the USA.

The Phonefile database is compiled by a direct marketing company, Metro Mail
Corp. of Illinois, from phone directories, computerized real estate
transactions, and other sources.  It was not speculated on what the "other"
sources might be, but I would suspect other telemarketing databases, magazine
subscriptions, credit services, Usenet email alias lists :^}) , and other
public sources of name/address information.

A Bellcore New Jersey privacy issues expert, James E. Katz, indicated that a
likely consequence of the directory will be an even greater increase in the
number of unlisted phone numbers in the United States.  It was noted that Japan
and European countries have practically no unlisted numbers, while the United
States runs about 25% of its phone number unlisted, with 33% of California
numbers unlisted.

While Compuserve assures that the directory was designed to discourage the
compilation of marketing lists for junk mail and telemarketing, privacy experts
assume that such use is inevitable.  A magazine for instance, could compile
phone numbers for a telemarketing campaign targeted at reader's whose
subscriptions have lapsed.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Getting out of Lotus' "Household Marketplace"
</A>
</H3>
<address>
&lt;<A HREF="mailto:todd@atd.dec.com">
todd@atd.dec.com
</A>&gt;
</address>
<i>
Wed, 12 Dec 90 09:44:29 -0800
</i><PRE>

If you don't want to be listed in the "Household Marketplace" database but you
don't have enough energy to write a letter, you can also do the following:

	Dial	1-800-343-5414
	press 3, then 2  (I don't know what to do if you don't have a
			touch-tone phone.)

This will get you a human who will want to send you information about
"Household Marketplace."  However, you can also say that you want to
be removed from the database.  You will then be given the choice of mailing
to Lotus or you can tell them your name and address and they say they will
remove you from the database and send you written confirmation.   I did this
yesterday, so I know they will take your name and address.  I can't vouch that
they send the confirmation, the U.S. Mail isn't that fast.

If you are energetically opposed to this product, here are some names
and addresses you might want to have for your own database:
	Lotus Development Corp.
	55 Cambridge Pkwy.
	Cambridge, MA 02142
	(Mary Ann Malloy Coffey, Marketing Programs Manager)
	(Jim P. Manzi, Chairman, President, and CEO)

	Equifax, Inc.
	1600 Peachtree St. N.W.
	Atlanta, GA 30309
	(Jeff V. White, Chairman of the Board)
	(C.B. Rogers, Jr., President and CEO)

Equifax is the original collector of the data which Lotus is selling. 	/tdn

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
update on Lotus
</A>
</H3>
<address>
&lt;<A HREF="mailto:todd@atd.dec.com">
todd@atd.dec.com
</A>&gt;
</address>
<i>
Wed, 12 Dec 90 13:54:14 -0800
</i><PRE>

Someone told me that they phoned Lotus today about getting off the Marketplace
Household database and were told something different than I was told yesterday.
Apparently, today's story is that if you want written confirmation that you've
been removed from the database, you have to send mail to:
	Lotus Development Corp.
	Attn: Marketplace Name Removal
	55 Cambridge Pkwy.
	Cambridge, MA 02142

If you just phone them, they now say they won't send written confirmation.
I wonder what they'll say tomorrow.                                   /tdn

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: a fondness for turkeys (Re: Mellor, <A HREF="/Risks/10.65.html">RISKS-10.65</A>)
</A>
</H3>
<address>
99700000
&lt;<A HREF="mailto:haynes@ucscc.UCSC.EDU ">
haynes@ucscc.UCSC.EDU 
</A>&gt;
</address>
<i>
Fri, 7 Dec 90 23:30:41 -0800
</i><PRE>

I'll suggest a third reason [for the problems Pete Mellor discussed in modern
weapons system development], that I like to call Model Railroading.  Designing
a complex electronic system to solve some warfare problem is interesting,
challenging, and fun; and somebody else is paying the bills.  As long as we're
not in a war, as long as the system doesn't have to solve some real problem, it
is a delightful toy; and as with a model railroad we get to keep arranging the
scenery so it appears to be doing the Real Thing.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Call for Papers - 14th National Computer Security Conference
</A>
</H3>
<address>
Jack Holleran 
&lt;<A HREF="mailto:Holleran@DOCKMASTER.NCSC.MIL">
Holleran@DOCKMASTER.NCSC.MIL
</A>&gt;
</address>
<i>
Sat, 8 Dec 90 23:32 EST
</i><PRE>

 CALL  FOR  PAPERS
 14th NATIONAL  COMPUTER  SECURITY  CONFERENCE
 Sponsors:
 National Computer Security Center and
 National Institute of Standards and Technology

 Theme:  Information Systems Security:  Requirements &amp; Practices

 OCTOBER 1-4, 1991       OMNI SHOREHAM HOTEL       WASHINGTON, D.C.

 The focus of the 14th NCS Conference will be on the "Experiences in our
Applications".  These applications include, but are not limited to, efforts to
meet the policy requirements required by law or corporate policy.  We would
like you to share your learning curve with the Computer Security Community.  We
also encourage submission of papers on the following topics of high interest:

Systems Application
 * Access Control Strategies
 * Achieving Network Security
 * Application of Trusted Technology
 * Integrating INFOSEC into Systems     
 * User Experience with Trusted Systems 
 * Secure Architectures                 
 * Securing Heterogeneous Networks      
 * Small Systems Security     

Criteria, Evaluation and Certification            
 * Assurance and Analytic Techniques
 * Conducting Security Evaluations      
 * Federal Computer Security Criteria   
 * Experiences in Applying Verification 
 * Integrity and Availability           
 * Formal Policy Models

Management and Administration           
 * Accrediting Information Systems and Networks
 * Specifying Computer Security Requirements      
 * Life Cycle Management
 * Managing Risk              
 * Role of Standards                    
 * Preparing Security Plans   

International Computer Security Activities
 * Conformance Test Development and Evaluation
 * Harmonized Criteria
 * International Evaluation Infrastructure
 * Prototype Development
 * Research Activities

Innovations and New Products
 * Approved/Endorsed Products
 * Audit Reduction Tools and Techniques
 * Biometric Authentication
 * Data Base Security
 * Personal Identification and Authentication
 * Smart Card Applications
 * Tools and Technology

Awareness, Training and Education
 * Building Security Awareness
 * COMPUSEC Training:  Curricula, Effectiveness, Media
 * Curriculum for Differing Levels of Users
 * Keeping Security In Step With Technology
 * Policies, Standards, and Guidelines
 * Understanding the Threat

Disaster Prevention and Recovery
 * Assurance of Service
 * Computer Viruses
 * Contingency Planning
 * Disaster Recovery
 * Malicious Code
 * Survivability    

Privacy and Ethical Issues
 * Computer Abuse/Misuse
 * Ethics in the Workplace
 * Laws
 * Privacy and Individual Rights
 * Relationship of Ethics to Technology
 * Standards of Ethics in Information Technology

     We are pleased to invite academic Professors to recommend Student papers
in the application of Computer Security methodology.  Three student submissions
will be selected by the Technical Committee for publication in the 14th NCS
Conference Proceedings.  To be considered, the submission must be solely
authored by an individual student and be recommended by an Academic Professor.
Only one copy for student submission is required.

  BY FEBRUARY 15, 1991: Send eight copies of your draft paper* or panel
suggestions to one of the following addresses.  Include the topical category of
your submission, author name(s), address, and telephone number on the cover
sheet only.  (* Government employees or those under Government sponsorship must
so identify their papers.)

  BY MAY 11, 1991: Speakers selected to participate in the conference will be
notified when their camera-ready paper is due to the Conference Committee.
All referee comments will be forwarded to the primary author at this time.

For additional information on submissions, please call (301) 850-0272.

Mailing Information:
 1.  FOR PAPERS SENT VIA U.S. or Foreign Government MAIL ONLY:

 National Computer Security Conference
  ATTN:  NCS Conference Secretary
  National Computer Security Center
  9800 Savage Road
  Fort George G. Meade, MD 20755-6000

          
    2.  FOR PAPERS SENT VIA COMMERCIAL COURIER SERVICES (e.g.- UPS, FEDERAL
EXPRESS, EMERY, etc.)

 National Computer Security Conference
  c/o NCS Conference Secretary
  National Computer Security Center
  911 Elkridge Landing Road
  Linthicum, MD  21090

  Please note that the US Government Postal System does not deliver to
Elkridge Landing Road.

    3.  FOR Electronic Mail:  
          NCS_Conference@DOCKMASTER.NCSC.MIL   
            (1 copy only; no figures or diagrams)

Preparation Instructions for the Authors
          To assist the Technical Review Committee, the following is required
for all submissions:

Page 1:  Title of paper, submission, or panel suggestion
     Focus &amp; keywords (e.g. - Innovations and New Products - Biometric
                               Authentication, Tools and Technology)
     Author(s)
     Organization(s)
     Phone number(s) 
     Net address(es), if available
     Point of Contact

  Additionally, submissions sponsored by the U.S.  Government must provide the
following information:
  U.S. Government Program Sponsor or Procuring Element
  Contract number (if applicable)
  U.S. Government Publication Release Authority 
    Note: Responsibility for U.S.  Government pre-publication review lies with
the author(s).

  Page 2:  
   Title of paper or submission - do not include author(s) or organization(s)
     Abstract (with keywords)
     The paper (Suggested Length: 8 pages, double columns, including figures
and diagrams; pitch: no smaller than 8 point.)

     A Technical Review Committee, composed of Government and Industry
Computer Security experts, will referee submissions only for technical merit
for publication and presentation at the National Computer Security (NCS)
Conference.  No classified submissions will be accepted for review.

     The Conference Committee provides for a double "blind" refereeing.
Please place your names and organizations on page 1 of your submission, as
defined above.  Failure to COMPLY with the instructions above may result in
non-selection BEFORE the referee process.

     Papers drafted as part of the author's official U.S.  Government duties
may not be subject to copyright.  Papers submitted that are subject to
copyright must be accompanied by a written assignment to the NCS Conference
Committee or written authorization to publish and release the paper at the
Committee's discretion.  Papers selected for presentation at the NCS
Conference requiring U.S.  Government pre-publication review must include,
with the submission of the final paper to the committee, a written release
from the U.S.  Government Department or Agency responsible for pre-publication
review.  Failure to comply may result in rescinding selection for publication
and for presentation at the 14th NCS Conference.

     Technical questions can be addressed to the NCS Conference Committee by
mail (see Mailing Information) or by phone, (301) 850-0CSC [0272].

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.67.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.69.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-42</DOCNO>
<DOCOLDNO>IA013-000136-B030-487</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.69.html 128.240.150.127 19970217041013 text/html 22155
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:08:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 69</TITLE>
<LINK REL="Prev" HREF="/Risks/10.68.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.70.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.68.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.70.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 69</H1>
<H2> Tuesday 18 December 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Computer Models Leave U.S. Leaders Sure of Victory" 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Re: Airline safety 
</A>
<DD>
<A HREF="#subj2.1">
Jim Rees
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
The Incredible Lightness of Reference 
</A>
<DD>
<A HREF="#subj3.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Unexpected effects of PC's 
</A>
<DD>
<A HREF="#subj4.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Long-distance printing, or the risks of being well-known 
</A>
<DD>
<A HREF="#subj5.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Organizational Aspects of Safety 
</A>
<DD>
<A HREF="#subj6.1">
Lance J. Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Covert communication through public databases 
</A>
<DD>
<A HREF="#subj7.1">
Larry Hunter
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Computer Models Leave U.S. Leaders Sure of Victory"
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:JON@GAFFER.RAD.WASHINGTON.EDU   ">
JON@GAFFER.RAD.WASHINGTON.EDU   
</A>&gt;
</address>
<i>
Tue, 18 Dec 1990 10:09:53 PST
</i><PRE>

That's the headline for this story from THE SEATTLE TIMES, Dec. 17, 1990, p. A3:

COMPUTER MODELS LEAVE U.S. LEADERS SURE OF VICTORY by Robert C. Toth,
Los Angeles Times

... Computer models of ground warfare convince the administration it can
deliver on its promise of an overwhelming victory.  An Army assessment of US
and Soviet-made Iraqi equipment --- from tanks to rifles --- shows that the 
United States has an edge in quality to compensate for its numerical
disadvantage. ...

When such assessments are factored into opposing ground-combat units and the
forces are pitted against each other in war games, the conclusion by Pentagon
and many non-government experts seems to be the same: "We'd crush them," said
Joshua Epstein of the Brookings Institution.

Iraqi numbers, including its million-man army, should not be a problem, added
Barry Posen of the Massachusetts Institute of Technology.  "If anything, we
might begin to address the ethical question of how much slaughter you want to
inflict on his forces if war comes." ...

Computer modelling for a ground war is based on assessments of the U.S. Army
War Gaming Agency of the combat value and combat effectiveness of 10 types of 
weapons. ... Effectiveness ratings were determined for (... tanks and ...)
other weapons categories from artillery to small arms.  A rifle is valued at
1.0, a machine gun at 1.77, a 155 mm howitzer at 1.02 and a MLRS rocket system
at 1.16.  (... etc. ...)  

The combat value, or relative weight, of the weapon categories were decided by
a team of experienced battlefield commanders.   Most valuable, they decided,
are attack helicopters, followed by artillery, tanks, scaling down to small
arms. 

When the number of weapons in a U.S. armored division is multiplied by those
effectiveness ratings and their combat value, the resulting total --- about
130,000 --- becomes the Armored Division Equivalent at 1.  All other units can
be measured against that standard.  A U.S. infantry division, for example, is
given an ADE of 0.5, or half an armored division.

Epstein and his associate, Alf Hutter, calculate that all U.S.-led forces in
Saudi Arabia will be valued at 17.6 ADE's by February, when the buildup is
completed.  They calculate that Iraqi forces in Kuwait will be valued at 7.4
ADE's, and those in northern Kuwait and southern Iraq at 9.6 ADE's.

That appears to place opposing forces in balance, but the Iraqi forces are
widely dispersed in defense, offering a challenge of only 2.3 ADE's for U.S.
forces in the "main attack sector."

Epstein's bottom line, based on his modeling, is an 18-day war.  The first six
days would be used for air strikes to establish control and soften up Iraqi 
ground forces.  In the next six days, the ground attack, breakthrough and
movement northward would take place.  The final six days would be used to mop
up.  Casualties would be about 15,000 (with 25 percent dead), he said, although
they could range from 3,600 to 22,000.

Posen said such models understate the U.S. advantage because they do not
reflect the better training, logistic supplies, command and control, and other
qualitative edges.  "We will have total control of the air," he said. ...

U.S. forces wil be able to concentrate at their intended attack point to reach
a jump-off advantage of 5-1, Posen said, because of the U.S. expectation that
Iraqi artillery --- the usual weapon to prevent such concentrations behind
enemy lines --- will be largely wiped out.

"We are very good at counter-battery fire," he said, pointing to special radar
to locate any Iraqi artillery batteries that could then be assaulted with
massive, rapid-fire artillery weapons and the Multiple-Launch Rocket Systems.
One MLRS volley of 12 rockets is supposed to have the same effect as 72 rounds
of 155 mm howitzers.

"In just artillery alone, we figured we could delivery 500 tons of metal
(artillery shells) on his positions in only one hour," Posen said.  "We
astonished ourselves with that figure."

[ And so on.   There were a few caveats: "There are doubters...  skeptics
  remain unpersuaded... experts .... warn that unpredictable events could 
  turn the most modern technological projections into catastrophe ...  - JJ]

- Jon Jacky, University of Washington, Seattle jon@gaffer.rad.washington.edu

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Airline safety
</A>
</H3>
<address>
Jim Rees
&lt;<A HREF="mailto:rees@citi.umich.edu ">
rees@citi.umich.edu 
</A>&gt;
</address>
<i>
11 Dec 1990 14:35 -0500 (Tuesday)
</i><PRE>

In RISKS 10.67, Donald A Norman writes a sermon on the Economist article
concerning airline safety.  He apparently didn't read the article itself and
I wanted to clear up some things.

The suggestions in the Economist article were not advanced by the Economist.
They were from Mr. Earl Weener, safety chief at Boeing.  Weener did not urge
the introduction of a new decision speed.  He said that in two out of three
accidents involving a go/abort decision on takeoff, the decision was wrong.
[ I find this hard to believe, since tossing a coin would give the correct
answer more often.  Maybe he just means the calculated V1 speed was wrong,
not that the decision was wrong. ]

Weener suggests improving the Ground Proximity Warning System (GPWS).  The
current GPWS is apparently not trustworthy, and accidents are caused when
pilots ignore its warnings.  Improving this system to the point where pilots
feel they can trust it seems like a good idea to me.

Boeing's four suggestions -- better estimates of V1, better GPWS, ILS
installed at more airports, and better use of flight data recorders -- all
seem to me to be good ideas, although I also think that Mr. Norman is right
in suggesting that a more comprehensive, systems approach is needed.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
The Incredible Lightness of Reference
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Tue, 11 Dec 90 09:27:53 EDT
</i><PRE>

My article on executives and PC's indicates the issue of Business Week that it
was published in.  Since Business Week is widely available, you can dig up the
original article if you want more details or have doubts about the accuracy of
my quotation.

Or can you?  Like many mass-market periodicals today, Business Week takes
advantage of the flexibility of computer and printing technology to produce
different editions for different audiences.  The article I quoted appeared in
the Bits and Bytes column of the Information Processing section.  That section
is part of the "Information Processing" pages specific to the
"Industrial/Technology" edition that I receive.  It may or may not appear in
other editions; if it does appear, it may appear on different pages, under
different headings, or even on different dates.  Business Week has its own
algorithms for deciding which edition to send you - they don't ask.  (I suppose
if you ask to be receive a particular one, they'll put you on the appropriate
list.)

Anyone who has written an article citing information gleaned from a network
posting knows that traditional citation techniques are not adequate for this
new medium:  Even a citation to a respected, broadly-read moderated list like
RISKS would be very difficult for a traditional librarian to deal with, and
most network postings are evanescent, archived nowhere and impossible to
examine, much less verify, after the fact.

What's slipped in unnoticed is that the same technological mismatch has begun
to apply for the seemingly traditional paper forms.  Today, it's newspapers and
magazines.  Tomorrow, textbooks will be tailored to individual school
districts, individual schools, even individual classes - a technology all the
major textbook producers are working hard at introducing.  Given that
technology, perhaps we'll soon see different editions of novels, even of
non-fiction works, tuned to regional differences in interest, dialect, social
mores, or what have you.

The world network is supposed to be bringing us all together.  In some ways,
however, the same techology is acting to fragment our world:  If everything is
"narrow-cast" to more and more finely subdivided audiences, what do we share?

							-- Jerry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Unexpected effects of PC's
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Tue, 11 Dec 90 09:04:08 EDT
</i><PRE>

	For Many Executives, PC's Mean More Typing -- and Less Managing

	Some computer technology, such as automated teller machines, has
	made life easier.  But in business, that's not necessarily so.
	A Georgia Institute of Technology study found that personal
	computers can make life harder for managers.  The reason?  When
	companies install PC's, they often cut back on support workers.
	So middle managers now spend a third of their time performing
	administrative tasks and only 25% managing, the study found.

	"Companies think they're going to try to pay for technology by
	letting secretaries go," says Peter G. Sassone, the Georgia Tech
	economist who wrote the study.  "But someone has to do the
	typing, filing, and copying."  He says corporate buyers mistakenly
        think PC's can deliver the same degree of productivity improvement 
	that mainframes brought to inventory and payroll jobs in the 1960's. 
        And "computer companies still try to sell that same idea," he adds.

Ten to fifteen years ago, when word processing systems were starting to spread
rapidly, I (and others) pointed out an interesting paradox:  These systems
were sold (and usually bought) as money savers.  The idea was that you could
get more work done with a smaller number of typists.  In practice, the number
of typists was unchanged; what actually changed was the quality (in some often
hard to perceive sense) of the output:  Since making changes was now so cheap,
documents would go through many more revisions.

Well, it took a while but the original "purpose" of that equipment has
reasserted itself - and this time it is being attained by management fiat.

Middle managers are particularly vulnerable since information processing
technology has put so much pressure on them anyway.  (I saw an estimate not
long ago that there are some 25% fewer middle management jobs now than there
were in 1985.)  However, the trend is much broader.  My wife is a lawyer who
made the transition from a large Manhattan firm to an in-house counsel position
for a very large industrial company about a year ago.  One of the changes she
had to adjust to was the lack of support staff: There is one secretary for
three lawyers and several other professionals, and each person is expected to
do most of the word processing for his own jobs.  The comment from a friend -
also a lawyer, but one very involved in the future of the profession - is that
any lawyer starting out today had better learn to use a word processor; it'll
be part of his job within a few years at most.
							-- Jerry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Long-distance printing, or the risks of being well-known
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Sat,  8 Dec 90 16:31:11 EDT
</i><PRE>

In a recent RISKS, Hank Nussbacher reports on printouts that were intended for
a local printer in North Carolina but, due to a one-character error in
specifying the receiving node, were regularly being printed in Israel.  He's
inspired me to write this note, which I've been meaning to get down one paper
for quite some time.

There's an interesting class of risks in computer systems, particularly
networked systems, that I call "the risks of being well known" - though I
suppose "the risks of knowing too well" is better :-).  The underlying problem
is that the ability to easily address and reach a huge number of systems,
without any built-in testing of the reasonableness of requests, can lead to
some very interesting failures.

1.  Digital sells a printer server known as the LPS40.  This is a Postscript
printer you stick on your Ethernet and then print to from a number of other
machines on the net.

In order for your machines to be able to find the printer, you have to give it
a DECnet node name.  In DECnet as it is today, the namespace involved is flat.

The LPS40 documentation had many examples in which the printer was addresses
as node LPS40.  If you don't think things through, and simply type the example
startup commands as given, you will have a series of machines trying to send
output to a printer named LPS40.  This, indeed, happened at a number of sites
at DEC several years ago.

If your local DECnet configuration has never heard of node LPS40, your attempts
to start the software will fail.  However, one of the first LPS40's at DEC,
installed in Hudson, Mass., reserved that name; so it was in the standard
configuration database distributed throughout the company.  As a result, new
sites all over the world found themselves printing files in Hudson.

As it happens, the protocol used for talking to an LPS40 is officially
supported only over Ethernets, and won't work RELIABLY over wide-area nets -
but it will work SOMETIMES.  When I heard this story, the record for
long-distance printing was from somewhere in Georgia.

2.  I'm not sure where I heard the following story; details would be welcome.
The Andrew system, developed at CMU, provides a variety of network file
services.  At first, it was used only at CMU; later, CMU started distributing
it to other universities.  One university got the source code and started doing
local modifications.  Then they found their modifications mysteriously being
removed - the system somehow migrated back to its old state.

Apparently, included with the source package was software to ensure that local
copies of the system stayed up to date.  On a regular (nightly?) basis, the
software checked for local files that differed from those on a "reference"
machine, and brought over "reference" copies if necessary.

Unfortunately, the "reference" machine was hard-coded as some machine at CMU!

3.  Much simpler, but much more widespread:  There have been many reports of
FAX messages inadvertently sent to the wrong destination.
            						      -- Jerry

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Organizational Aspects of Safety
</A>
</H3>
<address>
Lance J. Hoffman
&lt;<A HREF="mailto:hoffman@eesun.gwu.edu ">
hoffman@eesun.gwu.edu 
</A>&gt;
</address>
<i>
Tue, 18 Dec 90 14:07:27 EST
</i><PRE>

RISKS readers might be interested in "Organizational Aspects of Engineering
Safety: The Case of Offshore Platforms" by M. Elisabeth Pate'-Cornell in
SCIENCE Magazine, p. 1210 ff. of 30 November 1990.  It describes how, while
organizational errors are often at the root of failures of critical engineering
systems, engineers tend to focus on technical solutions, in part because of the
way risks and failures are analyzed.  But, for example, in some systems
described, improving design review costs two orders of magnitude less than
adding steel to structures (the technical fix) to gain the same improvement in
reliability.

Prof. Lance J. Hoffman, Dept. of Electrical Engineering and Computer Science,
The George Washington University, Washington, D. C. 20052 (202) 994-4955 

    [Also noted by haynes@ucscc.UCSC.EDU]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Covert communication through public databases
</A>
</H3>
<address>
Larry Hunter
&lt;<A HREF="mailto:hunter@work.nlm.nih.gov ">
hunter@work.nlm.nih.gov 
</A>&gt;
</address>
<i>
18 Dec 90 17:39:19
</i><PRE>

This is not all that new, but I haven't seen discussion of the issue
in RISKS, so I thought I would post excerpts from an interesting
InfoWeek article (26 Nov 1990, pp.12-13):

[A] handful of major airlines - including American, United, Delta, and
TWA - are being sued by almost three dozen plaintiffs who allege that
the airlines use a shared database to "fix" prices and circumvent ...
competition....

The ATPCO [Airline Tariff Publishing Co] database, critics allege, has
become an electronic forum wherein airlines communicate with each
other to keep ticket prices artificially high by discouraging
competitive fares.  A number of techniques are used by the carriers to
signal one another, insiders say; for example, if a regional airline
drops prices on a given route in an effort to boost traffic, a larger
airline may slash fares on its flights in and out of the regional
airline's hub airport, sending a strong signal that it disapproves of
the smaller airline's new fares.  The larger airline's low fares may
remain in effect for only a day or two, but the other airline gets the
message....

One airline spokesman acknowledged that airlines watch the database
and closely respond to competitors' actions, but he calls that "the
dynamics of the industry, not price fixing."

Ian Ayers, a faculty member at the law school at Northwestern
University and a specialist in anti-trust cases, says: "The issue is,
are the airlines just sharing data, or are they going beyond that and
[through the database] talking about what they are going to do about
the data?"

"Back in the good old days," says John Timmons, minority counsel to
the Senate Commerce Committee and a close monitor of the airline
industry, "if you were going to fix the price of something like steel,
you'd make a phone call.  Today, you'd use technology, but to my way
of thinking, it's just like that phone call."...

Lawrence Hunter, PhD., National Library of Medicine, Bldg. 38A, MS-54
Bethesda. MD 20894   (301) 496-9300 hunter%nlm.nih.gov@nihcu (bitnet/earn)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.68.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.70.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-43</DOCNO>
<DOCOLDNO>IA013-000136-B030-511</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.70.html 128.240.150.127 19970217041033 text/html 22286
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:08:56 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 70</TITLE>
<LINK REL="Prev" HREF="/Risks/10.69.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.71.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.69.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.71.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 70</H1>
<H2> Tuesday 18 December 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Telephone Voting 
</A>
<DD>
<A HREF="#subj1.1">
Bill Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Voting Technology 
</A>
<DD>
<A HREF="#subj2.1">
William W. Plummer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: Hacked NASA phones 
</A>
<DD>
<A HREF="#subj3.1">
Barton Christopher Massey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: "Legion of Doom" 
</A>
<DD>
<A HREF="#subj4.1">
Irving Wolfe
</A><br>
<A HREF="#subj4.2">
 Mike Black
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Computer Virus as Military/Political Weapon? 
</A>
<DD>
<A HREF="#subj5.1">
Sanford Sherizen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Request for Info on Undergraduate Computer Security Classes 
</A>
<DD>
<A HREF="#subj6.1">
Al Arsenault
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Telephone Voting
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray.Catwalk@DOCKMASTER.NCSC.MIL">
WHMurray.Catwalk@DOCKMASTER.NCSC.MIL
</A>&gt;
</address>
<i>
Sat, 8 Dec 90 16:23 EST
</i><PRE>

&gt;One risk that I don't think I saw mentioned in the discussion of
&gt;"Dial-A-Vote" systems relates to the identity of voters.

To the contrary, it has been dealt with ad nauseam, usually erroneously.

&gt;Such a system, by definition,  would need to know the identity of each caller
&gt;to check registration and avoid duplications.

This statement is patently false.  While an identity-based system would be
one way to accomplish these objectives, a voucher system would serve just as
well.  Such voucher systems are well described in the literature, but the
same issue of RISKS which carried the above assertion, contained two
descriptions of such systems for voting by mail.

The problem of disassociating the vote from its origin, i.e. location of the
phone, is much more resistant to solution.

All voting systems are subject to abuse, not the least are those systems
currently in use.  All voting systems have some problems of equity.  In
many of our current systems, these problems were deliberately engineered
in for political motives.  These problems resist solution precisely
because any change will shift the political balance, however slightly.

To the extent that we can move to systems that are more secure, more
equitable, and more economic, we should do so.  Such systems clearly
exist.  My personal preference is for more equity.  While I have
difficulty in believing that any new system can be any more subject to
abuse than most of those in use, I would be prepared to sacrifice some
security for more equity, as long as the lower security would not result
in a loss of confidence in the results. 

Any new systems and the move to them will be fraught with problems.
Much dialogue will have to precede any such moves.  However, over-stating the
problems of the new systems, preferring the faults of the old ones, and
pandering to the fears of the ignorant are not productive.  

William Hugh Murray, Executive Consultant, Information System Security
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840   203 966 4769

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
  Voting Technology
</A>
</H3>
<address>
"William W. Plummer" 
&lt;<A HREF="mailto:plummer@altacoma.wang.com">
plummer@altacoma.wang.com
</A>&gt;
</address>
<i>
Mon, 17 Dec 1990 14:09:59 EST
</i><PRE>

I would like to propose a new voting system that will benefit from electronic
and/or cryptographic techniques.  Before going too public with this, I hope to
get additional suggestions and pitfall information from you readers.

The voting system that I would like to see simply weights your vote by the
number of tax dollars that you pay.  We have often heard that the super wealthy
use tax loopholes to lower their tax to zero while manipulating laws to make
this possible.  On the other end of the scale, the poor are accused of using
tax supported services far in excess of their tax payments; the poor tend to
vote for candidates that promise to keep up the handouts.  Of course, it is the
middle income people that support all of this.  So, my scheme has the
appropriate negative feedback built into it.

A major problem with the system is that it require a constitutional amendment.
In other words we would no longer have "One man, one vote."  But I argue that
the Constitution was written before income tax and local taxes etc.  In a sense
everybody was taxed equally back then.  All this new system does is to restore
the equality of the voting power.

Implementing this system is tricky unless you want to trust "the government" to
correctly credit your voting power.  I think the ability to check one's own
account is desired, but you really don't want it to become public knowledge;
worse than busybodies and neighbors would the the targeted marketing concerns
and the politicians spending their resources where the voting power is.  So, a
secret ballot is still a must.	 The ballot must be unforgeable and not
modifiable.

One idea that is almost right is to use public key crypto technology.  The IRS
would issue voting stickers which have the number of votes encrypted such that
only the vote counters could read them.  I would use my stickers by sticking
them to a paper ballot; they could not be removed without destroying them.
This fails because I cannot check that the sticker is worth the number of votes
that I think it should be.

Making the stickers have duplicate information, one that the vote counters can
read and one that I can read, is also almost right.  It's a little impractical
since it requires that I keep a decryption key around so that I can decode my
half of the sticker.  So, everybody has to be assigned a key and everybody has
to avoid losing it.

Does anybody out there know how to do this?  Thanks.

William W. Plummer   Work: 508-967-4870
plummer@wang.com     Home: 508-256-9570

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Hacked NASA phones (<A HREF="/Risks/10.65.html">RISKS-10.65</A>)
</A>
</H3>
<address>
Barton Christopher Massey
&lt;<A HREF="mailto:bart@cs.uoregon.edu ">
bart@cs.uoregon.edu 
</A>&gt;
</address>
<i>
Mon, 10 Dec 90 23:51:56 GMT
</i><PRE>

&gt; [...] computer intruders have stolen some $12 million in free telephone
&gt; service through Johnson Space Center...  That figure was calculated from costs
&gt; of similar break-ins described by law enforcement agents specializing in
&gt; computer crime.

There *must* be some kind of mistake or error here, right?  Imagine this
principle applied to better-understood areas of criminal jurisprudence: "Little
Johnny Nogood has stolen some $2000 worth of goods from the corner store
today...  That figure was calculated from costs of similar thefts described by
law enforcement agents specializing in shoplifting."  Right.  The whole thing
is especially ludicrous in light of NASA's recent report that their whole
yearly phone bill is only on the order of $12 million...

The computer-related risk, IMHO, is that because the law-enforcement community
doesn't understand computer crime, it may be made to seem much more harmful to
its victims and to society than it actually is, and resources that would be
better spent elsewhere will be devoted to stopping it.  This risk is especially
severe in light of the "computer crime experts" who have made a name for
themselves because of the imputed significance of these kinds of cases, and
thus have a vested interest in exaggerating their significance.
                                				    Bart Massey

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Response to article on "Legion of Doom" sentencing (<A HREF="/Risks/10.65.html">RISKS-10.65</A>)
</A>
</H3>
<address>
Irving Wolfe
&lt;<A HREF="mailto:irv@happym.wa.com ">
irv@happym.wa.com 
</A>&gt;
</address>
<i>
9 Dec 90 18:26:16 GMT
</i><PRE>

I, too, am opposed to uninvited access to others' computers.

In <A HREF="/Risks/10.65.html">RISKS-10.65</A>, we have

&gt;Sorry.  I don't buy it.  If I leave my keys in my car with the windows open,
&gt;and you get in and drive off, you're still just as guilty of stealing the car

That is true.  But it is also a crime in some states for you to have left the
keys in the car.  It is written in many insurance contracts, too, that the
insurer will not have to pay you if you have encouraged the theft in this way.

Thus, in this other area of life that you drew an analogy to, your "asking for 
trouble" by making it easy and attractive does indeed reduce or eliminate your 
protection under the law or constitute a punishable minor crime itself.  

&gt; [several posters drew analogies to the crime of "breaking and entering"]

Breaking and entering is a crime that has two parts: "breaking" and
"entering."  If you leave your front door ajar, one need not "break" to
"enter."  If a company leaves the door to its office ajar, it cannot accuse an
outsider found walking down its hallway (doing no harm) of any crime, it can
only tell him to leave.  Since people here seem so fond of analogies, I'll
suggest that to the extent that a company leaves the door to its computer 
system ajar, the breaking and entering analogy fails, and the mere entry of
an outsider would not constitute a crime.

These analogies are silly.  

If we are to have a law in this area, it should be simple:  Attempting to log
into a computer system or otherwise access it without having been explicitly
invited should be a crime whether or not the attempt succeeds and whether or
not any damage was done.  Probably using a normally-public area like an ftp
or anonymous uucp directory should be explicitly excepted, as should a small
number of attempts to log into a system accidentally, provided no hacker-type
activities (systematically guessing passwords, taking advantage of system
defects to gain privileged access, etc.) were involved.

But if this is to be a crime, it is fundamentally unrelated to old-time crimes
like breaking and entering or car theft.  We are making it a crime because
we'd like to discourage it, not because there's a clear moral issue or any
harm being done.  There may or may not be.  The law is for our convenience,
and has no moral side, and the violator is not to be punished for his evil
character, but merely for having violated a well-known law carrying a
well-known penalty.
 
 irv@happym.wa.com (Irving_Wolfe)    Happy Man Corp.    206/463-9399 ext.101
 4410 SW Point Robinson Road,  Vashon Island, WA  98070-7399     fax ext.116
 SOLID VALUE, the investment letter for Benj. Graham's intelligent investors
Information free (sample $20 check or credit card): email patty@happym.wa.com

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Legion of Doom (<A HREF="/Risks/10.67.html">RISKS-10.67</A>)
</A>
</H3>
<address>
Mike Black
&lt;<A HREF="mailto:black@seismo.CSS.GOV ">
black@seismo.CSS.GOV 
</A>&gt;
</address>
<i>
9 Dec 90 13:18:40 GMT
</i><PRE>

In the discussions of the Legion of Doom a few points are raised but
not taken to fruition seeing as how we are talking about a new
technology (relatively new that is).  Allow me to paraphrase:

1.  "The company left its' doors open and that was a criminal act...".
Response: "Leaving your garage door unlocked isn't".  
	Having a phone line into your company is definitely not a criminal
act.  However, if you leave a pile of money on the street and someone steals
it, there isn't a judge in the world who would convict because you did
something a reasonable person wouldn't have done.  The problem crops up when
you come with a new technology that has inherent risks.  What the heck is
a reasonable person...the two guys that invented it?  On hacking, we have
a case where technology allows extremely easy access to computers over phone
lines.  The fact that a company uses this technology does not relieve it of
responsibility to behave as reasonable persons.  The problem is that the
hackers are perceived as a bunch of teenage hoods and they do not suffer from
this technology.  If every time one of them called they got electrocuted, I
assure you that the company would be held liable.

2.  "Leaving my keys in my car is not...".  In most states, leaving the keys
in your car is definitely considered criminal as you are inviting a crime.
Doesn't then hooking an easy access phone line also invite a crime?

3.  "We are in business to do business...".  True, but businesses have a
responsibility to society to ensure their business does not invite criminal
behaviour.

4.  "We shouldn't have to spend time closing known holes...".  If I talked to
your security department they might disagree.  If there are known holes, is
management adequately apprised of the potential for business loss and have they
made a knowledgeable decision to not close them, or do the system managers just
say, "The boss wouldn't understand so I'm not going to tell him"?  Companies
devote massive resources to security and this hacking thing is a new threat.
So is the idea that your competitor could get in and muck about too.  It would
seem that a business shouldn't have to spend a lot of time closing security
holes opened by a product they bought, so me thinks I would complain LOUDLY to
whomever supplied this product to close up the holes.

5.  Finally, let's try and define a reasonable person on this matter:

	1.  When you hook-up a phone line to your computer, a reasonable person
	would expect to get calls from unauthorized users.

	2.  A reasonable person would not expect the simple userid/passwd to
	foil everyone, however the same person should expect that a concerted
	effort not be made to overcome it.  i.e.  If you have userid "root"
	with no password, that's unreasonable, most anything else migrates
	toward reasonableness.

	3.  A reasonable person would assume that one who finally got in would
	do most anything.

	I propose the following:

	1.  All dial-up's contain a warning about the penalties of unauthorized
	entry. (virtually none do, how 'bout a trespass warning people?)

	2.  Entry into such a system would be a misdemeanor.  Retrieval of
	info would be the same.

	3.  Damage caused would upgrade eventually to a felony depending on
	lost business, time to recover, etc.  The trick here is the need to
	prove the hacker was proximate cause to the damage beyond reasonable
	doubt.

P.S.  I personally do not support "hacking".

: usenet: black@beno.CSS.GOV   :  land line: 407-494-5853  : I want a computer:
: real home: Melbourne, FL     :  home line: 407-242-8619  : that does it all!:

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Computer Virus as Military/Political Weapon?
</A>
</H3>
<address>
Sanford Sherizen 
&lt;<A HREF="mailto:0003965782@mcimail.com">
0003965782@mcimail.com
</A>&gt;
</address>
<i>
Mon, 17 Dec 90 22:11 GMT
</i><PRE>

I would like to gather any *hard* evidence that viruses have been used for
political/military purposes.  It is possible that the Jerusalem virus was first
set off to commemorate a Palestinian event but has there been any way to verify
this?  Are there other viruses that have been specifically distributed or
directed to harm a political foe?  It is important to differentiate this type
of attack from someone setting off a virus that contains a political statement
but which is not directed against a particular target. I know that this
differentiation is soft but I am trying to develop an appropriate
categorization.  Any help on this is appreciated.

What got me thinking about this is my work on developing a model of computer
crime trends and development stages.  The current situation in the Persian Gulf
made me wonder about the use of the virus as a political weapon.  Is the virus
a potential "small nation's weapon"?  Can viruses become terrorist surrogates,
disrupting an enemy nation without leaving direct fingerprints (strings?)
traceable back to the ultimate sponsor?  What roles could viruses play in
future small scale intensive conflicts as well as major wars?  Have viruses
been considered in war scenarios that military commands have developed?  The
flap earlier this year about the availability of a small business contract to
develop a virus for the U.S. military may well be part of a larger picture of
computerized warfare joining other threats such as biological and chemical
warfare.

Comments can be posted to me on Risks or sent directly to me at MCI MAIL:  
SSHERIZEN  (396-5782).  This message has also been posted to Virus-L.

Thanks, Sandy 

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Request for Information about Undergraduate Computer Security Classes
</A>
</H3>
<address>
Al Arsenault 
&lt;<A HREF="mailto:arsenaul@usafa.af.mil">
arsenaul@usafa.af.mil
</A>&gt;
</address>
<i>
Thu, 13 Dec 90 13:47:46 MST
</i><PRE>

We are requesting information from any and all colleges about Computer
Security courses offered as part of the undergraduate Computer Science
program.  This information is needed as part of a research project on 
teaching Computer Security.  The goal is to produce a summary of available
courses, to be included in a paper we are writing.

The researchers involved are:

	Alfred Arsenault, Visiting Professor of Computer Science,
and 
	Captain Gregory White, Instructor of Computer Science,

both at the U. S. Air Force Academy.

Specifically, we are seeking answers to the following questions:

	(1) Does your school offer a course in Computer Security as part
of its undergraduate Computer Science curriculum?  If so, what is the 
title of that course?

	(2) If so, is the course required or an elective for Computer
Science majors?
	
	(3) What textbook is being used, if any?

	(4) What are the prerequisites for the Computer Security course?
(Please use descriptive titles, e.g., Operating Systems, rather than 
course numbers or designators.)

	(5) Is the course offered once a year, or every semester?

	(6)  Approximately how many students typically enroll in the course?

	(7) If your institution does not offer an undergraduate Computer
Security course, is there a particular reason?  (e.g., no faculty interest
in teaching such a course; not enough students interested in taking such
a course; no room in the undergraduate Computer Science curriculum for 
another course)

	(8) Who is a point of contact that we can get in touch with if 
we need further information?

As previously stated, we are requesting this information to assist us with
a research effort on "Teaching Computer Security in an Undergraduate Computer
Science Curriculum."  The short-term goal is to develop reasonably accurate
statistics about how many institutions offer Computer Security courses.
Negative responses (i.e., 'my college does not offer a Computer Security
course') are welcome.

We would be happy to send summaries of the responses we receive to anyone
who requests one.

	Please send responses to either:

	Alfred Arsenault:  arsenaul@usafa.af.mil  or
			   AArsenault@Dockmaster.ncsc.mil

	Greg White:  white@usafa.af.mil
		     GWhite@Dockmaster.ncsc.mil

If you have questions, or want more information, we can be reached on the net
at the above addresses; by telephone at (719) 472-3590; or by U. S. Mail at

	Department of Computer Science
	HQ USAFA/DFCS
	U. S. A. F. Academy, CO  80840

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.69.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.71.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-44</DOCNO>
<DOCOLDNO>IA013-000136-B030-547</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.71.html 128.240.150.127 19970217041049 text/html 20998
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:09:17 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 71</TITLE>
<LINK REL="Prev" HREF="/Risks/10.70.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.72.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.70.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.72.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 71</H1>
<H2> Wednesday 19 December 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: "Computer Models Leave U.S. Leaders Sure of Victory"
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  
</A>
<DD>
<A HREF="#subj2.1">
Marcus J. Ranum
</A><br>
<A HREF="#subj2.2">
 Karl Lehenbauer
</A><br>
<A HREF="#subj2.3">
 Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Compass Airlines disrupted by possible computer attack 
</A>
<DD>
<A HREF="#subj3.1">
Sarge
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Punny user interface [anonymous]
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Process control risks discussed in IEEE Software 
</A>
<DD>
<A HREF="#subj5.1">
Andy Oram
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Unexpected effects of PC's 
</A>
<DD>
<A HREF="#subj6.1">
P.J. Karafiol
</A><br>
<A HREF="#subj6.2">
 ark
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Missing reference 
</A>
<DD>
<A HREF="#subj7.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
A semi-folk tale on the risks of being well-known 
</A>
<DD>
<A HREF="#subj8.1">
Daniel P Dern
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Re: the risks of being well known 
</A>
<DD>
<A HREF="#subj9.1">
Scott Schwartz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
Re: Organizational Aspects of Safety 
</A>
<DD>
<A HREF="#subj10.1">
Charlie Martin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re:  "Computer Models Leave U.S. Leaders Sure of Victory"
</A>
</H3>
<address>
Marcus J. Ranum
&lt;<A HREF="mailto:mjr@decuac.DEC.COM ">
mjr@decuac.DEC.COM 
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 00:26:20 -0500
</i><PRE>

	I've always been particularly interested in wargaming, and was really
happy on the occasion I managed to game with a guy who also did occasional work
with Navy wargames systems. His descriptions of how gaming parameters are
derived may have been (I hope!) exaggerated, but I don't think I'd place much
confidence in the results the games give. They may reflect a battle - but it's
more likely the game will reflect the relative lobbying skills of the various
groups who set the parameters. I gather that some arguments put forward run
along the lines of:
	"It's impossible to sink a carrier in this scenario," say the carrier
drivers.
	"Well, ok," reply the submariners, "then the probability of
detecting a sub in case X is only Y%".

	The end result is a game - but does it have anything to do with even
the situation it is supposed to be simulating (which does not address the fact
that in a real war, you are *never* presented with the situation you think you
will be).

	Apparently many of the parameters for weapons systems, etc, are drawn
from manufacturer's specs, and the "actual" combat capability is extrapolated
from published MTBFs, etc. This doesn't always take into account little things
like grains of sand that may skew a value.

	There's also the story of the wargame developed ("Firefight" by Jim
Dunnigan I think it was) for the U.S. Army designed to train in infantry fire
fight tactics. Apparently it was almost impossible by game rules for the OPFOR
to win. (The game has been released as a commercial boardgame, with the values
"fixed" - or "unfixed").

	If you're interested in the subject, there's a pretty good book
entitled, "_War_Games_", by Thomas B. Allen that glosses over the military's
flirtation with game theory. It looks like another sad case of trying to make a
"science" out of something, without having any real scientific way of
quantifying the experimental subject. How *do* you make a meaningful statement
about the result of a battle?

	It sure would be rich if we learn years down the road that some
white-tower theoretical soldiers in the Soviet Union were the REAL driving
force behind perestroika because they couldn't get a 100% win in a conventional
war simulation in Europe, because all their specs were drawn from the malarkey
glossies defense contractors give the Pentagon.
                                                            mjr.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Computer Models Leave U.S. Leaders Sure of Victory
</A>
</H3>
<address>
Karl Lehenbauer 
&lt;<A HREF="mailto:karl@ficc.ferranti.com">
karl@ficc.ferranti.com
</A>&gt;
</address>
<i>
19 Dec 90 09:34:58 CST (Wed)
</i><PRE>

No doubt this article is going to generate a lot of responses.  Peter da
Silva finds this reminiscent of the infamous Club Of Rome models that
assigned pollution to a single numerical value and predicted that we'd
all be dead by now.

Rolling the clock back twenty years or so, had the ADE been around 
we could be fairly certain that the assigned ADE of US Forces in Viet
Nam far exceeded that of the enemy and that, therefore, a quick victory
would be certain.

For a more recent example, consider that the ADE of the USSR forces
in Afghanistan surely exceeded that of the Afghan rebels, yet they lost.

-- uunet!sugar!ficc!karl (wk)

</PRE>
<HR><H3><A NAME="subj2.2">
Risks of believing war game models
</A>
</H3>
<address>
"FIDLER::ESTELL" 
&lt;<A HREF="mailto:estell%fidler.decnet@scfb.nwc.navy.mil">
estell%fidler.decnet@scfb.nwc.navy.mil
</A>&gt;
</address>
<i>
19 Dec 90 10:04:00 PDT
</i><PRE>

A comment on the RISKS-FORUM Digest item of Tuesday 18 December 1990  
RE: "Computer Models Leave U.S. Leaders Sure of Victory" is in order.

1. Computer models are usually naive, or even stupid.  That does NOT
necessarily mean that the one(s) cited in the referenced article were of poor
quality; but it DOES mean that these models do NOT speak for intelligent,
thoughtful PEOPLE - such as Gen. Colin Powell, Sec. Def. Dick Cheney, Senator
San Nunn, etc.

2. How do I know that models are so often naive?  First, I have read much
available literature, from the RAND Corp., the GAO, etc. (e.g., "DOD
SIMULATIONS: Improved Assessment Procedures Would Increase the Credibility of
Results", GAO/PEMD-88-3, Dec. 1987; and "Analysis for Military Decisions", E.S.
Quade, editor, Rand McNally &amp; Co., 1964; and "Handbook of Systems Analysis",
Hugh Miser and E.S. Quade, eds., North-Holland, 1988.  Once you get into these,
follow the trail that the bibliographies give.  Like me, you can focus your
interest, and still read three dozen books and conference papers.)

Moreover, I have used some of the "better regarded" models, including 
one that has been "certified" by the Navy.  (I found and fixed several 
fatal bugs in the code; the model has not since been recertified.)

Finally, I have designed and written and used my own model; it is as "good"
(based on comparison of results) as many of the better known larger, older
models.  I call it "Ape" because it mimics the others.  It is robust and
elegant, but no genius.  In particular, it is subject to the "garbage in
garbage out" syndrome; i.e., if you tell Ape that your aircraft cannot be shot
down by their tanks, Ape will let you do that.  Mother Nature may not; as the
late Richard Feynman noted, She always enforces all of Her rules, even when we
(scientists et al) forget.

3.  In grad school, one my my profs had worked for Getty Oil, as an Ops
Researcher.  He told of the rivalry between the Getty half brothers.  One had
done a "study" to prove something; the other asked my prof to "... prove my
brother wrong."  They ran "their best model" and it said that the other brother
was right; so, they "tuned" the input data and reran the model; and it still
said the other brother was right; so ...  on the 242nd retry, it finally said
that the other brother was wrong.  Remarkably, when these "results" (sans the
history of 243 runs) were presented to J.P. Getty, he believed them, and
cancelled the first brother's plans.  Does DoD *ever* do things like that?  You
read the Wall Street Journal and Aviation Week articles about SDI, B-2, A-12,
etc. and draw your own conclusions.  My invitation to those so sure of success
is, why not go over to Arabia and lead the troops to victory?  You could be a
hero?
                                        Bob

</PRE>
<HR><H3><A NAME="subj2.3">
Compass Airlines disrupted by possible computer attack
</A>
</H3>
<address>
Sarge
&lt;<A HREF="mailto:sarge@batserver.cs.uq.oz.au ">
sarge@batserver.cs.uq.oz.au 
</A>&gt;
</address>
<i>
19 Dec 90 06:27:48 GMT
</i><PRE>

Compass Airlines, a new airline company in Australia (since deregulation
a couple of weeks ago), has reported that there reservation system
was being jammed. On one day alone 25,713 calls had been made.

The Chief Executive suspects a computer was used to repeatedly dial
telephone numbers, which aborted when answered.

Note that they do NOT think any rival airline is involved.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Punny user interface
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
19 Dec 90
</i><PRE>

While reviewing the design of an important control system, I came across the
following (slightly edited):

      "The OK flags are used to request operator input for an operation.  If
      bit 2 is set by the operation, the keyboard control task displays a
      message, eg. OPERATION OK? If the operator types Y (yes), bit 1 is set.
      If (s)he types 9 (no - in German) bit 3 is set."

I don't know the full history of this decision to use "9" to represent "no",
but it seems to me that someone with a fondness for puns and a lack of concern
about the user interface managed to get a little joke included into the
design.  Please don't accuse me of lacking a sense of humour; if I had come
across this in a game program I would have laughed heartily.  But the user
interface to a critical control system must be as clear and understandable as
possible.  An operator wanting to abort an operation should not have to
remember that for this particular system, the opposite of "Y" is "9".

The field of computer programming abounds in little jokes like this.  Some can
actually be useful (eg. the little trash can on the Macintosh screen which
bulges when full) but others are tiresome or actually dangerous.  People who
want to use computers to accomplish an important job should not have to learn
all the "in" jokes of the fraternity of programmers.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Process control risks discussed in IEEE Software
</A>
</H3>
<address>
Andy Oram
&lt;<A HREF="mailto:andyo@westford.ccur.com ">
andyo@westford.ccur.com 
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 10:37:28 EST
</i><PRE>

The following recent article should interest all RISKS readers:

	Leveson, Nancy G., "The Challenge of Building Process-Control
	Software," IEEE Software, 7:6, November 1990, pp. 55-62.

Her subject matter touches on almost every application where a computer
interacts with real-life activities -- including interaction with a user who
supposedly has final control over the situation.  Compared to some posters on
this forum, her premise is an optimistic one: she takes for granted that
computers should be used to control airplanes, factory production, power
plants, etc.  But she's very open about the difficulties of predicting and
handling events.

The article includes some classic examples of computer-aided processes that
went hay-wire.  More significantly, she carefully tries to distinguish
different levels of human and technological risk, and proposes research areas
for dealing with each one.

I'm sure others have read this article, since it's in a major journal.  Since
I'm still a novice in the issues involved, I'd enjoy seeing comments -- please
mail them to andyo@westford.ccur.com.

Andrew Oram, Concurrent Computer Corporation, One Technology Way, Westford, MA
01886 (508) 392-2865                      {harvard,uunet,petsd}!masscomp!andyo

This is not an official statement from Concurrent, but my own opinion;
therefore you can count on having one person who stands behind it.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Unexpected effects of PC's
</A>
</H3>
<address>
P.J. Karafiol
&lt;<A HREF="mailto:karafiol@husc8.harvard.edu ">
karafiol@husc8.harvard.edu 
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 11:55:29 -0400
</i><PRE>

In RISKS 10.59, Jerry Leichter says,

&gt;each [lawyer]  is expected to do most of the word processing for his own jobs.
&gt;The comment from a friend - also a lawyer, but one very involved in the
&gt;future of the profession - is that any lawyer starting out today had better
&gt;learn to use a word processor; it'll be part of his job within a few years
&gt;at most

I find this somewhat hard to believe.  My father is a lawyer at a largish firm,
and, indeed, many of the lawyers do some of their own word processing and are
encouraged to know how to do it *in case of emergency*.  But considering that
the average lawyer there bills in the vicinity of $150/hr (if not more!) and
the secretaries bill $30/hr to the client, most clients would rather the firm
use more secretarial help than have lawyers spend precious time and money word
processing.  Since these billing schedules are even more skewed in the large NY
firms, I hardly think that self-wordprocessing lawyers are going to be a major
trend in the legal profession.
							== pj karafiol

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Unexpected effects of PC's
</A>
</H3>
<address>
&lt;<A HREF="mailto:ark@research.att.com">
ark@research.att.com
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 15:17:14 EST
</i><PRE>

I have a lawyer friend who told me that she is forbidden to use a computer,
word processor, typewriter, or any other similar labor-saving device.  The
firm's rationale is that they charge by the hour.

</PRE>
<HR><H3><A NAME="subj6.2">
Missing reference
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 09:09:12 EDT
</i><PRE>

An article of mine in RISKS 10.69 referred to another article in the same
issue, pointing out the difficulty of tracking down an apparently-solid
bibliographic reference given in the latter.  However, the second article
didn't include the reference!  Apparently it was lost in editing.

For completeness, that reference was:  Business Week, 17 Dec 90, Page 96C/

							-- Jerry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
A semi-folk tale on the risks of being well-known
</A>
</H3>
<address>
Daniel P Dern
&lt;<A HREF="mailto:ddern@world.std.com ">
ddern@world.std.com 
</A>&gt;
</address>
<i>
Tue, 18 Dec 90 22:05:56 -0500
</i><PRE>

Jerry Leichter's (leichter@lrw.com) story on many printers within a network
sharing the same name calls to mind a story I heard back when I was at BBN.
This was in the period when the company was just starting to market/sell packet
networks to commercial customers (i.e., private nets that weren't part of the
ARPA/Internet).  To initialize the IMP (older name for packet switch), the
network installer made a tape from an active ARPAnet machine, and loaded that
into the customer's single node.

I could all but hear this poor lonely packet switch waking up, as it were, and
soliliquizing, "OK, I guess somebody had to restart me.  Let's see who else is
out there, and tell them I'm awake again.  Hello?  Hello?  Is anyone out there?
Hey, where is everybody?  Dagnab, I'm a stub again... say, you don't suppose
that war broke out and I'm the only one left do you?  Ah, here's packets to
handle!  That's a relief.  Yo! Guys!  Anybody home! ..."

Sure, it worked.  But how cruel...

Daniel Dern

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: the risks of being well known (Leichter, <A HREF="/Risks/10.69.html">RISKS-10.69</A>)
</A>
</H3>
<address>
Scott Schwartz
&lt;<A HREF="mailto:schwartz@groucho.cs.psu.edu ">
schwartz@groucho.cs.psu.edu 
</A>&gt;
</address>
<i>
Tue, 18 Dec 90 23:37:53 EST
</i><PRE>

How many machines are there out there named, say, "vax1"?  We have one here.
There is one at the University of Delaware.  I think Digital used to have one.
Now of course these all have their names qualifed so that they are unique, but
if you happen to have a friendly terminal server that caches recently accessed
hosts, and also does name completion, then ``telnet vax1'' may not get you
where you expect to be.

On a related note, psuvax1 hasn't been a vax for many years, but the name has
stayed the same: the machine gateways lots of mail and the system adminstrators
wanted to avoid any surprises.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Organizational Aspects of Safety (Hoffman, <A HREF="/Risks/10.69.html">RISKS-10.69</A>)
</A>
</H3>
<address>
Charlie Martin
&lt;<A HREF="mailto:crm@cs.duke.edu ">
crm@cs.duke.edu 
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 10:22:19 -0500
</i><PRE>

Lance Hoffman noted the SCIENCE article pointing out that the cost of fixing
structural problems in drill rigs is two orders of magnitude greater than the
cost of engineering reviews to catch the problems before construction.  It's
interesting that this is about the same cost saving reported in software
engineering (errors caught early in design versus errors caught during O,E&amp;M).

It looks like "it cost 1/100th as much to do it right as it costs to do
it over" may be a general rule.

Does anyone know of similar cost data in other engineering fields?

Charlie Martin (...!mcnc!duke!crm, crm@summanulla.mc.duke.edu)
O: NBSR/One University Place/Suite 250/Durham, NC  27707/919-490-1966

    [By the way, I noticed yesterday that the ENTIRE Contents section was
    omitted from the distributed version of <A HREF="/Risks/10.69.html">RISKS-10.69</A>.  I added it to 
    the CRVAX archive copy.  Sorry.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.70.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.72.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-45</DOCNO>
<DOCOLDNO>IA013-000136-B030-579</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.72.html 128.240.150.127 19970217041110 text/html 24675
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:09:34 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 72</TITLE>
<LINK REL="Prev" HREF="/Risks/10.71.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.73.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.71.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.73.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 72</H1>
<H2> Wednesday 19 December 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Computer Models Leave U.S. Leaders Sure of Victory 
</A>
<DD>
<A HREF="#subj1.1">
Richard Schroeppel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Re: Voting Technology ...
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  
</A>
<DD>
<A HREF="#subj3.1">
Brian Rice
</A><br>
<A HREF="#subj3.2">
 Jerry Leichter
</A><br>
<A HREF="#subj3.3">
 Michael J. Chinni
</A><br>
<A HREF="#subj3.4">
 Lauren Weinstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Legion of Doom 
</A>
<DD>
<A HREF="#subj4.1">
John Boyd
</A><br>
<A HREF="#subj4.2">
 K. M. Sandberg
</A><br>
<A HREF="#subj4.3">
 Brendan Kehoe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Value of data integrity 
</A>
<DD>
<A HREF="#subj5.1">
Mahan Stephen
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Computer Models Leave U.S. Leaders Sure of Victory
</A>
</H3>
<address>
Richard Schroeppel
&lt;<A HREF="mailto:r@fermat.UUCP ">
r@fermat.UUCP 
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 14:02:12 PST
</i><PRE>

My wife's reaction:  Let's just hope Iraq is running the same simulation.

War Game Vendor, Telephone Support Service:
"Really?  ...  That's awful.  ...  I wonder how that happened. ...
 What version are you running?  ...
 4.1.3?  Oh, yeah, that version has a bug in the enemy tanks.  Give
 me your address, and I'll send you the upgrade to 4.2. ...
 Does who have it?  ...
 Probably; we sent out the upgrades three weeks ago.  You should have
 gotten it by now.  Did you send in your registration card? ..."

Rich Schroeppel                              rcs@la.tis.com

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
The topic that wouldn't die: telephone voting
</A>
</H3>
<address>
Brian Rice
&lt;<A HREF="mailto:rice@dg-rtp.dg.com ">
rice@dg-rtp.dg.com 
</A>&gt;
</address>
<i>
Mon, 17 Dec 90 16:33:50 est
</i><PRE>

&gt;From the Associated Press (appeared in the News and Observer
of Raleigh, N.C., 17 Dec 1990, p. 2B):

"WINSTON-SALEM, N.C.: State elections officials looking
 over November's balloting say voter fraud has tapered
 in recent years to 'tolerable' levels.

"State Elections Director Alex K. Brock says he foresees
 a day when North Carolinians will vote by telephone.
 Their voice patterns will be confirmed and their votes
 tallied by computer. [...]"

Aaack!  These three sentences have got to be the most thoroughly alarming I've
seen with my morning joe in years, even if I ignore the civil-liberties
implications of "tolerable levels of voter fraud," or of making voting
difficult without a phone, or even of the state's having (or thinking it has)
every citizen's "voiceprint."

I 'spec I need to send Mr. Brock some back issues of the RISKS digest.  It's
alarming when a public official seems not at all to have thought about issues
that seem obvious to you and me...and the most recent N.C. elections should
have given him pause, his satisfaction with them notwithstanding.

Many RISKS readers will have been aware of a recent well-publicized race for
office in North Carolina between candidates we'll call A and B.  Now, candidate
A has for quite some years referred to members of a certain ethnic group as the
"bloc vote"--that is, against him--so it was not a surprise when reports
surfaced after the election that members of A's party went to a precinct
heavily populated by members of that ethnic group and methodically challenged
every single voter's right to vote.  This is an involved process, involving
signatures of elections officials, sealed ballots, etc.; obviously this takes a
while, and enormous delays were created, mitigating turnout.

I'm refraining from naming the candidates, parties, and ethnic groups involved
because I'm not trying to make political hay (yes, I worked for B), because
these reports have not been confirmed, and because the party-A folks were
acting within the letter of the law.  Nonetheless, Mr. Brock apparently hasn't
heard the phrase "denial-of-service attack."  Sigh.

Brian Rice, DG/UX Product Assurance Engineering Data General Corp., Research
Triangle Park, N.C.  rice@dg-rtp.dg.com     +1 919 248-6328

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Voting Technology
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 09:39:00 EDT
</i><PRE>

William Plummer asks about cryptographic technology for implementing secure
voting.  (He also includes a long ramble about weighting voting by amount of
taxes paid, a social and political issue that is completely independent of
the technology used to implement elections.)

There are, in fact, algorithms to implement such votes.  There are some very
general algorithms allowing groups of mutually-distrustful people to reach a
common decision.  (One way such problems get posed in the theory community is
as follows:  The members of a millionaire's club are curious as to which of
them is the wealthiest.  However, they are also jealous of their privacy, so
none is willing to reveal his actual wealth to any of the others.  Devise an
algorithm which will indicate which of them is the wealthiest, but which will
reveal no other information about their wealth to anyone.  Solutions to this
problem exist.  They are quite non-trivial!)

An algorithm designed specifically for voting was described in Josh Benaloh's
PhD thesis.  (Yale, 1987 or 88 I think.)  In Benaloh's basic algorithm, we
assume a central government and a public, broadcast network.  People vote by
posting various encrypted messages on the network.  The protocol provides two
guarantees:  No voter can determine another voter's vote; the government
cannot fake the outcome (i.e., any voter can look at the published data and,
if the government cheated, determine that fact).

In the basic algorithm, the government can read anyone's vote.  From this
basic algorithm, Benaloh goes on to show how to get by without a trusted
government - essentially, one can split the government's responsibilities up
among a number of independent agents in such a way that only the collusion of
ALL the agents would allow a vote to be read.  (The idea is that you would
choose to do your voting through the Democratic, Republican, and Libertarian
Party clearing-houses, plus for good measure the ACLU and the NRA, figuring
that if ALL of them are allied against you, there's not much point in worrying
about trivialities like vote privacy.)

Finally, Benaloh shows how to construct an election which reveals only the
minimum of information:  Who won, but nothing at all about the vote totals.

Again, the techniques involved are mathematically quite sophisticated.  (They
are closely related to RSA, but not identical to it.)  They are all "efficient"
in the theoretician's sense (polynomial time), but not (yet?) practical for a
real, large election.

If you want further information, at last word mail to benaloh@cs.yale.edu was
still being forwarded.
							-- Jerry

</PRE>
<HR><H3><A NAME="subj3.2">
 Re:  Voting Technology
</A>
</H3>
<address>
"Michael J. Chinni, SMCAR-CCS-E" 
&lt;<A HREF="mailto:mchinni@PICA.ARMY.MIL">
mchinni@PICA.ARMY.MIL
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 13:05:05 EST
</i><PRE>

&gt;From "William W. Plummer" &lt;plummer@altacoma.wang.com&gt;:
&gt; 	The voting system that I would like to see simply weights your vote
&gt; by the number of tax dollars that you pay.  We have often heard that the
&gt; super wealthy use tax loopholes to lower their tax to zero while manipulating
&gt; laws to make this possible.  On the other end of the scale, the poor are
&gt; accused of using tax supported services far in excess of their tax payments;
&gt; the poor tend to vote for candidates that promise to keep up the handouts.
&gt; Of course, it is the middle income people that support all of this.  So, my
&gt; scheme has the appropriate negative feedback built into it.

	Yeah, negative feedback. TO MUCH NEGATIVE FEEDBACK.
	The MAJOR problem with your scheme is that government under it would
only represent those with the most money (the rich).  If your plan was made
law, I foresee the rich changing their tax-status and doing their tax-returns
so that they are taxed the most. This gives them enough votes to elect ANYONE
they want.  Regardless of the votes of everyone else.  This then makes our
country no longer a democracy ruled by the will of the majority, but a country
ruled by a priviledged few (kind of what england was like before the Magna
Carta or what South Africa is like now). What possible results would this have
for the non-priviledged few. Results like:
	result				why
	no labor laws			costly (gives the employee more money
					and hence more voting power)
	no financial aid for college	costly (more smarts and people might
					realize that they have effectively no 
					say in the way they are governed)
The idea being that everything that has made the life (working and private) of
the middle and lower classes better, that is funded by the government or was
made possible only by government regulation, would be done away with if it
interfered with what the rich wanted.
	End result - the rich get richer and more powerful and 
		     the middle and lower classes become one class - the lower
			class

&gt; 	A major problem with the system is that it require a constitutional
&gt; amendment. In other words we would no longer have "One man, one vote."  But I
&gt; argue that the Constitution was written before income tax and local taxes
&gt; etc.  In a sense everybody was taxed equally back then.  All this new system
&gt; does is to restore the equality of the voting power.
	Back then it wasn't so much as tax equality as it was to insure that
those being governed had an effective way to decide how they would be governed.

(insert standard disclaimer here)               ...!uunet!pica.army.mil!mchinni
Michael J. Chinni, Simulation Techniques and Workplace Automation Team, US Army
Armament Research, Development, and Engineering Center, Picatinny Arsenal, NJ

</PRE>
<HR><H3><A NAME="subj3.3">
telephone voting
</A>
</H3>
<address>
Lauren Weinstein
&lt;<A HREF="mailto:lauren@vortex.com ">
lauren@vortex.com 
</A>&gt;
</address>
<i>
Tue, 18 Dec 90 18:50:53 PST
</i><PRE>

In a recent digest, a contributor quoted (without attribution) from an original
Risks message of mine which pointed out some potential problems with
"Dial-A-Vote" systems--particularly in regards to identity issues.  He used
phrases such as "patently false" and "pandering to the fears of the ignorant",
and seemed to feel that other messages pointing out ways to do physical mail
voucher voting invalidated the concerns.

I'd like to point out that my original message was clearly oriented
*specifically* toward the issues of telephone-based voting systems.  I was not
discussing physical mail-based systems.  The author admitted that the issue of
disassociating the vote from its origin in a telephone-based system was a
serious problem.  That's the whole point of my original message!  Given the
realities of modern telephone technology, there is no way for users of such a
system to be sure that their telephone number, and thus their address, has not
been tagged by the voting system.  Even if the system doesn't need to
differentiate among voters in a multi-voter household, the simple capability of
automatically correlating vote with voter location should trigger the Risks
alarm bells.  Anyone who thinks that significant numbers of voters will bother
to vote from payphones (assuming such is possible) to avoid such problems is
dreaming!

Finally, I don't consider pointing out these concerns to be "pandering to the
ignorant".  Even when there is a theoretical way to do the job right (which
isn't always the case), the way the job may actually be done may not avail
itself of the correct techniques, in the interests of time, money, or other
factors.  Unfortunately, it's all too easy for such systems to be made to "sell
to the gullible", particularly when attempts are made, however benignly, to
minimize discussion of the potential problems involved.
                                                             --Lauren--

</PRE>
<HR><H3><A NAME="subj3.4">
Re: Response by Legion of Doom
</A>
</H3>
<address>
John Boyd;CRENP
&lt;<A HREF="mailto:johnboyd@logdis1.oc.aflc.af.mil ">
johnboyd@logdis1.oc.aflc.af.mil 
</A>&gt;
</address>
<i>
Wed Dec 19 10:29:41 1990
</i><PRE>

&gt;Date: 9 Dec 90 18:26:16 GMT
&gt;From: irv@happym.wa.com (Irving Wolfe)
&gt;Breaking and entering is a crime that has two parts: "breaking" and
&gt;"entering."  If you leave your front door ajar, one need not "break" to
&gt;"enter."  If a company leaves the door to its office ajar, it cannot accuse an
&gt;outsider found walking down its hallway (doing no harm) of any crime, it can
&gt;only tell him to leave.  

Isn't this trespassing?  If I arrive home with an armload of groceries,
unlock the front door, take say, three steps and set the groceries on the
floor, and turn to lock my door and find you standing in my living room,
you'll stand a good chance of either getting your butt kicked or shot!

From: black@seismo.CSS.GOV (Mike Black)

&gt;3.  "We are in business to do business...".  True, but businesses have a
&gt;responsibility to society to ensure their business does not invite criminal
&gt;behaviour.

And don't people in general have a responsibility to society to behave in
acceptable, legal ways?  'The devil made me do it' was never a defense.  So
far, I don't think the phone companies have been sued as being a party to
bookmaking operations.


&gt;5.  Finally, let's try and define a reasonable person on this matter:
	

&gt;1.  When you hook-up a phone line to your computer, a reasonable
&gt;person would expect to get calls from unauthorized users.

And a reasonable person would expect the company that wrote the software to
have made _reasonable_ efforts to defeat entries by those unauthorized
users (hard-core, criminal hackers notwithstanding).  But then, they've 
already taken themselves off the hook with those legalese non-warranties.

               johnboyd@ocdis01.af.mil            

  Disclaimer - If I express an opinion, the Air Force will deny I know
               what I'm talking about.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Response to "Legion of Doom" (Wolfe, <A HREF="/Risks/10.70.html">RISKS-10.70</A>)
</A>
</H3>
<address>
K. M. Sandberg
&lt;<A HREF="mailto:sandberg@ipla01.hac.com ">
sandberg@ipla01.hac.com 
</A>&gt;
</address>
<i>
19 Dec 90 16:37:46 GMT
</i><PRE>

&gt;Breaking and entering is a crime that has two parts: "breaking" and
&gt;"entering."  If you leave your front door ajar, one need not "break" to
&gt;"enter."  If a company leaves the door to its office ajar, it cannot accuse an
&gt;outsider found walking down its hallway (doing no harm) of any crime, it can
&gt;only tell him to leave.  Since people here seem so fond of analogies, I'll
&gt;These analogies are silly.  

How about trespassing? Actually breaking and entering is a good analogy because
most computer systems do have a lock, the passwords and accounts, but they are
not very strong, like houses. To have not password would be like leaving the
door unlocked, but how many companies do this? Cars are also the same, dare you
say that leaving a nice car around where someone can see it it causing an it to
be stolen? The solution: get rid of everything that might attract someone. Is
this what you want?

Just how strong of a lock must you have before you are no longer accused
of making it easy for someone to break in?

&gt;If we are to have a law in this area, it should be simple:  Attempting to log
&gt;into a computer system or otherwise access it without having been explicitly
&gt;invited should be a crime whether or not the attempt succeeds and whether or
&gt;not any damage was done.  Probably using a normally-public area like an ftp
&gt;or anonymous uucp directory should be explicitly excepted, as should a small
&gt;number of attempts to log into a system accidentally, provided no hacker-type
&gt;activities (systematically guessing passwords, taking advantage of system
&gt;defects to gain privileged access, etc.) were involved.
&gt;
&gt;But if this is to be a crime, it is fundamentally unrelated to old-time crimes
&gt;like breaking and entering or car theft.  We are making it a crime because
&gt;we'd like to discourage it, not because there's a clear moral issue or any
&gt;harm being done.  There may or may not be.  The law is for our convenience,
&gt;and has no moral side, and the violator is not to be punished for his evil
&gt;character, but merely for having violated a well-known law carrying a
&gt;well-known penalty.

I'm sorry, but I do think that breaking in to a computer has a moral side.
People should take responsibility for their own actions and know that something
is wrong and not just because of a law. Society can not, nor should not in my
opinion, make a law for every possible thing that can or will be done. A person
has to be reasonable and for someone to say that they did not think that
breaking into a computer system (getting around the password protection at
least) was not wrong is being unreasonable, besides if they didn't think it was
wrong, why do they hide the fact that they are doing it?

On the computer systems I have been responsible for I have put a notice
on login "Unauthorize access is prohibited", which makes it clear that
unless you are authorized, you don't belong on the system. Even use
by employees can be questioned if they use the system for non-work
related things that impact the system, but this is not the intent.

						Kemasa.

It would be interesting if people would listen to what they are saying,
but then again others are not listening either, so why should they?

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Response to article on "Legion of Doom" sentencing
</A>
</H3>
<address>
Brendan Kehoe
&lt;<A HREF="mailto:brendan@cs.widener.edu ">
brendan@cs.widener.edu 
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 14:34:29 GMT
</i><PRE>

In Risks digest 10.70, Irving Wolfe (irv@happym.wa.com) wrote:

&gt; Attempting to log into a computer system or otherwise access it
&gt;without having been explicitly invited should be a crime whether or
&gt;not the attempt succeeds and whether or not any damage was done.

  How in the world would such a thing be enforced? Agreed, you'd have to give
leeway for the cases like ftp/uucp, accidental attempts, etc.  But trying to
word such a law would be sheer hell -- the number of loopholes that'd be
created would far outweigh the number of benefits.  For example: just last
night, someone tried to log in as root through FTP to one of my machines. How
would this fall under these guidelines?  It's an FTP session, so it's got the
shadow of "exempt" hanging above it. But wait! It was an attempted login to
*the* privileged account, right? True. But the person could easily say they
were root on their own machine (assuming it was the same person) and they just
hit &lt;Return&gt; at the name: prompt before they realized what they were doing, and
subsequently were stuck with logging the FAILED LOGIN message. A really messy
situation.

  I completely agree that there should be some sort of law concerning this
issue, even moreso in recent months (with the # of attempted logins from
unrestricted terminal servers on the rise). But trying to make such a law real
would be dangerously close to constantly monitoring every connection for
anything that some "objective party" deems suspicious.

&gt;But if this is to be a crime, it is fundamentally unrelated to old-time crimes
&gt;like breaking and entering or car theft.  We are making it a crime because
&gt;we'd like to discourage it, not because there's a clear moral issue or any
&gt;harm being done.  There may or may not be.

  Exactly. We're trying to take a law that restricts walking pets in the park
and make it apply to bringing your adorable scorpion "Spike" for a little jaunt
down the block.

     Brendan Kehoe - Widener Sun Network Manager - brendan@cs.widener.edu

</PRE>
<HR><H3><A NAME="subj4.3">
Value of data integrity
</A>
</H3>
<address>
&lt;<A HREF="mailto:Mahan_Stephen@lanmail.ncsc.navy.mil">
Mahan_Stephen@lanmail.ncsc.navy.mil
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 10:16:00 CST
</i><PRE>

     I have a few thoughts on the ideas expressed [in <A HREF="/Risks/10.66.html">RISKS-10.66</A>?] about "no
damage being done by an unauthorized user".

     The data in a computer has value.  This applies to software under 
development, experimental records, financial records, and almost all 
other forms of electronically recorded data.  

     A large part of the value of the data lies in the knowledge of the
integrity of the data and the confidence placed in the data as a result.  If an
unauthorized used has gained the ability to change the information in the
computer then REGARDLESS of whether any information was actually changed the
degree of confidence in this information is necessarily lessened.

     Restoring the original level of confidence in the data will require some
finite amount of effort, whether restoring from backups, reconstructing,
comparing against old printouts, or other techniques.  The amount of effort
depends on the value of the data and the willingness to accept a lesser
confidence level, as well as other implementation dependent details.

     Viewed in this respect, unauthorized access to the system does result in
losses to the owners of the system whether or not any alteration of the
information took place.

     These are my opinions only and do not necessarily represent any 
other person or organization.

Stephen Mahan, Naval Coastal Systems Center, Panama City, FL  32407-5000

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.71.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.73.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-46</DOCNO>
<DOCOLDNO>IA013-000136-B031-26</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.73.html 128.240.150.127 19970217041126 text/html 21496
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:09:53 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 73</TITLE>
<LINK REL="Prev" HREF="/Risks/10.72.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.74.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.72.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.74.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 73</H1>
<H2> Friday 21 December 1990 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
*** HAPPY HOLIDAYS *** 
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
HERO - Hazard of Electromagnetic Radiation to Ordnance 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Washington (state) E-mail Privacy Suit 
</A>
<DD>
<A HREF="#subj3.1">
Peter Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Process control risks discussed in IEEE Software 
</A>
<DD>
<A HREF="#subj4.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: "Computer Models Leave U.S. Leaders Sure of Victory" ...
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  
</A>
<DD>
<A HREF="#subj6.1">
P.G. Capek
</A><br>
<A HREF="#subj6.2">
 Jerry Hollombe
</A><br>
<A HREF="#subj6.3">
 Neil Galarneau
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Risks of Automated Collections and a Happy Ending 
</A>
<DD>
<A HREF="#subj7.1">
L.J. Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: The topic that wouldn't die: telephone voting 
</A>
<DD>
<A HREF="#subj8.1">
Gregory G. Woodbury
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
HERO - Hazard of Electromagnetic Radiation to Ordnance
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.El_Segundo@Xerox.com">
Hoffman.El_Segundo@Xerox.com
</A>&gt;
</address>
<i>
Fri, 21 Dec 1990 13:47:30 PST
</i><PRE>

Summary of a 30-column-inch article in the Dec. 21, 1990 'Los Angeles Reader'
(see final paragraphs below):

   WORLD'S MOST ADVANCED ARMY IS IN DANGER OF ZAPPING ITSELF

   The Hazard of Electromagnetic Radiation to Ordnance,
   Or, How an Electronic Accident Could Ignite a Gulf War

   By Patricia Axelrod and Capt. Daniel Curtis (USAF Ret.)

HERO, a feature of the electronic battlefield the Pentagon prefers to keep
secret, can launch a rocket or crash a plane without warning.  During the
Libyan air strike, it caused an American fighter bomber to crash and
accidentally bomb friendly embassies and residences.

USAF Col. Charles Quisenberry says electronic emissions from US weapons "were
interfering with each other" in the Libyan attack, and that "we did it [the
mishaps] to ourselves."  He also blames HERO for a series of UH-60 Black Hawk
Army helicopter crashes.

Quisenberry is conducting a classified 3-year study of HERO called the Joint
Electromagnetic Interference Study -- JEMI.  Quisenberry says preliminary JEMI
findings are that combinations of US weapons transmitting radio waves at
certain frequencies can bring down an aircraft by putting it into an
uncommanded turn or dive or by turning off its fuel supply.

The Pentagon classifies the electroexplosive device (EED), as especially
HERO-prone.  The EED is used universally throughout the weapons industry as a
fuse trigger, activating everything from artillery to nuclear missiles.
Charles Cormack, Navy EED specialist, claims that the EED has caused 25 weapons
accidents, but civilian experts believe that there have been many more.
Defective wiring such as "Kapton," which can cause HERO, is reported to be used
on more than 50 types of aerospace vehicles.

Among many possible HERO-caused accidental firings, explosions, bombings,
crashes, etc., a worst case scenario might be the accidental explosion of a
Tomahawk or other nuclear device.  The electromagnetic pulse following such an
explosion could then trigger HERO chain reactions.

   - - - - [end of article summary]

The 'Los Angeles Reader' is a weekly give-away not generally known for its hard
news coverage, nor for any attempt at "balance" in its stories.

At the end of the article I've excerpted, an editorial note says it "is based
on ... findings extracted from personal interviews ... government and military
documents, accident and mishap reports released through the Freedom of
Information Act, and newspaper and journal articles, and expert research
papers.  It was made possible in part by a grant from The John D. and Catherine
T. MacArthur Foundation ... for Research in Peace, Security and International
Co-operation."

    [Los Angeles Readers not to be confused with Los Angeles Raiders,
    who have a newly regained electromagnetic pulse each week.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
WA E-mail Privacy Suit
</A>
</H3>
<address>
Peter Marshall
&lt;<A HREF="mailto:peterm@halcyon.UUCP ">
peterm@halcyon.UUCP 
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 09:32:40 PST
</i><PRE>

&gt;From Jim Simon, "Computer Privacy at Issue in Suit," THE SEATTLE TIMES,
9/17/90, D1:

  Like thousands of other state employees, Ron Collins figured the confidential
computer messages he sent...couldn't be read by his bosses or anyone else.
  He figured wrong.
  The agency[Labor &amp; Industries]in what officials say was an unprecedented
monitoring of a state employee's private computer files, secretly retrieved and
copied Collins' "electronic mail" messages as part of an investigation into
whether he was improperly using state computers.  In turn, Collins and the
Washington Federation of State Employees filed suit last week...alleging the
agency violated state privacy statutes, including those preventing wiretapping
or other electronic surveillance without a court order....  the Collins case is
already attracting national attention....
  "We're in an era where every advance in technology means that each case like
this brings us to the next frontier of privacy laws," says Sharon Beckman, an
attorney for the...Electronic Frontier Foundation....  Collins...came under
scrutiny in June after a supervisor noticed a message written by him on an open
computer screen.  Joe Dear, director of labor and industries, said the message
prompted such concern that the agency--after getting approval from the state
attorney general's office--had the Department of Information Services retrieve
all of Collins' messages in early June....  
  Union officials said workers were never told the system couldn't be used for
personal messages. They note that the use of electronic mail--a system known as
PROFS and used by 3,000 state employees--requires a password....  "I think this
is going way overboard, way too intrusive," said Gary Moore, head of the state
employees union....  
  Collins' suit is one of a handful of of similar cases around the nation....
The problem, many observers say, is that privacy laws designed for telephones
and telegraphs are being made obsolete by telecommunications advances.  Privacy
advocates around the nation have battled against caller-identification
telephone programs, and observers say voice-mail systems could wind up as
susceptible to employer snooping as E-mail....  The American Civil Liberties
Union has sought federal laws preventing employers from monitoring employees'
private computer files. And Dear concedes the Collins case should prompt
agencies to write more explicit rules....

[Update: ...and, indeed, just that appears to be in the works now in Olympia,
the state capital. With the lead taken by the Dept. of Information Services,
who had no relevant rules in place before the Collins case, the Gov.'s Cabinet
is developing rules expected to take final form in an Executive Order. The
Collins case, however, is still in process.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Process control risks discussed in IEEE Software (Oram, <A HREF="/Risks/10.72.html">RISKS-10.72</A>)
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@murphy.ICS.UCI.EDU">
nancy@murphy.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 15:47:19 -0800
</i><PRE>

  Compared to some posters on this forum, [Leveson's] premise is an optimistic 
  one: she takes for granted that computers should be used to control 
  airplanes, factory production, power plants, etc.  But she's very 
  open about the difficulties of predicting and handling events.

I guess I wasn't very clear in my Nov 90 IEEE Software article.  Actually, I am
more of a cynic than an optimist -- I take for granted that computers will (vs.
should) be used in process-control and try to present some research topics that
need to be addressed (it was an invited paper on challenges for the 90's).

An article that deals more directly with software safety and techniques to try
to reduce risk will appear in the February issue of CACM (it was supposed to
appear side-by-side with and as an alternative viewpoint to Dave Parnas'
article last May but somehow got delayed in press).

nancy leveson

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re:  "Computer Models Leave U.S. Leaders Sure of Victory"
</A>
</H3>
<address>
Peter G. Capek 
&lt;<A HREF="mailto:CAPEK@YKTVMT.BITNET">
CAPEK@YKTVMT.BITNET
</A>&gt;
</address>
<i>
Wed, 19 Dec 90 23:07:24 EST
</i><PRE>

A colleague used to have a sign on his office wall which said roughly:

   "A model is an artifice for helping you convince yourself that you
    understand more about a system than you do."

Enough said.

Peter Capek -- IBM Research

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"Computer Models Leave U.S. Leaders Sure of Victory" (<A HREF="/Risks/10.69.html">RISKS-10.69</A>)
</A>
</H3>
<address>
The Polymath
&lt;<A HREF="mailto:hollombe@ttidca.tti.com ">
hollombe@ttidca.tti.com 
</A>&gt;
</address>
<i>
20 Dec 90 01:57:12 GMT
</i><PRE>

A friend of mine (name omitted for his protection) is a contract programmer who
worked on one of these models for over 5 years.  It's his opinion that parts of
the model had been deliberately tweaked to "tell the generals what they want to
hear." i.e.: That their equipment works as advertised, so they'll win.  Model
results can then be used to justify purchase of more of the same equipment.

If things continue as they are, we may well find out if it matters in the real
world.

Jerry Hollombe, Citicorp(+)TTI 3100 Ocean Park Blvd.  Santa Monica, CA 90405
(213) 450-9111, x2483 {csun | philabs | psivax}!ttidca!hollombe

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: "Computer Models Leave U.S. Leaders Sure of Victory"
</A>
</H3>
<address>
Neil Galarneau
&lt;<A HREF="mailto:neil@progress.com ">
neil@progress.com 
</A>&gt;
</address>
<i>
Thu, 20 Dec 90 14:44:30 GMT
</i><PRE>

An excellent book on the topic that has come out recently is Peter Perla's
            _The Art of Wargaming_

The book deals with both the military and commercial sides of the topic.
He mentions some problems the Japanese had in wargaming the Battle of Midway,
for example.

Neil

P.S.  For those who are curious, the referee of the wargame (a Japanese
admiral) pointed out to the Japanese team that although they had won, they had
no plans for dealing with the American fleet if it was north-west(?) of Midway.

Due to cryptanalysis, guess where we were? :-)

</PRE>
<HR><H3><A NAME="subj6.2">
Risks of Automated Collections and a Happy Ending
</A>
</H3>
<address>
Lance J. Hoffman
&lt;<A HREF="mailto:hoffman@eesun.gwu.edu ">
hoffman@eesun.gwu.edu 
</A>&gt;
</address>
<i>
Thu, 20 Dec 90 13:52:29 EST
</i><PRE>

     Recently, I had a run-in with my bank which had a happy ending.  The
letters between me and it are self-explanatory, so, without further ado:

LETTER FROM ME TO BANK ON NOVEMBER 28, 1990:

Mr. (name deleted)
President
(bank name and address)

Dear Mr. (name deleted):

     I am a professor of computer science at The George Washington University.
I want to thank you for giving me an example of an insensitive and
counterproductive computer-aided system to discuss with my classes.  Let me
explain.

     Yesterday evening, I received a telephone call at approximately 6:50 p.m.
from your credit collection department.  A human operator asked for me and
then, when I identified myself, played a taped message asking me to pay my Visa
bill (account number (deleted), after which the connection was broken.

     The tape stated that my account was overdue, despite the fact that when I
called two days ago, I was told it was current.  I had been away for a month or
so and when I returned last week I immediately mailed in the complete payment
for the old overdue bill and then, a day later, I mailed in a complete payment
for the newly arrived and current bill.  Since I received an overdue notice in
the mail early this week and a(nother) phone call from a human on my recording
machine, I called back.  By that time, you must have received one of my
payments at least, since I was told (three days ago) that my account was
current!

     At about 9:50 a.m. this morning, I talked with Ms. (name deleted) of your
customer service department.  She was pleasant, understanding, volunteered that
I had a valid point, and knew how the system operated.  (That's where I got the
bank president's name -- LJH) According to her, if a bill is not paid by me by
the 17th of a month, I will get a recorded call from the Collections system,
even if my payment is received in the intervening time.  (Your bank) obviously
doesn't care enough to fax to the human operator who initiates the call a list
of "late pays, now current", and would rather have people like me tell my
friends horror stories about (your bank).

     I don't enjoy having my dinner interrupted by taped messages, especially
when your right hand apparently doesn't know what your left hand is doing.
Whatever bozo put in this telephoning system should be demoted, after being
called at dinnertime every day for a month.  He or she would have been lucky to
pass with a low D any system design course I taught!

     I have now stopped telling my friends about the 1% rebate (a definite plus
for your Visa card); they can give their business to whatever bank they want,
as far as I am concerned.

     I think your action is especially uncalled for since my record in the past
is exemplary in paying my bills, including yours.  I think you owe me an
apology.  Moreover, I think your recording may violate harassment provisions of
the Fair Credit Reporting Act or some other federal law; by copy of this
letter, I am asking my attorney for a quick opinion.

     To date this year, I have written $(amount deleted) in checks to your bank
in payment of my Visa bills:

(I inserted a transaction log here, generated by Quicken)

     I think such a customer deserves more consideration than your "system"
gives him, and I hope you take steps to change it.  

Sincerely,

Lance J. Hoffman

c: (name deleted), Manager, Collections
   (name deleted), Supervisor, Customer Service
   (name of a friend who is an attorney), Esq.

* * * * BANK'S RESPONSE DATED DECEMBER 13, 1990, RECEIVED DECEMBER 20, 1990

Dear Mr. Hoffman:

Your letter to (bank president) has been referred to me as I am directly
responsible for the Collections Department. ...

[The Collection Recording System's] scheduling of the recorded call is
designed to allow sufficient time for our customers to submit a payment
before their account reaches 30 days past due. ...

The taped messages were scheduled to be made on November 19th, 20th, and
21st.  Regrettably, our processor (which type?!-LJH) did not begin calling
until November 27th. ...

Your letter has prompted us to reanalyze the entire program.  As stated
earlier its purpose is to serve as a friendly reminder for payment.  Its
(sic) obvious, however, that any delays that may occur in the future will
only serve to offend our good customers such as yourself.  Therefore, we've
decided to phase out the Collection Recording System within the next three
months.

I sincerely apologize ...

(name deleted)
Group Vice President
(bank) Card Center


It's nice to see that sometimes one well-aimed missive can change things.

Professor Lance J. Hoffman, Department of Electrical Engineering and Computer
Science, The George Washington University, Washington, D. C. 20052 202-994-4955

</PRE>
<HR><H3><A NAME="subj6.3">
Re: The topic that wouldn't die: telephone voting
</A>
</H3>
<address>
Gregory G. Woodbury
&lt;<A HREF="mailto:ggw%wolves@cs.duke.edu ">
ggw%wolves@cs.duke.edu 
</A>&gt;
</address>
<i>
Thu, 20 Dec 90 19:28:05 GMT
</i><PRE>

Brian Rice notes that the Directory of the NC State Board of Elections
forsees a day when big brother will have everyone marked by voiceprint.

Fortunately, not all of the folks here are going to take his comments
seriously.  The NC legislature has to make any changes to the system and
they are NOT inclined to trust technology.

A few years back, the NC House of Representatives installed an
electronic voting system in response to public pressure to provide more
accountability.  It has taken them nearly 10 years to get used to it.

As for the challenging of all votes by a certain candidates workers in
some precincts:  the process of challenging a voter in NC is specific
and costly.  An incorrect challenge costs the challenger cash and
personal court appearances when the challenge is overturned.

Following the severe problems with the machines in Durham and Guilford
counties, there have been all sorts of stories trying to account for why
these two counties had all the problems.  The latest reports that I have
heard from the Durham BoE confirmed my earlier report that these two
counties had some specific changes in the way the voting machines were
to be programmed that were not anticipated as leaving the machines
vulnerable to jamming.

In both counties, there was ONE independent candidate for a partisan
office that had a relatively full slate in each of the two main parties.
In this case it seems that the way the machines are physically linked in
the back had only one long and inadequate lever connecting the third row
to the interlock section.  Voting for a full complement in the main
parties and then also selecting the independent candidate would spring
the interlock section for that race and render the machine unuseable
until the mechanics could get there and unjam the machine.

In my precinct, we spotted the inoperative machines very quickly and
quit using them until they could be fixed.  In other precincts it was
reported that the malfunctions were not noticed until several voters
had used the malfunctioning machines.

There are rumours that this jamming may have been deliberatly caused by
some (unknown) party's instructing voters how to jam the machines, but 
there is no confirmation of this that I am aware of.

Gregory G. Woodbury @ The Wolves Den UNIX, Durham NC ggw%wolves@mcnc.mcnc.org
UUCP: ...dukcds!wolves!ggw ...mcnc!wolves!ggw

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.72.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.74.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-47</DOCNO>
<DOCOLDNO>IA013-000136-B031-59</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.74.html 128.240.150.127 19970217041142 text/html 35384
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:10:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 74</TITLE>
<LINK REL="Prev" HREF="/Risks/10.73.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.75.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.73.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.75.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 74</H1>
<H2> Thursday 3 January 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Vicious elevator door failure recovery 
</A>
<DD>
<A HREF="#subj1.1">
Curtis Jackson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Dehumanization by old Cobol programs; how to get more junk mail 
</A>
<DD>
<A HREF="#subj2.1">
Darrell Long
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Computer data putting history out of reach 
</A>
<DD>
<A HREF="#subj3.1">
Jay Elinsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Computer Age Causes Key U.S. Data To Be Lost Forever 
</A>
<DD>
<A HREF="#subj4.1">
Joe A. Brownlee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: computer "warfare" 
</A>
<DD>
<A HREF="#subj5.1">
John Abolins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: "Computer Models Leave U.S. Leaders Sure of Victory"...
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  
</A>
<DD>
<A HREF="#subj7.1">
Jeff Griffen
</A><br>
<A HREF="#subj7.2">
 David Holland
</A><br>
<A HREF="#subj7.3">
 John C Slimick
</A><br>
<A HREF="#subj7.4">
 David Wright
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Trojan in MS-DOS 4.01? 
</A>
<DD>
<A HREF="#subj8.1">
John Chapman Flack
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Re: Organizational Aspects of Safety 
</A>
<DD>
<A HREF="#subj9.1">
Nick Szabo
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
A RISKy video store kiosk 
</A>
<DD>
<A HREF="#subj10.1">
R. Aminizade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
Call for papers, VDM '91 
</A>
<DD>
<A HREF="#subj11.1">
Hans Toetenel
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Vicious elevator door failure recovery
</A>
</H3>
<address>
Curtis Jackson
&lt;<A HREF="mailto:jackson@adobe.UUCP ">
jackson@adobe.UUCP 
</A>&gt;
</address>
<i>
2 Jan 91 22:48:02 GMT
</i><PRE>

While vacationing in Honolulu last week, my fiance and I had the misfortune to
run into a very vicious failure recovery mode in an elevator in our hotel.  As
near as I could tell, the elevator doors did not have the usual leading-edge
vertical strip which, when depressed horizontally, causes the doors to open so
as not to crush a person or appendage.  Instead, this function was relegated
entirely to an "electronic eye" beam.

One particular elevator was malfunctioning -- closing only partially before
jerking open as if someone had broken the beam.  But regardless, if the doors
on any elevator attempted to close for four times without success due to the
beam being broken (or due to a faulty perception that the beam was being
broken), it would buzz loudly as it closed the doors slowly and completely.
During this final closure, presumably to prevent someone from standing in the
doorway and monopolizing the elevator on one floor, the doors would close
regardless of what the electronic eye told them.  I tested this by placing my
shoulder between the doors (an action that normally always opened the doors
because I broke the beam), and the doors continued to close onto my shoulder
and then made a meaningful attempt to crush my shoulder.  The DOOR OPEN button
had no effect when the elevator was in this close-at-all-costs recovery mode.

My first thought was what would happen to someone who slipped on the doorsill
of the elevator and injured themselves.  The doors would attempt to close
several times, then buzz at the poor sod as they attempted to crush him/her in
the doors.  Even if the elevator had not been programmed to ignore the beam in
this mode, I would still find the lack of a physical means to override the door
closure (the traditional leading-edge strip) to be a severe safety hazard.

Curtis Jackson @ Adobe Systems in Mountain View, CA  (415-962-4905)
                                    uucp: ...!{apple|decwrl|sun}!adobe!jackson

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Dehumanization by old Cobol programs; how to get 4x as much junk mail
</A>
</H3>
<address>
Darrell Long 
&lt;<A HREF="mailto:darrell@sequoia.ucsc.edu">
darrell@sequoia.ucsc.edu
</A>&gt;
</address>
<i>
Wed, 26 Dec 90 10:29:14 PST
</i><PRE>

My dear mother blessed (or perhaps cursed) all of her children with two middle
initials, in my case "D" and "E".  This has caused me a good deal of trouble,
as you can imagine.

It seems that TRW (and now we learn Lotus) sells certain parts of you credit
information, such as your name and a demographic profile.  Well, I recently
got a new credit card from Gottchalks and found to my chagrin that my name
had been truncated to "Darrell D. Long".  I went to the credit manager and
patiently explained my situation, and was assured that things would be fixed
and they were very sorry etc, etc.

Well, two things happened: I got a new credit card, this time as "Darrell E.
Long", and TRW now has an annotation in my file to the effect "File variation:
middle initial is `E'".  Soon after this I start getting mail for "Darrell E.
Long" (along with the usual "Darrell Long" and "Darrell D. Long" and the
occasional "Darrell D. E. Long").

I called up the credit bureau and it seems that the programmer who coded up the
TRW database decided that all good Americans are entitled to only one middle
initial.  As the woman on the phone patiently told me "They only allocated
enough megabytes [sic] in the system for one middle initial, and it would
probably be awfully hard to change."

I know I'm not the only one with more than one middle initial -- of my 
european friends have several.  I wonder what they do with a name like
"Ananthanarayanan", do they randomly truncate it?  -- I suppose I should my
friend.

I'm afraid it's going to get worse before it gets better though.  With Lotus'
product such name mutilation will only spread.                             DL

Dr. Darrell D. E. Long, University of California at Santa Cruz

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Computer data putting history out of reach"
</A>
</H3>
<address>
"Jay Elinsky" 
&lt;<A HREF="mailto:ELINSKY@YKTVMZ.BITNET">
ELINSKY@YKTVMZ.BITNET
</A>&gt;
</address>
<i>
Wed, 2 Jan 91 14:11:38 EST
</i><PRE>

This is an excerpt, extracted by Charlie Hart in IBM Raleigh and appended to
the IBM internal NEWSCLIP FORUM, from an article with the above title from the
Raleigh News &amp; Observer 1/2/90 (Associated Press):

* A slice of American history has become as unreadable as Egyptian hieroglyphics
  before the discovery of the Rosetta stone.
* More historic, scientific and business data in danger of dissolving into a
  meaningless jumble of letters, numbers and computer symbols.
* Americans pay billions to collect the data and may pay millions more to
  preserve it.
* Much information from past 30 years stranded on computer tape from primitive
  or discarded systems - unintelligible or soon to be so.
* Detection of disease, environmental threat or social shift could be delayed
  because data was lost.
* Examples:
  - 200 reels of 17 year old Public Health Service tapes were destroyed last
    year because no one could find out what the names and numbers on them meant
  - Agent Orange task force unable to use Pentagon's tapes containing date,
    site, and size of every herbicide bombing in Vietnam.
  - Extensive record of U.S. WW II vets exists only on 1600 reels of microfilm
    of computer punch cards - no money or manpower to return data to computer.
  - Census data from the 1960s &amp; old NASA data exist only on old tapes - some
    may have decomposed; others may fall apart if run through the balky
    equipment that survives from that era.
* Director of National Archives states it would take 25 years to process 20
  years of old data if money and manpower existed.
* One of the biggest headaches is sloppy record keeping - no written record of
  programs or data formats. "Generally it's the last thing you do and pay the
  least attention to" according to assistant Census director Gerald Cranford.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"Computer Age Causes Key U.S. Data To Be Lost Forever"
</A>
</H3>
<address>
jbr@cblph.att.com 
&lt;<A HREF="mailto:j.a.brownlee">
j.a.brownlee
</A>&gt;
</address>
<i>
3 Jan 1991  14:43 EST
</i><PRE>

[text of the same article read by the previous contributor deleted ...] 

While the risks of storing important data on media with short life-spans or in
undocumented formats are fairly obvious, I suppose that it should not be a
surprise that the U.S. government is having such problems.  After working at
companies that do government work and seeing the many rules in place to
``protect'' the American taxpayers, this is almost predictable.  Because of the
procurement process and the length of time it takes to solicit proposals and
bids for a system, often by the time the implementation begins, the requirements
can be several years old -- a long time for computer systems.  Changing
requirements to be more reasonable can mean up to a year of red tape.  Also,
the government has been known to buy some rather non-standard systems.

All in all, this is a rather startling article when you consider the type and
amounts of important data that are probably already lost forever.

Joe Brownlee, Analysts International Corp. @ AT&amp;T Network Systems, 471 E Broad
St, Suite 1610, Columbus, Ohio 43215; (614) 860-7461 E-mail: jbr@cblph.att.com

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: computer "warfare"
</A>
</H3>
<address>
John Abolins
&lt;<A HREF="mailto:jabolins@well.UUCP ">
jabolins@well.UUCP 
</A>&gt;
</address>
<i>
Tue, 1 Jan 91 20:41:21 pst
</i><PRE>

In <A HREF="/Risks/10.70.html">RISKS-10.70</A>, Sanford Sherizen wrote...
 
&gt; I would like to gather any *hard* evidence that viruses have been used for
&gt; political/military purposes.
&gt; It is possible that the Jerusalem virus was first set off to commemorate a  
&gt; Palestinian event but has there been any way to verify this?
 
The best person to speak for the virus case at Hebrew University in early 1988 
would be Y. Radai.  In BITNET e-mail "chats" with him in 1988, Radai 
emphasized that the virus was NOT politically motivated.
 
Unfortunately, the claim of political origins was circulated in various
reports, including an article in the New York Times.  The author of the New
York Times article had claimed that the Friday May 13, 1988 (when the virus
would wreck many files) was connected to May 14, 1988 , the 40th anniversary of
the establishment of the State of Israel.  The author, thus, interpreted May
13, 1988 as the "last day of Palestine".  (More correctly, it was the last day
of the BRITISH Palestine Mandate.)  For the Middle East (where when something
goes "boom", many hands reach for a phone to claim the act), it was too "cool".
No individual or group claimed credit for this virus. No messages were embedded
in the code.  The only reason people outside of the Middle East interpreted the
virus as a political act was that 1) it was causing problems for an Israeli
institution, 2) some computers used by Mossad were allegedly also affected by
the virus, and 3) it happened in the Middle East so near Israel's 40th
anniversary.  By this reasoning, any auto accident or heart attack in
Washington, DC must be politically caused. :-)
 
Sanford Sherizen continues...
 
&gt; Are there other viruses that have been specifically distributed or
&gt; directed to harm a political foe? ...
&gt; Is the virus a potential "small nation's weapon"?  Can viruses become
&gt; terrorist surrogates, disrupting an enemy nation without leaving direct
&gt; fingerprints (strings?) traceable back to the ultimate sponsor?  What roles
&gt; could viruses play in future small scale intensive conflicts as well as
&gt; major wars?
 
While it is possible that unreported cases with actual political origin exist,
the reported substantiated cases of political attacks against computers have
been physical, not logical. For example, the bombings of computer facilities in
Europe.  By these trends, it would look that most computer related attacks will
be against the hardware or against the people working with the computers
themselves.
 
I said "by these trends" because there is no guarantee that those trends will
hold out forever.  The physical means have been favored because they are
spectacular, producing fear in the general society, and playing well in the
media.  Computer "warfare" is more difficult to exploit because to many people
the effects of a virus are abstract. (A newscaster try to describe a virus
grabs less attention than fire and blood.) But as societies of the West and
many other areas of the world become more dependent upon computers, computer
may be more enticing targets.
 
The most enticing aspect of computer targets is the quality of civilization
that terrorism most seeks to destroy: trust. (Although many people talk about
computer errors and bugs, how many people actual stop using credit cards, ATMs,
airlines, etc.?)  A savvy group could exploit the computer environment to erode
trust in a society's systems. Gumming up the works of financial systems, air
traffic controls, etc. could make people uneasy about commerce or travel. It is
also possible for a group to attack a very specific types of system (military,
government, etc.) for the purpose of incapacitation pure and simple.  One of
the difficulties in this type of attack is the ability to get a suitable virus
on suitable targets.  In most cases, it would take someone getting inside (or
being able to get an unwitting person to get the code inside). This aspect
increases the possibility of detection.
 
Another possibility is general harassment. Just letting more generalize
computer viruses go their way.  This mode is hard to detect as evidenced by the
difficulty in tracing down virus writers in general. This mode is good for
discouraging people from sharing files but, as seen from the past two years of
non-political viruses, not all that disruptive. (And even profitable for some
software companies. ;-] )
 
Regarding the possibility of viruses as a "small nation's weapon", it does
exist.  However, similar possibilities exist for other weapons, especially
biological.  By various reports, a simple biological arsenal (nothing exotic)
could be started for much less cost than most aircraft or armored vehicles. Or
chemicals, in crude way, could be used. (The old "LSD in the city's water
supply" scenario.)  Fortunately, for one reason or another (perhaps human
inertia), these thing have not yet happened.
 
By the way, making a computer virus can be done by one person.  Thus, the 
usual indicators of offensive development (eg.; satellites photos of 
installations, movement of materials and personnel, etc.) may be nonexistent. 
Lest one dismisses the possibility of some Third World group being "smart 
enough" to produce a computer virus, many terrorist or partisan groups have 
better educated people than popular stereotypes claim. Also, since a computer 
virus can be easily transferred on disk, tape, etc., the virus can be produced 
practically anywhere. And it does not require a member of the group or even 
sympathetic to it.  False flagging is always possible by convincing a 
technically competent person that the code is being made for another cause, 
one favored by the person.
 
With computer technology, an important change occurs in terrorism/partisan
warfare: an individual might be able to inflict continuous harm beyond the
capabilities of groups using tradition methods. The reason for this is that
with groups, the risk of infiltration, defection, disclosure, etc. increase
with the number of members.  THe advantage of groups is the  people resources.
But if a terrorist is skilled with certain technologies and chooses to use
them, counter measures may be much more difficult.
 
In my thoughts about such possibilities for computer viruses, I prefer to move
away from the usual category of "terrorism" and use the broader category of
"partisan conflict". Partisan conflicts can include conflicts not usually
considered as warfare or terrorism but, nonetheless could involve computer
viruses. Such conflicts could be those involving animal rights, tax protest,
abortion, etc. (In short, anything that draws intense conviction and
sentiment.)
 
But in many of these partisan conflicts, computers may be used in generally
legitimate applications such as communications services (eg.; BBS's), desktop
publishing, etc.  In some case, computer "warfare" could occur in the form of
using computers to monitor opponents or targets, to increase the effect of
black propaganda" and forged materials (eg. fake pamphlets in the name of the
target group), possibly to plant misinformation in institutional systems.
 
Viruses as a terrorist tools might be more attractive to Third World
entities on the basis that "blowback" is of less danger than for 
industrialized entities. That is, entities that don't have computers don't 
have to worry about the virus affect their systems. Their main problem is the 
access to the technology to make the virus in the first place.
 
One of the chief disadvantages with viruses for such warfare is the danger of 
side effects.  For example, indiscriminate disruption of a country's military 
C3I could lead to firing of weapons in panic with unpredictable results.  
Also, the disrupted C3I may be part of the same system that is need to give 
orders for surrender and negotiations.  Considering these things, perhaps, a 
nihilistic partisan group may be more likely to unleash computer viruses. 
(Just as a group that has no goals and just wants to inflict harm may be more 
partial to biological agents.)
 
J. D. Abolins   301 N. Harrison Str. #197   Princeton, NJ 08540  USA 
jabolins@well.sf.ca.us                                  609-633-0740

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: "Computer Models Leave U.S. Leaders Sure of Victory"
</A>
</H3>
<address>
Griffen
&lt;<A HREF="mailto:griffenj@ncube.com ">
griffenj@ncube.com 
</A>&gt;
</address>
<i>
Mon, 24 Dec 90 11:52:50 PST
</i><PRE>

In the June-July 1990 issue of Fire &amp; Movement (a wargamer's magazine),
there is a _Forum_ section with several articles from various authors
regarding battlefield simulation as practiced by the US armed forces.

Probably the most applicable article of these is "The Right Tool Wrongly
Used", by Eric M. Walters.  In it, he mentions that the simulations and
wargames used by the armed forces are regularly modified "in order to
achieve training objectives," and not necessarily to promote realism.

He mentions several examples, such as the modification of a rule allowing 
M60A1 tanks to engage - in force - with enemy vehicles at ranges over 3Km.
Walters (Captain in US Marines) states that while hits are possible at
those distances, the number of hits in a real war against a "thinking,
moving enemy" would be statistically insignificant.  The tanker lobby won.

I'll close with the following quote from the article:

  ...Red Force electronic warfare is reduced or eliminated because its
  success causes a complete breakdown in exercise force command and
  control (with a corresponding "loss of staff training time"); and so on.
  Thus, game "reality" is molded to accommodate Blue Force plans and
  intentions - not vice versa.

- Jeff

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
re: "Computer models leave U.S. leaders sure of victory"
</A>
</H3>
<address>
David Holland
&lt;<A HREF="mailto:achilles@pro-angmar.UUCP ">
achilles@pro-angmar.UUCP 
</A>&gt;
</address>
<i>
Mon, 24 Dec 90 01:57:35 EST
</i><PRE>

Someone referred to the wargames undertaken by the Japanese prior to the
battle of Midway; I quote, from _Miracle_At_Midway_, by Gordon W. Prange,
Penguin Books, 1983, ISBN 0 14 00.6814 7:
 
     Ugaki presided with a firm hand, and carried through this grandiose scheme
  on tabletop with a sunny lack of realism. As he sincerely believed that no
  situation could exist in which the Japanese would not be in complete control,
  he allowed nothing to happen which would seriously inconvenience the smooth
  development of the war games to their predestined conclusion. He did not
  scruple to override unfavorable rulings of other umpires.  (Ch. 4, pg. 31.)
 
Also:
   
      [Ugaki] cautioned Nagumo that the possibility of an enemy breakthrough
  must be taken into consideration. Yet Ugaki himself promptly nullified any
  good his warning might have done. For during the table maneuvers, the
  theoretical American forces broke through and bombed Nagumo's carriers while
  their aircraft were away from their mother ships attacking Midway - the very
  situation which had concerned Ugaki. Lieutenant Commander Masatake Okumiya,
  the umpire, ruled that the enemy had scored nine hits, sinking both _Akagi_
  and _Kaga_. But Ugaki would not suffer such *lese majeste*, and immediately
  overruled Okumiya, allowing only three hits, with _Kaga_ sunk and _Akagi_
  slightly damaged. And later, when conducting the second phase practice, he
  blandly resurrected _Kaga_ from her watery grave to participate in the New
  Caledonia and Fiji invasions.  (Ch. 4, pp. 35-6)
 
Now, considering that all that took place 48 years ago, without any computers,
where all the participants could see and understand the workings of the
simulation, how much worse will it be in the Pentagon - after all, even if all
the generals understand the RISKS of computer simulations, they *still* don't
know what algorithms are being used and can't tell if the computer has been
engaging in this sort of fudging.
 
All I can say is I hope they don't have to learn the hard way.
 
David A. Holland  pro-angmar!achilles@alphalpha.com  aeneas@blade.mind.org

</PRE>
<HR><H3><A NAME="subj7.2">
re: "Computer models leave U.S. leaders sure of victory"
</A>
</H3>
<address>
John C Slimick 
&lt;<A HREF="mailto:slimick@unix.cis.pitt.edu">
slimick@unix.cis.pitt.edu
</A>&gt;
</address>
<i>
26 Dec 90 20:54:09 GMT
</i><PRE>

The usual reference to the wargaming in the Imperial Navy during the planning
of the Midway operation was that on one roll of the dice, the value indicated
that the attack force would lose three aircraft carriers.  The attack force
team immediately appealed to the referee that such an event was impossible. The
referee agreed and apparently the next toss was more acceptable. Note: in
reality, the attack force lost four carriers.

This is usually cited as an example of the "Victory Disease" that swept over
Japan from 1940 through late 1942, where everyone was convinced that the war
was won and the Japanese forces were the best (and that's why they won) and so
on.  My own interpretation is that such games can produce the desired results,
and that little has changed since early 1942.

John Slimick, University of Pittsburgh at Bradford   slimick@unix.cis.pitt.edu

</PRE>
<HR><H3><A NAME="subj7.3">
Re: "Computer Models Leave U.S. Leaders Sure of Victory"
</A>
</H3>
<address>
David Wright 
&lt;<A HREF="mailto:wright@stardent.com">
wright@stardent.com
</A>&gt;
</address>
<i>
Sat, 29 Dec 90 14:26:28 EST
</i><PRE>

This discussion caused me to recall the professor in my simulation course,
circa 1980.  He had consulted for the Army and was extremely skeptical of some
of their simulation work.  To paraphrase his words, "They use a computer model
that runs for a week and then provides a single number as an answer.  How can
you possibly have any confidence in that?"

David Wright, Stardent Computer Inc                      uunet!stardent!wright

</PRE>
<HR><H3><A NAME="subj7.4">
Trojan in MS-DOS 4.01?
</A>
</H3>
<address>
John Chapman Flack 
&lt;<A HREF="mailto:76066.1006@compuserve.com">
76066.1006@compuserve.com
</A>&gt;
</address>
<i>
31 Dec 90 21:06:03 EST
</i><PRE>

After replacing one SCSI host adapter with another, I found that I was unable
to boot my system from my SCSI disk.  Knowing that changing host adapters
should have no effect on the accessibility of data on a SCSI device, I decided
to boot from my original MS-DOS 4.01 distribution diskette (OEMed by AST
Research).

I popped the diskette in the drive and hit reset.  The system beeped, accessed
the diskette, and, without warning or pause, formatted my hard disk.  (It
ordinarily presents a menu offering to install DOS on a disk or diskette, or to
exit to the command level).

After going through the required stages (disbelief, denial, anger, guilt,
restoration from backups), I experimented to learn what had happened.  When the
DOS installation program first gets control, it checks to see if there is a
hard disk.  If there is a disk, and it has no partition set up (as would be the
case with a new system), the familiar menu is presented.  If the user chooses
to install DOS on the hard disk, the program creates a partition table, and
then forces a reboot so the table will be loaded.

If, on bootstrap, the program sees a hard disk which is PARTITIONED but not
FORMATTED, it assumes it is continuing the process above.  So, without any
further interaction with the user, it formats the disk and copies the DOS
system files onto it.

Changing the host adapter of course has no effect on the data maintained by the
drive and its controller.  However, SCSI devices are addressed by logical block
number, and the IBM BIOS disk functions use physical cylinder, head, and sector
numbers, so each host adapter needs to map the actual logical addresses into
fake physical addresses, and different adapters have different algorithms for
doing that.  The disk, whose fake physical layout appears to have changed (but
with data intact), evidently looks to the install program like a partitioned
but unformatted disk.

It's easy to see why the installation program was designed as it was.  On the
other hand, the documentation nowhere mentions that the program might format
the disk without consulting the user.  (In fact, the only references in the
installation instructions to formatting the disk *at all* is an instruction to
see the Command Reference manual for information on how to format a disk, and
the line "once your hard disk is formatted and partitioned correctly, SELECT
completes the installation of MS-DOS...."

So the "feature" meets the definition of a Trojan horse, and in destructive
power ranks right up with the biggies (loss of all hard disk data).  And it
could have been easily avoided with the addition of "Continue the Install
process by formatting the disk (Y/N)?"

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Organizational Aspects of Safety (<A HREF="/Risks/10.71.html">RISKS-10.71</A>)
</A>
</H3>
<address>
Nick Szabo 
&lt;<A HREF="mailto:szabo@sequent.uucp">
szabo@sequent.uucp
</A>&gt;
</address>
<i>
28 Dec 90 23:31:53 GMT
</i><PRE>

Charles Martin proposes the rule, "it costs 1/100th as much to do it right as
it costs to do it over."

Often (most of the time?), nobody knows with 100% certainty what is "right".
Where knowledge is lacking, and cannot be inexpensively obtained, doing it over
-- and over and over again, until it is right -- may be far cheaper and faster
than trying to do it right the first time.

Nick Szabo			szabo@sequent.com

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
A RISKy video store kiosk
</A>
</H3>
<address>
&lt;<A HREF="mailto:r.aminzade@lynx.northeastern.edu">
r.aminzade@lynx.northeastern.edu
</A>&gt;
</address>
<i>
Thu,  3 Jan 91 14:18:15 EST
</i><PRE>

Last weekend I went to the newly-opened Empire Video store here in Burlington,
VT.  Empire uses both standard classifications like comedy, sci-fi, foreign,
and clever classifications like "feel-good", "tearjerkers" "Bogart", etc.  This
made it hard to find a film we were looking for.  Knowing that most of these
stores have a computerized database to help find titles (and show which are
currently out), I looked around.  sure enough, I found a kiosk with paper
catalogs, books of movie reviews, and a CRT aimed out at the floor, clearly for
customers.  The terminal was off, but we found the ON switch.

"It's broken," said my friend.  Sure enough, the machine was displaying only a
'&gt;' prompt.  Hmm.  I tried "DIR".  No luck.  "ls" didn't work either.  Tried
several other UNIX, VAX, and DOS commands.  EXIT seemed to work!  It put me
into a menuing system...but it didn't seem to list films, it looked like the
entire store-management database!

Before I could stop myself, I had looked up my file information (nothing
overdue, can't remember if they had my VISA card number, but I think they did)
.  I wandered around a bit until I realized that I was doing something
not-very-ethical.  I turned the machine off before checking which of my
neighbors had checked out dirty movies.

Sure Hope the next person to turn on the CRT and try some random commands
thinks through the ethical implications.  I'll talk to the store manager this
week.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Call for papers, VDM '91
</A>
</H3>
<address>
Hans Toetenel
&lt;<A HREF="mailto:winfabi@dutrun.tudelft.nl ">
winfabi@dutrun.tudelft.nl 
</A>&gt;
</address>
<i>
3 Jan 91 14:52:37 GMT
</i><PRE>

                               Call for Papers 
                                   VDM '91 
                      Formal Software Development Methods 
			Noordwijkerhout, The Netherlands 
                              October 21-25, 1991 

This symposium is the fourth in a series addressing model-oriented
approaches to formal software specification and development. The first
three symposia concentrated on specification and design notation and
techniques, featuring approaches such as VDM and Z.

The fourth symposium, VDM '91, will concentrate on formal *development*.
It will be organised as two days of tutorials and three days of conference,
with two parallel tracks throughout: one dedicated to practice, and one
dedicated to theory. The symposium will also include tools demonstrations.

After many years of research into and application of model-oriented
methods like VDM, Z, RAISE and B, the time is now ripe to record facets
of development in more detail, as well as the role of formal development
methods in the larger context of problem domain modelling, software
engineering, tool development and management. One can identify a spectrum
of formality offered or required by various methods, as well as a set of
paradigms and principles, such as invent-and-verify, transformation, and
design-calculi. 

On this basis, papers (to be fully refereed) are welcomed in the following
and related areas:
- stepwise development of architectural requirements
- stepwise development of software designs
- development by transformation
- data reification
- rigorous justification
- proof of correctness
- recording of validation and verification conditions
- links between formal development and pragmatic aspects of software
  engineering (such as requirements tracing, version control, configuration
  management, change request control, test case generation and validation)
- principles of support tools

Also, project reports , recording industrial experience and ongoing tool
development and research are welcomed.

Important dates:                           Program Committee   
  
Submission deadline:                       Patrick Behm (France)   
   March 1, 1991                           Andrzej Blikle (Poland)   
                                           Hans Langmaack (Germany)   
Notification of acceptance:                Peter Lucas (U.S.A.)   
   June 17, 1991                           Soeren Prehn (chairman) (Denmark) 
                                           Hans Toetenel (The Netherlands)
Camera ready papers due:                   Jim Woodcock (U.K.)   
   August 16, 1991    

Please direct all mail and inquiries to: Hans Toetenel, Delft University
of Technology, Faculty of Technical Mathematics and Informatics, PO Box 356,
NL-2600 AJ Delft, The Netherlands; E-mail: toet@dutiab.tudelft.nl.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.73.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.75.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-48</DOCNO>
<DOCOLDNO>IA013-000136-B031-81</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.75.html 128.240.150.127 19970217041157 text/html 20209
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:10:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 75</TITLE>
<LINK REL="Prev" HREF="/Risks/10.74.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.76.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.74.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.76.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 75</H1>
<H2> Monday 7 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
NY area fiber-optic telephone cable severed; extensive effects 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
British military information stolen 
</A>
<DD>
<A HREF="#subj2.1">
Charles Bryant
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Wargames and Reality 
</A>
<DD>
<A HREF="#subj3.1">
Robert Firth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Vicious elevators 
</A>
<DD>
<A HREF="#subj4.1">
Tom Lane
</A><br>
<A HREF="#subj4.2">
 Mark Brader
</A><br>
<A HREF="#subj4.3">
 Roland G. Ouellette
</A><br>
<A HREF="#subj4.4">
 Jake Livni
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Dehumanization by old Cobol programs 
</A>
<DD>
<A HREF="#subj5.1">
Karen Ward
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: "Computer Models Leave U.S. Leaders Sure of Victory" 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: "Computer Age Causes Key U.S. Data To Be Lost Forever" 
</A>
<DD>
<A HREF="#subj7.1">
Rick Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: "Little pitchers have big ears": ATM Risk 
</A>
<DD>
<A HREF="#subj8.1">
Michael McKay
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Cars and Automation [again] 
</A>
<DD>
<A HREF="#subj9.1">
Balakumar
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
NY area fiber-optic telephone cable severed; extensive effects
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Sat, 5 Jan 1991 12:33:40 PST
</i><PRE>

An AT&amp;T crew removing an old cable in Newark NJ accidentally severed a
fiber-optic cable carrying more than 100,000 calls.  Starting at 9:30am on 4
Jan 91, effects included shutdown of the New York Mercantile Exchange, several
commodities exchanges, disruption of FAA air-traffic control communication in
NY, Washington and Boston, causing lengthy flight delays at those and impinging
airports, and blockage of 60% of long-distance telephone calls into and out of
NY, for much of the day.  (AP, 5 Jan 91).  This came as we approach the
anniversary of the 15 Jan 90 nine-hour outage due to a self-propagating bug in
the recovery software.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
British military information stolen
</A>
</H3>
<address>
Charles Bryant 
&lt;<A HREF="mailto:ch@dce.ie">
ch@dce.ie
</A>&gt;
</address>
<i>
Thu, 3 Jan 91 16:56:55 GMT
</i><PRE>

An article in `The Irish Times' Jan 3 states that extremely sensitive
information relating to British military operations in the Gulf may
still be on a computer which was stolen from a staff car beloning to
Wing Commander David Farquhar on December 17th. The laptop was stolen
along with some documents. The documents were later found in a skip,
but the computer is still missing.

Presumably the inherent value of the computer made the thief keep it.

Charles Bryant (ch@dce.ie)

  [A skip is an open-top container for rubbish (garbage) which is about the
  size of a small car and is delivered and collected by a special type of
  vehicle. It must be called something different in the US.]  [Dumpster]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Wargames and Reality
</A>
</H3>
<address>
&lt;<A HREF="mailto:firth@SEI.CMU.EDU">
firth@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Fri, 4 Jan 91 11:14:00 -0500
</i><PRE>

I too am concerned at the seemingly naive acceptance by the Department of
Defense of the trustworthiness of simulated combat.  Others have pointed out
that the military cheat at war games, citing especially the Battle of Midway.
That is a clear risk.  As another example, the German General Staff often gamed
the Schlieffen Plan, and also often cheated.

However, there is in my opinion a further, and equally significant risk, even
in an honestly conducted simulation, and that is the risk that the simulation
incorporate some fallacy critical to the simulated outcome.  As an example,
consider how, in the 1930s, a possible German invasion of France would be
gamed.  On the map, the Ardennes would be clearly labelled 'heavily wooded:
impassable to tanks', as was the general opinion of the time.  A German player
who attempted an armoured breakthrough at that point would be immediately
stopped by the referee, and informed of his rule violation.  But we all know
what happenned in 1940.

To relate this to today: the performance figures for military tanks,
helicopters, aeroplanes &amp;c are usually taken either from nominal specifications
or from the results of field exercises in temperate terrain.  However, for the
present terrain and climate, values for speed, range, manoeuverability and
endurance should be adjusted downwards, by some unknown but probably drastic
amount.  Has this been done?  If so, where did the numbers come from?

Robert Firth

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Vicious elevator door failure recovery (<A HREF="/Risks/10.74.html">RISKS-10.74</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Tom.Lane@G.GP.CS.CMU.EDU">
Tom.Lane@G.GP.CS.CMU.EDU
</A>&gt;
</address>
<i>
Thu, 3 Jan 1991 21:39-EST
</i><PRE>

Actually, I believe that elevators with mechanical door sensors (strips)
are also programmed to override the sensors and close anyway after a
certain number of tries.  (I know for sure that the ones in Wean Hall at
CMU do this; they are of '60s vintage.  They even have the warning buzz
you describe.)  The reasoning, presumably, is the same as you gave: to
defend against sensor failures and denial-of-service attacks.

However, the door closing mechanisms (at least at Wean Hall) are not
strong enough to actually hurt a person; in fact they can be forced back
by a reasonably determined push.  This strikes me as a far better failsafe
design than relying on a backup sensor, which is what I think you are
advocating.  (Think about common-mode failures...)  The doors *are* strong
enough to be uncomfortable, which I'm sure is deliberate.

Of course, that's not to say that the elevator you encountered is actually
designed properly; but the mere use of electrical rather than mechanical
sensors does not seem to me to increase the risk in a properly designed
system.  Mechanical sensors fail, too.
                                       			tom lane
      ...!cs.cmu.edu!tgl   tgl%cs.cmu.edu@cmuccvma    &gt;internet:tgl@cs.cmu.edu

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Vicious elevator door failure recovery
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Fri, 4 Jan 1991 11:52:00 -0500
</i><PRE>

On some elevators this sensor is not a discrete strip, but is built into
the seemingly rigid edge of one of the two layers of door.  Either it
senses flexing of the edge, or it senses resistance to the door being
closed; I can't tell which.  It does require more force to operate than
the traditional rubber strip, but not so much as to make a "meaningful
attempt to crush" the user.  Perhaps the elevator in question actually
had this type of sensor, but it was not working.

Mark Brader, SoftQuad Inc., Toronto, utzoo!sq!msb, msb@sq.com

</PRE>
<HR><H3><A NAME="subj4.3">
Other vicious elevators
</A>
</H3>
<address>
Roland G. Ouellette
&lt;<A HREF="mailto:rouellet@pinnacle.crhc.uiuc.edu ">
rouellet@pinnacle.crhc.uiuc.edu 
</A>&gt;
</address>
<i>
Fri, 4 Jan 91 11:31:15 CST
</i><PRE>

The University of Illinois is suing Otis Elevator because of a pair of
these hungry elevators.  They've bitten a few people, most notably
people pushing computers and/or huge boxes onto and off of the elevator.

</PRE>
<HR><H3><A NAME="subj4.4">
Re: Vicious elevator door failure recovery (Jackson, <A HREF="/Risks/10.74.html">RISKS-10.74</A>)
</A>
</H3>
<address>
jake@mars.bony.com 
&lt;<A HREF="mailto:Jake Livni">
Jake Livni
</A>&gt;
</address>
<i>
Fri, 4 Jan 91 14:32:15 EST
</i><PRE>

Curtis Jackson writes about elevator doors that close, regardless of who's in
the way.  I know of such elevators, too.  (Incidentally, they may use some
other sensing mechanism like micro-switches rather than mechanical panels or
light beams; an elevator engineer once told me that some elevators use
micro-switches in the floor to estimate load and then adjust motor settings
accordingly.)

The elevator doors I have seen withdraw several times before becoming
insistent, then slowly beep their way closed.  This, however, is always
followed a few seconds later by a voice on the intercom from a guard downstairs
asking if anything is wrong.  A human gets into the loop.  Guards are always on
duty, though I don't know what controls over the elevator they might have from
their station.
                                        Jake     &lt;JAKE@DBCLUA&gt;

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re:  Dehumanization by old Cobol programs
</A>
</H3>
<address>
Karen Ward 
&lt;<A HREF="mailto:wardk@cse.ogi.edu">
wardk@cse.ogi.edu
</A>&gt;
</address>
<i>
Fri, 4 Jan 91 08:59:43 -0800
</i><PRE>

Darrell D. E. Long writes of thoughtlessly-designed billing software that
assumes that all people have only one middle initial.  This is not, as he
implies, only a risk of old COBOL programs.  Instead, he has identified one
aspect of a larger ongoing problem: balancing the desire to edit to ensure data
validity against the need for sufficient flexibility to accomodate unusual
cases.  Within the past year alone I have had to argue against system designs
that would assume that:

- All names look like "Given I. Family" (I have no middle initial,
  and my SE has only one name.  Many of our customers prefer their
  family name printed first)

- All children share their parents' family name

- Leading zeros should never print (There are both post-office boxes
  and street addresses in Portland, Oregon that have significant leading
  zeros, that is, the same number without the leading zero represents a
  different address)

- Zipcodes are always 5 (or 9) digits (non-USA zipcodes?)

- Names never contain special characters (Hyphens?  Also, some
  businesses have exclamation points and numbers in their names)

- All names start with a capital letter followed by lower case (I know
  of at least one person whose name starts with a lower case and contains
  an embedded upper case.  I know of another whose full name is III,
  pronounced "three")

For the applications I most frequently work with - business systems for
a public utility - I try to keep limiting assumptions about personal
information (names, addresses) to a minimum, and to edit with warnings
that can be overridden.  Our customers will forgive a one-time error
far more quickly than they will forgive our inability to correct that error.

Karen Ward (wardk@cse.ogi.edu)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: "Computer Models Leave U.S. Leaders Sure of Victory"
</A>
</H3>
<address>
Henry Spencer
&lt;<A HREF="mailto:henry@zoo.toronto.edu ">
henry@zoo.toronto.edu 
</A>&gt;
</address>
<i>
Fri, 4 Jan 91 21:11:59 GMT
</i><PRE>

&gt;  ...Red Force electronic warfare is reduced or eliminated because its
&gt;  success causes a complete breakdown in exercise force command and
&gt;  control...

After a discussion several years ago on a vaguely similar theme, I had
a bit of correspondence with a fellow who'd spent some time in electronic
warfare in the Army.  (I suspect I should not identify him.)  He said that
they were normally under severe restrictions in what they could do as part
of field exercises, and as a result the folks who were supposed to benefit
from said exercises had gotten very blase' about communications practices
and the like.  Then the EW people, after a lot of begging and pleading,
got permission to take the gloves off just once and show the commanders
what serious EW could do.  His summary of the results:  "we paralyzed them".

Henry Spencer at U of Toronto Zoology  henry@zoo.toronto.edu   utzoo!henry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: "Computer Age Causes Key U.S. Data To Be Lost Forever"
</A>
</H3>
<address>
Rick Smith
&lt;<A HREF="mailto:smith@SCTC.COM ">
smith@SCTC.COM 
</A>&gt;
</address>
<i>
Sun, 7 Jan 90 11:18:14 CST
</i><PRE>

I've been a packrat for most of my life and I've done historical research
and I've worked with databases. But I'm finding it very hard to mourn the
*general problem* of fading and decomposing magnetic media.

For one thing, the data is meaningless if you don't know how it was
collected. NASA has zillions of tapes, but do we really know how all
of that data was collected? Which sensor? What setting? Once this
information is lost, the data itself is just a tombstone.

For another thing, data has no value for its own sake. If there's a
researcher that can use some of the computer readable data out
there, then that's great. But I don't think we should save every
last byte "just in case" someone wants to use it in their dissertation
on rat populations in rural Podunk. The pot only holds so much. What
do we discard instead?

Sure, we should save what is "reasonable." For lack of a better
measure, let's save what people will use. For example, we might want
to establish a "computer research data recovery fund" which paid the
costs for grad students to recover "threatened" digital data and use it
in their research. The costs would pay for converting the data to work
on the researcher's PC or whatever and for a copy of the data in an
archival format. This is somewhat similar to the way that various
(usually state) historical societies are making microfilm collections
of community newspapers.

I don't know what a good "archival format" would be, however. I read recent
descriptions of de-lamination problems with CDs, and I have personal experience
with the unreliability of paper tape ...

Rick Arden Hills, Secure Computing Technology Corporation, Minnesota

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
RE: "Little pitchers have big ears": ATM Risk
</A>
</H3>
<address>
&lt;<A HREF="mailto:MCKAY_MICHAEL@atalla.com   [tandem.com?]">
MCKAY_MICHAEL@atalla.com   [tandem.com?]
</A>&gt;
</address>
<i>
3 Jan 91 16:38:00 +1600
</i><PRE>

I am currently the sustaining software engineer for the product mentioned by
zowie in his posting (11-25-90), and I wanted to clarify some things.  He was
disturbed by hearing modem tones during an ATM card activation at a Wells Fargo
Bank branch.  In fact, recording the 300 BAUD transaction (or tapping the phone
line) would not reveal his friend's PIN.  The PIN is encrypted by the terminal,
using DES and a "Unique Key Per Transaction (UKPT)" algorithm (our newer
terminals conform to ANSI 9-24, Wells Fargo still uses some older terminals
that predate 9-24 with a psuedo UKPT).

Once the transaction is reported to the host, a hardware security box
translates the PIN from the terminal's key to some irrreversible internal
format.  Once the PIN is entered into the terminal, it never appears in the
clear (that is to say unencrypted) in any computer.  This is much better than
the usual situation, where you would either be assigned a PIN, or have to write
down your PIN and have somebody enter it for you.  If anybody would like more
details on the process, feel free to contact me.

Michael McKay   (MCKAY_MICHAEL @ tandem.com)  (408) 435-8850

US MAIL: Atalla, A Tandem Company, 2304 Zanker Road, San Jose, CA 95131

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Cars and Automation [again]
</A>
</H3>
<address>
&lt;<A HREF="mailto:Bala.Kumar@IUS3.IUS.CS.CMU.EDU">
Bala.Kumar@IUS3.IUS.CS.CMU.EDU
</A>&gt;
</address>
<i>
Fri, 4 Jan 1991 14:18-EST
</i><PRE>

We were driving at 70 mph [automatic transmission, new car &lt; 1 K
miles]. All of a sudden the speedometer cable got cut [I believe] and
the needle fell back to 0 mph. In addition there was a heavy noise and
could feel the drag on the engine. I pulled out, put it in neutral and
raised the engine hood. Nothing wrong with the engine. All other things were
OK. Car moved without much problem up to 15 mph.  Beyond that it felt
like driving at Ist gear. Auto mechanic checked it too. Conclusion:

"Either auto transmission or fuel injection system is taking the input/cue from
the speedometer. They think the car is at a lower speed and act accordingly"

Could someone explain the situation?

We could have got into a major accident. Sure, the cause of the accident would
have been careless driver....  When I called the rental company for
replacement, they could not locate my file on the computer [god knows why] and
it took three hours ........
                                         -balakumar    pbk@cs.cmu.edu

    [Please respond directly to balakumar, unless this really is a
    computer-related problem.  Otherwise, try the two brothers in Boston 
    on NPR.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.74.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.76.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-49</DOCNO>
<DOCOLDNO>IA013-000136-B031-103</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.76.html 128.240.150.127 19970217041227 text/html 24969
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:10:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 76</TITLE>
<LINK REL="Prev" HREF="/Risks/10.75.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.77.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.75.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.77.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 76</H1>
<H2> Wednesday 9 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Suit says Nissan Fired 2 After reading e-mail 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Email flash from the past 
</A>
<DD>
<A HREF="#subj2.1">
Paul Eggert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: Cars and Automation: Yes, a computer problem! 
</A>
<DD>
<A HREF="#subj3.1">
Gregory G. Woodbury
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Another train crash in London 
</A>
<DD>
<A HREF="#subj4.1">
Olivier M.J. Crepin-Leblond
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: NY area fiber-optic telephone cable severed 
</A>
<DD>
<A HREF="#subj5.1">
Tony Scandora
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Vicious elevator door failure recovery 
</A>
<DD>
<A HREF="#subj6.1">
David Magnay
</A><br>
<A HREF="#subj6.2">
      Olivier M.J. Crepin-Leblond
</A><br>
<A HREF="#subj6.3">
 Michael J. Chinni
</A><br>
<A HREF="#subj6.4">
 Russell McFatter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Journal of Computer Security, Call for papers 
</A>
<DD>
<A HREF="#subj7.1">
Sushil Jajodia
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Suit says Nissan Fired 2 After reading e-mail
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.El_Segundo@Xerox.com">
Hoffman.El_Segundo@Xerox.com
</A>&gt;
</address>
<i>
Wed, 9 Jan 1991 07:30:07 PST
</i><PRE>

Summarized from an article by George White, `Los Angeles Times', 8 Jan 1991

Two former employees of Nissan Motor Corp. USA allege that they lost their jobs
after a manager eaves-dropped on their electronic mail messages.  Their lawsuit
claims that they were illegally discharged and denied their constitutional
right to privacy.

The plaintiffs used electronic mail to track the needs of Nissan dealers,
occasionally sending personal messages to dealerships.  One of the messages was
critical of a Nissan manager.  The suit mantains that a Nissan manager
intercepted their personal messages and threatened to dismiss the two.  One was
fired outright, the other was told to resign or be fired.  Their attorney said
Nissan was retaliating against the pair for filing an invasion of privacy
complaint with Nissan's Human Resources Dept. on Dec. 28.

Nissan denies the charges, calling them "unfounded."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Email flash from the past
</A>
</H3>
<address>
Paul Eggert
&lt;<A HREF="mailto:eggert@twinsun.com ">
eggert@twinsun.com 
</A>&gt;
</address>
<i>
Mon, 7 Jan 91 14:01:34 PST
</i><PRE>

&gt;From RISKS 10.75 (7 Jan 91):

  Date: Sun, 7 Jan 90 11:18:14 CST        [ &lt;==== sic ===== ]
  From: smith@SCTC.COM (Rick Smith)
  Subject: Re: "Computer Age Causes Key U.S. Data To Be Lost Forever"

  I've been a packrat for most of my life and I've done historical research...

It's ironic that a message about old data claimed to be one year older than it
really was.  No doubt the problem was a system administrator's error in
entering a date after a reboot, the sort of thing that software should warn
about but often doesn't.  Beware of dates in early January.

   [See my Inside Risks column in the January 1991 CACM summarizing some
   of the more interesting clock problems discussed in the RISKS FORUM
   over the years (and over the years' ends), albeit familiar to long-time
   RISKS readers.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Cars and Automation: Yes, a computer problem! (<A HREF="/Risks/10.75.html">RISKS-10.75</A>)
</A>
</H3>
<address>
Gregory G. Woodbury
&lt;<A HREF="mailto:ggw%wolves@cs.duke.edu ">
ggw%wolves@cs.duke.edu 
</A>&gt;
</address>
<i>
Wed, 9 Jan 1991 04:27:34 GMT
</i><PRE>

	This really is a computer related problem.  Given that it is a
fuel-injection new car, the spark advance and fuel metering are under the
control of a micro-controller.  On many late model cars, the speedometer
readings on the driver's console are derived from the output to the drive
wheels (assuming front wheel drive) in the transmission and not from reading
the rotation of the wheel!
	This is the only source for the micro-controller to know the
approximate speed of the vehicle so that it can compute engine load and adjust
fuel metering and spark advance.
	Additionally, several late models also put the automatic transmission
under the control of a micro-controller (usually the same one as is controlling
fuel).
	The RISKS are obvious.  There is only one micro-controller in the
system; the car will NOT operate without the controller working properly; there
are no redundancies in most of the critical input systems.  Additionally, the
micro-controllers are overly sensitive in many cases to: changes in voltage
delivered, electromagnetic interference from radio transmissions,
electromagnetic interference from power distribution systems, EMI from other
systems in the vehicle, and even EMI from traffic sensing devices embedded in
the roadways.  Further discussion is probably unnecessary.

Gregory G. Woodbury @ The Wolves Den UNIX, Durham NC  ggw%wolves@mcnc.mcnc.org
UUCP: ...dukcds!wolves!ggw   ...mcnc!wolves!ggw 

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Another train crash in London
</A>
</H3>
<address>
"Olivier M.J. Crepin-Leblond" 
&lt;<A HREF="mailto:UMEEM37@vaxa.cc.imperial.ac.uk">
UMEEM37@vaxa.cc.imperial.ac.uk
</A>&gt;
</address>
<i>
Wed, 9 Jan 91 13:09 BST
</i><PRE>

	A man has died and 348 people were hurt when a packed rush-hour train
failed to stop at Cannon Street station in London, and ploughed into the end
buffer.
	The train was packed with about 800 commuters. The accident happened on
Jan 8th, 1991, at the height of the rush hour, at 8:45am.  It appears that the
brakes failed to work when the driver tried to slow down when entering the
station. The train hit the buffer at the speed of 5 mph only, but some
carriages got crushed because of its weight and age. The sixth carriage was
pushed onto the fifth carriage. The train was 35-40 years old. The UK's Rail
Minister promised a full enquiry. Ambulances, helicopters, and even a London
red bus were used to carry the victims to hospital.

	Once again there is a major train crash in London. British Rail has had
a pretty bad record of crashes. Lately there has been an average of 1 major
crash per year. This year it seems that they are reaching their quota pretty
early !  The main problem seems to be prolonged lack of investment into new
rolling stock, and hence British rail ends up with old trains, old stations,
etc. Cost-cutting measures brought more over-crowding during peak rush hours. I
have often taken trains similar to the one invollved in yesterday's crash.
Most local commuter routes are served using these trains. The ride is something
of an experience. During the rush hour, most people stand-up between the seats.
Carriages, although being good for natural history museum exhibitions, are
crowded to their full load. Yes, carriages with inside walls still made of
wood, and grey seats facing each other. The ride is anything but comfortable.
One tends to bounce on the seats, as though the train was actually hopping from
rail to another rail. 5 years ago British Rail started and extensive
refurbishment of these trains. The only visible improvements were are new coat
of paint outside, and the replacement of filament light bulbs with fluorescent.
Oh, and yes, the logo on the trains was changed from British Rail to Network
Southeast.  There is no safety mechanism about opening doors. One can open a
door whereas the train is in a station or speeding between 2 stations.  Some
London underground trains have also been built in the 1950's.  They should have
been replaced 2 years ago, but one of the new replacement trains went off the
tracks during trials, and it was all back to the drawing board. London
underground says that new trains should be introduced in 1992.

	Although there have been so many accidents, I guess I shall miss these
British Rail carriages when the new ones replace them (when ? in a year's time
I'm told ?). Travelling on Network Southeast was much of an adventurous
experience. But like any thrill, it was only good in small doses.

Olivier Crepin-Leblond, Imperial College, London, UK.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: NY area fiber-optic telephone cable severed; extensive effects (PGN)
</A>
</H3>
<address>
Tony Scandora 708-972-7541
&lt;<A HREF="mailto:B35048@ANLCMT.CMT.ANL.GOV ">
B35048@ANLCMT.CMT.ANL.GOV 
</A>&gt;
</address>
<i>
Tue, 8 Jan 1991 11:36:49 CST
</i><PRE>

My father spent all morning Friday 4 January trying to return a phone call from
his office near Chicago to a customer in the Dominican Republic.  After endless
"We're sorry, all circuits are busy.  Please try your call later." messages, he
heard on the news that a cable had been cut near New York, which affected some
overseas calls.  He continued trying all day Friday, and never got through.  He
spent all day Saturday trying to make a FAX call and never got through.  A
cable cut in Newark made it impossible to place a call from Chicago to the
Dominican Republic for at least two full days.

How's that for depending on a single point of failure?  It brought back
memories of the Hinsdale fire on Mothers Day a couple of years ago, when a fire
in an unattended office took out most of Chicago for three weeks.  At the time,
I started to worry that fifty strategically placed terrorists with street gang
incendiaries could cripple the entire country.  It could even be done without
receiving any return fire.  The history of telephone service since then has
done nothing to restore my confidence.  Back in the bad old days of Ma Bell,
they used to brag that the call might be routed through Arizona, Montana, and
Guam, but it would get there.  Why are today's telecommunications systems
designed to depend on extremely vulnerable single points of failure?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Vicious elevator door failure recovery [<A HREF="/Risks/10.76.html">RISKS-10.76</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:david@marvin.jpl.oz.au">
david@marvin.jpl.oz.au
</A>&gt;
</address>
<i>
Tue, 8 Jan 1991 11:04:58 +1100
</i><PRE>

I speak as an Australian Lift ( OZ for "elevator") manufacturer, and so cannot
speak directly for USA lifts. However, the observed behaviour is consistent
with OZ lifts.

Historically, the door sensors have been a notoriously unreliable element, and
whilst many improvements have occured over the years, being at the "working
face" of lifts, they still fail regularly. To prevent the lift being out of
commision without warrant, controller logic assumes that 4 or 5 retries is good
enough if we have stuck people, and then assumes that it must be a sensor
failure, and attempts to close. In Oz, this behaviour is often written into
building specifications.

However, things are not as bad as they look. Lifts are governed by a VERY large
set of regulations, and door related regs are a good part. The door controller
design MUST not allow more than a specified force to be applied in the event of
a blockage. Whilst this force must be reasonably strong to cover day-to-day
events, it is not sufficient to break a limb ( 130N: let the Regulators
beware), although it could cause a broose(?) on the frail. Most door
controllers will physically dis-engage the drive mechanism on a solid blockage,
allowing even for uncontrolled torque on the closing motor.

"Where the closing of doors is delayed by a period of not less than 10 s
through the operation of the passenger-protection device ( door beams), the
doors may power close with the passenger-protection device in-effective
provided that the kinetic energy does not exceed 3.4J, and an audible warning
is sounded in the car."	Aus. Standards 1735.2 p64

The passenger's main fear is that the doors will close with unreasonable force,
to sever the limb; or that the lift will leave the floor with the limb extended
thru the door. Above and beyond the controllers S/W checks on timing and
sensors, independant door sensors prevent this occurence, all covered by
national standards.

Mr Jackson implies that there is a hidden design risk in the behaviour of the
doors. Whilst all may not agree on the fine print, it is an area of intense
scrutiny and regulation.

These opinions are my own, and although not different to the views of the
Company, cannot be taken as an official voice.

David Magnay, Boral Elevators (was: Johns Perry Lifts), 45 Wangara Road, 
Cheltenham 3192, Victoria, Australia    (03) 584-3311 O/seas	+61 3 584 3311

</PRE>
<HR><H3><A NAME="subj6.2">
RE: Vicious elevator door failure recovery (<A HREF="/Risks/10.74.html">RISKS-10.74</A>)
</A>
</H3>
<address>
"Olivier M.J. Crepin-Leblond" 
&lt;<A HREF="mailto:UMEEM37@vaxa.cc.imperial.ac.uk">
UMEEM37@vaxa.cc.imperial.ac.uk
</A>&gt;
</address>
<i>
Tue, 8 Jan 91 18:24 BST
</i><PRE>

	The few elevators ('lifts' in UK) of the London undergound system
are now all operated by computers. They do have a warning beep, and they 
also have door sensors in case someone gets trapped. The idea has
never come into my mind to try to block the doors, but from what
I can recall about the commuter crowding during the rush hour, they 
also shut for good after a few aborted attempts. One can hold them
back without trouble.
	However the doors of the underground trains are operated by the
driver. The only sensor they have checks if the doors are closed or not
so that the train cannot start if the doors are not properly shut.
About a year ago, one sensor failed and a woman was dragged along the
length of a platform. Fortunately other passengers stopped the train
by pulling the emergency alarm system.
	Once, a friend of mine got his glasses broken when the train door
slammed in his face. Drivers are supposed to keep doors open as long as
passengers are boarding the train but during the rush hours, they slam them
shut so as not to get delayed too much. Again, the doors can be held back,
although here if you are not related to Arnold Schwarznegger, it is advisable
to request the help from other passengers. So many people have had a bad
experience getting trapped in underground train doors !
	Personally, I would prefer computers and sensors to control the doors
of any moving carriage. At least when you are trapped the doors open-up again,
whereas when there is human interaction, it all depends on his mood.

Olivier M.J. Crepin-Leblond, Elec. Eng. Dept., Imperial College London, UK.

</PRE>
<HR><H3><A NAME="subj6.3">
 Re: Vicious elevator door failure recovery
</A>
</H3>
<address>
"Michael J. Chinni, SMCAR-CCS-E" 
&lt;<A HREF="mailto:mchinni@PICA.ARMY.MIL">
mchinni@PICA.ARMY.MIL
</A>&gt;
</address>
<i>
Tue, 8 Jan 91 9:43:50 EST
</i><PRE>

Given all the comments on this topic I have a question:

	Since the elevator door is insisting on closing regardless of something
interfering with its closing, what is to prevent the elevator from thinking
that the door IS closed and start moving (remember the fact that no button in
the elevator was pressed is immaterial since the elevator may be summoned from
another floor)?

	If there is a final failsafe such that the elevator KNOWS that the door
isn't fully closed and therefore that it mustn't start moving then the only
concern (albeit a significant one) is the doors closing on a person.
Seriousness of this depends upon the force the door exerts on the object
blocking its full closing.

	If there ISN'T such a failsafe then this problem is a fatality (and a
gruesome fatality) waiting to happen.

			    Michael J. Chinni
	 US Army Armament Research, Development, and Engineering Center
                       Picatinny Arsenal, New Jersey  
     ARPA: mchinni@pica.army.mil     UUCP: ...!uunet!pica.army.mil!mchinni

</PRE>
<HR><H3><A NAME="subj6.4">
Re: Vicious Elevators
</A>
</H3>
<address>
Russell McFatter
&lt;<A HREF="mailto:russ@alliant.com ">
russ@alliant.com 
</A>&gt;
</address>
<i>
Tue, 8 Jan 91 10:02:49 EST
</i><PRE>

All of the elevators I've seen have some kind of door-edge safety device--
(officially called a "safety edge").  The older (and still most prevalent)
style is the mechanical rubber bumper, which usually has to be pushed in by 1-2
inches to cause the door to retreat.  Other elevators have a thin plastic (but
still mechanical) edge which works much the same way.  The newest Otis
installations I've seen all have a proximity sensor, which is a plastic device
mounted flush with the inner door (and usually has a small calibration light)--
most of the time, these reverse the door before it touches anything.  In an
event where it doesn't (such as when the OUTER door is blocked), you are
protected by devices which limit the force that the door can apply.  Both the
closing speed (feet per minute) and closing force (pounds) of an elevator door
are regulated by law (and is one of those things that should be checked when an
elevator is inspected).  Rather than a clutch, I believe that most modern
elevators limit the closing force of the door electronically.  The test is to
resist the door WITHOUT tripping the safety edge or "electric eyes" (on
elevators equipped with this).  It's usually firm, but shouldn't be able to
crush or otherwise injure someone.  Most importantly, the elevator should not
move with an obstruction in the door, even if the door is refusing to reopen.
This is one place where I think that advanced technology has reduced RISKs to
the public; modern elevators can detect "unreasonable" situations that
mechanical controllers don't (such as: door does not close within a certain
time limit), and take appropriate action.

The safer we make something (elevator doors), the more people take this safety
for granted, and, ironically, we end up with more types of unpredictable
trouble.  I've always been amused by the New York public service commercials
which advertise the hazards of subway-train doors, and makes the point that
"these doors mean business" and do not reopen (at one point, showing them with
teeth).  People know to stay out of the way, and this helps to avoid accidents.
Imagine what would happen if you tried to introduce the first subway system
based on the design that exists in most modern cities (including the very
modern Washington D.C. "metro"): A crowded concrete platform ends at a
five-foot drop to the tracks below; no walls or doors to prevent people from
falling (or being shoved) off the edge; and no way back up once one falls.  At
the bottom are exposed metal rails carrying lethal voltages at huge currents.
Whether or not one survives, the next train arriving at the station won't be
able to stop in time to avoid hitting him.  Even those passengers who remain on
the platform and successfully board a train, avoiding those nasty teeth-bearing
doors, will find themselves sitting or standing(!) in a boxful of glass
windows, doors, metal rails, and with nothing particular to keep them in place
when the train derails or smashes into another train, filling the dark tunnel
with toxic smoke.  Would you expect this design to be approved?

Still, the greatest RISK to your health isn't the subway itself, but
other passengers (especially in NYC).

--- Russ McFatter [russ@alliant.Alliant.COM]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
call-for-papers, Journal of Computer Security
</A>
</H3>
<address>
Sushil Jajodia
&lt;<A HREF="mailto:jajodia@gmuvax2.gmu.edu ">
jajodia@gmuvax2.gmu.edu 
</A>&gt;
</address>
<i>
Tue, 8 Jan 91 09:27:01 -0500
</i><PRE>

                       CALL  FOR  PAPERS
                  JOURNAL OF COMPUTER SECURITY

The Journal of Computer Security is a new archival research journal on computer
security, to be published quarterly by IOS Press, Amsterdam.  It will publish
significant advances in the theory, architecture, design, implementation,
analysis, and application of secure computer systems.  Its scope encompasses
all aspects of computer security, including confidentiality, integrity, and
denial of service.  Subject areas include computer architecture, operating
systems, database systems, networks, distributed systems, formal models,
verification, algorithms, mechanisms, and policies.

Editors-in-Chief:

Prof. Sushil Jajodia                 Dr. Jonathan Millen
George Mason University 	     The MITRE Corporation
Department of Information Systems    Mail Stop K325       
and Systems Engineering              Burlington Road
Fairfax, VA 22030-4444, U.S.A.       Bedford, MA 01730, U.S.A.
jajodia@gmuvax2.gmu.edu  	     jkm@mbunix.mitre.org
(703) 764-6192  	             (617) 271-3580

Editorial Board Includes:

Marshall Abrams, MITRE               Carl Landwehr, NRL
Thomas Beth, U. of Karlsruhe         E. Stewart Lee, U. of Toronto
Matt Bishop, Dartmouth	             Teresa Lunt, SRI
John Dobson, Newcastle upon Tyne     John McLean, NRL
Gerard Eizenberg, ONERA/CERT         Ravi Sandhu, George Mason
Virgil Gligor, 	U. Maryland          Marv Schaefer, TIS
Bhavani Thuraisingham, MITRE

Instructions to Authors:

Submit six copies of your manuscript to one of the editors-in-chief with a
submittal letter signed by one of the authors.  In case of multiple authors,
designate an author for correspondence.  Please keep the editors informed of
any changes of address.

Submitted papers must be original and present a significant result, and must
not have been previously published or submitted for publication elsewhere,
although portions may have been published in conference proceedings.  It will
be assumed that all necessary clearances for publication have been obtained by
the author(s) by the time a paper is submitted for publication.

Papers will be refereed in a manner customary with scientific journals before
being accepted for publication.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.75.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.77.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-50</DOCNO>
<DOCOLDNO>IA013-000136-B031-127</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.77.html 128.240.150.127 19970217041242 text/html 40394
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:11:09 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 77</TITLE>
<LINK REL="Prev" HREF="/Risks/10.76.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.78.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.76.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.78.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 77</H1>
<H2> Friday 11 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer program gives police a bum rap 
</A>
<DD>
<A HREF="#subj1.1">
David A Smallberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Unusual distance metric could waste consumers' time and gas 
</A>
<DD>
<A HREF="#subj2.1">
David A Smallberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Computers Stolen in the USSR 
</A>
<DD>
<A HREF="#subj3.1">
Sanford Sherizen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: British military information stolen 
</A>
<DD>
<A HREF="#subj4.1">
Stephen Carter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Vicious Subway Cars 
</A>
<DD>
<A HREF="#subj5.1">
Ed Ravin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Vicious Doors on London Underground/Network South-East 
</A>
<DD>
<A HREF="#subj6.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Defence of British Rail/Network SouthEast 
</A>
<DD>
<A HREF="#subj7.1">
David Green
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
RISKS of computer-assisted emergency dispatch systems 
</A>
<DD>
<A HREF="#subj8.1">
Ed Ravin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
2nd IFIP Dependable Computing Conference 
</A>
<DD>
<A HREF="#subj9.1">
Rick Schlichting
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
First Conference on Computers, Freedom &amp; Privacy 
</A>
<DD>
<A HREF="#subj10.1">
Dorothy Denning
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer program gives police a bum rap
</A>
</H3>
<address>
David A Smallberg 
&lt;<A HREF="mailto:das@CS.UCLA.EDU">
das@CS.UCLA.EDU
</A>&gt;
</address>
<i>
Fri, 11 Jan 91 11:54:34 PST
</i><PRE>

Summarized from an article by Roxana Kopetman, Los Angeles Times, 10 Jan 1991:

Long Beach, California, police officials believe that a programming error
partly explains why their department has the worst crime solving record among
11 large California cities.

The California Department of Justice ranks departments by their rate of solving
crimes.  Long Beach has placed last 11 times in the last 15 years.  Last year,
for example, the city solved 14.2% of its cases; the statewide average is 22%.

However, the department just found out that their system lists a crime as
solved only if it is solved in the same month it was reported.  Other police
departments don't do this.  The tallies are done by a program in the city's
information services bureau.

Police don't put all the blame on the program.  They cite an understaffed
detective bureau and officers taking time off for job-related injuries at a
rate three times the state average, taking twice as long as average to return
to work.

-- David Smallberg, das@cs.ucla.edu

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Unusual distance metric could waste consumers' time and gas
</A>
</H3>
<address>
David A Smallberg 
&lt;<A HREF="mailto:das@CS.UCLA.EDU">
das@CS.UCLA.EDU
</A>&gt;
</address>
<i>
Fri, 11 Jan 91 13:00:23 PST
</i><PRE>

A friend related an experience he had calling a swimming pool supply company's
800 number to find a local distributor.  The operator asked for his zip code
and told him the address of the nearest distributor, saying it was 3.5 miles
away.  It actually was more like 8 miles, so my friend figured the distance
was measured from his post office.  Since he lives near a zip code boundary,
he asked for the nearest distributor from the neighboring zip code, hoping to
find something closer.  This is where things started to get weird, so he tried
zip codes from his office and parents' home:

  Start location &amp; Zip		Nearest distributor location &amp; distance
   Sherman Oaks, CA 91423	  Reseda (3.5 reported miles, 8 actual miles)
   North Hollywood  91607	  Hacienda Heights (30 miles! Reseda's closer!)
   Santa Monica     90405	  Torrance (15 miles)
   West Los Angeles 90064	  Carson City, Nevada (400 miles!)

At this point my friend figured out what was happening:

   Sherman Oaks	    91423  ==&gt;  91335  Reseda
   North Hollywood  91607  ==&gt;	917xx  Hacienda Heights
   Santa Monica     90405  ==&gt;	905xx  Torrance
   West Los Angeles 90064  ==&gt;	897xx  Carson City, Nevada

The programmer obviously assumed that proximity in zip codes meant proximity in
space.  E.g., for 90064, since there was no distributor in 900xx, the program
tried 901xx and 899xx, then 902xx and 898xx, etc.   How many customers wasted
their time and gas going to the wrong store?  How much business did the company
lose from people who decided not to make a long trip?

I've noticed similar foolishness from companies that assume that any store
location in my telephone area code (818) is worth telling me about, while none
of the nearer stores in neighboring 213 are.

-- David Smallberg, das@cs.ucla.edu

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computers Stolen in the USSR
</A>
</H3>
<address>
Sanford Sherizen 
&lt;<A HREF="mailto:0003965782@mcimail.com">
0003965782@mcimail.com
</A>&gt;
</address>
<i>
Thu, 10 Jan 91 21:01 GMT
</i><PRE>

The following falls into the "Isn't this a small world" category.  It appears
that the Soviet Union is getting more Westernized by the moment.  Their
criminals and police seem to be just like ours.

The message originally appeared on internet news and then was posted on a net
concerned with Soviet computing (USSRECOM).  
 
Sandy

*********
In article &lt;1991Jan7.150851.2143@hq.demos.su&gt;, avg@hq.demos.su (Vadim Antonov)
 writes:
|&gt; Hi, our small team just faced to a new problem: some thieves
|&gt; stole our net's major backbone machine (a 486 :-). These guys are
|&gt; already caught but the machine is still a "material evidence" and
|&gt; we had to switch to (much heavier :-) VAX. Is it a first actual
|&gt; case of stealing of a backbone hardware? :-) :-) :-) At least we found
|&gt; that all the messages were stolen together with the machine :-).
|&gt;
|&gt; Vadim Antonov
|&gt; DEMOS, Moscow, USSR

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: British military information stolen (Bryant, <A HREF="/Risks/10.75.html">RISKS-10.75</A>)
</A>
</H3>
<address>
Stephen Carter 
&lt;<A HREF="mailto:stevedc@syma.sussex.ac.uk">
stevedc@syma.sussex.ac.uk
</A>&gt;
</address>
<i>
Thu, 10 Jan 91 18:14:17 GMT
</i><PRE>

&gt; An article in `The Irish Times' Jan 3 states that extremely sensitive
&gt; information relating to British military operations in the Gulf may
&gt; still be on a computer which was stolen from a staff car ...

It is worth adding that this information was known and published outside
of the UK, but was not published (censorship) in the UK until (I think)
6 Jan 91 when Associated Press threatened to run the story anyway.

Stephen Carter, The University of Sussex, Falmer, Brighton BN1 9RH, UK
Tel: +44 273 678203  Fax: +44 273 678335     UUCP: stevedc@syma.uucp

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Vicious Subway Cars (was: Vicious Elevators)
</A>
</H3>
<address>
Unix Guru-in-Training
&lt;<A HREF="mailto:elr%trintex@uunet.UU.NET ">
elr%trintex@uunet.UU.NET 
</A>&gt;
</address>
<i>
Thu, 10 Jan 91 12:42:54 EST
</i><PRE>

Here's a quick rundown on RISKS of stepping through the doors on a New York
City subway car: each of the twin doors can be as much as 3 inches open
when the train starts moving, giving you a maximum gap of 6".  Although an
interlock prevents the train from starting while the doors are open (called
the "indication" by the train crew), the sensors aren't too precise.  People
can (and do) get dragged by moving cars when they're stuck in the doors.
Usually it's their own fault -- hyped up New Yorkers who won't wait the next
three or five minutes for the next rush hour train (or ten or twenty minutes
off peak) blocking the doors open in the vain hope the conductor will
re-open and let them in.  As a previous RISK poster noted, this all depends
on the conductor's mood and if s/he is in a hurry or not.  It also depends on
their line supervisors: some managers emphasize speed, others passenger safety.

A few years ago the Transit Authority had a problem with "doors opening
enroute" on the older (pre-1976 or so) cars -- an individual door would
open while the train was in motion, once on a speeding express train
(thankfully, no one was hurt).  The TA rewired all their newer trains
with an interlock so that the emergency brake would activate if the
doors opened while the train was in motion.

You can experiment with this safety interlock by attempting to force one of the
doors open while the train is moving.  One day I observed two teenagers on the
way to Brooklyn doing exactly that, thrilling over pushing open a door two
inches as the train sped through the tunnel.  When I warned them that they
would kick in the emergency brake if they went too far they had a spell of
enlightened self-interest (it can take ten or fifteen minutes for the crew to
reset the emergency brake) and left the poor door alone.

Ed Ravin, Prodigy Services Company, White Plains, NY 10601    elr@trintex.UUCP    
                                         +1-914-993-4737   philabs!trintex!elr

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Vicious Doors on London Underground/Network South-East
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Thu, 10 Jan 91 21:33:56 PST
</i><PRE>

I was interested in Olivier M.J. Crepin-Leblond's two mailings (<A HREF="/Risks/10.75.html">RISKS-10.75</A>)
regarding the recent train crash and the behaviour of tube train doors.

I am also a victim (sorry, commuter! :-) of "Network South-East", the bit of 
what used to be British Rail that serves East Anglia and the area south-east
of London. They are a by-word for discomfort and overcrowding, even where the
rolling stock is new, as it is on the lines from Peterborough and Cambridge
into London King's Cross. It was recognised at the enquiry into the Clapham
rail disaster that a large proportion of the deaths and serious injuries in
a crash can be attributed to passengers having to stand in the aisles between 
the seats. Even a low-speed impact means that standing passengers who insist
on obeying Newton's first law of motion will continue their journey along the
carriage until brought to rest by their fellow passengers or by the door to
the adjoining carriage.

Even so, it does not appear to be cost-effective to supply adequate numbers
of carriages to cope with the rush-hour. After all, the management has to 
show a profit so that privatisation will attract investors, and a yearly
season ticket between Stevenage and London only costs 1744 pounds sterling.

Another bit of cost-cutting is to use driver-only trains. There is no guard
to check the doors before the train pulls out. This is so on most rail and
underground services. There is usually a TV monitor which the driver can use
to check the length of the platform. This does not seem to be particularly
effective, judging by the number of incidents I have personally witnessed
over the last few years, such as:

A driver closing the automatic doors and pulling away after a mother got out 
but before her children had time to leave the train. (Frantic waving and 
shouting by other people on the platform made him stop.) - Network South-East.

An elderly woman boards the train (Underground: Piccadilly Line), and the
driver closes the doors and moves off before her equally elderly husband can
get on.

I leaped onto a crowded tube train (Underground: Metropolitan Line) carrying a 
shoulder bag just as the doors were closing. I got on, but my bag didn't. The
doors closed around the strap, and the train moved away with the bag hanging 
outside the carriage, and me pinned to the door by the strap around my shoulder,
just waiting for the first obstruction to snag the bag. Fortunately, someone
pulled the emergency handle, and the train stopped before it entered the tunnel.

What has this got to do with computers? Not a lot! All these incidents occurred
with a human in the loop (just one human, and obviously not very firmly in the 
loop!). I think that less, not more, automation is the answer to safety here.
Bring back the guard!

(I went through King's Cross on the Circle Line while the fire was raging a
few years ago. They're gonna get me one day! :-)

Peter Mellor, Centre for Software Reliability, City University, Northampton Sq.,
London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Defence of British Rail/Network SouthEast
</A>
</H3>
<address>
David Green (MSc 90/91) 
&lt;<A HREF="mailto:davidg@aipna.edinburgh.ac.uk">
davidg@aipna.edinburgh.ac.uk
</A>&gt;
</address>
<i>
Fri, 11 Jan 91 15:33:24 GMT
</i><PRE>

In the latest RISKS DIGEST:

Date: Wed, 9 Jan 91 13:09 BST
From: "Olivier M.J. Crepin-Leblond" &lt;UMEEM37@vaxa.cc.imperial.ac.uk&gt;
Subject: Another train crash in London

&gt; [general criticism of British Rail esp. Network SouthEast]

Yes, there's been a major train crash in London. But I've seen no claims that
computers were involved - as Olivier points out, BR's main problem is hardware
dating from the 1950's, and hardly the over-enthusiastic application of new
technology. The UK news reports I heard only listed 1 fatality, and I wouldn't
like to estimate the number of deaths that would be likely to result from all
of the rail commuters driving into London instead. For seven years I travelled
about 20 miles a day (going to and from school) by Network SouthEast, and
although we didn't always get seats, clean trains, or particularly punctual
arrivals, we always got there in one piece. I don't think there exists a
perfect public transport system; the UK rail network only offers one of the
better alternatives.

Unlikely though this may seem to some of your readers, I am in no way connected
to British Rail, Network SouthEast, or any of their subsidiaries.
                                                                    David Green

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
RISKS of computer-assisted emergency dispatch systems
</A>
</H3>
<address>
Unix Guru-in-Training
&lt;<A HREF="mailto:elr%trintex@uunet.UU.NET ">
elr%trintex@uunet.UU.NET 
</A>&gt;
</address>
<i>
Thu, 10 Jan 91 13:08:34 EST
</i><PRE>

Thanks to budget cuts a fire company was recently closed near Richmond Hill,
in Queens (New York City).  This past Monday, two people died in a fire
nine blocks from the closed engine company.  It's been getting lots of local
news coverage, because the firefighter's union, in a bid to reverse the
closures, has claimed that those persons might have lived if the engine
company had not been shut down.

In the post-mortem analysis of the response to the fire, several other
problems were turned up that cost time in getting water pumped into the
burning building.  The biggest one was that the engine company that was
dispatched (engine companies have the pumps and hoses that will squirt water
from a hydrant into the fire, ladder companies have the rescue team for
clambering into the building and recovering people stuck inside) was told
that they were the "auxiliary" engine company.  So they did what an auxilliary
company is supposed to do, namely hook up to the second-closest hydrant and
let the "main" company get the first assault into the fire.  But the "main"
company was supposed to be the engine that had been closed down, and so no
other water-pumping equipment was sent.  The firefighters quickly realized
the mistake, and lost only a couple of minutes putting back their hoses and
moving to the closer hydrant.

Apparently the Fire Department's computer dispatch system was not updated
about the demise of the engine company, and thus designated the remaining
engine in the area as the auxiliary.  And despite news headlines about
firehouse closings, none of the dispatchers realized in time that they were
making an error.

It looks like the people who build dispatch systems (or telephone
operator's consoles, airline reservation systems, etc) are interesting only
in improving "efficiency", which usually translates to less operators and
lesser-trained operators.  In a place like NYC, without computer assistance
dispatchers would have to be well versed in the operations of the emergency
service they were controlling, if not the local neighborhood their units
were operating in.  Now, from what I've heard over my scanner, dispatchers
can be almost anyone who can sit in front of the computer console that's
supposedly keeping track of which units are where and which calls from 911
haven't been answered yet.  Operators can be changed or transferred frequently
because the computer is supposed to "remember" the status of all outstanding
calls.  So more work is dumped on lesser-trained people, and the results
are degraded service and mistakes like that described above.  (To be fair,
this is less true of the NYC Fire Department than of the Police Department.)

Ed Ravin, Prodigy Services Company, White Plains, NY 10601    elr@trintex.UUCP    
                                         +1-914-993-4737   philabs!trintex!elr

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
2nd IFIP Dependable Computing Conf.
</A>
</H3>
<address>
Rick Schlichting
&lt;<A HREF="mailto:rick@cs.arizona.edu ">
rick@cs.arizona.edu 
</A>&gt;
</address>
<i>
11 Jan 91 18:17:06 GMT
</i><PRE>

   [Please note that the preregistration and hotel reservation deadlines
    are fast approaching.]


                   *** Final Call for Registration ***
                    Second IFIP Working Conference on

              DEPENDABLE COMPUTING FOR CRITICAL APPLICATIONS
                        Can we rely on computers?

                 Hotel Park Tucson, Tucson, Arizona, USA
                          February 18-20, 1991

Organized by
    IFIP Working Group 10.4 on Dependable Computing and Fault Tolerance

Registration Information:

Advance registration is strongly encouraged.  The advance registration 
fee, due by January 15, is 300 U.S. dollars, by bank draft drawn on a 
U.S. Bank.  Limited on-site registration will be available at a cost of 
340 U.S. dollars.

The registration fee includes: attendance at the Working Conference, a welcome
reception, 3 lunches, coffee breaks, and the banquet, as well as one copy of
the conference pre-prints and a copy of the proceedings.  The proceedings will
be published as a volume of the Springer-Verlag series "Dependable Computing
and Fault-Tolerant Systems."

CONFERENCE REGISTRATION FORM

Return to: R. D. Schlichting, 2nd DCCA Working Conference, Dept. of Computer
   Science, University of Arizona, Tucson, AZ 85721

Name: 
Affiliation: 
Address: 
Phone:
email:

Registration Fee:
  Advance Registration $ 300          _______
     (Must be received by Jan. 15)
  Regular Registration $ 340          _______
  Ticket to Reception and Banquet
  for guests ($60 per person)         _______

TOTAL                                 _______

Payment must be made in U.S. Dollars, by bank draft drawn on a U.S. bank.

Accommodations for the Working Conference will be provided by the Hotel Park
Tucson.  Attendees should make their reservations prior to January 17 either by
mailing in the form below or telephoning the hotel.  The hotel can be reached
from the Tucson airport via rental car, taxi, or van.  Van service is provided
by the Arizona Stagecoach, at a cost of $7.50 each direction.  To make use of
this service, exit the airport to the curb and look for a van with "Arizona
Stagecoach" printed on the side.  No reservations are necessary.

HOTEL REGISTRATION FORM

2nd IFIP Working Conf. on Dependable Computing for 
Critical Applications (February 18-20, 1991)

Return to: Hotel Park Tucson, 5151 E. Grant Road, Tucson, AZ 85712
      Phone: 1 (602) 323-6262  or  1 (800) 257-7275

Please reserve accommodations for:

Name: 
Address: 
Smoking (Yes/No):
Will Share Room With: _________________
Arrival Date: _____________ Time: _____
Departure Date: ___________ Time: _____
Telephone: ____________________________

Check-in time is 3:00 p.m. Check-out is 12 noon.  Reservations must be received
by January 17 to insure rate.  Rooms will be held until 6:00 p.m. on the date
of arrival.  To guarantee your reservation, please enclose a check for one
night's deposit or assure your reservation with a major credit card (American
Express, VISA, Mastercard, Carte Blanche).

Card Type: _________  Exp. Date: _____
Card #: ______________________________
Signature: ___________________________

Rates:                     # rooms  # people
Suite (One Bed)     $85      ______   ______
Suite (Two Beds)    $85      ______   ______

Suite accommodations are on a space availability basis.  All reservations
subject to sales and occupancy taxes.

For More Information:

Rick Schlichting                  Bill Sanders
General Chair                     Local Arrangements Chair
Dept. of Computer Science         Dept. of Elect. and Comp. Engin.
University of Arizona             University of Arizona
Tucson, AZ 85721  USA             Tucson, AZ 85721  USA

Voice:  1 (602) 621-4324          Voice:  1 (602) 621-6181
FAX:    1 (602) 621-4246          FAX:    1 (602) 621-8076
email:  rick@cs.arizona.edu       email:  whs@ece.arizona.edu

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
FIRST CONFERENCE ON COMPUTERS, FREEDOM &amp; PRIVACY 
</A>
</H3>
<address>
Dorothy Denning
&lt;<A HREF="mailto:denning@src.dec.com ">
denning@src.dec.com 
</A>&gt;
</address>
<i>
10 Jan 1991 1519-PST (Thursday)
</i><PRE>

Please copy, post &amp; circulate!      [Abridged by PGN.  Send EMAIL to 
                                    jwarren@well.sf.ca.us for more info.]

         *********************************************************
         *  THE FIRST CONFERENCE ON COMPUTERS, FREEDOM &amp; PRIVACY *
         *********************************************************

             Pursuing Policies for the Information Age in the
                 Bicentennial Year of the Bill of Rights

     Tutorials &amp; Invitational Conference, Limited to 600 Participants
                   Monday-Thursday, March 25-28, 1991

Airport SFO Marriott Hotel, Burlingame, California (San Francisco Peninsula)

Co-sponsors &amp; cooperating organizations include
  Institute of Electrical and Electronics Engineers-USA
  Association for Computing Machinery      Electronic Networking Association
  Electronic Frontier Foundation           Videotex Industry Association
  Cato Institute                           American Civil Liberties Union
  ACM Special Interest Group on Software
  IEEE-USA Intellectual Property Committee
  ACM Special Interest Group on Computers and Society
  ACM Committee on Scientific Freedom and Human Rights
  IEEE-USA Committee on Communications and Information Policy
  Autodesk, Inc.        The WELL           Portal Communications

Sponsored by the Computer Professionals for Social Responsibility
  A nonprofit educational corporation
(415)322-3778,  e-mail: cfp@well.sf.ca.us.  fax: (415)851-2814

ABOUT COMPUTERS, FREEDOM &amp; PRIVACY

We are at a crossroads as individuals, organizations and governments depend
more and more on computers and computer networks.  Within ten years, most
global information will be collected and utilized electronically.

The 1990's are the pivotal decade in which statutes, policies and judicial
precedents will be developed for controlling access, use -- and abuse -- of
computerized information and electronic mail.

Current government and private-sector policies are an uncoordinated jumble,
created as  each group evolves ways  to collect, manipulate, extract,
share and protect computerized and networked information and services.

Data on individuals and groups is being computerized by numerous agencies,
organizations and special interests, often without the knowledge or approval
of those it concerns, and with varying degrees of accuracy.

Computers can greatly assist individuals, organizations and government in
making sound decisions based on efficient access to adequate information --
for personal benefit, business improvement and national well-being.

Or, inappropriate use and regulation can seriously threaten fundamental
freedoms, personal privacy, and the democratic processes that are at the
very foundation of this nation and of any free society.

ABOUT THE CONFERENCE SESSIONS (Tuesday-Thursday, March 26th-28th)

PLENARY SPEAKERS:

* Laurence H. Tribe, Professor of Constitutional Law, Harvard Law School,
offering major policy proposals in the opening Conference session, "The
Constitution in Cyberspace: Law &amp; Liberty Beyond the Electronic Frontier".

* Eli M. Noam, Director of the Center for Telecommunications and Information
Studies, Columbia University, and a recognized leader in telecommunications
regulation, international communications policies and economics, will discuss,
"Network Environments of the Future: Reconciling Free Speech and Freedom of
Association."

* William A. Bayse, Assistant Director, FBI Technical Services Division,
Washington DC, providing perspectives on "Balancing Computer Security
Capabilities with Privacy and Integrity" at the Wednesday evening banquet.

THE CONFERENCE SESSIONS offer diverse speakers &amp; panel discussions:

Trends in Computers &amp; Networks.  Overview and prognosis of computing
capabilities and networking as they impact personal privacy, confidentiality,
security, one-to-one &amp; many-to-one communications, and access to information
about government, business and society.

International Perspectives &amp; Impacts.  Other nations' models for protecting
personal information and communications, and granting access to government
information; existing and developing laws; requirements for trans-national
dataflow and their implications; impacts on personal expression;
accountability.

Personal Information &amp; Privacy.  Government and private collection, sharing,
marketing, verification, use, protection of, access to and responsibility for
personal data, including buying patterns, viewing habits, lifestyle, work,
health, school, census, voter, tax, financial and consumer information.

Law Enforcement Practices &amp; Problems.  Issues relating to investigation,
prosecution, due process and deterring computer crimes, now and in the future;
use of computers to aid law enforcement.

Law Enforcement &amp; Civil Liberties.  Interaction of computer crime, law
enforcement and civil liberties; issues of search, seizure and sanctions,
especially as applied to shared or networked information, software and
equipment.

Legislation &amp; Regulation.  Legislative and regulatory roles in protecting
privacy and insuring access; legal problems posed by computing and computer
networks; approaches to improving related government processes.

Computer-based Surveillance of Individuals.  Monitoring electronic-mail, public
&amp; private teleconferences, electronic bulletin boards, publications and
subscribers; monitoring individuals, work performance, buying habits and
lifestyles.

Electronic Speech, Press &amp; Assembly.  Freedoms and responsibilities regarding
electronic speech, public and private electronic assembly, electronic
publishing, prior restraint and chilling effects of monitoring.

Access to Government Information.  Implementing individual and corporate access
to federal, state &amp; local information about communities, corporations,
legislation, administration, the courts and public figures; allowing access
while protecting confidentiality.

Ethics &amp; Education.  Ethical principles for individuals, system administrators,
organizations, corporations and government; copying of data, copying of
software, distributing confidential information; relations to computer
education and computer law.

Where Do We Go From Here?  [closing session] Perspectives, recommendations and
commitments of participants from the major interest groups, proposed next steps
to protect personal privacy, protect fundamental freedoms and encourage
responsible policies and action.

Also: Tuesday and Wednesday will include structured opportunities for attendees
to identify groups with whom they want to establish contact and, if they wish,
announce topics they would like to discuss, one on one.

ABOUT THIS PREMIER EVENT

This is an intensive, multi-disciplinary survey Conference for those concerned
with computing, teleconferencing, electronic mail, computerized personal
information, direct marketing information, government data, etc. -- and those
concerned with computer-related legislation, regulation, computer security, law
enforcement and national and international policies that impact civil
liberties, responsible exercise of freedom and equitable protection of privacy
in this global Information Age.

For the first time, this four-day invitational event will bring together
representatives from all of these groups and more, all in one place, all at one
time.

Many of the recognized leaders and strongest advocates representing the various
groups having an interest in the issues of the conference will discuss their
concerns and proposals.

A maximum of 600 applicants will be invited to attend.  Balanced representation
from the diverse groups interested in these issues is being encouraged.  Please
see the enclosed Invitation Application for details.

To inform participants about topics beyond their specialties, half-day seminars
are scheduled for the first day (Monday, March 25th).  These parallel tutorials
will explore relevant issues in computing, networking, civil liberties,
regulation, the law and law enforcement.  Each tutorial is designed for those
who are experienced in one area, but are less knowledgeable in the subject of
that tutorial.

To explore the interactions and ramifications of the issues, conference talks
and panel discussions are scheduled for the remaining three days
(Tuesday-Thursday, March 26th-28th).  These will emphasize balanced
representation of all major views, especially including probing questions and
discussion.

Explicit Conference events to foster communication across disciplines are
planned.  Working luncheons, major breaks and two evening banquets will further
encourage individual and small-group discussions.

Speakers include (among others) Ken Allen, Sharon Beckman, Jerry Berman, Paul
Bernstein, Sally Bowman, David Burnham, Mary Culnan, Peter Denning, Dorothy
Denning, Dave Farber (UPenn), Cliff Figallo, David Flaherty, John Ford, Bob
Gellman, Janlori Goldman, Harry Hammit, Martin Hellman, Evan Hendricks, Lance
Hoffman, Don Ingraham, Bob Jacobson, Mitch Kapor, Tom Mandel, John McMullen,
Peter Neumann, Donn Parker, Ron Plesser, John Quarterman, Jack Rickard, Tom
Riley, Lance Rose, Marc Rotenberg, Noel Shipman, Harvey Silverglate, Gail
Thackeray, Robert Veeder, Willis Ware, Sheldon Zenner.

ABOUT THE LOW-COST TUTORIALS (Monday, March 25th)

Seminars on the first day offer introductions to the different disciplines
that intersect in this conference.  These are surveys for individuals not
already expert in the topics presented.  These half-day tutorials are
scheduled in four parallel tracks:

Global Communications &amp; the Worldwide Computer Matrix.  [morning*]
  Survey of electronic-mail &amp; teleconferencing services, global information
access, remote services and the matrix of networks.

Low-Cost Computer Networking &amp; Computer Bulletin Board Systems. [afternoon*]
  Reviews e-mail, bulletin board and teleconferencing alternatives on
personal computers; outlines low-cost PC-based networks and their gateways
to the global matrix.
  -- Mark Graham*, co-founder of Institute for Global Communications,
PeaceNet and EcoNet; Pandora Systems

Current &amp; Proposed International Policies.  [morning*]
  Law and regulation that will or may impact trans-border data-flow and
computer communications, impacting U.S. information practices and
international business.

Federal Legislation Impacting Computer Use.  [afternoon*]
  Detailed review of landmark federal statutes impacting access to
information, privacy of information, computer security and computer crime.
  -- Marc Rotenberg*, former congressional counsel and expert on federal
legislation, CPSR, Washington DC.

How Computer Crackers Crack!  [morning*]
  Suggested by a deputy district attorney specializing in high-tech crime,
this is for law enforcement officials, prosecutors, systems administrators
and Bulletin Board System (BBS) sysops.
  -- Russell Brand*, computer security specialist; programmer with
Reasoning Systems, Palo Alto CA.

How Computer Crime is Investigated.
  [afternoon*]  This reviews investigation, search, seizure and evidence
requirements for pursuing computer crime.  It is for computer users,
computer owners, BBS sysops and investigators unfamiliar with computer
crime practices.

Information Security.  [afternoon*]
  Survey for systems managers of internal and external threats, security
measures, alternatives and other computer and data security issues.
  -- Donn Parker*, a leading consultant in information security and
computer crime, SRI International.

* - Lecturers, descriptions and times were confirmed as of 1/8/91, but may
be subject to change.

CONFERENCE CHAIR
Jim Warren, Autodesk, Inc. &amp; *MicroTimes*
  415-851-7075,  jwarren@well.sf.ca.us / e-mail

                   ============================
                   =  Request for Invitation  =
                   ============================
         First Conference on Computers, Freedom &amp; Privacy
                       March 25-28, 1991
     Monday: Tutorials,  Tuesday-Thursday: Conference Sessions
  SFO Marriott Hotel, 1800 Old Bayshore Hwy., Burlingame CA 94010
For hotel reservations at Conference rates, call:   (800)228-9290 #3

** Invitational Conference, limited to 600 participants. **
  To facilitate useful dialogue and balanced participation by representatives
from all of the diverse groups interested in these issues, attendance is
limited.  (The capacity of the Conference facility is similarly limited).
  All interested individuals are encouraged to request an invitation.
Invitations will be primarily issued on a first-come, first-served basis within
each major interest group.

  Fees if payment is received:    by Jan.31    Feb.1-Mar.15    after Mar.15
    Tutorials (full day)          $  95           $ 145           $ 195
    Conference (3 days)           $ 295           $ 350           $ 400
Conference Registration fee includes three luncheons, two banquet meetings
and selected handouts:
  Please make checks payable to "Computers, Freedom &amp; Privacy/CPSR".
Please don't send cash.  Invitations will be promptly issued, or the
uncashed check will be voided and promptly returned.

Please type or print.  Thank ye, kindly.
name:
title:
organization:
mailing
	address:
city, state ZIP:
phone(s):
fax:
e-mail:

Comments to assist in evaluating this request:

To aid in balancing participation among groups,
  please check all significantly applicable items.
[ ]  user of computers or computer networking
[ ]  user of electronic-mail services
[ ]  user of teleconferencing services
[ ]  user of direct marketing services
[ ]  user of computerized personal information
[ ]  user of government information
[ ]  computer professional
[ ]  BBS sysop (bulletin board system operator)
[ ]  systems administrator / infosystems manager
[ ]  network administrator
[ ]  computer / communications security specialist
[ ]  provider of data communications services
[ ]  provider of electronic-mail services
[ ]  provider of teleconferencing services
[ ]  provider of direct marketing services
[ ]  provider of computerized personal information
[ ]  provider of government information
[ ]  legislative official            [ ] federal    [ ] state
[ ]  regulatory official or staff    [ ] federal    [ ] state
[ ]  law enforcement official        [ ] federal    [ ] state    [ ] local
[ ]  prosecutor                      [ ] federal    [ ] state    [ ] local
[ ]  judicial representative         [ ] federal    [ ] state    [ ] local
[ ]  criminal defense attorney
[ ]  corporate or litigation attorney
[ ]  civil liberties specialist
[ ]  journalist  [ ] newspaper    [ ] television    [ ] radio    [ ] other
[ ]  other:
[ ]  other:
&lt;&lt;1/7/91&gt;&gt;

Please mail form and payment to:
  CFP Conference, 345 Swett Road, Woodside CA 94062

Privacy Notice: This information will not be sold, rented, loaned, exchanged or
used for any purpose other than official CPSR activity.  CPSR may elect to send
information about other activities, but such mailings will always originate
with CPSR.

Sponsor:  Computer Professionals for Social Responsibility, (415)322-3778
A nonprofit, educational corporation  [ Internal Revenue Code 501(c)(3) ]
e-mail: cfp@well.sf.ca.us;            fax: (415)851-2814
Chair: Jim Warren, (415)851-7075

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.76.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.78.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-51</DOCNO>
<DOCOLDNO>IA013-000136-B031-155</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.78.html 128.240.150.127 19970217041256 text/html 20190
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:11:25 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 78</TITLE>
<LINK REL="Prev" HREF="/Risks/10.77.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.79.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.77.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.79.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 78</H1>
<H2> Tuesday 22 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
(No) Viruses in Iraq's EXOCET? 
</A>
<DD>
<A HREF="#subj1.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Risks of NOT believing war game models 
</A>
<DD>
<A HREF="#subj2.1">
Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: MoD computer stolen in UK 
</A>
<DD>
<A HREF="#subj3.1">
Olivier M.J. Crepin-Leblond
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Computer program gives police a bum rap 
</A>
<DD>
<A HREF="#subj4.1">
William H. Glass
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Voting by Phone 
</A>
<DD>
<A HREF="#subj5.1">
Evan Ravitz
</A><br>
<A HREF="#subj5.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
(More) word processor atrocities 
</A>
<DD>
<A HREF="#subj6.1">
Pete Mellor
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
(No) Viruses in Iraq's EXOCET?  (Misguided Missiles)
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein@rz.informatik.uni-hamburg.dbp.de">
brunnstein@rz.informatik.uni-hamburg.dbp.de
</A>&gt;
</address>
<i>
15 Jan 91 11:10 GMT+0100
</i><PRE>

French press (La Liberation) and media reported (Jan.10) in some detail that
computer viruses could be planted, either in advance or afterwards, in French
EXOCET rockets to influence their performance such as to misguide them.
Following a report of the German Press Agency (dpa), German media (on Jan.11)
were full of reports about "viruses in Hussein's rockets".  According to dpa,
(unnamed) French computer scientists said:

   - manufacturers of war material usually implant, "for mere commercial
     reasons", viruses in exported war electronics to provoke, after some time,
     faults and "profitable repair work";

   - though Iraqian weapon computers are "hermetically cut-off from the outside
     world", computer viruses could be implanted e.g. via "weather data";

   - moreover, the built-in computers contain programs which may be triggered
     remotely; the control system of (French-built) EXOCET rockets could be
     switched-off from French ships; the only problem would be the mass of 
     weapon computers to be switched-off simultaneously.

As usual in events related to malicious code, truth is mixed up with
misunderstandings, errors and impossibilities:

   - the implementation of weapon software makes self-reproducing programs
     (=viruses) impossible; moreover, it is very improbable, that such systems
     may be (re-)programmed remotely; French "experts" with such arguments are
     non-trustable;

   - on the other hand, other aspects of "malicious code" may well be present
     in weapon computers; at least in the test phase, rockets can be destroyed
     by triggering a self-destruction system remotely; following the
     well-established principle "never change a running program", such
     "backdoors" (the proper name for this type of malicious code) could
     survive the test version;

   - moreover, French system analysis might well have foreseen scenarios in
     which to defend against French-made rockets (e.g. EXOCETS); French
     warships might remotely influence the EXOCET control systems if this
     remains unchanged by the (Iraqian) users of such technology; with
     equivalent probability, other Western weapon control systems could contain
     similar self-protection mechanisms (e.g.  US' Hawk missiles having been
     captured in Kuweit) ;

   - finally, it is well-published (even in non-military periodicals) that and
     how electronic countermeasures (ECM) may mislead weapon electronics.

Some interesting questions following from such "possibilities":

   - May Iraq detect, influence or adapt such weapon software? As software
     technology is not well-enough developed in Iraq (and most part of the Arab
     world), they probably must rely on foreign experts (as they evidently do
     in other Hi-Tech areas).

   - If French EXOCET rockets are remotely controllable: why did the French not
     warn their "friends" who suffered severe losses through their weaponry
     (e.g., UK in Falkland crisis, or US in the Iran crisis, see accident of USS
     STARK)?  Do they at least now warn and properly equip their allies in
     the Arabian desert?
 
For "RISK experienced" experts, it is not surprising that misinformation lives
best in threatening situations (such as at the Gulf); apart from general
attitudes of newsmedia, computer scientists who nominate their technological
constructs (e.g., "self-reproducing programs") in such inadequate terms as
"viruses" (see also: "intelligence", etc.) are highly responsible for
misinterpretation and misunderstanding by less well informed media people and
the public!  On the other side, authorities and the public only in such
threatening circumstances become aware of riskful assumptions inherent in
contemporary computer systems.  Such unfortunate experience may lead to the
cynical assumption that risks may best be conceived by (hopefully: moderately)
"ex post" experiencing them, rather than analysing and avoiding them "ex ante".

Postscriptum: computer "viruses" may nevertheless play a role in "Operation
Desert Shield".  There are (yet unconfirmed) news items that several thousand
PCs (5000?) have been infected by ordinary "computer viruses".  This would not
be a surprising experience, as the soldiers had to "waste" ample time waiting
for Jan.15; in the absence of other possibilities for spending free time,
computer games (usually a source of "virus" infections) may have played a major
psychological role, maybe with some impact on their "ordinary functional
behaviour".

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
risks of NOT believing war game models
</A>
</H3>
<address>
"FIDLER::ESTELL" 
&lt;<A HREF="mailto:estell%fidler.decnet@scfb.nwc.navy.mil">
estell%fidler.decnet@scfb.nwc.navy.mil
</A>&gt;
</address>
<i>
14 Jan 91 17:34:00 PDT
</i><PRE>

The risk of NOT believing war gaming models should be revisited, in view
of the Congress' vote this past weekend.

In all such "contests" (sports games, wars ...) there is always a chance,
regardless of how low the probability, that some rare event may occur; e.g.,
"mighty Casey may strike out."  This is particularly true when one side (or
both) have some players with particularly LOW vulnerability, and/or some
weapons with particularly HIGH lethality.  The outcome of the "game" will vary
drastically, depending on what happens to these "superior" players/weapons -
and WHEN it happens.

To take a hypothetical case, based on history, SUPPOSE that Gen. Custer had
gone into his last stand, with a hundred Gattling Guns; and suppose that those
operating these guns had plenty of ammo, and were lucky enough to not be
wounded -- at least, until they had done their (dirty) work.  One might imagine
that it would have been Custer's greatest victory.

IF the Congressional debaters were right, Iraq has some "unusual" weapons; IF
these weapons survive long enough to be used, who knows what the outcome might
be?  The lesson of the Spanish Armada's defeat suggests that Gen. Eisenhower
and others were right: After the war starts, no one knows ...
                                                                   Bob

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: MoD computer stolen in UK
</A>
</H3>
<address>
"Olivier M.J. Crepin-Leblond" 
&lt;<A HREF="mailto:UMEEB37@vaxa.cc.imperial.ac.uk">
UMEEB37@vaxa.cc.imperial.ac.uk
</A>&gt;
</address>
<i>
Thu, 17 Jan 91 16:20 BST
</i><PRE>

	Just a quick word to advise RISKS readers that the MOD laptop computer
stolen in UK has been recovered by the MOD. The information was in the press
last week. There was no mention of any arrest. Understandably, since the gulf
hostilities have just started, the MOD is keeping full secrecy about the
outcome of the story.
	The fact that classified military information was present on the hard
disk of a laptop computer would certainly seem to be a risk in itself. It is
even more unbelievable that the laptop was left unattended in a car in Acton
(West London), which is not the safest of areas in London. I certainly would
not leave a laptop (if I had one) in my car in that area !
	When computers were as large as a bus, there was no risk of one being
"lost" in nature. Now they are so small that one can carry them all around the
place. And since a small plastic box looks less important than 20Mb worth of
printed paper (with red ink warning notices), it is worrying that the holder of
this box becomes that negligent.

Olivier M.J. Crepin-Leblond, Elec.Eng. Dept, Imperial College London, UK.

   [The computer's return was also noted by Steve Bellovin
   (smb@ulysses.att.com), Margaret Fleck &lt;fleck@robots.oxford.ac.uk&gt;,
   Tim Steele &lt;tjfs@tadtec.uucp&gt; (who added that although the MoD refused
   to reveal the contents of the note, they said that it convinced them that 
   the data is secure), and Charles Bryant &lt;ch@dce.ie&gt;.  THANKS!  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Computer program gives police a bum rap (Smallberg, <A HREF="/Risks/10.77.html">RISKS-10.77</A>)
</A>
</H3>
<address>
William H. Glass
&lt;<A HREF="mailto:glass@vixvax.mgi.com ">
glass@vixvax.mgi.com 
</A>&gt;
</address>
<i>
Tue, 15 Jan 1991 00:00:11 CST
</i><PRE>

In <A HREF="/Risks/10.77.html">RISKS-10.77</A>, David A Smallberg writes about the problems of a police
department determining its crime solving record.  This reminds me of a problem
I observed years ago while working on a research project studying crime
statistics.  The city of Philadelphia had one of the lowest auto theft rates of
any major city in the US.  One of the principal reasons for this was that if
the car was recovered within 24 hours (as many are), the crime was reclassified
as "joy riding".  The Philadelphia police liked this system because it looked
like good publicity to have a low auto theft rate.  Then, a new federal program
was started that among other things gave funding to local police departments
based on the number of auto thefts.  As you might guess, suddenly Philadelphia
suffered a major increase in auto thefts.

William H. Glass, Management Graphics, Inc., 1401 E. 79th Street, Minneapolis,
MN 55425              Phone: +1 (612) 854-1220         Internet: glass@mgi.com

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Voting by Phone
</A>
</H3>
<address>
Evan Ravitz
&lt;<A HREF="mailto:eravitz@isis.cs.du.edu ">
eravitz@isis.cs.du.edu 
</A>&gt;
</address>
<i>
Mon, 14 Jan 91 23:39:46 MST
</i><PRE>

SECURITY &amp; PRIVACY OF VOTING BY PHONE

The ultimate demonstration that Voting by Phone is reliable is this: we intend
to publish not only the election totals, but how each and every Voter ID number
voted, so you can check that your vote got through correctly.  Since the ID
numbers would be assigned anonymously (drawn randomly from a hat, say) nobody
could possibly know how you personally voted.  Since the "password" part of the
number would not be published, nobody could steal your vote at the next
election, having seen your ID number in the results.

Most usefully, the results could be published on a computer diskette (and be
available for inspection at election offices and libraries) so anyone could
check that the individual anonymous votes indeed added up to the all-important
totals.

This is in keeping with our desire to publish the program that controls the
computer that runs the phone election.  Currently, all the programs (computers
already count most votes in the US) are proprietary software and not open to
our inspection and rarely that of the election officials.

The use of "Caller ID" (also called Automatic Number Identification) to
identify voters by the phone numbers they call from can be easily defeated by
simply voting from any phone other than your own.  Eventually special
solid-state 'smart cards' used with your phone could encrypt your voting so
that you could vote totally anonymously from your own phone as well.

Responding to November's comments:

Voting by phone does not disenfranchise the phoneless!  Phone booths are far
more common than voting booths and of course the call should be free.  Some are
always further from the polls than others -- think of rural dwellers, and how
this would help them.

In Colorado as well, no ID is needed to vote.  They take your signature, but it
is not compared to anything unless you are challenged, which would only occur
if the judges happened to know you personally.  The system is archaic and
relies on the judges knowing us by sight.

The problem of the use of caller ID to prevent 'hackers' from constantly
calling disenfranchising poor neighborhoods with only 1 phone can be solved
thusly: register these phones so the system expects many calls from them.  But
this is likely unnecessary as most attempts to 'guess' ID numbers will fail --
the system needs to lock out only phones that repeatedly try and fail.

Proxy voting should be criminalized and a reward offered for turning in anyone
offering to buy votes.  If one expects coercion, 'prevoting' would preempt
anyone forcing their choice on you.  And since reporting coercion (by phone)
would bring a reward this problem would be minimized.

The 'California problem' of voting on so many issues at once is actually
another benefit of voting by phone -- why struggle with 40 at once when each
could get its own week-long 'slot'?  This also makes voting more timely and
your ID easier to remember. Phone voting makes this economicly practical.

Telephone service bureaus are prepared now with 1000s of lines for just such
applications as phone elections.  By opening the lines for several days (voting
by mail and absentee are precedents for this) and educating people to spread
out their voting, busy signals should be a very small problem indeed.

The main problem of getting the ID numbers to the right people is solved by
having them come in to register for the new system, once.  This would also
prevent them from voting in person as well, just like voting by mail (formerly
'absentee') does.

'Writing in' candidates can be replaced with 'speaking in' their names, along
with the spelling.  The infrequency of writeins will prevent the transcription
from becoming a major expense.

No system is perfect.  But phone voting is more secure, inexpensive,
convenient, and ecological than our archaic system.  That's why most modern
business is done by phone-polling, international banking, e-mail, etc.  The
reason this wasn't done long ago is because it is also the tool for a more
direct democracy -- voting on more referenda and initiatives more often -- and
this threatens the hegemony of our 'representatives', who now rule with the
approval of a diminishing minority of Americans.

The Voting by Phone Foundation can be reached at 774 19th St, #5, Boulder CO
80302 or (303) 444-3596 or eravitz@nyx.cs.du.edu.  We'd be happy to send you
our brochure, or the E-mail version.

Evan Ravitz, Director

</PRE>
<HR><H3><A NAME="subj5.2">
Voting by Phone
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 22 Jan 1991 15:51:51 PST
</i><PRE>

Evan Ravitz' contribution makes an interesting case, although it fails to
adequately address some of our classic vulnerabilities, such as bogus votes
inserted by insiders (or outsider/insider collusions).  (Insiders could also
juggle the expected total number as well.)  No one would complain that HIS or
HER vote was missing, and yet no one would be able to notice the bogus votes!
Another problem is that people would tend to write down their ID/password, and
either forget it or lose it between elections.  Insiders could also wait until
the last minute before closing time and instantaneously vote for those who
hadn't yet gotten around to it.  But there is much merit to the idea.  PGN

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Word processor atrocities
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Mon, 14 Jan 91 09:49:20 PST
</i><PRE>

On the general theme that a word processor does for words what a food processor
does for food, in his column in the Observer on the Sunday before last, Simon
Hoggart recounted the tale of a novelist who decided at the last minute to
change her main character's name from David to Jeff, with the result that a
piece of dialogue about sculpture referred to the previously unknown work
"Michaelangelo's Jeff".

He followed it up last Sunday with a medical study which was originally written
with the family name of the subject of the research given only as "B", to
preserve confidentiality. For some reason, it was decided that the full name
could, after all, be used, which led to the discovery of the new disease
"Hepatitis Blenkinsop".

Peter Mellor, Centre for Software Reliability, City University, Northampton Sq.,
London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

    [Also noted by smith@canon-research-europe.co.uk (Mark Smith).]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.77.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.79.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-52</DOCNO>
<DOCOLDNO>IA013-000136-B031-189</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.79.html 128.240.150.127 19970217041313 text/html 31944
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:11:38 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 79</TITLE>
<LINK REL="Prev" HREF="/Risks/10.78.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.80.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.78.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.80.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 79</H1>
<H2> Wednesday 23 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Lotus Marketplace 
</A>
<DD>
<A HREF="#subj1.1">
various sources
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
UK firms poor on computer health 
</A>
<DD>
<A HREF="#subj2.1">
Olivier M.J. Crepin-Leblond
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Data privacy abuse in Australia 
</A>
<DD>
<A HREF="#subj3.1">
Phil Clark
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
MasterCard policy opens door to crooks 
</A>
<DD>
<A HREF="#subj4.1">
Marv Westrom
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Lotus Marketplace
</A>
</H3>
<address>
&lt;<A HREF="mailto:Peter G. Neumann <neumann@csl.sri.com> ">
Peter G. Neumann &lt;neumann@csl.sri.com&gt; 
</A>&gt;
</address>
<i>
Wed, 23 Jan 91 15:00:23 PST
</i><PRE>

Excerpted [by PGN] from today's Wall Street Journal (23 Jan 91) and AP items.

[Lotus Development Corp. was expected to announce today that it will drop its
plans to place on the marketplace Lotus Marketplace, discussed here copiously
in earlier issues (<A HREF="/Risks/10.61.html">RISKS-10.61</A>,62,63,68,74).]

``The turnaround on Marketplace suggests that technology companies are slowly
learning how to strike a publicly acceptable balance between privacy and the
explosion of electronic data.  One example came last year when phone companies
introduced "Caller ID" options that flash a caller's number on the other
party's phone.  In response to consumer complaints, some phone companies are
adding a feature that lets callers block their numbers.''  [WSJ]

``Lotus said it also would discontinue shipment of Lotus MarketPlace: Business,
a database of information on 7 million U.S. businesses. That product had been
offered since October.'' [AP] [The WSJ article implied that this product would
NOT be cancelled.]

``Marketplace touched a raw nerve among consumers, and took on a broad symbolic
significance in the debate over electronic privacy.  When Lotus offered to
delete data about anyone who called or wrote, it was flooded with about 30,000
requests.  Consumers learned about the product through widespread news reports.
... Marketplace also became one of the hottest topics on the computer networks
linking technology students and professionals.  Complaints and protest letters
were posted an copied on hundreds of networks.  Opponents circulated Lotus's
phone number and the electronic-mail address of Jim Manzi, its chief executive
officer.  "If you market this product, it is my sincere hope that you are sued
by every person for whom your data is false, withe the eventual result that
your company goes bankrupt," declared one letter to Lotus that was posted on
several networks.''  [WSJ]

``Privacy advocates' chief objection to Marketplace was that it wouldn't
be easy enough for consumers to delete their data, or correct any
inaccuracies.  They worried that even if Lotus offered to update the
disk with corrections and deletions, offending earlier versions would
still go on sale.''  [WSJ]

``Lotus and Atlanta-based Equifax spent two years developing Marketplace
Household. Lotus spokesman Richard Eckel declined to estimate Lotus'
development costs.''  [AP]

``"There was no effective way to make sure that everyone listed on that product
had freely consented," says Marc Rotenberg, Washington director of Computer
Professionals for Social Responsibility.  The nonprofit group was one of
Marketplace's loudest opponents.''  [WSJ]

And then there was this item, contributed roundabout, in a memo today from Jim
Manzi to Lotus and Equifax folks, announcing the demise of both products:

  ``Unfortunately, we feel the majority of concern over the Households product
  has been generated by misinformation about the product's content and a general
  lack of understanding about the direct marketing industry.  From the very
  beginning, Lotus and its data partner, Equifax Marketing Decision Systems,
  implemented a number of privacy-related controls that exceeded traditional
  direct marketing industry practices.  We felt confident that these procedures
  limited any potential abuse of the product.  Consumers should demand that
  future products of this type be as scrupulous and responsible.''  [Jim Manzi]

    [The WSJ item was noted by Sean Kirkpatrick &lt;sean@NISD.CAM.UNISYS.COM&gt; and
    others.  The AP item was noted by Steve Bellovin &lt;smb@ulysses.att.com&gt;; an
    earlier personal phone call to Lotus attempting to get himself removed from
    the database resulted in Scott Wilson &lt;swilson@pprg.unm.edu&gt; being told
    that there would be no database from which he could be removed.  

    On Monday, Roger H. Goun  &lt;goun@ddif.enet.dec.com&gt; noted an article in
    the Boston Globe Business section, T.G.I.M. column, 21 January 1991, the
    writer of which included the following premonition to those who wanted to 
    object to their being in the database:

      Save your breath, and save Lotus the dime.  They're getting the message.
      If I were a betting man, I'd bet you won't see Lotus in this Marketplace
      much longer.   

    And yes, for you skeptics, there are still 10-cent payphone calls in
    Massachussetts, among other places, although the incoming 800 number is
    probably not exactly 10 cents per call.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
UK firms poor on computer health
</A>
</H3>
<address>
"Olivier M.J. Crepin-Leblond" 
&lt;<A HREF="mailto:UMEEB37@vaxa.cc.imperial.ac.uk">
UMEEB37@vaxa.cc.imperial.ac.uk
</A>&gt;
</address>
<i>
Thu, 17 Jan 91 16:19 BST
</i><PRE>

This article has appeared in a specialised publication in UK called Technology
Graduate, Nov/Dec 1990 issue.

        British companies are not doing enough to safeguard their employees
against the health hazards of working with computer technology.  Only a quarter
of businesses take formal health and safety measures, according to a survey
published in "Which Computer ?" magazine.
	A sixth of the organisations who took part in the survey reported staff
illness directly related to the use of information technology equipment,
injuries such as headaches, repetition strain injuries (RSI), eye problems and
back, neck, wrist and finger ailments.  A third of them said they received
staff complaints about the health risks associated with computers.
	However, employers will soon be compelled to take statutory action on
the welfare of staff. By the end of 1992, EC member states have to put up with
a directive which lays down minimum health and safety requirements for work
with IT. Employers will become legally responsible for ensuring that all new
equipment installed meets its requirements; existing equipment must be brought
up to standard within four years.
	The directive also governs mandatory inspections of computer equipment
and sets down minimum standards for the ergonomic design of computer screens
and keyboards, desks, seating and lighting.
	It provides for training and organisation of time to allow for periodic
breaks from screen work and regular free eye tests and glasses where necessary.
	Display screens must be flicker-free and fully adjustable.  The
keyboard must also be separate from the screen. Sufficient desk space must be
provided for hand and arm support. Computer users' chairs must be adjustable
and a footrest must be available on request.
	Many of the companies surveyed were ignorant of both the risks and of
where so seek advice on computer health and safety.  Less than a quarter had
consulted the Government's Health and Safety Executive on computer users'
rights and only one in 10 had taken advice from an ergonomist. "

 - Typing this has given me a backache. -

Olivier M.J. Crepin-Leblond, Elec. Eng. Dept, Imperial College London, UK.

                                                        [Cogito, ergo nomics.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Data privacy abuse in Australia
</A>
</H3>
<address>
Phil Clark
&lt;<A HREF="mailto:pgc@csadfa.cs.adfa.OZ.AU ">
pgc@csadfa.cs.adfa.OZ.AU 
</A>&gt;
</address>
<i>
17 Jan 91 00:44:26 GMT
</i><PRE>

The following items appeared in the "Canberra Times" of Monday 14th January
1991 and Tuesday 15th July 1991. These show how computer information,
databases, banking and credit records are being abused in Australia, with
little or no recourse for the general public.


IN 199O THE Commonwealth Privacy Commissioner published a thick report listing
the extensive tabs the Government keeps on its citizens, including details on
people's sexual lifestyles and relationships, held by the Department of
Immigration, local Government and Ethnic Affairs.

It showed that dossiers are created on people who write to government
ministers, and that the Federal Government has access to all state birth, death
and marriage registers and state vehicle and licence authorities' records,
which it matches up with Medicare, taxation and social-security files. The
Taxation Office collects information on Medicare records, bank accounts,
land-title records, car registration and virtually every immigration movement
into and out of Australia, and the Department of Employment, Education and
Training has access to most university records.

The flow of personal data in Australia is generally freely swapped between
state and federal governments. In 1990 the Government passed the Cash Reporting
Transactions Act, which effectively makes the banking industry an arm of
government, providing details on major transactions, and which is rapidly
moving towards the Government having full on-line computer access to people's
bank accounts. Even the NRMA (*NSW motoring organisation) gives its
three-million-name membership list to help the authorities track down unpaid
parking fines.

Australia lags far behind France, Germany, Singapore, Belgium and Austria,
which have detailed laws protecting privacy. This prompted, by the mid-80s, a
series of European media reports detailing Australia's departure from the norms
of developed countries. Among examples are NSW laws allowing people to be taken
into custody without being charged and forced to give blood, and, more
recently, laws dealing with the search and seizure of private property.

One of the most far-reaching of recent laws is the one that confiscates assets
`SUSPECTED' of being the proceeds of crime or even associated with crime. It
can deny the accused access to his money for legal representation, and in some
cases reverse the onus of proof.

Some of these state laws directly depend upon the ever-increasing information
flow to round up suspects. Many people so accused have been innocent, chosen
for investigation simply because they fitted a certain computer profile, such
as a businessman arrested because he travels overseas a lot and appears to the
computer as if he might be a drug courier.

In a recent radio interview presented by the wife of the NSW Premier, Kathryn
Greiner, it was revealed that a woman had wrongly been reported to the Taxation
Office as running a brothel. The information was reported to the Government by
her credit union, to which she had applied for a loan.

The Cash Transactions Reporting Act in the past six months has caused dozens of
innocent individuals' lives to be invaded by the authorities.  In some cases
their homes have been seized. Most Western European countries strictly prohibit
the collection and networking of data. The next step is the introduction of a
Bill in a few months requiring Australian citizens to have an exit visa before
being allowed to leave the country.

Partly in response to the criticism of the European Press and growing concern
of Australians about privacy, the Commonwealth Government enacted the Privacy
Act. The preamble specifically recites Australian obligations to protect
personal privacy under the International Covenant on Civil and Political
Rights.

The main Act relating to Commonwealth records was passed in 1988, with an
accompanying Bill which purported to regulate the activities of credit-rating
bureaus. After heavy lobbying by the finance industry and the Credit Reference
Bureau of Australia Ltd, the Bill was delayed.

The Act gains nation-wide coverage by a backdoor method to overcome
constitutional limitations. The thinking of the Government in drafting the
legislation relies upon reform of the way organisations collect and manage
information. The linchpin is the commissioner's power to create a Code of
Conduct which if breached gives the commissioner the power to award
compensation - a duty he has been given to enforce with just 11c per
Australian. As the general manager of the Credit Reference of Association of
Australia Ltd points out, at the time of drafting the prosecution provisions
were rarely (if ever) expected to be used.

The reality is that the privacy legislation already a complex 90-page 
hotchpotch of provisions unable to be read without reference to other
legislation, offers little real protection of privacy and even less compliance
with the spirit of the treaty to which it supposedly gives effect.

The Privacy Act is being used by the Government to add a further obstacle on
top of the already restricted Freedom of Information Act to deny information
legitimately sought by journalists. An example is where ministers' officers
refuse to comment on cases by saying erroneously that the Act prohibits them
from saying anything.

It exempts intelligence agencies, the National Crime Authority, most activities
of government enterprises, and Royal commissions and government ministers. The
information can be used for any purpose or exchanged "for any other purpose"
where the Government believes a person impliedly agreed to such a release.

Because most government-agency forms contain broad boilerplate clauses which
provide for the exchange of information, implied consent "for other purposes"
will nearly always be present. For example, the Department of Immigration,
Local Government and Ethnic Affairs places on its forms that it is the
department's "usual practice [to] pass on some or all such information to
agencies which deal with education, health community services, social welfare,
employment and labour, intelligence, law enforcement, taxation and statistics".

As it stands, the legislation is sufficiently vague to offer Commonwealth
agencies wide discretion in deciding what constitutes implied consent and what
is meant by the word "reasonable". Similarly, the legislation provides a
blanket clause that allows private information to be given out where it is
"reasonably" necessary for the "enforcement of the criminal law or of a law
imposing a pecuniary penalty, or for the protection of the public revenue". It
allows Social Security to match up its records against tax and income details
held by other departments, a practice recently entrenched by data-swapping
legislation passed in the last week of parliamentary sittings.

The exchange of information currently extends to Social Security getting lists
of drivers from taxi companies so it can look for pensioners and the unemployed
attempting to earn a few undeclared dollars. Its computer combs state death
registers to identify deceased beneficiaries. Unfortunately the same procedure
has led to embarrassing errors where innocent people have had their income
stopped because of a mistaken identity.

Social Security and Taxation also use the Credit Reference Association of
Australia Ltd to investigate people's finances.

The legislation is wide enough to cover also the release of information for
ANTICIPATED evasion of any law, such as state stamp duties, investigations or,
for that matter, nearly any act of a state government which has a connection or
responsibility of administering a government Act. In other words, the
exceptions are so wide as to empty the legislation of any real clout.

The legislation fails to address a general fear of the spectre of a 1984 "big
brother" that is an all-knowing omnipresent surveillance, because it does
nothing to control effectively the real mischief which lies in cross-linking
the records which affect a person's life.

Except for tax-file-number information, few controls are put on what state
governments do with information given to them by the Commonwealth.  With up to
a dozen government agencies swapping data, a large number of people learn
secrets, and information may become less accurate on each transfer.

In recent times there have been a number of prosecutions against Social
Security staff, tax officers and other public servants selling data-base
information, police in various states accused of selling motor-traffic and
other government information, and other illegal passages of information.
Private investigators have boasted of how easy it is to extract information.
The average person has reason to have serious doubts as to privacy within state
government records with which the Commonwealth freely swaps data.

The Privacy Commissioner, former barrister Kevin O'Connor, appointed to
administer the Act operates under a number of fetters, including a curious
provision requiring him to have regard to "social interests that compete with
privacy including the general desirability of a free flow of information and
the recognition of the Government and business to achieve their objectives in
an efficient way". This is wide enough to force the commissioner to take into
account government policy aimed at matching up its records and creating
detailed profiles of people's spending patterns for taxation or any other type
of investigations the Government thinks desirable.

At present the commissioner works on a tiny budget of just over $2 million a
year, which is grossly inadequate to carry out his enormous task. He is also
muzzled by extraordinary provisions which' enable the Attorney-General to
certify that he may not investigate certain breaches of the Act by the
Government for such ill-defined reasons as national security, international
relations or where an investigation is planned or where the matter concerns the
methods and practices adopted by law-enforcement or intelligence-type agencies,
despite that it is in this very area that the greatest fears for personal
privacy exist.

The commissioner has limited powers to award compensation in certain cases
although the legislation is silent as to how much and when this provision may
operate. How can a person put a value on having put on public display his
personal affairs, which will never be the same again? How to value the feeling
of being personally invaded and the hassle of clearing it up? To give the
legislation some teeth, the commissioner will need to take a robust attitude in
order to make organisations responsive and to encourage aggrieved individuals
to take the time and trouble to make and follow through a complaint.

Yet even where compensation is awarded, if the person against whom the order is
made refuses to pay, then the whole matter is reheard by the Federal Court, an
expensive and time-consuming process where legal costs can quickly wipe out any
compensation payment.

Tomorrow: Credit reporting agencies.

The Credit Reference Association of Australia is the largest credit-reporting
bureau in Australia and is jointly owned by the banks, insurance companies and
to a lesser extent its smaller subscribers. It has records on about nine
million adult Australians.

Amendments to the Privacy Act that claim to control this agency were passed in
the last fortnight of the 1990 Parliament and heralded by Senator Nick Bolkus
(Lab, SA) as one of the great reforms of the Labor Party. The Bill was
originally introduced in 1988 but stalled for two years while heavy lobbying
took place behind the scenes.

According to the general manager of the association, Bruce Bagon, it hired
former Commonwealth Ombudsman Jack Richardson to draft model legislation for
its own governance.

Contrary to the great achievement claimed by the Government, the recent
amendments to the Commonwealth Privacy Act were not new because the association
had already been restricted since the 1970s under various state legislations
and by its own internal policies.

The effect of the new legislation, which does not become law for another nine
months, claims to restrict who can gain access to consumer files by allowing
access to only "credit providers". This means that many peripheral users such
as real- estate agents, Telecom and insurance companies can no longer get
credit information.

It also prevents "positive reporting" being placed on a file - something the
association had at one stage planned to introduce. Positive reporting puts a
person's current details on file, whether positive or adverse, such as current
credit accounts held and balances owing on each account, payment details and so
on.

Other provisions force the association to separate - but not delete - a
person's "commercial" activities, such as whether a person is a director or
otherwise associated with a failed company or a business.

It also requires publicly available records such as electoral-roll information
and telephone-book information to be stored separately, but not deleted. The
law still allows court judgments and bankruptcy notices to be included on a
person's file.

Similarly, insurance records will be separated.

The result will be that most people will have three files, one for personal
credit, another for insurance, with a last one holding information on any
"commercial" activities.

As with the provisions of the Privacy Act that claim to regulate government
files, the parts that regulate the credit bureaus contain numerous loopholes.
The association's general manager says the legislation adds very little to its
existing practices, except to cause the separation of files. It creates a vague
list of "privacy principles" and requires a "code of conduct" yet to be
formulated to cover the nitty-gritty details of regulation, such as how to
decide what constitutes a person's "commercial", as opposed to personal,
financial activities.

The federal legislation does not give consumers a specific right to directly
ask the credit bureau to remove errors, in contrast to legislation in countries
such as the United States, which has had a Fair Credit Reporting Act since
1971.

This weakness forces customers to go through their credit providers to have the
error completely removed. As the credit provider has no financial incentive to
correct records actively, it in effect puts consumers in the position that the
banks decide when and what to tell the credit bureau. There is virtually no
chance of successful prosecution.

The only restriction placed on the credit provider is that it must tell the
bureau "as soon as practicable" that a person has paid an outstanding bill or
denies liability. In practice this allows the banks the flexibility to delay
making corrections while it "investigates" any other type of error. The
consumer's only direct right is to have a note added to his file stating that
there is an error.

But, unfortunately for the consumer, the maxim "no news is good news" is
especially relevant in the credit industry. Despite any note on the file, a
consumer is unlikely to be given the benefit of the doubt by another potential
credit provider.

The result is that the consumer is effectively at the mercy of the banks
as to when they decide to act on a complaint - a disheartening prospect 
considering the poor service that seems prevalent with banking nowadays.

The US legislation, by contrast, foresaw this problem and requires any disputed
negative items to be removed until (and if) the matter is cleared up. The bank
that made the negative report has 30 days to justify its claim, after which the
negative item permanently lapses.

Although the legislation claims to restrict the use of information for the
purposes of assessing credit applications, it can be used for many other
purposes if it believes on "reasonable grounds" that a consumer is no longer
willing to comply with his obligations.

Then the legislation allows the information to be used "in connection" with the
consumer's alleged lack of compliance. This gives great latitude to credit
providers.

In modern credit-management practices, if a person refuses to return phone
calls, refuses to do as the creditor asks or perhaps refuses to discuss the
matter, the consumer runs the risk of being labelled as "delinquent" or as a
"skip", with the result that other credit providers are given the names on a
special alert list.

Just what "reasonable grounds" means to a credit provider or in-house debt
collector is unspecified, unlike the US law, which sets up a specific regime.

There is little chance of successfully prosecuting credit providers or
reporting bureaus. A prosecution must prove corporate criminal liability -
difficult to establish at the best of times but almost impossible under the new
legislation.

The Privacy Act requires that the entity must knowingly or recklessly breach
the Act; show that the employee who committed the act in question did so within
the scope of his actual or apparent authority; have the requisite state of
mind; and finally requires proof that it failed to take reasonable precautions
and to exercise due diligence.  Each of the four criteria must be proved beyond
reasonable doubt.  Privacy legislation in Australia therefore offers very
little to the public.

The various principles and unstated practice codes are so widely defined as to
be meaningless and/or easily interpreted in such a way that nearly any act can
be justified with-in its framework.

With the likelihood of successful prosecution virtually nil, the legislation
does protect tax-file numbers but, far from the breakthrough claimed by the
Government, it remains little more than window dressing.

The Government needs to bite the bullet and use its external-affairs power to
create a uniform and detailed law on privacy for the whole of Australia,
written m plain English in a consolidated Act.

Phil Clark [VK1PC] Department of Computer Science, Australian Defence Force
Academy, Northcott Drive, Campbell, Canberra, Australia, 2600.  +61 6 268 8157

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
MasterCard policy opens door to crooks.
</A>
</H3>
<address>
&lt;<A HREF="mailto:Marv_Westrom@mtsg.ubc.ca">
Marv_Westrom@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Mon, 21 Jan 91 09:56:48 PST
</i><PRE>

I have a MasterCard account which I use regularly. I keep my receipts and match
them to the line items on the statement each month. On January 15th I received
a regular statement which contained an item for which I did not have a receipt.
A phone number is provided on the statement; I telephoned Customer Inquiry to
ask further about the charge. Possibly I had lost the receipt; or possibly the
charge was made incorrectly.
 
A man identifying himself as Warren informed me that they could not provide me
with a copy of the sales receipt, and the only way to address this matter was
for me to write a letter (to Julia) explaining that the charge was incorrect.
There was a second charge to the same merchant (an EXXON station) on the same
day and upon learning that I still had my copy of this sales slip, he explained
that a photocopy of it would be required with my letter so that they would have
proof of an erroneous charge. I felt that these demands defied common business
practice and all common sense but he assured me that this was company policy.
 
MasterCard is a significant presence in our society. I use both MasterCard and
Visa as a part of my regular personal financial activities. These two companies
have a virtual monopoly on this form of credit; I do not have the opportunity
to take my business elsewhere. So perhaps they can use their monopoly power to
institute a policy that is contrary to common sense. But I don't think they
should be allowed to do so.
 
An unscrupulous person knowing that this was MasterCard policy could set up a
system of generating unwarranted charges with some cover of plausible
deniability. Many of these charges would be paid simply because customers do
not check their accounts closely. But even those who notice the spurious
charges now have the onus of taking action and proving that they did not incur
the charge. For a charge of $30 or so, many people would pay up rather than get
involved in the hassle of proving that they did not owe it.
 
What protection do I have from spurious and unwarranted charges to my
MasterCard account, from unscrupulous merchants who could note my number and
then put through fictitious charges and from errors by cooperating merchants
and MasterCard itself? I can see that MasterCard would wish to be relieved of
the burden of being honest and accurate, but surely the onus for proving that I
owe money has to be on them. Notwithstanding that this is contrary to company
policy.
 
I will write my letter to Julia and enclose the proof that she requires. But I
think that MasterCard's policy in this matter is a significant and serious
deviation from acceptable practice and poses a significant risk to us all.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.78.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.80.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-53</DOCNO>
<DOCOLDNO>IA013-000136-B031-213</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.80.html 128.240.150.127 19970217041330 text/html 21651
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:11:56 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 80</TITLE>
<LINK REL="Prev" HREF="/Risks/10.79.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.81.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.79.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.81.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 80</H1>
<H2> Friday 25 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
7th Chaos Computer Congress, Hamburg, 27-29 Dec 1990 
</A>
<DD>
<A HREF="#subj1.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
San Francisco taxes its computer people rather than its property owners 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Not risk versus convenience, but risks of conveniences 
</A>
<DD>
<A HREF="#subj3.1">
Jack Campin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Computer program gives police a bum rap 
</A>
<DD>
<A HREF="#subj4.1">
Mark Hull-Richter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Lotus Marketplace 
</A>
<DD>
<A HREF="#subj5.1">
Richard A. Schumacher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
MasterCard policy opens door to crooks 
</A>
<DD>
<A HREF="#subj6.1">
Steve Pozgaj
</A><br>
<A HREF="#subj6.2">
 anonymous
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
7th Chaos Computer Congress, Hamburg, 27-29 Dec 1990
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein@rz.informatik.uni-hamburg.dbp.de">
brunnstein@rz.informatik.uni-hamburg.dbp.de
</A>&gt;
</address>
<i>
24 Jan 91 14:19 GMT+0100
</i><PRE>

In its 7th year, the annual conference of Chaos Computer Club was held in
Hamburg (Germany) in the last week of December. A broad spectrum of themes was
offered, dominated by networking, but also covering legal aspects, ecological
computing, freedom of information, female computer handling, psychology of
hackers and others.  Among the more than 300 participants, only few people from
European countries (Netherland, Italy) and USA participated.  The Congress
newspaper (covering reports about most sessions, available as *.DOC or *.TXT
files, see below) is only in German.  Though the printed (DTP-ed) version of it
looks more professionally, some essential discussions (e.g.  female computer
handling, computer viruses, the new German Information Security Agancy, GISA)
are missing; quality and readibility of articles is rather mixed.  As there
were only few spectacular themes (phreaking, copying bank cards), public
interest and coverage in newsmedia, as compared to CCC'89 (the year, when the
KGB hack was published) was moderate.

Among the spectacular themes, a group HACK-TIC from Netherland demonstrated a
machine (about 1,500$) to copy credit and Eurocheque cards (EC); according to
Wau Holland (co-founder of CCC), this was arranged "to demonstrate the
insecurity of these plastique cards".  While the speaker of Hamburg's saving
bank (HASPA, which was the victim of CCC's famous "Btx/HASPA-attack") said that
this is impossible, a journalist of BILD (a German boulevard newspaper)
received a printout of his account with a copy of his card, but when trying to
order money from a teller machine, his card was collected.

The most spectacular event was a workshop on (phone) "Phreaking".  Experiences
and methods how "to call as far as possible with as many phreaks as possible at
lowest possible price" were described in some detail (few of which were
written).  Tricks with German PTT's 130-number (and connection to US' 700/800
numbers) as well as with the (PTT-internal) test number 1177 to establish
low-cost (at least for the phreaks) teleconferences and voice mailboxes were
discussed. It is surprising to hear from a US phreak that the old tricks (2,600
MHz, red boxes to simulate the coins' click) even work today; some new
experiences esp.  tricks with Calling Cards (due to missing expiration date on
some cards or delayed update of MCI databank) were added to "help fight the
excessive telephone costs".  Dutch phreaks informed about "use" of 008-numbers;
a hotel reservation service at a large airport doesnot check the validity of
credit cards (file: PHREAK.DOC).  The workshop was not concerned with legal
aspects of Phreaking.

Several sessions were devoted to networking.  Chaos Computer Club runs a
network ("Zerberus") with gateways to international networks and a growing
number of regional mailbox systems.  Despite mixed (or even bad) experiences
with new mailbox systems and gateways (the gateway group emailed invitation to
this workshop; 50% of the invitations came back, essentially with "error-mail";
file NETWCHAoS.DOC), several sessions were devoted to introductions into
networking (file WSI-NET.DOC covering a detailed INTERNET survey; several files
on GATOR, a GATEway ORientation guide to regional and international
communication and gateways).  A special report was devoted to communication of
graphic and sound data, where special standards, command languages and software
are under development (file SCF.DOC).  Special discussions were devoted to
applications of mailboxes for ecological purposes (file UMWE-DFU.DOC) and as
infrastructure for publications (file Med-DFU.DOC), as well as to aspects of
(German) publication laws (file PRESRECH.DOC).

One session was devoted to CCCs idea to aid the former GDR (now "5 new federal
countries") in establishing a citizen computer network "DDRNET".  Despite of
significant aid by computer dealers (who spontaneously donated PCs, software
and modems in significant numbers) and despite of the interest of local groups
and parties (New Forum, essential force in the East-German revolution), tax and
organisation problems finally stopped the project when German reunification
happened.  The document (file: DDRNET.DOC) gives a lively example of good ideas
and plans being killed by hostile bureaucracy.

Following earlier CCC' discussions on sociological aspects of hacking, a
student (Tommy) described his examination thesis (diplom work) relating
Psychology and Computing (file PSYCHO.DOC, thesis in compacted form: PSYCH.LZH
in 109kBytes). According to Tommy, hackers exhibit their self-consciousness as
an elite by their techno-speak. "Ordinary" people of same age with no
understanding of computing are rather suspicious about hackers, even more as
computers appear as threats to their civil rithts and working places.  In such
controversies, hackers seems to flee reality, mostly unconsciously, and they
live in simulated worlds such as Cyberspace ("not as dangerous as other
drugs").  Anonymous or technically depersonalized communication (e.g.
mailboxes) lowers the threshold of moral scruples, resulting in communication
garbage and flames. Btw: as in previous years, a special workshop on Cyberspace
demonstrated EEG-coupled graphical devices and software (file: CYBER.DOC); the
sub-culture (as initiated by Gibson's book "Neuromancer") developing around
this techno-drug has it's first European magazines (Decoder, Cyberpunk).

A special discussion developed on computer "viruses".  Two speakers working
with Ralph Burger (author of the "Big Book of Computer Viruses", also
publishing virus code in German, English and Russian) described his work to
classify new viruses and to establish a databank of virus code.  In their
classification, the group starts with a specific model of virus mechanisms
including self-encryption; this model is in some contradiction with other
classification (e.g.  as a virus in their model must always have an effect,
parent viruses like DONOTHING having no effect would not be a virus while their
descendants are), and stealth mechanisms other than encryption are not
foreseen. The speakers argued that information on virus details should be
easily accessible to all relevant parties.
 
A controversial discussion arose when the author of this report informed about
the establishment of CARO (=Computer Antivirus Research Organisation, cofounded
by V.Bonchev/Sofia, Ch.Fischer/Karlsruhe, F.Skulason/Rejkjavik, A.Solomon/UK,
M.Swimmer/Hamburg, M.Weiner/Vienna and the author) to establish a database with
virus specimen and procedures to quickly analyse new viruses and distribute the
disassemblies for verification and antivirus developmernt.  As the number of
viruses grows significantly (more than 400 MsDos viruses known, plus new
developments visible in Soviet Union, Hungary etc) with advanced stealth
methods and more sophisticated damage, restrictions in the access to such virus
specimen based on concepts of "trusted persons" and "need to know" are
presently discussed (also controversially).  In contrast to such concepts,
CCC'90 participants and the speakers expressed their view that such virus
specimen should be accessible to any interested party.

Summary: apart from the session on phone phreaking, Chaos Computer Club visibly
demonstrated its distance to criminal activities which dominated the last
conferences (e.g.  KGB hack).  In discussing themes of technical and related
interests, they return to the list of items which were described in their
foundation document (file THESEN.TXT, October 1981).  Themes related to civil
rights (e.g.  "Freedom of Information") are visibly of more interest than
classical hacking techniques.  As CCC didnot discuss any consequences of the
KGB case (after the trial in March 1990) for its members or related persons,
CCC omitted the opportunity to prepare for it's role in future hacks in it's
environment.  While their annual conference was less chaotically organised than
last year, it's structure and future developments remain as the name indicates:
chaotic and computer-minded, yet with a sense for new ideas and applications.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
San Francisco taxes its computer people rather than its property owners
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Thu, 24 Jan 1991 12:02:03 PST
</i><PRE>

Last year, as many as 8700 San Francisco property owners did not receive their
annual tax bill (normally arriving by 1 November).  A "computer glitch" in the
tax collector's office was blamed for not sending bills to owners in the
"default" category (as a result of having missed or been late on a previous
payment).  

[Source: San Francisco Chronicle, 14 Dec 1990.  I finally got around to
entering this item, even though it is now old-hat.  However, I haven't seen
anything further about the problem being fixed, although it presumably has by
now.  Surprisingly, the Tax Collector was quoted as saying he did not think
they would lose money because of the delay!  Not much interest in getting it
fixed?  I would think there would be interest LOST from NOT getting it fixed.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Not risk versus convenience, but risks of conveniences
</A>
</H3>
<address>
Jack Campin 
&lt;<A HREF="mailto:jack@cs.glasgow.ac.uk">
jack@cs.glasgow.ac.uk
</A>&gt;
</address>
<i>
Wed, 23 Jan 91 20:28:58 GMT
</i><PRE>

&gt;From the Glasgow Herald, 18 January 1991:

Superloos reveal all                           by Graeme Smith
********************                           ***************

Vandals who tangle with a new (pounds) 50,000 superloo in Aberdeen face the
prospect of having their misdemeanours revealed to all.

Apparently the most advanced convenience in the world allows undesirables
just 1.7 seconds of misbehaviour before it throws open its door to reveal
their misdemeanours and sprays them with violet coloured dye which will
remain on their skin for at least five weeks.

If, however, you are there for legitimate purposes it will allow you 15
minutes of luxury for just 10p.  The air is perfumed, as well as heated,
there is background music to help you relax and there are special
facilities for the disabled and for baby changing.

When you have completed your business and safely departed the superloo
spruces itself up for the next customer.  The walls, floor and WC
automatically wash themselves down and when the disinfecting cycle is
completed the WC is dried with warm air.

It is careful to ensure that thrifty Aberdonians do not try to sneak in two
at a time to half the cost, or for any other purpose.  It will happily
allow a mother with children and a pram to enter but if two adults step
inside, the computerised equipment which the importers claim is sensitive
enough to tell the size of your shoes, will prevent the door closing.

Three have been commissioned in Aberdeen this week, one in Byron Square in
Northfield, one in a layby on the Stonehaven road on the outskirts of the
city, and the third at North Deeside Road.

(Any Aberdeen readers brave enough to try changing their shoes in one? - jack)

Jack Campin, Computing Science Department, Glasgow University

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Computer program gives police a bum rap (<A HREF="/Risks/10.77.html">RISKS-10.77</A>)
</A>
</H3>
<address>
Mark Hull-Richter
&lt;<A HREF="mailto:mhr@ccicpg.UUCP ">
mhr@ccicpg.UUCP 
</A>&gt;
</address>
<i>
Wed, 23 Jan 91 11:22:09 PST
</i><PRE>

It is with great interest that I read the referenced article.  Of all the
police departments in the state of California, I would have thought that the
Long Beach Police were the least capable of being given a "bum rap", least of
all by a computer program.

Unless things have changed drastically in the last few years, the Long Beach
Police Department is the most likely to deserve a "bum rap".  They had a policy
(unofficial, of course) many years ago of not investigating crimes which they
considered to be unimportant, even when they knew who the perpetrator(s) were
and that there was evidence of same.  Perhaps this was limited to the low-rent
areas with high Hispanic concentrations in the population or other poor areas
of the city, but this happened over and over again during the late 70s and
early 80s (last I checked).

Furthermore, the Long beach Police Department is the one wherein seven police
officers were sued for the wrongful death of a man who was murdered by LBPD
officers in a case of mistaken identity.  This was fairly well-documented in
the press at the time.  Summary: four police cars with seven police officers
were called to a house late in the evening to apprehend a suspect in a series
of crimes.  The suspect was taken out to the police cars where he was beaten to
death by the police despite the fact that, according to witnesses, he did not
resist the arrest in any way nor was he armed.  It turns out the man was the
_wrong_ person, selected (I think) incorrectly from a partial license plate and
his slight resemblance to the real suspect.

Brutality and refusals to enforce of the above nature used to be common in Long
Beach.  I don't know if they still are, but I would be greatly surprised if
not.  Thus, I find it difficult to believe that the computer programs actually
gave them a bum rap.  In fact, it wouldn't surprise me if the LBPD actually
abandoned cases they couldn't solve within one month, hence the reporting.

Mark A. Hull-Richter, ICL North America, 9801 Muirlands Blvd 
Irvine, CA  92713       (714)458-7282x4539      UUCP: ccicpg!mhr    

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Lotus Marketplace 
</A>
</H3>
<address>
Richard A. Schumacher
&lt;<A HREF="mailto:schumach@magnum.convex.com ">
schumach@magnum.convex.com 
</A>&gt;
</address>
<i>
Thu, 24 Jan 91 19:56:58 -0600
</i><PRE>

So Lotus will withdraw its product, and everyone will go home happy and
satisfied that they have preserved their privacy.  Well, as faculty at the
University of Wisconsin - Madison and elsewhere have told me informally, these
people are wrong.  Everything that Lotus was offering on CD-ROM is already
available at "substantially" the same price and conditions; these academics say
they are puzzled about the uproar, since in their opinion Lotus offered nothing
new.

If we want to truly change things it will take new laws and new attitudes in
the business community concerning what information it is acceptable to gather
and use. Halting this one form of marketing won't change anything by itself,
but it can be the opening skirmish in the necessary public relations war.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
MasterCard policy opens door to crooks (Re: Westrom, <A HREF="/Risks/10.79.html">RISKS-10.79</A>)
</A>
</H3>
<address>
Steve Pozgaj
&lt;<A HREF="mailto:steve@dmntor.uucp ">
steve@dmntor.uucp 
</A>&gt;
</address>
<i>
Thu, 24 Jan 1991 09:54:46 -0500
</i><PRE>

&gt; A man identifying himself as Warren informed me that they could not provide me
&gt; with a copy of the sales receipt, and the only way to address this matter was
&gt; for me to write a letter (to Julia) explaining that the charge was incorrect.

This sounds bizarre.  In the 20 years I've been a MasterCard holder, I've had
this problem twice.  Each time I was told that they would indeed send me a copy
of the slip [shich they are legally bound to keep for some number of years].
However, if it turned out to be mine legitimately, then I would be charged a ~$6
processing fee.  If it was indeed not mine, no charge would be incurred.  (In
both cases, it was not my charge!)

So, I believe your "Warren" is simply misinformed, or the laws protecting
consumers in the US are seriously worse than those here in Canada.  However,
there still remains an irk:  I got no reimbursement for the money that they
had forced me to pay while the credit was being processed.  This I find rather
despicable.  I was told by my "Warren" that if I didn't pay the amount as due, I
would be charged interest on it, and, EVEN IF it were not mine, hell would
freeze over before I got the interest credit.

So, even though the charge was erased, I was out of pocket, without
compensation, for the approximately 8 weeks this all took.  On ~$200 at the
then-current rate of 10% savings account interest, that represents about $3!

Steve Pozgaj @ Digital Media (steve@dmntor)

</PRE>
<HR><H3><A NAME="subj6.2">
"Mastercard" Policy
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
Wed, 23 Jan 1991 18:47:31 PST
</i><PRE>

It is worth nothing that almost all issues relating to charges, errors,
credits, etc. on VISA and MASTERCARD statements are under the control of the
particular bank/financial institution issuing the particular card and/or
merchant account in question.  VISA and MASTERCARD themselves are primarily
umbrella organizations for properly allocating purchase charges and credits
among the member financial institutions.  While VISA and MASTERCARD do have
umbrella security regulations, the sorts of problems mentioned by a recent
writer to RISKS should be addressed to the financial institution directly.
Since policies on such matters vary widely between institutions, blaming VISA
or MASTERCARD themselves is probably a misdirected effort.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.79.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.81.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-54</DOCNO>
<DOCOLDNO>IA013-000136-B031-244</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.81.html 128.240.150.127 19970217041346 text/html 22477
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:12:13 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 81</TITLE>
<LINK REL="Prev" HREF="/Risks/10.80.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.82.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.80.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.82.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 81</H1>
<H2> Monday 28 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks in forensic use of dental and medical records 
</A>
<DD>
<A HREF="#subj1.1">
Sanford Sherizen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Kinking Foreign-sold Military Equipment 
</A>
<DD>
<A HREF="#subj2.1">
Karl Lehenbauer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Patriot missiles 
</A>
<DD>
<A HREF="#subj3.1">
Phil Agre
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Electronic cash completely replacing cash 
</A>
<DD>
<A HREF="#subj4.1">
David 'Witt'
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: San Francisco taxes its computer people ... 
</A>
<DD>
<A HREF="#subj5.1">
Bill Davidsen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Random Voting IDs and Bogus Votes (Vote by Phone) 
</A>
<DD>
<A HREF="#subj6.1">
Li Gong
</A><br>
<A HREF="#subj6.2">
 Kathy Vincent
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: Lotus Marketplace 
</A>
<DD>
<A HREF="#subj7.1">
Samuel Bates
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: Superloo 
</A>
<DD>
<A HREF="#subj8.1">
Lars-Henrik Eriksson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks in forensic use of dental and medical records 
</A>
</H3>
<address>
Sanford Sherizen 
&lt;<A HREF="mailto:0003965782@mcimail.com">
0003965782@mcimail.com
</A>&gt;
</address>
<i>
Fri, 25 Jan 91 21:06 GMT
</i><PRE>

A recent review of a book on developments in forensics mentioned that the use of
dental records to reconstruct the identities of bodies was not as successful as
once thought.  The technological developments for the reconstructing of
identities has advanced but the limits are from the original dental records. 
Some dentists have not been recording the true dental history of patients but
have structured their records to reflect the categories that insurance and other
third party coverage plans use for repayment.  This is also a problem with
physicians, who have been treating patients for one problem but reporting
patient treatments with an eye toward what payment structures allow.

This does not have to mean that proper assistance is withheld.  It just points
to the social limits to relying upon technology.

Sandy        Sanford Sherizen, Data Security Systems, Inc., 5 Keane Terrace, 
             Natick, MA 01760                                 (508) 655-9888

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Kinking Foreign-sold Military Equipment
</A>
</H3>
<address>
Karl Lehenbauer
&lt;<A HREF="mailto:karl@sugar.hackercorp.com ">
karl@sugar.hackercorp.com 
</A>&gt;
</address>
<i>
26 Jan 91 03:16:47 CST (Sat)
</i><PRE>

As the complexity of software in military equipment increases, it will be ever
easier for a contractor to slip a kink in.  For example, a special message,
cleverly sent, turns off a jet's engines, changes a missile's course, etc.

As today's allies can quickly become tomorrow's enemies, and hardware a country
exports can end up being used against it, there is some incentive to code in an
"insurance policy."

This would be a two-edged sword because an enemy of your client-customer could
discover a kink in something you sold them, and use it against them.

I have often wondered whether the Star Wars people plan to include a way to
turn off the several thousand "Brilliant Pebble" space-based anti- ballistic
missiles, if they were ever to be deployed.  Being able to update the software
remotely would be desirable too, to put it mildly.  It would seem an essential
requirement, yet it is easy to imagine our guys building and launching
thousands of these things without an off switch for fear that the Soviets would
figure out how to turn them off or reprogram them, and some terrible possible
consequences (of not having a way to switch them off), like bugs causing the
pebbles to attack satellites and spacecraft.                   uunet!sugar!karl

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Patriot missiles
</A>
</H3>
<address>
Phil Agre 
&lt;<A HREF="mailto:phila@cogs.sussex.ac.uk">
phila@cogs.sussex.ac.uk
</A>&gt;
</address>
<i>
Sat, 26 Jan 91 18:22:50 GMT
</i><PRE>

The Patriot missiles genuinely seem to be working well, at least in the desert
environment.  Yet a few years ago the Patriot was the very prototype of the
incompetent high-tech military development program.  Its testing in particular
came in for congressional ridicule.  What happened?  According to its
manufacturer and to various other experts quoted in the press, its software was
greatly improved through the application of software technology developed for
SDI.  These experts regard the success of the Patriot as evidence that the
SDI's software nay-sayers were wrong.  I am willing to calm down for a minute
and give this proposition a serious hearing.  Has anybody got any details?

Phil Agre, University of Sussex

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Electronic cash completely replacing cash
</A>
</H3>
<address>
"David 'Witt' DTN 226-6044" 
&lt;<A HREF="mailto:wittenberg@ultra.enet.dec.com">
wittenberg@ultra.enet.dec.com
</A>&gt;
</address>
<i>
Fri, 25 Jan 91 12:16:14 PST
</i><PRE>

I'm sure I don't have to go into all the RISKS of this, but it is very scary.
The comments at the end that are meant to be reassuring are the scariest part.
He seems to be completely oblivious to people's desire to keep some information
private, even from the govenment.

The problems of reliability are also obvious.

--David Wittenberg

[I didn't see the original article, so I only trust that this is transcribed
accurately.  --dkw]

		The New York Times, Saturday, December 29, 1990

Three Radical Proposals that could transform New York City, the nation
and maybe, the world.     			 by Harvey F. Wachsman

Abolish Cash (Great Neck, N.Y.)

	With the nation's economic tailspin causing the loss of tax revenues,
the President and the Congress are going to be considering a variety of options
that no one will like: raising taxes, cutting services or both.  But before
they increase the burden on the American people, they should consider a system
that would collect all the taxes that are already owed.
	If all the people who do business in cash were forced to report their
incomes accurately - if the under-ground economy were forced to the surface -
the Government could collect an additional $100 billion a year for the nationl
treasury - without raising taxes.  States and cities, many in serious financial
trouble, would also benefit from collecting previously unpaid income and sales
taxes.
	How do we create a system to keep cash businesses honest ??  Eliminate
cash.  That may sound revolutionary, but the exchange of cash for electronic
currency is already used in nearly all legitimate international business
transactions.
	The expansion and application of this concept to domestic transactions
would have tremendous benefits, and not just budgetary ones.  In addition to
forcing cash businesses to report their actual income, it would allow law
enforcement agencies to crack down on illicit enterprises.
	Think about it.  Drug deals, muggings, corruption, businesses
concealing their income - they all require cash and secrecy.  A monetary system
bases solely on electronic currency would leave a trail that would cripple such
enterprises.
	Here's how it would work.  The Government would change the color of the
currency and require all old money to be exchanged at the Treasury.
	Then, all the new currency would be returned by its owners to the bank
of their choice.  All banks would be required to open accounts, free of charge,
to all depositers. (Banks would surely be delighted to provide this service at
it would result in increased deposits.)
	We would offer a period of tax amnesty to encourage compliance, but as
a practical matter compliance would be assured because after a certain date all
currency would be worthless.
	In place of paper money, we would receive new cards - let's call them
Americards - each bio-mechanically impregnated with the owner's hand and retina
prints to insure virtually foolproof identification.
	The Government would supply all homes and businesses, free of charge,
with machines, to read the card, certify the holder's identity, and make
instantaneous electronic debits and credits.  Regardless of what such machines
would cost, the Government, with $100 billion in new revenues and no more
printing and mining costs, would come out ahead.
	And think of the benefits to the average American.  No one would have
to write a check again.  Bills could be paid electronically from home.  Such a
system is already available through banks and businesses on a limited, optional
basis.
	Credit cards would function as they do now.  Americard would simply be
a way of transferring funds from one account to another, without cash.
	For example, on payday, instead of receiving a paycheck, your salary
would be electronically transferred into your account.  At lunch- time, you
would go to your favorite resteraunt - or the local hot dog stand -and instead
of paying cash, you'd use your Americard.  You'd get a receipt instantly and
could get a cumulative record from you bank (or your personal computer) as
often as you like.
	The benefits would be tremendous.  Individuals and businesses would no
longer be able to conceal income.  All transactions would be recorded in a
computerized bank file and would be easy for the I.R.S.  to check.  Muggers and
buglars would be out of business: no one would be carrying cash and stolen
property would be difficult to sell because there would be records of all
transactions.
	Fugitives would be easier to track down, legal judgements easier to
enforce, illegal aliens simpler to spot, debtors unable to avoid their
responsibilities by skipping town.  The census wouln't overlook households.
	The Federal Reserve would be better able to follow the economy, helping
to stabilize the financial markets.  The current series of economic indicators
would be replaced by instant access to solid information.  And with all income
being reported for tax purposes, we could not only balance the budget but
actually cut taxes.
	Some people might be concerned about possible abuses of civil
liberties.  But there would be a record of anyone who entered another's account
- officials would be granted access only after electronic verification of their
hand and retina prints.  Civil and criminal penalties for theft of information
would be devistatingly severe.  Government agencies and prosecutors would be
subject to the same Constitutional contraints that currently exist for access
to bank information or for the granting of wiretaps.
	And there would be no information on the Americard computer that
doesn't already exist in other forms today.  If anything, our rights to privacy
would be more secured with the protections that the Americard would offer.
	And besides, I'd like to ask every parent whose child walks to school
through a gauntlet of drug dealers, everyone whose home has been robbed,
whether they think that their rights have been jeopardized by a system that
could solve all these problems ??
	Since computer systems occasionally fail, Americard would be contained
on several connected secure computers: at the local bank branch, the main bank,
the regional office of the Federal Reserve and the Federal Reserve in
Washington, D.C.
	Americard may seem like a drastic approach but its advent is
inevitable.  In the days of the telegraph and the pony express, who could have
imagined that one day there would be a phone on every street corner in
Manhattan ??

	[Harvey F. Wachsman, a neurosurgeon and lawyer, is president 
	of the American Board of Professional Liability Attorneys.]

                [Also noted by Martin Minow, minow@bolt.enet.dec.com]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
San Francisco taxes its computer people ... (PGN, <A HREF="/Risks/10.80.html">RISKS-10.80</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:davidsen@crdos1.crd.ge.com">
davidsen@crdos1.crd.ge.com
</A>&gt;
</address>
<i>
Fri, 25 Jan 91 15:17:57 EST
</i><PRE>

  Nope, the tax collector is right. People either pay their taxes on
time without fail, or they let them go as long as possible, particularly
when they are thinking of selling the structure and put the money into
either fixup or their pocket.

  The people who are behind are probably not going to pay right away, if at
all. Rebilling them a little later won't lose anthing, the city charges (I
assume) more interest than the banks pay, so better late, actually.

bill davidsen	(davidsen@crdos1.crd.GE.COM -or- uunet!crdgw1!crdos1!davidsen)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
California's DMV licenses (Re: <A HREF="/Risks/10.79.html">RISKS-10.79</A>)
</A>
</H3>
<address>
The Polymath
&lt;<A HREF="mailto:hollombe@ttidca.tti.com ">
hollombe@ttidca.tti.com 
</A>&gt;
</address>
<i>
26 Jan 91 03:03:30 GMT
</i><PRE>

The state of California Dept. of Motor Vehicles (DMV) announced its new format
driver's license last week.  The license appears to be a standard magnetic
stripe (MS) card with the usual driver's license information on the front
including the licensee's photograph as a hologram.  The DMV claims these
licenses will be much harder to fake and forge.  They did not say what specific
information was on the MS.

The risks of MS cards have been discussed here before.  The fact that I'll
probably know what's on my license's MS the day I get it should give some idea
of how insecure that information is.  It takes little more to alter it.

The specifications for MS cards and data are part of a published ANSI/ISO
standard.  The hardware to build an MS reader/writer can be purchased at Radio
Shack.

Further, I can imagine retailers demanding to run my license through their MS
readers along with my credit card or to verify a check.  I'm not happy about
that prospect at all.

The Polymath (aka: Jerry Hollombe, M.A., CDP, aka: hollombe@ttidca.tti.com)
Head Robot Wrangler at Citicorp(+)TTI             Illegitimis non
3100 Ocean Park Blvd.   (213) 450-9111, x2483       Carborundum
Santa Monica, CA  90405 {rutgers|pyramid|philabs|psivax}!ttidca!hollombe

</PRE>
<HR><H3><A NAME="subj6.2">
Random Voting IDs and Bogus Votes (Vote by Phone)
</A>
</H3>
<address>
&lt;<A HREF="mailto:li@helen.oracorp.com">
li@helen.oracorp.com
</A>&gt;
</address>
<i>
Fri, 25 Jan 91 14:16:48 EST
</i><PRE>

The lastest RISKS discussed a proposal of "vote by phone" -- registered voters
are assigned random numbers as ids, and the ids with the corresponding votes
are published afterwards so that voters can verify that their votes are
included correctly.

(1) Talking about the use of randomization techniques, one might also want to
randomize the ballot papers so that on each individual paper, candidiates are
listed in random order.  The gains are obvious -- many people just vote for the
first name (or the last ?).

(2) PGN rightly pointed out the risk that bogus votes can be inserted because
there are no voters who check them.  On this front, bogus votes are sometimes
useful.  David Wheeler and I once thought up the idea of "inserting controled
bogus votes" in the following manner.

Each voter is given an id number to vote, but is told that the number is either
positive or negative.  Suppose there are two candidates, Alice and Bob.  If the
number is negative, a vote for Alice is actually counted as a vote for Bob.
This has the advantage that a third (malicious) party who forces a voter to
vote cannot verify (from the published list) if the vote is indeed the desired
one.  It is easy to generalize to multiple-candidates.  An additional advantage
is that people can write their numbers on papers.  One can steal a number, but
won't be sure how to use it (even if I write down +1234567, I could have
mentally remembered it to be a negative number.  Now I remember 1 bit
information, not a long random number).

Of course, there must be some measures to control (and verify ?) the process of
counting the ballots.  Maybe we are talking about conflicting requirements :-)

Li Gong, ORA Corp., Ithaca, New York.  li@oracorp.com

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Voting by Phone (<A HREF="/Risks/10.80.html">RISKS-10.80</A>)
</A>
</H3>
<address>
Kathy Vincent
&lt;<A HREF="mailto:kathy@rbdc.UUCP ">
kathy@rbdc.UUCP 
</A>&gt;
</address>
<i>
Thu, 24 Jan 91 13:47:04 GMT
</i><PRE>

That's like saying no one can hack your bank account because you have a
personal security code.  And no numbers are so anonymous that someone so
inclined couldn't find out exactly who placed what vote for whom.  You may not
be so inclined, but some people are -- esp people who want to control outcomes,
which is what our secret ballot system is specifically supposed to guard
against.  If information connecting a person with a vote is stored in such a
manner as to prevent fradulent voting, no matter how fragile the linkage,
someone or someones with enough determination can easily find the linkage and
exploit it to their own advantage.

Not to mention ... people with the right kind of electronic equipment can sit
outside your house and monitor your computer keyboard clicks and know exactly
what you're typing.  They can monitor your touch-tone phone tones and know
exactly what numbers you're dialing.  Or what numbers you're using to place
your vote -- including your password and anonymous ID number.  People with
cordless or cellular phones are esp vulnerable.  And with the kind of
technology that makes caller ID possible, well ...

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Lotus Marketplace (Schumacher, <A HREF="/Risks/10.80.html">RISKS-10.80</A>)
</A>
</H3>
<address>
Samuel Bates
&lt;<A HREF="mailto:samuel@cs.wisc.edu ">
samuel@cs.wisc.edu 
</A>&gt;
</address>
<i>
Fri, 25 Jan 91 14:03:49 CDT
</i><PRE>

I would venture to say that the uproar is due to the fact that people heard
about the Lotus product, whereas they didn't hear about the others.  I would be
interested to hear about other ways of getting the same information; if we
object to Lotus putting together the product, then we should object to other
companies doing the same.  If you can get names of companies that produce the
information, I would like to know them.  Barring that, will you tell me the
names of the academics with whom you spoke?

Samuel Bates	samuel@cs.wisc.edu	University of Wisconsin-Madison

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Superloo (Campin, <A HREF="/Risks/10.80.html">RISKS-10.80</A>)
</A>
</H3>
<address>
Lars-Henrik Eriksson
&lt;<A HREF="mailto:lhe@sics.se ">
lhe@sics.se 
</A>&gt;
</address>
<i>
Sat, 26 Jan 91 19:37:57 GMT
</i><PRE>

There is an obvious risk here. In fact, I have read a newspaper report
(although it was several years ago so I can't give any sources), that
this "disinfecting cycle" once started while a girl was still inside.
She later died because of lung damages after having inhaled the
disinfectant fluid.

Lars-Henrik Eriksson, Swedish Institute of Computer Science, Box 1263
S-164 28  KISTA, SWEDEN    +46 8 752 15 09

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.80.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.82.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-55</DOCNO>
<DOCOLDNO>IA013-000136-B031-271</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.82.html 128.240.150.127 19970217041359 text/html 32635
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:12:28 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 82</TITLE>
<LINK REL="Prev" HREF="/Risks/10.81.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.83.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.81.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.83.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 82</H1>
<H2> Tuesday 29 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Patriots: SDI, etc. 
</A>
<DD>
<A HREF="#subj1.1">
Dave Parnas
</A><br>
<A HREF="#subj1.2">
 Nathaniel Borenstein
</A><br>
<A HREF="#subj1.3">
 Phil R. Karn
</A><br>
<A HREF="#subj1.4">
     Hans Mulder
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Re: Patriots and electronic cash 
</A>
<DD>
<A HREF="#subj2.1">
Karl Kluge
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: Electronic cash completely 
</A>
<DD>
<A HREF="#subj3.1">
David Lamb
</A><br>
<A HREF="#subj3.2">
 Larry Nathanson
</A><br>
<A HREF="#subj3.3">
     Randal L. Schwartz
</A><br>
<A HREF="#subj3.4">
 K. M. Sandberg
</A><br>
<A HREF="#subj3.5">
 Peter da Silva
</A><br>
<A HREF="#subj3.6">
 Richard A. Keeney
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Patriot Missile (Agre, <A HREF="/Risks/10.81.html">RISKS-10.81</A>)
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:parnas@qucis.queensu.ca ">
parnas@qucis.queensu.ca 
</A>&gt;
</address>
<i>
Mon, 28 Jan 91 23:21:58 EST
</i><PRE>

Phil Agre &lt;phila@cogs.sussex.ac.uk&gt; asked for comments about the "Patriot"
missiles.  There seem to be people around who are trying to exploit events in
the Gulf War to revive SDI.  Let's look at his remarks one at a time.

&gt;"The Patriot missiles genuinely seem to be working well, at least in the 
&gt;desert environment."

Actually, we have very little information about how well they are working.  We
know that they have had some successes and some failures but we have no idea
how many Patriot's have been fired for each SCUD shot down.

&gt; Yet a few years ago the Patriot was the very prototype of the incompetent
&gt;high-tech military development program.  Its testing in particular came in for
&gt;congressional ridicule.  What happened?

Among other things, it has been given a particularly easy job.  It was
originally developed as an anti-aircraft system, not an ABM system.  In many
ways the job of a terminal phase (point defense) ABM system (for incoming
missiles or warheads in unpowered flight) is much simpler than the
anti-aircraft task for which Patriot was first developed.  Aircraft can take
evasive action and use sophisticated devices to fool systems like Patriot.
Older missiles such as the SCUD can do neither.  I suspect that the Patriot is
still not very effective on its original target, manned aircraft.  The SCUD is
an ideal target for the Patriot.

As far as I can determine the key to the Patriot is the launcher, which has a
sophisticated Phased Array Radar that can track incoming objects, backed up by
a computer that can predict the future path of the object (assuming that it is
not powered or steered).  This is a rather simple job.  The Patriot has an
operator to determine whether an object being tracked is friend or foe and
designate a target.  The Patriot missile itself is launched on a path that will
intercept the path of the incoming missile (another simple application of
physics) and has a very simple homing system that is effective when (and if) it
gets near its target.  Were the target missile to change course drastically
after launch, the Patriot missile would end up somewhere else.  Some reports
indicate that some Patriots have missed their targets and ended up where they
did damage to the buildings that they were supposed to protect.  (These are
unconfirmed reports.)

&gt;According to its manufacturer and to various other experts quoted in the
&gt;press, its software was greatly improved through the application of software
&gt;technology developed for SDI.

The design and production phase of the Patriot was completed in 1980, and the
missile went into operational status in late 1984.  Flight tests of the Patriot
started in 1974.  The development and manufacture tooling stage of the Patriot
was completed in 1980, the year before Reagan took office.  The SDI program was
not announced until 1983.  There was no SDI software technology to be applied
to Patriot.  In fact, I believe the reverse was true.  SDIO funded Raytheon to
see if the Patriot ideas could be used for the terminal phase components of
SDI.  If there was technology transfer, must have been from Patriot to SDI.
Remember that SDI funds were to be used for "research" on the space-based
shield; they were not to be used for improving other weapons.

&gt;These experts regard the success of the Patriot as evidence that the
&gt;SDI's software nay-sayers were wrong.  

Those experts had better go back and read what we "software nay-sayers"
actually said.  The objections that were raised were to the space based aspects
of the system.  I, and others, repeatedly said that the only place where
something could be done was the terminal phase for the defense of important
(hardened) targets.  Terminal phase defense systems like Patriot can operate
without the elaborate communication and synchronization that was envisaged for
SDI and do not have to automate the decisions that would have to be automated
for the space-based system.  Terminal defense systems can have an operator who
makes decisions that would have had to be automated in the space-based system.
The range of terminal defense systems is rather limited and they cannot prevent
the warheads of the incoming missile from detonating if intercepted.  For SCUD
missiles that carry conventional armaments this is not a serious problem.  For
the threat portrayed by SDI supporters it was a fatal weakness.  Patriot is
subject to all the known limitations of terminal phase defense systems.  For
example, the maximum range is reputed to be 70km and the effective range is
reduced if the launcher is not near the projected impact point.

We should never forget that the Patriot was about 19 years in development.
(Remember former President Reagan's generous offer not to deploy SDI for 7
years!)  The SCUD was first deployed about 1965 - Patriot about 19 years later.
All RISKS readers should think about the advances that we have seen in 19
years.  It should come as no surprise that the Patriot can sometimes destroy
missiles that were deployed when its development began.  The interesting
question is what it would do against aircraft and modern weapons.

Dave

</PRE>
<HR><H3><A NAME="subj1.2">
Patriots:  Reprogramming, SDI implications
</A>
</H3>
<address>
Nathaniel Borenstein 
&lt;<A HREF="mailto:nsb@thumper.bellcore.com">
nsb@thumper.bellcore.com
</A>&gt;
</address>
<i>
Mon, 28 Jan 1991 15:16:04 -0500 (EST)
</i><PRE>

I heard this weekend on NPR that American &amp; Israeli technicians are furiously
working to reprogram the Patriots to be "more intelligent about people on the
ground."  It seems that nothing in the Patriot's programming informs it about
the population (or lack thereof) in the area.  The NPR report was unclear on
what the differential actions would be, but I presume that it might have
options regarding the moment of interception, and is being reprogrammed to
favor intercepting when not directly over a populated area.  Aside from being
amazed that this was never taken into account in the first place, I'm awestruck
that they're willing to reprogram the Patriot -- which seems, after all, to
basically work -- right in the middle of the war!  I know I feel like I'm
living dangerously even when I install a new binary in peacetime...

On the subject of "Does Patriot prove SDI could work?"  I think the answer is a
clear and resounding no.  First of all, the Patriots can't even hit all the
SCUD missiles.  Letting 1 of every 10 SCUDs through is a big success, but
letting 1 of 10 Soviet nuclear missiles in would be a disaster.  Second, the
SCUD is a relatively slow missile that follows a fixed trajectory; it would be
useless against anything that can take evasive action, such as a Cruise
missile, and you'd probably need some sort of AI-like techniques to predict the
future trajectory of a Cruise taking evasive action.  Finally, I heard an air
force officer explaining on CNN the other day that the Patriots may never again
be as useful as they are being in this war, because "now that their
capabilities are known, it will be trivial to make the next generation of
missiles able to fool them.  Basically, in this game all the cards are stacked
in favor of the offense."  In other words, we're very lucky that the Patriots
are so well suited to the current situation, but we'd be foolish to extrapolate
wildly to future situations, and particularly to SDI.

</PRE>
<HR><H3><A NAME="subj1.3">
Re: Patriot (<A HREF="/Risks/10.81.html">RISKS-10.81</A>)
</A>
</H3>
<address>
Phil R. Karn
&lt;<A HREF="mailto:karn@thumper.bellcore.com ">
karn@thumper.bellcore.com 
</A>&gt;
</address>
<i>
Mon, 28 Jan 91 20:24:19 EST
</i><PRE>

Ever since the first successful Patriot intercept over Saudi Arabia, I began
waiting for the SDI crowd to being crowing. I didn't have to wait long - Louis
Rukeyser on PBS's Wall Street Week last Friday was one notable example of
engaging mouth with brain in neutral.

But no reputable critic of SDI ever said that a system like the Patriot could
NEVER hit missiles fired singly or in small volleys that target relatively
small areas, carry conventional high explosive warheads, and lack some fairly
obvious countermeasures.

Yet despite the relatively easy targets presented by the Iraqi SCUDs there have
already been quite a few failures of the Patriot to destroy them, and several
cases where the Patriots have themselves apparently caused damage to the cities
they are supposedly protecting. I wouldn't exactly use the phrase "genuinely
seem to be working well" when night after night I see TV footage of missiles
(incoming SCUDs and/or errant Patriots) producing unmistakable explosions when
they hit the ground in Saudi Arabia and Israel.

If the SCUDs launched at Israel over the past two weeks had been carrying
nuclear weapons (which is, after all, the original SDI scenario), northern
Israel would now be a smoking ruin -- Patriots or no Patriots.  Even the
Pentagon admits Patriots are of little use against SCUDs armed with chemical
warheads since they would merely disperse the chemical over the target.  [...]

Phil

</PRE>
<HR><H3><A NAME="subj1.4">
Re: Patriot missiles
</A>
</H3>
<address>
Hans Mulder
&lt;<A HREF="mailto:hansm@cs.kun.nl ">
hansm@cs.kun.nl 
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 18:16:26 +0100
</i><PRE>

In Risks 10.81 Phil Agre writes:

&gt; The Patriot missiles genuinely seem to be working well, at least in the
&gt; desert environment.

Actually, a bug was discovered last week.  Apparently, Patriot launchers
can operate in two modes: fully automatic and human-in-the-loop.  They
have been exercised in human-in-the-loop mode for several years now, and
work rather accurately that way.  But the Patriot launchers defending
cities in Isreal and Saudi Arabia are currently running in fully automatic
mode, primarily on the ground that they can react a few seconds faster
that way.  In contrast, the Patriot launchers defending Incirlik Air Base
near Ardana, Turkey, reverted to running in human-in-the-loop mode after
it was discovered that a bug in fully automatic mode causes the machine to
occasionally launch two missiles for no reason (they are always launched
in pairs -- presumably because they are so reliable :-} ).

A Ministry of Defense spokesperson explained: ``We can't afford to waste
these missiles: they cost $600,000 a piece.''
I haven't seen such a thorough risk assessment for years...

Hans Mulder		hansm@cs.kun.nl

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Risks 10.81 (Patriot missiles and electronic "cash")
</A>
</H3>
<address>
&lt;<A HREF="mailto:Karl.Kluge@G.GP.CS.CMU.EDU">
Karl.Kluge@G.GP.CS.CMU.EDU
</A>&gt;
</address>
<i>
Mon, 28 Jan 1991 21:13-EST
</i><PRE>

1) No one, but no one, that I am aware of ever seriously suggested that it was
impossible to construct software to do terminal interception of ballistic
objects. That is a gross distortion of the arguments over SDI software. The
idea that the success of the Patriot has any impact (sic) on the issues
involved is false.

2) I have seen the electronic "cash" proposal before, and yes these people are
serious. My basic philosophy is that the government should have to justify to
me why I ought allow them to keep data on me. The idea behind this proposal is
that I somehow have to justify to the government why they shouldn't have data
on me -- the old "if you have nothing to hide, it shouldn't bother you"
argument. Given what we know the government is capable of (remember J. Edgar
Hoover, or Nixon's "dirty tricks" squad?) to try to reassure people by saying
"Governmental agencies...would be subject to the same Constitutional constrints
that currently exist...for the granting of wiretaps" is a joke. Almost makes me
want to buy a gun and join the NRA.

Karl Kluge (kck@g.cs.cmu.edu)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Electronic cash completely replacing cash (<A HREF="/Risks/10.81.html">RISKS-10.81</A>)
</A>
</H3>
<address>
David Lamb
&lt;<A HREF="mailto:dalamb@umiacs.UMD.EDU ">
dalamb@umiacs.UMD.EDU 
</A>&gt;
</address>
<i>
Mon, 28 Jan 91 15:39:10 -0500
</i><PRE>

Hmm.  I know this isn't misc.legal or talk.politics, but...  In addition to the
obvious RISKS reasons to resist this one, I imagine any serious proposal would
get tremendous opposition from fundamentalist Christians, demanding (at least)
an exemption for religious reasons.  There's a prophecy in Revelations about
"the mark of the Beast" without which one could neither buy or sell.  There was
tremendous furor about Social Security numbers when they were first introduced,
from the same group, for the same reason.  This proposal is a lot more like the
Mark than SSN's were.

And of course, one exemption would breed others.

David Alex Lamb				

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Electronic cash completely replacing cash (`witt', <A HREF="/Risks/10.81.html">RISKS-10.81</A>)
</A>
</H3>
<address>
Larry Nathanson
&lt;<A HREF="mailto:lan@bucsf.bu.edu ">
lan@bucsf.bu.edu 
</A>&gt;
</address>
<i>
28 Jan 91 22:37:57 GMT
</i><PRE>

&gt;        If all the people who do business in cash were forced to
&gt;report their incomes accurately - if the under-ground economy were
&gt;forced to the surface - the Government could collect an additional
&gt;$100 billion a year for the nationl treasury - without raising taxes.

How is the author so sure of his figures, if this is money that has not been
reported?  

&gt;        How do we create a system to keep cash businesses honest ??
&gt;Eliminate cash.  That may sound revolutionary, but the exchange of
&gt;cash for electronic currency is already used in nearly all legitimate
&gt;international business transactions.

Define "honest".  If every store complied with every last OSHA regulation, most
small businesses couldn't afford to stay in business.  Sometimes small
businesses skirt the rules slightly so as to be able to stay in business. 
There won't be much of an increase in tax revenue, if the letter of the law is
enforced so strongly that no business can survive.

&gt;        Think about it.  Drug deals, muggings, corruption, businesses
&gt;concealing their income - they all require cash and secrecy.  A
&gt;monetary system bases solely on electronic currency would leave a
&gt;trail that would cripple such enterprises.

Just because the listed illegal acts all require secrecy, does not mean that
all secret acts are illegal.  If I share an account with my wife, and we both
have instant access to every last dime, I can't throw her a surprise party or
really be at the bar drinking, when I told her I was at the office.  What about
minors?  Do they have their own card?  Do their parents get to see their
accounts?  Or are they just not allowed to have money?

&gt;        Then, all the new currency would be returned by its owners to
&gt;the bank of their choice.  All banks would be required to open
&gt;accounts, free of charge, to all depositers. (Banks would surely be
&gt;delighted to provide this service at it would result in increased
&gt;deposits.)

Tell that to my bank.  I get hit for around $8 a month just to have an account.
It costs money to maintain the information.  If everything was completely
dependent on this system, as the article states, then it would cost more to
maintain the information.  No bank in their right mind would let me keep a $20
account without a monthly.

&gt;        In place of paper money, we would receive new cards - let's
&gt;call them Americards - each bio-mechanically impregnated with the
&gt;owner's hand and retina prints to insure virtually foolproof
&gt;identification.

What about those who don't have hands?  Or retinas?  Or neither?  If I buy a
pair of socks, I have to be fingerprinted, and put my eye to a machine?  (BTW-
great way to spread conjunctivitis)

&gt;        The Government would supply all homes and businesses, free of
&gt;charge, with machines, to read the card, certify the holder's
&gt;identity, and make instantaneous electronic debits and credits.
&gt;Regardless of what such machines would cost, the Government, with $100
&gt;billion in new revenues and no more printing and mining costs, would
&gt;come out ahead.

Hmmm..  a combination MS card reader, full hand finger print analyzer, retina
scanner, computer, and modem, supplied to every individual that wants one. 
This is supposed to save money over green ink on white paper?  

&gt;        And think of the benefits to the average American.  No one
&gt;would have to write a check again.  Bills could be paid electronically
&gt;from home.  Such a system is already available through banks and
&gt;businesses on a limited, optional basis.

And that's the way it should be.  On an optional basis.  What if I WANT to
write a check?  What if I'm going to mail a check to someone, so that by the
time it gets there, it will be payday, and I'll have money in my account?
Instantaneously paying bills from home is great, IF you want to pay them that
way.

&gt;        For example, on payday, instead of receiving a paycheck, your
&gt;salary would be electronically transferred into your account.  At
&gt;lunch- time, you would go to your favorite resteraunt - or the local
&gt;hot dog stand -and instead of paying cash, you'd use your Americard.
&gt;You'd get a receipt instantly and could get a cumulative record from
&gt;you bank (or your personal computer) as often as you like.

And the hot dog vendor can see how much money I've got in my account?  Every
last hot pretzel vendor on the streets of NYC is going to have a MS card
reader/retina scanner/fingerprint analyzer?  (Not to mention a generator to
keep it running)  Some of these guys can't afford the wood to burn under the
pretzels!

&gt;        The benefits would be tremendous.  Individuals and businesses
&gt;would no longer be able to conceal income.  All transactions would be
&gt;recorded in a computerized bank file and would be easy for the I.R.S.
&gt;to check.  Muggers and buglars would be out of business: no one would
&gt;be carrying cash and stolen property would be difficult to sell
&gt;because there would be records of all transactions.

Money purely man's invention.  If people can't get access to 'real' money, then
they will find something else of value, and trade it instead.  Gold, Silver,
Platinum, and everything else of value would have to be banned.  Not to mention
barter.  This wouldn't even put a dent in illegal activities.  But on the other
hand, Joe's wife could notice that he bought a 24 pack of condoms, the day
after she left on a business trip.

&gt;        Fugitives would be easier to track down, legal judgements
&gt;easier to enforce, illegal aliens simpler to spot, debtors unable to
&gt;avoid their responsibilities by skipping town.  The census wouln't
&gt;overlook households.

I'd say the odds on it magically reducing tooth decay are better than the odds
on it fixing any one of the above problems.

&gt;        And there would be no information on the Americard computer
&gt;that doesn't already exist in other forms today.  If anything, our
&gt;rights to privacy would be more secured with the protections that the
&gt;Americard would offer.

I fail to see the logic underlying that statement.

&gt;        And besides, I'd like to ask every parent whose child walks to
&gt;school through a gauntlet of drug dealers, everyone whose home has
&gt;been robbed, whether they think that their rights have been
&gt;jeopardized by a system that could solve all these problems ??

In other words, in order to prevent crime, we should radically change the
economic structure of our country.  Instead of Americards, how about just
switching to communism!  In the Soviet Union only drug problem is alcohol, and
the muggers are shot in the streets.   It would be a LOT cheaper just to elect
the communist party than to muck around with all this technology stuff.  Maybe
there are some things that Americans hold more dear (like freedom and privacy)
than things even like safety.

&gt;        Since computer systems occasionally fail, Americard would be
&gt;contained on several connected secure computers: at the local bank
&gt;branch, the main bank, the regional office of the Federal Reserve and
&gt;the Federal Reserve in Washington, D.C.

And making the system more complex would tend to reduce problems and increase
security?

&gt;        Americard may seem like a drastic approach but its advent is
&gt;inevitable.  In the days of the telegraph and the pony express, who
&gt;could have imagined that one day there would be a phone on every
&gt;street corner in Manhattan ??

Poor analogy.  There are many inventions and ideas that never made it off the
drawing board.  This will be another.

Larry Nathanson . 726 Comm Av #5J . Boston, MA 02215 . 617 266 7419 

</PRE>
<HR><H3><A NAME="subj3.3">
Re: Electronic cash completely replacing cash (`witt', <A HREF="/Risks/10.81.html">RISKS-10.81</A>)
</A>
</H3>
<address>
Randal L. Schwartz
&lt;<A HREF="mailto:merlyn@iwarp.intel.com ">
merlyn@iwarp.intel.com 
</A>&gt;
</address>
<i>
Mon, 28 Jan 91 15:49:21 PST
</i><PRE>

[...]  I'd hate to see this system in place.  I'm not a luddite, but replacing
moveable tokens for ones and zeroes that are necessarily manufactured and
replicated at will is opening up a whole bunch of issues all at once.  We don't
have the authorization/authentication technology far enough along and cheap
enough to do this on a national scale yet.

And, are you really going to give every man, woman, and child a smartcard?
"Here's your allowance junior.  Oops!  The cardreader is broke.  Well, I guess
you're not getting one today."  And what about the gazillions of vending
machines out there?  Are you going to make those invalid overnight?

A suggestion I had seen was that there'd be small "currency" valid for amounts
under, say, $100.  Banks (or corner vending machines) would provide for
transfers between your smartcard and some "currency".

I think we're getting closer to this compromise forced not by government
mandate, but by economics.  Bills over $100 haven't been printed for quite some
time, because most legitimate uses of those bills have been replaced with EFT.
I'm using cash less and less each day.  I pay nearly all of my daily expenses
with my Visa card.  In fact, the local Burger King and Seven-Eleven stores take
Visa now!  I write checks to pay my bills through the mail, although many
pay-by-phone services exist so that I wouldn't even have to do that.

And not one part of this is by government mandate.  Economics have pushed the
gradual phase-in of the cashless society.  And it's happening quite gradually
and rather nicely, thank you.

Just another cash-kinda-guy,
 
Randal L. Schwartz, Stonehenge Consulting Services (503)777-0095
merlyn@iwarp.intel.com ...!any-MX-mailer-like-uunet!iwarp.intel.com!merlyn 

</PRE>
<HR><H3><A NAME="subj3.4">
Electronic cash completely replacing cash (<A HREF="/Risks/10.81.html">RISKS-10.81</A>)
</A>
</H3>
<address>
K. M. Sandberg
&lt;<A HREF="mailto:sandberg@ipla01.hac.com ">
sandberg@ipla01.hac.com 
</A>&gt;
</address>
<i>
28 Jan 91 21:16:18 GMT
</i><PRE>

The worst part about this is that I am sure that the author believes what is
said, yet fails to understand the risks involved. True, it would get more tax
dollars, but at an unknown cost for all the machines and networks to make it
work. What do you do if you lose your card since nobody will trust you without
it? With cash at least you can put some aside in case of emergency, but with
only a card that may decide to not work it is all or nothing.

It also assumes the the barter system does not exist, after all who would
exchange items for work. Unless you then take inventory of all the items that a
person bought, just to make sure.

Of course the line of "if you are honest, why should it bother you" is bound to
come up. This means that "honest" people would not mind having cameras watching
them all the time since it would cut down on crime, then you could tatto
everyone so that there is no doubt about identification. And so it goes,
welcome to 1984 by Orwell.

Was this in the editorial or opinion section at least? Also what does it take
to get people to think about what they are saying, or to just plain think?

	Kemasa          

</PRE>
<HR><H3><A NAME="subj3.5">
Americard...
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:peter@taronga.hackercorp.com ">
peter@taronga.hackercorp.com 
</A>&gt;
</address>
<i>
Tue, 29 Jan 1991 00:46:28 GMT
</i><PRE>

&gt; 	Think about it.  Drug deals, muggings, corruption, businesses
&gt; concealing their income - they all require cash and secrecy.  A monetary
&gt; system bases solely on electronic currency would leave a trail that would
&gt; cripple such enterprises.

And, of course, let others flower. How well would a cashless economy have
prevented the S&amp;L scandal? And, of course, the government would have to call in
all the precious metals again. This would just make it easier for the rich...
with easily liquifiable assets in the form of stocks, bonds, real estate, and
so on... at the expense of the poor and middle class.

And that's without considering the possibility of fraud in the system itself!

</PRE>
<HR><H3><A NAME="subj3.6">
Re: Abolish Cash
</A>
</H3>
<address>
Richard Keeney
&lt;<A HREF="mailto:keeney@vixvax.mgi.com ">
keeney@vixvax.mgi.com 
</A>&gt;
</address>
<i>
Tue, 29 Jan 1991 00:11:30 CST
</i><PRE>

When I read the artical "Abolish Cash" by Harvey F. Wachsman, "The Government"
appears to be the only safegard in his proposed system.  Many people would
agree with me when I bring up the point that we still have not devised a good
method of completely safeguarding ourselves from the various forms of
government that are necessary to run our society.  A system where the
appropriate legislative body has such absolute control over trade and
enterprise would seriously undermine the population's ability to remove such a
body from power when they no longer agree with that body's policies or
activities.  I would assert that "cash" provides a significant safeguard of our
right to freely assert our political views, especially in the face of
disagreement from those currently in power.

I will go even further and point out that such a legislative body would find it
almost impossible to resist making full use of the level of control offered by
such a system, and would certainly find many innovative ways to make us regret
giving them so much control.  There are many historical examples of how even
the best intentioned use of legislative power can go bad.  Not only do we have
no reason to trust "The Government" with such a system, but we have many
reasons to mistrust them. 

Another weakness of such a system that I would like to point out relates to the
inability of such a system to deal with all the seemingly small but necessary
transactions required to "grease" the machine to make things move smoothely.  I
can imagine that people would become obsessed with every little penny.  When
you have to take the trouble to make an official "transaction", people will
become less generous with things like gratuities, informal loans, small gifts,
etc.

Such a system would be very cruel (perhaps even to the point of violating our
constitutional right to be free from cruel and unusual punishment) to somebody
who is denied access to their money due to a lost or damaged card, an error, or
red tape.  One day everything would seem fine, and the next, wham! "I am sorry
sir, but we cannot accept your Americard due to a hold placed by agency
Red_Tape_Is_Us relating to a delinquent payment of $0.39.  By the way sir, you
can clear that up with them on Mondays between 2:00 and 3:00 PM (excepting
national holidays of course) if you fill out form 55-A-1-55-92194 in triplicate
and have a note from your mom."

I would also like to point out one area that would be very similar to credit
cards that would require additional thinking.  What happens when there is a
dispute over a charge between a merchant and a customer?  Who would have the
onus of proof?  What about when a merchant has to have a person's account
number to post a running series of transactions as in the case of a hotel, for
example?  It would be tough to imagine Uncle Sam eating those disputed amounts
like credit card companies often do to keep the good will of both the card
holder and the merchant.  Truth in advertising would also continue to be a
problem.  How do you know what charge will appear on your card when you put it
into a vending machine or give the number to some mail order merchant?

Finally, I think "Americard" may already be registered as a trademark by
somebody (Ameribank sticks in my head).

Richard A. Keeney, Senior Software Engineer, Management Graphics, Inc.,
1401 East 79th Street #6, Bloomington, MN, 55425      Phone:  +1-612-851-6126         

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.81.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.83.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-56</DOCNO>
<DOCOLDNO>IA013-000136-B031-300</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.83.html 128.240.150.127 19970217041413 text/html 29452
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:12:41 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 83</TITLE>
<LINK REL="Prev" HREF="/Risks/10.82.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.84.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.82.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.84.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 83</H1>
<H2> Tuesday 29 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of automatic flight (flying at low level) 
</A>
<DD>
<A HREF="#subj1.1">
Olivier M.J. Crepin-Leblond
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Broadcast local area networks are a'comin 
</A>
<DD>
<A HREF="#subj2.1">
Tom Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: Risks in forensic use of dental and medical records 
</A>
<DD>
<A HREF="#subj3.1">
Jim Purtilo
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Patriots 
</A>
<DD>
<A HREF="#subj4.1">
Clifford Johnson
</A><br>
<A HREF="#subj4.2">
 Donald L. Wegeng
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Random Voting IDs and Bogus Votes 
</A>
<DD>
<A HREF="#subj5.1">
Raymond Chen
</A><br>
<A HREF="#subj5.2">
 Colin Plumb
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Call for Papers, 7th Computer Security Applications Conference 
</A>
<DD>
<A HREF="#subj6.1">
Daniel Faigin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Call for papers, Theorem provers in circuit design 
</A>
<DD>
<A HREF="#subj7.1">
Victoria Stavridou
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of automatic flight (flying at low level)
</A>
</H3>
<address>
"Olivier M.J. Crepin-Leblond" 
&lt;<A HREF="mailto:UMEEB37@vaxa.cc.imperial.ac.uk">
UMEEB37@vaxa.cc.imperial.ac.uk
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 14:25 BST
</i><PRE>

Following is a translation of a short article published in a French newspaper
"Le Figaro", on 21st January 1991. It was part of a special supplement
describing the new electronic weapon systems the allies are currently using.

  Electronic navigation systems are now so advanced that the pilot of a fighter
airplane is not obliged to play an active role during the flying phase.  The
computer is in fact a better pilot in sorties involving penetration of enemy
territory by flying at very low altitude (under the sensitive radar zones). It
is not prone to tiredness, and much better at avoiding obstacles: it is
therefore possible to fly at supersonic speed ( &lt; 1000 km/h) in a hilly region,
whilst constantly being at an altitude of 15 metres from the ground.  This is
very reliable, since the sensors of the airplane constantly provide data which
the navigation systems computer uses.
  Unfortunately, the actual pilots cannot stand this type of passive flight.
Not because by vanity, but because they tend to get sick: the U.S. Air Force
has found out during experimental missions that even the best and toughest of
pilots gets sea-sick after a few minutes when submitted to accelerations and
bearing changes that he did not generate himself.
  This is so serious that when some pilots arrived at the target site, they had
lost all faculties of analysis, and as a result the U.S. Air Force has decided
to abandon at least partially the concept of automated piloting for very low
altitude flights. "

Olivier M.J. Crepin-Leblond, Elec. Eng., Imperial College London, UK.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Broadcast local area networks are a'comin
</A>
</H3>
<address>
&lt;<A HREF="mailto:Tom.Lane@G.GP.CS.CMU.EDU">
Tom.Lane@G.GP.CS.CMU.EDU
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 11:30:10 EST
</i><PRE>

Today's New York Times states (on page two of the business section) that
Apple has filed with the FCC to reserve radio bandwidth for use in wireless
local area networks.  Instead of running LAN cable all around your building,
you put low-power transmitter/receivers in all your machines, and away you
go.  The assigned bandwidth would be used by all comers on a first come,
first served basis within each area, much as cordless phones or garage door
openers are now.  They estimate 150ft as the useful radius of communication;
data rates would be the same as wired LANs (10Mb/sec or so).

The risks should be pretty obvious to readers of this digest.  Somebody in
the next building could eavesdrop on your traffic, or actively connect into
your net, with NO special hardware.  I sure hope Apple is at least planning
to encrypt the packets---no mention of this, or of any security concerns, in
the article.  (But if they are going to support 10Mb/sec data rates, the
encryption would have to be fairly weak, methinks.)

If I ran a corporate network, I wouldn't touch this with a 10-foot pole.

			tom lane

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Risks in forensic use of dental and medical records
</A>
</H3>
<address>
Jim Purtilo
&lt;<A HREF="mailto:purtilo@cs.UMD.EDU ">
purtilo@cs.UMD.EDU 
</A>&gt;
</address>
<i>
Mon, 28 Jan 91 15:26:31 -0500
</i><PRE>

I can offer first-hand experiences concerning use of technology in forensics.
Some colleagues and I have developed software systems to help manage forensic
information `in the field' following a mass casualty disaster.  Initially we
focused upon dental information, where the goals are to capture both antemortem
and postmortem records rapidly, then suggest possible matches between them.
Based upon suggestions from the software, an expert would take the time only to
perform an autopsy (in order to confirm the match) once enough confidence had
been built up by the software that the match was likely.  Previously, only
paper records were kept; matches were based upon having medical examiners pick
up a file folder of raw records, and then walk down a long row of human
remains, comparing each in turn until a possible match was found.  With our
software, both goals are attained:

1. Some amount of organization was brought to raw data that begins to gush
   forth after a tragedy (dentists employ many recording schemes, most of
   them conflicting, it seems).

2. The heuristic we developed for suggesting matches works.  Our first
   suggestion for a possible match has proven to be correct better than 95%
   of the time, based upon analysis of records that have been made available
   to us following previous air disasters.

So much for the advertising.  Now for the nitty gritty.  The only way we can
obtain this success is by *ignoring* much of the key information that an expert
would use to help make a positive identification!  Earlier versions of our
program attempted to consider detailed information about such things as root
canals, the quality of tooth enamel (hypoplasia, abrasions, mottled), and shape
of incisors.  The program was magnificently successful when used with quality
information.  However, our testing showed that there is almost no quality
information to be had in the first place.  Dentists (some!)  will charge for
work not done, or will mark the wrong tooth on paper records when in a hurry to
get to the next patient (off by one, or right index from wrong side of mouth).
They will mark down the wrong type of filling material.  Or they won't update a
patent's records if they find new work done there by someone else (say, the
patient was on the road, needed a quick filling by someone near at hand).  And
so on.  Never mind the problems that any program will have should you send out
for the records of "Jane and John Doe", only to find Jane answers the phone,
but John's secretary is missing...

Next, the transcription problem.  Lots of data, with diverse formats and
inconsistent attention to details, cannot be accurately transcribed by
assistants conscripted by airlines (or local ME office, or whatever).

With experiments, we were able to find a choice of parameters that is least
likely to be screwed up in the original antemortem form, is sufficient to get
us very close in suggested matches, and yet is simple enough that a spreadsheet
editor can let users enter all the material on one screen.  By giving up the
urge to use all the data and be *exact*, we were able to find a solution that
got very close.  In this case, this is sufficient to guide expert users, who
will then make very good use of their time (confirming matches, not investing
time looking for them).

In summary, Sherizen's observation is correct:  the key problem is obtaining
accurate information in the first place (i.e., we have rediscovered GIGO).
The key engineering problem, therefore, is anticipating common error modes
and adapting our technology accordingly.

Jim Purtilo, Computer Science Department, University of Maryland

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Patriots
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 10:57:45 PST
</i><PRE>

There was an accidental Patriot launch in Turkey of two Patriots against
aircraft returning from Iraq.  Four aircraft took evasive action, and all
esacped.  Although the system was in anti-ballistic (vs. anti-aircraft) mode,
this does show the Patriot may be useless against anything other than
predictably moving hunks of metal, and that automatic launch on warning is as
dangerous as we thought.

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Patriot Missile
</A>
</H3>
<address>
wegeng@arisia.xerox.com 
&lt;<A HREF="mailto:Donald_L._Wegeng.henr801c@xerox.com">
Donald_L._Wegeng.henr801c@xerox.com
</A>&gt;
</address>
<i>
Tue, 29 Jan 1991 10:47:13 PST
</i><PRE>

Dave Parnas writes in RISKS 10.82:
&gt; There was no SDI software technology to be applied to Patriot.

Today I spoke with someone who works in an engineering capacity with a US Army
guided missile group (I didn't ask if my source minded being quoted, so I won't
be more specific).  According to my source, the sensors that are currently
being used on Patriot missiles to track BMs were developed as part of the SDI
program (recall that the Patriot was originally an anti-aircraft system, and
thus used different sensors).  The first test of these new sensors on a Patriot
took place about six months ago at White Sands.  So while the Patriot itself is
not based on SDI technology, the sensors that it uses to track BMs are based on
SDI technology.
                                             Don Wegeng

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Patriots, and whats under them at intercept.
</A>
</H3>
<address>
Ed Wright 
&lt;<A HREF="mailto:edw@sequent.uucp">
edw@sequent.uucp
</A>&gt;
</address>
<i>
29 Jan 91 18:48:59 GMT
</i><PRE>

Some years back I was stationed with HHB 45th Arty (AD) a Nike Hercules unit.
45th ADA was located in Arlington Heights Il, a suburb of Chicago at the time.
The Herc had a high explosive warhead, but could also be fitted with one of
several nuclear warheads.  Contemplating the effects of a nuclear blast over
say Northfield ( a northern suburd of Chicago) and being willing to question
authority I posed to my superior the question "What good does it do to shoot
down a Russian bomber with a missle that will destroy the town under it ?"  and
the reply was "Well son .... what would you rather have: ## kilotons over
Evanston, or 10 to 50 megatons over the loop ?"  Now at the time it almost made
sense, 10 to 50 mt over the loop would sure negate the suburbs, and ## kt in
the burbs would only cause significant damage to the loop area. Please note the
key word is almost.  I have no doubt that the same mindset is in use today and
the question has got to be: "Well son, would you rather have big burning
fragments of Patriot and Scud over the burbs or a Scud downtown ?"  {Could that
be Scud or Scud Lite ? :-) } I sure as hell don't have the answer.  Ed Wright

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Random Voting IDs and Bogus Votes (Vote by Phone)
</A>
</H3>
<address>
Raymond Chen
&lt;<A HREF="mailto:raymond@math.berkeley.edu ">
raymond@math.berkeley.edu 
</A>&gt;
</address>
<i>
Mon, 28 Jan 91 11:34:09 PST
</i><PRE>

In &lt;RISKS DIGEST 10.81&gt; li@helen.oracorp.com proposed a partial precaution
against bogus-vote insertion, namely that some votes be tagged `negative',
meaning that the votes cast are really reversed.  I leave the security and
sociological consequences to more qualified folk.

I address the following claim:

&gt;(even if I write down +1234567, I could have
&gt;mentally remembered it to be a negative number.  Now I remember 1 bit
&gt;information, not a long random number).

I wouldn't trust the public's ability to remember a single bit of information.
Indeed, even I have trouble remember whether the my front door is locked or
unlocked when the handle is in the vertical or horizontal position, and this is
a door I lock every day.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Voting by phone and buying votes
</A>
</H3>
<address>
Colin Plumb
&lt;<A HREF="mailto:ccplumb@rose.uwaterloo.ca ">
ccplumb@rose.uwaterloo.ca 
</A>&gt;
</address>
<i>
Mon, 28 Jan 91 17:29:46 EST
</i><PRE>

This is out of high school history, but fortunately that isn't too far in
the past for me:

The old technique for buying votes had a person watching on the way from the
voting booth to the ballot box.  You had to unfold your ballot and show them a
correctly marked ballot, then go and drop it in the box.  Then you got yor $5
(or whatever it was).  If not, you got a visit from some large guys.

Politics is almost the definitive dirty activity.  We need a very foolproof way
to prevent influence where we don't want it.  I'm not implying that anyone
today would engage in widespread abuse, but blatant vote-buying is not too long
in Canada's history, at least (I don't know about the U.S.), and it could
return in 25 years.

To be secure against bribery and intimidation of individual voters, it must not
be possible for A to prove to B that he did or did not vote for B.  (Well, if
*nobody* in A's district voted for B, then B has some idea, but...)

This is why I like the current method of constructing a human-readable ballot
and placing it in a box.  Recounts are possible, the voter can clearly see what
they're doing, and ensuring that there are initially no ballots in the box and
that each voter places at most one ballot in the box is relatively easy and can
be done by several witnesses.  It's not impossible to abuse, but it requires a
large conspiracy.

Will these voting by phone techniques prevent me from signing up a few hundred
drunks, having them vote from a telephone I supply, with me listening on an
extension, and giving them each a bottle of rum afterwards?  In a marginal
constituency, this could make a difference.

	-Colin

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Call for Papers -- 7th Computer Security Applications Conference
</A>
</H3>
<address>
&lt;<A HREF="mailto:faigin@aerospace.aero.org">
faigin@aerospace.aero.org
</A>&gt;
</address>
<i>
Mon, 28 Jan 91 09:31:11 PST
</i><PRE>

                         CALL FOR PAPERS AND PARTICIPATION

                         Seventh Annual Computer Security
                              Applications Conference
                                December 2-6, 1991
                                San Antonio, Texas

The Conference.  Operational requirements for civil, military, and commercial
systems increasingly stress the necessity for information to be readily
accessible.  The Computer Security Act of 1987 requires that all Federal
agencies take certain actions to improve the security and privacy provided by
federal computer systems. Accomplishing both operational and security
requirements requires the application of the maturing technology of integrated
information security to new and existing systems throughout their life cycle.
This conference will explore technology applications for both civil and
military systems; the hardware and software tools and techniques being
developed to satisfy system requirements; and specific examples of systems
applications and implementations.  Security policy issues and standards will
also be covered during this five day conference.

Papers and Tutorials.  Technical papers and tutorials that address the
application of integrated information security technologies in the civil,
defense, and commercial environments are solicited.  Original research,
analyses and approaches for defining the computer security issues and problems
identified in the Conference's interest areas; secure systems in use or
development; methodological approaches for analyzing the scope and nature of
integrated information security issues; and potential solutions are of
particular interest.  A prize of $500, plus expenses paid to attend the
conference, will be awarded for the best paper written by a student.  For
details contact Ravi Sandhu at the address below.

INSTRUCTIONS TO AUTHORS: Send five copies of your paper or panel proposal to
Ann Marmor-Squires, Program Chairman, at the address given below.  We provide
"blind" refereeing; put names and affiliations of authors on a separate cover
page only.  It is a condition of acceptance that manuscripts submitted have not
been previously published.  Papers that have been accepted for presentation at
other conferences should not be submitted.  Tutorial proposals should be sent
to Daniel Faigin at the address given below.

Papers and tutorial proposals must be received by May 17, 1991.  Authors will
be required to certify prior to June 19, 1991, that any and all necessary
clearances for publication have been obtained, that they will be represented at
the conference to deliver the paper, and that the paper has not been accepted
elsewhere.  Authors will be notified of acceptance by July 29, 1991.  Camera
ready copies are due not later than September 18, 1991.  Material should be
sent to:

           Ann Marmor-Squires  		Daniel Faigin         
           Technical Program Chair      Tutorial Program Chair
           TRW Systems Division         The Aerospace Corporation
           2751 Prosperity Ave.         P.O. Box 92957, MS M1/055
           Fairfax, VA  22031  		Los Angeles, CA  90009-2957
           (703) 876-8161     		(213) 336-8228        
           marmor@a.isi.edu    		faigin@aerospace.aero.org

Ravi Sandhu, Student Paper Award, George Mason Univ., ISSE Dept.,
Fairfax,  VA 22030-4444, (703) 764-4663    sandhu@gmuvax2.gmu.edu

Areas of Interest Include: Advanced Architectures, C3I Systems,	Trusted DBMSs
and Operating Systems, Public Law 100-235, Networks and Open Systems, Software
Safety, Policy and Management Issues, Risk/Threat Assessments, State-of-the-Art
Trusted Products, Electronic Document Interchange and Modeling Applicability,
Certification, Evaluation and Accreditation, 		Current and Future
Trusted Systems Technology, Reviewers and Prospective Conference Committee
Members.

Anyone interested in participating as a reviewer of the submitted papers,
please contact Ann Marmor-Squires at the address given above.  Those interested
in becoming members of the conference committee should contact Dr. Ronald Gove
at the address below.

For more information or to receive future mailings, please contact the
following at:
           Dr. Ronald Gove     		     	     Diana Akers           
           Conference Chairman 			     Publicity Chair       
           Booz-Allen &amp; Hamilton                     The MITRE Corporation
           4330 East-West Highway                    7525 Colshire Dr.
           Bethesda, MD  20814 			     McLean, VA 22102
           (301) 951-2395      			     (703) 883-5907        
           Gove@dockmaster.ncsc.mil                  akers@mitre.org

Victoria Ashby, Publication Chair, The MITRE Corporation, 7525 Colshire Dr.,
McLean, VA 22102	(703) 883-6368		ashby@mitre.org

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Call for papers, Theorem provers in circuit design
</A>
</H3>
<address>
&lt;<A HREF="mailto:Victoria.Stavridou@prg.oxford.ac.uk">
Victoria.Stavridou@prg.oxford.ac.uk
</A>&gt;
</address>
<i>
Fri, 25 Jan 91 15:00:32 GMT
</i><PRE>

                   C A L L   F O R  P A P E R S
                   INTERNATIONAL CONFERENCE ON
    T H E O R E M   P R O V E R S   I N   C I R C U I T   D E S I G N :
       T H E O R Y ,   P R A C T I C E   A N D   E X P E R I E N C E 

             NIJMEGEN, THE NETHERLANDS, 22-24 JUNE, 1992

FOCUS AND OBJECTIVES

   Formal methods are increasingly seen as important in the design of digital
systems. The use of these techniques in practice is often regarded as being
strongly dependent on the support of appropriate mechanized theorem proving
tools.  The purpose of this conference is to provide a forum for discussing 
the role of theorem provers in the design of digital systems. The objective 
is to cover all relevant  aspects of work in the field, including original 
research  as well as case studies and other practical experiments with new 
or established tools.  

   The primary focus will be on the ways in which formal methods are supported
by theorem proving tools, rather than on the theoretical foundations of 
formalisms and design methods. The topics of interest include the philosophy 
behind such tools, their design and development, their evolution, and their 
evaluation through use. Of equal importance is the migration path of a theorem
proving tool and the associated technology into current digital engineering 
practice. 

  The intended audience includes workers in the field of hardware verification
as well as practising digital designers. 


TUTORIALS

   It is intended that the conference will address, among other issues, 
practical questions such as:

   Why use a theorem prover?
   Which theorem prover should I use?
   When should I use it?
   How should I use it?
 
   To enhance this aspect of the proceedings, the working sessions will be 
complemented by tutorials on a variety of theorem proving tools and
associated topics. A Tutorials Chair has been established to ensure that a
wide range of systems are represented and to underline the importance that is
placed on the matter.


PROGRAMME AND PROCEEDINGS

   The conference programme will start with a day of tutorials and
demonstrations, followed by two days of presentations by contributing authors.
The programme will also include invited lectures by three prominent
researchers in the field of machine-assisted verification. The invited
speakers are:

   Mike Gordon, University of Cambridge.
   Warren Hunt, Computational Logic Inc.
   Dave Musser, Rensselaer Polytechnic Inst.
 

   A digest of papers will be made available to participants at the conference
and the proceedings will be published  after the conference. 


ORGANIZATION

   The conference is organized by the Computer and Communications Systems Group
of the University of Nijmegen, the Netherlands. The conference organizers are:

      General Chair:   
    Raymond Boute, University of Nijmegen. 

      Programme Chair:    
    Victoria Stavridou, University of London.  

      Tutorials Chair:   
    Tom Melham, University of Cambridge.   

      Local Arrangements Chair:   
    Huub van Thienen, University of Nijmegen.   


PROGRAMME COMMITTEE

   The programme committee includes:

 Albert Camilleri (HP Labs, UK)  
 Luc Claesen (IMEC, Belgium)  
 Ed Clarke (CMU, USA)  
 Mike Fourman (Edinburgh Univ., UK)  
 Joseph Goguen (Oxford Univ., UK)  
 Allen Goldberg (Kestrel Institute, USA)  
 Keith Hanna (Univ. of Kent, UK)  
 Warren Hunt (CLInc, USA)  
 Jeff Joyce (UBC, Canada)  
 Deepak Kapur (Albany SU, USA) 
 Dave Musser (RPI, USA) 
 Tobias Nipkow (Univ. of Cambridge, UK) 
 Paolo Prinetto (Politechnico di Torino, Italy) 
 Clive Pygott (RSRE, UK) 
 David Shepherd (Inmos, UK) 
 Joseph Sifakis (IMAG, France) 


IMPORTANT DATES

   The important dates are as follows:

30 September 1991 : 
       Final deadline for the submission of papers.
28 February 1992 : 
       Date for notification of acceptance or rejection.
30 April 1992 : 
       Final camera-ready copy due.
22-24 June 1992 : 
       Conference at Nijmegen.

SUBMITTING A PAPER

   Four copies of a complete paper (in English) should be sent to the Programme
Chair at the address given below to arrive no later than  30 September 1991.
Papers must not exceed 6000 words in length, with full-page figures counted as
300 words.  Each paper should include a short abstract and a list of keywords
for subject classification.  All papers will be refereed and the final choice
will be made by the programme committee on the grounds of relevance,
significance, originality, correctness and clarity. Submitted papers must not
be published or under consideration for publication elsewhere in the same or
similar form. Authors of accepted papers will be sent LaTeX style files to
aid in the production of camera-ready copy.

PROPOSALS FOR TUTORIALS

   Proposals are solicited for tutorial presentations on relevant theorem 
proving technology or tools. The intention is that a tutorial will provide
an overview of the basic ideas behind a theorem proving tool, rather than
detailed instruction in how to use it. Tutorials should include an assessment
of strengths and weaknesses of a tool and should concentrate on general issues
such as security, robustness, the degree of interaction required, the user
interface, and the mathematical skill required of the user.  

   Proposals for tutorials should not exceed 1000 words in length and should 
give a clear indication of the topic and structure of the presentation.
Also welcome are proposals for informal demonstrations of working systems.
Proposals for both tutorials and demonstrations should be sent to the
Tutorials Chair at the address given below to arrive no later than 30
September 1991.



ADDRESSES FOR CORRESPONDENCE

   Papers and all general correspondence should, in the first instance, be sent
to the Programme Chair at the following address:

Victoria Stavridou, 
TPCD  Programme Chair, 
Department of Computer Science, 
RHBNC , University of London, 
Egham Hill, Egham, 
Surrey, TW20 0EX, United Kingdom.
Tel: (+44) 865 273808 (until 30/9/91) 
Tel: (+44) 784 443429/3421 (after 30/9/91) 
Fax: (+44) 865 273839/784 437520 
Email: victoria@cs.rhbnc.ac.uk
 
  Proposals for tutorials and demonstrations should be sent to the Tutorials
Chair:

Tom Melham, 
TPCD  Tutorials Chair, 
Computer Laboratory, 
University of Cambridge, 
New Museums Site, Pembroke Street, 
Cambridge, CB2 3QG, United Kingdom.
Email: tfm@cl.cam.ac.uk
 
  All correspondence should include a return postal address and, if possible, 
an electronic mail address.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.82.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.84.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-57</DOCNO>
<DOCOLDNO>IA013-000136-B031-321</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/10.84.html 128.240.150.127 19970217041438 text/html 29175
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:13:02 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 10: Issue 84</TITLE>
<LINK REL="Prev" HREF="/Risks/10.83.html">
<LINK REL="Up" HREF="/Risks/index.10.html">
<LINK REL="Next" HREF="/Risks/10.85.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/10.83.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.85.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 10: Issue 84</H1>
<H2> Wednesday 30 January 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
It's not always pilot error" - Official! 
</A>
<DD>
<A HREF="#subj1.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
IRS overbills for $1B interest 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: Patriots 
</A>
<DD>
<A HREF="#subj3.1">
Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Risks of automatic flight (flying at low level) 
</A>
<DD>
<A HREF="#subj4.1">
Brinton Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Automated brokerage service 
</A>
<DD>
<A HREF="#subj5.1">
Kent M Pitman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Broadcast local area networks are a'comin 
</A>
<DD>
<A HREF="#subj6.1">
Brinton Cooper
</A><br>
<A HREF="#subj6.2">
 P.J. Karafiol
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: Electronic cash 
</A>
<DD>
<A HREF="#subj7.1">
Bob Stratton
</A><br>
<A HREF="#subj7.2">
 Rick Smith
</A><br>
<A HREF="#subj7.3">
 Stephen Perelgut
</A><br>
<A HREF="#subj7.4">
 Art Medlar
</A><br>
<A HREF="#subj7.5">
    who-news?
</A><br>
<A HREF="#subj7.6">
 Ed Ravin
</A><br>
<A HREF="#subj7.7">
 Leslie DeGroff
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
It's not always pilot error" - Official!
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 22:00:48 PST
</i><PRE>

    Tube train's open doors beat fail-safe   (By-line: Dick Murray)
    London Evening Standard, Thursday, 24 January, 1991

A tube train travelled four stops with a set of double doors open after its
"fail-safe" system broke down, it was revealed today.  The driver was not aware
of what had happened until alerted by an off-duty Tube manager who was
travelling on the Circle-line tube at the time.

London Underground has always described such an incident as "the one which
could never happen", and now seriously concerned engineers are worried that a
similar fault might occur on other trains.

The train has had a detailed examination and a full inquiry began today.
Luckily, the incident happened at one of the quietest times of the week, early
on a Saturday morning, but drivers are now worried about the consequences of a
similar incident taking place on a crowded rush-hour train.

London Underground says the driver of the train, which travelled between
Aldgate and Farringdon [the stop at which I get off! - PM], was not at fault.
A light in the cab's control panel tells a driver when all doors are closed.
If a door does not close, the "fail-safe" system should come into operation and
prevent it from moving off.  But in this case - the train was driver-only with
no guard [Sorry to say "I told you so!", but see my previous mailing! - PM] -
it seems the fault may have affected the panel light operation and the
automatic "fail-safe" system.  One driver said: "He got the light that that
everything was OK. He acted by the book."

An Underground spokesman confirmed the incident took place on Saturday, 12
January, and said: "The 6.18am from Aldgate was taken out of service at
Farringdon after a report from a supervisor on the train.  A set of doors
remained open but it appears the driver was not aware of this.  It would appear
to have been a train malfunction."

Peter Mellor, Centre for Software Reliability, City University, Northampton
Sq.,London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
IRS overbills for $1B interest 
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Wed, 30 Jan 1991 10:15:21 PST
</i><PRE>

Having ruled that Dickie Ann Conn of San Jose CA owed $67,714 in back taxes,
the IRS billed her for more than $1 billion (including penalties).  (The ruling
was based on the precedent of a recent court case, and stemmed from charitable
deductions to the Church of Scientology that Conn had claimed over six years.)
When she called the IRS to object, she was told by a clerk that her only
recourse was to sue the government.  Yesterday the IRS admitted that they had
found a mistake in the interest calculations, and said they will correct it.
[Source: San Francisco Chronicle, 30 Jan 91, p.4] (Conn is a computer consultant 
and part owner of Connsult Inc.  She is probably used to jokes about Conn Jobs,
but in this case it sounded as if the IRS was trying to be Conniverous.)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Patriots (Wegeng, <A HREF="/Risks/10.83.html">RISKS-10.83</A>)
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:parnas@qucis.queensu.ca ">
parnas@qucis.queensu.ca 
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 17:35:20 EST
</i><PRE>

Don Wegeng writes that sensors that were developed as part of the SDI research
program, and first tested about six months ago, are now deployed on the
thousands of Patriots in the field.  This is so inconsistent with my experience
with DoD deployment that I would not believe it unless the source was willing
to be identified.  There is a long road between first tests and deployment and
it is not usually travelled in six months.

One should also note that this would mean that SDI money was used to enhance
the Patriot, not that SDI software technology was used to enhance the Patriot.

Dave Parnas

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Risks of automatic flight (flying at low level) (<A HREF="/Risks/10.83.html">RISKS-10.83</A>)
</A>
</H3>
<address>
Brinton Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Wed, 30 Jan 91 9:39:30 EST
</i><PRE>

Olivier M.J. Crepin-Leblond &lt;UMEEB37@vaxa.cc.imperial.ac.uk&gt; reports on the
risks of automatic flight (flying at low level) incurred by fighter pilots:

Perhaps the U.S. Air Force should consider abandoning HUMAN pilots for very low
altitude flights of this type.  As the proposal often begins, 

    "Research is required..."

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Automated brokerage service
</A>
</H3>
<address>
Kent M Pitman 
&lt;<A HREF="mailto:KMP@STONY-BROOK.SCRC.Symbolics.COM">
KMP@STONY-BROOK.SCRC.Symbolics.COM
</A>&gt;
</address>
<i>
Thu, 20 Dec 1990 15:38 EST  [recently resent, never previously received]
</i><PRE>

My company's stock recently did a one-for-ten reverse split and I wanted to
follow the changes in its price.  I figured I might as well use the Charles
Schwab 24-hour 800 number with `automated telebroker,' so I could just punch in
the stock symbol and get info automatically.

I did this a few times at intervals after the split, and it kept telling me
that it was bid at 2-1/4, and asking 2-7/8.  Eventually I became suspicious.
Finally I heard a different price from someone and decided to call Schwab and
find out the straight story.

The guy tried to call up the price of SMBX on his computer and said it wasn't
there.  I assured him it had worked when I tried.  Then he said, ``oh, it's
trading under a new symbol--SMBXD.  It's at--'' and I forget exactly what price
he quoted but it was in the low 1's.

So my stock [fortunately not major dollars] had lots half its value and they
hadn't kept me aware.  Great.  [I wondered if there was any recourse, but
somehow doubt it.] The guy agreed it was a problem that should be fixed and
promised to notify the appropriate people.

Pretty clearly the bug was [and perhaps still is] the presence of an open
record for an account that was `renamed' when the reverse split occurred.

I called a couple days later to see if it had been fixed.  Nope.  At first the
attendant denied that you could call up such a record, and then said ``oh, are
you using that telebroker service?'' What did he think I was using?  The first
thing it says when I call up is to press `1' for the service if I'm using a
touch-tone phone.  Then when I explained the story about how I'd asked that it
be fixed, he said (as if this explained off the problem) ``well, that's an
automated service.''  He went on to add something to the effect of ``If you
really cared, you should have followed it more closely and noticed the problem
sooner yourself.''

&gt;From a corporate point of view, I thought he put forward a phenomenally bad
image for his company and I will pursue my that gripe via the company's
customer relations department.  But from a pragmatic technological standpoint,
he was probably right.  Being in the computer business, I should probably have
known enough to understand that even an automated system like that still relies
on lots of human care and feeding, and is likely to have lots of problems.
Still, I wonder how many non-computer people understand that risk.

The other thing that bugged me in talking to him was the fact that I tried to
explain why it was a bug that when I asked for the dead account, it echoed back
``Symbolics Incorporated'' when all I'd punched in was its code, 73612292
[their telephone keypad code for "SMBX"].  But even now, when I punch in the
right symbol, 7361229231 ["SMBXD"], it echos back "ess em bee ex dee" and
doesn't give me tons of confidence that I'm even asking about the right thing.
He didn't seem to see why that was a problem.  I tried explaining several
different ways why it was important for the system to echo back something
meaningful after I pressed a bunch of digits so I could know I'd pressed the
right ones, and he couldn't seem to grasp why I felt that hearing the right
name after punching the wrong digits contributed to my feeling of having been
deceived, or why it bothered me that even now if you pressed the right digits
you heard something that was not the name of the company.

There should be a place in the world where you can send bug reports about
companies whose facilities for accepting bug reports are broken.  In the long
run, the free market may attend to these things, but in the short run that's
not much of an answer.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Broadcast local area networks are a'comin (Tom.Lane, <A HREF="/Risks/10.83.html">RISKS-10.83</A>)
</A>
</H3>
<address>
Brinton Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Wed, 30 Jan 91 9:44:24 EST
</i><PRE>

Tom.Lane@G.GP.CS.CMU.EDU reports on the filing by Apple computer for allocation
of radio bandwidth to implement wireless local radio networks.  He correctly
observes

&gt;The risks should be pretty obvious to readers of this digest.  Somebody in
&gt;the next building could eavesdrop on your traffic, or actively connect into
&gt;your net, with NO special hardware.  I sure hope Apple is at least planning
&gt;to encrypt the packets... (But if they are going to support 10Mb/sec data rates, the
&gt;encryption would have to be fairly weak, methinks.) ...

Beyond this, the risk for spectral chaos seems to be quite high.  Imagine the
RFI (radio frequency interference) implications of a central city full of
wireless ethernets(tm?) attempting to coexist with cellular phone, radio paging
systems, public safety radio, business use of dispatch radio, amateur radio
repeaters, etc. Pulsed signals 10 Mb/s may well wreak havoc in many such
receivers.
                                        _Brint

</PRE>
<HR><H3><A NAME="subj6.2">
Broadcast local area networks are a'comin
</A>
</H3>
<address>
P.J. Karafiol
&lt;<A HREF="mailto:karafiol@husc8.harvard.edu ">
karafiol@husc8.harvard.edu 
</A>&gt;
</address>
<i>
Wed, 30 Jan 91 09:52:44 -0500
</i><PRE>

This summer I saw ads for a similar product: Appletalk LANS created by a system
of infrared transmitters and receivers.  The idea was that each desk would have
a doodad that would bounce the signals off the ceiling; the system was designed
for a cubicle-type environment where offices were reconfigured frequently.  It
was about $500/connection.  This seems more reasonable than the radio LAN
because we are talking about a true line-of-sight kind of communication;
besides, the beams were only sufficiently intense for about 150'.  To intercept
this LAN would require a listening (watching?) post *outside*the*window* of the
offices in question.  The obvious defense would be to locate on the 56th floor
. . .
						== pj karafiol

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Re: Electronic cash completely replacing cash (Lamb, <A HREF="/Risks/10.82.html">RISKS-10.82</A>)
</A>
</H3>
<address>
Bob Stratton 
&lt;<A HREF="mailto:dsc3rjs@nmdsc20.nmdsc.nnmc.navy.mil">
dsc3rjs@nmdsc20.nmdsc.nnmc.navy.mil
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 15:51:10 EST
</i><PRE>

&gt; ...There's a prophecy in Revelations about "the mark of the Beast" without
&gt; which one could neither buy or sell.  ...

As I understand it, the world's largest EFT (electronic funds transfer)
computer, which I believe to be in Switzerland, is affectionately nicknamed
"The Beast", and more than one religious group has capitalized on this fact in
its literature. (I've seen some of it, but it was a while ago...)

Bob Stratton, Stratton Systems Design, strat@ai.mit.edu   +1 703 823 MIND

</PRE>
<HR><H3><A NAME="subj7.2">
Re: Electronic cash completely replacing cash (`witt', <A HREF="/Risks/10.81.html">RISKS-10.81</A>)
</A>
</H3>
<address>
Rick Smith
&lt;<A HREF="mailto:smith@SCTC.COM ">
smith@SCTC.COM 
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 17:35:19 CST
</i><PRE>

As a "cash resistant" individual, I enjoyed reading the proposals to "eliminate
cash."  Personally, I usually carry only enough cash to pay for lunch for the
week, and use credit cards for everything else.

But I don't think the "Americard" proposal would work. Not in America.  The
author's recommendations require the assignment of a unique number that gets
copied and used in virtually every transaction.  This sounds like a clone of
the Social Security Number, and I think the current trend in restricting use of
SSNs bodes ill for the implementation of similar numbers. It is also not clear
whether the author expects that private credit card organizations will be put
out of business for this government boondoggle, but it seems to be implied.

Most people know that their credit card numbers and Social Security numbers are
sensitive information. You don't give your credit card number to just anyone.
Right now, credit card numbers are used by a fairly restricted set of
organizations. The banks who process credit card purchases for stores are very
careful about the stores they work with. The bank and store are very, very
interested in the security of these transactions. The store doesn't want any
improper credits and the bank doesn't want any improper sales.  Credit slips go
into a special pile that unauthorized people can't go looking through. But if
every Tom, Dick, or Harriet can plug in their Americard reader and post
"payments" from other people, how soon will it be before someone builds the new
generation "blue box" that steals money electronically?

&gt;...  Muggers and bu[r]glars would be out of business: no one would
&gt;be carrying cash and stolen property would be difficult to sell
&gt;because there would be records of all transactions....

Burglary begins at home. Why hit the streets if you can steal it all with a
little box of electronics?

&gt;        Think about it.  Drug deals, muggings, corruption, businesses
&gt;concealing their income - they all require cash and secrecy.  A
&gt;monetary system bases solely on electronic currency would leave a
&gt;trail that would cripple such enterprises.

And people will establish electronic laundries to undo all of this.
Transactions will identify buyer and seller, and probably include some
transaction-specific code agreed on by the buyer and seller.  For example, if
I'm paying my phone bill I use code 1234506 and if I'm paying for overpriced
repair services I use code 9876765, both paid to the phone company. Or, if I'm
trying to launder a transaction, I funnel it through some bizarre set of
recepients with a peculiar set of transaction codes. The recipients have to be
in on it, of course, so a good laundry would probably be a regional fast food
chain, for example. In order to trace laundry transactions you'd have to
reconstruct numerous "small" transactions and follow them through accounts that
would be gone when investigators went looking for them.

The only way to prevent such laundering would be to pass laws, laws, and more
laws, trying to stay ahead of potential data paths. Most of the laws would be
unenforceable without a platoon of data police. You'd bind up business with so
many transaction regulations that the economy would grind to a halt. And we'd
get a centralized economy that even Josef Stalin would envy. As it is, a
variety of small businesses have special treatment under currency reporting
regulations. That keeps them from going out of business due to excessive
regulatory paperwork.

&gt;...  The benefits would be tremendous.  Individuals and businesses
&gt;would no longer be able to conceal income.  All transactions would be
&gt;recorded in a computerized bank file and would be easy for the I.R.S.
&gt;to check....

This is a benefit? I don't think the proposer has any idea how massive such a
file would be. It took the IRS years to set up a fairly mundane procedure to
cross check income reports against individual tax returns. That handled
millions of transactions per year. The other database would be millions per
day, if not per hour. People could conceal income by just refusing to report it
twice. Data like that can only be used after they filter it. The only things
they'll find are things they look for. You bypass such things by hiding the
"bad" transaction behind a set of "good" ones. And it's just a case of staying
one step ahead of their filtering program, which can't look for everything.
After all, it's only a computer.

Finally, some economic considerations:

&gt;        In place of paper money, we would receive new cards - let's
&gt;call them Americards - each bio-mechanically impregnated with the
&gt;owner's hand and retina prints to insure virtually foolproof
&gt;identification. ...
&gt;At lunchtime, you would go to your favorite [restaurant] - or the local
&gt;hot dog stand - and instead of paying cash, you'd use your Americard.

This is the technological battering ram hitting the proverbial fly.  Each hot
dog stand needs a high reliability, secure, bidirectional link to the
international electronic funds financial network (typical hotdog stands don't
even have telephones, after all). This link is connected to a device that does
pattern recognition on fingerprints or retinas, and reads some data off of a
card. Finally we find it attached to a numeric keypad. And it's probably as
easy to use as a helicopter. As a kid I remember predictions of the "mass
market personal airplane." It never happened. Some technological systems are
too costly. I expect the bio-identification and the security problems will keep
the costs of "Americard" very high indefinitely.

In any case, how do you know you can trust a cheesy vending machine at some gas
station to charge you a quarter and not $25.00 ??  We already have that problem
with pay phones.

Rick Smith, SCTC, Arden Hills, Minnesota

</PRE>
<HR><H3><A NAME="subj7.3">
Re: RISKS DIGEST 10.82
</A>
</H3>
<address>
Stephen Perelgut 
&lt;<A HREF="mailto:perelgut@turing.toronto.edu">
perelgut@turing.toronto.edu
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 21:59:13 EST
</i><PRE>

More cash-card questions (from an infrequent reader).  What happens to
people travelling from outside the U.S.  Do we stop at immigration and
get an Americard?  Is it a credit card, debit card, ???  What about
Americans travelling outside the country?  Surely they would use the
appropriate currency.  I'd guess that Canadian $'s would become the
coinage of the underground marketplace thereby artificially inflating
the value of $CDN thereby destroying one of our economic underpinnings.

</PRE>
<HR><H3><A NAME="subj7.4">
Electronic cash completely replacing cash
</A>
</H3>
<address>
Art Medlar 
&lt;<A HREF="mailto:art@big-ben.UUCP">
art@big-ben.UUCP
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 20:27:09 PST
</i><PRE>

&gt;	If all the people who do business in cash were forced to report
&gt;their incomes accurately - if the under-ground economy were forced to the
&gt;surface - the Government could collect an additional $100 billion a year
&gt;for the nation[a]l treasury - without raising taxes.  States and cities, many
&gt;in serious financial trouble, would also benefit from collecting
&gt;previously unpaid income and sales taxes.

Though not all would agree that this is a RISK of the technology (as opposed to
a benefit), certainly one potential outcome of Mr. Wachsman's scheme would be
the enhancement and strengthening of the very underground economy he seeks to
destroy; and consequentially the elimination of even more tax income from the
national treasury.  An active, established barter system, and a thriving black
market economy based on the easily convertible currency of some foreign
country, would tend to destabilize and decentralize the control of the monetary
system.

But it's in the subtext of Mr. Wachsman's loopy proposal that the real RISK
lies.  I've heard that there's a delightful Yiddish word, "farpotchket" I
think, which means not simply broken, but broken because somebody tried to fix
it. The danger of the haphazard application of computer technology to
situations that are really getting along just fine in the first place should be
apparent to all.
                                        --art

</PRE>
<HR><H3><A NAME="subj7.5">
Cashless society
</A>
</H3>
<address>
C-News
&lt;<A HREF="mailto:news@eng.umd.edu ">
news@eng.umd.edu 
</A>&gt;
</address>
<i>
Wed, 30 Jan 91 09:37:22 -0500
</i><PRE>

The risks of a cashless economy are charmingly illustrated in the fiction of
Frederik Pohl.  I especially recommend The Space Merchants by Pohl and C. M.
Kornbluth.
                           [The c-news are tensed these days?  Who are you?]

</PRE>
<HR><H3><A NAME="subj7.6">
Re: Electronic Cash
</A>
</H3>
<address>
Unix Guru-in-Training
&lt;<A HREF="mailto:elr%trintex@uunet.UU.NET ">
elr%trintex@uunet.UU.NET 
</A>&gt;
</address>
<i>
Wed, 30 Jan 91 08:59:54 EST
</i><PRE>

For an excellent treatment of how easily an electronic cash system can be
abused by the government in power, check out "The Handmaid's Tale" by Margaret
Atwood.  The theme is a Christian Fundamentalist takeover of the US Government.
In one scene, the new government in power decides that women shouldn't be
allowed to handle money (hmm... sounds like Saudia Arabia, doesn't it).
Everyone in the country was already using an "Electrobank" card system, and
women's account numbers ended in an even numbered digit.  One day everyone
wakes up and women's cash cards don't work anymore.  All their balances were
switched to their husband's, father's or other patriarchal figure (such as the
government itself).

The simplicity of Atwood's scenario and its nearness to our current reality is
chilling.  (This applies to most of the scenarios in the book.)  I was
especially struck by this section, perhaps because in spite of the fact that I
work with computer networks every day and consider myself well informed on
these threats to our civil liberties, 1984 just never seemed so close as when I
read this novel.

Ed Ravin, Prodigy Services Company, White Plains, NY 10601
    philabs!trintex!elr   +1-914-993-4737 

</PRE>
<HR><H3><A NAME="subj7.7">
Comment on all electronic currency
</A>
</H3>
<address>
Leslie DeGroff 
&lt;<A HREF="mailto:DEGROFF@GENIE.INTELLICORP.COM">
DEGROFF@GENIE.INTELLICORP.COM
</A>&gt;
</address>
<i>
Tue, 29 Jan 91 14:02:53 PST
</i><PRE>

   Being a day behind on reading risks many of my comments have been made by
others but I would like to make two additions to the commentary, The
"Underground" economy is a vigorous part of the system and in many places and
times when the official currency of a country is at risk, either by price and
bank controls or by simply not being worth much you find that the most valued
street money is some other countries currency. For example in many parts of
asia or eastern europe a greatly desired street currency is US dollars... which
are generally not easily exchanged locally for official goods or currency. The
coupling of the official currency and the subeconomy by cash is not typical or
required for it to work. Note also the current Soviet attempt to withdraw large
bills from circulation...  partly to try and weaken the subeconomy.
   A second point that I think is critical is that such a scheme has many
attractions to banks and government officials and in a severe financial crisis
might be sold to the American public (or at least to the elected officials)
Among it's attractions besides better control of taxation; more precision in
economic statistics, ability to quickly deflate/inflate currency especially in
regards to foreign exchanges (out of one currency into another).  Such a system
is an attractive trap and one that one can slip slowly into..

  today (credit and debit cards (more than one per American)
         legally mandated reporting of large cash transactions
         S&amp;L and bank problems and discussion about limits
         on government backed deposit insurance)
  tomorrow
         (tax's need to be paided by transaction card 
          with valid ID
          Social Security cards that are magnetic media
          encoded (there was a note recently in Risks
          about California Drivers Licences on encoded cards)
          Costs continue to decline for access and software
          systems.
 end point 
         A primary cashless system (by law and by withdrawal of
         currency and coin) and an underground economy back to
         specie (gold and silver), barter and other countries
         currency.

Leslie DeGroff                                        Degroff@Intellicorp.com

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/10.83.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.10.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/10.85.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-58</DOCNO>
<DOCOLDNO>IA013-000136-B031-356</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/9.01.html 128.240.150.127 19970217041457 text/html 23570
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:13:21 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 9: Issue 1</TITLE>
<LINK REL="Up" HREF="/Risks/index.9.html">
<LINK REL="Next" HREF="/Risks/9.02.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/index.9.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/9.02.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 9: Issue 1</H1>
<H2> Thursday 6 July 1989  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Elevator inquest update 
</A>
<DD>
<A HREF="#subj1.1">
Walter Roberson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  UK Defense software standard 
</A>
<DD>
<A HREF="#subj2.1">
Sean Matthews
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Exxon loses Valdez data 
</A>
<DD>
<A HREF="#subj3.1">
Steve Smaha -- and Hugh Miller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "Managing risk in large complex systems" 
</A>
<DD>
<A HREF="#subj4.1">
Bob Allison
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A "model" software engineering methodology? 
</A>
<DD>
<A HREF="#subj5.1">
Rich D'Ippolito
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  CERT Offline 
</A>
<DD>
<A HREF="#subj6.1">
Edward DeHart
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Audi 5000 acceleration 
</A>
<DD>
<A HREF="#subj7.1">
Dave Platt
</A><br>
<A HREF="#subj7.2">
 Mark Seecof
</A><br>
<A HREF="#subj7.3">
 Michael McClary
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
   Elevator inquest update
</A>
</H3>
<address>
&lt;<A HREF="mailto:Walter_Roberson@CARLETON.CA">
Walter_Roberson@CARLETON.CA
</A>&gt;
</address>
<i>
Fri, 30 Jun 89 11:07:29 EST
</i><PRE>

Another two days of the testimony into the April 1st elevator fatality
in Ottawa has revealed some interesting/ scary facts.
  It seems that the elevator type in question had a known problem
with potentially being able to move when only one of the two doors
was closed. A repair which involved moving only *one* wire was known,
and had been recommended by the manufacturer in 1978. The repair
was not made until 4 days *after* the accident, 11 years later.
In the meantime, the ownership of the building changed hands (in 1980),
and the maintenance company changed (in 1988). The government inspectors
never noticed that the change hadn't been made (there are only 2
inspectors for the Ottawa area, which has 3000+ elevators), and the
new repair company didn't notice it either. The owner of the company that
checked the elevator just 1 hour before the death *was* aware of the
change notice, but, as he put it:
  "Are you telling me 10 years after a letter comes out... I should
remember that?" [...]
  "I would assume in 1980 [when the building was sold -- WDR] all those
changes would be made, let alone 1988 [when he took over maintenance].
I don't know of any way any elevator company could know about it all."

The scary part came at the end of yesterday's article:

  "The inquest was told no maintenance records were available for the
  elevators, installed with building construction in 1973. Records are not
  required by the ministry and are often removed by maintenance companies if
  the contract expires in order to hinder the new contractors, Allan Maheral
  said."

         [The Ottawa Citizen, 28 June 1989, p. B1, and 29 June 1989, pp. A1-A2]

  Walter Roberson &lt;Walter_Roberson@Carleton.CA&gt;

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
UK Defense software standard
</A>
</H3>
<address>
Sean Matthews 
&lt;<A HREF="mailto:sean@aipna.edinburgh.ac.uk">
sean@aipna.edinburgh.ac.uk
</A>&gt;
</address>
<i>
Fri, 30 Jun 89 13:49:12 BST
</i><PRE>

I have just seen a copy of the UK department of defence draft standard
for safety critical software  (00-55).

Here are a few high (and low) points.

1. There should be no dynamic memory allocation (This rules out explicit
recursion - though a bounded stack is allowed).

2. There should be no interupts except for a regular clock interupt.

3. There should not be any distributed processing (i.e. only a single
processor).

4. There should not be any multiprocessing.

5. NO ASSEMBLER.

6. All code should be at least rigourously checked using mathematical
methods.

7. Any formally verified code should have the proof submitted as well, in
machine readable form, so that an independent check can be performed.

8. All code will be formally specified.

9. There are very strict requirements for static analysis (no unreachable
code, no unused variables, no unintialised variables etc.).

10. No optimising compilers will be used.

11. A language with a formally defined syntax and a well defined semantics,
or a suitable subset thereof will be used.

Comments.

1. means that all storage can be statically allocated.  In fact somewhere it
says that this should be the case.

2-4 seem to leave no option but polling.  This is impractical, especially in
embedded systems.  No one is going to build a fly by wire system with those
sorts of restrictions. (maybe people should therefore not build fly by wire
systems, but that is another matter that has been discussed at length here
already).  it also ignores the fact that there are proof methods for dealing
with distributed systems.

5. This is interesting, I seem to remember reading somewhere that Nasa used
to have the opposite rule: no high level languages, since they actually read
the delivered binary to check that the software did what it was supposed to
do.

6-7.  All through the draft the phrase `mathematical methods' or `formal
methods' is *invoked* in a general way without going into very much detail
about what is involved.  I am not sure that the people who wrote the report
were sure (Could someone from Praxis - which I believe consulted on drawing
it up - enlarge on this?).

8. this is an excellent thing, though it does not say what sort of language
should be used.  Is a description in terms of a Turing machine suitable?
After all that is a well understood formal system.

10. Interestingly, there is no requirement that the compiler be formally
verified, just that it should conform to international standards (though
strictly), and not have any gross hacks (i.e. optimisation) installed.
There is also no demand that the target processor hardware be verified
(though such a device exists here already: the Royal Signals Research
Establishment's Viper processor).

11. seems to be a dig at Ada and the no subsets rule.  It also rules out C.

Conclusions.

I find the idea of the wholesale mayhem and killing merchants being forced
to try so much harder to ensure that their products maim and kill only the
people they are supposed to maim and kill, rather amusing.

The standard seems to be naive in its expectations of what can be achieved
at the moment with formal methods (That is apparently the general opinion
around here, and there is a *lot* of active research in program verification
in Edinburgh), and impossibly restrictive.

An interesting move in the right direction but too fast and too soon.  And
they might blow the idea of Formal verification by tring to force it too
soon.  And I would very much like to see these ideas trickle down into the
civil sector.

I might follow this up with a larger (and more coherent) description if
there is interest (this was typed from memory after seeing it yesterday)
there is quite a bit more in it.

Sean Matthews                   
Dept. of Artificial Intelligence JANET: sean@uk.ac.ed.aipna
University of Edinburgh           ARPA: sean%uk.ac.ed.aipna@nsfnet-relay.ac.uk
80 South Bridge                   UUCP: ...!mcvax!ukc!aipna!sean
Edinburgh, EH1 1HN, Scotland     

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Exxon loses Valdez data
</A>
</H3>
<address>
Steve Smaha 
&lt;<A HREF="mailto:Smaha@DOCKMASTER.NCSC.MIL">
Smaha@DOCKMASTER.NCSC.MIL
</A>&gt;
</address>
<i>
Wed, 5 Jul 89 11:58 EDT
</i><PRE>

This appeared in the 2 Jul 89 Austin (TX) "American-Statesman".

"Exxon accidentally destroys data files on Alaska oil spill,"
          by Roberto Suro, New York Times Service

HOUSTON - A computer operator at Exxon headwuarters in Houston says he
inadvertently destroyed computer copies of thousands of documents with
potentially important information on the Alaskan oil spill.
  A federal court had ordered Exxon to preserve the computer records along
with all other material concerning the grounding of the Exxon Valdez in
Prince William Sound on March 24 and the subsequent cleanup effort.
  Les Rogers, a spokesman for the Exxon Company USA, confirmed the
destruction of the computer records but said the oil company's lawyers
believed other copies exist.
  "Very early in the spill, even before the court order, Exxon took
the initiative to instruct all its employees to save all documents
relating to the event because of the anticipated litigation," Rogers
said.  "We assume these instructions have been followed."
  The computer technician, Kenneth Davis, said that it would be difficult
and perhaps impossible to determine what documents were on destroyed
conmputer files.
  Exxon faces about 150 lawsuits as a result of the spill, which dumped 
11 million gallons of crude oil into Prince William Sound, and it appears
certain that the loss of these documents will be the subject of court
arguments.
  Stephen Sussman, a Houston lawyer involved in a suit against Exxon on
behalf of Alaska fishermen, Native Americans, and others, said, "The
destruction of these records is potentially significant to our case in
that we will be arguing that Exxon has been negligent throughout this
disaster and now perhaps it was negligent even in the handling of its
own documents."
  Davis, 33, was dismissed June 8, the day after the destruction of the
records was discovered.
  In several interviews, and in written statements to the Texas Employment
Commission, Davis alleged that his superiors had been negligent in
safeguarding the computer records and that his actions resulted from
their failures.
  The destroyed material included all internal communications and
word-processing documents from both the Exxon Shipping Co., which owned
the tanker, and the executive offices of Exxon USA.
  Davis said that since the tapes were the only complete copy of what
passed through those computer systems, it might be impossible to
determine what was lost.

   [The full NYT text was sent in by Hugh Miller &lt;MILLER@vm.epas.utoronto.ca&gt;,
   who prefaced the text with this reference to `1984' by George Orwell:

     ``I was thinking just this morning about how Winston Smith's job in
       historical engineering would have been a lot easier if everything had
       been kept on magnetic media, when this item appeared in today's NYT.''

   To conclude, he made some comments about the difficulties of prosecuting
   after the documents have been destroyed (with reference to Ollie and Fawn).
   ``Want to bet Exxon doesn't use a PROFS system?''

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
IEEE Spectrum June issue: "Managing risk in large complex systems"
</A>
</H3>
<address>
&lt;<A HREF="mailto:bobal@microsoft.UUCP">
bobal@microsoft.UUCP
</A>&gt;
</address>
<i>
Wed Jul  5 16:40:22 1989
</i><PRE>

The June 1989 issue of IEEE Spectrum contains a series of articles discussing
risk management techniques and failures, paying particular attention to the
areas of aging aircraft ala the Aloha Airlanes 737 incident, the Hinsdale 
fire which shut down phone service near Chicago, the Savannah river nuclear 
reactors, the space shuttle, and the release of lethal chemicals in Bhopal.

Perhaps because of my own particular biases, the space shuttle article was
particularly interesting where it describes the risk of a shuttle accident also
dooming the space station (due to the destruction of single copies of critical
space station components).

Bob Allison

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
A "model" software engineering methodology? (<A HREF="/Risks/8.86.html">RISKS-8.86</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:rsd@SEI.CMU.EDU">
rsd@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Mon, 03 Jul 89 14:46:23 EDT
</i><PRE>

In RISKS 8.86, Jon Jacky quotes Stan Shebs:

  We supposedly had a "model" software engineering methodology; what I
  remember most clearly is that half the work was done on one flavor of IBM
  OS, and the other half done on a different flavor, and file transfer
  between the two was tricky and time-consuming.

The coupled clauses are unrelated, a compositional practice Mr. Shebs is
apparently quite fond of.  Let's concentrate on Mr. Sheb's text to see what
his understanding of software development is:


  The day-to-day work was [...] writing the "Program Design" for an
  already-written program (is that stupid or what), figuring out how to
  compute the intersection of two polygons in space.  

Without context, this is not evidence that the SE method was good or bad.
Of course the program design should have been documented beforehand, but
recognizing that it is necessary to have for testing and maintenance
purposes is not stupid.  I have seen many systems where the software is very
old (or inhereted) and must be re-documented to current standards.  What was
the case here?


  I suppose the greatest risk of failure derives from things that weren't
  anticipated during testing, such as a Siberian snowdrift changing the
  topography on a navigation map...

[How does the snow get on the map?!]  One does not wait until testing to
anticipate such contingencies.  Does Mr. Shebs think so?


  (Regarding) statistics on software quality, the closest thing we had was
  maybe a count of problem reports (hundreds, but each report ranged from
  one-liners to one-monthers in terms of effort required).

Sigh.  There is no mention here whether this applies to _delivered_ product
or corrected production errors.  Is this his view of what constitutes
quality?


  Nothing classified, we had the odd situation that the *data* was [sic]
  classified, but the *program* wasn't even rated "confidential"!

Odd situation?  Apparently, Mr. Shebs had a single experience in the MCCR
community.


This article was posted to illuminate "the accuracy/quality of strategic
weapons guidance systems", presumably by offering a coherent and reasoned
exposition.  Instead, it presents jokes, innuendo, and unsubstantiated
charges and conclusions in indefinite (and sloppy, such as the 1/2 inch
diameter missile) language such as:

  The difficulty of all this apparently didn't occur to anybody until after
  the missile was working...

  ...error accumulation over 2000 km is immense,... 

  ...cute little cassette tapes...

  The precision and formality of the software was very low, but it was
  exhaustively tested over and over and over again.  


Really, if Mr. Shebs's rambling demonstrates anything, it shows that the
greatest risk is hiring inarticulate and confused programmers like himself
who don't have the faintest idea what software engineering is.

Mr. Shebs appears to come clean in only one statement:

  The fragility of something like the cruise missile and its software is
  something I've spent a lot of time wondering about, and don't really
  have any idea.  

Indeed.

Rich D'Ippolito

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
CERT Offline                        [Computer Emergency Response Team]
</A>
</H3>
<address>
&lt;<A HREF="mailto:Edward DeHart <ecd@cert.sei.cmu.edu> [forwarded via many different paths]">
Edward DeHart &lt;ecd@cert.sei.cmu.edu&gt; [forwarded via many different paths]
</A>&gt;
</address>
<i>
Wed, 5 Jul 89 14:19:09 EDT
</i><PRE>

The supply of cold water to our air-conditioners has been turned off due to a
major break in the pipes.  The problem may not be corrected until the weekend.

The lack of cold water is bad news for the computer room.  All of the systems
are going to be turned off.

For the next day or so, CERT will not be able to send or receive EMAIL via the
Internet.

We will be in the building if you need to contact us.  Our telephone number is
412-268-7090.

Please forward this information to others in your group.

Thanks, Ed DeHart

    [whhada yuh know; CERT needs a CERT!  The police dept's computers are 
    down ...  Willis Ware]

    [I suppose the famous detective, Air-Cool Pour-out, will investigate.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Audi 5000 acceleration [<A HREF="/Risks/8.87.html">RISKS-8.87</A>]
</A>
</H3>
<address>
Dave Platt
&lt;<A HREF="mailto:dplatt@coherent.com ">
dplatt@coherent.com 
</A>&gt;
</address>
<i>
Fri, 30 Jun 89 10:40:37 PDT
</i><PRE>

&gt; The study, ``An Examination of Sudden Acceleration,'' explored ...
&gt;
&gt; However, there was evidence of minor surges of about three-tenths of the
&gt; Earth's gravity for 2 seconds caused by electronic faults in the idle
&gt; stabilizer systems of the Audi 5000 ... the surge could startle a driver
&gt; enough to accidentally push the accelerator instead of the brake, ...

Minor??  .3G works out to roughly 10 feet/sec^2, or a zero-to-sixty
acceleration time of about 9 seconds.  This may not be considered "full power"
or "major" acceleration for a sports-car, but my old Volvo has difficulty
reaching highway speed (55) in 9 seconds even if I floor the accelerator.

A .3G surge for 2 seconds would accelerate a car from a standstill to somewhere
in the neighborhood of 20 feet/second, and would carry the car about 10 feet
forwards.  Startling?  I should say so... especially to drivers who might have
only recently switched to the Audi from an older, lower-powered car.

Even if this fault in the idle stabilizer cannot invoke "full"
acceleration by itself, it sounds substantially dangerous in and of
itself.  Coupled with poor pedal/linkage layout and design, it
apparently adds up to a real hazard.

Dave Platt    FIDONET:  Dave Platt on 1:204/444        VOICE: (415) 493-8805
  USNAIL: Coherent Thought Inc.  3350 West Bayshore #205  Palo Alto CA 94303

</PRE>
<HR><H3><A NAME="subj7.2">
misleading Audi surge report
</A>
</H3>
<address>
&lt;<A HREF="mailto:lcc.marks@SEAS.UCLA.EDU">
lcc.marks@SEAS.UCLA.EDU
</A>&gt;
</address>
<i>
Fri, 30 Jun 89 11:39:11 PDT
</i><PRE>

Three-tenths of the Earth's gravity is not "minor."  That's about
three meters per second squared.  At the end of two seconds the car
would have travelled about six meters or twenty feet.  3m/sec^2 on
a 1500 Kg automobile for just a moment will set it moving fast
enough to squish or bash-in any likely obstacle (inertia, you know).

I'll bet drivers are startled!  They aren't likely to accellerate
that fast when parking...  Sixty miles per hour is about a hundred
kilometers per hour.  That's about twenty-eight meters per second.
At 3m/sec^2 it takes only nine or ten seconds to reach 28m/sec; the
owners of Audi 5000's are probably pleased with the "zero to sixty
in six seconds" performance of their cars; that's less than 5m/sec^2.
(Many cars can't do 0-60 in less than 9 seconds flat out.)  This
means the "surges... caused by electronic faults" are equivalent to
accellerating away from a stop light in traffic--and only a third
less than flooring the gas pedal to get onto the Pasadena Freeway
in Highland Park.  Imagine if you were easing your car into your
garage at an idle and it suddenly accellerated like you were taking
off from a stop sign.

(Before you all write to criticize the math, I'm aware that I've neglected air
resistance and gear shifting, but I don't think this invalidates the
discussion.)

If the report does minimize the fault in the Audi's electronic controls to lay
the blame on the driver, then we must ask whether the authors wanted to shift
concern away from Audi where it seems to belong.  (No, I've never owned or even
driven an Audi.)

 Mark Seecof, Locus Computing Corp., Los Angeles (213-337-5218)
 My opinions only, of course...

</PRE>
<HR><H3><A NAME="subj7.3">
Audi surges (Re: RISKS DIGEST 8.87)
</A>
</H3>
<address>
Michael McClary
&lt;<A HREF="mailto:michael@xanadu.COM ">
michael@xanadu.COM 
</A>&gt;
</address>
<i>
6 Jul 89 18:06:27 GMT
</i><PRE>

&gt;However, there was evidence of minor surges of about three-tenths of the
&gt;Earth's gravity for 2 seconds caused by electronic faults in the idle
&gt;stabilizer systems of the Audi 5000

Is this a missprint?  I find the characterization of a two-second, 3/10 g surge
as "minor" to be ludicrous.

This is especially true if it is the result of a malfunction in an idle speed
control system, implying that it would occur when the vehicle was stopped.  At
a busy intersection, for instance, with pedestrian cross-traffic or another
stopped car just a foot or two ahead.

After one second, a 3/10g surge would have moved the vehicle almost five feet
forward, and have it traveling over 6 1/2 MPH.  By the end of the two second
surge, if nothing is done, the car would be doing 13 MPH and have gone nearly
twenty feet.

No hypothetical "pedal misapplication" is necessary to make such a vehicle
hazardous, and while zero-to-sixty in under ten seconds may not be full
throttle for an Audi, it's close enough for me.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/index.9.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/9.02.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-59</DOCNO>
<DOCOLDNO>IA013-000136-B031-376</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/9.98.html 128.240.150.127 19970217041509 text/html 379
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:13:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML>
<HEAD>
<TITLE>Risks Digest</TITLE>
</HEAD>
<BODY>
<H1>Bad request</H1>
"/RISKS/9.98.html" is not a valid issue of Risks.
<HR>
<ADDRESS>
<A HREF="http://catless.ncl.ac.uk/Lindsay.html">Lindsay.Marshall@newcastle.ac.uk</A>
</ADDRESS>
</BODY>
</HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-60</DOCNO>
<DOCOLDNO>IA013-000136-B031-394</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/9.00.html 128.240.150.127 19970217041517 text/html 379
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:13:51 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML>
<HEAD>
<TITLE>Risks Digest</TITLE>
</HEAD>
<BODY>
<H1>Bad request</H1>
"/RISKS/9.00.html" is not a valid issue of Risks.
<HR>
<ADDRESS>
<A HREF="http://catless.ncl.ac.uk/Lindsay.html">Lindsay.Marshall@newcastle.ac.uk</A>
</ADDRESS>
</BODY>
</HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-61</DOCNO>
<DOCOLDNO>IA013-000136-B032-11</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/12/index.html 128.240.150.127 19970217041545 text/html 82292
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:13:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Index to Volume 12</TITLE>
<LINK REL="Pref" HREF="/Risks/11/index.html">
<LINK REL="Next" HREF="/Risks/13/index.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/13/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Index to Volume 12</H1>
<H2> Tuesday 31 December 1991 </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------">
<DL>
<DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.01.html">Volume 12 Issue 01 (1 Jul 91)</A>
<DD><UL>
<LI><A HREF="/Risks/12.01.html#subj1">  The Risks of Undelete and the Law (Ron Dippold)</A>
<LI><A HREF="/Risks/12.01.html#subj2">  Patriot missile specifications (Robert I. Eachus)</A>
<LI><A HREF="/Risks/12.01.html#subj3">  Lawsuit Pending over Patriot's Failure to Stop Dharan Scud (Sean Smith)</A>
<LI><A HREF="/Risks/12.01.html#subj4">  Word Perfect file locking poor protection (John Gilmore and Helen Bergen via    Peter Jones)
</A>
<LI><A HREF="/Risks/12.01.html#subj5">  Statement in Support of Communications Privacy (John Gilmore)</A>
<LI><A HREF="/Risks/12.01.html#subj6">  NIST announces public-key digital signature standard (John Gilmore)</A>
<LI><A HREF="/Risks/12.01.html#subj7">  Re: Videotape of the pilot discussing the crash of UAL 232 (Robert Dorsett)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.02.html">Volume 12 Issue 02 (2 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.02.html#subj1">  Insecure Superman leads to Superbill (Paul Leyland)</A>
<LI><A HREF="/Risks/12.02.html#subj2">  Too Many Computer Systems Hurt War on Drugs, study says (PGN)</A>
<LI><A HREF="/Risks/12.02.html#subj3">  Colombian Constitution Erased (Brian Snow)</A>
<LI><A HREF="/Risks/12.02.html#subj4">  More phone disruptions (Fernando Pereira)</A>
<LI><A HREF="/Risks/12.02.html#subj5">  Bell Atlantic 26 June Failure (Robert McClenon)</A>
<LI><A HREF="/Risks/12.02.html#subj6">  Re: The Risks of Undelete and the Law (Al Donaldson)</A>
<LI><A HREF="/Risks/12.02.html#subj7">  Searching the RISKS archives via WAIS (Ephraim Vishniac)</A>
<LI><A HREF="/Risks/12.02.html#subj8">  "On the Danger of Simple Answers" (elnitsky via Rob Slade)</A>
<LI><A HREF="/Risks/12.02.html#subj9">  Videotape of the pilot discussing the crash of UAL 232 (Mary Shafer)</A>
<LI><A HREF="/Risks/12.02.html#subj10">  Risk of posting to RISKS (Jerry Hollombe)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.03.html">Volume 12 Issue 03 (8 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.03.html#subj1">  Alcor/Email suit pays off! (Henson)</A>
<LI><A HREF="/Risks/12.03.html#subj2">  Computer based estimation of mortality (Richard I. Cook)</A>
<LI><A HREF="/Risks/12.03.html#subj3">  On finding a coding bug in the Time Server Daemon (Martin Minow)</A>
<LI><A HREF="/Risks/12.03.html#subj4">  Animated hieroglyphics on telco operators's terminals (Dan Jacobson)</A>
<LI><A HREF="/Risks/12.03.html#subj5">  Dutch Phreaks and Chaos Congress 90 (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/12.03.html#subj6">  Risks Forum and Vulnerability (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/12.03.html#subj7">  Re: Global warming: Not so funny. (Victor Yodaiken)</A>
<LI><A HREF="/Risks/12.03.html#subj8">  Re: "On the Danger of Simple Answers" (Chuck Karish)</A>
<LI><A HREF="/Risks/12.03.html#subj9">  The advantages of posting to RISKS (Brian Tompsett)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.04.html">Volume 12 Issue 04 (9 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.04.html#subj1">  Clip-Art Confusion Causes City Change (Christopher Davis)</A>
<LI><A HREF="/Risks/12.04.html#subj2">  Hiding a face on television (Tim Smith)</A>
<LI><A HREF="/Risks/12.04.html#subj3">  A RISKy night in Georgia (Robert E. Van Cleef)</A>
<LI><A HREF="/Risks/12.04.html#subj4">  Risks of HR 1400 to modem community (Jim Thomas)</A>
<LI><A HREF="/Risks/12.04.html#subj5">  Dissemination of confidential information (Hugh Cartwright)</A>
<LI><A HREF="/Risks/12.04.html#subj6">  Review of "TERMINATOR 2: Judgment Day" (R. Mehlman)</A>
<LI><A HREF="/Risks/12.04.html#subj7">  Re: Computers and Exporting (Vadim Antonov)</A>
<LI><A HREF="/Risks/12.04.html#subj8">  Re: Formalism vs Experimentation (Vadim Antonov, Daniel Palumbo)</A>
<LI><A HREF="/Risks/12.04.html#subj9">  Disk based crime plan (Rob Boudrie)</A>
<LI><A HREF="/Risks/12.04.html#subj10">  Deleting vs. Shredding (Brad Templeton)</A>
<LI><A HREF="/Risks/12.04.html#subj11">  Re: The Risks of Undelete and the Law (Steven Tepper, William Ricker)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.05.html">Volume 12 Issue 05 (11 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.05.html#subj1">  TRW Accused of Exploiting Consumers (PGN)</A>
<LI><A HREF="/Risks/12.05.html#subj2">  Dissemination of confidential information (Adam Curtin)</A>
<LI><A HREF="/Risks/12.05.html#subj3">  Phone disruptions (Ed Andrews)</A>
<LI><A HREF="/Risks/12.05.html#subj4">  (Im)probability theory (By Arthur Salm)</A>
<LI><A HREF="/Risks/12.05.html#subj5">  Leaking of Gates memo not an IT risk (Henry J. Cobb)</A>
<LI><A HREF="/Risks/12.05.html#subj6">  Coding bug (Dennis L. Mumaugh)</A>
<LI><A HREF="/Risks/12.05.html#subj7">  Re: A RISKy night in Georgia (Trevor Kirby, Bruce Perens, Paul Smee)</A>
<LI><A HREF="/Risks/12.05.html#subj8">  Risk Preferences [Research effort!] (Kevin Crocker)</A>
<LI><A HREF="/Risks/12.05.html#subj9">  FINAL CALL, COMPUTING &amp; VALUES CONFERENCE, AUG 12-16 (Walter Maner)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.06.html">Volume 12 Issue 06 (16 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.06.html#subj1">  Bay-Area Long-Distance Service Disrupted (again!)</A>
<LI><A HREF="/Risks/12.06.html#subj2">  Computer Showers a Briton with Gifts (Henry Cate III via Mark Brader&amp;rec.humor)</A>
<LI><A HREF="/Risks/12.06.html#subj3">  Computer "assistance" in the UK Grand Prix (Brian Randell)</A>
<LI><A HREF="/Risks/12.06.html#subj4">  Re: auto telemetry records (Erik Nilsson)</A>
<LI><A HREF="/Risks/12.06.html#subj5">  Free [Canadian] Money? (Mark Batten)</A>
<LI><A HREF="/Risks/12.06.html#subj6">  Nitwit ideas (Niven and Pournelle) (Clive Feather)</A>
<LI><A HREF="/Risks/12.06.html#subj7">  Puzzle boxes for critical device interfacing (Ross Williams)</A>
<LI><A HREF="/Risks/12.06.html#subj8">  U.S. Electronic Data Move Challenged on Privacy Issue (NYT via Jeff Helgesen)</A>
<LI><A HREF="/Risks/12.06.html#subj9">  NPTN Infosphere Report (Sue Anderson)</A>
<LI><A HREF="/Risks/12.06.html#subj10">  Re: Risks of Posting to RISKS (Chuck Dunlop)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.07.html">Volume 12 Issue 07 (16 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.07.html#subj1">  RISKS: US West 10x charges users (patlo)</A>
<LI><A HREF="/Risks/12.07.html#subj2">  Houston City Hall voice-mail prank (PGN, S. Spenser Aden)</A>
<LI><A HREF="/Risks/12.07.html#subj3">  Re: Risks of posting to newsgroups (Li Gong)</A>
<LI><A HREF="/Risks/12.07.html#subj4">  1992 IEEE Symposium on Research in Security and Privacy (John McLean)</A>
<LI><A HREF="/Risks/12.07.html#subj5">  Puzzle Boxes: Reply to comments (Ross Williams)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.08.html">Volume 12 Issue 08 (25 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.08.html#subj1">  Another false apprehension -- erroneous database information (PGN)</A>
<LI><A HREF="/Risks/12.08.html#subj2">  Human Error Blamed for Soviet N-Plant Problems (PGN)</A>
<LI><A HREF="/Risks/12.08.html#subj3">  Shuttle Atlantis out to launch (PGN)</A>
<LI><A HREF="/Risks/12.08.html#subj4">  Risks of getting used to computers (Geoff Kuenning)</A>
<LI><A HREF="/Risks/12.08.html#subj5">  Index of Known MsDos Malware: 998 viruses/trojans (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/12.08.html#subj6">  Sometimes they even warn you about the pitfalls (self-trapping) (Andrew Koenig)</A>
<LI><A HREF="/Risks/12.08.html#subj7">  Smart cockpit with no backup (Henry Spencer)</A>
<LI><A HREF="/Risks/12.08.html#subj8">  Black boxes in autos for accident "facts" (Mark Seecof)</A>
<LI><A HREF="/Risks/12.08.html#subj9">  Re: Artificial Dissemination (Edward Jung)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.09.html">Volume 12 Issue 09 (25 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.09.html#subj1">  The limits of simulation (Henry Spencer)</A>
<LI><A HREF="/Risks/12.09.html#subj2">  RISKS vs. RISKS (Steve Bellovin)</A>
<LI><A HREF="/Risks/12.09.html#subj3">  Gottschalks rejects check (Todd Heberlein) </A>
<LI><A HREF="/Risks/12.09.html#subj4">  Proposed law on computer searches (Chris Hibbert)  [longish]</A>
<LI><A HREF="/Risks/12.09.html#subj5">  New Jersey "software engineering" registration legislation (John M. Ritter     via Arthur Rubin)  [longish]
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.10.html">Volume 12 Issue 10 (29 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.10.html#subj1">  Summer slowdown (PGN)</A>
<LI><A HREF="/Risks/12.10.html#subj2">  Egad, sail-by-wire! (W. K. (Bill) Gorman)</A>
<LI><A HREF="/Risks/12.10.html#subj3">  Third Chicago Airport: Rare Events &amp; Computer Projections (William E. Mihalo)</A>
<LI><A HREF="/Risks/12.10.html#subj4">  Risks of human error in Soviet nuclear "industry" (Tom Blinn)</A>
<LI><A HREF="/Risks/12.10.html#subj5">  Re: Smart cockpit with no backup (Simson Garfinkel)</A>
<LI><A HREF="/Risks/12.10.html#subj6">  Licensing of Software Engineers (Bill Murray)</A>
<LI><A HREF="/Risks/12.10.html#subj7">  Re: New Jersey "software engineering" registration legislation (Bob Frankston)</A>
<LI><A HREF="/Risks/12.10.html#subj8">  ACM SIGSOFT '91, SOFTWARE FOR CRITICAL SYSTEMS (Judith Burgess)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.11.html">Volume 12 Issue 11 (30 July 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.11.html#subj1">  DEFSTAN 00/55-56 (Victoria Stavridou and Andres Ravn)</A>
<LI><A HREF="/Risks/12.11.html#subj2">  Computer problems at BCCI (David Shepherd)</A>
<LI><A HREF="/Risks/12.11.html#subj3">  Census data in the Land of Oz (Michael Panosh)</A>
<LI><A HREF="/Risks/12.11.html#subj4">  Soft Eng Cntrl aids during Hydraulic Failure (Science News) (Jeffrey Sorensen)</A>
<LI><A HREF="/Risks/12.11.html#subj5">  Risks of human error in Soviet nuclear "industry" (Ken Mayer)</A>
<LI><A HREF="/Risks/12.11.html#subj6">  Cardphone Problems in Ireland (D.P.O'Donoghue)</A>
<LI><A HREF="/Risks/12.11.html#subj7">  Book review:  Practical Unix Security (Clifford Stoll)</A>
<LI><A HREF="/Risks/12.11.html#subj8">  *WRONG* ftp-adress in Brunnstein: Index of Known Malware (Eibo Thieme)</A>
<LI><A HREF="/Risks/12.11.html#subj9">  Re: Smart cockpit with no backup (Henry Spencer)</A>
<LI><A HREF="/Risks/12.11.html#subj10">  Re: The limits of simulation (Henry Spencer)</A>
<LI><A HREF="/Risks/12.11.html#subj11">  Re: Licensing of Software Engineers (Henry Spencer)</A>
<LI><A HREF="/Risks/12.11.html#subj12">  Data entry is NOT software engineering.. (Thomas P. Blinn)</A>
<LI><A HREF="/Risks/12.11.html#subj13">  New Jersey "software engineering" registration legislation (Arthur Rubin,    A. Padgett Peterson, Christopher R Riley, Chris Riley, Joseph Beckenbach)
</A>
<LI><A HREF="/Risks/12.11.html#subj14">  Flawed assertion in <A HREF="/Risks/12.08.html">RISKS-12.08</A> (Mark Seecof)</A>
<LI><A HREF="/Risks/12.11.html#subj15">  Re: Risks of Posting to RISKS (Jerry Hollombe)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.12.html">Volume 12 Issue 12 (12 August 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.12.html#subj1">  Teenage Hacker Emulates Hess (PAJ)</A>
<LI><A HREF="/Risks/12.12.html#subj2">  Future Risks (Hilarie Kauiolani Orman via Richard Schroeppel)</A>
<LI><A HREF="/Risks/12.12.html#subj3">  Security comes to the Free Software Foundation (Martin Minow)</A>
<LI><A HREF="/Risks/12.12.html#subj4">  Lotus Marketplace Epilogue (Marc Rotenberg)</A>
<LI><A HREF="/Risks/12.12.html#subj5">  Computer frustration (Andrew Goldberg via Les Earnest)</A>
<LI><A HREF="/Risks/12.12.html#subj6">  Yet another threat to telephone privacy (Jeff Makey)</A>
<LI><A HREF="/Risks/12.12.html#subj7">   "Enemy of the State" -- Story on risk to privacy (Richard Thomsen</A>
<LI><A HREF="/Risks/12.12.html#subj8">  Firefighters won't give first aid to AIDS patients (Sean Eric Fagan)</A>
<LI><A HREF="/Risks/12.12.html#subj9">  Lifestyle discrimination (Martyn Thomas)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.13.html">Volume 12 Issue 13 (19 August 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.13.html#subj1">  Junk Mail in Outer Space: Shuttle test mail-bombed (Peter Scott)</A>
<LI><A HREF="/Risks/12.13.html#subj2">  ATM mixup in New York (John Martin)</A>
<LI><A HREF="/Risks/12.13.html#subj3">  Computer failure helps Bakthiar murder suspect (Fernando Pereira)</A>
<LI><A HREF="/Risks/12.13.html#subj4">  Deutsche Airbus 2000 (Martyn Thomas)</A>
<LI><A HREF="/Risks/12.13.html#subj5">  Bell V22 Osprey crash (Martyn Thomas)</A>
<LI><A HREF="/Risks/12.13.html#subj6">  "Doctored" radios (PGN)</A>
<LI><A HREF="/Risks/12.13.html#subj7">  "Virus Implants in DoD Weapons" (David Risler via Jerry Leichter)</A>
<LI><A HREF="/Risks/12.13.html#subj8">  Cracker charged in Australia (Fernando Pereira)</A>
<LI><A HREF="/Risks/12.13.html#subj9">  Profitable Drug Wars -- Innocents Presumed Guilty (mauler via Charles    Hoequist)  [SEE ALSO <A HREF="/Risks/12.13.html">RISKS-12.13</A>LAW]
</A>
<LI><A HREF="/Risks/12.13.html#subj10">  Patriot and Dhahran again (Phil R. Karn)</A>
<LI><A HREF="/Risks/12.13.html#subj11">  Re: "Traffic crystal ball" may be in your car's future (Secty Samuel Skinner,     [editorial], via Jeff Helgesen)
</A>
<LI><A HREF="/Risks/12.13.html#subj12">  Risks of Calling Reporters in Ohio: Procter &amp; Gamble (PGN)</A>
<LI><A HREF="/Risks/12.13.html#subj13">  Risk of Power Failures in Computer Controls: 9 Mile Point (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.14.html">Volume 12 Issue 14 (19 August 1991  )</A>
<DD><UL>
<LI><A HREF="/Risks/12.14.html#subj1">  TRW Wrong on Credit Reports for Entire Town (Scot Drysdale)</A>
<LI><A HREF="/Risks/12.14.html#subj2">  Computer Crime Bill - S1322 (Robert E. Van Cleef)</A>
<LI><A HREF="/Risks/12.14.html#subj3">  Bank Shot (RISKS of automatable documents) (Ed Ravin)</A>
<LI><A HREF="/Risks/12.14.html#subj4">  Misuse of computerized auto registration info (Rodney Hoffman)</A>
<LI><A HREF="/Risks/12.14.html#subj5">  Risk of licensing programmers -- lost freedom and creativity (John Gilmore)</A>
<LI><A HREF="/Risks/12.14.html#subj6">  A320 revisited (Robert Dorsett)</A>
<LI><A HREF="/Risks/12.14.html#subj7">  Re: Procter&amp;Gamble (Steve Bellovin)</A>
<LI><A HREF="/Risks/12.14.html#subj8">  Re: FSF machine having to clamp down on security (Paul Mauvais)</A>
<LI><A HREF="/Risks/12.14.html#subj9">  Re: "locking" DoD smart weapons (Guy Sherr)</A>
<LI><A HREF="/Risks/12.14.html#subj10">  Re: Rumor regarding Soviet calibers (Michael Edelman)</A>
<LI><A HREF="/Risks/12.14.html#subj11">  More Credit Bureau Risks (Mike Waters)</A>
<LI><A HREF="/Risks/12.14.html#subj12">  RISKS of calling 911 from cellular phones (E.M. Culver)</A>
<LI><A HREF="/Risks/12.14.html#subj13">  Book: "Narcissistic process and corporate decay..." (Dan Jacobson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.15.html">Volume 12 Issue 15 (22 August 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.15.html#subj1">  Electronic mail beams shuttle's message home (Joe Abernathy, PGN)</A>
<LI><A HREF="/Risks/12.15.html#subj2">  The RISKS of a national computerized entertainment ticketing network (KJPhelan)</A>
<LI><A HREF="/Risks/12.15.html#subj3">  Personal data in California (Phil Agre)</A>
<LI><A HREF="/Risks/12.15.html#subj4">  Electronic Library Systems in Airliners (Robert Dorsett)</A>
<LI><A HREF="/Risks/12.15.html#subj5">  Microsoft, IBM demonstrating faults in each other's products (Jon Jacky)</A>
<LI><A HREF="/Risks/12.15.html#subj6">  "Citicorp Creates Controversy With Plan To Sell Data ..." (Jerry Leichter)</A>
<LI><A HREF="/Risks/12.15.html#subj7">  NY Times Letter on Fake Documents (Sanford Sherizen)</A>
<LI><A HREF="/Risks/12.15.html#subj8">  ATM videotapes (Jyrki Kuoppala)</A>
<LI><A HREF="/Risks/12.15.html#subj9">  Re: Bell V22 Osprey crash -- assembly error (Henry Spencer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.16.html">Volume 12 Issue 16 (26 August 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.16.html#subj1">  Pacific Bell "Message Center" failure in San Francisco Area (David Schachter)</A>
<LI><A HREF="/Risks/12.16.html#subj2">  More Risks of Computer Billing -- $22,000 water bill (PGN)</A>
<LI><A HREF="/Risks/12.16.html#subj3">  Risk Perception (Rodney Hoffman)</A>
<LI><A HREF="/Risks/12.16.html#subj4">  More on Houston Chronicle spacemail item (Joe Abernathy)</A>
<LI><A HREF="/Risks/12.16.html#subj5">  Internal computer fraud at Pinkerton (Rodney Hoffman)</A>
<LI><A HREF="/Risks/12.16.html#subj6">  P&amp;G phone record search (Mark Seecof)</A>
<LI><A HREF="/Risks/12.16.html#subj7">  RISKS on trusting organizations like CERT (Jyrki Kuoppala)</A>
<LI><A HREF="/Risks/12.16.html#subj8">  TCAS sees ghosts (IEEE Spectrum article via Jim Horning)</A>
<LI><A HREF="/Risks/12.16.html#subj9">  More on the Lauda Air crash (Brian Acohido via Nancy Leveson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.17.html">Volume 12 Issue 17 (26 August 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.17.html#subj1">  Computer-related problems at Cape Canaveral (Steve Bellovin)</A>
<LI><A HREF="/Risks/12.17.html#subj2">  Computer communications and the aborted Soviet coup (PGN)</A>
<LI><A HREF="/Risks/12.17.html#subj3">  Medical records for sale (Jerry Leichter)</A>
<LI><A HREF="/Risks/12.17.html#subj4">  Citicorp selling of credit card data (Bud Couch)</A>
<LI><A HREF="/Risks/12.17.html#subj5">  Automating commodities markets (Cameron Laird)</A>
<LI><A HREF="/Risks/12.17.html#subj6">  Re: Bank Shot (RISKS of automatable documents) (Jerry Hollombe)</A>
<LI><A HREF="/Risks/12.17.html#subj7">  Re: Microsoft, IBM demonstrating faults in each other's products       (Flint Pellett)
</A>
<LI><A HREF="/Risks/12.17.html#subj8">  More about California's Automatic Vehicle Identification spec (Steve Bagley)</A>
<LI><A HREF="/Risks/12.17.html#subj9">  California DMV AVI proposal (Phil Agre)</A>
<LI><A HREF="/Risks/12.17.html#subj10">  Use of ATM for blackmail in UK TV script (Mark Evans)</A>
<LI><A HREF="/Risks/12.17.html#subj11">  Desktop Forgeries (John Moore)</A>
<LI><A HREF="/Risks/12.17.html#subj12">  Re: SSNs (Brad Templeton)</A>
<LI><A HREF="/Risks/12.17.html#subj13">  Sometimes you can only get there using the long way around (Bob Cunningham)</A>
<LI><A HREF="/Risks/12.17.html#subj14">  Re: canopus.stanford.edu goes nova (Joe Dellinger)</A>
<LI><A HREF="/Risks/12.17.html#subj15">  FTCS 22--Symposium on Fault-Tolerant Computing (Jack Goldberg)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.18.html">Volume 12 Issue 18 (27 August 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.18.html#subj1">  13 Aug 91 NY Nine Mile Point 2 Nuclear Plant Incident Reassessed (PGN)</A>
<LI><A HREF="/Risks/12.18.html#subj2">  Risks to Computers from Coup Attempt (Aldis Ozols)</A>
<LI><A HREF="/Risks/12.18.html#subj3">  Oil Firm Surveys for Data and a Data Interchange Format (John F Stoffel)</A>
<LI><A HREF="/Risks/12.18.html#subj4">  Ada beats C++ according to the DoD (John F Stoffel)</A>
<LI><A HREF="/Risks/12.18.html#subj5">  Unwarranted equivalence assumptions (Andrew Koenig)</A>
<LI><A HREF="/Risks/12.18.html#subj6">  Study Recommends Earthquake Warning Network (Fernando Pereira)</A>
<LI><A HREF="/Risks/12.18.html#subj7">  Re: Firefighters won't give first aid to AIDS patients (Tim Oldham)</A>
<LI><A HREF="/Risks/12.18.html#subj8">  Re: Cracker charged in Australia (Richard A. O'Keefe)</A>
<LI><A HREF="/Risks/12.18.html#subj9">  FAA seems misled (Re: TCAS Sees Ghosts) (Richard Johnson)</A>
<LI><A HREF="/Risks/12.18.html#subj10">  Risks of CDROM publishing (Donald M. Craig)</A>
<LI><A HREF="/Risks/12.18.html#subj11">  The RISKS of a national computerized entertainment ticketing network    (Steve McDowell)
</A>
<LI><A HREF="/Risks/12.18.html#subj12">  New List: C+HEALTH (Computers and Health) (Judy Smith)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.19.html">Volume 12 Issue 19 (28 August 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.19.html#subj1">  Phone Fraud (Ed Andrews summarized by PGN)</A>
<LI><A HREF="/Risks/12.19.html#subj2">  (Assumed) False Alarm at Nuclear Plant (Rodney Hoffman)</A>
<LI><A HREF="/Risks/12.19.html#subj3">  O, Oh, what a difficult name (Gene Spafford)</A>
<LI><A HREF="/Risks/12.19.html#subj4">  Programs Pester Public Policy People (Jeffrey Sorensen)</A>
<LI><A HREF="/Risks/12.19.html#subj5">  Re: 13 Aug 91 NY Nine Mile Point 2 Nuclear Plant Incident (Steve Bellovin)</A>
<LI><A HREF="/Risks/12.19.html#subj6">  Re: Ada beats C++ according to the DoD (Brinton Cooper)</A>
<LI><A HREF="/Risks/12.19.html#subj7">  Re: Unwarranted equivalence assumptions (Brinton Cooper)</A>
<LI><A HREF="/Risks/12.19.html#subj8">  Re: TCAS sees ghosts (Steve Jay, Lars-Henrik Eriksson, Keith Hanlan)</A>
<LI><A HREF="/Risks/12.19.html#subj9">  pugwash.dcs.ed.ac.uk goes nova too (John Butler)</A>
<LI><A HREF="/Risks/12.19.html#subj10">  NIST High Integrity Lecture Series: talk by Laszlo Belady (Laura Strigel)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.20.html">Volume 12 Issue 20 (30 August 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.20.html#subj1">  "Thieves Hit Social Security Numbers" (Yasmin Anwar via PGN)</A>
<LI><A HREF="/Risks/12.20.html#subj2">  Jetliners in near-miss over Cleveland (PGN)</A>
<LI><A HREF="/Risks/12.20.html#subj3">  More T/CAS (Martyn Thomas, Robert Dorsett)</A>
<LI><A HREF="/Risks/12.20.html#subj4">  Overseeing dementia patients by computer (Urban Fredriksson)</A>
<LI><A HREF="/Risks/12.20.html#subj5">  Heisenberg effect for credit data? (Peter G. Capek)</A>
<LI><A HREF="/Risks/12.20.html#subj6">  The story of O [and Ng] (Jerry Leichter, Stuart I Feldman)</A>
<LI><A HREF="/Risks/12.20.html#subj7">  A number is no name (Clifford Johnson)</A>
<LI><A HREF="/Risks/12.20.html#subj8">  The need for utilities to deal with non-standard situations (Tom Lincoln)</A>
<LI><A HREF="/Risks/12.20.html#subj9">  Uncle Sam Can't Keep Track of his Trillions (Bob Frankston)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.21.html">Volume 12 Issue 21 (DIGEST  31 August 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.21.html#subj1">  `Risk perception' (Phil Agre)</A>
<LI><A HREF="/Risks/12.21.html#subj2">  Flaming makes the mainstream media (again) (Charles Forsythe via Gene Spafford)</A>
<LI><A HREF="/Risks/12.21.html#subj3">  Phone Fraud Story a Fraud? (Michael Barnett)</A>
<LI><A HREF="/Risks/12.21.html#subj4">  Re: Phone Fraud -- Langley VA [anonymous]</A>
<LI><A HREF="/Risks/12.21.html#subj5">  +&amp;*#$ (Bob Frankston)</A>
<LI><A HREF="/Risks/12.21.html#subj6">  Banks, Credit Cards, and Short Names (Bill Biesty)</A>
<LI><A HREF="/Risks/12.21.html#subj7">  YASSNS (Yet Another Social Security Number Story) (S. Peter Loshin)</A>
<LI><A HREF="/Risks/12.21.html#subj8">  Re: Programs Pester Public Policy People (Jeffrey Sorensen)</A>
<LI><A HREF="/Risks/12.21.html#subj9">  Police tickets &amp; computers in the Netherlands (Ralph Moonen)</A>
<LI><A HREF="/Risks/12.21.html#subj10">  Re: Cracker charged in Australia (Gene Spafford)</A>
<LI><A HREF="/Risks/12.21.html#subj11">  Senseless Actions Invite Trouble (Charlie Lear)</A>
<LI><A HREF="/Risks/12.21.html#subj12">  A Danger Associated with Intelligent Terminals (Douglas Thomson)</A>
<LI><A HREF="/Risks/12.21.html#subj13">  Re: Unwarranted equivalence assumptions (Andrew Koenig)</A>
<LI><A HREF="/Risks/12.21.html#subj14">  Old School Reports of the Famous (Kernel Mustered via Spaf and Keith Bostic)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.22.html">Volume 12 Issue 22 (3 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.22.html#subj1">  Madison mail mess-up (Tom Slone)</A>
<LI><A HREF="/Risks/12.22.html#subj2">  RISKS of using electronic mail, and universal addressing (David Parnas)</A>
<LI><A HREF="/Risks/12.22.html#subj3">  Re: +&amp;*#$ (Tom Blinn)</A>
<LI><A HREF="/Risks/12.22.html#subj4">  Re: Study Recommends Earthquake Warning Network (Floyd Ferguson)</A>
<LI><A HREF="/Risks/12.22.html#subj5">  Re: Risks of Risk Perception Research (William P Gardner, Craig Seidel)</A>
<LI><A HREF="/Risks/12.22.html#subj6">  Symposium on Reliable Distributed Systems, Advance program (Lorenzo Strigini)</A>
<LI><A HREF="/Risks/12.22.html#subj7">  DIAC-92 CALL FOR PAPERS AND PARTICIPATION (Douglas Schuler)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.23.html">Volume 12 Issue 23 (3 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.23.html#subj1">  Herb Caen on Computerized Radar (via Mike Seibel, Brad Templeton, Allan Meers)</A>
<LI><A HREF="/Risks/12.23.html#subj2">  "Miser held in record Social Security fraud" (Barry Jaspan)</A>
<LI><A HREF="/Risks/12.23.html#subj3">  Re: "Thieves Hit Social Security Numbers" (Lars-Henrik Eriksson)</A>
<LI><A HREF="/Risks/12.23.html#subj4">  Computer Abuse Amendments Act of 1991 (Thomas Zmudzinski)</A>
<LI><A HREF="/Risks/12.23.html#subj5">  Re: A Danger ... with Intelligent Terminals (Paul Stachour)</A>
<LI><A HREF="/Risks/12.23.html#subj6">  Complain to Journalists (John E. Mollwitz)</A>
<LI><A HREF="/Risks/12.23.html#subj7">  The RISKS of Superiority (Arthur Clarke [!] via Ellen Spertus)</A>
<LI><A HREF="/Risks/12.23.html#subj8">  NASA severs connection on electronic mail linkup (wrapup by Joe Abernathy)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.24.html">Volume 12 Issue 24 (4 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.24.html#subj1">  Radiation therapy machine dose rate doubled by configuration error     (Lawrence W. Berkley and James A. Purdy, summarized by Jon Jacky)
</A>
<LI><A HREF="/Risks/12.24.html#subj2">  Salomon Brothers -- Database Design [anonymous]</A>
<LI><A HREF="/Risks/12.24.html#subj3">  Airworthiness Directive for 747-400 electrical system (Robert Dorsett)</A>
<LI><A HREF="/Risks/12.24.html#subj4">  `Risk perception' (Phil Agre)</A>
<LI><A HREF="/Risks/12.24.html#subj5">  Re: Risk Assesment High Priesthood (Robert W. Kerns)</A>
<LI><A HREF="/Risks/12.24.html#subj6">  Re: A number is no name (EKristia...)</A>
<LI><A HREF="/Risks/12.24.html#subj7">  Re: Re: +&amp;*#$ (Bob Frankston)</A>
<LI><A HREF="/Risks/12.24.html#subj8">  Re: "Thieves Hit Social Security Numbers" (Urban Fredriksson)</A>
<LI><A HREF="/Risks/12.24.html#subj9">  Re: Risks of a Universal Identifier (Martin Minow)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.25.html">Volume 12 Issue 25 (5 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.25.html#subj1">  A kludge too far?  FAX-to-OCR-to-speech (Bob Frankston)</A>
<LI><A HREF="/Risks/12.25.html#subj2">  LA Times Article on E-mail (Mike Kimura)</A>
<LI><A HREF="/Risks/12.25.html#subj3">  Re: RISKS of using electronic mail (Brian Clapper, David Parnas)</A>
<LI><A HREF="/Risks/12.25.html#subj4">  More on SSN risks (Glen Osterhout)</A>
<LI><A HREF="/Risks/12.25.html#subj5">  Universal Email addresses and SSN (Jim Anderson)</A>
<LI><A HREF="/Risks/12.25.html#subj6">  Re: "Thieves Hit Social Security Numbers" (Bob Frankston)</A>
<LI><A HREF="/Risks/12.25.html#subj7">  Re: National Character variations in ASCII (Jim Haynes)</A>
<LI><A HREF="/Risks/12.25.html#subj8">  Pork barrel software validation (Paul Eggert)</A>
<LI><A HREF="/Risks/12.25.html#subj9">  Multics/UNIX Lessons (Edward Rice)</A>
<LI><A HREF="/Risks/12.25.html#subj10">  Call for Papers, FICS 92, Singapore (Harold Joseph Highland)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.26.html">Volume 12 Issue 26 (6 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.26.html#subj1">  The Dead Sea Scrolls and Data Security (Jerry Leichter)</A>
<LI><A HREF="/Risks/12.26.html#subj2">  Charging batteries (Erling Kristiansen)</A>
<LI><A HREF="/Risks/12.26.html#subj3">  ``Returns for Senders'' (US Postal Service handling of forwardings)      (Dinah Wisenberg Brin in Common Cause, via PGN)
</A>
<LI><A HREF="/Risks/12.26.html#subj4">  Re: Portability of E-mail Addresses (Robert Neff)</A>
<LI><A HREF="/Risks/12.26.html#subj5">  DDN Management Bulletin 84 on NIC transfer (NIC)</A>
<LI><A HREF="/Risks/12.26.html#subj6">  Re: +&amp;*#$ (David J. Fiander, Tom Blinn)</A>
<LI><A HREF="/Risks/12.26.html#subj7">  Re: Story of O (Will Martin)</A>
<LI><A HREF="/Risks/12.26.html#subj8">  Re: A number is no name (Merlyn LeRoy, Bob Frankston)</A>
<LI><A HREF="/Risks/12.26.html#subj9">  Re: RISKS of using electronic mail ... (Brinton Cooper, Bob Frankston)</A>
<LI><A HREF="/Risks/12.26.html#subj10">  Re: National Character variations in ASCII (Bob Frankston)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.27.html">Volume 12 Issue 27 (7 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.27.html#subj1">  Play the lottery via Nintendo (Mike Cepek)</A>
<LI><A HREF="/Risks/12.27.html#subj2">  Re: Salomon Brothers -- Database Design (Jeff Berkowitz)</A>
<LI><A HREF="/Risks/12.27.html#subj3">  The REAL RISKS and REWARDS of E-Mail (Larry Press via Tom Lincoln)</A>
<LI><A HREF="/Risks/12.27.html#subj4">  Re: ``Returns for Senders'' (Willis H. Ware)</A>
<LI><A HREF="/Risks/12.27.html#subj5">  Re: +&amp;*#$ (John Moore, Andy Goldstein)</A>
<LI><A HREF="/Risks/12.27.html#subj6">  Re: A number is no name (RMRichardson, Bob Frankston)</A>
<LI><A HREF="/Risks/12.27.html#subj7">  Re: Unusual characters in addresses (David Lamb)</A>
<LI><A HREF="/Risks/12.27.html#subj8">  Re: A permanent EMAIL address (Mike Van Pelt)</A>
<LI><A HREF="/Risks/12.27.html#subj9">  Re: RISKS of using electronic mail" (David Parnas, John Sloan)</A>
<LI><A HREF="/Risks/12.27.html#subj10">  Re: The Dead Sea Scrolls and Data Security (Chuck Karish)</A>
<LI><A HREF="/Risks/12.27.html#subj11">  Re: WHOIS (David A. Curry, Chuck Karish)</A>
<LI><A HREF="/Risks/12.27.html#subj12">  A better model for cracking (Scott Draves)</A>
<LI><A HREF="/Risks/12.27.html#subj13">  Prize for Most Useful Computer Virus (Cliff Stoll)</A>
<LI><A HREF="/Risks/12.27.html#subj14">  15,000 Cuckoo Letters  [Another RISK OF EMAIL?] (Cliff Stoll)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.28.html">Volume 12 Issue 28 (9 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.28.html#subj1">  FAA on 755 thrust reversers (PGN)</A>
<LI><A HREF="/Risks/12.28.html#subj2">  Inmate, working for TWA, steals credit card numbers (Rodney Hoffman)</A>
<LI><A HREF="/Risks/12.28.html#subj3">  Re: Salomon Brothers -- Database Design (William Dye)</A>
<LI><A HREF="/Risks/12.28.html#subj4">  Fax machine IDs (Robert Morris)</A>
<LI><A HREF="/Risks/12.28.html#subj5">  Re: Unusual characters in addresses (Bob Frankston)</A>
<LI><A HREF="/Risks/12.28.html#subj6">  Failsafe mode for 3.5" Floppies (Don Phillips)</A>
<LI><A HREF="/Risks/12.28.html#subj7">  Re: The RISKS of Superiority (John Hobson)</A>
<LI><A HREF="/Risks/12.28.html#subj8">  Re: A Danger ... with Intelligent Terminals (Randolph Bentson)</A>
<LI><A HREF="/Risks/12.28.html#subj9">  Risk assessment: a specific experience (Mark Fulk)</A>
<LI><A HREF="/Risks/12.28.html#subj10">  Re: Risk Perception (Geoff Kuenning, Chuck via Phil Agre, David Chase,       Dan Drake, Craig Partridge, William P Gardner, Phil Agre, Fred Heutte)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.29.html">Volume 12 Issue 29 (10 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.29.html#subj1">  CIA dumps on the National Security Archive (Tom Slone)</A>
<LI><A HREF="/Risks/12.29.html#subj2">  CAA grant Cat IIIB autoland clearance for 747/767 (Martyn Thomas)</A>
<LI><A HREF="/Risks/12.29.html#subj3">  Follow-up on Hobson's M16 story (Jim Purtilo) </A>
<LI><A HREF="/Risks/12.29.html#subj4">  Risks of Incompatibilities (Harry Erwin)</A>
<LI><A HREF="/Risks/12.29.html#subj5">  Crackers for hire (Mark Seecof)</A>
<LI><A HREF="/Risks/12.29.html#subj6">  Re: Salomon Brothers -- Database Design (Dan Drake)</A>
<LI><A HREF="/Risks/12.29.html#subj7">  Re: Risk assessment: a specific experience (Peter Wayner)</A>
<LI><A HREF="/Risks/12.29.html#subj8">  Re: The risk of thinking we are in control (Larry Seiler)</A>
<LI><A HREF="/Risks/12.29.html#subj9">  Re: National characters on car plates (Torsten Lif)</A>
<LI><A HREF="/Risks/12.29.html#subj10">  Re: Failsafe mode for 3.5" Floppies (BartMassey, BruceHamilton, AndrewKlossner)</A>
<LI><A HREF="/Risks/12.29.html#subj11">  Re: Number of virus events dropping (Mark Hittinger)</A>
<LI><A HREF="/Risks/12.29.html#subj12">  Re: Prize for Most Useful Computer Virus (Raymond Chen, Richard A. Schumacher,      Dave Butterfield)
</A>
<LI><A HREF="/Risks/12.29.html#subj13">  It is RISKy to believe that Averages are `average' [!] (David Paschall-Zimbel)</A>
<LI><A HREF="/Risks/12.29.html#subj14">  Seventh Annual Conference on Computer Assurance (James Bret Michael)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.30.html">Volume 12 Issue 30 (11 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.30.html#subj1">  Export controls on workstations (John Markoff via PGN)</A>
<LI><A HREF="/Risks/12.30.html#subj2">  Re: Multinational Character sets (Hugh Davies)</A>
<LI><A HREF="/Risks/12.30.html#subj3">  Re: National Character variations in ASCII (Kim Greer)</A>
<LI><A HREF="/Risks/12.30.html#subj4">  Re: Risks of sloppy terminology (Geoff Kuenning)</A>
<LI><A HREF="/Risks/12.30.html#subj5">  Re: M16 (Ty Sarna)</A>
<LI><A HREF="/Risks/12.30.html#subj6">  Re: Failsafe floppies? (Jordan M. Kossack, Bob Jewett, Doug Krause, David Palmer,      Mike Berman)
</A>
<LI><A HREF="/Risks/12.30.html#subj7">  Re: Beneficial viruses considered harmful (Brian Rice)</A>
<LI><A HREF="/Risks/12.30.html#subj8">  Re: Prize for Most Useful Computer Virus (Joe Dellinger)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.31.html">Volume 12 Issue 31 (12 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.31.html#subj1">  Re: Export controls on workstations (Neil W Rickert, Brinton Cooper,      Haakon Styri)
</A>
<LI><A HREF="/Risks/12.31.html#subj2">  "Checkless society" (Daniel B Dobkin)</A>
<LI><A HREF="/Risks/12.31.html#subj3">  Re: Multinational Character sets (Dik T. Winter, Robert Ullmann, Hugh Davies)</A>
<LI><A HREF="/Risks/12.31.html#subj4">  Re: +&amp;*#$ (Mike Morris)</A>
<LI><A HREF="/Risks/12.31.html#subj5">  Re: M16 and James Fallows' "Two Weapons" (Jon Jacky, Tom Faller)</A>
<LI><A HREF="/Risks/12.31.html#subj6">  Junk Mail -- In memoriam, Dave Sharp (Peter Mellor)</A>
<LI><A HREF="/Risks/12.31.html#subj7">  Risks of assumptions? (R. Cage)</A>
<LI><A HREF="/Risks/12.31.html#subj8">  The seriousness of statistics mistakes (Jeremy Grodberg)</A>
<LI><A HREF="/Risks/12.31.html#subj9">  Risk Assessment: a specific experience (Justine Roberts)</A>
<LI><A HREF="/Risks/12.31.html#subj10">  Re: risk analysis (Victor Yodaiken)</A>
<LI><A HREF="/Risks/12.31.html#subj11">  Averages and distributions (Jerry Leichter)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.32.html">Volume 12 Issue 32 (12 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.32.html#subj1">  Security in software distribution (Joe Morris)</A>
<LI><A HREF="/Risks/12.32.html#subj2">  Re: Crackers for hire (Joan Eslinger, James Deibele)</A>
<LI><A HREF="/Risks/12.32.html#subj3">  Re: Helpful Viruses? (Stan Kurzban, Bob Johnson, Chuck Royalty)</A>
<LI><A HREF="/Risks/12.32.html#subj4">  Re: Cheap air tix (Mark Seecof)</A>
<LI><A HREF="/Risks/12.32.html#subj5">  Re: EMP (Phil Agre, Tom Faller)</A>
<LI><A HREF="/Risks/12.32.html#subj6">  Re: The seriousness of statistics mistakes ... (Mark Fulk, Ronald A. Thisted)</A>
<LI><A HREF="/Risks/12.32.html#subj7">  Re: ASCII (Eric Florack, Mark Seecof)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.33.html">Volume 12 Issue 33 (15 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.33.html#subj1">  British Telecom computer failure cuts off 42000 (Paul Leyland)</A>
<LI><A HREF="/Risks/12.33.html#subj2">  Security Software Bug Locks Up System (Sanford Sherizen)</A>
<LI><A HREF="/Risks/12.33.html#subj3">  Companies Steal Information (Sanford Sherizen)</A>
<LI><A HREF="/Risks/12.33.html#subj4">  Industrial espionage (Jerry Leichter)</A>
<LI><A HREF="/Risks/12.33.html#subj5">  Re: Junk Mail ... 737 crash (Steven Philipson)</A>
<LI><A HREF="/Risks/12.33.html#subj6">  RSA vs. NIST (digital security standards) (Tom Slone)</A>
<LI><A HREF="/Risks/12.33.html#subj7">  Re: Salomon Brothers -- Database Design (Gary Beckmann)</A>
<LI><A HREF="/Risks/12.33.html#subj8">  Secret Computations the basis for Corporate Decisions (Jeffrey Sorensen)</A>
<LI><A HREF="/Risks/12.33.html#subj9">  Re: +&amp;*#$ (Bob Clements, H. Fuss)</A>
<LI><A HREF="/Risks/12.33.html#subj10">  History of Internationalization of ASCII (Paul Green, Lars Henrik Mathiesen)</A>
<LI><A HREF="/Risks/12.33.html#subj11">  Export controls on workstations, or, more mantras (Jerry Leichter)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.34.html">Volume 12 Issue 34 (16 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.34.html#subj1">  Network Security Lacking at Major Stock Exchanges (PGN)</A>
<LI><A HREF="/Risks/12.34.html#subj2">  "Planted" data in databases [anonymous]</A>
<LI><A HREF="/Risks/12.34.html#subj3">  Re: RSA vs. NIST (Greg Rose, Steve Bellovin, Dan Bernstein, Kevin McCurley)</A>
<LI><A HREF="/Risks/12.34.html#subj4">  Re: Export controls on workstations (Hank Nussbacher, Lars-Henrik Eriksson,      John Mainwaring)
</A>
<LI><A HREF="/Risks/12.34.html#subj5">  RISKS of trying to get hard facts [OS/2] (Conrad Bullock via Gideon Yuval)</A>
<LI><A HREF="/Risks/12.34.html#subj6">  RISKS (yet again) of not enough data (Bill Gunshannon)</A>
<LI><A HREF="/Risks/12.34.html#subj7">  Re: +&amp;*#$ (Dave Roberts)</A>
<LI><A HREF="/Risks/12.34.html#subj8">  Re: Multics/UNIX Lessons (Dick Karpinski)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.35.html">Volume 12 Issue 35 (17 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.35.html#subj1">  Computer security breach at Rocky Flats nuclear weapons plant    (Fernando Pereira, Allen Miller)
</A>
<LI><A HREF="/Risks/12.35.html#subj2">  DSA is weak (Jim Bidzos)</A>
<LI><A HREF="/Risks/12.35.html#subj3">  The difficulty of RSA (Jerry Leichter)</A>
<LI><A HREF="/Risks/12.35.html#subj4">  Re: RSA vs. NIST (digital security standards) (Richard A. Schumacher)</A>
<LI><A HREF="/Risks/12.35.html#subj5">  Re: Export controls on workstations, ... (John R. Levine)</A>
<LI><A HREF="/Risks/12.35.html#subj6">  Virus halted government computers in south China (PGN)</A>
<LI><A HREF="/Risks/12.35.html#subj7">  Smart Pill Bottles (Joe Abernathy) (from CACM via VOGON)</A>
<LI><A HREF="/Risks/12.35.html#subj8">  Retraction: The seriousness of statistics mistakes (Jeremy Grodberg)</A>
<LI><A HREF="/Risks/12.35.html#subj9">  The seriousness of statistical mistakes (Clifford Johnson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.36.html">Volume 12 Issue 36 (18 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.36.html#subj1">  AT&amp;T Phone Failure (Ed Andrews)</A>
<LI><A HREF="/Risks/12.36.html#subj2">  Fly-by-wire without leaving the ground (JCF)</A>
<LI><A HREF="/Risks/12.36.html#subj3">  World Bank virus (Ted Lee)</A>
<LI><A HREF="/Risks/12.36.html#subj4">  SunOS SPARC Integer Division Vulnerability (CERT Advisory)</A>
<LI><A HREF="/Risks/12.36.html#subj5">  The risks of a computer-based forum (Brian Holt Hawthorne)</A>
<LI><A HREF="/Risks/12.36.html#subj6">  Descriptive terms [false positives and negatives] (Jon Krueger)</A>
<LI><A HREF="/Risks/12.36.html#subj7">  Risks of mistreating programmers (Arun Welch)</A>
<LI><A HREF="/Risks/12.36.html#subj8">  Re: Security Software Bug Locks Up System (Sanford Sherizen)</A>
<LI><A HREF="/Risks/12.36.html#subj9">  RSA stuff (John Mount)</A>
<LI><A HREF="/Risks/12.36.html#subj10">  Manipulation of digital images (Joe Morris)</A>
<LI><A HREF="/Risks/12.36.html#subj11">  Re: +&amp;*# (Richard Ristow, John Wichers, Gary Beckmann, Timothy Freeman,     Lynn R Grant, John F. Woods)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.37.html">Volume 12 Issue 37 (20 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.37.html#subj1">  Letter to Congress on NIST's DSS (Jim Bidzos)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.38.html">Volume 12 Issue 38 (20 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.38.html#subj1">  Midwest Stock Exchange Reaps Millions Due to Accounting Glitch (Jeff Helgesen)</A>
<LI><A HREF="/Risks/12.38.html#subj2">  Newark NJ high school computer problem (Martin A. Leisner)</A>
<LI><A HREF="/Risks/12.38.html#subj3">  Technology and the oldest profession (Henry Cox)</A>
<LI><A HREF="/Risks/12.38.html#subj4">  YATO (Yet Another Telco Outage) (Richard Johnson)</A>
<LI><A HREF="/Risks/12.38.html#subj5">  AT&amp;T switch trouble (Fernando Pereira)</A>
<LI><A HREF="/Risks/12.38.html#subj6">  English Supermarket Checkout Failure (Maddock)</A>
<LI><A HREF="/Risks/12.38.html#subj7">  Samurai Hackers' Cunning Employer Screening Process (Marco Barbarisi)</A>
<LI><A HREF="/Risks/12.38.html#subj8">  Re: Fly-by-wire without leaving the ground (A. Padgett Peterson)</A>
<LI><A HREF="/Risks/12.38.html#subj9">  MSAFP, utilities, and all that (Mark Fulk)</A>
<LI><A HREF="/Risks/12.38.html#subj10">  Computer monitoring of pill bottles (Jennifer Heymont)</A>
<LI><A HREF="/Risks/12.38.html#subj11">  Documentation and lack thereof (Stanley (S.T.H.) Chow)</A>
<LI><A HREF="/Risks/12.38.html#subj12">  Just the wrong number (Jerry Leichter)</A>
<LI><A HREF="/Risks/12.38.html#subj13">  Reliability and Redundancy (Bill Murray)</A>
<LI><A HREF="/Risks/12.38.html#subj14">  CPSR Annual Meeting (Eric Roberts)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.39.html">Volume 12 Issue 39 (23 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.39.html#subj1">  Carpal Tunnel Syndrome strikes (Peter Mellor)</A>
<LI><A HREF="/Risks/12.39.html#subj2">  Risks of technical translation (Bertrand Meyer)</A>
<LI><A HREF="/Risks/12.39.html#subj3">  Patent for Travelmation on Fare-Search System (Bob Frankston)</A>
<LI><A HREF="/Risks/12.39.html#subj4">  Rounding and truncating within multilevel software (Brenton Hoff)</A>
<LI><A HREF="/Risks/12.39.html#subj5">  Re: SunOS SPARC Integer Division Vulnerability (Dik T. Winter)</A>
<LI><A HREF="/Risks/12.39.html#subj6">  Re: Risks of mistreating programmers (Vesselin Vladimirov Bontchev)</A>
<LI><A HREF="/Risks/12.39.html#subj7">  Re: Play the lottery via Nintendo (Mike Cepek)</A>
<LI><A HREF="/Risks/12.39.html#subj8">  Re: documentation and the obsolete parts problem (Lou)</A>
<LI><A HREF="/Risks/12.39.html#subj9">  Ideas made simple (Bob Frankston)</A>
<LI><A HREF="/Risks/12.39.html#subj10">  Book review: Technological Risk, H.W. Lewis (Jack Goldberg)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.40.html">Volume 12 Issue 40 (25 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.40.html#subj1">  Bell V-22 Osprey - correct sensor outvoted (John Wodehouse)</A>
<LI><A HREF="/Risks/12.40.html#subj2">  Challenger O-ring Problem heads topics at conference on ethics (George Leach)</A>
<LI><A HREF="/Risks/12.40.html#subj3">  People and Public Screens (Antony Upward, PGN)</A>
<LI><A HREF="/Risks/12.40.html#subj4">  Credit bureaus, heisenbugs, and clerical errors (Peter G. Capek)</A>
<LI><A HREF="/Risks/12.40.html#subj5">  Electronic locks at Harvard (David A. Holland)</A>
<LI><A HREF="/Risks/12.40.html#subj6">  Bad error handling in Lamborghini Diablo engine management (Richard Boylan)</A>
<LI><A HREF="/Risks/12.40.html#subj7">  Denver Hacker Hacks NASA (Andy Hawks)</A>
<LI><A HREF="/Risks/12.40.html#subj8">  Re: MSAFP, utilities, and all that (Eric Eldred)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.41.html">Volume 12 Issue 41 (28 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.41.html#subj1">  Ada Code Formatters pretty dangerous (Richard G. Hash)</A>
<LI><A HREF="/Risks/12.41.html#subj2">  Risks of computerized typesetting (Simson Garfinkel)</A>
<LI><A HREF="/Risks/12.41.html#subj3">  Galileo's Revenge - Junk Science in the Courtroom (Martin Minow)</A>
<LI><A HREF="/Risks/12.41.html#subj4">  Readings in Judgement and Decision Making (Doug Jensen)</A>
<LI><A HREF="/Risks/12.41.html#subj5">  Nintendo Lottery Is For Real (Jim Huggins)</A>
<LI><A HREF="/Risks/12.41.html#subj6">  Radio Shack computerized mailing list problem (Joseph Poirier )</A>
<LI><A HREF="/Risks/12.41.html#subj7">  Re: Security in software distribution (Kilgallen)</A>
<LI><A HREF="/Risks/12.41.html#subj8">  Re: Bell V-22 Osprey (John Wodehouse, A. Padgett Peterson)</A>
<LI><A HREF="/Risks/12.41.html#subj9">  Have you tested your machine lately? (K. M. Sandberg)</A>
<LI><A HREF="/Risks/12.41.html#subj10">  Electronic Locks in Universities (Martin Ewing, Jim Huggins, Dean Rubine,    Kraig Meyer, Mike Carleton)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.42.html">Volume 12 Issue 42 (30 September 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.42.html#subj1">  Dialup lottery (PGN)</A>
<LI><A HREF="/Risks/12.42.html#subj2">  Space Station Software Hubris (David Bremner)</A>
<LI><A HREF="/Risks/12.42.html#subj3">  Re: V-22 Osprey (Henry Spencer)</A>
<LI><A HREF="/Risks/12.42.html#subj4">  Re: Risks of computerized typesetting (Lauren Weinstein, Gene Spafford)</A>
<LI><A HREF="/Risks/12.42.html#subj5">  Re: Radio Shack computerized mailing list problem (John R. Levine, et al.)</A>
<LI><A HREF="/Risks/12.42.html#subj6">  Re: eelskin wallets and magnetic cards (Robert Ullmann, et al.)</A>
<LI><A HREF="/Risks/12.42.html#subj7">  Re: Have you tested your machine lately? (Bennet Yee, Henry Spencer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.43.html">Volume 12 Issue 43 (7 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.43.html#subj1">  Full (16 rounds) DES Broken (Li Gong, Dave Roberts)</A>
<LI><A HREF="/Risks/12.43.html#subj2">  AT&amp;T "Deeply Distressed" over Outage (Mark Seecof, Michael F Eastman)</A>
<LI><A HREF="/Risks/12.43.html#subj3">  Fred Cohen's contest and ``good viruses'' (Gene Spafford, John Markoff)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.44.html">Volume 12 Issue 44 (8 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.44.html#subj1">  RISKS of Highway warning signs (Jim Hofmann)</A>
<LI><A HREF="/Risks/12.44.html#subj2">  US Coast Guard's user fiendly software [sic] (Dave Schmidt)</A>
<LI><A HREF="/Risks/12.44.html#subj3">  Fiber optics can spontaneously destroy themselves! (Jeffrey Sorensen)</A>
<LI><A HREF="/Risks/12.44.html#subj4">  911 Glitch Delayed Help in Fatal Mt. Prospect Fire (W.F. Wicks via Mark Brader)</A>
<LI><A HREF="/Risks/12.44.html#subj5">  Risks of owning a modem (Geoff Kuenning)</A>
<LI><A HREF="/Risks/12.44.html#subj6">  Emergency phone dialer in Contra Costa county (Darren Alex Griffiths)</A>
<LI><A HREF="/Risks/12.44.html#subj7">  ECC == Error CAUSING Code?  Tape drive overcorrects itself... (John Board)</A>
<LI><A HREF="/Risks/12.44.html#subj8">  Re: AT&amp;T "Deeply Distressed" (Bob Colwell)</A>
<LI><A HREF="/Risks/12.44.html#subj9">  Re: Back quotes print wrong (Dick Karpinski, Simson L. Garfinkel)</A>
<LI><A HREF="/Risks/12.44.html#subj10">  Re: Space Station Software Hubris (Stephen G. Smith)</A>
<LI><A HREF="/Risks/12.44.html#subj11">  Schipol Airport (Peter De Graaf via Mark Kennedy)</A>
<LI><A HREF="/Risks/12.44.html#subj12">  Computer Mediated Ethical Discussion: An Invitation (Peter Danielson)</A>
<LI><A HREF="/Risks/12.44.html#subj13">  ACM Computer Security Day (Beth Olson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.45.html">Volume 12 Issue 45 (9 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.45.html#subj1">  TACAS -- good news / bad news (Martin Minow, PGN)</A>
<LI><A HREF="/Risks/12.45.html#subj2">  Safer flying through fly-by-wire (Henry Spencer)</A>
<LI><A HREF="/Risks/12.45.html#subj3">  Friendly (?) viruses (Paul Smee)</A>
<LI><A HREF="/Risks/12.45.html#subj4">  Computers and missile control (Walt Thode)</A>
<LI><A HREF="/Risks/12.45.html#subj5">  Re: Known plaintext attacks (Ted Rodriguez-Bell, Clive Feather)</A>
<LI><A HREF="/Risks/12.45.html#subj6">  Re: AT&amp;T "Deeply Distressed" (Steve Bellovin, Bob Colwell)</A>
<LI><A HREF="/Risks/12.45.html#subj7">  Re: Schipol Airport (Henry Spencer)</A>
<LI><A HREF="/Risks/12.45.html#subj8">  Re: RISKS of Highway warning signs (K. M. Sandberg, Joe Morris,      Dominic G. Flory, Michael Cook)
</A>
<LI><A HREF="/Risks/12.45.html#subj9">  Risks of computerized typesetting (Paul Wallich, Joe Smith)</A>
<LI><A HREF="/Risks/12.45.html#subj10">  Re: Ada Code Formatters (or the dangers of old software) (Kent Mitchell)</A>
<LI><A HREF="/Risks/12.45.html#subj11">  Re: Computerized typesetting and character sets (Richard S. D'Ippolito)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.46.html">Volume 12 Issue 46 (10 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.46.html#subj1">  Encryption Exportability (Clark Weissman) (from ``Inside Risks'')</A>
<LI><A HREF="/Risks/12.46.html#subj2">  Security Criteria, Evaluation and the International Environment (Steve Lipner)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.47.html">Volume 12 Issue 47 (10 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.47.html#subj1">  Ex-DMV worker admits altering driving records for money (Vireday)</A>
<LI><A HREF="/Risks/12.47.html#subj2">  Software migration at Johnson Space Center (Joe Bouchard)</A>
<LI><A HREF="/Risks/12.47.html#subj3">  European Ideal Embraces Harmonised Pornography (Brian Randell)</A>
<LI><A HREF="/Risks/12.47.html#subj4">  Prison Phone Phraud (or The RISKS of Spanish) (Jim Flanagan)</A>
<LI><A HREF="/Risks/12.47.html#subj5">  "Peace Patent" and "Colossus: The Forbin Project" (Lauren Weinstein)</A>
<LI><A HREF="/Risks/12.47.html#subj6">  UCSC to install touch-tone registration (HELP WANTED) (Darrell Long)</A>
<LI><A HREF="/Risks/12.47.html#subj7">  Re: Ada Code Formatters (... old software) (David Parnas)</A>
<LI><A HREF="/Risks/12.47.html#subj8">  Re: Encryption Exportability, by Clark Weissman (Carl Ellison)</A>
<LI><A HREF="/Risks/12.47.html#subj9">  Re: Fiber optics can spontaneously destroy themselves! (Paul Leyland)</A>
<LI><A HREF="/Risks/12.47.html#subj10">  Re: Safer flying through fly-by-wire (Randal L. Schwartz)</A>
<LI><A HREF="/Risks/12.47.html#subj11">  Re: ``Friendly'' (?) viruses (Bertrand Meyer)</A>
<LI><A HREF="/Risks/12.47.html#subj12">  Re: AT&amp;T Outages (Peter G. Rose)</A>
<LI><A HREF="/Risks/12.47.html#subj13">  Re: RISKS of Highway warning signs (Steven Philipson, Arthur Hamlin,       Richard Thomsen, Bob Haar, Keith Henson)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.48.html">Volume 12 Issue 48 (11 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.48.html#subj1">  Police raid wrong house -- for second time (David B. Benson)</A>
<LI><A HREF="/Risks/12.48.html#subj2">  Crypto Public Policy (Bill Murray)</A>
<LI><A HREF="/Risks/12.48.html#subj3">  Re: Security Criteria, Evaluation and the International Environment      (Henry Spencer, PGN)
</A>
<LI><A HREF="/Risks/12.48.html#subj4">  Re: "Safer Flying through Fly-By-Wire (Arnd Wussing, Mary Shafer)</A>
<LI><A HREF="/Risks/12.48.html#subj5">  Re: Computers and missile control (Eric Prebys)</A>
<LI><A HREF="/Risks/12.48.html#subj6">  Re: Software migration at Johnson Space Center (Bob Frankston, Doug Burke,      Guy J. Sherr)
</A>
<LI><A HREF="/Risks/12.48.html#subj7">  Human error: once more, with feeling (Don Norman)</A>
<LI><A HREF="/Risks/12.48.html#subj8">  Re: AT&amp;T outage (Bob Colwell, Mark Seecof, Bob Niland, Martyn Thomas)</A>
<LI><A HREF="/Risks/12.48.html#subj9">  A step towards adopting DefStan 00-55 (Vicky Stavridou)</A>
<LI><A HREF="/Risks/12.48.html#subj10">  Digital Retouching on the Telephone (Chuck Dunlop)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.49.html">Volume 12 Issue 49 (14 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.49.html#subj1">  Nuclear Computer Safety Fears (Antony Upward)</A>
<LI><A HREF="/Risks/12.49.html#subj2">  Computer Error by Policeman (Antony Upward)</A>
<LI><A HREF="/Risks/12.49.html#subj3">  Thermostat failure mode (Liudvikas Bukys)</A>
<LI><A HREF="/Risks/12.49.html#subj4">  I really like banks -- world wide! (Boyd Roberts)</A>
<LI><A HREF="/Risks/12.49.html#subj5">  I'm sorry, the computer says your credit is bad (David Bremner)</A>
<LI><A HREF="/Risks/12.49.html#subj6">  "Who Flies the Plane?" (Ken Tindell)</A>
<LI><A HREF="/Risks/12.49.html#subj7">  Risks of Enterprise-Wide Phone Systems (David Fiedler)</A>
<LI><A HREF="/Risks/12.49.html#subj8">  AT&amp;T Outage (Jerry Schwarz)</A>
<LI><A HREF="/Risks/12.49.html#subj9">  Re: "AT&amp;T `Deeply Distressed' (Flint Pellett)</A>
<LI><A HREF="/Risks/12.49.html#subj10">  Re: External risks to computer systems (Peter Mellor)</A>
<LI><A HREF="/Risks/12.49.html#subj11">  Re: Keeping people in the loop (George W. Leach)</A>
<LI><A HREF="/Risks/12.49.html#subj12">  Re: ``Friendly'' (?) viruses (Brandon S. Allbery, Paul Smee)</A>
<LI><A HREF="/Risks/12.49.html#subj13">  Re: buggy software (James B. Shearer)</A>
<LI><A HREF="/Risks/12.49.html#subj14">  Re: Security Criteria, Evaluation ... (David States)</A>
<LI><A HREF="/Risks/12.49.html#subj15">  Re: Software migration at Johnson Space Center (Richard H. Miller, Tim Parker)</A>
<LI><A HREF="/Risks/12.49.html#subj16">  Informatik journal available (Duane)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.50.html">Volume 12 Issue 50 (15 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.50.html#subj1">  TRW misreports local taxes (Mark Seecof)</A>
<LI><A HREF="/Risks/12.50.html#subj2">  ATM Doesn't Catch Cash Cache Problem (Ed Miller)</A>
<LI><A HREF="/Risks/12.50.html#subj3">  Re: buggy software (David Parnas)</A>
<LI><A HREF="/Risks/12.50.html#subj4">  Risks of genetic engineering? (Michael Pilling)</A>
<LI><A HREF="/Risks/12.50.html#subj5">  Electronic thermostat failures (Ralph Palmer, Mary Shafer, Bob Wilson)</A>
<LI><A HREF="/Risks/12.50.html#subj6">  ACM SIGSOFT'91: SOFTWARE FOR CRITICAL SYSTEMS [timely reminder] (Nancy Leveson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.51.html">Volume 12 Issue 51 (16 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.51.html#subj1">  Mathematical and scientific foundations for engineering (Henry Petroski via PGN)</A>
<LI><A HREF="/Risks/12.51.html#subj2">  Thermostat failure (Richard Schroeppel)</A>
<LI><A HREF="/Risks/12.51.html#subj3">  Blockbuster `Loses' Returned Video (Mowgli C Assor)</A>
<LI><A HREF="/Risks/12.51.html#subj4">  Credit Card Fraud (Brian Randell)</A>
<LI><A HREF="/Risks/12.51.html#subj5">  New Massachusetts check/credit card ID law (John R. Levine)</A>
<LI><A HREF="/Risks/12.51.html#subj6">  Giving Away Privacy (Continued) (Sanford Sherizen)</A>
<LI><A HREF="/Risks/12.51.html#subj7">  Re: buggy software (Martyn Thomas, Magnus Kempe, Dave Parnas, Bart Massey,       Ernesto Pacas-Skewes)
</A>
<LI><A HREF="/Risks/12.51.html#subj8">  Re: TRW misreports local taxes (Rob Spray)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.52.html">Volume 12 Issue 52 (21 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.52.html#subj1">  The Future is Here (Amos Shapir)</A>
<LI><A HREF="/Risks/12.52.html#subj2">  The_RISKS_of_Geraldo (Andy Hawks)           [totally accidental juxtaposition!]</A>
<LI><A HREF="/Risks/12.52.html#subj3">  Re: Police raid wrong house -- for second time (Amos Shapir)</A>
<LI><A HREF="/Risks/12.52.html#subj4">  Re: TRW (Bob Colwell, Anthony DeBoer, Steve Hollasch)</A>
<LI><A HREF="/Risks/12.52.html#subj5">  Re: buggy software (Mark R Cornwell, James B. Shearer, Byron Rakitzis,       Richard Hanlon, Stephen G. Smith, Bob Wilson, David Parnas, David Chase)
</A>
<LI><A HREF="/Risks/12.52.html#subj6">  Licensing Software Engineers (Christopher E Fulmer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.53.html">Volume 12 Issue 53 (21 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.53.html#subj1">  Inappropriate ATM error codes (Sean Eric Fagan)</A>
<LI><A HREF="/Risks/12.53.html#subj2">  Blood Donor Cards (Robert E. Van Cleef)</A>
<LI><A HREF="/Risks/12.53.html#subj3">  RISKs of new E911 system (Paul Robichaux)</A>
<LI><A HREF="/Risks/12.53.html#subj4">  Unusual risks of frequent flying (Rob Aitken)</A>
<LI><A HREF="/Risks/12.53.html#subj5">  Review of THE GLASS COCKPIT (Robert Dorsett)</A>
<LI><A HREF="/Risks/12.53.html#subj6">  Yet another journalistic cock-up (cracker activity) (Simon E Spero)</A>
<LI><A HREF="/Risks/12.53.html#subj7">  Assurance of High-Integrity Software - Report (Rick Kuhn)</A>
<LI><A HREF="/Risks/12.53.html#subj8">  Video stores losing videos... (Chris A. Anderson)</A>
<LI><A HREF="/Risks/12.53.html#subj9">  Re: Blockbuster (Brian Boutel, Matt Crawford, Kevin Hughes, Patricia Shanahan)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.54.html">Volume 12 Issue 54 (22 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.54.html#subj1">  Oki Telephone Programming (Stuart Bell)</A>
<LI><A HREF="/Risks/12.54.html#subj2">  Nintendo lottery sidetracked for now </A>
<LI><A HREF="/Risks/12.54.html#subj3">  Single Point of Failure in L-1011 Intercom (Craig H. Seidel)</A>
<LI><A HREF="/Risks/12.54.html#subj4">  Computer reads water meter (John Sullivan)</A>
<LI><A HREF="/Risks/12.54.html#subj5">  Risks of software controlled safety switch (Diomidis Spinellis)</A>
<LI><A HREF="/Risks/12.54.html#subj6">  Re: Licensing of Software Engineers (David Parnas)</A>
<LI><A HREF="/Risks/12.54.html#subj7">  Law requiring bug fixes (Mark Seecof)</A>
<LI><A HREF="/Risks/12.54.html#subj8">  Re: Yet another journalistic... (Amos Shapir)</A>
<LI><A HREF="/Risks/12.54.html#subj9">  More ATM anecdotes (Ralph Moonen)</A>
<LI><A HREF="/Risks/12.54.html#subj10">  Re: TRW misreports local taxes (Matt Bishop)</A>
<LI><A HREF="/Risks/12.54.html#subj11">  Re: JSC SMS rehost (David Carlson)</A>
<LI><A HREF="/Risks/12.54.html#subj12">  Avis vs. Spaf (Gene Spafford)</A>
<LI><A HREF="/Risks/12.54.html#subj13">  Re: Have you tested your machine lately? (Boyd Roberts)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.55.html">Volume 12 Issue 55 (23 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.55.html#subj1">  Power outage downs New York Stock Exchange for 24 minutes (PGN)</A>
<LI><A HREF="/Risks/12.55.html#subj2">  Near-sighted or far-sighted fibre-opticians? (PGN)</A>
<LI><A HREF="/Risks/12.55.html#subj3">  MCI Friends &amp; Family &amp; anyone else with a touch-tone phone (Brian R. Krause)</A>
<LI><A HREF="/Risks/12.55.html#subj4">  Risks of double standards (on PRODIGY)? (David HM Spector)</A>
<LI><A HREF="/Risks/12.55.html#subj5">  Use of Prodigy on AMC Computers (Louise R. Silsby via Brinton Cooper)</A>
<LI><A HREF="/Risks/12.55.html#subj6">  A note on RISKS contributions (PGN)</A>
<LI><A HREF="/Risks/12.55.html#subj7">  Re: Videos and "Dumbing Down" (again) (Daniel J Yurman)</A>
<LI><A HREF="/Risks/12.55.html#subj8">  Re: More ATM anecdotes (Mark Bartelt)</A>
<LI><A HREF="/Risks/12.55.html#subj9">  Re: Oki Telephone Programming (Randal L. Schwartz)</A>
<LI><A HREF="/Risks/12.55.html#subj10">  Re: Computer reads water meter (Lauren Weinstein, Sam Ho via John Sullivan,      Lars Poulsen, Bjorn N. Freeman-Benson)
</A>
<LI><A HREF="/Risks/12.55.html#subj11">  Re: Have you tested your machine lately? (Neil Hunt)</A>
<LI><A HREF="/Risks/12.55.html#subj12">  Re: Software Migration at the Johnson Space Center (Joe Bouchard)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.56.html">Volume 12 Issue 56 (25 October 1991  )</A>
<DD><UL>
<LI><A HREF="/Risks/12.56.html#subj1">  More O'Hare-raising experiences </A>
<LI><A HREF="/Risks/12.56.html#subj2">  Swedish election results were delayed (Martin Minow)</A>
<LI><A HREF="/Risks/12.56.html#subj3">  Campaign against telco info services (Mark Seecof)</A>
<LI><A HREF="/Risks/12.56.html#subj4">  The computer is always right. (E. Kristiansen)</A>
<LI><A HREF="/Risks/12.56.html#subj5">  1-900 scam (Torsten Lif)</A>
<LI><A HREF="/Risks/12.56.html#subj6">  RISKS of Electronic Credit Card Authorization (Derek Atkins)</A>
<LI><A HREF="/Risks/12.56.html#subj7">  Australian Software Quality Management Standard (Douglas Thomson)</A>
<LI><A HREF="/Risks/12.56.html#subj8">  AT&amp;T/ATC outage revisited (Alfred H. Scholldorf via PGN)</A>
<LI><A HREF="/Risks/12.56.html#subj9">  Re: Single Point of Failure in L-1011 Intercom (Brinton Cooper)</A>
<LI><A HREF="/Risks/12.56.html#subj10">  Re: Law requiring bug fixes (Geoffrey H. Cooper)</A>
<LI><A HREF="/Risks/12.56.html#subj11">  Re: Prodigy (Jamie Saker, Fred Gilham, Ronald Hale-Evans, Greg Brail)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.57.html">Volume 12 Issue 57 (28 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.57.html#subj1">  DSA/DSS -- Digital Signatures (Ron Rivest)</A>
<LI><A HREF="/Risks/12.57.html#subj2">  Porn-Sabotage in Italian newspaper (Enrico Musio)</A>
<LI><A HREF="/Risks/12.57.html#subj3">  Re: MCI Friends &amp; Family (Allan Meers)</A>
<LI><A HREF="/Risks/12.57.html#subj4">  Do floor vibrations damage disks? (Magnus Redin)</A>
<LI><A HREF="/Risks/12.57.html#subj5">  Re: Software migration at Johnson Space Center (Doug Burke)</A>
<LI><A HREF="/Risks/12.57.html#subj6">  A New Twist on "Speed Controlled by Radar" (Andrew C. Green)</A>
<LI><A HREF="/Risks/12.57.html#subj7">  Call for Papers ESORICS-92 (Yves Deswarte)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.58.html">Volume 12 Issue 58 (29 October 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.58.html#subj1">  Would you put your rook and bishop out on knights like this? (PGN)</A>
<LI><A HREF="/Risks/12.58.html#subj2">  Re: DSA/DSS -- Digital Signatures (James B. Shearer, Ron Rivest)</A>
<LI><A HREF="/Risks/12.58.html#subj3">  FDA-HIMA Conference on Regulation of Software (Rob Horn)</A>
<LI><A HREF="/Risks/12.58.html#subj4">  UCI computing survives power outage [almost] (Doug Krause)</A>
<LI><A HREF="/Risks/12.58.html#subj5">  Re: Swedish election results were delayed (Lars-Henrik Eriksson)</A>
<LI><A HREF="/Risks/12.58.html#subj6">  Re: Licensing of Software Developers (John Gilmore)</A>
<LI><A HREF="/Risks/12.58.html#subj7">  The risks of "convenient" technology (Curtis Galloway)</A>
<LI><A HREF="/Risks/12.58.html#subj8">  Free Call-Back (Lars-Henrik Eriksson)</A>
<LI><A HREF="/Risks/12.58.html#subj9">  The flip side of the 1-900 scam (Andrew Koenig)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.59.html">Volume 12 Issue 59 (5 November 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.59.html#subj1">  New Computer Center for Soviet President [anonymous]</A>
<LI><A HREF="/Risks/12.59.html#subj2">  "Computer rats on students who don't show up in class" (Steve M. Barr?)</A>
<LI><A HREF="/Risks/12.59.html#subj3">  Bank tries to lose 14 billion pounds (Nigel Cole)</A>
<LI><A HREF="/Risks/12.59.html#subj4">  Management Often Bungles Firing Process (Jeff Helgesen)</A>
<LI><A HREF="/Risks/12.59.html#subj5">  Chaos Congress 91 (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/12.59.html#subj6">  Japan's barriers against IT risks (Tokyo conf.report) (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/12.59.html#subj7">  DES is better than anyone would have guessed! (John Sullivan)</A>
<LI><A HREF="/Risks/12.59.html#subj8">  DES Watch (Richard Outerbridge)</A>
<LI><A HREF="/Risks/12.59.html#subj9">  Risks of ``record'' and ``replay'' terminal capabilities (Bertrand Meyer)</A>
<LI><A HREF="/Risks/12.59.html#subj10">  Re: Licensing of Software Developers (David Parnas)</A>
<LI><A HREF="/Risks/12.59.html#subj11">  Re: campaign against telco info services (Dave Bakken)</A>
<LI><A HREF="/Risks/12.59.html#subj12">  Re: Mathematical and scientific foundations (Leslie J. Somos)</A>
<LI><A HREF="/Risks/12.59.html#subj13">  Re: UCI computing survives power outage (William Walker)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.60.html">Volume 12 Issue 60 (6 November 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.60.html#subj1">  Driver arrested in computer muddle: Data protection problem (paj)</A>
<LI><A HREF="/Risks/12.60.html#subj2">  Computer Saboteur Pleads Guilty (Rodney Hoffman) </A>
<LI><A HREF="/Risks/12.60.html#subj3">  Blaming the computer (again) (Randal L. Schwartz) </A>
<LI><A HREF="/Risks/12.60.html#subj4">  YAHIR (Yet another human interface risk) (Friedrich Knauss)</A>
<LI><A HREF="/Risks/12.60.html#subj5">  Certified Voting Program (Brian A Wichmann) </A>
<LI><A HREF="/Risks/12.60.html#subj6">  Electronically controlled bus transmission (Mark Seecof) </A>
<LI><A HREF="/Risks/12.60.html#subj7">  V-22 Tiltrotor Roll Sensors and Triple Redundancy (Mike Allard) </A>
<LI><A HREF="/Risks/12.60.html#subj8">  Re: FDA-HIMA Conference on Regulation of Software (Frank Houston) </A>
<LI><A HREF="/Risks/12.60.html#subj9">  RISKS of propagating legendary RISKS (Paul Karger) </A>
<LI><A HREF="/Risks/12.60.html#subj10">  Software safety, formal methods, standards (Jonathan Bowen via Jim Horning)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.61.html">Volume 12 Issue 61 (7 November 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.61.html#subj1">  Cop Charged with Doctoring Computerized Citation Record</A>
<LI><A HREF="/Risks/12.61.html#subj2">  Legal status of digital signatures (Steve Bellovin)</A>
<LI><A HREF="/Risks/12.61.html#subj3">  The dangers of telco competition (Lauren Weinstein)</A>
<LI><A HREF="/Risks/12.61.html#subj4">  Oven temperature regulator problem (Jane Beckman)</A>
<LI><A HREF="/Risks/12.61.html#subj5">  No Power backup on Electronic Fuel Injection (Gareth Howell)</A>
<LI><A HREF="/Risks/12.61.html#subj6">  Another smart card risk (34AEJ7D)</A>
<LI><A HREF="/Risks/12.61.html#subj7">  UK Phone charge card risk (Graham Toal)</A>
<LI><A HREF="/Risks/12.61.html#subj8">  Risks of telephones with status displays (Neil Strauss)</A>
<LI><A HREF="/Risks/12.61.html#subj9">  Don't bank on computer viruses! (Gene Spafford)      [WWN strikes again!]</A>
<LI><A HREF="/Risks/12.61.html#subj10">  NSF researchers required to undergo security checks? (Nancy Leveson)</A>
<LI><A HREF="/Risks/12.61.html#subj11">  Re: Have you tested your machine lately? (Matt Crawford, Dave W. Hamaker)</A>
<LI><A HREF="/Risks/12.61.html#subj12">  Re: Blaming the computer (again) (George Malits, Paul J Karafiol)</A>
<LI><A HREF="/Risks/12.61.html#subj13">  Re: A new twist on "Speed Controlled by Radar" (Clive Dawson)</A>
<LI><A HREF="/Risks/12.61.html#subj14">  Re: Electronically controlled bus transmission (Adam V Reed, Jamie Mason)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.62.html">Volume 12 Issue 62 (12 November 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.62.html#subj1">  Leaves cause railway signal failure (Graeme Tozer)</A>
<LI><A HREF="/Risks/12.62.html#subj2">  Computer controlled train is unsafer (Bob Devine)</A>
<LI><A HREF="/Risks/12.62.html#subj3">  More air scares and phone moans (PGN)</A>
<LI><A HREF="/Risks/12.62.html#subj4">  RISKS of infrared car door locks (Andrew Evans)</A>
<LI><A HREF="/Risks/12.62.html#subj5">  Summary of responses on UK phone card risks (Graham Toal)</A>
<LI><A HREF="/Risks/12.62.html#subj6">  Re: Licensing of Software Developers (Brinton Cooper, David Parnas)</A>
<LI><A HREF="/Risks/12.62.html#subj7">  Searching a library database (Matthew Merzbacher)</A>
<LI><A HREF="/Risks/12.62.html#subj8">  Audi Pedal Pushers (Bob Ayers [and others])</A>
<LI><A HREF="/Risks/12.62.html#subj9">  Religious bias in RISKS posts is counter-productive (Bill Gray)</A>
<LI><A HREF="/Risks/12.62.html#subj10">  Re: Radar (Eric Florack)</A>
<LI><A HREF="/Risks/12.62.html#subj11">  Security failure: recycled "unlisted" phone number (Steven J. Edwards)</A>
<LI><A HREF="/Risks/12.62.html#subj12">  You can help build the National Public Network.  (Gerard Van der Leun)</A>
<LI><A HREF="/Risks/12.62.html#subj13">  Call for Papers: 5th Annual Computer Virus/Security Conference (Jack Holleran)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.63.html">Volume 12 Issue 63 (14 November 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.63.html#subj1">  Copy of Letter to NIST in response to proposed DSS (Martin Hellman)</A>
<LI><A HREF="/Risks/12.63.html#subj2">  Antivirus software vendor creates viruses (Richard Kulawiec)</A>
<LI><A HREF="/Risks/12.63.html#subj3">  I DEMAND AN APOLOGY FOR THIS LIBEL! (W. K. Gorman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.64.html">Volume 12 Issue 64 (15 November 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.64.html#subj1">  MCI's Response for RISKS (Sally McCaffrey)</A>
<LI><A HREF="/Risks/12.64.html#subj2">  Computer-assisted trading (Brendan Kehoe)</A>
<LI><A HREF="/Risks/12.64.html#subj3">  Risks of truncation in the stock market (Frank G Kienast)</A>
<LI><A HREF="/Risks/12.64.html#subj4">  gray vs gorman (Fred Gilham)</A>
<LI><A HREF="/Risks/12.64.html#subj5">  ACM SIGSOFT'91:  SOFTWARE FOR CRITICAL SYSTEMS (Peter G. Neumann)</A>
<LI><A HREF="/Risks/12.64.html#subj6">  5th Refinement Workshop: Theory and Practice of Formal Software Development    (Cliff B Jones)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.65.html">Volume 12 Issue 65 (26 November 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.65.html#subj1">  Phone outages ... tied to typing mistake (Rudy Bazelmans/Jim Horning)</A>
<LI><A HREF="/Risks/12.65.html#subj2">  Weather Service Circuit Failure</A>
<LI><A HREF="/Risks/12.65.html#subj3">  Problems with nuclear plant safety computer in the UK (Peter Ilieve)</A>
<LI><A HREF="/Risks/12.65.html#subj4">  Results of Train Accident Investigations (Jymmi C. Tseng)</A>
<LI><A HREF="/Risks/12.65.html#subj5">  Bank misdeposits money (David Shepherd)</A>
<LI><A HREF="/Risks/12.65.html#subj6">  Mass. Governor wants to sell list of drivers licenses [Yes and No] (Kent Quirk)</A>
<LI><A HREF="/Risks/12.65.html#subj7">  CPSR FOIAs U.S. Secret Service (Craig Neidorf)</A>
<LI><A HREF="/Risks/12.65.html#subj8">  The Trojan Horse named `AIDS'</A>
<LI><A HREF="/Risks/12.65.html#subj9">  Banning of autodialers? (John Sullivan)</A>
<LI><A HREF="/Risks/12.65.html#subj10">  A new risk for computer folks? Computers and termination policy (Mark Bartelt)</A>
<LI><A HREF="/Risks/12.65.html#subj11">  E911 system brought to it's knees by a prank (Glenn S. Tenney)</A>
<LI><A HREF="/Risks/12.65.html#subj12">  Study on Computer Addiction (Chris)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.66.html">Volume 12 Issue 66 (26 November 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.66.html#subj1">  Pentagon computers vulnerable</A>
<LI><A HREF="/Risks/12.66.html#subj2">  Risks of hardcoded hexadecimal instead of symbolic constants? (Tom Blinn)</A>
<LI><A HREF="/Risks/12.66.html#subj3">  Re: Leaves cause railway signal failure (Geraint Jones)</A>
<LI><A HREF="/Risks/12.66.html#subj4">  Re: Termination (David Lamb, anonymous)</A>
<LI><A HREF="/Risks/12.66.html#subj5">  Proposed Antivirus Certification (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/12.66.html#subj6">  Call for Papers: IFIP World Congress'92/Vulnerability (Klaus Brunnstein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.67.html">Volume 12 Issue 67 (2 December 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.67.html#subj1">  Computer Delays costs Hospital over \pounds 300,000 (Paul Leyland)</A>
<LI><A HREF="/Risks/12.67.html#subj2">  A RISK of dishonestly using a visible password (Paul Leyland)</A>
<LI><A HREF="/Risks/12.67.html#subj3">  Sprint Voice Calling Card uses SS# (Lauren Weinstein)</A>
<LI><A HREF="/Risks/12.67.html#subj4">  Bright AT&amp;T billing sys? (Thomson Kuhn)</A>
<LI><A HREF="/Risks/12.67.html#subj5">  `Contractor queries data security' (Matthew Farwell)</A>
<LI><A HREF="/Risks/12.67.html#subj6">  Proposed traffic congestion charging system, Cambridge UK (Hugo Tyson)</A>
<LI><A HREF="/Risks/12.67.html#subj7">  Mailing lists - a right royal mistake (Dave Horsfall)</A>
<LI><A HREF="/Risks/12.67.html#subj8">  Re: Leaves, trains, and computers (Peter Mellor)</A>
<LI><A HREF="/Risks/12.67.html#subj9">  Re: Proposed Antivirus Certification (David A. Honig)</A>
<LI><A HREF="/Risks/12.67.html#subj10">  Re: Employee Termination (anonymous, Bill Murray)</A>
<LI><A HREF="/Risks/12.67.html#subj11">  Re: Pentagon computers vulnerable (Brinton Cooper)</A>
<LI><A HREF="/Risks/12.67.html#subj12">  Re: Risks of hardcoded hex instead of symbolic constants? (Bob Frankston,      Bennet Yee, Graham Toal, Brandon S. Allbery, Paul S. Miner)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.68.html">Volume 12 Issue 68 (13 December 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.68.html#subj1">  Hubble Trouble: Space Telescope shuts itself down (Henry Cox)</A>
<LI><A HREF="/Risks/12.68.html#subj2">  Postal worker leaves automated stamper in test configuration (Palmer Davis,    Joe Brownlee)
</A>
<LI><A HREF="/Risks/12.68.html#subj3">  2 Safeway preferred customers, to go! (Bear Giles)</A>
<LI><A HREF="/Risks/12.68.html#subj4">  Hospital computer solicits the dead (Adam Gaffin)</A>
<LI><A HREF="/Risks/12.68.html#subj5">  Computer records track killer (Robert Jenkins)</A>
<LI><A HREF="/Risks/12.68.html#subj6">  Train crash in UK - is it human error? (Olivier M.J. Crepin-Leblond)</A>
<LI><A HREF="/Risks/12.68.html#subj7">  TRW lawsuit settled with FTC, 19 states (Phil R. Karn)</A>
<LI><A HREF="/Risks/12.68.html#subj8">  National Fingerprint Database specs (Clifford Johnson)</A>
<LI><A HREF="/Risks/12.68.html#subj9">  Bill on computer usage about to become law in Ireland (Mark Humphrys)</A>
<LI><A HREF="/Risks/12.68.html#subj10">  The description is right, only the language is wrong (Dan Franklin)</A>
<LI><A HREF="/Risks/12.68.html#subj11">  Poll tax incompetence (Robin Fairbairns)</A>
<LI><A HREF="/Risks/12.68.html#subj12">  Truth in Antiviral Advertising (Russell Aminzade)</A>
<LI><A HREF="/Risks/12.68.html#subj13">  Re: Pentagon computers vulnerable (Steve Bellovin)</A>
<LI><A HREF="/Risks/12.68.html#subj14">  Post-structuralism and Technology   (Phil Agre)</A>
<LI><A HREF="/Risks/12.68.html#subj15">  Chaos Congress 91 Program (Klaus Brunnstein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.69.html">Volume 12 Issue 69 (16 December 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.69.html#subj1">  800 telephone outage due to software upgrade (PGN)</A>
<LI><A HREF="/Risks/12.69.html#subj2">  Stock-listings typo: The possibilities are scary. (James Parry)</A>
<LI><A HREF="/Risks/12.69.html#subj3">  More on Lauda crash and computers (Nancy Leveson)</A>
<LI><A HREF="/Risks/12.69.html#subj4">  "Questioning Technology" in WHOLE EARTH REVIEW (Rodney Hoffman)</A>
<LI><A HREF="/Risks/12.69.html#subj5">  Privacy of Email (James Ting Lui)</A>
<LI><A HREF="/Risks/12.69.html#subj6">  More on E911 and representation (Bob Frankston)</A>
<LI><A HREF="/Risks/12.69.html#subj7">  Re: Computer records track killer (Brinton Cooper)</A>
<LI><A HREF="/Risks/12.69.html#subj8">  Re: The description is right, only the language is wrong (Scott E. Preece)</A>
<LI><A HREF="/Risks/12.69.html#subj9">  The EFF Pioneer Awards (Gerard Van der Leun)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.70.html">Volume 12 Issue 70 (18 December 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.70.html#subj1">  Life, Death, and Faxes -- Convicted forger released by bogus fax (PGN)</A>
<LI><A HREF="/Risks/12.70.html#subj2">  BT ordered to pay damages for keyboard injuries (Olivier M.J. Crepin-Leblond)</A>
<LI><A HREF="/Risks/12.70.html#subj3">  Re: Privacy of Email (Eric Florack)</A>
<LI><A HREF="/Risks/12.70.html#subj4">  Re: More on E911 and representation (Erling Kristiansen)</A>
<LI><A HREF="/Risks/12.70.html#subj5">  Software safety, formal methods and standards (Jonathan Bowen)    [Full text FTPable from RISKS-12.BOWEN]
</A>
<LI><A HREF="/Risks/12.70.html#subj6">  2nd Conf on Computers, Freedom, and Privacy (Lance J. Hoffman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.71.html">Volume 12 Issue 71 (24 December 1991)</A>
<DD><UL>
<LI><A HREF="/Risks/12.71.html#subj1">  Illegal sales of confidential data (Fernando Pereira)</A>
<LI><A HREF="/Risks/12.71.html#subj2">  The London Stock Exchange "Taurus" System (Brian Randell)</A>
<LI><A HREF="/Risks/12.71.html#subj3">  Computer Database of Former E. German State Police (Stasi) (Sanford Sherizen)</A>
<LI><A HREF="/Risks/12.71.html#subj4">  Remember, computer data is far from sacred. (Dean Pentcheff)</A>
<LI><A HREF="/Risks/12.71.html#subj5">  Outgoing fax numbers and Mercury PIN security (Nick Rothwell via Werner Uhrig)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/12.72.html">Volume 12 Issue 72 (31 December 1991 [actually issued 30 December 1991])</A>
<DD><UL>
<LI><A HREF="/Risks/12.72.html#subj1">  Airbus Fuel monitoring; tanks shown full when they were not (John Van Voorhis)</A>
<LI><A HREF="/Risks/12.72.html#subj2">  Recent Novell Software Contains a Hidden Virus (John Markoff)</A>
<LI><A HREF="/Risks/12.72.html#subj3">  Has anybody ever been spoofed on the wide network? (George Michaelson)</A>
<LI><A HREF="/Risks/12.72.html#subj4">  Re: Whole Earth Review Questions Technology (Tom White)</A>
<LI><A HREF="/Risks/12.72.html#subj5">  The Whole Earth is greater than the sum of its parts (Re: Jerry Mander) (PGN)</A>
</UL></DL>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/13/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-62</DOCNO>
<DOCOLDNO>IA013-000136-B032-41</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.01.html 128.240.150.127 19970217041600 text/html 31507
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:14:28 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 1</TITLE>
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.02.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.02.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 1</H1>
<H2> Monday 4 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Enterprising Vending Machines 
</A>
<DD>
<A HREF="#subj1.1">
Allan Meers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Re: Risks of automatic flight 
</A>
<DD>
<A HREF="#subj2.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: Voting by Phone &amp; public-key cryptography 
</A>
<DD>
<A HREF="#subj3.1">
Evan Ravitz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Random Voting IDs and Bogus Votes (Vote by Phone) 
</A>
<DD>
<A HREF="#subj4.1">
Mike Beede)
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Patriots ...    
</A>
<DD>
<A HREF="#subj5.1">
Steve Mitchell
</A><br>
<A HREF="#subj5.2">
 Steven Philipson
</A><br>
<A HREF="#subj5.3">
 Michael H. Riddle
</A><br>
<A HREF="#subj5.4">
 Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Man-in-the-loop on SDI 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: Broadcast local area networks ...    
</A>
<DD>
<A HREF="#subj7.1">
Curt Sampson
</A><br>
<A HREF="#subj7.2">
 Donald Lindsay
</A><br>
<A HREF="#subj7.3">
 John Stanley
</A><br>
<A HREF="#subj7.4">
 Jerry Leichter
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Enterprising Vending Machines
</A>
</H3>
<address>
Allan Meers - Sun Education
&lt;<A HREF="mailto:allans@ebay.sun.com ">
allans@ebay.sun.com 
</A>&gt;
</address>
<i>
Thu, 31 Jan 91 22:21:02 PST
</i><PRE>

         	USER-HOSTILE VENDING-MACHINE PROGRAMMING

My wife stopped at a Post Office yesterday to buy some stamps, and had a run in
with some technology.  They have a vending machine for stamps, which takes
old-fashioned paper money of up to $20 denominations.  To prevent you from
using the machine as a change machine, the bill-counter attachment is
programmed to give you change of a very limited amount, forcing you to spend
about 2/3 of whatever cash you insert.  She tried a $10 in this USPS
slot-machine.

Not until she had put money into the bill-counter would it tell her that the
selection was sold out by saying so on a display above the selection buttons.
There were no little soldout lights by each sample like on some types of
machines, and the display would not activate until you fed some cash into this
one-armed bandit.  Worse yet, even for a sold-out selection, you had to put in
as much money as the selection costs to find out that it was sold out -
otherwise the first/only message you got was "Need $.cc more".

Fortunately the common stamps were in multiple channels - unfortunately these
were all sold out also.  So here's the rock and the hard place.  There is no
sold out lights, no display on the panel without some money, no indication that
a particular selection is sold out til you have put in enough money (which can
be up to $25.00), and NO refunds without purchase.  Additionally, you have to
spend about 70% of the cash you put in.  Goldie settled on a bunch of 15c
postcard stamps that can be used next week when the letter rates go to 29c.

The risk here is that this machine is meant to be used by the general public,
and many of them are likely to be using it for the first time.  It's operation
and behavior differ greatly from the more normal soda and candy machines,
unfortunately - with much greater amounts of cash involved than with a Snickers
bar.

The bill-collecting portion appears to be an added-on unit, with no feedback
from the dispensing unit regarding product availability until AFTER the money
part has received the purchase price for that selection.  Extra programming
added in later to prevent the machines use as a change machine (for the bus
stop outside), did not take into account sold-out selections - which should
have been checked first, with or without money.  I believe that this unit was a
retrofit on an old machine, with additional programming adding later making it
a one-of-a-kind unit which acts like it didn't get much QA on the
customization.

SUMMARY:

  No (sold out) light always on.

  No light if you push the button without money to test.

  No light even with money entered, unless the amount is enough
	for that particular selection.

  No refund without purchase.

  No tag backs, no refunds, all sales final - gotcha.

I kinda thought you would appreciate the risks of a hostile-programmed vending
machine.  Especially one that would be in an environment like a post-office,
where people wouldn't necessarilly use it every day, and with a high percentage
of first-time users, who could get skunked by the over-zealous application of
the rules.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Risks of automatic flight
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Fri, 1 Feb 91 00:52:25 EST
</i><PRE>

&gt;It's ludicrous to believe that any airman would allow his pink flesh to be
&gt;routinely thrown at the ground without some control ...

I can think of one possible legitimate motive for this, which makes it a bit
less ludicrous than it first sounds.  The way for aircraft to survive in combat
is to get as low as possible.  In a real war, with serious and capable
opposition (it is not clear whether Iraq qualifies at present), a lot of flying
would be done at altitudes circa 50 feet.  The trouble is that flying at 50ft
is very different from flying at 500ft, which is a more usual training altitude
for the USAF.  The South African air force trains at 50 ft.  So do the
Israelis.  But the USAF considers training at realistic altitudes to be
unacceptably dangerous for peacetime.  The intent might have been to get the
benefits of the low altitude without the political difficulties of relatively
dangerous peacetime training or the fearful attrition rate associated with
having to learn new basic skills while being shot at.

                         Henry Spencer at U of Toronto Zoology   utzoo!henry

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Voting by Phone &amp; public-key cryptography
</A>
</H3>
<address>
Evan Ravitz
&lt;<A HREF="mailto:eravitz@isis.cs.du.edu ">
eravitz@isis.cs.du.edu 
</A>&gt;
</address>
<i>
Fri, 1 Feb 91 08:54:08 MST
</i><PRE>

Phil Zimmerman (prz@sage.cgd.ucar.edu (303)444-4541 ) is a computer security
consultant working with the Voting by phone foundation on public-key
cryptographic protocols used for voter authentication and privacy.  His group's
scheme would prevent the government from entering bogus votes, using the PINs
of those who had not voted at the end of the election, to use PGN's example.
              
For those who doubt that a PIN could not be anonymous I suggest drawing them
from a hat (perhaps using a device like we used to select gumball prizes with).
The other worries, like caller ID and wire-tapping can be avoided by simply
voting from any other phone.  I'm sure I pass a dozen a day.
              
Paranoia is justified, but apply it to how we vote now, as well.  Don't you
think that a government that can photograph your license plate from outer space
can install a tiny video camera that watches how you vote in a booth?
              
Please read our brochure (E or regular mail) before picking at a system you
don't have full info on.  Contact Phil for his ingenious cryptographic system,
or myself for the brochure (eravitz@nyx.cs.du.edu)
              
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Random Voting IDs and Bogus Votes (Vote by Phone)
</A>
</H3>
<address>
Mike Beede
&lt;<A HREF="mailto:beede@SCTC.COM ">
beede@SCTC.COM 
</A>&gt;
</address>
<i>
Fri, 1 Feb 91 12:24:07 CST
</i><PRE>

&gt;Each voter is given an id number to vote, but is told that the number is either
&gt;positive or negative.  Suppose there are two candidates, Alice and Bob.  If the
&gt;number is negative, a vote for Alice is actually counted as a vote for Bob.

Now suppose there are four candidates.  We give each voter a complex number X.
A vote for Alice is (1+i)X, while Bob is (1-i)X, Carol is (-1+i)X, and Ted is
(-1-i)X. For up to 16 candidates we issue each voter a quaterion, but this has
the drawback that only people with graduate degrees in mathematics are able to
vote.

I believe that phone voting is trying to solve a problem that is already solved
pretty well.  The goals are 1) make it convenient for the voter to vote, 2)
make it impossible, or nearly so, to determine anyone's vote, and 3) make it
very difficult to falsify results.  I argue that 1) is already met closely
enough that the virtual sacrifice of 2) and 3) in the vote-by-phone schemes are
not justified in the least.

Mike Beede, Secure Computing Technology Corp, 1210 W. County Rd E, Suite 100           
            Arden Hills, MN  55112                            (612) 482-7420

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Patriot (Leichter, <A HREF="/Risks/10.85.html">RISKS-10.85</A>)
</A>
</H3>
<address>
Steve Mitchell
&lt;<A HREF="mailto:steve@caticsuf.CSUFresno.EDU ">
steve@caticsuf.CSUFresno.EDU 
</A>&gt;
</address>
<i>
Fri, 1 Feb 91 09:31:15 PST
</i><PRE>

A thought on the RISKS of evaluating the Patriot system's performance:

The arguments I've heard in the digest and in the media lately seem to leave
out an important aspect of this discussion.  By pointing out numerous successes
in the Persian Gulf theater, proponents of this system, proponents of complex
weapons systems, and even advocates for SDI are now implying that ALL of their
Patriots, complex weapons systems, and SDI systems will function *as promised*.
The question here has never been whether the Patriot can shoot down rather easy
targets.  The question here (and the question in evaluating the
cost/performance ratio, practicality, and effectiveness of any weapons system),
is whether the Patriot system can function in the role for which it was
designed.

If the Iraqi's had effective ECM operating, radar busting aircraft deployed,
and were attempting coordinated attacks on these cities with maneuverable
aircraft, would the Patriot be as effective as it was designed to be?  The
results from the Persian Gulf theater are inconclusive at best.  The Patriot
system's design advantages and sophistication, the very aspects of the system
that make it so expensive, are still relatively untested in combat.  These are
the aspects of the system that have been used to rationalize it's development
and deployment costs.

If GM claimed that it's new Family Van Mk IV was amphibious, would you label it
a magnificent success just because you saw 30 of them cruise down the highway
at 50 MPH?  If all you need is a Family Van that can cruise down the highway at
50 MPH, why not save a few million and go for the Family Van Mk III that
doesn't claim the amphibious capabilities.

I do not feel that the Patriot's "amphibious" capabilities have been
demonstrated here.
                               Steve_Mitchell@csufresno.edu

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Patriots: Reprogramming, SDI implications (<A HREF="/Risks/10.82.html">RISKS-10.82</A>)
</A>
</H3>
<address>
Steven Philipson
&lt;<A HREF="mailto:stevenp@decwrl.dec.com ">
stevenp@decwrl.dec.com 
</A>&gt;
</address>
<i>
Thu, 31 Jan 91 16:09:04 -0800
</i><PRE>

Nathaniel Borenstein &lt;nsb@thumper.bellcore.com&gt; writes:
&gt;I'm awestruck that they're willing to reprogram the Patriot [...] right
&gt;in the middle of the war! [...]

   Wartime modification and upgrade of systems is a common and time honored
practice by military units.  Experience is gained on a daily basis and both
sides modify both their systems and tactics to make use of it.  If one can't
adapt, one is placed at a tremendous disadvantage.  It would likely be deemed
unacceptable if modifications could NOT be made in this timeframe.

&gt;[...] Patriots may never again be as useful as they are being in this war,
&gt;because "now that their capabilities are known, it will be trivial to
&gt;make the next generation of missiles able to fool them.

   There are large inventories of missiles with current and relatively outdated
technologies.  The SCUD itself is considered an archaic weapon.  The Patriot
will have a place in defense against these weapons.  Patriot upgrades, both
software and hardware, will likely increase effectiveness against more advanced
threats.  Certainly current assessments of their capabilities will be of
limited usefulness in estimating future performance.

karn@thumper.bellcore.com (Phil R. Karn) writes:

&gt;Even the Pentagon admits Patriots are of little use against SCUDs armed
&gt;with chemical warheads since they would merely disperse the chemical over
&gt;the target.  [...]

   If such dispersal were guaranteed, then the Patriot would be an effective
countermeasure.  Chemical weapons are effective only when chemicals can be
delivered with sufficient concentration.  Isolated high altitude airbursts of
the chemical containers will cause the material to disperse as it descends,
this lessening concentration and reducing effectiveness.

   One of the things we've seen with the Patriots is that some but not all
intercepts disable warhead arming.  Thus some intercepted SCUDS hit the ground
without detonating, but some explode anyway.  This has major implications for
an SDI terminal area defense against nuclear weapons for which a nuclear
near-miss may be as good as a direct hit.
						Steven Philipson

</PRE>
<HR><H3><A NAME="subj5.3">
Re: Patriot Missile 
</A>
</H3>
<address>
Michael H. Riddle
&lt;<A HREF="mailto:riddle@hoss.unl.edu ">
riddle@hoss.unl.edu 
</A>&gt;
</address>
<i>
Fri, 1 Feb 91 08:18:46 cst
</i><PRE>

Until about a year ago, my brother worked for Teledyne Brown Engineering in
Hunstville, on contract to the Army Ballistic Missile Division.  He claims
credit for a small part of the SDI technology that was retrofit to the Patriot,
although for obvious security reasons will not say more.  He has confirmed,
however, that SDI technology was used in some of the follow-on modifications to
both the Patriot missile itself (rocket motors) and the command/control radars
and software.

riddle@hoss.unl.edu  postmaster%inns@iugate.unomaha.edu 
University of Nebraska, College of Law, Lincoln, Nebraska, USA
 
</PRE>
<HR><H3><A NAME="subj5.4">
SDI -&gt; Patriot? and related topics
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Fri, 1 Feb 1991 07:17:20 PST
</i><PRE>
Summary: No Way

&gt; The [Patriot] system was contracted for 15 years ago by the Redstone
&gt; Arsenal.  It was initially to be an anti-aircraft missile, and it still
&gt; is, but about four years ago, unspecified software upgrades on the ground
&gt; equipment and hardware upgrades on the missile's detonation fuze were
&gt; made so that the system willa also be able to destroy tactical missiles,
&gt; such as the Russian Scud.

&gt; Various news organizations have alluded to or asserted outright that the
&gt; upgrades are technologies developed under the Strategic Defense
&gt; Initiative program.  "That is bull!  There is no 'Star Wars' hardware or
&gt; software in Patriot," [Redstone Arsenal public affairs officer David]
&gt; Harris said.  "There has been no 'Star Wars' funding of Patriot.  This is
&gt; all Army."  He said the SDI Organization is planning to provide $40
&gt; million for continuing development of the Patriot's advanced seeker
&gt; (nose-cone radar), but it has not been received by the Army yet.

This from "Portrait of a Patriot" by Brian Santo.  Unfortunately I have no idea
where this appeared; the clipping was posted in our coffee room this AM and I
have been unable to run down the source!  However, the technical content is
high and consistent, so I am inclined to believe that the foregoing is a true
reflection of the [US Army Missile Command's version of the] history of the
Patriot.

The article *does* assert that "[t]he missile itself has its own radar. .
.which kicks in as it nears its target," but the description of operation is
otherwise consistent with Henry Spencer's recent posting (RISKS DIGEST 10.85):

&gt; Even Patriot's homing is actually controlled by the ground computers; the
&gt; missile itself has no brains to speak of, just a receiver system that
&gt; picks up radar reflections off the target and relays them to the ground
&gt; for assessment

so possibly a passive radar was meant but not explicitly stated.  On the other
hand, if SDIO sees an application it seems more likely that the Track Via
Missile (TVM) radar is active, not passive.

Finally, in the same message Henry remarks

&gt; I've never understood why it is fundamentally impossible to put "man in
&gt; the loop" for space-based systems.  I'd be interested in seeing this
&gt; explained. There is clearly a serious shortage of time for
&gt; decision-making, but the same is true of terminal defence against
&gt; tactical missiles -- which have much shorter flight times than ICBMs --
&gt; and short-notice decision-making in combat is both possible and
&gt; practical, as any fighter pilot can testify.

I'd say alertness.  Crews, even highly-trained fighter pilots, need time to
come up to combat-readiness from standby.  Note that in the current case of
"terminal defence against tactical missiles" (Santo again)

&gt; [t]he detection and firing sequence is entirely automatic, and the only
&gt; intervention required of a human operator is to stop the Patriot from
&gt; firing.

This kind of tripwire arrangement looks unacceptable, at least for boost phase.
I suppose one could quibble over the the use of the word "fundamentally," but
*I* wouldn't want to have to design a robust system of this type.

Mark &lt;MJackson.Wbst147@Xerox.COM&gt;

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Patriots
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Fri,  1 Feb 91 10:16:27 PST
</i><PRE>

Henry writes:
&gt; The recent incident of an accidental launch against
&gt; aircraft is silly as a test case, since the Patriot system
&gt; reportedly was in antimissile mode and thus probably wasn't
&gt; expecting evasive action.

It would seem that this mistake exhibited a flaw in the antimissile software
design, though further details are needed for confirmation.  Namely, there was
no effective software check of observed radar track for ballistic trajectory.
A launch against returning planes should have been precluded by a simple
trajectory test.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Man-in-the-loop on SDI
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Fri, 1 Feb 91 12:59:22 EST
</i><PRE>
Cc: mjackson.wbst147@xerox.com, parnas@qucis.queensu.ca

&gt; ... one could quibble over the the use of the word "fundamentally," but
&gt; *I* wouldn't want to have to design a robust system of this type.

The question, of course, is whether one can design a better system
without humans involved, where "better" includes not just probability
of functioning well when desired but probability of functioning when
not desired.  If you compare fallible, inattentive humans against the
Pentagon's imaginary perfect computers, then of course you conclude
that the man-in-the-loop system is inferior.  Against real computers
running real software, I'm not so sure.

                                         Henry Spencer at U of Toronto Zoology
                                          henry@zoo.toronto.edu   utzoo!henry
</PRE>
<HR><H3><A NAME="subj7.2">
Re: Broadcast local area networks (Cooper, <A HREF="/Risks/10.84.html">RISKS-10.84</A>
</A>
</H3>
<address>
Curt Sampson
&lt;<A HREF="mailto:curt@cynic.wimsey.bc.ca ">
curt@cynic.wimsey.bc.ca 
</A>&gt;
</address>
<i>
Thu, 31 Jan 91 03:42:27 PST
</i><PRE>
Comments: Guru?  Or charlatan?

&gt; From: Brinton Cooper &lt;abc@BRL.MIL&gt;
&gt; Subject: Re: Broadcast local area networks are a'comin (Tom.Lane, <A HREF="/Risks/10.83.html">RISKS-10.83</A>

Brinton Cooper &lt;abc@BRL.MIL&gt; writes:

&gt; the risk for spectral chaos seems to be quite high.  Imagine the RFI
&gt; (radio frequency interference) implications of a central city full of
&gt; wireless ethernets(tm?) attempting to coexist with cellular phones, [etc.]

Interference will only be had by devices operating on the same frequencies.  If
the networking system is given its own band of frequences it won't interfere
with cellular phones any more than FM radio does.

There are other risks to this scheme, though.  Ethernet is based on a collision
detection scheme.  If two nodes send out a message at the same time they detect
the collision (because the data is scrambled) and then wait a random amount of
time before retrying the send.  It would be relatively simple to build a small
box which would output a short burst of RF every few milliseconds.  The more
often this box "squawked" the more collisions it would create on the network
and the slower the network would get.  Generate these pulses often enough and
you could bring the entire network to a halt.  The box would certainly be able
to operate for several days powered from a normal nine volt battery, and would
be small enough to hide easily.

Now what if several major financial firms relied on wireless networks in their
office and I decided that I wanted to create a little chaos and impede their
ability to respond on the morning of a large takeover bid?  Simply drop by for
a "visit" and toss one of these boxes in a nearby garbage can.

curt@cynic.wimsey.bc.ca   curt@cynic.uucp    {uunet|ubc-cs}!van-bc!cynic!curt

</PRE>
<HR><H3><A NAME="subj7.3">
Re: Broadcast local area networks are a'comin 
</A>
</H3>
<address>
&lt;<A HREF="mailto:Donald.Lindsay@GANDALF.CS.CMU.EDU">
Donald.Lindsay@GANDALF.CS.CMU.EDU
</A>&gt;
</address>
<i>
Thu, 31 Jan 1991 23:28-EST
</i><PRE>

I'm not familiar with Apple's proposal, but I am very pleased with Motorola's
WIN (Wireless In-building Network) proposal.

WIN is to use 10 MHz channels within the 18-19 GHz band, and this has some very
special propagation characteristics.  Each "microcell" network can ignore
another network's use of the same channel, 120 or 200 feet away - less if a
concrete floor or wall intervenes. (Unlike infrared, 18 GHz can pass through
drywall and partitions.)

The system uses "low power" (I don't have a number).  It also uses a fair bit
of multiplexing and packetizing, with source/destination pairs changing at 1
MHz. But best of all, 18 GHz reflects off walls, causing a considerable
multipath problem (ie multiple out-of-phase copies of the signal).  Some very
clever design was required to allow in-cell reception at all: things should be
pretty well incoherent, a very small distance away. WIN is probably as secure
as the office suite it's in.

Don		D.C.Lindsay .. temporarily at Carnegie Mellon Robotics

</PRE>
<HR><H3><A NAME="subj7.4">
Re: broadcast LANs (Letts, <A HREF="/Risks/10.85.html">RISKS-10.85</A>)
</A>
</H3>
<address>
John Stanley
&lt;<A HREF="mailto:stanley@phoenix.com ">
stanley@phoenix.com 
</A>&gt;
</address>
<i>
Fri, 01 Feb 91 15:58:51 EST
</i><PRE>

-&gt;Reading the notices about the approach of broadcast LAN's reminded me of a
-&gt;semihumorous incident that happened about 2 years while I was doing some
-&gt;consulting for a "local" oil company.  ...

-&gt;All of the remote telemetry units were communicating with the
-&gt;master station computer via low power Johnson radios, and I had made sure that
-&gt;we had dummy loads on all of the antennae so as to cut down the range of the
-&gt;transmissions.  This screwed up SWR's and about everything else, 

    Dummy loads are designed not to screw up the SWR's. They are a
perfect match, unless you are using the wrong dummy loads. Somehow, in
this case, that wouldn't surprise me. But I quote this section as
anecdotal evidence that the system was not licensed for data
communications work. 

-&gt;Sporadically, we would get bursts of errors for seemingly no reason, and then
-&gt;good comm again for a while.  ...

-&gt;Much to my surprise, I heard
-&gt;some poor fella in a delivery truck complain about "there's that doggone
-&gt;buzzing sound again" to his dispatcher at the same time that our comm
-&gt;efficiency dropped to zero!

   This is quite humorous. Ha. And quite lucky that you were not
using radios that just happened to be tuned to the hospital or other
emergency frequency. But you were probably saved by using radios that
were licensed for business band voice communications, so all you screwed
up were all the other users of that frequency.

-&gt;It was kinda fun listening to all of those guys swear at the strange 
-&gt;interference that they were getting.

   Yes, many sick people DO find it quite a hoot to cause deliberate
interference to licensed users of the spectrum (and the moment you
identified the source of the interference to YOU, you became deliberate
interference to the pizza service). I don't think the FCC feels like it
is a fun game. They tend to levy fines on people for doing it.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
re: Broadcast local area networks are a' comin
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Fri,  1 Feb 91 17:37:29 EDT
</i><PRE>

Two responses to points raised by some recent messages on this issue:

	1.  Ian Clements is concerned about possible effects on medical
		devices such as implanted heart monitoring devices.  All
		thing are possible, but there are already TONS of transmit-
		ters out there.  This is hardly a new or poorly understood
		problem.  However, note that a broadcast LAN, designed to work
		over a 150 foot radius, is likely to use much lower power than
		a cellular telephone, which must work over many miles.

	2.  Rich Rosenbaum comments that some of these technologies use
		spread-spectrum techniques, hence may be inherently secure.
		Well, yes and no - but mainly no.  There are several different
		spread-spectrum techniques, but let's take a simple one,
		frequency hoping.  In this technique, we select a broad
		channel - say 100Mhz wide.  We consider it to be subdivided
		into 100 1Mhz-wide slots.  Traditionally, we then parcel those
		slots out to 100 users.  In frequency hoping, we instead
		send signals on ALL the bands.  Each "channel" corresponds to
		a sequence of slots spread over the entire channel.  The
		sender hops through its sequence at a rapid rate - say, it
		switches every millisecond.  The receiver follows the same
		sequence of slots, synchronized with the sender.  A receiver
		that follows some other sequence has only a one in a hundred
		chance of intercepting the signal at any given time.  So a
		receiver listening on a a "channel" receives very little junk
		from any given unrelated channel.  It's possible to choose a
		large number (&gt;&gt; 100) of different "channels" (sequences) such
		that any subset of, say, 20 transmitting hardly interfere.
		This means that you can have many more than 100 users on the
		channel, who can almost always get through (unless too many
		want to do so at once).

		Now, if you don't know the particular sequence the sender is
		using, you have a hard time reading his message.  In fact,
		it's not even easy to tell that he's sending!  The acronyms in
		use to describe this stuff include LPD/LPI/LPE (Low Probabili-
		ty of Detection (enemy can't even tell you are there)/Inter-
		cept (enemy knows you are sending but can't extract any signi-
		ficant features of the message)/Exploitation (even if the
		enemy can "read" your signal, he can't tell what it means)).
		The flip side of this is AJ, Anti-Jam (i.e., jam-resistant).

		However, keeping the sequences secret complicates the system.
		It's much simpler to use fixed, pre-assigned, publically known
		sequences.  What's traded off is the protection the modulation
		technique COULD provide.  In the case of a broadcast LAN, LPD
		and LPI are of little importance; what you care about is LPE.
		If you were to use strong, secret sequences, you'd get those -
		but the hardware needed (which must generate a cryptographic-
		ally strong sequence of slot numbers) is comparable to the
		hardware you'd need to do encryption, and you'd still have to
		add all sorts of stuff to complete the system:  You can use
		the same key safely on a lot of different messages, but you
		can never safely re-use a hop sequence (so there's a whole
		synchronization problem to solve).

							-- Jerry

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.02.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-63</DOCNO>
<DOCOLDNO>IA013-000136-B032-63</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.02.html 128.240.150.127 19970217041614 text/html 17392
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:14:43 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/11.01.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 2</H1>
<H2> Tuesday 5 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Bogus draft notices are computer generated 
</A>
<DD>
<A HREF="#subj1.1">
Jonathan Rice
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
People working at home on important tasks 
</A>
<DD>
<A HREF="#subj2.1">
Mike Albaugh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Predicting system reliability 
</A>
<DD>
<A HREF="#subj3.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Patriots 
</A>
<DD>
<A HREF="#subj4.1">
Steven Markus Woodcock
</A><br>
<A HREF="#subj4.2">
 Mark Levison
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Hungry copiers (another run-in with technology) 
</A>
<DD>
<A HREF="#subj5.1">
Scott Wilson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Enterprising Vending Machines 
</A>
<DD>
<A HREF="#subj6.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Broadcast LANs 
</A>
<DD>
<A HREF="#subj7.1">
Peter da Silva
</A><br>
<A HREF="#subj7.2">
 Scott Hinckley
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Bogus draft notices are computer generated
</A>
</H3>
<address>
Jonathan Rice
&lt;<A HREF="mailto:rice@willow.cray.com ">
rice@willow.cray.com 
</A>&gt;
</address>
<i>
Tue, 5 Feb 91 9:21:58 CST
</i><PRE>

Last night's local news reported that "hundreds, perhaps thousands" of draft
notices have been posted around the Minneapolis campus of the University of
Minnesota.  The official looking notices are replete with convincing official
jargon, announcing that men in a certain age group are to report for immediate
duty.  Readers are directed to report to a room in the Hennepin County
Courthouse (the room is vacant) or to call one of two telephone numbers.  The
numbers are those of the Minneapolis Star &amp; Tribune news desk, and of a
blameless lady in St. Paul who seemed from the interview to have kept her sense
of humor despite the barrage of calls.  Interviews with young men on campus
indicated that many had not thought to doubt the authenticity of the notices.

What caught my ear was a statement that University officials would be "checking
their computer facilities" to see if the notices had been composed and printed
there.

The risk is one that has been pointed out before: laser printers enable several
types of fraud -- forged checks, phony invoices, letterheads for nonexistent
businesses -- that once would have been ruled out by the need to have a
professional print shop as an accomplice.  But this is a new twist.

Jonathan C. Rice, Cray Research, Inc., 655F Lone Oak Drive Eagan, MN 55121
UUCP: uunet!cray!rice 612-683-5370

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
People working at home on important tasks
</A>
</H3>
<address>
Mike Albaugh
&lt;<A HREF="mailto:albaugh@dms.UUCP ">
albaugh@dms.UUCP 
</A>&gt;
</address>
<i>
Mon Feb  4 15:22:33 1991
</i><PRE>
Original-Subject: Well, then, that's not so important!

An article on the accuracy of medical tests in the latest "Parade" (a
syndicated Sunday Supplement) had the following "interesting" statement.  Some
context: A women died of cervical cancer not detected due to screwups in
handling her pap smear. The lab tech who mishandled the test in question was
working at home. The woman's attorney is quoted:

	"Working at home might be fine for computer programmers, but
	it's reckless when your job involves making selective judgements
	that can affect someone's life."

We can all rest easier knowing that computer programmer's can have no negative
effect on people's lives.
  					    Mike Albaugh

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Predicting system reliability
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Mon, 4 Feb 91 17:14:45 BST
</i><PRE>

It is hard to define what evidence we need, in order that we can have
confidence that a system meets its designed level of reliability.

(I am using reliability, loosely, to mean that the system does what you
wanted it to do, when you wanted it, for the period that you wanted it).

It seems clear that the following argument is unsound:

System X has been shown to meet its requirements.
System Y is no more difficult than System X.
Therefore System Y meets its requirements.

Therefore, even if an SDI system had been shown to work before, it would not
be evidence that a new SDI would work. A fortiori, any degree of success of
the Patriot system provides no evidence that SDI would work.

I think the confusion arises because two different arguments get conflated:

Argument 1: A system as complex as SDI could never be designed so that it
worked correctly. (I do not support this argument - any [computable] system
*could* be designed so that it worked correctly [ even by chance]. I am more
interested in how we accumulate the evidence which allows us to form the
opinion that a *particular* system has achieved its design objectives. This is
argument 2, below).

Argument 2: A system as complex as SDI can never be evaluated in a way which
would give reasonable grounds for claiming that it would work correctly when
deployed. (I believe that this is true. SDI would be too complex for formal
proof of correctness - and the specification may be wrong. SDI would be
impossible to test under operational conditions. In general you need to test
for more than 10 times the period of fault-free operation you are looking for,
with no faults found, to achieve 99% confidence that you will meet the
requirement. SDI would probably only need to work correctly for a few days, so
a few weeks fault-free operation [under operational conditions - ie under
attack!] would demonstrate achievement. The time isn't the problem, but
creating the test conditions is surely impossible).

When we move the argument to some other safety-critical systems, the time
factor becomes dominant. A constant-control system, such as the A320
fly-by-wire, needs 10^-8 probability of failures per hour. This implies 10^9
hours of fault-free operation to justify a claim (to 99% confidence) that the
requirement has been met. This is clearly absurd, so how do we judge whether or
not the requirement has been met?

On-demand critical systems, such as spacecraft course-correction or reactor
shutdown systems, may only need to operate correctly for a few minutes or hours
during their whole design lifetime. This is clearly testable (if we can be sure
that the operational conditions can be reproduced accurately enough - which
becomes the problem).

I would welcome further discussion of these basic questions: how should we form
an opinion about the probable future reliability of a system; what
justification is needed for that opinion, if it is to stand up to critical
appraisal by other engineers; what is the practical limit (in terms of
failures/hour) which we can realistically expect to be able to justify, and how
is this limit affected by the complexity of the system?

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Patriots (<A HREF="/Risks/10.83.html">RISKS-10.83</A>)
</A>
</H3>
<address>
Steven Markus Woodcock
&lt;<A HREF="mailto:swoodcoc@isis.cs.du.edu ">
swoodcoc@isis.cs.du.edu 
</A>&gt;
</address>
<i>
Mon, 4 Feb 91 23:30:55 MST
</i><PRE>

Regarding the use of Patriots:
 
   I work for Martin Marietta, and know several people who helped design
and build the Patriot.  I also work at the National Test Bed, so I'm 
quite familiar with SDI's role in the Patriot's development.

   The Patriots fired at the aircraft in Turkey missed precisely because
they were loaded with terminal defense missile software--a much simpler
interception problem than hitting an aircraft that's actively avoiding you.
If they had been loaded with their anti-aircraft software, it would
probably have been a different story (although isn't there a ground destruct
override on those things?).

</PRE>
<HR><H3><A NAME="subj4.2">
Patriots, ballistic missiles and aircraft
</A>
</H3>
<address>
Mark Levison
&lt;<A HREF="mailto:levisonm@qucis.queensu.ca ">
levisonm@qucis.queensu.ca 
</A>&gt;
</address>
<i>
Tue, 5 Feb 91 12:29:24 EST
</i><PRE>

   On the subject of the Patriot missile system: while the SCUDs they are
firing against are archiac, the basic problems do not change.  The only short
to medium range ballastic missile that change the problem significantly was the
Pershing II. This system had a terminal guidance phase, allowing course changes
during or after a counter missile launch.  Improvements in ballastic missile
technology since the SCUD are in the areas of speed (not significant),
accuaracy, range and payload.

   Against aircraft the problem changes significantly, while aircraft are
capable of evasive action they are also much slower moving targets typically
Mach 0.6 (for an A6 or A10 on an attack run) to Mach 2+ (fast moving ie Mirage
F1, 2000 etc) vs Mach 3 - 7 for a ballastic missile.  So ignoring ECM, chaff
and similiar capabalities aircraft should not significantly more difficult than
ballastic missiles. Of course we have not seen and hopefully will never need to
see examples of the Patriot system shooting down an aircraft in a real combat
situation.

   As should be obvious here I am only trying to demonstrate that Patriot
missile is probably capable of doing the job that its designers claim it can
do.  I am ignoring all issues of ECM and radars because of my scant knowledge
in this area.  I am also ignoring whether you actually want to shoot down
missiles that might be chemical/biological armed.

Mark Levison                                      levisonm@qucis.queensu.ca

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Hungry copiers (another run-in with technology)
</A>
</H3>
<address>
Scott Wilson [CHTM]
&lt;<A HREF="mailto:swilson@pprg.unm.edu ">
swilson@pprg.unm.edu 
</A>&gt;
</address>
<i>
5 Feb 91 04:33:35 GMT
</i><PRE>

I too have encountered some poorly thought out additions to old technology. Get
this:

Went down to the library to copy a paper. Didn't have enough change, but saw a
bill changer on the machine. (What will they think of next?)  Put in a $5 bill.
Put the paper in place, hit &lt;COPY&gt;. Machine grumbles, proceeds to hang, saying
"Check Paper". I begins to smell a rat.

I track down the student assistants at the front desk - thay cannot fix the
machine. They are the only attendants on duty (Murphy applies here).  I press
"Change return" and it says "Must make at least one copy".

The add-on bill changer was programmed to avoid use as a source of change by
requiring at least one copy. If the machine jams on the first copy, your bill
stays in until you can find a way to get it unjammed. If that cannot be
accomplished, then your imaginary copy costs you the bill!

I figured that if I wasn't going to get the bill back by arranging to have the
machine fixed, then I was at liberty to try other means.  Found the power cord,
unplugged said machine. Plugged back in.  Bill changer complained about "out of
order". Unplugged again.  Plugged back in. Changer starts thumping, spews out
my $5 bill.  I guess it was trying to clear itself.

Too many more "consumer improvements" and I'll scream!

Scott Wilson

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Enterprising Vending Machines
</A>
</H3>
<address>
&lt;<A HREF="mailto:davy@erg.sri.com">
davy@erg.sri.com
</A>&gt;
</address>
<i>
Tue, 05 Feb 91 08:23:29 -0800
</i><PRE>

Most post office vending machines I've used tell you to press the button
before putting your money in, and it will tell you whether it's sold out
or not.  These are the USPS machines with the "light bar" for messages
across the top and about four tiers of stamps.

So perhaps your surmise about this being an old retrofitted machine is correct.

--Dave
           [Dave and I share a vending machine in the Menlo Park CA Post Office
           that tells you to press the button before putting money.  But
           first-time apparently get burned quite frequently.  Here is another
           example of ordinary mortals having to gain sophistication in the
           vagaries of automated systems in order to maintain their cool.
           (My use of "their" was intentionally ambiguous.)  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Broadcast LANs
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:peter@taronga.hackercorp.com ">
peter@taronga.hackercorp.com 
</A>&gt;
</address>
<i>
Tue, 5 Feb 1991 04:56:03 GMT
</i><PRE>

A lesser problem that reduces the quality of the working environment is likely
to be plain old EMI. Already it's impossible to tune AM radio stations in
modern office buildings, and low-power FM ones (like the local PBS station) are
kind of marginal. I'd hate to think of what a wireless LAN would do to my
Classical or Jazz fix, let alone All Things Considered.

</PRE>
<HR><H3><A NAME="subj7.2">
Re: Broadcast local area networks are a'comin (Tom Lane, <A HREF="/Risks/10.83.html">RISKS-10.83</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:scott@huntsai.boeing.com">
scott@huntsai.boeing.com
</A>&gt;
</address>
<i>
Tue, 5 Feb 1991 09:58:37 -0600
</i><PRE>

&gt;&gt;If I ran a corporate network, I wouldn't touch this with a 10-foot pole.

How much of your data on the average network is really a security issue?
I work here at Boeing and, at least in my area, sensitive data is not
kept on the network (and it is over 150' to the nearest area off campus
anyway, not to mention a couple of concrete/steel walls)

Even in a small company I bet most data could be sent with little to no
encryption without any danger of sensitive material being lost.

In summary this WOULD be a good system for many (most?) networks where
cost/difficulty of cableing would be a major deterent, but (due to
limited channels and security risks) it would not be for everyone.

The existence of security risks does not negate the possible benefits of
technology per say, but rather is a side effect that must be
acknowleged and responsibly handled.

Scott Hinckley, Boeing AIC, 110 Pine Ridge Road #608 Huntsville Al35801
(205)461-2073             UUCP:..!uunet!uw-beaver!bcsaic!huntsai!scott

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-64</DOCNO>
<DOCOLDNO>IA013-000136-B032-97</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.03.html 128.240.150.127 19970217041641 text/html 34405
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:14:56 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 3</TITLE>
<LINK REL="Prev" HREF="/Risks/11.02.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.04.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 3</H1>
<H2> Wednesday 6 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Tube Tragedy 
</A>
<DD>
<A HREF="#subj1.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
New Zealand Computer Error Holds Up Funds 
</A>
<DD>
<A HREF="#subj2.1">
Gligor Tashkovich
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
"Inquiry into cash machine fraud" 
</A>
<DD>
<A HREF="#subj3.1">
Stella Page
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Quick n' easy access to Fidelity account info 
</A>
<DD>
<A HREF="#subj4.1">
Carol Springs
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Enterprising Vending Machines 
</A>
<DD>
<A HREF="#subj5.1">
Mark Jackson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Risks of no escape paths 
</A>
<DD>
<A HREF="#subj6.1">
Geoff Kuenning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
A risky gas pump 
</A>
<DD>
<A HREF="#subj7.1">
Bob Grumbine
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Electronic traffic signs endanger motorists... 
</A>
<DD>
<A HREF="#subj8.1">
Rich Snider
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Re: Predicting system reliability 
</A>
<DD>
<A HREF="#subj9.1">
Richard P. Taylor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
The new California licenses 
</A>
<DD>
<A HREF="#subj10.1">
Chris Hibbert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
Phone Voting -- Really a Problem? 
</A>
<DD>
<A HREF="#subj11.1">
Michael Barnett
</A><br>
<A HREF="#subj11.2">
 Dave Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
Re: Electronic cash completely replacing cash 
</A>
<DD>
<A HREF="#subj12.1">
Barry Wright
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Tube Tragedy
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Tue, 5 Feb 91 21:43:18 PST
</i><PRE>

The Sun, Tuesday, February 5th, 1991, p. 6:

A tube passenger was dragged to his death after getting his arm trapped in a
train's automatic doors.

Four pals inside the carriage watched as the victim was pulled along the
platform and smashed against the tunnel wall at London's Kings Cross. He was 
then sucked under the moving train. But the friends have not come forward,
and the man - believed to be Italian - has not been identified.

                            *********************

I was puzzled that this was not reported in the Guardian, or on the evening
TV news, so I rang London Underground's PR department for confirmation. 

It happened on Sunday night, on the Northern Line. Apparently the man, being
separated from his friends as the doors closed, had opened them by operating
the butterfly clasp on top of the carriage. (Presumably this is intended for
staff use only, to open doors in exceptional circumstances.) The doors then
closed faster than he expected, so trapping him before he could get on. (The
fact that the butterfly clasp had been operated, presumably meant that no
warning signal was sent.) According to the PR department, neither the guard
(still employed on older parts of the underground) nor the driver were to
blame. LU PR are surprised, however, that the man was able to reach and operate
the clasp.

It looks like a case of "No system is foolproof. It all depends on the size
of the fool!", but there may be some design implications here. Surely, for
instance, a warning should be given if a door is open for *any* reason?

In the meantime, London Underground is making 1000 staff redundant to cut
costs. According to one union leader, this will lead to unmanned stations at
night, and take the underground closer to being a "passenger-hostile system".

Peter Mellor, Centre for Software Reliability, City University, Northampton
Sq.,London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1 p.mellor@uk.ac.city (JANET)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 New Zealand Computer Error Holds Up Funds
</A>
</H3>
<address>

&lt;<A HREF="mailto:TASHKOVI@CRNLGSM.BITNET">
TASHKOVI@CRNLGSM.BITNET
</A>&gt;
</address>
<i>
Wed, 6 Feb 91 11:40 EST
</i><PRE>

&gt;From the New Zealand Herald, January 15th, 1991, p. 4.

NZPA -- Wellington A computer processing error at Databank has thrown many
savings account balances out of kilter.  Misalignment of account number
suffixes prevented Databank's computers from identifying some recipient
accounts.  The computer posted payments to a safe holding file until the
problem could be resolved, Databank said yesterday.  Although current accounts
(those with 00 suffixes) were not affected, accounts with other suffixes (such
as 02, 03) may not have received payments made on Friday.  This problem would
show up on automatic teller machine and Eftpos inquiries into savings and
special accounts.  All bank in New Zealand were affected but the problem was
expected to be resolved by start of business today, Databank said.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Inquiry into cash machine fraud"
</A>
</H3>
<address>
Stella Page 
&lt;<A HREF="mailto:sp@cs.city.ac.uk">
sp@cs.city.ac.uk
</A>&gt;
</address>
<i>
Mon, 4 Feb 91 11:33:31 GMT
</i><PRE>

Extracts from Finance and Economics article, The Guardian, 1 February 1991:

  A bank engineer is being interviewed by police investigating unauthorised
withdrawals from cash machines.  It is alleged that money was withdrawn from
customers' accounts through information gained during the servicing of machines
operated by Clydesdale Bank.
  ... Since the first cash machines appeared ... all banks have denied that
"phantom withdrawals" are possible, despite the fact that public complaints
alleging such withdrawals make up the biggest single item in the banking
Ombudsman's caseload.  In only one of many hundreds of complaints has the
Ombudsman found in the customer's favour ...  Last year, 482 complaints about
cash machine withdrawals were lodged ... None were resolved in the customer's
favour.  The only time the Ombudsman did find for the customer, in 1988, it was
on a legal technicality.  The first Ombudsman ... said his office accepted the
banking industry line that withdrawals could only be made by a person using a
card and a number.
  The banks have never accepted that cash-machine withdrawals could be made as
a result of computer error or internal security breaches.  Clydesdale said:
"Unauthorised transactions were revealed as a result of our investigative
procedures and the police advised. Only a very small number of accounts has
been affected and the bank has written to them."

Stella Page, Centre for Software Reliability, The City University, 
Northampton Square, London EC1V OHB, United Kingdom.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Quick n' easy access to Fidelity account info
</A>
</H3>
<address>
Carol Springs 
&lt;<A HREF="mailto:carols@drilex.dri.mgh.com">
carols@drilex.dri.mgh.com
</A>&gt;
</address>
<i>
Tue, 5 Feb 91 13:37:38 EDT
</i><PRE>

Robert Powell reports in the Boston Herald, February 5, 1991, that from January
8 to February 4 callers were able to access info on any Fidelity Investments
shareholder's account for which blocking had not been specifically requested --
solely via the investor's SSN.  The access is still available for most Fidelity
accounts.  From the article:

      The program, introduced Jan. 8 and called Fidelity 
      Telepeople Collection, lets folks dial an 800 telephone 
      number.  After being prompted by a computer, callers
      key in their or any customer's Social Security number
      to learn holdings of stocks, options, and mutual funds.

      People who knew the Social Security numbers of 
      Fidelity's bigwigs like Chairman Edward C. Johnson or
      Peter Lynch could easily learn whether Johnson put his
      money where his firm is, or just how many shares of the
      Magellan Fund Lynch owned.

      The Social Security numbers of most executive officers
      of investment advisory firms is on file with the
      Securities and Exchange Commission.  Fidelity, in
      reaction to a story in yesterday's Wall Street Journal,
      blocked the public's access to Fidelity executives'
      accounts.

The article goes on to add that individual shareholders can request that
telephone access to their accounts be blocked, according to Tracey
Gordon at Fidelity.  Marketing manager Judith McMichael adds that

      ...Fidelity changed the access code to the telephone
      service from a customer's account number to his or her
      Social Security number because of overwhelming customer
      support during the company's research.  And Fidelity
      has only received three complaints to date, she said.

Eric Kobren, the president of Mutual Fund Investors Association, is requesting
that his subscribers call Fidelity to ask them to require a PIN tag for the
service.
 
Carol Springs                      carols@drilex.dri.mgh.com

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:mjackson.wbst147@xerox.com">
mjackson.wbst147@xerox.com
</A>&gt;
</address>
<i>
Tue, 5 Feb 1991 12:55:01 PST
</i><PRE>
Subject: Re: Enterprising Vending Machines (Allan Meers, Risks 11.01)

In Risks 11.02, PGN writes:

&gt; Here is another example of ordinary mortals having to gain sophistication
&gt; in the vagaries of automated systems in order to maintain their cool.

Who are you calling a mere mortal?-)  Despite having read Allan Meers' posting
(Risks 11.01) *I* got burned this morning, and not by an older machine, either.

Around 11 AM I entered the lobby of the (brand-new) post office in Webster NY.
Approximately 35 people were waiting in line, so I turned to the (brand-new)
stamp vending machine.  Several of the selections were flashing "SOLD OUT" but
(great!) rolls of "F" stamps were still available for $29.00.

There was a puzzled couple ahead of me; they'd fed a dollar into the machine
thinking they could buy *one* F stamp, and were now trying to figure out what
to do (no purchase, no change; cheapest non-sold-out option was 10 23 cent
stamps for $2.30).  I offered to feed the machine a $10 and a $20 bill, buy the
$29.00 roll, and split the $2 change.  (There was a big sign posted next to the
machine warning about no change without purchase, noting that change up to $5
would be given in coins.)  No problem. . .until I got my stamps.  Displayed
credit dropped from $31.00 to $2.00.  Pressed the CHANGE button. . .display
changed to flashing "OUT OF COINS - NO CHANGE AVAILABLE"!

Gotcha!  There was *no* warning of this state until change was requested.
Getting a refund required pushing to the front of the line, flagging down a
clerk, then filling out a long postal refund form IN DUPLICATE. . .and, for all
I know, waiting for a government check to arrive from Washington.  We decided
to feed the machine some more change and take our change in 23 cent stamps, so
the other guy put in 35 cents (no nickel). . .and THEN we noticed that the
machine had quietly eaten the $2 credit.  At this point we gave up; final score
me -$1, them -$1.35, USPS +$2.35.

It seems the programmers did anticipate this problem (credit stuck in the
machine with no means of recovery).  From the Postal System's point of view,
this is a problem because IT DISABLES THE MACHINE.  So, apparently, the
solution is to clear unused credit after 60 seconds of inactivity, thereby
"resetting the trap."

Mark &lt;MJackson.Wbst147@Xerox.COM&gt;

  "This U.S. stamp, along with 25 [cents] of additional U.S. postage,
  is equivalent to the 'F' stamp rate"

		- Official Algorithm of the US Postal Service

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
	Risks of no escape paths
</A>
</H3>
<address>
Geoff Kuenning 
&lt;<A HREF="mailto:geoff@prodnet.la.locus.com">
geoff@prodnet.la.locus.com
</A>&gt;
</address>
<i>
Fri, 1 Feb 91 16:01:42 -0800
</i><PRE>

I just got a phone message from one of my credit card companies, asking for a
return call.  However, when I called their 800 number, I got a computerized
answering system.  The second prompt was "please enter your 16-digit account
number now."  Happens I have two cards from that company; which had they called
about?  Hang up, try again -- this time I figure I'll pretend to have a dial
telephone and talk to a human.  Wrong.  The hardware is actually smart enough
to detect dialing on a dial phone, and my fancy PBX won't let me masquerade by
flashing the hook.  Okay, I'll wait for a timeout.  Wrong.  After the timeout
it insists on a number.  Okay, how about an obviously incorrect number?  After
16 5's, it pauses and then complains that the account number is incorrect,
returning me to the original prompt.

In frustration, I begin composing this message.  While typing, I notice that
there is a "flash" button on my PBX phone.  Maybe that'll let me pretend to be
a dial phone.  Nope.  But my PBX is screwy enough that this attempt put the
line on hold without my noticing.  60 seconds later I notice the flashing light
and pick up, just in time to get a voice saying "Hello?"  I say "hello," and
the person at the other end asks for my account number.  But now I've got a
human, and when I tell him my problem, he is smart enough to handle me without
insisting on the account number.  Surprise!  I have more than two cards with
that company, because they just bought out another of my cards!  So now which
card do they care about?

The only good thing (other than a chuckle) about this whole thing is that
the phone answering system is still on trial, so if I can remember to call
on Monday, I can talk to a responsible person and perhaps (especially by
mentioning RISKS) affect their go/no go decision.

If I didn't love them so much, I'd hate computers...

	Geoff Kuenning	geoff@la.locus.com	geoff@ITcorp.com

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
A risky gas pump
</A>
</H3>
<address>

&lt;<A HREF="mailto:RMG3@PSUVM.PSU.EDU">
RMG3@PSUVM.PSU.EDU
</A>&gt;
</address>
<i>
Saturday, 2 Feb 1991 14:14:32 EST
</i><PRE>

  I guess risks readers haven't stopped for gas on the Ohio turnpike lately.

  A new service is being offered on the Ohio turnpike by Sohio (a division
of BP Oil).  I'll quote their flyer:

  " New from SOHIO and the Ohio Turnpike ... [Their ellipses]
    Now, RAPID PUMP lets you charge your gas quickly
    and conveniently right at the pump.  If you need
    a receipt, RAPID PUMP will give you one.  No
    need to walk to the cashier.  Just charge your
    gas at RAPID PUMP, and drive away.             "

On another flyer the operation is explained:

  "  1 Just insert and remove your card ...
     RAPID PUMP automatically checks for authorization.
     If you would like to cancel at any time before
     pumping fuel, use the CANCEL button.  You may
     also press the HELP button at any time for
     assistance

     2 Need a Receipt?
     Watch the display screen and select either the
     YES or the NO button

     3 Then select your fuel ...
     [text irrelevant to risks]

     4 Stop when you want ...
     When you reach the dollars and gallons you
     want, slide the lever down, replace the nozzle
     and your gas cap.  If you did not request a
     receipt, your transaction is complete and
     you may drive away.

     5 If you requested a receipt ...
     RAPID PUMP automatically prints your receipt
     for you.  Take it and drive away!             "

Having read risks for a while (or rather, having read the archive recently),
I did not try this 'convenience' out.  Just in the time I was pumping gas
I came up with several _risky_ questions about the process:
  What verification is there that the card that is authorized is really mine?
  What happens if the receipt disagrees with the amount pumped?
  How about if my number is not cleared from the pump's memory and I get
    billed for the entire day's gas from that pump?
  How do I get that receipt if the machine is out of paper?  Will is _always_
    know that it can't print _before_  I pump the gas?

  There are quite a few that risks readers could come up with.  This situation
does start to merge in to the 'Americard' type of risks as well.  Perhaps
this gas pump is a harbinger of the 'Americard'.  I hope not.
                                                                Bob Grumbine

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Electronic traffic signs endanger motorists...
</A>
</H3>
<address>
nexus.yorku.ca?
&lt;<A HREF="mailto:rsnider@xrtll                                          ">
rsnider@xrtll                                          
</A>&gt;
</address>
<i>
Tue, 5 Feb 91 16:19:31 EST
</i><PRE>

Recently in Toronto the Ministry of Transportation has introduced a system to
regulate/inform motorists while driving on a large section of highway that
crosses almost centrally through the city (also known as the 401).  This
highway has approx 16-20 lanes of traffic which has the daily weekday tendancy
to come to a full and complete stop during morning and afternoon rush hours.

The system they have given us consists of electronic signs much like typical
Stadium Scoreboards on which they will display messages about traffic
conditions ahead, behind, or wherever that they collect from a set of TV
cameras and wire loop sensors that are installed along the highway.

On a smaller highway that runs through the city they installed a single smaller
version of the big signs now installed, and for the last year or so they have
been conducting tests with it (I assume).

Now usually this smaller sign has contained a simple message saying what the
next exit is, but a few times it has displayed messages about weekend highway
closures.  This has resulted in the best chaos I have seen next to the typical
rush hour stuff.

There is a serious danger here of people crashing into others who are either
reading the message, or trying to avoid someone else who is.  This is ONE sign.
I figure there are about 30 of the big ones now going to be used.  I can only
imagine what we are going to see happen when they start displaying things like
"LEFT LANE BLOCKED, USE COLLECTORS AHEAD" and 700 motorists first slow down to
read this and then try and pull over to the two rightmost lanes in order to
exit off that section of the highway.  I suppose they could use some of the
other signs available to tell of the impending disaster in the collector lanes.

ISOTECH Computer Industries, Toronto, Canada ....Rich (rsnider@xrtll) Ls not 1s
                                         ....uunet!itcyyz!xrtll!rsnider

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Re: Predicting system reliability
</A>
</H3>
<address>
Richard.P.Taylor@nve.crl.aecl.ca     
&lt;<A HREF="mailto:taylorrp@nve.crl.aecl.ca">
taylorrp@nve.crl.aecl.ca
</A>&gt;
</address>
<i>
Wed, 6 Feb 91 11:37:45 EST
</i><PRE>

I would like to expand on the issues raised by Martyn Thomas concerning
reliability requirements, expectations and predictions.

Mr. Thomas points out that it is unsound to predict the reliability of one
system from knowledge of the reliability of another, "similar" system.  In my
opinion, this is the major problem with using reliability growth models to
predict the reliability of a system.  Whenever changes are made to fix errors
discovered by testing, the result is a new system.  The new system will
certainly be similar to the old system, but because the changes may have
introduced or uncovered new faults, we cannot predict that the reliability of
the new system will have any fixed relationship to the reliability of the old
system.

It seems clear to many investigators of software reliability that the only way
to gain confidence that a given level of reliability has been achieved is to
have a period of failure-free operation longer than the required period.
Therefore we must change some of our reliability requirements and definitions
in order to make reliability testing practical.  I believe that someone has
already pointed out in a previous RISKS debate concerning the A320, that there
are great differences in the control requirements and safety requirements
between takeoff, level flight, and landing.  It is much more feasible to test a
system over a large number of simulated takeoffs and landings than it is to
test for an extremely long operating time.  Similarly, as Mr. Thomas points
out, for on demand systems.

My own concern is with nuclear reactor shutdown systems.  While these systems
are "on-demand" (they are only required to "act" to shut down the reactor when
some kind of process anomaly is detected), they are in continuous operation in
a monitoring role.  In order to make reliability testing feasible, it is
necessary to design the system in such a way that each individual test need
not include the months of steady-state operation which generally precedes a
shutdown demand.  We must also be careful to define our reliability
requirements to separate the shutdown function and from the less critical
monitoring and reporting functions.

The Canadian Atomic Energy Control Board is currently working on ways to
define, test and review software safety system reliability.  I would also
welcome further discussion of these issues in RISKS.

Richard P. Taylor, Atomic Energy Control Board (AECB), P.O. Box 1046, 
Station B, 270 Albert St., Ottawa, Canada, K1P 5S9  (613) 995-3782

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
the new California licenses
</A>
</H3>
<address>
Chris Hibbert
&lt;<A HREF="mailto:hibbert@xanadu.UUCP ">
hibbert@xanadu.UUCP 
</A>&gt;
</address>
<i>
Tue, 5 Feb 91 11:02:13 PST
</i><PRE>

California did indeed introduce a new format of Driver's License.  I've been
following the issue for a while as part of CPSR's Palo Alto working group on
Computers and Civil Liberties.  Here are some of the details:

There will be a magnetic stripe on the back with three tracks encoded on it.
The middle track will be encoded in the same format as your credit cards, and
will therefore be readable with ordinary commercial readers.  This track will
only contain 40 bytes of information, and will only contain the name, driver's
license number, and expiration date.  The other two tracks will be in a format
that is incompatible with current commercial readers, and will contain the rest
of the information that is printed on the front: birth date, eye color, hair
color, height, weight etc.

The picture on the front will be an ordinary photo (I'm not sure whether it'll
be color or B&amp;W), with a hologram of the state and DMV seals to make
counterfeiting harder.  There will apparently be a different version for people
under the legal drinking age: the picture will be on the right instead of the
left.  (This tidbit from the Mercury News.  I hadn't noticed it before.)

The DMV says that the first and third stripes will be encoded at a higher
density and "corrosivity."  Apparently corrosivity is resistance to changing
the pattern of magnetization. (I welcome corrections or expansions on this
point.)  I'm not sure whether "Orsteds" are measures of density or corrosivity,
but they say that the standard specifies 30 Orsteds, and that's what the middle
stripe will use, while the other two stripes will be encoded at 3600 Orsteds.
The difference in density is for incompatibility with current commercial
readers, though I'm not convinced that new readers won't be made available soon
to the California business community.  The difference in magnetization is
intended to make the cards harder to erase or rewrite.  I don't know whether
it'll do any good, or whether there will be penalties for carrying an erased
card around.  I fully intend to see if I can erase my card first thing when I
get one.

The primary purpose of the new cards, according to the DMV, is to make it
easier for police officers to fill out tickets correctly and quickly.  There
will be readers for the new cards in all state police cars, though I don't know
what the schedule for installation is.  They'll probably wait until a
significant proportion of the citizenry have the new licenses.  A secondary
purpose is to save money and time when issuing renewal licenses.  The DMV
(actually, the contractor who won the bid) will keep digitized records of the
picture and other data on the card, and when renewal time comes around, they'll
be able to just pop a brand-new card in the mail.  This will get rid of the
certificates of renewal and address update cards that Californians now carry
around with their licenses until they get a new card.

Another purpose (as evidenced by the fact that the stripes are partially
compatible with commercial readers) is making the information more easily
available to merchants.  Since the information is accessible, merchants will
find a way to use it.  The most likely way is to keep track of customers and
their habits.  More efficient access to the bad-check data bases is a laudable
goal, but it's cost will be that more information will be stored about
everybody who's willing to let their licenses be scanned in the name of
efficency.  I've tried to explain this point to members of the state
legislature, but without success.  The fact that I didn't find out about the
plan until after the DMV had gotten some approval and had requested and started
processing bids didn't help my case.

In a response to a letter of mine, Assemblywoman Delaine Eastin (Chairwoman of
the committee on Governmental Efficiency and Consumer Protection; now there's a
pair of incompatible goals for one committee to work on!)  wrote: "I share your
concern that the stripes, if used improperly or if expanded beyond the current
plan, could constitute an invasion of privacy.  A society where people carry
around magnetically coded `ID' cards for use by police and store-keepers would
not be one most of us want to live in.  Nevertheless, the DMV plan, limited in
its scope, seems like a relatively benign way to save time and money for
everyone."

The new licenses constitute exactly the "magnetically coded `ID' cards for use
by police and store-keepers" that she said we wouldn't find acceptable.
Merchants will start asking customers for their licenses, and most customers
will comply unthinkingly.  Those who see the deeper privacy issues and don't
want their identity recorded along with their buying habits in yet another
computer system will have to contend with clerks who just do what the boss
tells them to.  They won't be allowed to ignore those behind them in line who
can only tell that someone is interrupting the routine and making them wait
longer.  I'm afraid that we've lost a little more of our privacy, and it's
going to be very hard to get it back.
                                                    Chris

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Phone Voting -- Really a Problem?
</A>
</H3>
<address>
Michael Barnett
&lt;<A HREF="mailto:mbarnett@cs.utexas.edu ">
mbarnett@cs.utexas.edu 
</A>&gt;
</address>
<i>
Tue, 5 Feb 91 13:03:29 CST
</i><PRE>

I must agree with Mike Beede in <A HREF="/Risks/11.01.html">RISKS-11.01</A> that phone voting is basically a
solution in search of a problem. I understand that we are all in technological
fields, but surely there must be times that we can see the answer to a problem
does not lie in technology. What is the problem that phone voting is trying to
solve? It appears to me that the main problem with elections in this country is
the low turnout. I find it hard to believe that it is the difficulty of
physically going to vote that accounts for that.  Why not try the solution many
countries have -- either make election day a holiday, or conduct it on Sundays
when most of the population is not working? (Of course, I'm tempted to say that
having a real choice on the ballot may be the best cure.)
                                                            Michael Barnett

</PRE>
<HR><H3><A NAME="subj11.2">
Re: Voting by Phone (Ravitz, <A HREF="/Risks/11.01.html">RISKS-11.01</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:daemon@celit.UUCP">
daemon@celit.UUCP
</A>&gt;
</address>
<i>
6 Feb 91 08:40:10 GMT
</i><PRE>
Reply-To: dave@com.UUCP (Dave Smith)

eravitz@isis.cs.du.edu (Evan Ravitz) writes:
&gt; (in regards to voting via phone)
&gt;Paranoia is justified, but apply it to how we vote now, as well.  Don't you
&gt;think that a government that can photograph your license plate from outer space
&gt;can install a tiny video camera that watches how you vote in a booth?

Sure the government could install a video camera in every voting booth.  Could
they keep it secret?  I don't think so.  However, accessing a database and
cracking a cryptographic code is something that could be done by a small group
of people working in secret.  That's the risk inherent.  I doubt that the
government proper will ever conduct a project like spying on the voters but a
small group, ala Ollie North and Friends, could very easily do it given a
relatively small amount of resources.

David L. Smith, FPS Computing, San Diego   ucsd!celit!dave or dave@fps.com

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Re: Electronic cash completely replacing cash
</A>
</H3>
<address>
Barry Wright
&lt;<A HREF="mailto:ronin@ronin.sbi.com ">
ronin@ronin.sbi.com 
</A>&gt;
</address>
<i>
Tue, 5 Feb 91 13:16:53 EST
</i><PRE>

&gt;       Think about it.  Drug deals, muggings, corruption, businesses
&gt; concealing their income - they all require cash and secrecy.  A monetary
&gt; system bases solely on electronic currency would leave a trail that would
&gt; cripple such enterprises.

Fat chance.  When was the last time you "hacked" a supposedly secure system,
just to prove you could?  I remember when BART (Bay Area Rapid Transit) was
just starting, with its supposedly secure, tamper-proof, "electronic tokens"
(cards that registered the amount in the commuter's "account" and allowed
a ticket purchase if there was enough remaining -- somewhat similar to the
electronic cash scenario).

A Berkeley councilman, suspecting the BART cards weren't quite as secure as
claimed, offered a cash reward (only $100, as I remember) to 50 UC Berkeley
students, if they could find a way to steal from the proposed system.  He got
fifty different successful hacks.  
      ^^^^^^^^^ 
Electronic cash would only breed electronic thieves.  A better breed, perhaps,
but thieves nonetheless...  :^)

B. Wright                                                 ronin@ronin.sbi.com

    [By the way, there is still an enormous collection of pending messages
    on mastercards and on americards.  If I have the patience to prune it
    a little, you'll get to see it.  Otherwise, it may just drop through
    the crack.  It required much more moderation on the part of your 
    moderator than usual...   PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-65</DOCNO>
<DOCOLDNO>IA013-000136-B032-132</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.04.html 128.240.150.127 19970217041708 text/html 34477
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:15:32 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 4</TITLE>
<LINK REL="Prev" HREF="/Risks/11.03.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.05.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 4</H1>
<H2> Thursday 7 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Subway door accidents 
</A>
<DD>
<A HREF="#subj1.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
"Virus" destroys part of Mass. state budget plan 
</A>
<DD>
<A HREF="#subj2.1">
Adam M Gaffin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Reinterpretation of term "Computer Security" 
</A>
<DD>
<A HREF="#subj3.1">
Frank Dixon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
SSN and Schwab Telebroker RISKS 
</A>
<DD>
<A HREF="#subj4.1">
Curtis Jackson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Inquiry into cash machine fraud 
</A>
<DD>
<A HREF="#subj5.1">
John Sloan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: the new California licenses 
</A>
<DD>
<A HREF="#subj6.1">
Mark Jackson
</A><br>
<A HREF="#subj6.2">
 Mark Gabriele
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
No more quick n' easy account info from Fidelity 
</A>
<DD>
<A HREF="#subj7.1">
Carol Springs
</A><br>
<A HREF="#subj7.2">
     B.J. Herbison
</A><br>
<A HREF="#subj7.3">
 Carl M. Kadie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: Electronic cash completely replacing cash 
</A>
<DD>
<A HREF="#subj8.1">
Lee S. Ridgway
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Re: Predicting System Reliability... 
</A>
<DD>
<A HREF="#subj9.1">
Brad L. Knowles
</A><br>
<A HREF="#subj9.2">
 Jeff Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
Electronic telephone directory 
</A>
<DD>
<A HREF="#subj10.1">
Jan Talmon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
**[A whole issue pending on postage stamp and gas vending machines.  GROAN!!!]**
</A>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
subway door accidents (Pete Mellor, <A HREF="/Risks/11.03.html">RISKS-11.03</A>)
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Thu, 7 Feb 1991 14:07:00 -0500
</i><PRE>

Here in Toronto, the subway staff can open one door on each side of each car,
but they need a key to do so.  There is an interlock so that any door open more
than 1-2 cm prevents acceleration from being applied, and opening the door with
the staff key apparently does not override the interlock.  (At least, the usual
indicator lights do come on.)  All of this is exactly the way I would expect
sensibly run systems everywhere to do it.  So let's hear about the
counterexamples...

It *is* possible for a train to run with a door open, in case the door fails;
to do so requires the operation of an override control concealed under the
passenger seats.  In that case the door-open warnings do not light.  On using
the override, the crew place large "Danger - Do Not Use" banners across the
doorway.  This too seems entirely sensible.

The open-door interlock is not sufficient to prevent accidents of the type
described above.  The closing doors can trap things like a coat sleeve or a
trailing purse, and people don't always react properly.  There was a fatal
accident here last year which may have been of this type (the exact cause was
not proved); it resulted in a long inquest and a lot of unfavorable publicity
for the transit system; and as a result of this, we now have what seem to me to
be annoyingly paternalistic advertisements, basically telling us that it's
always better to wait for the next train than to try to catch one that's just
leaving.

The operating practice here is to start the train the instant all doors are
closed -- often the driver sets the control to accelerate as they start
closing, and lets the interlock start the train when they finish.  On a past
visit to New York, on the other hand, I noticed that there they wait a couple
of seconds after closing the doors and before starting the train.  And as I
recall London does the same.  I then read about an accident in New York where
someone had tried to force the doors open during those seconds, and gotten
caught and killed.  My conclusions were that New York does not have a
door/power interlock (though I suppose it might be that the fool merely managed
to not trigger it) and that it is actually safer to start away at once because
it reduces the temptation to those who would try this sort of thing.

Mark Brader      SoftQuad Inc., Toronto	    utzoo!sq!msb, msb@sq.com

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
"Virus" destroys part of Mass. state budget plan
</A>
</H3>
<address>
Adam M Gaffin
&lt;<A HREF="mailto:adamg@world.std.com ">
adamg@world.std.com 
</A>&gt;
</address>
<i>
Thu, 7 Feb 1991 17:36:00 GMT
</i><PRE>

Reason 4,012 to back up documents: A case study
 
Middlesex News, Framingham, Mass, 2/7/91
 
By Adam Gaffin
NEWS STAFF WRITER
     BOSTON - State officials say a computer virus destroyed 50 pages 
of Gov. Weld's budget proposal earlier this week, but a computer 
consultant with experience in fighting the bugssays uit sounds more 
like a case of inadequate maintenance than anything sinister. 
     Michael Sentance of Maynard, a legislative aide to Weld, had typed 
in 50 pages of the governor's proposed budget on a Macintosh computer 
when he tried saving the document to the machine's hard drive around 3 
a.m. on Monday - only a few hours before it was due to be submitted to 
the Legislature. 
     But instead of being saved, the document disappeared, according to 
Liz Lattimore, a Weld spokeswoman. Sentance was eventually able to 
retrieve an earlier draft, filed under a different name, minus the 50 
pages, she said. Because of the snafu, Weld was forced to delay 
submitting the plan by a day.
     When Sentance ran a program to check for the presence of viruses 
on the machine, it responded with a message indicating a ``type 003 
TOPS network'' virus, Lattimore said. TOPS is the name of the network 
used by the Executive Office of Administration and Finance to connect 
its Macintoshes. 
     Sentance had borrowed one of that office's computers because he 
was more familiar with Macs than with the older Wang system in the 
governor's suite, Lattimore said. 
     Viruses are small programs that can take control of a computer's 
operating system and destroy other programs and data, and can be spread 
through people unwittingly sharing ``infected'' programs or disks. 
     Lattimore said officials managed to transfer data from the ailing 
computer to another machine, adding that they are now checking all of 
Administration and Finance's Macintosh computers for possible 
infection. 
     But Eileen Hoffman of Needham, a Macintosh consultant, says what 
happened to Sentance sounds more like a hard-drive ``crash'' than a 
virus - something she said is potentially far more destructive. 
     A document that disappears when the user tries to save it onto the 
hard drive usually means there is something physically wrong with the 
computer's hard drive, not that it is under viral attack, Hoffman said. 
     Hoffman, who keeps three or four infected disks in a safe so that 
she can test new anti-viral software, said the software that runs TOPS 
networks is written in such a way that it can show up as a ``virus'' in 
programs that check for viruses. She said a ``Type 003'' virus is one 
of these phantom ``sneak'' viruses. 
     Hoffman said Macintosh users are often more lax about maintaining 
their computer's hard drives than users of IBM compatible machines, 
because Macintoshes are aimed at people who do not want to have 
anything to do with the hardware of their machines. The Macintoshes 
were installed during the Dukakis administration. 
     But even Mac hard drives require regular maintenance, she said. 
She said she often gets calls from clients who blame disappearing data 
or strange things on their screens on viruses, but that almost always 
the problem is caused by a mechanical hard-drive problem. 
     She added that the particular version of anti-viral software Sentance used
is two years out of date. Since new viruses are created all the time, this
means the software might not be able to detect one even if the machine were
infected, she said.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Reinterpretation of term "Computer Security"
</A>
</H3>
<address>
Frank Dixon, fdixon@hq.dla.mil
&lt;<A HREF="mailto:fhi0011@hq.dla.mil ">
fhi0011@hq.dla.mil 
</A>&gt;
</address>
<i>
Wed Feb 6 09:01:17 1991
</i><PRE>

One of the moguls in our business has publically taken the position that
computer security, as a concern, should be interpreted to include _all_ data
not just data perceived to be "at risk." He suggests--at his most extreme
pole--that the term "sensitive data" should be stricken from the lexicon of
security practitioners.

Given that those charged with protected the information judged to be sensitive
are more or less plowing an uphill furrow, I am concerned that this movement
toward a broadening of the coverage of the concern will have either of two
deleterious effects: (1) It may weaken the already feeble attempts to protect
the truly sensitive, or (2) be used pragmatically as a justification for
"protecting" all communications.

I don't like the implications.

Frank Dixon, Alexandria, VA

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
SSN and Schwab Telebroker RISKS
</A>
</H3>
<address>
Curtis Jackson
&lt;<A HREF="mailto:!jackson@adobe.UUCP ">
!jackson@adobe.UUCP 
</A>&gt;
</address>
<i>
7 Feb 91 20:46:02 GMT
</i><PRE>

This morning my girlfriend decided to sell some stock in her Charles Schwab (a
popular U.S. discount stock brokerage firm) account.  Schwab has a 24-hour
automated telephone quote and order service called Telebroker, and since I know
that stock orders placed through Telebroker qualify for a 10% discount on
commission fees, I suggested she place her order over the telephone with the
automated system.

All of her records (including her account number) were at work, but she glibly
called up the local Schwab office and was able to obtain her account number
simply by giving her social security number and her address.  She then called
up Telebroker for the first time ever, entered her account number, and it asked
for *the last four digits of her social security number as her default
password*.  "This is easy," she said.  And indeed it is!  It then had her pick
a new password, and dropped her into the standard interface.  I do not know if
it would have balked if the "new" password she entered was the old one -- the
last four digits of her SSN.

Telebroker is a relatively new and somewhat unknown feature offered by Charles
Schwab.  As easy as it is to obtain social security numbers of people in the
U.S., it would be very easy to find someone who has a Schwab account but has
never used Telebroker.  If you couldn't get their Schwab account number on your
own, you could simply call up Schwab and get their account number, then call
Telebroker and have a good deal of fun at their expense.  Certainly you
couldn't get your hands on the proceeds from a stock sale, but if you wanted to
wreak havoc on their life you could sell valuable stocks they are holding, or
find a climbing stock and margin them into it to the hilt.  Schwab allows you
to purchase 1.5 times your equity on margin.  Schwab further has a [somewhat
lax] policy of not leaving completed transaction confirmation messages on
answering machines for privacy reasons, so if you do it while Mr. X is out of
town he won't find out what you've done until the margin call.

Even without the human-induced risk of giving out account numbers on the
telephone, the risk of using the last four digits of the SSN as the default
password is a great one.

Curtis Jackson @ Adobe Systems in Mountain View, CA  (415-962-4905)
Internet: jackson@adobe.com	uucp: ...!{apple|decwrl|sun}!adobe!jackson

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Inquiry into cash machine fraud (<A HREF="/Risks/11.03.html">RISKS-11.03</A>)
</A>
</H3>
<address>
John Sloan
&lt;<A HREF="mailto:jsloan@niwot.scd.ucar.EDU ">
jsloan@niwot.scd.ucar.EDU 
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 12:21:35 MST
</i><PRE>

&gt;  A bank engineer is being interviewed by police investigating unauthorized
&gt;withdrawals from cash machines.  It is alleged that money was withdrawn from
&gt;customers' accounts through information gained during the servicing of machines
&gt;operated by Clydesdale Bank.

This reminds me of a personal anecdote that illustrates how computers can play
passive partners in "low-tech" cash machine ripoffs. In 1975 I worked for a
national bank which was among the first to introduce cash machines to the
region. Normally the cash machines were online and continuously monitored by a
DEC PDP-11 front-ending an IBM 370/135 (I should mention that the cash machines
were not manufactured by either of these two firms). The machines had offline
capabilities in the case that the host systems went down and thus an account
could not be verified.

One weekend we were converting from a 370/135 to a 370/145 during which time
there was a short period in which the machines were left in offline mode. While
the machines were acting independently a large theft occurred from the cash
cassettes of several machines. There was no record of transactions on the
internal audit paper tape on any of the victimized machines. It was clearly an
inside job, since the thief knew precisely when the host system would be
unavailable.

Since I was on duty that weekend during the conversion I was among the
personnel interviewed by the FBI. Nearly a year later, after changing jobs, I
read where the FBI had arrested one of two of the cash machine vendor's service
people, who had confessed. His crime involved some special knowledge -- if a
cash machine were to be opened while online that would be time stamped on the
host system console -- but required no more technology than the key to open the
vault in the rear of the machine.

John Sloan, NCAR/SCD, POB 3000, Boulder CO 80307             +1 303 497 1243
jsloan@ncar.ucar.edu         ...!ncar!jsloan       jsloan%ncar@ncario.BITNET

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:mjackson.wbst147@xerox.com">
mjackson.wbst147@xerox.com
</A>&gt;
</address>
<i>
Wed, 6 Feb 1991 14:33:00 PST
</i><PRE>
Subject: Re: the new California licenses

That's "coercivity" rather than "corrosivity"; it's a measure of how "stiff"
the system is in the sense of resisting changes in magnetization.  (Differences
in coercivity between DD and HD diskettes in both 3 1/2 and 5 1/4" formats have
a lot to do with the inadvisability / impossibility of using DD disks at the
higher densities.)

The oersted is the unit of magnetic field strength in the CGS system.

Mark &lt;MJackson.Wbst147@Xerox.COM&gt;

     [Also noted by Fred Gilham &lt;gilham@csl.sri.com&gt;, Steve Bellovin
     &lt;smb@ulysses.att.com&gt;, Ron Fox &lt;fox@rudolf.nscl.msu.edu&gt;,
     and Mark Gabriele (gabriele@hub.toronto.edu).  Even PGN noticed
     it, but did not get around to fixing it.  I try, but I do not always
     fix everything that needs it.  If I did, I would probably be 
     Chorusively Orst(ed) on my own Peterd.  PGN]

</PRE>
<HR><H3><A NAME="subj6.2">
Re: the new California licenses
</A>
</H3>
<address>
Mark Gabriele
&lt;<A HREF="mailto:gabriele@riverdale.toronto.edu ">
gabriele@riverdale.toronto.edu 
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 11:13:43 EST
</i><PRE>

&gt;...  The other two tracks will be in a format that is incompatible
&gt;with current commercial readers, and will contain the rest of the
&gt;information that is printed on the front: birth date, eye color, hair
&gt;color, height, weight etc.

The author then goes on to point out the issues of loss of privacy from this
new system, and how all shopkeepers will soon inevitably upgrade their card
readers to capture this important and private information.

I don't see what the privacy problem is here, provided that the only data which
is encoded magnetically on the back of the cards is currently available in
human-readable format on the front of the card.  If you'll give your driver's
license to a clerk, you should be prepared to have the clerk copy down all of
the information on that license (I've had clerks meticulously copy my height,
weight, and eye color off of the driver's license while I and the customers
behind me waited).

=Mark Gabriele (gabriele@hub.toronto.edu)

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
No more quick n' easy account info from Fidelity
</A>
</H3>
<address>
Carol Springs 
&lt;<A HREF="mailto:carols@drilex.dri.mgh.com">
carols@drilex.dri.mgh.com
</A>&gt;
</address>
<i>
Wed, 6 Feb 91 13:18:42 EDT
</i><PRE>

In today's Boston Herald (Febrary 6), Robert Powell has a followup to 
his article on Fidelity that appeared yesterday.  Basically, Fidelity 
has "slammed the door shut" on Fidelity Telephone Connection.  Tracey
Gordon at Fidelity says, "We changed it in response to concerns by some
of our shareholders who called because of reports in the press."

People who called the toll-free number on February 5 got a real human
person asking for SSN and Fidelity account number.

According to Gordon, a system is being set up wherein callers will enter
their account number along with their SSN.  And a few weeks later, a PIN
system will be put into place. 

Carol Springs                      carols@drilex.dri.mgh.com

</PRE>
<HR><H3><A NAME="subj7.2">
Discontinued:  Quick n' easy access to Fidelity account info
</A>
</H3>
<address>
"B.J.  07-Feb-1991 1021" 
&lt;<A HREF="mailto:herbison@ultra.enet.dec.com">
herbison@ultra.enet.dec.com
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 07:46:47 PST
</i><PRE>

In a message in <A HREF="/Risks/11.03.html">RISKS-11.03</A>, Carol Springs described a system that allowed
access to Fidelity Investments account information using an 800 number and a
social security number.  The message said it was possible to call Fidelity and
request blocking for your accounts.  When I called Fidelity and asked about the
service, the response was:

	`No, we discontinued that service.'

I thanked the representative, told her I was pleased that the service was dead,
and hung up.  A small victory for privacy.

On a related note, when you call 1-800-DISCOVER you are given the opportunity
to check your Discover credit balance automatically.  When this service first
started, only the card number was needed.  Because of complaints, the system
now require your zip code as well.  Another reason to refuse to write your
address on your credit card receipt.

</PRE>
<HR><H3><A NAME="subj7.3">
Quick n' easy access to Fidelity account info
</A>
</H3>
<address>
"Carl M. Kadie" 
&lt;<A HREF="mailto:kadie@cs.uiuc.edu">
kadie@cs.uiuc.edu
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 11:27:52 -0600
</i><PRE>

I just called Fidelity. The representative say that the Telepeople system has
been taken down until they can add PIN protection.

                                                       [O PIN, O SESAME?  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
     Re: Electronic cash completely replacing cash
</A>
</H3>
<address>
"Lee S. Ridgway" 
&lt;<A HREF="mailto:RIDGWAY@mitvma.mit.edu">
RIDGWAY@mitvma.mit.edu
</A>&gt;
</address>
<i>
Thu, 07 Feb 91 10:46:55 EST
</i><PRE>

No one seems to have proposed the most obvious, simple solution to the risks of
americards and mastercards: cash! I find that for my normal purchasing habits,
I can pay cash. I can go to my bank machine two or three times a week [I know
some people who visit theirs daily!], get cash to cover known purchases for
several days, and not have to bother waiting for clerks to fill out charge
slips, get verifications, and other time-consuming procedures. Thus, I pay for
groceries, gas, meals, recordings, books, concerts, etc., etc.

I do have credit cards, but I use them only for large or very specific
purchases. That means few databases have records of my purchasing habits. I
also don't carry balances, or incur interest, and don't have to write several
big checks to credit card companies each month.

For those who are now going to say that cards are safer: I live in a city where
street robbery is not unknown, but I don't carry very much cash at one time -
and I don't carry my cards unless I know I will use them. Yes, I've been robbed
a few times (in about 20 years), but never lost much cash, and lost much more
in time and aggravation over stolen credit and ID cards than the cash.

For those who say cards are more convenient: Carry more than two, and they are
as bulky as bills. They require more time to complete a transaction (compare
the time it takes to pay a restaurant bill in cash vs. credit card!). Compare
the amount of time needed for a verification, especially if the phone or
computer connection is down or slow, or the manager is not around.  Compare the
amount of time needed once a month to sit down and check store receipts against
bills, write checks, etc.

One other possible blessing of cash and not cards: I find that I am on the
mailing list of only one or two mail-order houses, from whom I receive catalogs
maybe once a month, while my housemate, who uses credit cards for just about
everything, receives at least six or more catalogs per day! Cause and effect?

   [NO MORE RESPONSES on this topic for a while.  We are badly backlogged. PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Re: Predicting System Reliability...
</A>
</H3>
<address>
Brad L. Knowles
&lt;<A HREF="mailto:blknowle@frodo.jdssc.dca.mil ">
blknowle@frodo.jdssc.dca.mil 
</A>&gt;
</address>
<i>
Wed, 6 Feb 91 19:16:41 EST
</i><PRE>

    In reference to Richard P. Taylor's point in 11.03, namely that to show
"sufficient" reliability for a system requires that the entire system in
question run in a production environment for longer than the required time, I
must agree.  In fact, with the things about quality that we are learning from
the Japanese (who learned it from Dr. Deming), I would claim that the entire
system in question run in a production environment for a six-sigma period of
time.

    For those of you who might not have been accustomed to the term six-sigma,
I will attempt my best explanation (poor 'tho it will be):

	In statistics, we can call sigma the Standard Deviation of the
    Probability of Failure of the system in question.  The term x-bar (a lower-
    case x with a bar above it) is the Mean Probability of Failure of the
    system in question.  X-bar plus six-sigma is the value we want to prove is
    lower than some given criterion, to a certain level of confidence.

	We then compose what is called a "Null Hypothesis" that is the exact
    opposite of what we are trying to prove (namely, that our system will last
    at least x amount of time).  We then try to prove our Null Hypothesis
    wrong, to a probability of 95% or better.  If we prove to 95%, then we have
    proven to a two-sigma level of confidence that are system will last at
    least as long as desired.  If we prove to a 99%, then we have proven to a
    three-sigma level of confidence.  If we prove to a 99.997%, then we say we
    have a six-sigma level of confidence.  The test used to show the level of
    confidence is usually "Student's T Test", for historical reasons (I know,
    there are oodles of other tests, this just happens to be the first taught
    in most University Senior-level Stat courses, and probably the best
    known).

	One thing to keep in mind, as we get to higher levels of confidence, we
    must test our system for exponentially long periods of time, assuming that
    all else is equal (which, we all know, never happens).  That is, unless you
    test hundreds or even thousands of units, all in parallel.  This is how a
    disk drive manufacturer can say something like "50,000 Hours Mean Time
    Between Failures" -- you didn't think they actually had a single drive that
    they tested for 50K+ hours, did you?  I would go so far as to say that no
    well known drive manufacturer today has a single drive with 50K hours on it
    -- they'll get junked and replaced long before that happens.  Still, the
    drives fail.

	The exact numbers of units that you would have to test to prove a
    certain level of confidence can also be calculated by well known
    statistical methods, so that you might have to test only 53 units to get
    the level of confidence desired.

    Basically, this is what the Japanese are hitting us over the head with.
Most Japanese companies have been using six-sigma Statistical Quality Control
for years now, and many of the front runners are now going to nine-sigma (and
even twelve-sigma)!

    Now, the problem we've got is when we try to test a system like a Nuclear
Power plant.  We certainly can't afford to build a single plant to try to prove
our system will last at least x number of years without failure, much less
build *MULTIPLE* identical plants to do so.  Thus, all we can really do is
unit-test as many parts as we can, and forgo the system testing.  I can point
out to one very well known system where this has led to many heartaches, if not
outright system failure before it was ever put on line -- the Hubble Space
Telescope.  Everything was completely unit-tested, but system testing was
deemed too expensive and time-consuming.  Still, in some cases, system testing
just is not possible.

    Oh well, this is an interesting discussion of an ages-old problem -- it is
non-trivial to prove even trivial systems correct (or when they will fail), not
to mention how hard it is to prove non-trivial systems correct!

Brad Knowles, Sun System Administrator, DCA/JDSSC/JNSL, The Pentagon BE685,
Washington, D.C.  20301-7010    (703) 693-5849      |     Autovon: 223-5849     

Disclaimer: Nothing I have done or said in the above should be construed as an
official position or policy of the Defense Communications Agency or the United
States federal government.  The author is the sole person responsible for the
content of this message.

</PRE>
<HR><H3><A NAME="subj9.2">
Re: Predicting system reliability (RISKS 11.02)
</A>
</H3>
<address>
Jeff Johnson 
&lt;<A HREF="mailto:jjohnson@hpljaj.hpl.hp.com">
jjohnson@hpljaj.hpl.hp.com
</A>&gt;
</address>
<i>
Thu, 07 Feb 91 10:32:49 PST
</i><PRE>

This discussion is muddied by a failure to distinguish between reliability and
functional sufficiency.  I believe that there is a tradeoff in systems
engineering between reliability and sufficiency.  If a problem exists that is
to be solved by a system, the system designers are often faced with the choice
of designing a system that solves the problem or one that is reliable and
maintainable.  The reliable design usually solves some sub-problem.

Many system designers don't realize that they are faced with this tradeoff:
they design a system to solve the full problem and only after it is built do
they discover that it is so complex and bug-ridden that it cannot be relied
upon or maintained.  Or, perhaps seeing the tradeoff, perhaps not, they aim low
and deliver a reliable, maintainable system that doesn't do what was desired.
Either way, the resulting system doesn't solve the customer's problem.

Often, as a system designer, I've had programmers respond to design
specifications by saying: "Providing functional capability X would require me
to write a non-modular program.  I won't make it non-modular, so you can't have
feature X."  This argument is of course false -- any thing that can be done
"non-modularly" can also be done "modularly" -- but it illustrates the
programmer's tendency to sacrifice functional sufficiency for reliability and
maintainability.  Customers, salespeople, and those who write functional
specifications typically exhibit the opposite tendency: requesting or promising
functionality that would exceed developers' ability to produce a reliable
system.

An example from SDI: Initially, the plan was to design a system in which there
was a great deal of inter-component communication in order to coordinate the
defense.  Critics correctly shot down this plan as hopelessly unreliable.  The
SDIO responded by advocating a decentralized design involving significantly
less inter-component communication.  Under further criticism, control was
further decentralized until we ended up with "Brilliant Pebbles", in which at
least the "business-end" components are supposedly autonomous, and which
managed to win over a few SDI critics.

My reaction to Brilliant Pebbles and some of the other decentralized plans that
preceded it was that even if they are more reliable than centralized designs
(and this is debatable), they wouldn't solve the problem from a functional
point of view: massive inter-component communication may well be *necessary*
for the system to accomplish its task.  Unfortunately, massive inter-component
communication also implies a level of unreliablility that, for SDI, is
unacceptable.

If handed a functional specification for SDI, I could write a ten-line C/unix
program that would be (I assert) highly reliable.  But it wouldn't meet the
functional specification.  Some SDI proposals (and some proposals for other
ambitious projects) are simply schemes to develop slightly-larger "ten-line"
programs that won't do the job.

Computer Science has partially addressed the issue of reliability and
maintainability by developing: 1) formalisms for proving correctness of
programs, 2) programming languages and tools providing more support for program
correctness (e.g., modularity, strong-typing), 3) improved methodologies for
software engineering.  These don't insure reliable systems, but they help.  Has
Computer Science developed anything analogous for analyzing functional
sufficiency of programs (beyond a few proofs that certain extremely ambitious
functional specifications can't be met)?  Might such an analysis be useful here?

JJ, HP Labs

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
 Electronic telephone directory
</A>
</H3>
<address>

&lt;<A HREF="mailto:MFMISTAL@HMARL5.BITNET">
MFMISTAL@HMARL5.BITNET
</A>&gt;
</address>
<i>
Wed, 6 Feb 91 22:19 N
</i><PRE>

In the Netherlands, printed telephone directories provide telephone numbers
by using the name as an index. Currently, there is also an electronic
version of those directories available by means of a VIDITEL service.
Here it is also possible to ask for a telephone number by providing the
street name, the house number and the city. This involves an inherent risk.
When one observes that there are apparently no people in a house, one can
ask for the phone number, dial that number and when no one replies....
it may be safe for burglars to go in. It seems also to be an invasion of
one's privacy, since one need not to know a name in order to place
haressing/obscene phone calls.

The only thing one needs is a PC and a modem. The costs: 35 cents (20 $cents) a
minute.

Jan Talmon, Dept of Medical Informatics, University of Limburg, Maastricht,
The Netherlands

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-66</DOCNO>
<DOCOLDNO>IA013-000136-B032-149</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.05.html 128.240.150.127 19970217041718 text/html 26126
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:15:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 5</TITLE>
<LINK REL="Prev" HREF="/Risks/11.04.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.06.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 5</H1>
<H2> Thursday 7 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Enterprising Vending Machines (postal) 
</A>
<DD>
<A HREF="#subj1.1">
Jay Schmidgall
</A><br>
<A HREF="#subj1.2">
 Matt Deatherage
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Re: A risky gas pump [IF YOU CAN STAND IT!] 
</A>
<DD>
<A HREF="#subj2.1">
Donald Lehman
</A><br>
<A HREF="#subj2.2">
 James Helman
</A><br>
<A HREF="#subj2.3">
     Jonathan Clark
</A><br>
<A HREF="#subj2.4">
 Paul S. Sawyer
</A><br>
<A HREF="#subj2.5">
 Christopher Lott
</A><br>
<A HREF="#subj2.6">
 Guy Sherr
</A><br>
<A HREF="#subj2.7">
     Michael C. Tanner
</A><br>
<A HREF="#subj2.8">
 Michael Van Norman
</A><br>
<A HREF="#subj2.9">
 Barry Margolin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Enterprising Vending Machines (Allan Meers, Risks 11.01)
</A>
</H3>
<address>
"Jay Schmidgall" 
&lt;<A HREF="mailto:shmdgljd@rchvmw3.iinus1.ibm.com">
shmdgljd@rchvmw3.iinus1.ibm.com
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 12:37:24 CST
</i><PRE>

In  RISKS DIGEST 11.03,  mjackson.wbst147@xerox.com writes:

&gt;  It seems the programmers did anticipate this problem (credit stuck
&gt;  in the machine with no means of recovery).

Well, I got to witness a incident quite similar here at my onsite stamp
machine.  A person had put in $5 and tried to buy a book of 20 stamps.
Unfortunately, the price was now $5.80 because of the price per stamp increase
and the machine flashed an message "Use exact change" (as an aside, not quite
the response I would have expected, which would have been more like "Insert
additional funds" or some such.)  Also unfortunately, the person did not have
an additional 80 with them -- apparently he had just grabbed a fiver to buy
the stamps.  Fortunately, someone he knew was around so he asked them if they
had 80.  Unfortunately they did not.

When he got back to the machine, I suggested he just buy a book of the old 25
stamps, since it was posted that a purchase was required to get back change.
In fact, it was also posted that a minimum $7 purchase was required to get back
change -- this was a bit unclear as someone had just written it in red ink over
the operating instructions, which were on a roughly 3x5 sticker in small type
on the upper right corner of the machine.

When he tried to get the stamps, the "Use exact change" message flashed again.
He was pretty confused but, having read my RISKS this morning, I had an idea
what was happening.  I put in my money to get my stamps (exact change, BTW) and
sure enough, his $5 credit was gone.  I got my stamps, explained to him what I
thought had happened and suggested he contact Vending Services to get his money
back.  I also fired a note off to the vending person myself, suggesting that
this "feechur" be disabled if at all possible.  No response as yet.

Jay Schmidgall   RSCS:shmdgljd@rchvmw3  shmdgljd@rchvmw3.iinus1.ibm.com

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Enterprising Vending Machines (<A HREF="/Risks/11.03.html">RISKS-11.03</A>)
</A>
</H3>
<address>
 
&lt;<A HREF="mailto:mattd@apple.com">
mattd@apple.com
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 13:51:54 -0800
</i><PRE>

The hotbeds of American technology are not immune to this horrid machine.  I
went to the main post office right here in Cupertino, CA yesterday, having
already read the article in Risks 11.01 (happy anniversary!) warning of this
nasty machine.  I *intended* to purchase stamps at the window, but made the
mistake of arriving at 4:58 PM -- the service area was already locked, and only
those already inside were being let out.  So I went to the vending machine.

Just for fun, I pressed the button for an item without any money in the machine,
and the "SOLD OUT" light *did* illuminate.  I didn't take this at face value,
but I decided to risk that there was a roll of 29 cent stamps or two still in
the machine.

Problem:  All I had were $20 bills.  OK, I thought, even though this machine
had a label on it clearly saying that it will not deliver more than $3.00 in
change, I can put in 3 $20-bills and buy two rolls of 100 $0.29 stamps.  Right?

Wrong.  It cheerfully accepted my first $20, but rejected the second one with
"CAUTION:  USE SMALLER BILLS."  Apparently the machine knew that it's most
expensive item was $29 and wouldn't let me insert $40!  I had no smaller
bills, and the helpful postal employee in the lobby had a vocabulary limited
to the words "we're closed".  Finally, after about 5 minutes of trying to figure
a way out of this mess without having to purchase the entire machine, a postal
supervisor came out and gave me two $10 bills for a $20, enabling me to finish
and be on my way.

(The supervisor, by the way, had only come out to investigate a report that the
machine was not accepting coins, but gave change when he noticed that the
problem I'd encountered had stopped approximately 8 other potentional income
sources from taking their chances with this demonic mechanical contraption.)

--Matt Deatherage, Apple Computer, Inc.

      [THIS SERIES OF HORROR TALES IS BROUGHT TO YOU IN THE PUBLIC INTEREST,
      ALTHOUGH PUBLIC DISINTEREST IS LIKELY TO ENSUE RAPIDLY.  BEWARE.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: A risky gas pump
</A>
</H3>
<address>
Donald Lehman
&lt;<A HREF="mailto:dlehman@cyclonic.sw.stratus.com ">
dlehman@cyclonic.sw.stratus.com 
</A>&gt;
</address>
<i>
Wed, 6 Feb 91 21:20:14 EST
</i><PRE>

I remember a setup, similar to what Mr. Grumbine describes, in Sacramento
around 1985 or so.  I wish we had something like that around here.  I think
this is a case where the benifits outweigh the risks.  Unlike voting, buying
gas is something I do relatively often and I want the process to be optimized.
I consider the increased risks (relative to the risks already associated with
credit card puchases) to be minimal.

I respond:

&gt;  What verification is there that the card that is authorized is really mine?
     None.  But my other credit card purchases are not usually validated
either.  I think the fair credit acts protect you somewhat.

&gt;  What happens if the receipt disagrees with the amount pumped?
     Complain. Same as if the human attendant tried to overcharge you.
I would assume that these stations have a human attendant or at least
a telephone available.

&gt;  How about if my number is not cleared from the pump's memory and I get
&gt;    billed for the entire day's gas from that pump?
     This is a risk of any system. The same thing could happen with the 
computer at an attended pump. I'm not sure, but I believe that with 
modern systems the slips you sign are only looked at if there is a 
discrepancy. 

&gt;  How do I get that receipt if the machine is out of paper?  Will is _always_
&gt;    know that it can't print _before_  I pump the gas?
     I assume these things would be similar to an ATM in telling you if
it can't print receipts, but even if it doesn't, I don't consider it a 
big deal. It may mess up your records, but, except for expense accounts,
I can't think of a reason I need to prove that I bought gas. What I 
would want is proof that I didn't buy something, but that is practically
impossible.

&gt;Perhaps this gas pump is a harbinger of the 'Americard'.  I hope not.
     There is a major distinction between the issue of 'Americard' 
and credit cards, and that is credit. As I understand it, the 
'Americard' is like a debit card in that you don't need to 'agree'
to the charges by paying a bill. Unless you blindly pay what the
credit card company asks, you are protected to some extent. I've
never had to go to arbitration or litigation over credit card items,
so I don't know how powerful the companies may be, but you need to 
weigh the risks with the benefits.

   Don Lehman                   | Donald_Lehman@es.stratus.com
   Stratus Computer Inc.        | Standard Disclaimers Apply
   Marlboro, Mass               | I speak for myself...

</PRE>
<HR><H3><A NAME="subj2.2">
Re: A risky gas pump (<A HREF="/Risks/11.03.html">RISKS-11.03</A>)
</A>
</H3>
<address>
James Helman
&lt;<A HREF="mailto:jim@baroque.stanford.edu ">
jim@baroque.stanford.edu 
</A>&gt;
</address>
<i>
Wed, 6 Feb 91 21:39:45 -0800
</i><PRE>

A similar system is in use in at least one Chevron station on the SF Peninsula
(Belmont).  The only difference is that a receipt is always printed, so no
interaction beyond running the card through and pumping the gas is necessary.

Initially, the station attendants were running all around checking things and
said they were having problems.  But now it has settled down and is one of the
quicker places to get gasoline.

Personally, I find the convenience to be worth the additional risk.  The danger
does not appear to be substantially higher than other electronically entered
transactions, probably less since gasoline purchases are usually modest in
amount and frequency.  Perhaps, it's just another good reason to only carry
cards from reputable and responsive banks, just in case of problems.

Jim Helman, Department of Applied Physics, Stanford University, Durand 012
(jim@baroque.stanford.edu) 			            (415) 723-9127

</PRE>
<HR><H3><A NAME="subj2.3">
re: risky gas pumps
</A>
</H3>
<address>
Jonathan Clark
&lt;<A HREF="mailto:jhc@ulysses.att.com ">
jhc@ulysses.att.com 
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 09:54:29 EST
</i><PRE>

Completely unmanned petrol (gas) stations have been around in Europe 
for at least the last ten years. When I lived in Brussels I used to
patronize them all the time, because:

1) They were open 24 hours a day, 7 days a week; and
2) They were significantly cheaper.

They worked on a bank debit card system (like a money machine card),
and so were just as (in)secure as those. I believe that there was a
maximum amount of fuel that one was allowed to charge in one pass, this
would occasionally lead to drivers of cars with large tanks (V12 Jaguars
spring to mind) having to go through the ritual twice, in order to fill
up completely. As far as I recall one *always* got a receipt.

One of the risks they *reduced* was the possibility of driving away 
with the hose still attached to the car. When it's one's own money one
is very careful about closing off the transaction properly...

Perhaps some of our readers currently living in Europe would contribute
some horror stories?

Jonathan Clark                     jhc@ulysses.att.com, attmail!jonathan

</PRE>
<HR><H3><A NAME="subj2.4">
Re: A risky gas pump (<A HREF="/Risks/11.03.html">RISKS-11.03</A>)
</A>
</H3>
<address>
Paul S. Sawyer
&lt;<A HREF="mailto:paul@unhtel.unh.edu ">
paul@unhtel.unh.edu 
</A>&gt;
</address>
<i>
7 Feb 91 10:20:08 EST (Thu)
</i><PRE>

&gt; [Gas pumps which read credit cards directly] ...
&gt;
&gt;I did not try this 'convenience' out.  Just in the time I was pumping gas
&gt;I came up with several _risky_ questions about the process:
&gt;  What verification is there that the card that is authorized is really mine?
&gt;  What happens if the receipt disagrees with the amount pumped?
&gt;  How about if my number is not cleared from the pump's memory and I get
&gt;    billed for the entire day's gas from that pump?
&gt;  How do I get that receipt if the machine is out of paper?  Will is _always_
&gt;    know that it can't print _before_  I pump the gas?
&gt;
&gt;  There are quite a few that risks readers could come up with.  This situation
&gt;does start to merge in to the 'Americard' type of risks as well.  Perhaps
&gt;this gas pump is a harbinger of the 'Americard'.  I hope not.
&gt;                                                                Bob Grumbine

Mobil has been doing this for some time, and it usually seems to work [I only
use my Mobil card on the turnpikes, since they like to charge their regular
customers extra....]  They also take debit cards, including some bank teller
cards.  The problem is, during the authorization phase, they go for something
like $30-$35.  Then, you get $5-$10 worth of gas, and the difference is not 
credited until later. [possibly end of day batching?]  A local news item told
of a woman who could not get cash from an ATM to buy groceries because she
had just used the card to get gas....

Paul S. Sawyer             {uunet,attmail}!unhtel!paul    paul@unhtel.unh.edu
UNH CIS - - Telecommunications and Network Services      VOX: +1 603 862 3262
Durham, New Hampshire  03824-3523                        FAX: +1 603 862 2030

</PRE>
<HR><H3><A NAME="subj2.5">
Re: auto gas pumps
</A>
</H3>
<address>
Christopher Lott
&lt;<A HREF="mailto:cml@cs.UMD.EDU ">
cml@cs.UMD.EDU 
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 08:49:33 -0500
</i><PRE>

I am responding to the article about gas pumps that take payment;
the author encountered these on the Ohio Tpke.  

Maryland has these pumps, and I for one love them.  Around here, you
have to pay in advance for non-auto pumps, which in my case means walking
in and handing the attendant my credit card and then leaving it with
him/her for the 5-10 minutes it takes me to fill the truck tank (big tank!).

I feel that the purely human risks of leaving my cc with some joker far
outweigh the tech. risks of trusting the implementor of the pump to have
done the right thing.  

Of course I could always use cash!  ;-)

chris...

</PRE>
<HR><H3><A NAME="subj2.6">
Re: A Risky Gas Pump (devil's advocate)
</A>
</H3>
<address>
NSIL LCM 
&lt;<A HREF="mailto:0004222127@mcimail.com">
0004222127@mcimail.com
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 15:34 GMT
</i><PRE>

[comments &amp; disclaimers]
I am not a lawyer, and I do not work at a bank.  I am somewhat disheartened that
people simply do not take time to read credit agreements and learn how to
protect themselves.  Credit, while not really a friend, can be something of a
robber or "banker in your pocket."  I have never appeared in a published article
(and probably won't anytime soon).

[begin response]

It may come as a surprise to our international friends, but it should be noted
that on perhaps the rarest of occasions, proper identification may be required
to complete any transaction with a credit card.  The laws governing commerce and
use of demand consumer credit do not place a compulsion before the seller of any
good or service to identify the holder of a credit card as the authorized user. 
I personally know of no place, other than a hotel or motel, where the seller is
compelled to discover or validate your identity.  Also, in some hotels, credit
issuers agree in advance to a floor limit, which allows the innkeeper to
authorize charges without calling for an authorization (used to be significant,
but has probably decreased with automation).  I know these limits exist because
one of my cards was stolen and AFTER it was known to be stolen, it was presented
and accepted for a room (the billing was, I believe, over $200).

Secondly, on the point of agreement between the receipt and the delivery of any
good or service purchased with credit cards, it should be pointed out that every
consumer (in the United States) has the right to dispute any transaction
appearing on his account within 60 days of that charge's first appearance (most
grantors will afford some leeway in this).  In fact, the grantor of credit risks
the possibility that the authorized user will dispute valid charges and claim
that the card was lost or stolen.  Goodwill and plain honesty go a long way in
the relationship.

Thirdly, given the protection basically held above, receipt failures are not
serious faults.  The receipt for expendables like gasoline and food can be
written by hand and used for proof of a transaction (naturally, there is some
penalty for fraudulent receipts which should curb their creation), even to the
point that it is valid for an audit of one's income tax returns.  This question
is answered also by the power of a dispute.

Finally, the possibility that a single person might be charged with all the
transactions at one gas pump over a given period is that also where a single
person's bank account should become the target of an ATM gone silly.  There is
always that risk, but then there is always a limitation on spending as well. 
Banks impose a limit upon an account's daily withdrawls, and upon borrowing with
a credit card.

The real risks of pumping gas are more substantive than economics.  Gasoline is
a volatile high explosive.  The average car with a full tank has at least the
equivalent explosive potential of 140 sticks of dynamite.  A sufficient
discharge of static electricity anywhere on the fragile connection from pump to
filler neck could loose an explosion of no mean displacement (not to mention
during rush hour on a crowded city street).

[end response]

I wish I had something more substantial and helpful to say than "this is a good
list, and I wish I had been reading it before."  I don't have, and for that, I
am committing the rest of my life to the pursuit of the Oxford English
Dictionary, if she will have me.

Yours truly,

Guy Sherr, MCI, 12369 Sunrise Valley Drive, Reston, VA 22091 Dept 1076/637

</PRE>
<HR><H3><A NAME="subj2.7">
Re: A risky gas pump
</A>
</H3>
<address>
Michael C. Tanner
&lt;<A HREF="mailto:mtanner@gmuvax2.gmu.edu ">
mtanner@gmuvax2.gmu.edu 
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 14:54:33 -0500
</i><PRE>

Bob Grumbine &lt;RMG3@PSUVM.PSU.EDU&gt;, writes about gas pumps that take your
credit card, and don't require signatures, etc.

I've been using pumps like this for some time now.  I know there are certain
risks involved, but they are not that great.  I accept them in exchange for the
increased convenience.

Some of the issues he raises are easy to address.  If it doesn't print a
receipt, you go inside and ask for one and after suitable checking they give it
to you (that's how it works around here, anyway).  If the amount is different,
you go inside and talk about it.  Etc.  Having bought gas this way 50-75 times
in the last 6 months, I have failed to receive a receipt once and had the pump
fail to turn on once.  Otherwise, no problems.  Not a large sample, I know, and
one bad experience is all it takes, but it looks pretty good.

Another possible risk is that my number gets stuck in there somehow, and
everybody's gas is charged to my card at that pump/station/throughout northern
Virginia/USA for some period of time.  But I don't think I'd have much trouble
convincing anyone that I didn't really buy a million dollars worth of gas on
Friday.  I'm not convinced this is a real danger.

The only real problem, I think, is that 2 or 3 extra charges per month could
appear on my bill.  Since I check carefully before I pay any bill, it's not
likely this would get by me.  If it happens once, I can probably get the
charges removed.  If it happens regularly it may be more of a problem.  So the
real risk is that I get overcharged $20-30 per month, get into a hassle with
the company, and ultimately have a blot on my credit record.  My total exposure
is to maybe a $100 or so loss (I can cancel the card and pay it off after 4 or
5 months and have no credit problems).  The way I look at it, I run this risk
in simply having the card, whether I accept the credit pump, or have a person
enter the same data into the same computer.

So the way I look at it, I get greater convenience at little or no increased
risk.  A nice application of technology, I say.

Michael C. Tanner, Assistant Professor, CS Dept, AI Center, George Mason Univ.,
Fairfax, VA 22030       tanner@gmuvax2.gmu.edu       (703) 764-6487

</PRE>
<HR><H3><A NAME="subj2.8">
Re: A risky gas pump (RISKS DIGEST 11.03)
</A>
</H3>
<address>
Michael Van Norman (2)               
&lt;<A HREF="mailto:EGC4MV2@MVS.OAC.UCLA.EDU">
EGC4MV2@MVS.OAC.UCLA.EDU
</A>&gt;
</address>
<i>
Wed, 06 Feb 91 15:11 PST
</i><PRE>

Here in Los Angeles, ARCO has had the same type of service for years.
I have used it for years without any problem.  Now in LA you can even
get a hamburger at Carl's Jr. with your ATM card!

&gt;   What verification is there that the card that is authorized is really mine?

You enter your PIN after sliding your card through the reader.  I
believe that what the authorization entails is a check to see if you
sufficient funds to make a purchase.

&gt;   What happens if the receipt disagrees with the amount pumped?

Complain to the cashier.

&gt;   How about if my number is not cleared from the pump's memory and I get
&gt;     billed for the entire day's gas from that pump?

I have never had this happen (or have heard of it happening) but i have
also wondered about it.

&gt;   How do I get that receipt if the machine is out of paper?  Will is _always_
&gt;     know that it can't print _before_  I pump the gas?

Probably not :)

Michael Van Norman, Library Administrative Computing, 11334 University Research
Library, 405 Hilgard Avenue, Los Angeles, CA 90024-1575           (213)825-1206

</PRE>
<HR><H3><A NAME="subj2.9">
Re: A risky gas pump (from RISKS DIGEST 11.03)
</A>
</H3>
<address>
Barry Margolin
&lt;<A HREF="mailto:barmar@think.UUCP ">
barmar@think.UUCP 
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 00:40:29 GMT
</i><PRE>

Your tone suggests that this is a new risk.  The risks of these gas pumps
are precisely the same as many other uses of credit cards.  What makes the
gas pumps any different from credit card telephones?  The phones don't even
*try* to print a receipt.  And what about giving your credit card number
over the phone to a mail order house?  In general, the risk with all these
is that most credit cards don't have a PIN, even though they're being used
more and more for such automatic transfers.  But even a PIN won't solve the
"reuse" problems that you identified; to solve these, you generally need a
challenge/response authentication system, probably involving a smartcard
rather than a simple credit card.

&gt;  What verification is there that the card that is authorized is really mine?

None.  However, if you dispute a charge, the bank will generally remove it.
Your liability is only $50 for charges made on a stolen credit card, and
I think you have no liability for purchases made after reporting the card
lost or stolen.

&gt;  What happens if the receipt disagrees with the amount pumped?

I'd go to the attendant and get a refund of the excess charge.

What happens if the pump claims to have delivered more gas than it actually
has?  How would you even know, so long as the claim was within a gallon of
your expectation?  This relates to a misc.invest discussion I recently
participated in, regarding balancing one's checkbook; someone asked whether
I really trust greedy banks to properly maintain my balance.  I didn't
reply, but I was thinking: if they wanted to screw me, they'd be much less
likely to get caught if they skimmed from my interest payments rather than
play games with my deposits and withdrawals, as I'm unlikely to verify
their interest calculations.  So I *must* trust them.

&gt;  How about if my number is not cleared from the pump's memory and I get
&gt;    billed for the entire day's gas from that pump?

Complain and have the charge removed.  I don't think any bank would give
you a hard time if you were to dispute a charge for thousands of dollars of
gas from an ordinary gas station.

&gt;  How do I get that receipt if the machine is out of paper?  Will is _always_
&gt;    know that it can't print _before_  I pump the gas?

Who knows?  I think my bank's ATM warns about not being able to print receipts.

Barry Margolin, Thinking Machines Corp.           {uunet,harvard}!think!barmar

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-67</DOCNO>
<DOCOLDNO>IA013-000136-B032-163</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.06.html 128.240.150.127 19970217041730 text/html 7021
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:16:01 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 6</TITLE>
<LINK REL="Prev" HREF="/Risks/11.05.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.07.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 6</H1>
<H2> Friday 8 February 1991</H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Mailing lists 
</A>
<DD>
<A HREF="#subj1.1">
Dan Herrick
</A><br>
<A HREF="#subj1.2">
 Mary Culnan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Americard the Beautyfool (J.C.Patilla, Jay Schmidgall, Frank Wales, Alex Bangs,   Pink Prince or Prince Pink?, Jerry Leichter, Geoff Kuenning, Rob Aitken,   Daniel B Dobkin, Brian Yamauchi, Joe Keane, Richard A. O'Keefe,    Jeffrey Jonas, PGN 
</A>
<DD>
<A HREF="#subj2.1">
epilogue)
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Mailing lists are, indeed, cheaply and easily available (<A HREF="/Risks/10.81.html">RISKS-10.81</A>) 
</A>
</H3>
<address>
"CONTR  HERRICK, DAN" 
&lt;<A HREF="mailto:herrickd%iccgcc.DNET@abvax.UUCP">
herrickd%iccgcc.DNET@abvax.UUCP
</A>&gt;
</address>
<i>
29 Jan 91 09:56:00 EDT
</i><PRE>

Samuel Bates asked where you can get names of companies that produce the
Lotus-style information.

Look in your local Yellow Pages.  Possibly Madison is too much a one industry
town, so you may need to look in the Milwaukee Yellow Pages.  Use the Business
to Business Yellow Pages if they make that distinction out there.

The Cleveland Business to Business Yellow Pages have about 3 1/2 columns of
entries under Advertising, Direct Mail.  Both national and local firms.  More
than a third of those Yellow Pages advertisers will sell or rent the same kind
of information as Esmark and Lotus were offering.

dan herrick                                      herrickd@iccgcc.decnet.ab.com

</PRE>
<HR><H3><A NAME="subj1.2">
U.S. Mailing List Business
</A>
</H3>
<address>
"Mary Culnan" 
&lt;<A HREF="mailto:mculnan@guvax.georgetown.edu">
mculnan@guvax.georgetown.edu
</A>&gt;
</address>
<i>
30 Jan 91 20:30:00 EST
</i><PRE>

This is in response to the posting in RISKS 10.81 asking for the
names of companies that sell mailing lists based on personal
information.  The list business in the US is more than a $1 Billion
dollar/year industry.  To put it briefly, if it moves, it will be
for sale in a list.  If you use a credit card, call an 800 #, subscribe
to any publications, order from a catalog, contribute to a political
party or a charity, or return a warranty card, you are on somebody's
list.

Of most concern to me is that the two large credit bureaus, TRW
and Equifax, are both also in the list business.  Data from your
credit record are summarized and moved into the marketing databases.
This was the source of the data for the Lotus MarketPlace (plus
census data).  I don't believe that most people knew this.  

There is nothing illegal about this, and because the marketing
databases do not include an individual's *credit report*, these lists
are not covered by the Fair Credit Reporting Act.

If you are interested in seeing examples of actual lists, I suggest
you consult the following 3 trade publications:

1) Standard Rate &amp; Data Services (SRDS) volume on Direct Mail
  List Rates &amp; Data. (A multi-volume reference source available
  in many libraries--other volumes include names and addresses
  for radio stations, etc.)  

2) DM News, a weekly newspaper

3) Direct Marketing, a monthly magazine.

I will send a short handout with more information on specific list vendors as
well as general information on the list industry to anyone who sends me a
business-size stamped self-addressed envelope:

Mary Culnan, School of Business Administration, 
Georgetown University, Washington, D.C.  20057

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
cashless society
</A>
</H3>
<address>
Jolly C. Pancakes
&lt;<A HREF="mailto:jcp@islay.dco.dec.com ">
jcp@islay.dco.dec.com 
</A>&gt;
</address>
<i>
Wed, 30 Jan 91 14:49:25 -0500
</i><PRE>

	Margaret Atwood's book _The Handmaid's Tale_ makes an excellent case
against a cashless, plastic dependent society (doubtless there are other
books which deal with the subject but Atwood's is the one most familiar to
a wide segment of the population).
	At some time prior to the action in the book, everyone in the US has
converted to an "Americard"-type system. The legitimate government is then
overthrown and taken over by a fundamentalist Christian sect which then revokes
all bank accounts owned by women. At a single stroke, half of the adult
population can be immediately disenfranchised (and you can imagine for yourself
all the implications, etc.)
                                             -J.C.Patilla

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-68</DOCNO>
<DOCOLDNO>IA013-000136-B032-192</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.07.html 128.240.150.127 19970217041747 text/html 25481
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:16:13 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 7</TITLE>
<LINK REL="Prev" HREF="/Risks/11.06.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.08.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 7</H1>
<H2> Saturday 9 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Study links leukemia to power lines, TV's 
</A>
<DD>
<A HREF="#subj1.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
A note on electromagnetic fields 
</A>
<DD>
<A HREF="#subj2.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
City in Turmoil 
</A>
<DD>
<A HREF="#subj3.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: the new California licenses 
</A>
<DD>
<A HREF="#subj4.1">
David Redell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: automatic flight and seasickness 
</A>
<DD>
<A HREF="#subj5.1">
Charles Bryant
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Building very reliable systems 
</A>
<DD>
<A HREF="#subj6.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: Predicting System Reliability... 
</A>
<DD>
<A HREF="#subj7.1">
Bruce Hamilton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Electronic traffic signs endanger motorists... 
</A>
<DD>
<A HREF="#subj8.1">
Lars Henrik Mathiesen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Newborn security system 
</A>
<DD>
<A HREF="#subj9.1">
Eric Postpischil
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
Request for info on UNIX viruses 
</A>
<DD>
<A HREF="#subj10.1">
Tom Brendza
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Study links leukemia to power lines, TV's"
</A>
</H3>
<address>
"Martin Minow, ML3-5/U26  09-Feb-1991 0946" 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Sat, 9 Feb 91 06:56:52 PST
</i><PRE>

&gt;From the Boston Globe, Sat. Feb 9, 1991 (page 21, under the obituaries):

Study links leukemia to power lines, TVs (Lee Siegel, Asociated Press)

Los Angeles - Children may face twice the risk of getting leukemia if they live
near power lines, frequntly use hair dryers or watch black-and-white
television, says a study sponsored by electric utilities.  The findings offer
"considerable support for a relationship between children's electrical
applicance use and leukemia risk," said a summary of the study by the
University of Southern California.

The University of Sourthern California study of 464 Los Angeles County children
age 10 and younger is considered important because it was financed by the
Electric Power Research Institute, which had been skeptical of earlier studies
linking cancer to magnetic fields.  The study found children who lived closest
to neighborhood power lines were up to 2 1/2 times more likely to suffer
leukemia.  Frequent use of hair dryers and black-and-white televisions also
increased leukemia risk.

   That's the entire article -- does anyone have more information?
   Martin Minow		minow@bolt.enet.dec.com

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
A note on electromagnetic fields (and an epilog on cashless society)
</A>
</H3>
<address>
"Martin Minow, ML3-5/U26  08-Feb-1991 1429" 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Fri, 8 Feb 91 11:36:03 PST
</i><PRE>

The "risks of electromagnetic radiation" has a new, interesting, champion:
Wayne Greene, publisher of 73 magazine (and the founder of Byte Magazine).
He points out that amateur radio transmitters (especially when used by
Morse code enthusiasts) generate electromagnetic fields that seem to
match some of the more biologically active fields under study.  While
Greene isn't a scientist, he appears to be a reasonably competent
electrical engineer.  His editorial is in the current issue of 73 magazine.

If it hasn't been mentioned already, the "cashless society reading list"
ought to include John Bruner's "The Shockwave Rider."

Martin Minow	minow@bolt.enet.dec.com

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
City in Turmoil
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Fri, 8 Feb 91 18:37:00 PST
</i><PRE>

Infrastructure Collapses - 1000s of civilian casualties.

Is it Baghdad under Tomahawks and laser-guided bombs?

Is it Tel Aviv under SCUDs with nerve gas warheads?

NO! It's London under 6 inches of snow!

If Saddam Hussein could have delivered this lot, he'd be well pleased!

Once again, the Dunkirk spirit is to the fore, as the courageous inhabitants of
this plucky little island, once one of the bastions of civilisation, leaders of
the industrialised west [That's enough nauseating cliches! Get on with it! -
PM.], cope with a disaster the scale and magnitude of which is unparalleled in
the history of mankind, or even in the history of Network South-East, since at
least 1984.

The unsuspecting British were caught completely unawares by the sudden drop 
in temperature last night, to the previously unheard of level of -2 degrees C.
The only warning that the authorities had was a brief announcement from the
Met. Office a mere 5 days ago that things were going to get "...as cold as
a Polar Bear's packed lunch".

Taken by surprise, all the major services collapsed one by one. Trains ground 
to a halt as they ploughed into snow drifts, which, in places, reached depths
of almost 2 inches. Traffic skidded on the roads as gritting and salting 
services, with no practice in dealing with such a major catastrophe for at 
least 2 years, were stretched to the limit.

Telephone services were jammed by businessmen ringing up City University to say
that they could not make it to urgent appointments with software reliability
lecturers because it was impossible to get from Stevenage to London. In the
city itself, those who had not fled at the first sign of snow, got tanked up at
the Pheasant and Firkin and tried to get what sleep they could across two
chairs in their offices, expecting any moment to be hit by one of the
"Snowball" missiles raining down outside.

Normal life seems to have disappeared for ever. Today, students sat in
classrooms with no lecturers. The few lecturers who didn't get home last night
found their classrooms empty, because the students had assumed that lectures
would be cancelled and gone out to build snowmen in Northampton Square.

The fearsome dictator of the regime, John el Major, appeared on television to
rouse the population to new frenzies of resistance. In one speech, he went so
far as to declare: "Yes, it is a bit chilly. I advise everyone to wrap up
warmly."

Defence analyst Brig. Gen. (Ret'd) Sid Spotty said in interview:
"Of course, the apparent total devastation does not mean that the British 
haven't got a lot still in reserve. There must be a lot of logic bombs still
hidden in bunkers. It's amazing how a technologically unsophisticated nation
can still keep their software going in the face of overwhelming bombardment.
I could illustrate what I mean, but the last power cut ****ed my fixed disk."

  [This is Pete Mellor, RISKS network, London, Friday. (The last lecturer left
  in City University before the central heating goes off.)]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: the new California licenses (<A HREF="/Risks/11.04.html">RISKS-11.04</A>)
</A>
</H3>
<address>
David Redell
&lt;<A HREF="mailto:redell@src.dec.com ">
redell@src.dec.com 
</A>&gt;
</address>
<i>
Fri,  8 Feb 91 10:48:06 PST
</i><PRE>

In RISKS 11.04. Mark Gabriel writes:

&gt; I don't see what the privacy problem is here...  If you'll give your
&gt; driver's license to a clerk, you should be prepared to have the clerk
&gt; copy down all of the information on that license.

As I understand his argument, it boils down to:

  There's no reason to distinguish between:
    what a clerk may see,
    what a clerk may write down,
    what a clerk may enter in a computer

Two observations:

1) There can be good reasons for distinguishing between what is seen
   and what is recorded.  Often this principle is applied to mechanical
   recording (e.g. there are many situations in which you may listen
   to a phone conversation but may not record it) but even if the
   recording is manual, there can be good reasons for making the
   distinction.  For example, recent California legislation (effective
   1/1/91) prohibits the practice of writing down credit card numbers
   on checks as ID verification.  A clerk can still ask for a credit
   card as ID, but is not allowed to copy down the information from
   the card.

2) There is an important difference in effort between manually copying
   down information and swiping it through a magstripe reader.  (After
   all, if there weren't, the state wouldn't be going to all this
   trouble to issue magstripe licenses.)  Currently, if you pay by
   check, you greatly reduce the likelihood of your purchasing habits
   ending up in the kind of database described by Mary Culnan in RISKS
   11.06.  Using a magstripe driver's license for check ID will make
   it significantly easier for the merchant to pull together online
   information about you and your purchases.  (Of course, it would be
   possible for the clerk to type in the information manually, but the
   extra effort is enough to represent a qualitative change in
   practicality.)

Dave Redell, DEC Systems Research Center

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: automatic flight and seasickness
</A>
</H3>
<address>
Charles Bryant 
&lt;<A HREF="mailto:ch@dce.ie">
ch@dce.ie
</A>&gt;
</address>
<i>
Wed, 6 Feb 91 18:40:08 GMT
</i><PRE>

In risks 10.83 "Olivier M.J. Crepin-Leblond" &lt;UMEEB37@vaxa.cc.imperial.ac.uk&gt;
quotes from "Le Figaro" concerning computer-controlled low level flight:

&gt;  Unfortunately, the actual pilots cannot stand this type of passive flight.
&gt;Not because by vanity, but because they tend to get sick...

Surely this is not because the plane is not controlled by the pilot, since
there are two-seater aircraft in use where both crewmembers are expected to be
alert when they reach the target. It must be some characteristic of the motion
which is different when a human is in control.

Charles Bryant (ch@dce.ie)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Building very reliable systems
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Fri,  8 Feb 91 10:28:45 EDT
</i><PRE>

There have been a couple of notes on RISKS of late on the problem of building
very reliable systems - say, for the sake of discussion, those for which we
have some good reason to believe that the probablity of failure is less that 
1 in 10^8.  The general problem is hardly new to computer systems, and really
there are only two techniques in existence that can give you this kind of
assurance:

	1.  Testing (whether by explicit test in a lab or by actual use in
		the field) of very large numbers of copies of the system
		at issues.  This is the approach that most of the previous
		notes have mentioned.  That such an approach is being used is
		often clear when you see people talking about things like
		"aggregate experience hours".  The theory here is that running
		100 units for 100 hours apiece gives you the same information
		as running one unit for 10,000 hours.  Reliability of reactors
		is often argued in these terms; for items in mass production,
		where there may be hundreds of thousands if not millions of
		copies, "aggregate experience hours" mount very rapidly.

	2.  Functional decomposition of the system into a number of modules
		such that failure can occur only when ALL the modules fail.
		If there are three modules each of which has a probability
		of failure of 1 in 10^3, the system as a whole has a proba-
		bility of failure of 1 in 10^9 - extremely reliable.  Making
		modules that assured failure probabilities in the 1 in 10^3
		range is relatively easy.  SDIO always uses arguments of this
		form - "defense in depth" is an informal notion of the same
		thing.  An article in the New York Times this Tuesday talked
		about missile defense systems, and showed five successive
		layers.  Even if each layer misses 10% of the incoming
		targets, after five layers only one target in 10,000 makes it
		through - reliable enough to stop almost any conceivable
		attack.  This technique is, of course, also used in reactors
		in the form of multiple redundant safety systems.

Now, the criticism of technique 2 is that the multiplication of failure proba-
bilities is only valid when the failures of the different modules are known
to be uncorrelated.  There are many classic examples of lack of independence,
as for example in the fire that destroyed all the cables for several "indepen-
dent" reactor safety systems (at Brown's Ferry?).  In the software community,
technique 2, under the name of "n-version programming", has been sold as a
way to build reliable software:  Just run multiple independently-written
versions of the same software in parallel.  Unfortunately, Nancy Levenson and
others have shown that the "independently-written" versions cannot be assumed
to have independent failure modes.

So, is technique 2 worthless?  By no means:  It's just often misapplied.  To
use it, you need to establish (by formal techniques, testing, experience in
the field) not just the failure rates for the individual modules, but an
upper bound on failure correlation among modules.  This is by no means impos-
sible to accomplish.  For physical systems, it is often assumed (with little
real "proof") if the modules involved are physically far apart, and especially
if they are based on different physical mechanisms - e.g., a gasoline motor-
generator set as a backup for the main power grid, which in turn is driven
by multiple power sources scattered over the countryside, using a variety of
very different energy sources.  Things get much harder when the modules have
to be packed closely - correlated failures are much more of an issue in an
airplane than on the overall road system of a city.  The "different physical
mechanisms" idea doesn't translate easily to software (though the fifth
shuttle computer, using different hardware, is pretty close).  n-version
programming was a good idea, though it neglected this piece of the technique.
That's not to say that some still-unknown variant of n-version programming
can't be made to work.  In fact, I'd guess that it can be, though it won't
be easy - and I certainly wouldn't want to propose a mechanism.  If so, then
software systems to which we can reasonably ascribe "1 in 10^9" failure
probabilities should be quite buildable.

It's also worth pointing out that technique 1 ALSO relies on an assumption
- often unstated, rarely proven in any sense - that failures across copies of
a system are uncorrelated.  The fact that 100,000,000 digital watches have
calculated the date correctly for the last 5 years tells us nothing at all
about the probability that they will all decided incorrectly whether 2000 is
a leap year.  In general, technique 1 can let you make predictions about
reliability in the presence of external circumstances that occur fairly
frequently (e.g., wear over time); they can tell you nothing about design
flaws dealing with extremely rare circumstances.  Ten thousand "reactor years"
of experience in and of itself tells us nothing about what will happen if
a plane crashes into a containment dome.  (On the other hand, we have hundreds
of thousands of "experience years" with steel-reinforced concrete shells.)

In fact, techniques 1 and 2 are fundamentally the same thing:  One cuts the
world "vertically" between many complete copies of the same system; the other
cuts the system itself "horizontally" across its components.  The same two
issues - reliablity of the individual slices; independence of failure modes -
occurs in both cases.  Either technique can be used to get believable failure
estimates in the 1 in 10^8 (or even better) range.  Such estimates are never
easy to obtain - but they ARE possible.  Rejecting them out of hand is as much
a risk as accepting them at face value.
							-- Jerry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:bruce_hamilton.osbu_south@xerox.com">
bruce_hamilton.osbu_south@xerox.com
</A>&gt;
</address>
<i>
Fri, 8 Feb 1991 10:23:01 PST
</i><PRE>
Reply-To: BHamilton.OSBU_South@xerox.com                    [Ridiculous, eh?]
Subject: Re: Predicting System Reliability...

Re: "...you test hundreds or even thousands of units, all in parallel.  This is
how a disk drive manufacturer can say something like "50,000 Hours Mean Time
Between Failures" -- you didn't think they actually had a single drive that
they tested for 50K+ hours, did you?  I would go so far as to say that no well
known drive manufacturer today has a single drive with 50K hours on it"

I'm no M.E., but it's absurd to suggest that any mechanical system can be
meaningfully tested in parallel.  Fatigue, friction, dust accumulations, etc.
occur as a result of cumulative loads on a single system.

I can't speak for disk drives, but Aviation Week often talks about how one
airframe of each new type is used for fatigue testing, undergoing thousands of
repeated pressurize/depressurize cycles.

--Bruce     BHamilton.OSBU_South@Xerox.COM     213/333-8075

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Electronic traffic signs endanger motorists...
</A>
</H3>
<address>
Lars Henrik Mathiesen 
&lt;<A HREF="mailto:thorinn@diku.dk">
thorinn@diku.dk
</A>&gt;
</address>
<i>
Fri, 8 Feb 91 19:33:45 +0100
</i><PRE>

&gt;I can only
&gt;imagine what we are going to see happen when they start displaying things like
&gt;"LEFT LANE BLOCKED, USE COLLECTORS AHEAD" and 700 motorists first slow down to
&gt;read this and then try and pull over to the two rightmost lanes in order to
&gt;exit off that section of the highway.

I have seen a similar system in use in Belgium or the Netherlands; there,
however, they know enough to limit the information to a few bits. Each lane has
a square display that can show symbols for "go ahead", "don't use this lane",
lane changes (to warn of upcoming closed lanes) and speed limits; the first two
are color-coded (green and red, of course).

The displays stand at intervals of 1/2 to two miles, closest around exits etc..
Since they are visible at a distance of at least 1/2 mile, nobody has to slow
down or think. There were a fair amount of roadworks at the time I was there,
and the system really helped the traffic flow.

&gt;From what pictures I've seen, the amount of text on North American traffic
signs would strike a European traffic engineer with horror.  I'd think that it
all only works because most drivers are commuters who don't really need to read
the signs.

The RISK of the Toronto system is that the computer system can confuse
everybody in a new way every day.

Lars Mathiesen, DIKU, U of Copenhagen, Denmark      [uunet!]mcsun!diku!thorinn
Institute of Datalogy -- we're scientists, not engineers.      thorinn@diku.dk

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Newborn security system
</A>
</H3>
<address>
"Always mount a scratch monkey.  08-Feb-1991 0832" 
&lt;<A HREF="mailto:edp@jareth.enet.dec.com">
edp@jareth.enet.dec.com
</A>&gt;
</address>
<i>
Fri, 8 Feb 91 07:36:21 PST
</i><PRE>

The following is from the Nashua, New Hampshire, _Telegraph_, by Denise Lavoie
of Associated Press, entitled "Hospitals using electronic security to protect
newborns":

     Retailers use them to keep shoplifters from walking off with their
     merchandise.  Now hospitals are using electronic security devices to
     protect a more precious commodity:  newborns. ...

     St. Francis Hospital and Medical Center in Hartford quietly installed
     an electronic surveillance system after a woman kidnapped a
     16-hour-old baby from a maternity ward two years ago.  The girl was
     found unharmed 12 hours later.

     Abington Memorial Hospital in Abington, Pa., has one of the more
     elaborate systems.  There, the infant bracelets trigger an alarm and
     automatically turn on a video camera that records an abduction.

     St. Joseph's Medical Center in Wichita, Kan., normally uses the
     sensitized wrist bracelets, but has experimented with sensitized tags
     that are sewn into babies' clothing, and sometimes, their diapers. ...

     The costs of the systems vary, depending on how sophisticated a
     hospital wants to get.  Some hospitals want a system that triggers an
     alarm, turns on a video camera, and even locks the doors and
     elevators, [Sam] Shirley [of Sensormatic Electronic Corp.] said. ...

Automatic door locks is obviously a disaster waiting to happen -- imagine the
plight of people in a fire who realize they can leave but they cannot take the
babies with them.
				-- edp (Eric Postpischil)

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
request for info on UNIX viruses
</A>
</H3>
<address>
Tom Brendza
&lt;<A HREF="mailto:tomb@bellhow.UUCP ">
tomb@bellhow.UUCP 
</A>&gt;
</address>
<i>
Thu, 7 Feb 91 15:49:06 EST
</i><PRE>

I am requesting the following information as part of a research project
involving computer viruses, prophylactic software, and recovery procedures.
When the research is completed, I will gladly make available any information
that I am able to release to any interested RISKS readers.

Has there ever been a documented occurence of a computer virus attacking
the UNIX operating system outside of laboratory conditions?  I refer
to the strict definition of "computer virus" (i.e. reproducing by attaching
itself to existing code), and not the standard media definition of
computer virus (i.e. just about anything).

Personal anecdotes are also welcome.

Any information regarding this matter (including other places to request
information) would be greatly appreciated.  Please contact me at:

        Tom Brendza,       Bell &amp; Howell, PSC,     5700 Lombardo Center #220
        Cleveland, OH 44131-2531           (216) 642-9060 x288 (voice)
        ..!usenet.ins.cwru.edu!ncoast!ushiva!bellhow!tomb

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-69</DOCNO>
<DOCOLDNO>IA013-000136-B032-219</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.08.html 128.240.150.127 19970217041800 text/html 25556
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:16:30 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 8</TITLE>
<LINK REL="Prev" HREF="/Risks/11.07.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.09.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 8</H1>
<H2> Wednesday 13 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
News of His Death Much Exaggerated 
</A>
<DD>
<A HREF="#subj1.1">
Jeff Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Prison terms for airline computer ticketing fraud 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
PWR system "abandoned owing to technical problems" 
</A>
<DD>
<A HREF="#subj3.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Risks of having a sister 
</A>
<DD>
<A HREF="#subj4.1">
Robyn A Grunberg
</A><br>
<A HREF="#subj4.2">
 Charles Meo
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Study links leukemia to power lines, TV's 
</A>
<DD>
<A HREF="#subj5.1">
Steve Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Predicting System Reliability... 
</A>
<DD>
<A HREF="#subj6.1">
Jay Elinsky
</A><br>
<A HREF="#subj6.2">
 Tanner Andrews
</A><br>
<A HREF="#subj6.3">
     Martyn Thomas
</A><br>
<A HREF="#subj6.4">
 Jay Elinsky
</A><br>
<A HREF="#subj6.5">
 Paul Ammann
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
News of His Death Much Exaggerated
</A>
</H3>
<address>
Jeff Johnson 
&lt;<A HREF="mailto:jjohnson@hpljaj.hpl.hp.com">
jjohnson@hpljaj.hpl.hp.com
</A>&gt;
</address>
<i>
Tue, 12 Feb 91 14:15:18 PST
</i><PRE>

The San Francisco Chronicle (11 Feb 91) has on the second page a photo of a man
pointing to the Vietnam War Memorial wall in Washington, D.C.  The caption
reads:

  "Vietnam veteran Eugene J. Toni of suburban Virginia pointed to his name
  on the Vietnam Memorial in Washington yesterday.  Toni, a 41-year-old 
  former Army sergeant, is one of 14 Americans who can find their own 
  names carved in black granite among the 58,175 dead and missing in the 
  war.  Toni was listed because a wrong number was typed into a computer."

JJ, HP Labs

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Prison terms for airline computer ticketing fraud
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.El_Segundo@Xerox.com">
Hoffman.El_Segundo@Xerox.com
</A>&gt;
</address>
<i>
Wed, 13 Feb 1991 09:50:06 PST
</i><PRE>

In RISKS 7.72, I summarized a 'Wall Street Journal' article about a travel
agency employee charged with breaking into American Airline's computer
reservations system for fraud.

I believe this recent item is the conclusion of that case:

'Los Angeles Times', 11 Feb. '91: TRAVEL AGENTS SENTENCED: Their federal terms
ranged from nearly two years to four years in prison for running a scheme to
defraud American Airlines of frequent-flier tickets totaling $1.3 million
between 1986 and 1987.  Through a computer reservation terminal at North Ranch
Travel Agency in Woodland Hills (CA), the three men changed American Airlines'
records on frequent fliers, crediting fictitious accounts with miles flown by
legitimate passengers not enrolled in the frequent-flier program.  The
defendants then used the miles to apply for free flights, sold them for profit
or gave them to friends and family.  They were convicted after a trial last
year.  (Case No. 90-409.  Sentencing Feb. 5)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
PWR system "abandoned owing to technical problems"
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Wed, 13 Feb 91 13:25:04 GMT
</i><PRE>

The following story is from Nucleonics Week (pubs: McGraw-Hill) Vol 32 No 1
(Jan 3 1991) and No 2 (Jan 10 1991).

Electricite de France (EDF) has decided in principle to abandon the Controbloc
P20 decentralised plant supervisory computer system developed by Cegelec for
EDF's new N4 Pressurised Water Reactor (PWR) series, because of major
difficulties in perfecting the new product, according to EDF officials.

EDF does not yet know [as of Jan 3rd] what it can use in place of the P20 to
control the N4 reactors, the first of which is nearly completed. [They were
meeting to decide the way forward on January 25th. Options include trying to
salvage parts of the P20, or reverting to the N20 system used to control the
earlier P4 series of reactors {the numbering seems maximally confusing}.
Unfortunately, the P20 data acquisition and control uses dual LANs, called
Controbus, whereas the N20 uses cables. If they fall back to the N20, they will
have to design miles of cables into the reactor to replace the LANs.]

A Cegelec official described the P20 as "the most ambitious system you could
imagine". It has distributed control and monitoring, programmable logic
controllers, and 32-bit microprocessors. The N20 used 8-bit microprocessors.

Cegelec blame EDF reorganisations for the cancellation, but EDF's engineering
and construction division say that the problems were strictly technical.
According to Pierre Bacher, the division's president, the failure to achieve
sufficient capacity to process the mass of acquired reactor data with the
original P20 architecture had led to "increasingly complex software programs"
with "increasingly numerous interactions between subsystems". The complexity
apparently grew to the point where modification became difficult and there was
fear that the system could never be qualified [which I take to mean certified
for use].

According to the report, "Ontario Hydro faced a similar situation at its
Darlington station, in which proving the safety effectiveness of a
sophisticated computerized shutdown system delayed startup of the first unit
through much of 1989. Last year, faced with regulatory complaints that the
software was too difficult to adapt to operating changes, Hydro decided to
replace it altogether". [ I hope that Dave Parnas or Nancy Leveson can fill in
the details here.]

Of particular interest to UK RISKS readers is the fact that the P20 system is
on order for the Sizewell B PWR (due to load fuel in November 1993, and the
only remaining scheduled PWR in the UK nuclear power programme).  The P20 "is
to be applied less to safety systems at Sizewell than was planned on the N4",
the report says. [Sizewell has a separate shutdown system, although there are
rumours that all is not well with it.]

There is a fully computerised N4 control room designed to go with the P20
system. If the P20 cannot be salvaged, presumably this will be abandoned too.

[There is more detail in the two reports, which I recommend interested readers
acquire].

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Risks of having a sister
</A>
</H3>
<address>
Robyn A Grunberg
&lt;<A HREF="mailto:rag@yarra.oz.au ">
rag@yarra.oz.au 
</A>&gt;
</address>
<i>
12 Feb 91 02:32:26 GMT
</i><PRE>

On Thursday 7th February, I arrived home from an interstate trip to find a
letter in the mail stating that my driver's license had been cancelled for 6
months.  The cancellation took effect from January 15th, 1991 and was to
continue until July 15th 1991.  The cancellation was due to my driving a car
while exceeding the state limit of .05% alcohol in my bloodstream.  This
interested me greatly as I had not been breathalised nor blood tested on (or
even near) the day in question, stated on the notice as December 17th 1990.

The following day I approached VICROADS who had sent me the notice.  I
explained to them that I was not the offender of the crime and the clerk called
up the details of the charge.  My name was listed, as well as my license
number, however the registration number of the car involved in the incident was
not the registration number of my car.  The clerk suggested I fill out a
Statuary Declaration and file that (along with the notice) with them so that
the department could place the matter under investigation.

I then went to the Police Station where I obtained a Statuary Declaration and
had it witnessed.  I also asked if the officer could check and see whose car
was involved, as it wasn't mine.  The officer checked out the records and
returned to tell me that the car belonged to my sister, who is unlicensed.  He
also explained that I was able to drive as long as I carried the Stat Dec with
me at all times.

Unfortunately, my licensed expired *that day*, so I then had to approach
VICROADS and try and get them to reissue my license.  The clerk would not
reissue my license as it was currently under cancellation.  I showed him the
Stat Dec, which was no use to him (or me) at all, he could not reissue the
license until the matter is resolved.  He suggested I continue driving with the
Stat Dec.  I would not accept this statement from him and asked he put in
writing the fact that I had attempted to renew my license and he had refused to
reissue it.  He would not put it in writing, and suggested I speak to his
supervisor.

So here I am without a license, and waiting for the matter to be heard.  It
would appear that my sister was breathalised and gave my details when asked who
she was.  The car, she explained, she had borrowed from her sister Michealle,
which the police accepted in good faith.  As far as the police are concered,
all you need do is state your name, address and birthdate (which she did) and
the police will accept this and demand that you show your license at a later
date.  Unfortunately, they also went ahead and cancelled my license without any
proof that she was who she stated being, as she hasn't produced the license at
any stage.

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Risks of having a sister
</A>
</H3>
<address>
Charles Meo
&lt;<A HREF="mailto:cm@yarra.oz.au ">
cm@yarra.oz.au 
</A>&gt;
</address>
<i>
13 Feb 91 04:17:20 GMT
</i><PRE>

For non-Australians it is worth pointing out that under unique (and
unsuccessfully opposed) legislation, the burden of proof has been reversed and
police are empowered to record a conviction _without_ any judicial process
whatever and the driver is then obliged to prove his or her _innocence_ in the
matter.

This has enabled local police to generate enormous government revenues as many
traffic infringements are now handled in this way.

I do not know of any other civilised country that would allow this (the spirits
of the old prison governors are alive and well in our seats of government!) and
of course, when this law is translated into computer systems with _no_ safe
guards the situation Robyn has described can happen easily.

C. Meo #6512441/L (Turn to the right!)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Study links leukemia to power lines, TV's
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@ulysses.att.com">
smb@ulysses.att.com
</A>&gt;
</address>
<i>
Sat, 09 Feb 91 23:46:22 EST
</i><PRE>

The original AP story was considerably longer, and included many more
qualifiers.  As noted in the excerpt your paper ran, this study will receive
very careful scrutiny because it was sponsored by an industry group.

The methodology has been described as somewhat suspect by the Electric Power
Research Institute, though the University describes the findings as
significant.  The parents of children being treated for leukemia were quizzed
about their child's activities; their responses were compared with those of a
control group.  (The article did not say how the control group was selected.)
Unfortunately, memory plays funny tricks; in an era where newspapers often seem
to feature the carcinogen of the week, parents of such children may -- and I
stress the word ``may'' -- be more likely to recall suspect behavior patterns.
(For example, the article noted a correlation to home use of pesticides, and to
paternal exposure to spray paint at work during the pregnancy.)

More troubling, the objective measurements taken don't seem to agree with the
incidence of disease.  For example, bedroom electric field strength
measurements did not differ between the two groups, though since the
measurements used were 24 hour averages, there may have been differing peaks.
Similarly, there is no particularly obvious reason to suspect black-and-white
TVs; according to the article, the researchers ``speculated'' that such sets
might be older, and hence might not meet current standards.  (If we're
guessing, I'd guess that such TVs are smaller, and hence would be watched from
a closer distance.)

No statistically significant correlation was found with use of electric
blankets or hair curlers; the former, at least, would (as I recall) contradict
other studies.

The study itself has not been released, and will not be, pending peer review
and publication in a refereed journal.  But a precis was released by the
university and by the sponsors.

		--Steve Bellovin

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Predicting System Reliability...
</A>
</H3>
<address>
"Jay Elinsky" 
&lt;<A HREF="mailto:ELINSKY@IBM.COM">
ELINSKY@IBM.COM
</A>&gt;
</address>
<i>
Sun, 10 Feb 91 00:16:56 EST
</i><PRE>

Re Brad Knowles' statement that disk drives are tested in parallel, and Bruce
Hamilton's rejoinder that mechanical systems can't be tested in parallel: Just
as the airframes in Bruce's example are presumably pressurized and
depressurized at a much higher rate than occurs in actual takeoff-landing
cycles, disk drives can presumably be tested at a higher duty cycle than they
see in actual use.  That is, the manufacturer can keep the heads thrashing
around continually, unlike the typical drive on a desktop computer.  I don't
know how one would accelerate a test on a mainframe disk drive that perhaps
does thrash around 24 hours a day, nor do I know if it's possible to accelerate
the testing of the platter bearings, which are spinning 24 hours a day even on
powered-up but otherwise idle machines.

So, I assume (and I'm no M.E. either) that parallel testing is combined with
tests that tend to accelerate wear of components where possible.

Jay Elinsky, IBM T.J. Watson Research Center, Yorktown Heights, NY

</PRE>
<HR><H3><A NAME="subj6.2">
Re: Building very reliable systems
</A>
</H3>
<address>
Dr. Tanner Andrews 
&lt;<A HREF="mailto:tanner@ki4pv.compu.com">
tanner@ki4pv.compu.com
</A>&gt;
</address>
<i>
Sun, 10 Feb 91 9:51:25 EST
</i><PRE>

) The theory here is that running 100 units for 100 hours gives you
) the same information as running one unit for 10000 hours.
The theory is crocked.  It builds heat slowly. The actual behavior:
	100 hours:	a little warm
	200 hours:	case is softening
	250 hours:	case melts
	257 hours:	catches fire
The times and failure modes will vary, depending on the type of
device in question.

...!{bikini.cis.ufl.edu allegra uunet!cdin-1}!ki4pv!tanner

</PRE>
<HR><H3><A NAME="subj6.3">
Re: building very reliable systems
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Mon, 11 Feb 91 11:47:59 GMT
</i><PRE>

Jerry Leichter &lt;leichter@lrw.com&gt; writes:
.....
: 	2.  Functional decomposition of the system into a number of modules
: 		such that failure can occur only when ALL the modules fail.

: Now, the criticism of technique 2 is that the multiplication of failure proba-
: bilities is only valid when the failures of the different modules are known
: to be uncorrelated. 
..... 
: So, is technique 2 worthless?  By no means:  It's just often misapplied.  To
: use it, you need to establish (by formal techniques, testing, experience in
: the field) not just the failure rates for the individual modules, but an
: upper bound on failure correlation among modules.  This is by no means impos-
: sible to accomplish.
...........
: That's not to say that some still-unknown variant of n-version programming
: can't be made to work.  In fact, I'd guess that it can be, though it won't
: be easy - and I certainly wouldn't want to propose a mechanism.  If so, then
: software systems to which we can reasonably ascribe "1 in 10^9" failure
: probabilities should be quite buildable.

[I have extracted the elements from Jerry's article that I want to disagree
with. I thought the articles as a whole  was a very valuable contribution to
the discussion. I apologise in advance if I have distorted his argument by
selective quotation.]

How can we have confidence that the means by which we have combined the
n-versions (for example, the voting logic) has a failure probability below 1 in
10^9?

How can we be sure that our analysis of the upper bound on failure correlation
among modules is accurate? How accurate does it need to be - does it need to
have a probability of less than 1 in 10^9 that it is grossly wrong? (By
"grossly wrong" I mean wrong enough to invalidate the calculation that the
overall system meets the "1 in 10^9" figure).  This would seem impossible.
Consider, for example, the probability that the common specification is wrong.

I also have a question for statisticians: if we are attempting to build a
system "to which we can reasonably ascribe a 1 in 10^9 failure probability",
what *confidence level* should we aim for, if we are using statistical
methods? Does it make sense to be satisfied with 99% confidence of 1 in
10^9? Or should we aim for 99.9999999%? (I hope the answer isn't simply "it
depends what you mean by "reasonably". I am looking for guidance on how the
failure probability and the confidence levels interact in practical use).

(I suspect that I am missing some contributions to this discussion. I would
be grateful if anyone following-up would also copy me by email).

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<HR><H3><A NAME="subj6.4">
Re: Predicting System Reliability...
</A>
</H3>
<address>
"Jay Elinsky" 
&lt;<A HREF="mailto:ELINSKY@YKTVMZ.BITNET">
ELINSKY@YKTVMZ.BITNET
</A>&gt;
</address>
<i>
Sun, 10 Feb 91 00:11:17 EST
</i><PRE>

Re Brad Knowles' statement that disk drives are tested in parallel, and Bruce
Hamilton's rejoinder that mechanical systems can't be tested in parallel: Just
as the airframes in Bruce's example are presumably pressurized and
depressurized at a much higher rate than occurs in actual takeoff-landing
cycles, disk drives can presumably be tested at a higher duty cycle than they
see in actual use.  That is, the manufacturer can keep the heads thrashing
around continually, unlike the typical drive on a desktop computer.  I don't
know how one would accelerate a test on a mainframe disk drive that perhaps
does thrash around 24 hours a day, nor do I know if it's possible to accelerate
the testing of the platter bearings, which are spinning 24 hours a day even on
powered-up but otherwise idle machines.

So, I assume (and I'm no M.E. either) that parallel testing is combined with
tests that tend to accelerate wear of components where possible.

Jay Elinsky, IBM T.J. Watson Research Center, Yorktown Heights, NY

</PRE>
<HR><H3><A NAME="subj6.5">
Re:  Building very reliable systems (Jerry Leichter, <A HREF="/Risks/11.07.html">RISKS-11.07</A>)
</A>
</H3>
<address>
Paul Ammann
&lt;<A HREF="mailto:pammann@gmuvax2.gmu.edu ">
pammann@gmuvax2.gmu.edu 
</A>&gt;
</address>
<i>
Mon, 11 Feb 91 13:22:03 -0500
</i><PRE>

&gt;	1.  Testing (whether by explicit test in a lab or by actual use in
&gt;		the field) of very large numbers of copies of the system
&gt;	2.  Functional decomposition of the system into a number of modules
&gt;		such that failure can occur only when ALL the modules fail.

The first technique assesses performance directly, and can be applied to any
system, regardless of its construction.  As Jerry points out, various
assumptions must be made about the environment in which the testing takes
place.  The second technique estimates performance from a predictive model.

&gt; [...]                                                                  To
&gt;use [NVP], you need to establish (by formal techniques, testing, experience in
&gt;the field) not just the failure rates for the individual modules, but an
&gt;upper bound on failure correlation among modules.  

The Eckhardt and Lee model (TSE Dec 1985) makes it clear that performance
prediction is much more difficult.  To evaluate a particular type of system,
one must know what fraction of the components are expected to fail over
the entire distribution of inputs.  The exact data is, from a practical
point of view, impossible to collect.  Unfortunately, minor variations in
the data result in radically different estimates of performance.  For a
specific system, it is not clear (to me, anyway) what an appropriate
"upper bound of failure correlation among modules" would be, let alone
how one would obtain it.

&gt;In fact, techniques 1 and 2 are fundamentally the same thing:  One cuts the
&gt;world "vertically" between many complete copies of the same system; the other
&gt;cuts the system itself "horizontally" across its components.  The same two
&gt;issues - reliability of the individual slices; independence of failure modes -
&gt;occurs in both cases.  

I am uncomfortable with merging the issues of direct measurement with those
of indirect estimation.  The difficulties in 1 are primarily system issues;
details of the various components are by and large irrelevant. In technique 2
the major issue is the failure relationship between components.

&gt;                       Either technique can be used to get believable failure
&gt;estimates in the 1 in 10^8 (or even better) range.  Such estimates are never
&gt;easy to obtain - but they ARE possible.  Rejecting them out of hand is as much
&gt;a risk as accepting them at face value.

I am unaware of any application of NVP in which it has been (believably)
demonstrated that components of modest failure probability (say 1 in 10^4)
can been used to generate a system with a very low failure probability
(say 1 in 10^8).  The relatively scant empirical evidence indicates that NVP
might be good for an order of magnitude or so (which may be great, depending
upon the system).  However, there are no guarantees; in certain
circumstances, NVP may well be worse than the use of a single component. 
The real issue is economic: could better systems be built by applying
development resources to other technique(s).  There are strong views on
both sides of the question.

(As a final aside, there are random algorithms that, for certain well
behaved problems, *can* justifiably employ an independence model to obtain
very low system failure probabilities.  However, these techniques are not
in the domain of NVP).

-- Paul Ammann: pammann@gmuvax2.gmu.edu (703) 764-4664
-- George Mason University, Fairfax VA

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-70</DOCNO>
<DOCOLDNO>IA013-000136-B032-243</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.09.html 128.240.150.127 19970217041819 text/html 27198
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:16:48 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 9</TITLE>
<LINK REL="Prev" HREF="/Risks/11.08.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.10.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 9</H1>
<H2> Thursday 14 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Vote-by-fax plan before [CA] Legislature 
</A>
<DD>
<A HREF="#subj1.1">
clarinews via Eric Postpischil
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Douglas goes fly-by-wire 
</A>
<DD>
<A HREF="#subj2.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Vietnam Vet's Memorial article ambiguous 
</A>
<DD>
<A HREF="#subj3.1">
Sam Levitin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Tax Preparation 
</A>
<DD>
<A HREF="#subj4.1">
Peter Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Collection of Evaded Taxes 
</A>
<DD>
<A HREF="#subj5.1">
Cameron Laird
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Singacard anyone? 
</A>
<DD>
<A HREF="#subj6.1">
Bill J Biesty
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: the new CA driver license 
</A>
<DD>
<A HREF="#subj7.1">
Ian Clements
</A><br>
<A HREF="#subj7.2">
 Curt Sampson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: automatic flight and seasickness 
</A>
<DD>
<A HREF="#subj8.1">
Lars-Henrik Eriksson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Follow-up to wireless network 
</A>
<DD>
<A HREF="#subj9.1">
Frank Letts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
4th Annual Ides-of-March Virus &amp; Security Conference 
</A>
<DD>
<A HREF="#subj10.1">
Judy S. Brand
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Vote-by-fax plan before Legislature
</A>
</H3>
<address>
&lt;<A HREF="mailto:clarinews@clarinet.com">
clarinews@clarinet.com
</A>&gt;
</address>
<i>
6 Feb 91 02:49:14 GMT
</i><PRE>
Newsgroups: clari.tw.telecom,clari.news.hot.iraq,alt.desert-storm
Keywords: state government, government, election, politics, fighting,
Reply-To: info@clarinet.com (For More Information)
Article 6531 of alt.desert-storm:
Path:  shlump.nac.dec.com!news.crl.dec.com!deccrl!bloom-beacon!snorkelwacker.
  mit.edu!hsdndev!wuarchive!uwm.edu!lll-winken!looking!clarinews

[Provided for USENET readers by ClariNet Communications Corp.  This copyrighted
material is for one-time USENET distribution only.]       [SEE END OF MESSAGE!]
	SACRAMENTO (UPI) -- Troops fighting in the Persian Gulf could vote in
California elections by using fax machines to cast their ballots under
legislation announced Tuesday.
	The measure, SB293, would amend the state Elections Code to allow
members of the military and other California voters temporarily living outside
the United States to fax absentee ballot applications to county election
officials.
	County officials would then use fax machines to send absentee ballots
to overseas voters, who could return the completed ballots by fax.
	``Even when applications for overseas absentee ballots are received
early in the process, ballots sent halfway around the world sometimes arrive
too late to be returned by mail before the close of polls on Election Day,''
Secretary of State March Fong Eu said.
	``This legislation would allow overseas voters, such as those members
of the armed forces stationed in the Middle East as part of Operation Desert
Storm, to fax their voted ballots back in time to be counted,'' she said.
	The bill is coauthored by state Sen. Milton Marks, D-San Francisco, and
Assemblyman Peter Chacon, D-San Diego.
	Only a few people stationed at U.S. embassies, working at projects
overseas, and members of the military would be expected to take advantage of
the vote-by-fax program, Eu's spokeswoman Melissa Warren said.
	``The numbers aren't huge. We aren't expecting large numbers of people
to participate,'' she said.
	Several states accepted vote-by-fax ballots during last November's
elections, Warren said. If the measure is quickly passed by the Legislature and
signed by Gov. Pete Wilson, the first California election with fax voting would
be the March 19 special elections for two state Senate seats and one Assembly
seat.
	Marks said he would rush the measure through the Legislature. ``It
seems only fitting that at a time when we are engaged in a military struggle
with a ruthless despot, we make this effort to provide our servicemen and women
with the most important franchise of our democratic system -- the right to
vote,'' he said.

    [This item submitted to RISKS by Eric Postpischil &lt;edp@jareth.enet.dec.com&gt;.
    THE RESPONSE FROM clarinews@clarinet.com TO PGN's REQUEST FOR PERMISSION TO
    REUSE THE ABOVE IN RISKS IS From: Brad Templeton &lt;brad@looking.on.ca&gt;:
      "The one time statement indicates you have to ask for more.  You did, so
      I'll grant permission for RISKS in electronic form.  (We are unable to 
      grant permission for print forms).  Brad"]

         [Nice phrase, "take advantage" of it!!! Nice opportunities for 
         voter fraud?  I hope some sort of authentication is planned...  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Douglas goes fly-by-wire
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 13:19:09 GMT
</i><PRE>

McDonnell Douglas has switched to a full fly-by-wire flight control system
for its MD-12X, reports Flight International (13-19 Feb 1991, p4).

"With fly-by-wire we are able to retain the flying qualities of the aircraft
and more easily resemble MD-11 [handling]". "The benefit is predominately in
the area of cross-crew training". "A fly-by-wire aircraft should also be
cheaper to produce". [quotes from MD-12X management].

The control system will be modelled on that developed by GE aerospace for the
USAF C-17 airlifter.

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Vietnam Vet's Memorial article ambiguous (Johnson, <A HREF="/Risks/11.08.html">RISKS-11.08</A>)
</A>
</H3>
<address>
Go Mossad!  14-Feb-1991 0938 
&lt;<A HREF="mailto:levitin@cadsys.enet.dec.com">
levitin@cadsys.enet.dec.com
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 06:39:12 PST
</i><PRE>

RE: Jeff Johnson's article in RISKS 11.08 about the Vietnam Vets' memorial and
a photo in the SF Chronicle, I didn't see the photo, but I do know that there
is a possibility that this situation is *not* due to a typo. On the Vietnam
Veterans' Memorial in DC, there is a set of symbols: one to denote "Killed" (a
cross?), one for "Missing in Action", and "Formerly MIA but now known to have
survived" (a circle?).  The symbol used for MIA can be further carved in one
way to become the symbol for Killed in Action, and can be further carved in a
different way to become the symbol for "Formerly MIA".

Because I don't know which symbol appeared next to Eugene J. Toni's name on the
monument, I won't comment on the possibility of a typographical error, as
reported by the Chronicle. However, the language in the caption (or perhaps the
title of Johnson's RISKS article) makes it too easy for the reader to believe
that Toni was formerly believed killed.

Sam Levitin	Digital Equipment Corporation	

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Tax Preparation
</A>
</H3>
<address>
Peter Jones 
&lt;<A HREF="mailto:MAINT@UQAM.bitnet">
MAINT@UQAM.bitnet
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 12:12:12 EST
</i><PRE>

Today, I saw an advertisement in the mail about a new service on Bell's ALEX
service offering income tax preparation assistance. Customers can supply income
tax information and then order completed forms by mail. The RISKS I see are:

1) Transmitting confidential data in the clear over public phone lines.

2) Giving the service provider potential access to a lot of confidential
   information: SIN (SSN in the US), income, address, credit card number,...
   I found no mention of safeguards of confidential information when I
   browsed the literature.

3) Possible loss of all data entered if the phone connection is broken
   (unless the system provides a checkpoint facility. I don't want to
   spend $$$ to find out.

4) Underestimation of costs. The literature quotes about $12 for mailing,
   and this ALEX service costs $0.15/min. The literature estimates connect
   time to be 30 minutes for a couple. So we're talking about $35 or so here,
   and this may be optimistic (see 3, especially if the phone has Call
   Waiting.)

5) The system only covers certain basic forms (this is stated in the
   literature. So you have to be fairly knowledgeable about income tax to
   decide if the system is worth using.

Peter Jones  (514)-987-3542    UUCP: ...psuvax1!uqam.bitnet!maint
Internet:Peter Jones &lt;MAINT%UQAM.bitnet@ugw.utcs.utoronto.ca&gt;

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Collection of Evaded Taxes
</A>
</H3>
<address>
Cameron Laird
&lt;<A HREF="mailto:news@lgc.com ">
news@lgc.com 
</A>&gt;
</address>
<i>
Mon, 11 Feb 91 09:47:17 CST
</i><PRE>

Comp.risks supports continuing discussions on advantages and disadvantages of
automation of financial transactions; most recent was a proposal for an
AmeriCard, which would facilitate or enforce movement of all purchases to
equipment which would record those purchases.  One of the advantages claimed
for such schemes, including Mr. Gorbachev's latest "monetary reform", is that
they'll flush not-fully-taxed activities into the spotlight of tax enforcement
agencies.  For example, if you rebuild your neighbor's carburetor in exchange
for him removing the dying tree in your backyard, the Internal Revenue Service
expects you both to declare those (imputed) incomes and pay corresponding taxes
on them.  Thus, as an article in the 21 January 1991 *Forbes* asks,
"Politicians of all stripes love to claim the federal deficit can be cut by
cracking down on tax cheats.  Why cut spending when the IRS has $78 billion in
total accounts receivable and is losing $100 billion a year to tax evasion?"

The article's conclusion: "The argument ... grossly exaggerates the IRS'
ability to raise more money through tougher enforcement."  Note that the Agency
has strong institutional pressures to overestimate its capabilities.  Most
interesting from the point of view of economic science is the (unsupported)
assertion that, "As for outright cheating, even the IRS' toughest audits find
less than half the evasion it claims goes on."  In the midst of tendentious
estimates and murkiness, there's a real value in looking at the actual
operating experience of, for example, the IRS.

I've marked the distribution of this note for "world" because it's at least as
great an issue outside the USA.  France, for example, sometimes prides itself
on the vigor with which its citizens fail to co-operate with tax agencies; from
my little experience there, though, I can report that people were generally
more law-abiding than they should have to be, given the confusion those
agencies generate.

The article does make one incomplete reference to a scholarly study.  The
reporter might be willing to help someone pursue the subject; I've known some
who do, and some who don't.

I summarize: for the reasons others have already stated in comp.risks, tax
enforcement does *not* yield the windfalls some expect of it; in particular,
the IRS' own records suggest much lower returns than they estimate in their
reports to Congress.

Cameron Laird		USA 713-579-4613	USA 713-996-8546 

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Singacard anyone?
</A>
</H3>
<address>
Bill J Biesty
&lt;<A HREF="mailto:wjb@edsr.UUCP ">
wjb@edsr.UUCP 
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 09:33:35 CST
</i><PRE>

&gt;From the Wall Street Journal Wednesday, February 13, 1991, p.A7 c.1

  "Singapore Equals Push Buttons"
	From cashless shopping to electronic paperwork and even a computerized
  pig auction, Singapore is plugging its 2.6 million people into electronic
  grids linking the entire island nation.  It plans to build grids for
  shopping, booking tickets, checking data and sending documents.
	Singapore's small size and centralized bureaucracy simplified
  establishing the electronic groundwork.  All citizens carry a numbered
  identification card, allowing cross-indexing of data.  "The purpose ... is to
  turn Singapore into an intelligent island in which IT [information
  technology] will be fully exploited to improve business competiveness and,
  more importantly, to enhance the quality of life," and education ministry
  official said.  A master plan, IT 2000, will be unveiled at year end.
	Already, TRadeNet lets companies submit data electronically to the
  state and accounts for 90% of all trade documents.  The Network for
  Electronic Transfers, a cashless shopping system, has been operating for five
  years and is used by more than one-third of the population.
	Other networks include StarNet for air cargo, MedNet for Medical
  claims, and LawNet for company registry.  Coming next: "Smart Town," linking
  households.

I think it was mentioned in Risks, but was mentioned in WSJ that Singapore
plans to install sensors in cars and roads and start taxing vehicle owners
based on usage rather than an average fee to cover maintenance costs of roads.

Considering Singapore's government, widely considered autocratic, though it is
democratically elected, this will probably be less than beneficial to the entire
populace.  (The Editorial and Letters pages of the WSJ recently had a debate on
this.  Nepotism seems to be one indicator. Sorry no dates.)

The risk envolved is for those people whose idea of "quality of life" has
nothing to do with feeding the commercial/consumer dynamo.  Then again they
probably don't live in Singapore.

Another is as long as you're a good little consumer and a good little
entrepreneur you're ok.  The ability to catch laggards and other non-productive
types cannot be underestimated.  You've heard of sin taxes, Lazy Tax anyone?

What the article doesn't mention is how much independence exists for the
businesses that use the Nets.  Are the Nets a government service or control of
all players using them?  Will the Nets provide a situation similar to the
national airline reservation system(s) or will they nationalize industries
under monarchical control.

Bill Biesty, Electronic Data Systems Corp., Research and Advanced Dev., 7223
Forest Lane, Dallas, TX 75230 edsr.eds.com!wjb wjb@edsr.eds.com 214-661-6058

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
The new CA driver license (<A HREF="/Risks/11.07.html">RISKS-11.07</A>)
</A>
</H3>
<address>
Ian Clements
&lt;<A HREF="mailto:ian@lassen.wpd.sgi.com ">
ian@lassen.wpd.sgi.com 
</A>&gt;
</address>
<i>
Mon, 11 Feb 91 8:00:32 PST
</i><PRE>

 In RISKS 11.04 Mark Gabriel writes about privacy issues concerning the new CA
drivers license.  In issue 11.07 David Redell responds with two points
concerning recent privacy legislation and the clerks right to certain parts of
the information.

 Like many modern marvels, the magnetic strip is easily defeated.  If you're
concerned about what a clerk may or may not record or know about you, run a
magnet down the stripe.  This will render the stripe useless and the clerk (or
police officer) will once again have to rely on mechanical recording.

 I would be more concerned about the possibilities for abuse of this new
technology.  Insurance companies will surely ask potential customers for a
drivers license to check the driving record (given CA's new insurance rules,
there is much incentive to bit twiddle)--how long will it be before someone
figures out how to rearrange bits on the stripe?

--ian   Ian Clements   ian@sgi.com 415/962-3410 

</PRE>
<HR><H3><A NAME="subj7.2">
Re: The new California licenses (Hibbert, <A HREF="/Risks/11.03.html">RISKS-11.03</A>)
</A>
</H3>
<address>
Curt Sampson
&lt;<A HREF="mailto:curt@cynic.wimsey.bc.ca ">
curt@cynic.wimsey.bc.ca 
</A>&gt;
</address>
<i>
Sat, 09 Feb 91 10:40:56 PST
</i><PRE>

&gt; This track will only contain 40 bytes of information, and will only 
&gt; contain the name, driver' license number, and expiration date.

This would not likely leave more than 32 bytes for the person's name.
Yet another problem.  &lt;Sigh&gt;

Coercivity is a measure of how much magnetic energy it takes to imprint or
erase a magnetic medium, and it is measured in oersteds.  The typical
coercivity of a cassette tape would be in the 280-380 oersted range.  The
typical coercivity of a high-coercivity tape (such as DAT or 8 mm video) would
be 1000-1400 oersteds.

30 orsteds is quite low (surprisingly low, in fact).  That may explain why my
bank card has been "zapped" twice in the past year.  3600 is quite high, but a
standard videotape eraser might be able to affect it if you put the stripe
right up against the surface.  (An audiotape eraser would not affect it.)

I have little doubt that a dedicated hardware hacker would be able to
come up with a unit to read from and write to the cards with little
difficulty.  The hardest part would probably be machining a head to read
the stripe.  I wonder if the data is going to be encrypted in any way?

cjs curt@cynic.wimsey.bc.ca curt@cynic.uucp {uunet|ubc-cs}!van-bc!cynic!curt

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: automatic flight and seasickness (Bryant, <A HREF="/Risks/11.07.html">RISKS-11.07</A>)
</A>
</H3>
<address>
Lars-Henrik Eriksson
&lt;<A HREF="mailto:lhe@sics.se ">
lhe@sics.se 
</A>&gt;
</address>
<i>
Sun, 10 Feb 91 11:33:17 GMT
</i><PRE>

   [Re: Bryant on Olivier M.J. Crepin-Leblond" &lt;UMEEB37@vaxa.cc.imperial.ac.uk&gt;
   in <A HREF="/Risks/10.83.html">RISKS-10.83</A>]

I believe the original poster is right. I am a private pilot, and I have
noticed numerous times, that I do have a tendency to get sick when I go along a
a passenger. I have even noticed this tendency when flying the aircraft myself
with an instructor who tells me what to do.  When a fly as the
pilot-in-command, I have *no* problems with airsickness even on extended
flights in rough weather.

Lars-Henrik Eriksson, Swedish Institute of Computer Science, Box 1263, S-164 28
KISTA, SWEDEN      +46 8 752 15 09       

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
follow-up to wireless network
</A>
</H3>
<address>
frank letts 
&lt;<A HREF="mailto:letts@ficc.ferranti.com">
letts@ficc.ferranti.com
</A>&gt;
</address>
<i>
Sun Feb 10 13:16:10 1991
</i><PRE>

There seems to be some question regarding the legality of the radio telemetry
testing I described in an earlier post.  The story was presented with a bent
toward the (objectively) humorous and the obvious risks presented by the
wireless network.  Left out was some information that, by its absence, led some
to believe the the operation was an illegal one carried out by "sickos" and
technically incompetent bozos.

The oil company held a valid FCC license for data transmission over the
frequency in its normal operation mode, and a temporary permit for same at low
power in the Houston facility.  While looking for the source of the
interference we did find some bad dummy loads which we replaced, but, following
that, our installation was on spec and fully legal.  We did determine that the
delivery driver(s) were running linear amps and were bleeding over onto
adjacent frequencies when transmitting.  That would explain their interfering
with our operation, but not our interfering with them.  Odds were that the
driver(s) only heard the buzzing while driving directly past our building.
They should have had no problem receiving or transmitting.

As far as the personnel are concerned, the engineer and technicians all held
FCC tickets, were highly qualified for the work, and had been in the business
for many years.  I have been doing data acquisition and communications software
for about twenty years and consider myself somewhat competent in the area.
None of us are necessarily sickos.  One of the techs probably qualifies as a
bozo, but he's a nice enough fellow and a decent tech.

I hope that this quiets any unrest out there.

Frank Letts, Ferranti International Controls Corp., Sugar Land, Texas
       (713)274-5509 

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">

</A>
</H3>
<address>
Judy S. Brand
&lt;<A HREF="mailto:jsb@well.sf.ca.us ">
jsb@well.sf.ca.us 
</A>&gt;
</address>
<i>
Fri, 8 Feb 91 08:54:37 -0500
</i><PRE>
Subject: 4th Annual Ides-of-March Virus &amp; Security Conference

	     Who SHOULD attend this year's Ides-of-March
	  Fourth Annual Computer VIRUS &amp; SECURITY Conference
		 at the New York World Trade Center?
 
MIS Directors, Security Analysts, Software Engineers, Operations
Managers, Academic Researchers, Technical Writers, Criminal
Investigators, Hardware Manufacturers, Lead Programmers 
who are interested in:
 
WORLD-RENOWNED SECURITY EXPERTS:      CRIMINAL JUSTICE LEADERS:
     Dorothy Denning - DEC                  Bill Cook - US Justice Dept
     Harold Highland - Comp &amp; Security      Donn Parker - SRI Intl
     Bill Murray - Deloitte &amp; Touche        Steve Purdy - US Secret Service
     Dennis Steinauer - NIST                Gail Thackeray - AZ Attorney
 
UNIVERSITY RESEARCH LEADERS:        LEGAL/SOCIAL ISSUES EXPERTS:
     Klaus Brunnstein - Hamburg          Mike Godwin &amp; Mitch Kapor - EFF
     Lance Hoffman - GWU                 Emmanuel Goldstein - 2600 Magazine
     Eugene Spafford - SERC/Purdue       Tom Guidoboni - (R.Morris' lawyer)
     Ken van Wyk - CERT/CMU              Marc Rotenberg - CPSR
 
PLUS Fred Cohen, Ross (FluShot) Greenberg, Andy (DrPanda) Hopkins, and
over 40 MORE!
 
Over 35 PRODUCT DEMOS including: include Candle's Deltamon, HJC's
 Virex, McAfeeSCAN, Symantec's SAM, ASP 3.0, DDI's Physician,
 Gilmore's FICHEK, Certus, FluShot Plus, Iris's Virus Free, 5D/Mace's
 Vaccine, Norton Utilities, PC Tools, Quarantine, Viruscan, Panda's
 Bear Trap, Disk Defender, Top Secret, Omni, ACF2, RACF and OTHERS AS
 REGISTRANTS REQUEST.
 
FIFTY PRESENTATIONS INCLUDE:
 Security on UNIX Platforms, Tips for Investigators, HURRICANE Recovery,
 Dissecting/Disassembling Viruses, 6 Bytes for Detection, LAN Recovery,
 ISDN/X.25/VOICE Security, Encryption, Apple's Security, EARTHQUAKE Recovery,
 IBM's High-Integrity Computing Lab, US/Export Issues, 22-ALARM Fire Recovery,
 Publicly Available Help, Adding 66% More Security, NETWARE VIRUS Recovery,
 Next Generation of Computer Creatures, THE WALL STREET BLACKOUT Recovery,
 Mini Course in Computer Crime, Great Hacker Debate, REDUCING Recovery Costs,
 S&amp;L Crisis: Missing DP Controls, OSI and the Security Standard, Virus Myths,
 Viruses in Electronic Warfare, US Armed Forces Contracts for New Ideas....
 
INTERESTED? ONLY $275 one day (Thurs 3/14 - Fri 3/15) or $375 both days:
 *  Bound, 600-page Proceedings containing ALL materials - no loose paper!
 *  Eight meal breaks, including Meet-the-Experts cocktail party 107th Floor
 *  2-day track of product demo's     *  2-day course for ICCP Security exam
 *  Full-day Legal &amp; Justice Track    *  Full-day disaster Recoveries Track
There is a $25 discount for ACM/IEEE/DPMA members.
Fourth member in each group gets in for no charge!

To register by mail, send check payable to DPMA, credit card number
 (VISA/MC/AMEX), or purchase order to:
      Virus Conference
      DPMA
      Financial Industries Chapter
      Box 894
      New York, NY 10268
 or FAX to (202) 728-0884.  Be sure to include your member number if
 requesting the discounted rate.  Registrations received after 2/28/91
 are $375/$395, so register now!

For registration information/assistance, call (202) 371-1013

Discounted rates available at the Penta Hotel.  $89 per night.  Call
 (212) 736-5000, code "VIRUS"
Discounted airfares on Continental Airlines, call (800) 468-7022, code EZ3P71 

Sponsored by DPMA Financial Industries Chapter, in cooperation with
 ACM SIGSAC and IEEE-CS.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-71</DOCNO>
<DOCOLDNO>IA013-000136-B032-269</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.10.html 128.240.150.127 19970217041855 text/html 30637
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:17:10 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 10</TITLE>
<LINK REL="Prev" HREF="/Risks/11.09.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.11.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 10</H1>
<H2> Thursday 14 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
On-line in Saudi Arabia 
</A>
<DD>
<A HREF="#subj1.1">
Steve Elias via Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Serious bug in SVR3.2 gives root access easily 
</A>
<DD>
<A HREF="#subj2.1">
Patrick Wolfe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Risks of large disk drives 
</A>
<DD>
<A HREF="#subj3.1">
Roger H. Goun
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: The Risks of Having a Sister 
</A>
<DD>
<A HREF="#subj4.1">
David Ruderman
</A><br>
<A HREF="#subj4.2">
 John Sullivan
</A><br>
<A HREF="#subj4.3">
 Charles Meo
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Guilty until proven innocent 
</A>
<DD>
<A HREF="#subj5.1">
Andrew Koenig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Parking Ticket Notice 
</A>
<DD>
<A HREF="#subj6.1">
Robert McClenon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Reinterpretation of the term "Computer Security" 
</A>
<DD>
<A HREF="#subj7.1">
Barry Schrager
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
NCCV: COMPUTING &amp; VALUES CONFERENCE, 12-16 Aug 1991 
</A>
<DD>
<A HREF="#subj8.1">
Walter Maner
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
On-line in Saudi Arabia
</A>
</H3>
<address>
"Martin Minow, ML3-5/U26  14-Feb-1991 1444" 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 11:47:35 PST
</i><PRE>

Date: Fri, 08 Feb 91 16:06:19 -0500
From: Steve Elias &lt;eli@pws.bull.com&gt;
Subject: funny sco unix story
 
[...] at sco last week, they told me that their customer service line had
received a call from a US Army dude who was calling from inside his M1 tank in
the Saudi desert.  apparently, SCO Unix runs on one of the computers in the
tank.  the customer service person pointed him to the SCO BBS system and he
dialed it and downloaded the bug fix.
 
Steve Elias, eli@spdcc.com; 617 932 5598 (voicemail), 508 294 7556 (work phone)

                [Hmm.  I wonder if someone could dial up the tank's Unix?  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
serious bug in SVR3.2 gives root access easily
</A>
</H3>
<address>
Patrick Wolfe
&lt;<A HREF="mailto:pwolfe@kailand.kai.com ">
pwolfe@kailand.kai.com 
</A>&gt;
</address>
<i>
Wed, 13 Feb 1991 12:19:18 CST
</i><PRE>

I learned last night that the Esix operating system (really AT&amp;T Unix System
V/386 Release 3.2) which I run on my PC at home suffers from the serious
security bug recently reported in comp.unix.sysv386.  Someone posted a 51 line
(commented) program which shows how any user with access to a shell and C
compiler can obtain root priviledges with no effort at all.

I'm not familiar with all the details, but apparently it has something to do
with a bug in the numeric coprocessor emulation library and the os which makes
the user page (where uid information is stored) writable to the process.  The
posted program changes it's own effective uid and gid to zero (becoming root),
and changes the permissions on /etc/{passwd,shadow} to 666 (world writable).

Apparently the bug exists in Esix 3.2, Interactive Unix version 2.02 and 2.2,
and possibly others, but not in SCO Xenix or Unix, nor Intel's Unix 3.2 (these
give memory faults).  Interactive V2.2 users (and possibly some others - not
Esix) can fix the problem by installing a 387, changing the value of one kernel
variable (UAREARW) and rebuilding the kernel.

In my opinion, the rest of us are probably screwed.  I seriously doubt any of
these OS vendors will stop working on SVR4 to fix this bug in SVR3.2, except
possibly for customers who pay for software maintenance.  Many vendors are just
about ready to ship their SVR4 release.  I suspect most will tell those of us
who don't pay for maintenance that we must upgrade to fix the bug.

It just goes to show that it was a good idea when I set my bbs up to run in a
"chroot" filesystem, where even if a user could break out of the bbs program
into a shell, there is no compiler (in fact, there are hardly any useful
commands at all) to mess around with.

Patrick Wolfe, System Programmer/Operations Manager, Kuck &amp; Associates, 1906 
Fox Drive, Champaign IL USA 61820-7334, voice 217-356-2288, kailand!pat

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks of large disk drives
</A>
</H3>
<address>
"Roger H. Goun  12-Feb-1991 1602" 
&lt;<A HREF="mailto:goun@ddif.enet.dec.com">
goun@ddif.enet.dec.com
</A>&gt;
</address>
<i>
Wed, 13 Feb 91 02:03:05 PST
</i><PRE>

&gt;From an article in the USENET newsgroup clari.nb.general, announcing a new 
large-capacity Winchester disk drive from Fujitsu:

"You used to have to rely on 8 inch drives for capacity, performance and 
reliability," added [Mike] Gluck [senior vice president of Fujitsu America's 
Computer Products Group].  "Now we have put mainframe reliability into a 5.25 
inch disk drive.  Our MTBF (mean time between failure) is 200,000 hours and the 
advantage to using one large capacity drive like ours over three smaller drives 
is that even if the smaller drives have an equal MTBF, there are three chances 
to have a problem."

I see two risks here:

- As has recently been beaten to death in RISKS, the proffered MTBF figure is
  suspect, unless Fujitsu has actually withheld this product from market long
  enough to test a statistically significant number of samples for nearly 23
  years;

- Mr. Gluck seems to think that having a single point of failure is less risky
  than having three separate (though of course not entirely decoupled) points
  of failure.

Roger H. Goun, Digital Equipment Corporation, 110 Spit Brook Road, ZKO2-2/O23, 
Nashua, NH 03062 USA, +1 603 881 0022, goun@ddif.enet.dec.com or 
goun%ddif.enet@decwrl.dec.com, {uunet,sun,pyramid}!decwrl!ddif.enet!goun

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The Risks of Having a Sister (Any well informed sibling will do)
</A>
</H3>
<address>
David Ruderman
&lt;<A HREF="mailto:ruderman@sbcs.sunysb.edu ">
ruderman@sbcs.sunysb.edu 
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 16:54:12 EST
</i><PRE>

A few years ago, I encountered virtually the same problem with my driving
record.  I went to motor vehicles for my routine license renewal (every
three years), when I noticed on the bottom line a small comment that 
read "Last Conviction Speed In Zone $50".  

I was directed to the violations department, where they quickly
consulted my records on a terminal.  They told me that one year earlier
I had gotten a speeding ticket and evidently paid it.  They told me
that I had other tickets as well.  I was told that if I wanted a list
of 'my' violations I would have to send $5 or so to Albany (NY) and
they would send me a printout.

I discovered that my brother had simply told the police that he was me, and he
did not have his license with him (his was nearly suspended).  He then paid the
tickets.

The Risks are clear:
-  There was no confirmation of my brother's identity.
-  He was able to plead me guilty by mail.  
-  I was not provided with a routine way to review my driving record for 
   possible errors.  
-  The last risk is that I was not able to clean up my record, 
   since the only way would be to turn in my brother to the authorities.

David Ruderman, Department of Computer Science, SUNY at Stony Brook, 
Stony Brook, NY 11794-4400 ruderman@sbcs.sunysb.edu (516) 632-7675

</PRE>
<HR><H3><A NAME="subj4.2">
Re: risks of having a sister
</A>
</H3>
<address>
&lt;<A HREF="mailto:sullivan@poincare.geom.umn.edu">
sullivan@poincare.geom.umn.edu
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 04:02:13 CST
</i><PRE>

In the states of the USA with which I'm familiar, one must be a licensed driver
to register a car.  This allows a driver's license number to be associated
with, say, unpaid parking tickets.  I don't think that moving violations (say
in the case of a hit&amp;run driver whose plates are observed) can be ascribed to
the owner of the car without other evidence.  But it does seem that such a rule
might be useful in Australia to discourage unlicensed drivers.

John Sullivan  sullivan@geom.umn.edu

</PRE>
<HR><H3><A NAME="subj4.3">
Re: Risks of having a sister
</A>
</H3>
<address>
Charles Meo
&lt;<A HREF="mailto:cm@yarra.oz.au ">
cm@yarra.oz.au 
</A>&gt;
</address>
<i>
13 Feb 91 04:17:20 GMT
</i><PRE>

For non-Australians it is worth pointing out that under unique (and unsuccess-
fully opposed) legislation, the burden of proof has been reversed and police
are empowered to record a conviction _without_ any judicial process whatever
and the driver is then obliged to prove his or her _innocence_ in the matter.

This has enabled local police to generate enormous government revenues as many
traffic infringements are now handled in this way.

I do not know of any other civilised country that would allow this (the spirits
of the old prison governors are alive and well in our seats of government!) and
of course, when this law is translated into computer systems with _no_ safe
guards the situation Robyn has described can happen easily.
                                                                 C. Meo

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:ark@research.att.com">
ark@research.att.com
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 16:46:32 EST
</i><PRE>
Subject: guilty until proven innocent

C. Meo says he `does not know of any other civilised country' that would allow
the burden of proof to be reversed in the event of traffic violations.
Unfortunately, that is becoming more common here as well -- several states have
empowered police to seize licenses of people tho fail breath alcohol tests.  It
then becomes the problem of the accursed -- um, accused, to prove innocence.
Yeah, right.

I know a guy who was stopped for speeding once.  They looked him up and
discovered his license had been revoked, so they carted him off to the police
station and booked him for driving while on the revoked list.  He protested
that (a) he had never been informed that his licence had been revoked, and (b)
he had not done anything that should have caused his license to be revoked.

When his case came to trial, the state readily admitted that both (a) and (b)
above were true.  However, his name was indeed on the revoked list, albeit
erroneously, and he was accused of driving while his name was on the revoked
list, so he should be found guilty.  The judge agreed and found him guilty.
Afterwards, he asked what he might have done to avoid this.  The answer was
that it was his responsibility to check the revoked list to see if his name
turns up there.  He left the state shortly thereafter, and I don't suppose he
has been back since.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Parking Ticket Notice
</A>
</H3>
<address>
Robert McClenon 
&lt;<A HREF="mailto:76476.337@compuserve.com">
76476.337@compuserve.com
</A>&gt;
</address>
<i>
14 Feb 91 00:46:16 EST
</i><PRE>

     I received from the District of Columbia Government Bureau of Traffic
Adjudication a Notice of Delinquent Parking Tickets today for three tickets
issued in December 1990.  The tickets were all issued to a Volkswagen with
plate number 457-143 in a section of Washington that I have not visited.  I do
not own a Volkswagen.

     Prior to October 1987 I owned a Ford Fiesta with plate 457- 143.  Shortly
before October 1987 I lost the front plate.  Since I was preparing to trade it
in for a new van I did not replace the plate, and did not report it as lost.  I
simply requested a new plate rather than transferring an old plate.  The plate
expired in March 1988.

     Either the plate number was reissued, or someone found the lost plate and
is using it illegally.  If it was reissued, the problem is that the database
shows the wrong name as the owner.  If it was lost and found and is being used
illegally, then the system should have shown that the registration is no longer
valid.  Besides, if that old plate is being used, tickets should also have been
issued for using an expired license plate without renewal stickers.

     The specific RISK here is: "D.C. motor vehicle registration will not be
renewed if you have outstanding parking tickets."  The notice doesn't say that
it only restricts the renewal of this Volkswagen with plate 457-143.  They also
have my name, and presumably know that I now own a 1988 van.  A more serious
risk could arise with a system with this vulnerability in a state where parking
tickets are considered to be petty crimes, in that an arrest warrant could be
issued.  (Parking tickets in the District of Columbia are civil rather than
criminal.  That reduces the risk but doesn't eliminate it.)
                                                               Robert McClenon

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Reinterpretation of the term "Computer Security"
</A>
</H3>
<address>
Barry Schrager 
&lt;<A HREF="mailto:71370.2466@compuserve.com">
71370.2466@compuserve.com
</A>&gt;
</address>
<i>
08 Feb 91 23:02:59 EST
</i><PRE>
 
Mr Dixon seems to be perturbed that one of the moguls in his business has
determined that all data should be protected rather than just "sensitive
data."  Just who is going to be so totally aware of what the implications of
all data are to make an absolutely correct decision so that all company
sensitive information will be protected.  It is obviously much more secure
and definitely safer to assume that all data has some importance and
therefore should has some measure of protection.  If this is the case then
the data creator/owner or security manager can determine who should have
access to share this data.
 
If all data is protected by default then the error of omission is just an
inconvenience -- if only "sensitive data" is protected then the error of
omission is disclosure of sensitive data and presumably some corporate harm.
 
The security product I designed for large IBM Computer Systems -- ACF2 --
was the first product in that arena to protect all data by default and it
was done with less overhead than the products that presumably protected only
sensitive data.  Given this, there exists no reason to not protect all data
and determine who to share it with rather than guess which data should be
protected or not protected.   Thousands and thousands of computer sites
licensed this package so therefore they also felt that this was the correct
way to do this.
 
The SHARE Security Project Requirements for future data security in IBM
Operating Systems also called for all data to be protected as a default in
1974.  Obviously, Mr Dixon's business mogel is not alone with his
presumptions  -- in fact, I think he's right.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
COMPUTING &amp; VALUES CONFERENCE, N C C V / 91, Aug 12-16 1991
</A>
</H3>
<address>
Walter Maner
&lt;<A HREF="mailto:maner@bgsuvax.UUCP ">
maner@bgsuvax.UUCP 
</A>&gt;
</address>
<i>
9 Feb 91 17:35:09 GMT
</i><PRE>

NCCV/91 THE NATIONAL CONFERENCE ON COMPUTING AND VALUES, 
AUGUST 12-16, 1991, NEW HAVEN, CONNECTICUT  FIRST CALL FOR PARTICIPATION
 
The National Conference on Computing and Values will address the broad topic of
Computing and Values by focusing attention on six specific areas, each with its
own working groups.
 
      -  Computer Privacy &amp; Confidentiality
      -  Computer Security &amp; Crime
      -  Ownership of Software &amp; Intellectual Property
      -  Equity &amp; Access to Computing Resources
      -  Teaching Computing &amp; Values
      -  Policy Issues in the Campus Computing Environment

CONFERENCE HIGHLIGHTS -- Details follow

o  Active role for all attendees
o  Free associate membership in the Research Center on Computing and Society
o  Valuable take-home materials
o  A user-friendly conference
o  A family-friendly conference
o  Unique aspects
o  Members of the Planning Committee
o  Partial list of confirmed speakers
o  Modest cost
o  Further information and registration
 
ACTIVE ROLE FOR ALL ATTENDEES
 
A special feature of the National Conference on Computing and Values will be
the active role of all attendees.  Each attendee will belong to a small working
group which will "brainstorm" a topic for two mornings, then recommend future
research.  On the third morning, each group will report the results of its
activities to the assembled conference.  (Group reports will be incorporated
into the published proceedings of the conference.)

In addition, each person will be able to attend five keynote addresses, three
track addresses, three track panels, two evening kick-off events, two evening
enrichment events, and four days of exhibits and demonstrations.
 
FREE ASSOCIATE MEMBERSHIP IN THE RESEARCH CENTER ON COMPUTING AND SOCIETY
 
Every attendee can become an Associate of the Research Center on Computing and
Society for two years free of charge.  Associates receive the Center
newsletter, announcements of Center projects, lower registration fees at Center
sponsored events, and access to the Center's research library on computing and
values.
 
VALUABLE TAKE-HOME MATERIALS
 
The conference will provide a wealth of materials on computing and values,
including articles, government documents, flyers about organizations and
publications, a special "Resource Directory on Computing and Society," and a
"track portfolio" of materials for each of the six tracks.  Every attendee will
receive a copy of the resource directory, the track portfolios, plus many other
useful materials.
 
A USER-FRIENDLY CONFERENCE
 
The conference will be held on a residential campus at a quiet time between
semesters.  Adequate time for meals, conversations, and relaxation is
scheduled.  There will be social events, such as an ice cream social and a
conference barbecue.  In addition, various lounges will have coffee, tea,
juice, and snacks all day to encourage conversation among participants.  The
conference will include individuals from six different professional groups:
Computer Professionals, Philosophers, Social Scientists, Public Policy Makers,
Business Leaders, and Academic Computing Administrators.
 
A FAMILY-FRIENDLY CONFERENCE
 
Family members of attendees will be able to use university facilities, such as
the swimming pool, playing fields, tennis courts, and TV lounges.  In addition,
a day-care center, baby sitting service, and bus trips to local tourist
attractions will be available.  Attendees' spouses will be welcome at
conference social events; and both spouses and children may attend the
conference barbecue.
 
UNIQUE ASPECTS
 
The National Conference on Computing and Values will be one of most significant
assemblies of thinkers on computing and values ever to gather in one place.
 
Among the nearly 50 speakers who will address the 500 conference attendees are
philosophers, computer scientists, lawyers, judges, social scientists,
researchers in artificial intelligence, and experts in computer security.
 
The conference also will feature one of the most comprehensive exhibits of
materials ever assembled on computing and values.  The exhibit will including
books, journals, articles, government documents, films, videos, software,
curriculum materials, etc.
 
Hosted by Southern Connecticut State University, including the Research Center
on Computing and Society, Philosophy Department, Computer Science Department,
Adaptive Technology Laboratory, and the journal Metaphilosophy.
 
Planned in cooperation with: The American Association of Philosophy Teachers,
the American Philosophical Association, the Association for Computing
Machinery, the Canadian Philosophical Association, Computer Professionals for
Social Responsibility, and the Institute of Electrical and Electronics
Engineers.
 
Funded, in part, by grants from the National Science Foundation (DIR-8820595
and DIR-9012492).
 
MEMBERS OF THE PLANNING COMMITTEE
 
Terrell Ward Bynum, Co-chair,       Walter Maner, Co-chair

Ronald E. Anderson, Gary Chapman, Preston Covey, Gerald Engel, Deborah G.
Johnson, John Ladd, Marianne LaFrance, Daniel McCracken, Michael McDonald, 
James H. Moor, Peter Neumann, John Snapper, Eugene Spafford, Richard A. Wright
 
PARTIAL LIST OF CONFIRMED SPEAKERS
 
    Ronald E. Anderson, Chair, A C M Special Interest Group on Computing and
Society; Co-Editor, SOCIAL SCIENCE COMPUTER REVIEW
    Daniel Appelman, Lawyer for the USENIX Association, Specialist in Computer
and Telecommunications Law
    Leslie Burkholder, Staff Member of the Center for the Design of Educational
Computing, Carnegie-Mellon University; Editor, COMPUTERS AND PHILOSOPHY
    David Carey, Author and Speaker on Software Ownership; Doctoral
Dissertation on Software Ownership; Assistant Professor, Whitman College, WA
    Gary Chapman, Executive Director, Computer Professionals for Social
Responsibility; Editor, JOURNAL OF COMPUTING AND SOCIETY
    Marvin Croy, Author and Researcher on Ethical Issues in Academic Computing;
Associate Professor of Philosophy, University of North Carolina at Charlotte
    Gerald Engel, Vice-President of Education, Computer Society of the I E E E;
Member, Computing Sciences Accreditation Board; Editor, COMPUTER SCIENCE
EDUCATION
    Batya Friedman, Co-Editor of Computer Professionals for Social
Responsibility Anthology of Computer Ethics Syllabi; Teacher of Computer Ethics
at Mills College, CA
    Don Gotterbarn, Researcher and Speaker on Computer Ethics; Associate
Professor of Computer and Information Sciences, East Tennessee State University
    Barbara Heinisch, Co-Director, Adaptive Technology Computer Laboratory,
Southern Connecticut State University; Associate Professor of Special Education
    Deborah G. Johnson, Chair, Committee on Computers and Philosophy of the
American Philosophical Association; Author of the textbook COMPUTER ETHICS
    John Ladd, Professor Emeritus of Philosophy, Brown University; Author of
articles on Ethics and Technology
    Marianne LaFrance, Project Director, "Expert Systems: Social Values and
Ethical Issues Posed by Advanced Computer Technology"; Associate Professor of
Psychology, Boston College
    Doris Lidtke, Editorial Staff, Communications of the A C M; Professor of
Computer and Information Sciences, Towson State University
    Walter Maner, Director of the Artificial Intelligence Project, Bowling
Green State University; Author of Articles on Computer Ethics
    Dianne Martin, Researcher and Curriculum Developer in Computers and
Society; Co-Chair of "Computers and the Quality of Life 1990", A C M / S I G 
C A S conference
    Keith Miller, Computer Science, the College of William and Mary; Author and
Speaker on Integrating Values into the Computer Science Curriculum
    James H. Moor, Member, Subcommittee on Computer Technology and Ethics,
American Philosophical Association, Author of Articles on Computer Ethics
    William Hugh Murray, Consultant and Management Trainer in Information
Systems Security; Past Fellow on Information Security with Ernst &amp; Young
Accountants
    Peter Neumann, Senior Researcher in Computer Science, S R I International;
Chair, A C M Committee on Computers and Public Police; Editor, Software
Engineering Notes; Moderator of COMP.RISKS
    George Nicholson, Judge of the California Superior Court, Head of the
"Courthouse of the Future" Project
    Judith Perolle, Researcher on "Ethical Reasoning about Computers and
Society"; Associate Professor of Sociology, Northeastern University
    John Snapper, Illinois Institute of Technology; Author and Editor in
COMPUTER ETHICS; Member of the Center for the Study of Ethics and the
Professions
    Eugene Spafford, Member A C M - I E E E Joint Task Force on Computer
Science Curriculum; Author of Articles and Reports on Computer Viruses and
Security
    Willis Ware, Researcher, Author and Speaker on Computers and Privacy
    Terry Winograd, Past President of Computer Professionals for Social
Responsibility; Author and Researcher in Artificial Intelligence
    Richard A. Wright, Executive Director, American Association of Philosophy
Teachers; Director, Biomedical and Healthcare Ethics Program, University of
Oklahoma
    Bryant York, Professor of Computer Science, Boston University; Director of
the Programming by Ear Project for visually handicapped individuals
 
MODEST COST
 
Registration Fee
            Before 7/1/91    After 7/1/91
  regular       $175.00         $225.00
  student       $ 50.00         $100.00
 
Food (entire conference)
  $90.00 (adult)           $50.00 (child)
 
Dormitory Room (entire conference)
                             Before 7/1/91    After 7/1/91
  adult (double occupancy)      $100.00          $110.00
  adult (single occupancy)      $150.00          $175.00
  child                          $40.00           $50.00

  There are a limited number of single occupancy rooms available.
  A few Room &amp; Board Scholarships are available.
 
FURTHER INFORMATION AND REGISTRATION
 
Registration for the National Conference on Computing and Values is limited to
500 people (about 85 from each professional group).  It is highly recommended
that you pre-register well in advance to ensure a place in the conference.  To
receive a set of registration materials, please supply the requested
information (see "coupon" below) to Professor Walter Maner, the conference
co-chair:
 
By E-Mail:
   BITNet      MANER@BGSUOPIE.BITNET
   InterNet    maner@andy.bgsu.edu (129.1.1.2)
   CompuServe  [73157,247]
By Fax:
   (419) 372-8061
By Phone:
  (419) 372-8719  (answering machine)
  (419) 372-2337  (secretary)
By Regular Mail:
   Professor Walter Maner
   Dept. of Computer Science
   Bowling Green State University
   Bowling Green, OH 43403 USA
 
/------------------------- COUPON ---------------------------\
First Name:
Last Name:
Job Title:
Phone:
Institution or Company:
Department:
Building:
Street Address:
City:
State:
Zip:
Country:
Email Address(s):

     All attendees will be part of a working group that "brainstorms" a topic
and suggests further research for the next five years. PLEASE INDICATE YOUR
PREFERENCES BELOW (1 = first choice, 2 = second choice, 3 = third choice):
 
[  ] Privacy &amp; Confidentiality 
[  ] Equity &amp; Access 
[  ] Ownership &amp; Intellectual Property 
[  ] Security &amp; Crime 
[  ] Teaching Computing &amp; Values 
[  ] Campus Computing Policies

PLEASE MARK *ONE* OF THE FOLLOWING:
 
[ ] Send me registration information ONLY.  I'll decide later whether or not to
register.
 
[ ] Register me NOW.  Enclosed is my check (made payable to "B G S U") for $ to
cover all of the following (PLEASE ITEMIZE):
 
               Quantity
                [   ]    regular registration(s)
                [   ]    student registration(s)
                [   ]    meal ticket(s) for adult
                [   ]    meal ticket(s) for child
                [   ]    room(s) for adult (double occupancy)
                [   ]    room(s) for adult (single occupancy)
                [   ]    room(s) for child
 
Note that rates change on July 1, 1991.

\---------------------- END OF COUPON -----------------------/

InterNet maner@andy.bgsu.edu  (129.1.1.2)    | BGSU, Comp Science Dept
UUCP     ... ! osu-cis ! bgsuvax ! maner     | Bowling Green, OH 43403
BITNet   MANER@BGSUOPIE                      | 419/372-2337  Secretary
Relays   @relay.cs.net, @nsfnet-relay.ac.uk  | FAX is available - call

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-72</DOCNO>
<DOCOLDNO>IA013-000136-B032-297</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.11.html 128.240.150.127 19970217041920 text/html 31771
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:17:47 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 11</TITLE>
<LINK REL="Prev" HREF="/Risks/11.10.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.12.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 11</H1>
<H2> Friday 15 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Enterprising Vending Machines 
</A>
<DD>
<A HREF="#subj1.1">
Jeff Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Re: Electronic Cash 
</A>
<DD>
<A HREF="#subj2.1">
Joseph R. Beckenbach [2]
</A><br>
<A HREF="#subj2.2">
 34AEJ7D
</A><br>
<A HREF="#subj2.3">
 M P Evans
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: Cashless Banking and Privacy 
</A>
<DD>
<A HREF="#subj3.1">
Jake Livni
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Cashless gas pumps 
</A>
<DD>
<A HREF="#subj4.1">
Jeff Helgesen
</A><br>
<A HREF="#subj4.2">
 Dick Smith
</A><br>
<A HREF="#subj4.3">
 Lars-Henrik Eriksson
</A><br>
<A HREF="#subj4.4">
    K. M. Sandberg
</A><br>
<A HREF="#subj4.5">
 Sean Malloy
</A><br>
<A HREF="#subj4.6">
 Peter da Silva
</A><br>
<A HREF="#subj4.7">
 34AEJ7D
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Electronic telephone directory 
</A>
<DD>
<A HREF="#subj5.1">
Ralph Moonen
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Enterprising Vending Machines (Risks 11.03)
</A>
</H3>
<address>
Jeff Johnson 
&lt;<A HREF="mailto:jjohnson@hpljaj.hpl.hp.com">
jjohnson@hpljaj.hpl.hp.com
</A>&gt;
</address>
<i>
Mon, 11 Feb 91 15:26:14 PST
</i><PRE>

Just had my own run-in with a postal vending machine.  Was expecting trouble
because of what I'd read in RISKS, but got bitten anyway.  If not interested in
the details, skip to Summary.

Entered a post office to buy some new stamps.  Long line waiting.  Vending
machines (3) all flashing the "Use exact change" light.  Line backed up into
narrow hallway containing both vending machines and post boxes.  Hallway very
crowded; people angry because they must wait in line or because they can't get
through the crowd to their post box.  Several people standing in front of the
vending machines, trying to figure out how to coerce stamps from them, adding
to the crowd.  Purchase-pooling deals being suggested, mentally tested ("Let's
see, if I buy two books of stamps and you get 1 book of post-card stamps..."),
and tried.

One machine offered ten 29-cent stamps for $2.90, but wanted exact change.  I
had 3 ones and a twenty.  I decided to put in $3, get ten stamps, and forget
about the extra dime.  Put in first dollar: amount-display showed $1.00.  Tried
to put second bill in, but machine rejected it repeatedly.  Ditto other bill.
Pressed "change return" to get first dollar back.  Machine made four "ka-chunk"
noises, but no money actually appeared.  The amount-display now read $0.00, but
I didn't notice this at the time.  I put in the other 2 bills (this time the
machine accepted them); now the display said $2.00.  Hadn't notice that it had
gone to zero, so wondered where my other dollar had gone.  Figured that it must
have timed me out as reported in RISKS.  Had no more one-dollar bills, so was
stuck.  Pressed "change return" in frustration: eight "ka-chunks" but no money.
Noticed amount decreasing $.25 for each "ka-chunk" this time, so figured out
what happened to first dollar.

Asked to see station manager.  Told him what happened.  He didn't understand.
Invited him out into lobby to put bills into machine.  He did.  Told him to
press "change return".  He didn't want to: didn't want to lose his money.  I
said, "You've already lost your money since there's no way to get it back; you
might as well press 'change return' so you can see what happens."  He did,
heard the "ka-chunks", then said: "This machine is out of order; I need to put
a sign on it".  I said, "It's out of order, but not because it's
malfunctioning; this is what it is designed to do when out of change."  He
didn't think so.

I also tried to explain to him that new stamp price *means* that vending
machines must be refilled with change much more often.  By now he was beginning
to feel some of the stress and exasperation that filled the hallway.  He said,
"The guy who services these machines isn't here today," gave me my money back,
and put an "Out of Service" sign on the machine.  This ended the interaction,
because now several other people who had been having trouble with the machines
pounced upon him.

Summary: The new stamp-price ($.29) has side-effects that clearly were not
anticipated by the Postal Service.  The new price was calculated to increase
revenue to cover operating costs, but some of its ramifications weren't
anticipated.  One is that the vending machines will be dispensing much more
change and therefore must be re-filled more frequently if they are to serve
their purpose.  The change-making apparatus also will require more frequent
repair.  This increased servicing of machines will consume some of the expected
revenue gain.  Second, increased demand for change from the machines has
increased user-exposure to various design flaws in the change-making
functionality of the machines.  The Postal Service should either keep the
machines full of change or change the stamp-price to $.30.  Simply fixing the
machines to behave "correctly" when out of money won't solve the real problem:
long lines in post offices.

Jeff Johnson, HP Labs

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:jerbil@cobalt.cco.caltech.edu">
jerbil@cobalt.cco.caltech.edu
</A>&gt;
</address>
<i>
Fri, 8 Feb 91 10:26:55 PST
</i><PRE>

In comp.risks you (Brian Yamauchi &lt;yamauchi@cs.rochester.edu&gt;) write:

&gt;I'm in favor of replacing the various pieces of paper and bits of metal we
&gt;currently use for money with a more convenient electronic system, but I think
&gt;this should and will be done via the free market rather than as mandated by the
&gt;central government.

	Agreed.  This is what the growing trend for payroll electronic
automatic deposit, and Social Security "direct deposit", are all about.
Agreed, that for payments over $20 a credit card is handy.  But I'd rather
have the option, thanks, to handle my finances more flexibly.
	My big disagreement with you comes with the transfer scenario --
if that's the only method of transfer.  Checks of many sorts handle the large
transfers, as do wire transfers, and cash handles the small stuff.

	Want to absolutely ruin a cashless society?  Turn off the power to
the clearinghouses.  I wonder how commerce fared during the New York black-out
of several years ago, when no one had power.  Shopkeepers which didn't have to
depend on credit-card sales didn't see the same dip in sales for the month that
the others would, I'd wager....

&gt;I'm not extremely enthusiastic about giving the government too much
&gt;information.  It is true that they could abuse this.  On the other hand, the
&gt;real solution is to enact pro-freedom measures legislatively to limit the
&gt;government's power.  If either (1) the government ceases to become democratic,
&gt;or (2) the majority wants to allow government oppression, then there's not a
&gt;lot you can do -- short of armed rebellion -- the tanks can always roll through
&gt;the streets.

	If the government ceases to be democratic, or the majority wants
government oppressions, then those will be fought by citizens who do not want
to see the US Constitution circumvented.  The Constitution came out of the
efforts of citizens trying to weld together thirteen States in a failing
Confederation after a bloody armed rebellion.  The tanks can roll through the
streets, but unless there's valid authority behind it, it's unconstitutional.
The bystanders might be just as dead, but the following reactions would bring
the balance back.

&gt;Electronic cash would have both positive and negative effects on crime.  On the
&gt;positive side, violent crimes would drop substantially -- no longer would you
&gt;have to worry about being knifed for your wallet in a dark alley.  On the
&gt;negative side, the potential for computer crime would be increased.  At least
&gt;in theory, this could create the potential for truly huge sums of money to be
&gt;stolen, not by stealing large chunks, but by stealing minute amounts from large
&gt;numbers.  For example, stealing 1 cent from every transaction made in the U.S.
&gt;would probably result in a take in the $million/day range.

	Depends on the method of 'cashlessness'.  If the cards are truly
personal, stealing them would be a better method of tying him up than beating
himn into hospital.  If not personal, then anyone wishing more money would
simply mug for the cards, just as they currently mug for coins and paper
and cards.  (I thought most muggings were non-violent.)
	Several cases have already meandered though RISKS' attention about
computer money-skimming schemes at banks, including the 'take the round-off
balance account and assign it to me' scam.  And the 1-cent per transaction
fraud would be noticed somewhere, since it's simply a variation of how banks
get paid for their services.

&gt;Still, given a choice, I would rather have some hacker breaking into
&gt;my checking account than some mugger slitting my throat...

	I'd rather have the mugger.  Most of them don't go for the strong, the
active, or those who look like they know what they're doing.  The others tend
to be caught not long after.  With hackers, no one could be the wiser, it's not
clear what laws are applicable and to what extent, and the damage potential is
orders of magnitude higher.
                              		Joseph Beckenbach

</PRE>
<HR><H3><A NAME="subj2.2">
Re: Electronic cash completely replacing cash
</A>
</H3>
<address>
Joseph R. Beckenbach
&lt;<A HREF="mailto:jerbil@cobalt.cco.caltech.edu ">
jerbil@cobalt.cco.caltech.edu 
</A>&gt;
</address>
<i>
Fri, 8 Feb 91 10:40:39 PST
</i><PRE>

In <A HREF="/Risks/11.06.html">RISKS-11.06</A> Richard A. O'Keefe writes regarding David Witt in <A HREF="/Risks/10.81.html">RISKS-10.81</A>:

&gt;Eh?  These machines are going to be *at least* as expensive as VCRs, and we're
&gt;talking about distributing &gt; 500 million of them (ALL homes and businesses,
&gt;remember, and businesses will need as many of these gadgets as they have cash
&gt;registers).  Then think about maintenance.

	Let's see, that's running $150.00 x 200 x 10^6 as a low estimate.
$30 G-bucks.   That's over 1% of the current deficit.  GACK!

&gt;&gt; 	The Federal Reserve would be better able to follow the economy, helping
&gt;&gt; to stabilize the financial markets.

	It ain't broke, don't fix it.  At least, that part ain't broke.

&gt;Here we have someone who does not believe in the Free Market, and has
&gt;a wonderful child-like faith that because there is an outfit whose task
&gt;is to manage the economy that it is able to do it.  I have a bridge for him.

	See below....

&gt;The thing that is really evil about the suggestion is that it is a
&gt;technological fix to a social problem; the basic attitude is that
&gt;human "misbehaviour" is best cured by making people behave like good
&gt;little cogs.  "Forget trying to build a humane society so that fewer
&gt;people *want* to buy drugs, let's build electronic cages so they're
&gt;found out."  How do we educate people like this?

	I think it's as simple as saying "Eastern Bloc during the Cold War".
Reasonable minds can, and _should_, take it from there.
                                          		Joseph Beckenbach

</PRE>
<HR><H3><A NAME="subj2.3">
     RE: cashless society, a post-mortem
</A>
</H3>
<address>
&lt;<A HREF="mailto:34AEJ7D@CMUVM.BITNET">
34AEJ7D@CMUVM.BITNET
</A>&gt;
</address>
<i>
Mon, 11 Feb 91 09:35:36 EST
</i><PRE>

Two points militate more strongly against this scheme than any others I can
think of:

1.   The "barter" economy is already well-entrenched in the underground
     economy. This proposal would immeasurably swell the ranks of those
     trading by this method,

2.   The "hand print and retina pattern" scanners would, I am rather
     certain, run afoul of the recently-enacted ADA (Americans with
     Disabilities Act) as illegally discriminatory. There are, boys
     and girls, people in the good ol' US of A with neither hands
     nor eyes who are nevertheless productive citizens.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Electronic cash (post dated cheques)
</A>
</H3>
<address>
M P Evans 
&lt;<A HREF="mailto:evansmp@uhura.aston.ac.uk">
evansmp@uhura.aston.ac.uk
</A>&gt;
</address>
<i>
Mon, 11 Feb 91 19:17:11 GMT
</i><PRE>

With referance to Frank Wales article (<A HREF="/Risks/11.06.html">RISKS-11.06</A>) Post dated cheques (at
least in Britain) have no validity.  If someone were to write me a cheque with
next month's (or next year's) date on it I could immediately present it at my
bank, and they would accept it without question.  This has happened with a
cheque I wrote, which I was able to have returned to me, which clearly shows
that the date it was paid it (by to bank's stamp) was before the date which I
wrote on the cheque.  The only thing which can stop such a cheque being
processed is the staff at the bank, they do not check the date.  The only
information known to the automatic processing system is the cheque number, sort
code (bank), account number and the value of the cheque.  The first 3 are
preprinted on the cheque, the latter typed in at the bank.

Mark Evans, Univ. of Aston in Birmingham, Aston Triangle, Brimingham, England.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Cashless Banking and Privacy
</A>
</H3>
<address>
&lt;<A HREF="mailto:jake@mars.bony.com">
jake@mars.bony.com
</A>&gt;
</address>
<i>
Mon, 11 Feb 91 21:23:35 EST
</i><PRE>

[Internally-From: Jake Livni &lt;JAKE@DBCLUA&gt;]

Daniel B Dobkin &lt;dbd@marbury.gba.nyu.edu&gt; describes the ultimate government
surveillance tool:

&gt;Unfortunately, Smith doesn't attribute the source of this story; does
&gt;anyone out there have any clues?  Enquiring minds want to know.....

Try the Nova show called "Computers, Spies and Secret Lives" which first 
aired on PBS on Sept. 27, 1981.  Excerpts from the transcripts for 
that show follow: 

    PAUL ARMER
    Several years ago, I was a member of a workshop of computer people [and]
    law enforcement people who were gathered together and asked to pretend 
    that we were consultants to the Russian Secret Police...given the task
    of designing for them a system which would keep track of all the Soviet
    citizens, plus all the foreigners who happened to be within the boundaries
    of the USSR.  After considerable study, the workshop concluded that the
    best system to build for the KGB, the secret police, was an electronic
    funds transfer system, for the reason that electronic funds transfer
    systems not only know what you're buying, but where you are in real time 
    at the time you're making your financial transaction. 
    
    NARRATOR
    Some privacy experts acknowledge these threats and consider them beyond
    existing computer capacities.
    
    [This is followed by a bank vice-president who says that ATM usage produces
    too much information to sort through with then-current computers, except
    in a serial manner.]

Jake Livni                                               jake@bony1.bony.com

</PRE>
<HR><H3><A NAME="subj4.2">
Cashless gas pumps; alternative to credit card use
</A>
</H3>
<address>
Jeff Helgesen 
&lt;<A HREF="mailto:jmh@morgana.pubserv.com">
jmh@morgana.pubserv.com
</A>&gt;
</address>
<i>
Fri, 8 Feb 91 14:29:15 -0600
</i><PRE>

The risks inherent in automated charging to credit cards are easily avoided by
use of a system like the one(s) used by phone companies in many European
countries; that is, the user purchases a card of a particular denomination via
a vending machine [or human vendor, if the stories regarding post office
machines put you off]. This card has an mag strip encoded with a value which
can be read and written to by the automated pump. The card remains in the
machine and decrements the value available until the transaction is completed
(either the user stops the pump, or the value of the card is dropped to $0, and
the pump shuts off automatically), whereby it is ejected. Used-up cards may
then be discarded; cards with value remaining may be kept until the next time
the user needs petrol.

Benefits versus credit card system include:

	o  Difficult system to defraud; only risk to petrol vendor
	   is that a wily consumer will figure out the encoding scheme.

	o  Validation of identity is no longer required. Too bad if you
	   lose your card, though I'd rather lose one of these than my AmEx.

	o  Handling costs are reduced, presumably reducing the pump price
	   of gas.

	o  Big brother is not watching.

Jeff Helgesen					jmh@morgana.pubserv.com

</PRE>
<HR><H3><A NAME="subj4.3">
Re: A risky gas pump (Grumbine, <A HREF="/Risks/11.03.html">RISKS-11.03</A>)
</A>
</H3>
<address>
Dick Smith
&lt;<A HREF="mailto:dick@smith.UUCP ">
dick@smith.UUCP 
</A>&gt;
</address>
<i>
9 Feb 91 06:11:20 GMT
</i><PRE>

I worked on such a system at a previous employer, and think that the
concerns expressed are overdone.

Here are my thoughts on the worries expressed about this auto-approving gas
pump:

  Is card mine:  Well, it's probably checked as well as the typical
    human attendent checks it... I am surprised when someone looks at
    the back of mine to verify my signature.  I try to remember to thank
    them for doing it!

  Receipt disagrees:  Complain to the attendent immediately... (in the
    US, there WILL be an attendent, if only to shut the pumps off if
    there is a fire) just as you would if the receipt that you got
    inside was wrong.  It's a requirement that the amount pumped stay
    displayed on the pump until the next person uses it, so you'll
    have something to compare against if you hurry.

  It remembers my card number:  Again, I don't know why this is any more
    likely than the human attendent copying down your number and reusing
    it.  Certainly not on purpose, anyway.  When I worked in this 
    industry, I recall that the credit card network had its own
    validation organization which served as an independent check for
    credit equipment vendors.  I remember their testing as being
    fairly comprehensive, followed by a month long beta test at
    a single site with the paper logs checked.  We felt pretty good
    when we got through with it.

  The receipt printer doesn't work:  Well, the cutter kept jamming in
    ours... you'll have to go inside in that case, and get the guy to
    write one by hand.  He can copy the info off the paper tape log.

Actually, I worried more when I used a gas pump of a kind that wouldn't
be allowed in the U.S. (because of that fire law).  I was in Holland
last fall, and had occasion to buy gas on the AutoRoute late one night.
The station I pulled into has no attendent, just a bill reader for (I
think) 20 &amp; 50 guilder bills.  What I worried about was what I was going to
do if I put in too much money, since there was no change return at all.
I managed to buy 2/3 of a tank for my rental car, though, with no
trouble.

Dick Smith, R.H.E Smith Corp ...ast!smith!dick  dick%smith@ast.dsd.northrop.com

</PRE>
<HR><H3><A NAME="subj4.4">
Re: risky gas pumps (Clark, <A HREF="/Risks/11.05.html">RISKS-11.05</A>)
</A>
</H3>
<address>
Lars-Henrik Eriksson
&lt;<A HREF="mailto:lhe@sics.se ">
lhe@sics.se 
</A>&gt;
</address>
<i>
Sat, 9 Feb 91 15:34:40 GMT
</i><PRE>

I've been buying gas from automatic gas pumps (both manned and unmanned) in
Sweden for several years. I have not yet had a single case of incorrect
charging or any other problem that is worse than not getting gas out of the
machine.

However, at about 20% of all occations I use these machines, I do
*not* get a reciept. Usually because the machines are out of paper.

Lars-Henrik Eriksson				Internet: lhe@sics.se
Swedish Institute of Computer Science		Phone (intn'l): +46 8 752 15 09
Box 1263					Telefon (nat'l): 08 - 752 15 09
S-164 28  KISTA, SWEDEN

</PRE>
<HR><H3><A NAME="subj4.5">
Re: A risky gas pump
</A>
</H3>
<address>
K. M. Sandberg
&lt;<A HREF="mailto:sandberg@ipla01.hac.com ">
sandberg@ipla01.hac.com 
</A>&gt;
</address>
<i>
11 Feb 91 18:08:23 GMT
</i><PRE>
Sender: news@hacgate.UUCP

(Re: Lehman, <A HREF="/Risks/11.05.html">RISKS-11.05</A>)

&gt;     None.  But my other credit card purchases are not usually validated
&gt;either.  I think the fair credit acts protect you somewhat.

The difference is that with regular credit card transactions you have to sign
the slip, with ATM transactions you have to enter a pin code, either of which
indicates that you are the owner of the card or in the case of the signature,
you can show it is not your signature, with the readers there is no such
protection, but one question I have is what happens if you dispute a charge.
Since they have no proof of who charged it, except an electronic card number.

Normally a lot of the disputes can be resolved by looking at the signed charge
slip, in this case there is none, nor was there any pin code entered as an
electronic psuedo-signature, so is there really an agreement?

(Re Margolin, <A HREF="/Risks/11.03.html">RISKS-11.03</A>)

&gt;From: barmar@think.UUCP (Barry Margolin)
&gt;Subject: Re: A risky gas pump (from RISKS DIGEST 11.03)
&gt;
&gt;Your tone suggests that this is a new risk. ...

This is a new risk, allowing the use of a credit card with no trace back on who
used the card, no signature to forge, no pin code to break, nothing.  There is
no license plate recorded or anything else. You could take a valid charge and
say that it was not valid, how do they prove it was?  They take a charge that
is invalid, how do you prove it was not? Normally you can request the charge
slip and so it can be shown that it was not your signature, but in this case
anyone who has access to the card can use it. If someone borrowed your card,
you at least stand a chance of detecting who it was based on the signature.

As far as the phone credit calls, there is a record of the phone numbers and
where the call was placed from, along with a history which can be checked to
see if you ever called that number before, so it is quite different.

With mail order house they are supposed to have your signature on file and if
they don't you can dispute the charge, but in any case they have a record of
where the stuff was sent, and a way to track the person because of that.

I used such gas pumps, but I also write down all the information in a book to
watch the gas mileage, so if there was a problem I could show that the gas was
not put into one of my cars, unless I forged other entries. Personally I think
the gas stations are taking a large risk unless they have something to track
the cards better than it appears (ie. some information to ensure that the card
number really belongs to the person, like the name. ATM cards have this
information).  Also if the card is lost or stolen it is generally the case that
the person could not keep reusing the car because a person might notice and
might also recognize them. In this case the card holder is not seen. Maybe
there is a check to make sure that the card is not used too many times, I don't
know. What I do know is that if your card is lost and returned, you better be
very careful in knowing what you had charged to make sure that a charge was not
made before it was returned.
						Kemasa.

</PRE>
<HR><H3><A NAME="subj4.6">
Re: Burned by a gas pump (was Re: A risky gas pump, <A HREF="/Risks/11.05.html">RISKS-11.05</A>)
</A>
</H3>
<address>
Sean Malloy
&lt;<A HREF="mailto:malloy@nprdc.navy.mil ">
malloy@nprdc.navy.mil 
</A>&gt;
</address>
<i>
Mon, 11 Feb 1991 13:12:21 PST
</i><PRE>

&gt;  How about if my number is not cleared from the pump's memory and I get
&gt;    billed for the entire day's gas from that pump?

Your number can be cleared from the pump's memory and still try to
take you, as long as the programmers for the billing software don't
pay attention to wierd-case transactions.

Some months ago, I received a bank statement showing that I'd been billed twice
for the same transaction at an ARCO PayPoint gas station using my ATM card. The
circumstances were that I was returning home _late_ at night, and had stopped
to fill my tank. Between the time I'd opened the transaction and shut off the
pump after filling my tank, the time had rolled across midnight to the next
day. The billing software ARCO was using billed me for each end of the
transaction, since there was a transaction start record for an amount of $9.56
on day X, and a transaction end record for an amount of $9.56 on day Z+1.

The reason I noticed the error was that there were two transactions listed on
consecutive days with the same transaction number and amount. When I called the
customer service number for my bank and talked to the representative, they said
that they'd take the duplicate charge off my account and inform ARCO of the
problem; I got the notification of the credit to my account about a week later.
Since then, when I've had to fill my tank close to midnight, I always wait for
the date to change if there's a chance that it would roll over while I was
pumping gas.

 Sean Malloy, Navy Personnel Research &amp; Development Center, San Diego, 
   CA 92152-6800                                   malloy@nprdc.navy.mil

</PRE>
<HR><H3><A NAME="subj4.7">
Risky gas pumps
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:peter@taronga.hackercorp.com ">
peter@taronga.hackercorp.com 
</A>&gt;
</address>
<i>
Fri, 8 Feb 1991 14:01:30 GMT
</i><PRE>

These pumps appeared a couple of years ago here in Houston, then most
of them promptly vanished. Why? Simple... people buying gas this way
didn't tend to make impulse purchases of the overpriced soft drinks,
candy, motor oil, and other things they pile up around the regular
payment window and revenue actually went down.

The risks aren't just one-way.
                                    (peter@taronga.uucp.ferranti.com)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     gasoline
</A>
</H3>
<address>
&lt;<A HREF="mailto:34AEJ7D@CMUVM.BITNET">
34AEJ7D@CMUVM.BITNET
</A>&gt;
</address>
<i>
Fri, 08 Feb 91 08:31:26 EST
</i><PRE>

Guy Sherr writes:

&gt;Gasoline is a volatile high explosive.

Wrong. Gasoline is incapable of true "detonation", as required by the
definition of a "high" explosive.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Electronic telephone directory
</A>
</H3>
<address>
&lt;<A HREF="mailto:rmoonen@hvlpa.att.com">
rmoonen@hvlpa.att.com
</A>&gt;
</address>
<i>
Fri, 8 Feb 91 09:18 MET
</i><PRE>

MFMISTAL@HMARL5.BITNET (Jan Talmon) writes:

-&gt;In the Netherlands, printed telephone directories provide telephone numbers
-&gt;by using the name as an index. Currently, there is also an electronic
-&gt;version of those directories available by means of a VIDITEL service.
-&gt;Here it is also possible to ask for a telephone number by providing the
-&gt;street name, the house number and the city. This involves an inherent risk.
-&gt;When one observes that there are apparently no people in a house, one can
-&gt;ask for the phone number, dial that number and when no one replies....
-&gt;it may be safe for burglars to go in. 

So what's the big deal here? The Dutch PTT has a directory assistance number
(dial 008) that gives exactly the same service, but cheaper. And it's a 
voice number, so it's probably faster too. The computer number is only good
when wanting to look up a lot of numbers, as directory assistance only gives
you two informations per call. Another thing that the computer service does,
but the voice number not, is give you the name &amp; address, when you supply
only the telephone number. I don't consider this a COMPUTER risk as:
1) the service was available all along, only voice.
2) Unlisted number are not in the computer
3) Burglars don't tend to pre-select their victim, but rather go out to
   a 'nice' neighbourhood, and find a suitable house there and then.
4) Burglars don't tend to have computers &amp; modems unless they stole it from
   a previous victim :-)

-&gt;It seems also to be an invasion of one's privacy, since one need not to
-&gt;know a name in order to place haressing/obscene phone calls.

No. I definetely disagree with this statement. One NEVER needs to know a name
in order to find the telephone number. If this was an invasion of ones
privacy, then get your name-tag off your frontdoor too! Furthermore, if you
don't want _any_ unsollicited phonecalls, just change your number to an
unlisted one. This costs nothing if you do it at the initial request for
a telephone line, and it costs F35.00 ($20.00) if you want it changed to
an unlisted number later. (BTW: I live in The Netherlands too, and have an
unlisted number)

--Ralph Moonen   --rmoonen@hvlpa.att.com

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-73</DOCNO>
<DOCOLDNO>IA013-000136-B032-320</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.12.html 128.240.150.127 19970217041936 text/html 32110
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:18:02 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 12</TITLE>
<LINK REL="Prev" HREF="/Risks/11.11.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.13.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 12</H1>
<H2> Sunday 17 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: PWR system "abandoned..." [Darlington] 
</A>
<DD>
<A HREF="#subj1.1">
Richard P. Taylor
</A><br>
<A HREF="#subj1.2">
 Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
More on very reliable systems 
</A>
<DD>
<A HREF="#subj2.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Saudi air controllers 
</A>
<DD>
<A HREF="#subj3.1">
Donald Saxman via Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Enterprising Vending Machines 
</A>
<DD>
<A HREF="#subj4.1">
Marc Donner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Visa voided purchase woes 
</A>
<DD>
<A HREF="#subj5.1">
Jane Beckman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Credit enquiries appear to expose client lists to competitor's scrutiny    
</A>
<DD>
<A HREF="#subj6.1">
Janson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Re: PWR system "abandoned..." [Darlington nuclear plant]
</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard.P.Taylor@nve.crl.aecl.ca">
Richard.P.Taylor@nve.crl.aecl.ca
</A>&gt;
</address>
<i>
Fri, 15 Feb 91 12:16:49 EST
</i><PRE>

Some of the details of the situation regarding the Darlington nuclear power
plant's computerized shutdown systems referred to in the Nucleonics Week
article quoted by M. Thomas (RISKS 11.08) are given in a previous Nucleonics
Week article of May 24, 1990.  I will try to summarize that article and
include some further details from the Atomic Energy Control Board's (AECB)
review process and licensing decision.

That article correctly indicates that the problems with these shutdown systems
were that the software is difficult to verify and difficult to modify.  These
difficulties caused both delays and extra cost.  The article also mentions
briefly that the software "will have to be rewritten because it is not
designed so changes can be easily incorporated."  This requirement was placed
on Ontario Hydro by the AECB as part of the licensing decision.  To quote that
AECB licence:  "The Board ... has concluded that the existing shutdown system
software, while acceptable for the present, is unsuitable in the longer term,
and that it should be redesigned.  Before redesign is undertaken, however, an
appropriate standard must be defined."

What led to this conclusion was an extensive and thorough analysis of the
software.  The original software submitted by Ontario Hydro for AECB review
was obviously very complex and convoluted.  The introduction of digital
computers had been taken as an opportunity to add additional complexity and
new monitoring functions to the shutdown systems over and above previous
analog and hybrid systems.  The AECB was concerned about how such software
could be reviewed and demonstrated to be safe.  Dave Parnas was contracted to
advise the AECB, and Nancy Leveson was contracted to advise Ontario Hydro.
Nancy Leveson's advice resulted in a hazard analysis by Ontario Hydro and some
revisions to the code for better fault detection and safety.  The review
method eventually chosen by the AECB was strongly based on Dave Parnas' work
and involved rewriting the software requirements in "A-7 style" event and
condition tables, deriving similar format "program-function tables" from the
source code, and comparing the two sets of tables.

It should be pointed out that the software was not designed with such a
verification process in mind.  When Ontario Hydro safety analysts and AECB
reviewers (myself included) tried to verify this software, we encountered many
problems simply because the designers and programmers had not expected to have
their work verified by mathematical techniques.  Nor could they have; the
decision to do such a verification was made after the software was designed
and coded.  Nevertheless, the techniques were successfully applied to the
software for the two shutdown systems.  Since automated tools were not
available, most of the work had to by done manually, and to compensate for
human error, all verifications were independently reviewed.  The AECB's audit
of this process constituted a second independent review of the most critical
30-40% of the software.

Despite the difficulties, the AECB did eventually license the Darlington
reactor.  The NW article of May 24 quotes Zygmond Domaratzki of the AECB:  "At
the end of the long tedious process we went through to review the
software....(W)e don't have any reservations about its ability to shut down
the reactor in an emergency."  The other result of this process was
considerable assurance that the software would not perform any unintended,
unsafe actions.  Every part of the code was analyzed, some unintended actions
were discovered, but all actions were determined to be safe.

The current situation is that Ontario Hydro and Atomic Energy Canada Limited
(AECL) are developing methods for specifying, designing and verifying safety
critical software.  These methods will be applied to the development and
verification of some prototype systems before they are adopted for general
use, and for the redesign of the Darlington shutdown systems.  The goal of
these methods is to make software easier to modify and easier to verify and
review.  The AECB is monitoring this process closely.

The AECB also is working (with the help of Dave Parnas and Wolfgang
Ehrenberger of GRS in Germany) to develop Canadian standards for safety
critical software in nuclear power plants.  We are monitoring international
developments in this area to ensure that Canadian standards are on par with
the rest of the world.

A separate, but related issue is to find a method of predicting the reliability
of the software.  I hope to join that RISKS discussion again shortly.

Richard P. Taylor, AECB, Canada                       taylorrp@nve.crl.aecl.ca

*I have tried to be brief and informative rather than simply quoting published
material.  Any misquotes or additional material are strictly my own
interpretation and should not be taken as the position of the AECB.  All the
usual disclaimers apply.  Please also note that the AECB is distinct and
separate from AECL even though I get my e-mail via an AECL address.

</PRE>
<HR><H3><A NAME="subj1.2">
 Re: PWR system "abandoned..."
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@murphy.ICS.UCI.EDU">
nancy@murphy.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Sun, 17 Feb 91 16:00:18 -0800
</i><PRE>

   &gt; According to the report, "Ontario Hydro faced a similar situation at its
   &gt; Darlington station, in which proving the safety effectiveness of a
   &gt; sophisticated computerized shutdown system delayed startup of the first 
   &gt; unit through much of 1989. Last year, faced with regulatory complaints 
   &gt; that the software was too difficult to adapt to operating changes, Hydro 
   &gt; decided to replace it altogether". [ I hope that Dave Parnas or Nancy 
   &gt; Leveson can fill in the details here.]

This is not exactly the situation as I understand it.  Although I have not been
directly involved for a while, I do have contact with people at Ontario Hydro.

It is true that granting of a low-power testing license for the reactor was
delayed due to questions about how to certify the software.  Both Dave and I
were consulting on this -- Dave for the Atomic Energy Control Board (the
government agency) and me for Ontario Hydro.  Dave and I disagreed about what
OH had to do to ensure the safety of the shutdown software, and they ended up
having to satisfy both of us.

Very briefly, my major requirements were that the software be subjected to a
hazard analysis, including a software fault tree analysis.  A few other minor
suggestions involved such things as rewriting the code slightly so that it was
easier to read and review.

A paper on the results of the software hazard analysis (using Software Fault
Tree Analysis) was just presented at the PSAM (Probabilistic Safety Assessment
and Management) Conference in L.A. two weeks ago.  The Software Fault Tree
Analysis took 2 man months.  There were no "errors" found, but they did make 42
changes to the code as a result of what they learned by doing it (e.g., changed
the order of some statements to make it more naturally fault tolerant and added
assertions to detect hazardous states at various points in the code).  They
reported to me (and in the PSAM presentation) that they liked the software
fault tree analysis technique, have used it on some other control system
software, and are planning to use it again in the future.  A little more about
this can be found in my current CACM paper on how to build safety-critical
software.

Dave required that they rewrite their requirements specification in the A-7
style and that they do a "handproof" of the code using functional abstraction
from the code (called Program Function (PF) Tables).  This was quite costly and
painful in comparison with the fault tree analysis (at PSAM I was told that the
PF tables took 30 man years), but it is also more complete.  I heard that a few
errors were found in the specification (not in the code) as a result -- but
this may not be correct.  I have also heard from several people at Ontario
Hydro that they are not happy with the prospect of having to repeat the PF
analysis when changes are made in the code (which the AECB has decreed), and
some have suggested getting rid of the software altogether to avoid having to
go through this type of PF table analysis again.
                                                            nancy

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
More on very reliable systems
</A>
</H3>
<address>
Jerry Leichter 
&lt;<A HREF="mailto:leichter@lrw.com">
leichter@lrw.com
</A>&gt;
</address>
<i>
Fri, 15 Feb 91 11:46:08 EDT
</i><PRE>

Dr. Tanner Andrews writes:
	) The theory here is that running 100 units for 100 hours gives you
	) the same information as running one unit for 10000 hours.
	The theory is crocked.  It builds heat slowly. The actual behavior:
		100 hours:	a little warm
		200 hours:	case is softening
		250 hours:	case melts
		257 hours:	catches fire
	The times and failure modes will vary, depending on the type of
	device in question.

He's just re-discovered the problem of correlated failures, which was what
my whole article was about.  I gave a very similar example concerning digital
watches.

Martyn Thomas asks:

	How can we have confidence that the means by which we have combined
	the n-versions [of an n-version program] (for example, the voting
	logic) has a failure probability below 1 in 10^9?

Clearly, we can't.  If your view of an n-version program is that it just
produces some numbers that you somehow combine to get some other number,
you've got a problem.  But the real issue is how you build reliable systems
that somehow affect the real world.

Consider the brake system in an automobile.  It is divided into independent
halves from the master cylinder on; the halves control diagonally opposite
pairs of wheels.  Either half can stop the car, and failures that affect both
are "unlikely".  Now suppose we wished to build a computer-controlled brake.
We might try to get reliable operation by having redundant computers and a
voter which then applied all four brakes.  But it would make much more sense
to have a pair of independent computers controlling diagonally opposite pairs
of wheels.  The "voter" is then the car itself, and physical laws guarantee
that if either vote says "stop", the car stops.  (This actually comes full
circle to a comment I made a number of months back about the significance of
physical laws in mechanical systems, and the lack of such "enforced by the
universe" laws in digital systems.)

This is a HARD problem, there's no denying that!

	How can we be sure that our analysis of the upper bound on failure
	correlation among modules is accurate? How accurate does it need to be
	- does it need to have a probability of less than 1 in 10^9 that it is
	grossly wrong? (By "grossly wrong" I mean wrong enough to invalidate
	the calculation that the overall system meets the "1 in 10^9" figure).
	This would seem impossible.  Consider, for example, the probability
	that the common specification is wrong.

We can never be SURE.  Try and come up with any analysis that makes you SURE
(with high probability) that your car will stop when you hit the brakes - or,
for that matter, that the sun will rise tomorrow.  The language of mathematics
is very misleading here:  Mathematics deals with models of the world, not the
world itself.  There is no certainty, even of probabilistic estimates, in the
world.  But we have to muddle on.

I'm not knowledgeable enough in statistical theory to comment on how one
even measures the correlation, much less what the appropriate tests and
sample sizes are.  On the other hand, fairly small experiments showed the
FAILURE of the independence hypothesis for naive n-version programming.

Also, it's worth commenting on an assumption about testing that many people
make implicitly:  That only tests that do NOT use special knowledge about
the system being tested are acceptable.  In fact, hardly anything is ever
tested that way - it's just not practical.  It requires too many tests and
takes too long, often longer than the useful lifetime of the object under
test.

Consider, for example, computing MTBF for disks.  People ask how a manufactu-
rer can come up with an estimate of 100,000 hours on a fairly new product.
The answer is two-fold:  For failures that occur essentially at random during
the lifetime of a disk, testing a number of disks in parallel gives you a
valid estimate.  For failures related to aging - i.e., those whose probability
goes up as time in service goes up - there are a variety of "accelerated
aging" techniques.  Almost anything that's the result of a chemical reaction
(e.g., deterioration of lubricants) will proceed faster if you run the device
at higher temperatures.  Similarly, Dr. Andrews's slow heating will occur much
faster in a higher temperature environment.  Many kinds of mechanical failures
are due to CHANGE in temperature; a common test environment cycles the tempe-
rature repeatedly.  Similar considerations apply to humidity.  Vibration
stresses can be easily applied.  Someone asked about bearing failure after
many thousands of hours.  It may take a bearing thousands of hours to fail,
but the failure process doesn't suddenly happen - subtle changes are going
on in the bearing and the lubricants over that period of time.  A close
examination - much more than a "yes, it's still turning" determination - will
find chemical and physical changes:  Breakdown of the lubricant, migration of
metal into the lubricant (whether in macroscopic (chips of metal) or micro-
scopic (disolved metal) quantities), scoring of the bearing races, changes in
metal crystal structure.  We have a huge amount of experience with these kinds
of systems, and know what their plausible failure modes are.  Are we always
right?  No, of course not - but again, we have to muddle through.

Paul Ammann writes:

	&gt;	1.  Testing (whether by explicit test in a lab or by actual
	&gt;		use in the field) of very large numbers of copies of
	&gt;		the system 
	&gt;	2.  Functional decomposition of the system into a number of
	&gt;		modules such that failure can occur only when ALL the
	&gt;		modules fail. 

	The first technique assesses performance directly, and can be applied
	to any system, regardless of its construction.  As Jerry points out,
	various assumptions must be made about the environment in which the
	testing takes place.  The second technique estimates performance from
	a predictive model....

	I am uncomfortable with merging the issues of direct measurement with
	those of indirect estimation.  The difficulties in 1 are primarily
	system issues; details of the various components are by and large
	irrelevant. In technique 2 the major issue is the failure relationship
	between components.

I don't believe the distinction is sharp.  Again, most type 1 testing is NOT
a naive "try it for a while and see what happens"; one designs tests based on
assumptions about plausible failure modes.  This is, in effect, a predictive
model:  We predict that we've isolated all the important contributors to
system failure.  If we're careful, we even TEST that prediction:  After all
our tests are complete, we check to see how many failures were the results of
causes we did not include in designing our tests.  If there are too many, we
may have to go back and do it again.

Conversely, we can simply build the system from what we think are independent
modules and then do brute force testing for overall reliability.

	The Eckhardt and Lee model (TSE Dec 1985) makes it clear that
	performance prediction is much more difficult.  To evaluate a
	particular type of system, one must know what fraction of the
	components are expected to fail over the entire distribution of
	inputs.  The exact data is, from a practical point of view, impossible
	to collect.  Unfortunately, minor variations in the data result in
	radically different estimates of performance.  For a specific system,
	it is not clear (to me, anyway) what an appropriate "upper bound of
	failure correlation among modules" would be, let alone how one would
	obtain it.

See my earlier comments.  I don't believe there is any magic solution to this
problem; just as in the design of physical artifacts, it's something we'll
just have to learn about and solve on a case by case basis.

	&gt;                       Either technique can be used to get believable
	&gt;failure estimates in the 1 in 10^8 (or even better) range.  Such
	&gt;estimates are never easy to obtain - but they ARE possible. Rejecting
	&gt;them out of hand is as much a risk as accepting them at face value.

This statement came out sounding stronger than I intended.  I don't believe we
have the capability today to build a computer-based system for which we could
believe error estimates of this sort.  Nor do I see any techniques available
today that could provide such an estimate.  However, I don't see any funda-
mental reason to belive that such techniques could not exist.

BTW, it's also worth considering just how strong such a guarantee is, and in
particular how many of the systems we already deal with in the world are much,
much riskier.  If I remember the numbers right, about 30,000 people die in
car accidents every year.  If we do some really stupid estimating, and assume
that everyone in the US (about 3*10^8 people) gets into a car once a day, then
my chance of dying in a car accident is 1 in 10^4 each year.  Not a very
reliable system, is it?

In fact, I've always found it interesting how much more we demand from digital
systems than we demand from mechanical ones.  For example, we always reassure
beginners that no incorrect input to a program can physically harm the
machine.  And yet, consider what will happen to your car should you take it
down the highway at 60mph and then suddenly shift into reverse.  Does this
bother you?  Does it make you afraid to drive?
							-- Jerry

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Saudi air controllers
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:peter@taronga.hackercorp.com ">
peter@taronga.hackercorp.com 
</A>&gt;
</address>
<i>
Fri, 15 Feb 1991 13:58:51 GMT
</i><PRE>

The following message was posted on a local bulletin board.
 
Msg#:28798 *HOUSTON SHOUTS*
02-14-91 22:23:32 (Read 10 Times)
From: DONALD SAXMAN
  To: HELGA
Subj: WRITE YOUR CONGRESSMEN

(This message is really for anyone).  It was recently brought to my attention
that the Saudi Arabian government has replaced American traffic controlers in
the Desert Shield war zone with native Saudis. This was done partly to appease
Saudi nationalists and partly because some of the American military air traffic
controlers were women. (Saudi and other Islamic military pilots aren't
particularly fond of being directed by women, but they can live with it.  Saudi
civilian pilots reportedly would refuse to even listen to instructions fro
female air traffic controlers, pretending they didn't exist).  Anyway, the
Saudi controlers may or may not be as good at their job as the Americans. But
they reportedly don't speak English very well. (Sidebar: English is supposed to
be the international air traffic control language, but there are some holdouts
that don't follow this standard. Many of these are Islamic countries, although
Saudi Arabia apparently does use English-speakers.) Anyway, UN Coalition forces
are already having trouble coordinating operations.  Pilots who operate from
outside of the war zone, like refuelers or B-52s, are particularly at risk.
Anyway, there has been a suggestion made that users write their Congressmen and
complain about this situation.  It couldn't hurt.
   
If anyone out there has Usenet or Fidonet access, I'd appreciate them 
forwarding this message so that it gets as wide exposure as possible.

               (peter@taronga.uucp.ferranti.com)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Enterprising Vending Machines
</A>
</H3>
<address>
&lt;<A HREF="mailto:DONNER@IBM.COM">
DONNER@IBM.COM
</A>&gt;
</address>
<i>
Fri, 15 Feb 91 15:16:37 -0500
</i><PRE>

Grand Central Terminal in New York City has a number of ticket vending machines
that permit travellers who don't want to stand in long lines to purchase
tickets.  I had an unpleasant experience with one of them a while ago.  I
arrived at the terminal before the 6:00AM opening of the ticket offices with
the intention of taking a 6:10AM train.  Not knowing that the ticket offices
would open at 6 (it's not posted) I went to one of the ticket machines and
pressed the code for my destination.  It told me to insert $8.60.  The signs on
the front of the machine informed me that I could use bills of any denomination
up to and including $20.  Having only $20s on me (bless the cash machine) I
inserted one of them.  The light at the little window where tickets and change
are delivered flashed just as if it was delivering my ticket (I'd used the
machine before and I knew what to expect) but nothing came out.  My money
wasn't returned, I got no ticket, and I got no change.  Deciding that putting
another $20 into the machine wasn't wise, I wandered around the main concourse
looking for someone in authority for a few minutes until the ticket windows
opened.

I explained the situation to the ticket agent (after buying a ticket to my
destination) and he said "Oh, yes, it does that if you put a 20 in for a
purchase less than $10," and gave me a form to fill out requesting a refund.  A
few weeks later I received a letter from some official of the rail line
asserting that they hadn't found any excess $20 bills in their machines and
implying that I had been attempting to cheat them out of money.  He also
asserted that there were instructions on the machine explaining not to use $20
bills when less than $10 worth of tickets was being purchased.  I had looked
for such indications on the occasion of my loss and not found them, though on
my next visit to the station after receiving the letter I found that little
signs saying that had, in fact, been glued to the face of the machine in the
intervening time.

I wrote another letter suggesting that when the machine detected this problem
it could print out a receipt on ticket stock and give it to the user so that he
would have documentation for his loss.  This letter, which included several
other suggestions for simple, inexpensive solutions to the problem, evoked a
rather hostile letter in response.  At that point I gave up, though I did
fantasize about blowing the machine up for several weeks after.

Marc Donner

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Visa voided purchase woes
</A>
</H3>
<address>
Jane Beckman
&lt;<A HREF="mailto:jane@wombat.UUCP ">
jane@wombat.UUCP 
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 17:39:41 PST
</i><PRE>

I had heard that having to have a purchase voided out can tie up credit block 
allocations for a while, but here's my experience of last Friday that 
illustrates what can happen when Murphy really gets rolling...

I had a moderately sized chunk of cash I needed to pay for with my VISA card, 
over at the local Pay 'n Save.  Half the staff was out sick and the checkers 
who were in were overworked.  The checker opens a new register and runs my 
card through.  Nothing happens.  She finds that the printer for the reader is 
turned off.  She turns it on.  Still nothing.  So she runs the card through 
again.  This time, everything acts as normal until it goes to print out a 
register slip for me to sign.  The paper on the printer jams.  

Much swearing later, she tries to get into the register to void the purchase, 
and finds that it has billed me TWICE for the amount of purchase, once for 
when the printer was off, once for when the printer jammed.  The register 
doesn't know how to handle this, and refuses to void the second charge.  She 
has to go find the manager, who manages to consult the reference manual and 
get the printer voided.  

Okay, now that things are finally (theoretically) working, they run my card 
through again.  It comes back declined.  Why?  The two rather largish sums 
that were voided are stuck in my credit allocation, of course.  Of course it 
went through, the first two times.  I suppose I could have written a check 
at that point, but I decided to stubborn it out.  (Besides, I was interested 
in finding out what could be done, now.) 

The salesgirl calls the VISA number, hoping she can get a manual override.  
A mechanical voice wants her to punch in the store code.  She doesn't have it.
She hangs up, goes to another person, gets the store code.  She calls again, 
punches in the store code, then is asked for the credit card number.  I'm 
sorry, says the other end, that credit is declined.  Click.  She gets the 
manager.  He punches things in, and manages to get a real human being, and 
tries to explain what's going on to the credit authorization person.  That 
it was okayed the first two times, but now (with two voided charges on the 
allocation) it's topped my credit limit.  I'm sorry, says the credit drone, 
but I am not authorized to okay that credit authorization, despite what you 
tell me.  That can only be done by the credit card company.  Fine, says the 
manager, do you have a number for Citibank?  Call the customer service number 
on the back of the card, she suggests.  He calls the number, and explains to 
the Citibank service representative what has gone on.  The Citibank rep says 
that if he puts the card through one more time, he can manually override the 
declined credit order.  They put my card through one more time.  The credit 
goes through.  I get a slip to sign.  

However, you can bet I will be looking at my next bill very carefully.  Also, 
the override was obviously a once-only, and the credit is still set aside, 
somewhere, as I tried to use my card for a small purchase, this week, and it 
was declined.  That second charge is still in the system, somewhere.    Some 
time, someone is going to have to program the system to accept voids.

   --Jane Beckman   [jane@swdc.stratus.com]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Credit enquiries appear to expose client lists to competitor's scrutiny
</A>
</H3>
<address>
&lt;<A HREF="mailto:janson@ATHENA.MIT.EDU">
janson@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 18:57:34 EST
</i><PRE>

I have become sensitive to my exposure due to electronically compiled and
disseminated personal data, but, until recently, i had never considered
ways in which the users of such data expose themselves to possible losses.
I was both amused and disconcerted to learn that a company which uses
a credit reference service makes it easier for a competitor to target
customers through traces which are maintained by the credit agency.

This last week i received in the mail, from MCI, an offer for a
rebate in exchange for electing them as my long distance carrier.
   [Ignore for the present discussion ethical issues
   raised by the particular incentive mechanism which MCI employed.]
I had expected, and did receive, a number of enquiries from various alternative
carriers at the time when equal access provisions went into effect in this
area. I was, however, perplexed as to why they chose to target me now.

It took a bit of reflection, but i finally concluded that one focus of
MCI's current mailing is the holders of ATT Universal cards.
   [MCI used an address which gave them away.]
Not really the kind of thing which one company would deliberately give to a
competitor. So i called ATT to ask what happened.  I was informed that they
knew the likely path which the information had traveled, but that once they had
made a credit enquiry, they were powerless to preventing MCI from approaching
the credit agency and obtaining a list of those people for whom ATT had
requested credit histories.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-74</DOCNO>
<DOCOLDNO>IA013-000136-B032-354</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.13.html 128.240.150.127 19970217041954 text/html 26531
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:18:19 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 13</TITLE>
<LINK REL="Prev" HREF="/Risks/11.12.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.14.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 13</H1>
<H2> Tuesday 19 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
MAD HACKER appeal fails 
</A>
<DD>
<A HREF="#subj1.1">
Darren Dalcher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Paid to know everything about everybody? (Murder, She Wrote) 
</A>
<DD>
<A HREF="#subj2.1">
Kent M Pitman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Retail Sales Oversight -- No backup 
</A>
<DD>
<A HREF="#subj3.1">
Dave Rotheroe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Tube Tragedy 
</A>
<DD>
<A HREF="#subj4.1">
Pete Mellor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Serious bug in SVR3.2 gives root access easily 
</A>
<DD>
<A HREF="#subj5.1">
Richard H. Miller
</A><br>
<A HREF="#subj5.2">
     Sean Eric Fagan
</A><br>
<A HREF="#subj5.3">
 Steve Nuchia
</A><br>
<A HREF="#subj5.4">
 anonymous
</A><br>
<A HREF="#subj5.5">
 Daniel A. Graifer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Errors on Vietnam Veterans Memorial 
</A>
<DD>
<A HREF="#subj6.1">
Al Arsenault
</A><br>
<A HREF="#subj6.2">
 Mary Smolka
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Driving records 
</A>
<DD>
<A HREF="#subj7.1">
Jim Griffith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: Quick n' easy access to Fidelity account info 
</A>
<DD>
<A HREF="#subj8.1">
Steve Golson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
MAD HACKER appeal fails                          [From Darren Dalcher]
</A>
</H3>
<address>
"Peter G. Neumann" 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 19 Feb 1991 14:15:18 PST
</i><PRE>

Nicholas Whiteley, 21, of Ascot Gardents, Enfield, UK, was convicted earlier
[see <A HREF="/Risks/10.03.html">RISKS-10.03</A>,09,10,27] on four counts of damaging property, and sentenced
to 12 months in jail, 8 of them suspended.  A week later he was out on bail,
pending appeal.  The appeal process was completed on 22 January, and was
dismissed.  He was reportedly the "first computer hacker in Britain to be
jailed".  He had "deleted and added files, put on messages and changed
passwords of existing users enabling himself to use the system."  [Thanks to
Darren Dalcher at King's College, London, for a clipping received this morning
from the 6 Feb 91 Enfield Independent, apparently mailed on 6 Feb, although
unpostmarked, with a stamp that was uncancelled.]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Paid to know everything about everybody?
</A>
</H3>
<address>
Kent M Pitman 
&lt;<A HREF="mailto:KMP@STONY-BROOK.SCRC.Symbolics.COM">
KMP@STONY-BROOK.SCRC.Symbolics.COM
</A>&gt;
</address>
<i>
Mon, 18 Feb 1991 16:24-0500
</i><PRE>

In last night's ``Murder, She Wrote'' one of the key characters was a pesky
little IRS agent that went around always getting his way by making veiled
threats which bordered on extortion.  Irksome, but nothing really new from a
plot perspective.

What disturbed me more was that as the plot progressed, Jessica knew she was
out of clues and needed help.  So she went to what she called ``somebody who is
paid to know everything about everybody'' (the IRS guy) ...  and with only a
little bit of coaxing, managed to the agent that it was in the tradition of
trapping Al Capone on his taxes for him to reveal to her information on the
suspect.  And she probably thought that neither of them had done anything
wrong.

I'm going to write to CBS about this one.  Maybe I won't be the only one.

It seems to me like a little well-placed pressure on TV writers and producers
might not only get them back in line, but could even lead to some interesting
plot lines exploring the potential bad side-effects of ``well-intentioned'' 
invasions of privacy, such as this one.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Retail Sales Oversight -- No backup
</A>
</H3>
<address>
Dave Rotheroe
&lt;<A HREF="mailto:rotheroe@convex.com ">
rotheroe@convex.com 
</A>&gt;
</address>
<i>
18 Feb 91 21:02:00 GMT
</i><PRE>

I went to my local 'Best Buy' - a new home appliance, electronic, and computer
discount store in my area, to buy a few things last Saturday.  Things went
smoothly until I wanted to pay.  Turns out their main store computer was dead -
down for the count.  In their incredible wisdom, there was no backup system, as
the system was supposed to "come right back within a few minutes of going
down".  There was one (1) printout of prices in the entire store, which was
being kept at the service desk so they could continue to work.  The registers
had no price help, which ment there were people running all over the store
getting prices.  In addition, the automatically printed credit card receipts
weren't, forcing the clerks to manually imprint and fill out the forms, and
make phone calls for authorization - tasks they admitted they weren't properly
trained for, and had never done before.  Probably the only reason the store
managed to deal with it at all was that business was light.  I found it both
amusing and scary that the chain apparently has no backup system (like a
printout for each register), and does not train their employees in exactly what
to do and expect in the event of a long-term failure.

Dave Rotheroe, CONVEX Computer Corporation, Richardson (Dallas), TX 75083-3851
                                            (214) 497-4512 rotheroe@convex.COM

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Tube Tragedy (<A HREF="/Risks/11.03.html">RISKS-11.03</A>)
</A>
</H3>
<address>
Pete Mellor 
&lt;<A HREF="mailto:pm@cs.city.ac.uk">
pm@cs.city.ac.uk
</A>&gt;
</address>
<i>
Wed, 13 Feb 91 21:24:38 PST
</i><PRE>

Following my original mailing, Bill Carney &lt;8332P@EARN.NAVPGS&gt; wrote to say:

&gt; I had always thought that the were pressure sensitive switches located on 
&gt; each of the doors. I am basing this assumption on the fact that on the 
&gt; New York City Transit system, a child can hold the subway doors open.

This gave me pause for thought. Eventually I replied more-or-less as follows:

  I hope no child brought up in New york ever tries it on the London
  Underground!  The doors *can* be held open, but only by brute force. I would
  say it would take a fairly strong man to prevent them closing. This is based
  on observation of strong men attempting to get on as the doors were closing,
  and on feeling the force personally when doing the same myself. The safety
  feature is that the train will *not* move while any door (other than the
  guard's) is open.

  I have watched the guard carefully (on the few remaining two-man trains). He
  checks the platform, and pushes a button to close the doors. If these are
  obstructed, a light illuminates on the control panel. He opens the doors, to
  give the passengers a chance to get clear, checks, and tries again. When the
  doors close successfully and the warning light goes out, he pushes another
  button, and the train starts to move. (In the case of a driver-only train, I
  assume that the system is similar, except that the driver operates it, and
  checks using a TV monitor at the end of the platform.)

  The limit for a door to trigger the warning seems to be a couple of inches,
  so that if a leg or arm is trapped, there should be no problem. If a
  shoulder-bag is trapped outside, and the door closes on the strap, however
  (as once happened to me), the train will move.

  The interesting thing on two-man trains is that the guard's door must remain
  open as the train starts to move. Often there are several carriages with a 
  guard's control panel, though obviously, only one is operational on the train
  at any given time. There must therefore be a way of selectively disconnecting
  a door from the warning system, and I *think* that this is what the
  "butterfly clasp" does. I asked the guard the other day where the clasp was.
  (I couldn't see anything resembling a butterfly anywhere.) He knew what it
  was, all right, but he wasn't going to tell me. "There've been too many
  accidents with those things!", he said. He told me to write to LU if I wanted
  more information.

In the meantime, is there anyone out there who is well-informed about safety
systems on the London Underground, who can explain a) how a *passenger* could
operate such a device, b) why no special key is required to operate it, and
c) why the warning system cannot be designed so that *only* the door next to
the active guard's control panel can remain open *for whatever reason* as the
train begins to move?

I have also heard a story that a woman was strangled a short time ago when
the doors closed around her neck. Can anyone confirm this?

Peter Mellor, Centre for Software Reliability, City University, Northampton
Sq.,London EC1V 0HB +44(0)71-253-4399 Ext. 4162/3/1

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
serious bug in SVR3.2 gives root access easily (<A HREF="/Risks/11.10.html">RISKS-11.10</A>)
</A>
</H3>
<address>
Richard H. Miller
&lt;<A HREF="mailto:rick@pavlov.ssctr.bcm.tmc.edu ">
rick@pavlov.ssctr.bcm.tmc.edu 
</A>&gt;
</address>
<i>
15 Feb 91 17:27:11 GMT
</i><PRE>

&gt; Date: Wed, 13 Feb 1991 12:19:18 CST
&gt; From: pwolfe@kailand.kai.com (Patrick Wolfe)
&gt; Subject: serious bug in SVR3.2 gives root access easily
&gt; 
&gt; In my opinion, the rest of us are probably screwed.  I seriously doubt any of
&gt; these OS vendors will stop working on SVR4 to fix this bug in SVR3.2, except
&gt; possibly for customers who pay for software maintenance.  Many vendors are just
&gt; about ready to ship their SVR4 release.  I suspect most will tell those of us
&gt; who don't pay for maintenance that we must upgrade to fix the bug.

[As an aside, I have a difficult time understanding why a person who does not
pay for software maintenance expects to have bugs fixed. If you choose to
not pay for the service, then don't expect the vendor to fix it for free.] 

Now, as far as the risk is concerned, is this a good stand? Should security
holes be in a special category as far as fixes from the vendor are concerned?
The risk here is obvious since I, as a user of a BBS with a system with a
security flaw which is not fixed due to the unwillingness of the operator to
pay for software maintenance, have some exposure due to the hole. Should a
system operator disclose the type of hardware and software he is running as
well as the status of his maintenance so his users can determine their
exposure?

Should vendors provide security fixes free to authorized purchasers since the
type of risk is different than other bug fixes? What is the liability of a
system operator who chooses not to disclose that S/W maintenance is not done
and thus 'fixed' security bugs for a platform are not present? Can any
liability be attached to the vendor because of the operator's decision to not
pay for security fixes?
 
Richard H. Miller, Asst. Dir. for Technical Support, Baylor College of
Medicine, One Baylor Plaza, 302H, Houston, Texas 77030   (713)798-3532

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Serious bug in SVR3.2 gives root access easily
</A>
</H3>
<address>
&lt;<A HREF="mailto:sef@kithrup.com">
sef@kithrup.com
</A>&gt;
</address>
<i>
Sun, 17 Feb 91 00:33:35 -0800
</i><PRE>

In RISKS DIGEST 11.10 pwolfe@kailand.kai.com (Patrick Wolfe) writes:
&gt;It just goes to show that it was a good idea when I set my bbs up to run in a
&gt;"chroot" filesystem, where even if a user could break out of the bbs program
&gt;into a shell, there is no compiler (in fact, there are hardly any useful
&gt;commands at all) to mess around with.

This seems like a good place and time to point out that that isn't really
'secure' from the bug in question.  The major security aspect in the above
described system comes from the fact that there is no compiler or (easy?)
access to the shell; the chroot() only makes things slightly more
interesting and challenging.  (I leave it to the reader to figure out how to
change u.u_rdir, since *the entire u block is writable*.)

Systems known not to be affected by the bug include Dell UNIX (both 3.2 and
r4), in addition to the ones listed by Patrick.

For more details on the entire affair, read comp.unix.sysv386.

Sean Eric Fagan    sef@kithrup.COM

</PRE>
<HR><H3><A NAME="subj5.3">
Re: serious bug in SVR3.2 gives root access easily
</A>
</H3>
<address>
Steve Nuchia
&lt;<A HREF="mailto:steve@nuchat.sccsi.com ">
steve@nuchat.sccsi.com 
</A>&gt;
</address>
<i>
Fri, 15 Feb 91 23:16:44 GMT
</i><PRE>

On the subject of the 386 Unix security bug, which we recall makes
the u area (per-process system data structure) writable by user processes,
Patrick Wolfe (pwolfe@kailand.kai.com) said:

&gt;It just goes to show that it was a good idea when I set my bbs up to run in a
&gt;"chroot" filesystem, where even if a user could break out of the bbs program
&gt;into a shell, there is no compiler (in fact, there are hardly any useful
&gt;commands at all) to mess around with.

The number of ways one can go about getting bits into a file is truly amazing.
Even cat, or any of its moral equivalents, might do it if the bytes can get
past the serial driver.  In fact, finding a way to turn on an execute
permission bit is the hardest part of getting out of many chroot boxes.

The point I wanted to make here, lest anyone think that chroot is a shield
against this bug, is that the process' current root is stored (just like its
current directory) in the u area too.

This coupling of failure modes may strike one as undesirable initially,
But security is not the same as functional failure protection.  Rather than
making a single point to failure by grouping individually tollerable
failure points, putting all the security eggs in one u-area basket
makes a *single* single point to failure out of a whole clutch of them.

If the failure of any *one* component breaks the system, you don't
gain anything by running them on seperate power supplies.

Steve Nuchia	      South Coast Computing Services      (713) 964-2462

</PRE>
<HR><H3><A NAME="subj5.4">
386 Unix Security bug fixes from vendors
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
14 Feb 91
</i><PRE>

Without addressing any of the detailed (and significant) issues surrounding the
security bug in question at this time, the following is worth noting in any
case:

A recent poster to this list implied that they felt there would be no bug fixes
forthcoming for non-most-recent versions of 386 Unix from the various vendors.
This is not the case.  Two of the main vendors involved, ISC (386ix) and Everex
(Esix) have announced no-cost bug fixes or upgrades to be available to deal
with the problem.  ISC said that they expected their fix to become available
around 22 Feb 91.  Other involved 386 Unix vendors can hopefully be depended upon
to follow suit.

</PRE>
<HR><H3><A NAME="subj5.5">
Discussion of major security hole AT&amp;T SYSV/386 in comp.unix.sysv386
</A>
</H3>
<address>
Daniel A. Graifer 
&lt;<A HREF="mailto:dag@fciva.UUCP">
dag@fciva.UUCP
</A>&gt;
</address>
<i>
Mon, 18 Feb 91 11:33:51 est
</i><PRE>

Over the last few days, there has been a substancial discussion occuring in
comp.sysv.386 regarding a major security hole in a number of the commercial
Unix System V/386 version 3 releases.

On Thu Feb 14 08:11:04 EST 1991 lumpi@dobag.in-berlin.de posted a complaint
that he had found a technique by which any process could give itself
superuser priviliges under ISC Unix.  He claimed that ISC had been ignoring
his communications for half a year.  In "dispair" he posted a 50 line c program
which when executied made the /etc/passwd and /etc/shadow files world 
writable.  He also posted an uuencoded binary.

Responses poured in from owners of other systems.  SCO Unix appeared immune,
as were newer Dell releases.  ESIX was vulnerable, as are some of the
hardware vendor's proprietary releases (such as Prime's EXL300 series).

The bug arises from a combination of two factors in Intel 80386 based
machines.  Since many of these machines run without a numeric coprocessor,
allowance must be made to trap floating point instructions and invoke an
emulator.  Since the performance degradation of switching to kernal mode
for each instruction would be large, the emulator runs in user mode.  However,
it stores some items in the same memory page as the process' userid, and 
must have write access to this page (SysV/386 memory protection is on a
per page basis, the second contributing factor).  A process which may call
the emulator can dummy-up a pointer into this page and set it's uid to zero
(superuser).

It was claimed that AT&amp;T has known about the trapdoor for some time, had 
informed the source licensees long ago, and had distributed a fix with the
V.3.2.1 tapes.  An employee from SCO claimed they had fixed the problem
independently prior to the AT&amp;T release.  After someone on the net confirmed
that older versions of Dell unix were affected, an employee of Dell posted a
telephone number where owners of outdated releases could obtain fixes.  An
ISC employee posted that a fix would be available to A SUBSET (emphasis added
owners after February 22 by calling ISC's support number.

The discussion contained two threads especially interesting to risks readers:

	Was it proper for the "discoverer" of the hole to post it so widely and
	in such a dangerous form?  In his defence, he has not only raised the
	community's awareness of a serious problem, he has also forced ISC to 
	respond to the issue.  I did not see any postings in the group saying
	"Oh yeah, we systems administrators new about that."

	If it can be established that the vendors were well aware of the problem
	prior to the release of the software, were they legally negligent in
	distributing those release, and liable for any losses there customers
	sustained due this bug?

Because these systems are so 'cheap' (you can build a nice workstation for
significantly less than $1000), they are being installed at an enourmous
rate throughout the economy.  Even when the vendors get off the dime and
distribute fix already supplied by AT&amp;T,  how many vulnerable systems will
be left in operation?

This reminds me of the "sendmail bug" exploited by the Internet-Worm, or the
less well know System V "Inode Bug".  As a purchaser of operating systems, I
have no expectation that they will be bug free, but I am incensed when vendors
fail to distribute available fixes to well known major problems.  Or at least
make sysadmins aware in the release notes of their existence!

Daniel A. Graifer, Coastal Capital Funding Corp., 7900 Westpark Dr. Suite
A-130,	McLean, VA 22102 (703)821-3244	fciva.FRANKCAP.COM!dag@uunet.uu.net

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re:  Errors on Vietnam Veterans Memorial
</A>
</H3>
<address>
Al Arsenault 
&lt;<A HREF="mailto:arsenaul@usafa.af.mil">
arsenaul@usafa.af.mil
</A>&gt;
</address>
<i>
Fri, 15 Feb 91 16:22:03 MST
</i><PRE>

The following excerpts are taken from an Associated Press story in the Friday,
15 February Colorado Springs Gazette-Telegraph.

"Up to 38 live Viet vets may be listed as dead"

The man responsible for deciding which names were carved on the Vietnam
Veterans Memorial says there may be as many as 38 Army veterans mistakenly
listed as dead.  Robert W. Doubek said he wasn't positive at the time that the
men had been killed because their records were incomplete.  But he included
them anyway because he didn't know that it would be possible to add names once
the memorial was built.  "I had the idea these people might be lost to history
if we didn't include them", Doubek said in an interview.

The Associated Press disclosed earlier this week that 14 Army veterans listed
as dead on the wall are alive.  After reading that story, Doubek volunteered
that there may be another 24 errors.  Apparently it is `impossible' to REMOVE
names.

</PRE>
<HR><H3><A NAME="subj6.2">
vietnam vet's name on memorial
</A>
</H3>
<address>
Mary Smolka 
&lt;<A HREF="mailto:GA82293@INDYLLY.BITNET">
GA82293@INDYLLY.BITNET
</A>&gt;
</address>
<i>
Fri, 15 Feb 91 08:07 EST
</i><PRE>

    Regarding the comment about a name on the Vietman Memorial possibly
    being MIA:
        I was a tour guide in Washington DC for two summers while I was in
    college, and learned all sorts of trivia about the various memorials.
    It's true that there are different symbols on the memorial to denote
    KIA or MIA; a diamond next to a name indicated KIA while a cross, or a
    plus sign, indicates MIA. If a soldier listed MIA is found to have been
    killed, a diamond can easily be carved over the cross. If a soldier
    formerly MIA is found to be alive, the plan is to engrave a circle
    around the cross to denote "the circle of life." At the time I was
    guiding ('87,'88) there were no cases of this occurring, and I haven't
    heard of any since.
        With over 58,000 names on the memorial, there WERE mistakes made.
    Between my first and second summers, several names were added that had
    been found to be left off the memorial when it was first commissioned.
    And from what I understand, there are some other names that SHOULD be
    on, but there isn't any more room. Hope this helps.

    Mary Smolka.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Driving records (was Risks of having a sister)
</A>
</H3>
<address>
Jim Griffith
&lt;<A HREF="mailto:griffith@dweeb.fx.com ">
griffith@dweeb.fx.com 
</A>&gt;
</address>
<i>
Fri, 15 Feb 91 10:38:36 PST
</i><PRE>

sullivan@poincare.geom.umn.edu discussed tying tickets to drivers' licenses and
vehicles.  My understanding of California law is that they distinguish between
parking tickets and moving violations.  A moving violation is tied to a
driver's license, while a parking ticket is tied to a vehicle.  So moving
violations can affect license renewal, while parking tickets can affect vehicle
re-registration.  Strikes me as an intelligent approach, although I'm curious
as to how the DMV deals with changes of ownership of cars with unresolved
violations.
				Jim

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Quick n' easy access to Fidelity account info
</A>
</H3>
<address>
Steve Golson
&lt;<A HREF="mailto:sgolson@east.sun.com ">
sgolson@east.sun.com 
</A>&gt;
</address>
<i>
Thu, 14 Feb 91 19:14:45 EST
</i><PRE>

In RISKS 11.03 Carol Springs reports on a Fidelity Investments account
inquiry service that can be accessed with only the account holder's SSN.
 
I called Fidelity to ask them about it. They said the service had been
discontinued due to customer complaints, and that in any case it did
*not* allow complete access to holdings info. What you got was the
closing prices of the stocks etc. being held in the account, but *not*
the total value. Still this is bothersome enough. 
 
Fidelity does has a service called FAST (Fidelity Automated Service
Telephone) which requires an account number and the last four digits
of your SSN. Once you are into FAST you can get balance inquiries,
make account transfers, and even open new Fidelity accounts...
 
Steve Golson -- Trilobyte Systems -- Carlisle MA -- sgolson@east.sun.com
       (consultant for, but not employed by, Sun Microsystems) 
"As the people here grow colder, I turn to my computer..." -- Kate Bush

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-75</DOCNO>
<DOCOLDNO>IA013-000136-B032-377</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.14.html 128.240.150.127 19970217042011 text/html 22597
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:18:37 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 14</TITLE>
<LINK REL="Prev" HREF="/Risks/11.13.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.15.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 14</H1>
<H2> Wednesday 20 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Another Computer Application fiasco story 
</A>
<DD>
<A HREF="#subj1.1">
Christopher Allen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Software failures and safety of American (Red Cross) blood supply 
</A>
<DD>
<A HREF="#subj2.1">
Rob James
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
MD-11 computer problems 
</A>
<DD>
<A HREF="#subj3.1">
Steve Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
More on very reliable systems 
</A>
<DD>
<A HREF="#subj4.1">
Anthony E. Siegman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Predicting system reliability 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Broadcast LANs and data sensitivity 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: software warranties (re: SysV bug) 
</A>
<DD>
<A HREF="#subj7.1">
Brian Kantor
</A><br>
<A HREF="#subj7.2">
 David Lamb
</A><br>
<A HREF="#subj7.3">
     Steve Eddins
</A><br>
<A HREF="#subj7.4">
 Peter da Silva
</A><br>
<A HREF="#subj7.5">
 Henry Spencer
</A><br>
<A HREF="#subj7.6">
 Flint Pellett
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Another Computer Application fiasco story
</A>
</H3>
<address>
Christopher Allen 
&lt;<A HREF="mailto:Allen@RELAY.PRIME.COM">
Allen@RELAY.PRIME.COM
</A>&gt;
</address>
<i>
20 Feb 91 11:09:43 EST
</i><PRE>

The following copied from the (Manchester, UK) Guardian Weekly, Feb 17, 1991:

                         High-tech blackout

Whitehall's auditors are unable to verify Foreign Office spending last
year because of a breakdown in the main computer controlling the accounts.
John Bourn, the Comptroller and Auditor General, has refused to approve the
Foreign Office accounts, covering embassies, Nato, the United Nations, military
aid, the BBC World Service, and the British Council, because the ministry
cannot produce accurate evidence of the spending.

At one stage auditors found discrepancies totalling 458 million pounds between
the money granted to the Foreign Office and their own records.  After extensive
checking the auditors were left with 26 million pounds of imbalances in
accounts for embassies, external relations, the BBC and the British Council.

The trouble began when it was decided to replace its six-year-old computer
system with a new high-technology version.  Ministers allocated 560 thousand
pounds for the scheme, but ended up paying 937 thousand pounds employing a
software company, Memory Computers, which failed to deliver on time and went
into liquidation just after it did deliver.  Meanwhile, a hard disc shattered
inside the old computer, destroying all the information, and leaving officials
to rely on the new untried system.  Within months it started shutting down
unexpectedly, and inexplicably posting money to the wrong accounts.  All the
bookkeeping staff left and their replacements were not able to familiarise
themselves properly with the system to prevent further errors.

A consultant from the bankrupt software company is now working for the FO at a
salary of 53 thousand pounds a year to try to solve the problems.  MPs on the
Commons Public Accounts Committee are to summon Sir Patrick Wight, permanent
secretary at the FO, to explain the mess.

[FO=Foreign Office, MP=Member of Parliament, 1 pound ~ $2]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Software failures and safety of American (Red Cross) blood supply
</A>
</H3>
<address>
&lt;<A HREF="mailto:JAMESRC@QUCDN.QueensU.CA">
JAMESRC@QUCDN.QueensU.CA
</A>&gt;
</address>
<i>
Wed, 20 Feb 1991 12:51 EST
</i><PRE>

Recently "60 minutes" presented a report on the American Red Cross and on the
accidental release of untested donations to transfusion centres.  The FDA
documented &gt;2000 such cases, although (to my knowledge) no documented cases of
transfusion associated infection have yet been reported in the literature.
Some of the failures were associated with software problems in the various
regional AmCross centres, but that is as much as I know.

If anyone has further information on these (apparent) software failures,
I would appreciate additional information.

Rob James, Department of Community Health and Epidemiology, Queen's University
Kingston, Ontario, Canada K7l 2M1 613-542-3696

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
MD-11 computer problems
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@ulysses.att.com">
smb@ulysses.att.com
</A>&gt;
</address>
<i>
Wed, 20 Feb 91 15:50:02 EST
</i><PRE>

According to the AP, American Airlines has suspended flight certification
tests on a new MD-11 plane because of ``computer problems''.  That, and
some other problems with fuel economy, may lead the airline to refuse
delivery of a second MD-11.  No technical details on the computer problems
were given in the article; does anyone on RISKS know more?

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
More on very reliable systems 
</A>
</H3>
<address>
Anthony E. Siegman
&lt;<A HREF="mailto:siegman@sierra.Stanford.EDU ">
siegman@sierra.Stanford.EDU 
</A>&gt;
</address>
<i>
Wed, 20 Feb 91 12:13:10 PST
</i><PRE>

   Anyone concerned with the subject of multiple correlated failures in systems
with very reliable individual components should look back at the incident some
years ago when a United Airlines jet lost all three engines simultaneous in
flight over the Caribbean south of Miami.

   As best I recall, a mechanic servicing the plane had made the same mistake,
leaving out a needed O-ring (!), on the oil pressure sensors in all three
engines.  He did this because the stockroom clerk, who normally installed the
O-rings on the sensors before handing them to the mechanic, was temporarily
away, so the mechanic went behind the counter and got the sensors himself.

  This incident seemed to have multiple classic elements:

   1.  Minor change in procedures had major consequences.

   2.  The problem was really a false alarm, i.e., the oil 
       pressures were OK, just the sensor indications were wrong.

   3.  Confident claims that multiple jet engine failures were
       totally improbable proved completely wrong.

Oh, they did get one (or two?) of the engines restated, just in the
nick of time, however, and limped into Miami.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Predicting system reliability
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Tue, 19 Feb 91 23:40:50 EST
</i><PRE>

&gt;Argument 2: A system as complex as SDI can never be evaluated in a way which
&gt;would give reasonable grounds for claiming that it would work correctly when
&gt;deployed.

Of course, just what constitutes "reasonable grounds" is itself something
that should be part of the specifications, and it is something that may
have to be justified.  None of the complex systems designed for fighting
nuclear wars -- including the ones whose supposed efficacy has preserved
the peace of the planet for circa 40 years -- has *ever* been evaluated
in such a way (i.e. under nuclear attack!).  The design of test criteria
for such systems all too easily becomes a second-order way of cooking up
fallacious "proofs" that the system is anywhere from trivial to impossible.

Our lives depend frequently on systems that cannot possibly be tested to the
"reasonable confidence" point before they are used... if you interpret that to
imply reasonable confidence under the worst conceivable conditions.  No
airliner is ever tested in six-sigma turbulence.  No building is tested in
once-per-century wind loads.  Space-shuttle payload limits are based on landing
weight for the "Return To Launch Site" abort mode... a procedure that has never
been tried and which some astronauts doubt is survivable.  Operating-system
kernel software is rarely stress-tested under truly severe operational loads.

(As an example of that last, one of the major RISC-processor manufacturers does
massive simulation of new designs, to the point where their machine rooms go
from fairly quiet to furiously active at the time in late evening when the
night's batch of simulation jobs fire up.  This sudden huge surge in load has,
I'm told, had a serendipitous side effect: at least once it uncovered the
existence of very short "interrupt windows" in kernel code, where erroneous
assumptions about the atomicity of operations caused system failures only if an
interrupt struck in a window about a hundred nanoseconds long.  (Specifically,
the programmers had assumed that incrementing an integer in memory was an
atomic operation, which is sort of true on single-processor CISCs but is rarely
true on multiprocessors or RISC systems.)  The code containing this botch is
now theoretically obsolete, but it was in wide production use before the
problem was discovered and is probably still in use here and there.)

In traditional engineering, it is routine to assess worst-case behavior based
on extrapolation from less severe testing.  A demand that the worst case be
tested is often a disguised call for a system's cancellation, since such
testing is seldom feasible for large systems.  The proper consideration is not
whether we can safely extrapolate from less severe tests, because we must rely
on such extrapolation and we already do; the questions are how best to do such
extrapolation and what form of testing must be done to permit confident
extrapolation.
                         Henry Spencer at U of Toronto Zoology   utzoo!henry

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Broadcast LANs and data sensitivity
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Tue, 19 Feb 91 23:45:37 EST
</i><PRE>

&gt;How much of your data on the average network is really a security issue?
&gt;I work here at Boeing and, at least in my area, sensitive data is not
&gt;kept on the network ...

Unfortunately, this is probably a definition of "sensitive" which is too narrow
to be really applicable.  How much of your area's data could be posted on a
bulletin board in the bus station without upsetting Boeing or one of its
customers?  Probably not much.  Even material which is not "sensitive" in a
military sense is often of commercial value or significant to privacy.

                          Henry Spencer at U of Toronto Zoology    utzoo!henry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: software warranties (was: the SysV security bug)
</A>
</H3>
<address>
Brian Kantor
&lt;<A HREF="mailto:brian@ucsd.Edu ">
brian@ucsd.Edu 
</A>&gt;
</address>
<i>
20 Feb 91 06:00:25 GMT
</i><PRE>

&gt;From: rick@pavlov.ssctr.bcm.tmc.edu (Richard H. Miller)
&gt;[As an aside, I have a difficult time understanding why a person who does not
&gt;pay for software maintenance expects to have bugs fixed. If you choose to
&gt;not pay for the service, then don't expect the vendor to fix it for free.] 

I do expect the vendor to fix it for free.  When I pay for software, I do so
under the assumption that it would perform as specified, not that it sorta
might work kinda like what the manual said.

When you buy a device (say, a car) you are granted a warrantee that it's free
of defects, and will remain so for some length of time that is predicated
(disregarding, for the moment, marketing factors) on the designed length of
time it's to operate before it wears out.  Software does not wear out, although
it can become obsolete, so I would maintain that a piece of software which is
found, at any time, to not perform as specified at time of purchase is
defective and must be remedied by the vendor.  A manufacturer must remedy the
errors of his employees.  That you hire peoples' mistakes when you hire their
talents is one of the RISKS of doing business.

A company which is selling defective or adulterated materials should be made to
replace those materials with goods of the quality advertised.  I see no reason
that software should be exempt from this basic principle of fair dealing in
business.

Vendors who require paid maintenance agreements to repair faults where their
software does not perform as specified are ripping off their customers.  I
believe that it is unjust enrichment.

Does it seem fair to you that the product you bought does not work as specified
and could not have been tested by the maker of the product or he would have
found out that it didn't so work?  Not only have you been burned by buying
something that is broken, but you've had to act as the manufacturer's unpaid
quality control department, and they want you to pay for the privilege of
getting a working item!  Recall the definition of chutzpah - the man who kills
his parents then begs mercy from the court because he is now an orphan.

Now while I've overstated this for effect, I would really like people to think
about software warrantees, before the courts do it for us.  Ethics ARE
important: a professional should strive to be "an ornament to his profession."
	- Brian

</PRE>
<HR><H3><A NAME="subj7.2">
serious bug in SVR3.2 gives root access easily (<A HREF="/Risks/11.13.html">RISKS-11.13</A>)
</A>
</H3>
<address>
David Lamb
&lt;<A HREF="mailto:dalamb@avi.umiacs.umd.edu ">
dalamb@avi.umiacs.umd.edu 
</A>&gt;
</address>
<i>
20 Feb 91 14:07:18 GMT
</i><PRE>

A *bug* is a defect in the product.  Why *shouldn't* the vendor fix it for
free?  Enhancements, I'll agree, ought to be paid for.  Maybe this is diverging
from what RISKS ought to talk about, but...What are the risks to society of
fostering an attitude that the vendor has no responsibility for defects like
the security bug mentioned?

"Due to a design defect, your 1986 Model X car blows up if hit from behind in
an accident.  What, you didn't buy the $4000/year maintenance agreement?**
Sorry, no free recall for you.  Buy a 1991 Model X."

**25% of purchace price per year: a software "maintenance" price I've seen a
few times.
                                                  David Alex Lamb

</PRE>
<HR><H3><A NAME="subj7.3">
Charging for bug fixes (was: serious bug in SVR3.2 ... <A HREF="/Risks/11.10.html">RISKS-11.10</A>)
</A>
</H3>
<address>
Steve Eddins
&lt;<A HREF="mailto:eddins@uicbert.eecs.uic.edu ">
eddins@uicbert.eecs.uic.edu 
</A>&gt;
</address>
<i>
Wed, 20 Feb 91 14:37:22 GMT
</i><PRE>

I'll be the first to admit that I don't understand the economics of the
software industry and the in's and out's of software maintenance.  I'm just a
customer.  However, as a customer, I expect that when I pay for any product it
will work as advertised.  If it doesn't work, and the vendor wants to charge me
more money to make it work, I will cease purchasing from that vendor.

Steve Eddins	University of Illinois at Chicago, EECS Dept., M/C 154, 
1120 SEO Bldg, Box 4348, Chicago, IL 60680 	(312) 996-5771 		

</PRE>
<HR><H3><A NAME="subj7.4">
Re: RISKS DIGEST 11.13
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:peter@taronga.hackercorp.com ">
peter@taronga.hackercorp.com 
</A>&gt;
</address>
<i>
Wed, 20 Feb 1991 13:34:26 GMT
</i><PRE>

Poster #1:
&gt; [As an aside, I have a difficult time understanding why a person who does not
&gt; pay for software maintenance expects to have bugs fixed. If you choose to
&gt; not pay for the service, then don't expect the vendor to fix it for free.] 

Why not? The bug is the vendor's responsibility. Imagine Ford selling cars
with doors that unlocked if you hit them in the right place. Do you think
they would get away with only providing fixes to people with maintainance
agreements?

Poster #2:
&gt; Because these systems are so 'cheap' (you can build a nice workstation for
&gt; significantly less than $1000),

Could you explain how? My own system was more than that and I bought it
from a friend for a phenomenal price. The operating system alone is a
significant part of the cost.

I've seen 386SX platforms for $875. Add $375 for the cheapest runtime
only 2-user UNIX I've seen, and you're already at $1250. Add $300 for
the RAM and as much or more for the bigger hard drive, and you're in the
area of $2000. Now, $2000 I might be able to believe.

</PRE>
<HR><H3><A NAME="subj7.5">
Re: serious bug in SVR3.2 gives root access easily (<A HREF="/Risks/11.10.html">RISKS-11.10</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Wed, 20 Feb 91 13:12:44 EST
</i><PRE>

As I understand it, the people in question are not demanding free software
maintenance.  They are demanding that when they pay good money for software,
they get software that meets specifications at least to the extent of being
free of catastrophic flaws, and that if this cannot be assured at time of
purchase, some minimal effort is made to assure it when flaws are found.

                                         Henry Spencer at U of Toronto Zoology

</PRE>
<HR><H3><A NAME="subj7.6">
Re: serious bug in SVR3.2 gives root access easily (<A HREF="/Risks/11.10.html">RISKS-11.10</A>)
</A>
</H3>
<address>
Flint Pellett
&lt;<A HREF="mailto:flint@gistdev.gist.com ">
flint@gistdev.gist.com 
</A>&gt;
</address>
<i>
20 Feb 91 16:31:20 GMT
</i><PRE>

I would say that there is no reason software should be any different than
anything else you buy.  If you buy a new appliance, you get a guarantee for 90
days against defects in materials and workmanship, and when you buy software
you ought to get a similar guarantee.  A bug like this is a defect in the
workmanship, and if you are still covered by the guarantee, you ought to get it
fixed free.  But if you are past the 90 days (or however long) and you didn't
buy a maintenance contract, then you are (and ought to be) just as much out of
luck as if you didn't buy a maintenance contract on your fridge.  Software
buyers are likely to start paying attention to how long the guarantee is for,
and not buy from companies with really short guarantee periods.

However, there is another category of safety related bugs which have always
been in a seperate class: If the gas tank in your Pinto tends to explode, or
the car tends to shift itself into gear by itself, Ford does a recall (often
because the Govt. ordered it to) and fixes it at their expense.  The laws about
automobile recalls are a lot stricter than the ones on Software Developers, but
if software companies can't clean up their act themselves, then what we are
going to end up with is a big Federal bureaucracy monitoring stuff like this
just like the one that monitors the automakers.

This particular bug is pretty clearly a "safety related" bug, in that failure
to fix it could result in substantial losses by customers.  I believe the
software vendors also have a responsibility to let their customers know about
it too, and need to mail something out to all their users they know about that
either gives them the fix or tells them how to get it, just like the recall
notices that you get if something is wrong with your car that could affect your
safety.  If too many vendors decide that it will cost too much now to act
responsibly, then they're going to end up having to deal with a bunch of
federal regulators who will make them act responsibly, and it will end up
costing them (and us software buyers) a lot more.

Flint Pellett, Global Information Systems Technology, Inc., 
1800 Woodfield Drive, Savoy, IL 61874 (217) 352-1165 uunet!gistdev!flint 

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-76</DOCNO>
<DOCOLDNO>IA013-000136-B032-403</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.15.html 128.240.150.127 19970217042033 text/html 32973
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:18:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 15</TITLE>
<LINK REL="Prev" HREF="/Risks/11.14.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.16.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 15</H1>
<H2> Thursday 21 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Racetrack overpayments 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Peace Shield in trouble 
</A>
<DD>
<A HREF="#subj2.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Is Unix the ultimate computer virus? 
</A>
<DD>
<A HREF="#subj3.1">
Mike T. on Dick Gabriel
</A><br>
<A HREF="#subj3.2">
 via Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Murder, She Wrote 
</A>
<DD>
<A HREF="#subj4.1">
Jerry Hollombe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Maintenance, Warranties, etc. 
</A>
<DD>
<A HREF="#subj5.1">
Charles Shub
</A><br>
<A HREF="#subj5.2">
 Joseph M. Newcomer
</A><br>
<A HREF="#subj5.3">
    Richard H. Miller
</A><br>
<A HREF="#subj5.4">
 John Sullivan
</A><br>
<A HREF="#subj5.5">
 Greg Johnson
</A><br>
<A HREF="#subj5.6">
 Gene Spafford
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Racetrack overpayments
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.El_Segundo@Xerox.com">
Hoffman.El_Segundo@Xerox.com
</A>&gt;
</address>
<i>
Wed, 20 Feb 1991 15:16:26 PST
</i><PRE>

A short item by Steve Schuelein in the 'Los Angeles Times' 18 Feb. 91 says that
"a series of computer malfunctions" resulted in $26,000 in excess payouts at
the local Los Alamitos racetrack.  A too-lucrative payoff was posted for
several minutes before the error was corrected.

Track president and general manager Lloyd Arnold said the computer problems
also prevented satellite wagering at 14 outlets in Nevada, and the Nevada
Racing Commission might suspend wagering on races at Los Alamitos until the
problems are corrected.  According to Arnold, "[Amtote] said a printer on the
computer malfunctioned, but I think the personnel here is not qualified."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Peace Shield in trouble
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Wed, 20 Feb 91 22:21:48 EST
</i><PRE>

No, this is not another SDI contribution!  "Peace Shield" is the USAF-
managed project to provide Saudi Arabia with an integrated air-defence
control system.  From Flight International, 23 Jan:

	The USAF is looking to Hughes, Unisys, Westinghouse or General
	Electric to pick up the pieces of the Peace Shield Saudi Arabian
	air-defence ground environment following termination of most of
	Boeing's contracts on the beleaguered programme.

	The USAF says it cut the bulk of the $1.05 billion contract
	because of Boeing's "...failure to make progress so as to
	endanger final operational capability". [sic]

	[Original target date was April 1991.  Revised Boeing estimate
	was August 1994; USAF hopes others can do better.  USAF action
	probably prompted by Saudi pressure.]

	Boeing's difficulties centred on developing the software for
	integrating the disparate sensors, sector operations, sector
	command and command operations centres.

	The programme appears to have suffered a similar fate to other
	software-intensive projects in that the prime contractor
	underestimated the quantity and the technical complexity of
	the software.  Peace Shield required hundreds of thousands of
	code lines to be developed.

	The depth of the problem encountered by the company was indicated
	by its failure to meet even a considerably revised continental
	United States integration testing. [sic]

	[Boeing retains some minor hardware contracts for Peace Shield.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Is Unix the ultimate computer virus
</A>
</H3>
<address>
"Martin Minow, ML3-5/U26  19-Feb-1991 1606" 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Wed, 20 Feb 91 13:12:19 PST
</i><PRE>
                                            [Slightly edited by Martin Minow]

From:	"mt@media-lab.media.mit.edu"
To:	unix-haters@mc.lcs.mit.edu
Subj:	Worse is better 

I apologize for the relative lack of vituperation in the following,
but you can draw your own conclusions.
 
MADRE::MWM                                          203 lines   8-FEB-1991 
15:14

&gt;&gt; I once went to hear a talk by Thompson at MIT.  Thompson said one of
&gt;&gt; the professors had said to him, "I hate you.  UNIX stopped all research
&gt;&gt; in operating systems."  Thompson apologized.
 
The professor exaggerates - but not by much. The comments by Bob in .29
are relevant in both cases. Oddly enough, there's been some talk in
comp.society.futures about windowing systems, and an interesting article
(included below) on OS developement (included below) landed in my
mailbox recently.
 
The problem with OSF/Motif - and X in general - is not that it's missing
features; it's that critical parts of it are arcane and unusable. I'm not sure
that the resource mechanism can be deleted from it in any reasonable way.
 
	&lt;mike
 
This is an excerpt from Dick Gabriel's paper, "Good News, Bad News, and
How to Win Big."  The "MIT guy" and "Berkeley guy" mentioned herein are
Dan Weinreb and Bill Joy.
 
- - ---------- cut here and glue this to the inside of your forehead ----------
 
2.1    THE RISE OF ``WORSE IS BETTER''
 
I and just about every designer of Common Lisp and CLOS has had extreme
exposure to the MIT/Stanford style of design. The essence of this style can be
captured by the phrase ``the right thing.'' To such a designer it is important
to get all of the following characteristics right:
 
  + Simplicity -- the design must be simple, both in implementation and
    interface. It is more important for the interface to be simple than the
    implementation.
 
  + Correctness -- the design must be correct in all observable aspects.
    Incorrectness is simply not allowed.
 
  + Consistency -- the design must not be inconsistent. A design is allowed to
    be slightly less simple and less complete to avoid inconsistency.
    Consistency is as important as correctness.
 
  + Completeness -- the design must cover as many important situations as is
    practical. All reasonably expected cases must be covered. Simplicity is
    not allowed to overly reduce completeness.
 
I believe most people would agree that these are good characteristics.  I will
call the use of this philosophy of design the ``MIT approach.''  Common Lisp
(with CLOS) and Scheme represent the MIT approach to design and
implementation.
 
The worse-is-better philosophy is only slightly different:
 
  + Simplicity -- the design must be simple, both in implementation and
    interface.  It is more important for the implementation to be simple than
    the interface. Simplicity is the most important consideration in a design.
 
  + Correctness -- the design must be correct in all observable aspects. It is
    slightly better to be simple than correct.
 
  + Consistency -- the design must not be overly inconsistent.  Consistency can
    be sacrificed for simplicity in some cases, but it is better to drop those
    parts of the design that deal with less common circumstances than to
    introduce either implementational complexity or inconsistency.
 
  + Completeness -- the design must cover as many important situations as is
    practical. All reasonably expected cases should be covered.  Completeness
    can be sacrificed in favor of any other quality. In fact, completeness
    must sacrificed whenever implementation simplicity is jeopardized.
    Consistency can be sacrificed to achieve completeness if simplicity is
    retained; especially worthless is consistency of interface.
 
Early Unix and C are examples of the use of this school of design, and I will
call the use of this design strategy the ``New Jersey approach.'' I have
intentionally caricatured the worse-is-better philosophy to convince you that
it is obviously a bad philosophy and that the New Jersey approach is a bad
approach.
 
However, I believe that worse-is-better, even in its strawman form, has better
survival characteristics than the-right-thing, and that the New Jersey
approach when used for software is a better approach than the MIT approach.
 
Let me start out by retelling a story that shows that the MIT/New-Jersey
distinction is valid and that proponents of each philosophy actually believe
their philosophy is better.
 
Two famous people, one from MIT and another from Berkeley (but working on
Unix) once met to discuss operating system issues. The person from MIT was
knowledgeable about ITS (the MIT AI Lab operating system) and had been reading
the Unix sources. He was interested in how Unix solved the PC loser-ing
problem. The PC loser-ing problem occurs when a user program invokes a system
routine to perform a lengthy operation that might have significant state, such
as IO buffers. If an interrupt occurs during the operation, the state of the
user program must be saved. Because the invocation of the system routine is
usually a single instruction, the PC of the user program does not adequately
capture the state of the process. The system routine must either back out or
press forward. The right thing is to back out and restore the user program PC
to the instruction that invoked the system routine so that resumption of the
user program after the interrupt, for example, re-enters the system routine.
It is called ``PC loser-ing'' because the PC is being coerced into ``loser
mode,'' where ``loser'' is the affectionate name for ``user'' at MIT.
 
The MIT guy did not see any code that handled this case and asked the New
Jersey guy how the problem was handled. The New Jersey guy said that the Unix
folks were aware of the problem, but the solution was for the system routine
to always finish, but sometimes an error code would be returned that signaled
that the system routine had failed to complete its action. A correct user
program, then, had to check the error code to determine whether to simply try
the system routine again. The MIT guy did not like this solution because it
was not the right thing.
 
The New Jersey guy said that the Unix solution was right because the design
philosophy of Unix was simplicity and that the right thing was too complex.
Besides, programmers could easily insert this extra test and loop. The MIT guy
pointed out that the implementation was simple but the interface to the
functionality was complex. The New Jersey guy said that the right tradeoff has
been selected in Unix -- namely, implementation simplicity was more important
than interface simplicity.
 
The MIT guy then muttered that sometimes it takes a tough man to make a tender
chicken, but the New Jersey guy didn't understand (I'm not sure I do either).
 
Now I want to argue that worse-is-better is better. C is a programming
language designed for writing Unix, and it was designed using the New Jersey
approach. C is therefore a language for which it is easy to write a decent
compiler, and it requires the programmer to write text that is easy for the
compiler to interpret. Some have called C a fancy assembly language. Both
early Unix and C compilers had simple structures, are easy to port, require
few machine resources to run, and provide about 50%-80% of what you want from
an operating system and programming language.
 
Half the computers that exist at any point are worse than median (smaller or
slower). Unix and C work fine on them.  The worse-is-better philosophy means
that implementation simplicity has highest priority, which means Unix and C
are easy to port on such machines.  Therefore, one expects that if the 50%
functionality Unix and C support is satisfactory, they will start to appear
everywhere.  And they have, haven't they?
 
Unix and C are the ultimate computer viruses.
 
A further benefit of the worse-is-better philosophy is that the programmer is
conditioned to sacrifice some safety, convenience, and hassle to get good
performance and modest resource use. Programs written using the New Jersey
approach will work well both in small machines and large ones, and the code
will be portable because it is written on top of a virus.
 
It is important to remember that the initial virus has to be basically good.
If so, the viral spread is assured as long as it is portable.  Once the virus
has spread, there will be pressure to improve it, possibly by increasing its
functionality closer to 90%, but users have already been conditioned to accept
worse than the right thing.  Therefore, the worse-is-better software first
will gain acceptance, second will condition its users to expect less, and
third will be improved to a point that is almost the right thing.  In concrete
terms, even though Lisp compilers in 1987 were about as good as C compilers,
there are many more compiler experts who want to make C compilers better than
want to make Lisp compilers better.
 
The good news is that in 1995 we will have a good operating system and
programming language; the bad news is that they will be Unix and C++.
 
There is a final benefit to worse-is-better. Because a New Jersey language and
system are not really powerful enough to build complex monolithic software,
large systems must be designed to reuse components. Therefore, a tradition of
integration springs up.
 
How does the right thing stack up? There are two basic scenarios: the ``big
complex system scenario'' and the ``diamond-like jewel'' scenario.
 
The ``big complex system'' scenario goes like this:
 
First, the right thing needs to be designed. Then its implementation needs to
be designed. Finally it is implemented. Because it is the right thing, it has
nearly 100% of desired functionality, and implementation simplicity was never
a concern so it takes a long time to implement. It is large and complex.  It
requires complex tools to use properly. The last 20% takes 80% of the
effort, and so the right thing takes a long time to get out, and it only runs
satisfactorily on the most sophisticated hardware.
 
The ``diamond-like jewel'' scenario goes like this:
 
The right thing takes forever to design, but it is quite small at
every point along the way. To implement it to run fast is either
impossible or beyond the capabilities of most implementors.
 
The two scenarios correspond to Common Lisp and Scheme.
 
The first scenario is also the scenario for classic artificial intelligence
software.
 
The right thing is frequently a monolithic piece of software, but for no
reason other than that the right thing is often designed monolithically.
That is, this characteristic is a happenstance.
 
The lesson to be learned from this is that it is often undesirable to go for
the right thing first. It is better to get half of the right thing available
so that it spreads like a virus. Once people are hooked on it, take the time
to improve it to 90% of the right thing.
 
A wrong lesson is to take the parable literally and to conclude that C is the
right vehicle for AI software. The 50% solution has to be basically right, and
in this case it isn't.
 
But, one can conclude only that the Lisp community needs to seriously rethink
its position on Lisp design.  I will say more about this later.
 
 --- end ---

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Murder, She Wrote (<A HREF="/Risks/11.13.html">RISKS-11.13</A>)
</A>
</H3>
<address>
The Polymath
&lt;<A HREF="mailto:hollombe@ttidca.tti.com ">
hollombe@ttidca.tti.com 
</A>&gt;
</address>
<i>
21 Feb 91 02:01:58 GMT
</i><PRE>

}It seems to me like a little well-placed pressure on TV writers and producers
}might not only get them back in line ...

Alas, they never were in line in the first place.  I'm the son of a lawyer and
have many friends in the legal professions.  All agree on one thing:
Practically everything you see pertaining to the U.S. legal system in
television dramas is _wrong_.  Always has been.  Don't expect them to clean up
their act any time soon.

Jerry Hollombe, Citicorp, 3100 Ocean Park Blvd., Santa Monica, CA 90405
{rutgers|pyramid|philabs|psivax}!ttidca!hollombe (213) 450-9111, x2483

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Maintenance  (car recall/software analogies, <A HREF="/Risks/11.14.html">RISKS-11.14</A>)
</A>
</H3>
<address>
Charles Shub 
&lt;<A HREF="mailto:cdash@mumm.Colorado.EDU">
cdash@mumm.Colorado.EDU
</A>&gt;
</address>
<i>
Wed, 20 Feb 91 16:16:34 -0700
</i><PRE>

=&gt;  [ several articles on who gets fixes to bugs in software ]

I find this thread of discussion interesting and amusing.

We don't really do any "software maintenance" in this field.  What we are
really doing is "software upgrades" no matter what we want to call it.  I don't
know the history behind the term "maintenance" in this context but can
hypothesize several reasons.

The discussion brought to mind some past frustrations in dealing with a
subsidiary of Ford Motor Company, the frustrations arising on my part because
of my inability to convince some people there that software was somehow
fundamentally different from automobiles, and hence the construction processes
were probably dissimilar.  My frustration reached its peak when I was unable to
properly convey my incredulity at the notion of periodic scheduled preventive
maintenance on a piece of software.  I still do not understand what that means.

The risk, of course, is that by using a "wrong" term we imply wrong things as
aptly demonstrated (albeit peripherally) in the recent discussion of bug fixes.

charlie shub  cdash@boulder.Colorado.EDU  -or-  ..!{ucar|nbires}!boulder!cdash
              cdash@colospgs (BITNET)     -or-  (719) 593-3492

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Warranties
</A>
</H3>
<address>
"Joseph M. Newcomer" 
&lt;<A HREF="mailto:jn11+@andrew.cmu.edu">
jn11+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Wed, 20 Feb 1991 18:18:37 -0500 (EST)
</i><PRE>

&gt;&gt;From: rick@pavlov.ssctr.bcm.tmc.edu (Richard H. Miller)
&gt;&gt;[As an aside, I have a difficult time understanding why a person who does not
&gt;&gt;pay for software maintenance expects to have bugs fixed. If you choose to
&gt;&gt;not pay for the service, then don't expect the vendor to fix it for free.] 

&gt; brian@ucsd.Edu (Brian Kantor)
&gt;When I pay for software, I do so
&gt;under the assumption that it would perform as specified, not that it sorta
&gt;might work kinda like what the manual said.

Absolutely.  In fact, if Brian hadn't written this, I would have.  If a
shrink-wrap software license was applied to any product other than software,
Ralph Nader or his equivalent would be on the industry in nanoseconds, and
rightfully so.  I am a former product developer.  We took the attitude that you
had to add new features to a product, enough to justify the upgrade fee, AND
fix all the bugs reported in the previous version, insofar as possible (note
that it was not a bug if the software didn't do something the user expected, as
long as it hadn't been promised).  I find it immoral and unethical to charge
for bug fixes; the product was defective.  But since we couldn't afford to give
out free updates, we simply made the user buy the bug fixes by buying the new
features.  This is not totally acceptable, but is the best a 2.5 person company
can do.  On the other hand, I find it totally unacceptable that a company like
Apollo could release a Pascal compiler with known code generation problems and
refuse to fix it for a year because "it wasn't in the release cycle".  The
compiler generated incorrect code for compile-time constant expressions.

If we don't police ourselves, some vastly less competent and authoritarian
group will eventually do it for us.  And as software gets out more into the
public there is less and less tolerance for the past attitudes.

Law is a way of formalizing what should be polite behavior.  If everyone were
polite, laws wouldn't be needed.

Business-as-usual is putting us all at RISK.

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Serious bug... (Pellett, <A HREF="/Risks/11.14.html">RISKS-11.14</A>)
</A>
</H3>
<address>
Richard H. Miller
&lt;<A HREF="mailto:rick@pavlov.ssctr.bcm.tmc.edu ">
rick@pavlov.ssctr.bcm.tmc.edu 
</A>&gt;
</address>
<i>
21 Feb 91 00:26:50 GMT
</i><PRE>

Well, of all the postings so far in response to my original aside, this seems
to be the only one which read the rest of the article. I specifically made a 
point of asking whether this type of software defect warranted special 
treatment from software vendors. 

It is my feeling that there are two catagories of software defects that could
fit under this catagory, security defects and data corruption defects.I 
consider these two catagories to be similar to the type of defect which would
require a car to be recalled. They can cause the system to be destroyed or
data within it to become unreliable. [In a software sense this is comperable
to having the brakes fail or the gas tank explode.] These defects should be
fixed free of charge. 

Other types of defects would fit into the same category as what you get with a
car. The software is warrented for a period of time in which fixes will be
provided. At the end of this time, if you choose to not pay for maintenance,
then you are out of luck. [Just as if your distributor goes out on your card
after 1 year].

With this premise, what are the responsibilities of the vendor in providing
fixes to the two types of defects? I can see no problem on the part of S/W
vendors if a patch is all that is required to fix a problem. But if the problem
is in the design of the software and requires a redesign which would appear in
the next release, should users be provided the new version for free.

For the record, I believe that for security and data-integrity problems, the
vendor does have an obligation to provide fixes within the scope of the
original purchase.

Richard H. Miller, Asst. Dir. for Technical Support, Baylor College of
Medicine, One Baylor Plaza, 302H, Houston, Texas 77030   (713)798-3532

</PRE>
<HR><H3><A NAME="subj5.3">
Re: software warranties
</A>
</H3>
<address>
&lt;<A HREF="mailto:sullivan@poincare.geom.umn.edu">
sullivan@poincare.geom.umn.edu
</A>&gt;
</address>
<i>
Wed, 20 Feb 91 20:21:30 CST
</i><PRE>

Risks 11.14 had a very interesting discussion on software warranties.  Many
people responded to Richard Miller's suggestion (that someone who does not pay
for maintenance should not expect bug fixes) by pointing out that bugs are
defects and thus covered under the standard implicity warranties.

Flint Pellett suggests that software come with a limited-time guarantee, but
-&gt;if you are past the 90 days (or however long) and you didn't
-&gt;buy a maintenance contract, then you are (and ought to be) just as much out of
-&gt;luck as if you didn't buy a maintenance contract on your fridge.  Software
-&gt;buyers are likely to start paying attention to how long the guarantee is for,
-&gt;and not buy from companies with really short guarantee periods.

Since software does not deteriorate over time like hardware, I see little
point in putting a time limitation on any warranty.  Vendors may wish
to allow a short time period in which a dissatisfied customer could get
a refund, but bugs (no matter when they are discovered) were presumably
present at the time of purchase and should still be covered.  Of course,
there might be a problem if the company has long since discarded the
product.  But software usually has a limited useful life so I don't really
think we have to worry about people making warranty claims 20 years later.

There needs to be some limit, however, on the kinds of bugs covered.
Brian Kantor says
-&gt;I would maintain that a piece of software which is
-&gt;found, at any time, to not perform as specified at time of purchase is
-&gt;defective and must be remedied by the vendor.
I think this would merely lead to a lack of detailed specifications:
"You found a bug?  Oh, no, that's a feature."

It seems clear that safety-related bugs, like holes in operating systems,
should be fixed for free.  And if there is gross misrepresentation of
what the software does, or if it is so flaky as to be unusable, you would
want a refund.  If you buy a "screen editor" and get "ed", you return it.
But if you get "vi", I'm afraid you're stuck with a few minor problems
and shouldn't expect to have them fixed.  Everyone seems to know bugs
in "vi" (especially in autowrap), but don't hold your breath waiting for
Sun or Silicon Graphics or anyone like that to fix them.  The bugs are
often annoying, but "vi" is still quite useful, and does its basic job.
But does it "perform as specified"?

Software vendors should be expected to fix major bugs for free, but
when it comes to more obscure problems or those with easy workarounds,
this is less clear.  If the vendor has switched to a new version, with
substantial improvements along with fixes, it is hard for them to keep
maintaining all earlier versions.  While we might want free upgrades for
life, this should be an option at purchase time, not required by the
government, as it might drastically increase the cost of some software.

John Sullivan     sullivan@geom.umn.edu

</PRE>
<HR><H3><A NAME="subj5.4">
Software is not Hardware...(AT&amp;T != Ford)
</A>
</H3>
<address>
Greg Johnson
&lt;<A HREF="mailto:johnson@castor.cs.uga.edu ">
johnson@castor.cs.uga.edu 
</A>&gt;
</address>
<i>
Thu, 21 Feb 91 00:37:30 EST
</i><PRE>

Flint Pellet says:

&gt;I would say that there is no reason software should be any different than      
&gt;anything else you buy.  If you buy a new appliance, you get a guarantee for 90 
&gt;days against defects in materials and workmanship, and when you buy software   
&gt;you ought to get a similar guarantee.  A bug like this is a defect in the      
&gt;workmanship, and if you are still covered by the guarantee, you ought to get it
&gt;fixed free.  But if you are past the 90 days (or however long) and you didn't  
&gt;buy a maintenance contract, then you are (and ought to be) just as much out of 
&gt;luck as if you didn't buy a maintenance contract on your fridge.

I disagree.  The salient difference is that software, unlike hardware, is
not affected by physical laws.  Software is the expression of thought,
and does not wear out.  There are no bearings to go, no heat to fatigue.  Thus,
the defects which manifest themselves are purely a result of a failure on the
part of the manufacturer.   There is not, and should not be a MTBF for soft-
ware. Though migration between architectures may be grounds to void this
warranty, I cannot see how software houses can rationally set a warranty
period shorter than that on my hard drive.

</PRE>
<HR><H3><A NAME="subj5.5">
Re: warranties etc. (<A HREF="/Risks/11.14.html">RISKS-11.14</A>)
</A>
</H3>
<address>
Gene Spafford
&lt;<A HREF="mailto:spaf@cs.purdue.edu ">
spaf@cs.purdue.edu 
</A>&gt;
</address>
<i>
21 Feb 91 17:02:00 GMT
</i><PRE>

In RISKS 11.14 there were many responses along the lines of "If I pay
good money to buy software, I expect it to work as it should."

Brace yourself -- you didn't buy it.  You have licensed it.  If you check out
all the fine print somewhere, you'll see that you have a limited license to use
the software.

Also, if you look in that same fine print, you are probably going to find a
disclaimer of warranty that absolves your vendor of all liability, and that
explicitly disclaims any warrant of mechantability or fitness for any purpose.
I.e., the software may not do anything, but they aren't *legally* representing
it as supposed to be doing anything!

I don't think this is a proper way to do business, but it has become standard
in the industry.  There have been some cases where such warranty disclaimers
have been struck down in courts if the software failed to even boot up, but I
have never heard of the provisions being struck down for something like the
security bug leading to this discussion.

In general, if you were to purchase a car or TV or any other major
appliance, and in so doing had to sign a piece of paper that said
(effectively): 
  "You are not really buying this, you are leasing it.  You can't sell
   it or give it away without our permission, nor are you allowed to
   take it apart to see how it works.  We don't promise that it does
   anything in particular, despite what the salesman said.  If you try
   to use it and it fails, we're not responsible for any damages of
   any kind.  If really pressed, we'll exchange the item for a pile
   of the raw materials we used to construct it, at no charge to you.
   No other warranties are in effect on this item (except what may
   be in your state law) no matter what the salesman says -- we
   disavow any promises he made beyond this statement."
would you buy it?  We do it with software all the time.....

The problem has complex roots, beyond the scope of a short message
here: intellectual property, software specification and testing, and
poorly-informed consumers add to the problem.  We have cultivated a
professional and commercial attitude that is really like only 2 other
professions -- and they have state licensing imposed on them:
   "I'm sorry, we did everything we could to treat the infection, but
    he just didn't respond."
   "I'm sorry -- we gave it our best shot, but the jury didn't
    believe you."
   "I'm sorry -- we used state-of-the art methods, but you know how
    hard it is to find *every* bug."
 
The bottom line: by current definition and tradition, your vendor is not really
obliged to provide a fix unless you have a separate maintenance agreement.
Talk of a recall is "silly."  If you don't like it, you can always try to find
another vendor to whom you take your business.

Before any of you get too outraged by this, check carefully:
  *  If you sell a computer product, what do *you* disclaim?
  *  If you are a consumer, how many products have you bought
     this way without complaint?
  *  When have you conveniently blamed something on "the computer"?
 
Gene Spafford, NSF/Purdue/U of Florida, Softw. Eng. Research Center, Dept. of
Computer Sciences, Purdue University, W. Lafayette IN 47907-2004 (317) 494-7825

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-77</DOCNO>
<DOCOLDNO>IA013-000136-B033-13</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.16.html 128.240.150.127 19970217042048 text/html 22341
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:19:16 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 16</TITLE>
<LINK REL="Prev" HREF="/Risks/11.15.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.17.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 16</H1>
<H2> Monday 25 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
RISKS in radiation treatment of cancer 
</A>
<DD>
<A HREF="#subj1.1">
Peter Kendell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Computer Tax Glitch in Los Angeles 
</A>
<DD>
<A HREF="#subj2.1">
Steve Milunovic
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Computer problems with MD-11 jumbo jet 
</A>
<DD>
<A HREF="#subj3.1">
Fernando Pereira
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Re: Warranties 
</A>
<DD>
<A HREF="#subj4.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Accuracy in movies and newspapers 
</A>
<DD>
<A HREF="#subj5.1">
Tom Neff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Biology of Unix; Message attributions 
</A>
<DD>
<A HREF="#subj6.1">
Michael Travers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: Worse-is-better for the 1990s (Unix) 
</A>
<DD>
<A HREF="#subj7.1">
Joseph M. Newcomer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Peace Shield and "software development problems" 
</A>
<DD>
<A HREF="#subj8.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Monopoly Security Policies for Thumb Prints 
</A>
<DD>
<A HREF="#subj9.1">
Bob Baldwin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
Re: More on very reliable systems 
</A>
<DD>
<A HREF="#subj10.1">
Rod Simmons
</A><br>
<A HREF="#subj10.2">
 Robert I. Eachus
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
RISKS in radiation treatment of cancer
</A>
</H3>
<address>
Peter Kendell 
&lt;<A HREF="mailto:pete@tcom.stc.co.uk">
pete@tcom.stc.co.uk
</A>&gt;
</address>
<i>
23 Feb 91 10:07:42 GMT (Sat)
</i><PRE>

&gt;From the Guardian (London edition) Saturday February 23rd

Patients die after radiation mix-up

A Spanish health official said yesterday that he feared the worst for 24 cancer
patients who received high doses of radiation when a Zaragoza hospital's linear
accelerator went haywire for 10 days.  Three patients have already died.

A Zaragoza judge is investigating the causes of the disaster, which the
director of the Insalud chain of state-run hospitals called "the worst
accident in the world" of its type.

"We fear the worst for some of the patients," an Insalud spokesman, Fernando
Gomez, said.  "We are seeking information to find someone who has experience
in this kind of situation."

General Electric officials were unable to comment on the machine's operation.
Hospital officials said that the machine was now functioning normally.

Peter (pete@tcom.stc.co.uk)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer Tax Glitch in Los Angeles 
</A>
</H3>
<address>
"Steve Milunovic" 
&lt;<A HREF="mailto:Steve_Milunovic@qm.sri.com">
Steve_Milunovic@qm.sri.com
</A>&gt;
</address>
<i>
25 Feb 91 10:31:19 U
</i><PRE>

  [abridged by PGN]

A story by Denis Wolcott (with contributions from Walter Hamilton) in today's
Los Angeles Daily News from the NY Times service described how thousands of LA
County homeowners were billed up to $15,000 for three years' property taxes,
because of a 1988 glitch in an $18M computer system (`Optimum'), which did not
work and had to be rewritten from scratch.  As a result, the county was unable
to collect $10M in taxes, and has kept them from disbursing the tax money to
schools districts and other agencies.  Mercifully, the county will not charge
back interest on the unbilled back taxes!

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer problems with MD-11 jumbo jet
</A>
</H3>
<address>
Fernando Pereira
&lt;<A HREF="mailto:pereira@klee.research.att.com ">
pereira@klee.research.att.com 
</A>&gt;
</address>
<i>
Sun, 24 Feb 91 14:55:19 EST
</i><PRE>

According to the AP (2/20/91), American Airlines might refuse delivery of a
second MD-11 jet from McDonnell Douglas because of computer and fuel problems
with the first MD-11 it received. American's chairman said that the airline is
``very, very, very unhappy'' with the plane.  American has suspended flight
certification tests for the plane because of the computer problems.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Warranties
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.dec.com ">
horning@src.dec.com 
</A>&gt;
</address>
<i>
Thu, 21 Feb 91 12:31:18 PST
</i><PRE>

I, too, consider the standard shrinkwrap warranties scandalous, and definitely
a RISK to the public.  But it's not easy to see how to fix them.  Even though
the function of hardware is much better specified, computer hardware generally
comes with what I call the Kodak Film Warranty: "liability limited to cost of
unexposed film."

The current round of discussion has relied too much on strained analogies
with automobiles, and not enough on a rational discussion of the issues.
Greg Johnson and Gene Spafford separately made two important points in
RISKS 11.15.  Taken together, they provide a basis for considering what
a sensible warrantee should promise.

1) Software isn't a "thing" that can be purchased, it is a design.  As
Dijkstra has said, "The true subject matter of the programmer is the design
of computations."  If we pursue the automobile analogy, we need to consider,
not defective automobiles, but defective automobile designs (e.g., Pinto
gas tanks).

2) Software doesn't wear out, and hence doesn't need "maintenance" to cope
with physical wear.  Any defects were present at the outset.

I think publishing provides a more natural and enlightening analogy:

- We buy media containing software, just as we buy CD's containing music
or books containing words.

- There is a sharp distinction between the medium being defective (lost bits
or missing pages) and the contents being defective.

- Most publishers warrantee only the medium, not the contents.  However,
if a CD was labeled as Beethoven's Fifth Symphony and the contents turn out
to be 2 Live Crew, you can probably get an exchange during the first week
after purchase, even if you've broken the shrink wrap.

- The medium is subject to physical wear and decay, not the contents.

- Some publishers of certain kinds of books will, for a fee, provide periodic
updates to the contents of their books.  Most book buyers don't pay for such
services, but they are invaluable for a few.  Other publishers will supply
errata on request.

- There are few legal restrictions on what purchasers may do with the medium,
many more about what they may do with the contents.

Not much software is sold with a specification precise enough to allow a
customer to prove it "doesn't perform as specified."

Maybe someone who is outraged at the security hole that started this
discussion would post the part of his vendor's specification stating that
no such security holes exist?  Failing that, maybe someone would post a
specification that the vendors "ought to have" based their warrantees on?

After we see these specifications, we can discuss:

- What fraction of the total functionality of the operating system this
component of the specification represents.  We need some idea of the size
of the total specification that a warrantee should be based on.

- What fraction of the outraged customers would have noticed if JUST THIS
PIECE of the specification had been omitted by their software vendor.  And
what fraction of those who noticed would then have refused to buy it.

Until we have ANSI standards (or their equivalents) for complete operating
systems and application packages, I'm afraid that the ordinary customer is at
the mercy of the competence and goodwill of the software vendors.
                                                                     Jim H.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Accuracy in movies and newspapers (Re: Hollombe, <A HREF="/Risks/11.15.html">RISKS-11.15</A>)
</A>
</H3>
<address>
Tom Neff
&lt;<A HREF="mailto:tneff@bfmny0.bfm.com ">
tneff@bfmny0.bfm.com 
</A>&gt;
</address>
<i>
21 Feb 91 00:00:14 GMT
</i><PRE>

The beauty of TV and newspapers is that _everything_ in them is wrong!  This is
really true.  No matter what the subject matter is, if you happen to be a
specialist in that area, you'll grit your teeth when you read or watch.
Neurosurgery -- ballet -- the law -- names of streets in your own hometown --
archaeology -- accounting -- you name it, they get it wrong.  I'm not
surprised: the media have to talk about everything under the sun but couldn't
possibly afford to be experts in all of it.  The fun part is that even when
we're done rolling our eyes at, say, some egregious astronomy error, we sit
back and take at face value something about China or Churchill or Chernobyl or
child development!  We shouldn't.  Experts in those areas are busy gritting
their teeth even now -- while they swallowed the astronomy stuff without
complaint. :-)

    [Another instance that strikes home even more is being directly MISquoted
    after making a carefully worded direct statement and insisting that it
    be used verbatim if at all...  Perhaps there is nothing special about
    computers and related technologies that causes many media folks to be so
    far off the mark.  But there are lots of technological nonsophisticates
    writing on technology (and only a few really thoughtful and careful ones). 
    Perhaps the worst problem is the tendency toward 10-second sound bites and
    25-words-or-less oversimplifications.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Biology of Unix; Message attributions
</A>
</H3>
<address>
&lt;<A HREF="mailto:mt@media-lab.media.mit.edu">
mt@media-lab.media.mit.edu
</A>&gt;
</address>
<i>
Thu, 21 Feb 91 15:39:14 EST
</i><PRE>

Sorry, but I'm not the author of that message, it was forwarded from
some company's internal mail system and the best guess at the author
ID is MADRE::MWM.  My own opinion of Unix is that it's more like
crabgrass, or rabbits in Australia -- a rapidly-spreading and
obnoxious weed that invades computational ecologies and displaces the
native species.

Also, the Mike that signed the first few paragraphs is not me as you
inferred; it must be MWM.  I only wrote the first sentence.

    [finger informs me that "mt" is Michael Travers.  Apparently he was
    unaware that HIS OWN FROM: field did not give his own name!  In 
    response to a poke from me, he has now upgraded.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
worse-is-better for the 1990s
</A>
</H3>
<address>
"Joseph M. Newcomer" 
&lt;<A HREF="mailto:jn11+@andrew.cmu.edu">
jn11+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Thu, 21 Feb 1991 15:32:30 -0500 (EST)
</i><PRE>

Here we are in 1991.  The two primary operating systems (at least in volume)
are representative of O/S technology of the late 1960s to early 1970s (Unix and
MS-DOS), and the three important languages are C (vintage mid-1960s, i.e., it
is BCPL in disguise), LISP (vintage late 1950s) and Ada (vintage early 1970s).
With the exception of LISP, there have been many better operating systems and
languages lost along the way, and there seems to be no interest in updating our
technology.  I have my list of better languages and O/Ss (and it is probably
different than yours).  But on the whole, the barely-adequate-but-portable has
replaced the not-too-bad or even pretty-good but-not-portable.  There is a
lesson here.  There is a risk of accepting the barely adequate; you may have to
live with it for a long time.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Peace Shield and "software development problems"
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Mon, 25 Feb 91 14:45:19 EST
</i><PRE>

A friend, who has asked not to be identified, says it looks to him like the
Boeing problem with Peace Shield was not software-development trouble but cost
estimation.  (He has worked for Boeing but is not currently a Boeing employee.)
His feeling is that Boeing bid low on a fixed-price contract, discovered an
impending cost overrun, found that the Saudis weren't interested in pumping in
more cash, decided that the best way to cut its losses was to encounter fatal
software-development problems, and more or less stopped work on the project
until the schedule slippage became too severe to ignore and the contract was
cancelled.

This explanation is certainly plausible.  Whether accurate or not, it points
out a significant issue: problems in developing large software systems are
sufficiently common that it's convenient to use them as an excuse when
something goes wrong elsewhere.  It's probably wise to be very cautious about
blaming the software people for recent military systems, in particular.  DoD
has recently been using fixed-price contracts a lot, and a good many military
contractors have discovered -- the hard way -- that they've forgotten how to do
realistic cost estimates.  Since DoD basically has no memory, it's better to
default on the contract and accept some transient bad feelings than to fulfill
it and lose money.  Software makes a wonderful excuse, since it's considered a
natural law that a certain fraction of big software projects inexplicably fail
with nobody to blame.
                           Henry Spencer at U of Toronto Zoology   utzoo!henry

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Monopoly Security Policies for Thumb Prints
</A>
</H3>
<address>
baldwin_bob#tsii@tandem.com
&lt;<A HREF="mailto:Bob Baldwin ">
Bob Baldwin 
</A>&gt;
</address>
<i>
25 Feb 91 11:53:00 -0800
</i><PRE>

The California department of motor vehicles requires a right thumb print to get
a driver's license or state ID card, so the DMV now has a large online database
of thumb prints.  The primary purpose of this database is to prevent people
from taking on new identities without DMV knowing about it (and thus getting
clean driving records).

What if someone is supposed to have a new identity?  What about
witness relocation programs?  What about undercover police officers?
The DMV has to treat all its thumb print data as being as sensitive
as the most sensitive thumb print it contains.  One alternative is
for each government agency submit a list of the thumb prints that
need special restrictions.  Needless to say, the DMV wouldn't want to
pay for the safeguards that would be required on such a list.

The underlying problem is the desire to enforce security (access) policies that
imply monoploy control of data.  For example, the FBI wants to know about all
queries matching the finger prints of its employees.  The National Crime
Information Center can support this policy, but such a policy is hard to
enforce when different states are involved.  The FBI doesn't what to tell all
the states about all its employees.

What's the solution?  We could eliminate monopoly security policies and the
programs that depend on them.  We could have the federal government maintain
its monopoly, and provide services to the states.  We could trust the states to
make sure that only "good guys" access the data.  Perhaps the best solution is
to ignore the problem and go to lunch.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: More on very reliable systems (Leichter, <A HREF="/Risks/11.12.html">RISKS-11.12</A>)
</A>
</H3>
<address>
rod simmons 
&lt;<A HREF="mailto:rod@uceng.UC.EDU">
rod@uceng.UC.EDU
</A>&gt;
</address>
<i>
Sun, 24 Feb 91 11:56:15 -0500
</i><PRE>

&gt;In fact, I've always found it interesting how much more we demand from digital
&gt;systems than we demand from mechanical ones.       ^^^^^^^^^^^^^^^^^^^^^^^^^^^ 

Perhaps we "do" because we "can," or at least we think that we "can," based
upon an inspection of failure probabilities for various types of components and
devices (such as those given in WASH 1400, and other similar compilations of
failure data).
                                        --Rod Simmons

</PRE>
<HR><H3><A NAME="subj10.2">

</A>
</H3>
<address>
Robert I. Eachus
&lt;<A HREF="mailto:eachus@d74sun.mitre.org ">
eachus@d74sun.mitre.org 
</A>&gt;
</address>
<i>
Mon, 25 Feb 91 17:11:12 EST
</i><PRE>
Subject: Re: More on very reliable systems (Siegman, <A HREF="/Risks/11.14.html">RISKS-11.14</A>)

   Anthony E. Siegman (siegman@sierra.Stanford.EDU) said:

&gt;     Anyone concerned with the subject of multiple correlated
&gt;  failures in systems with very reliable individual components should
&gt;  look back at the incident some years ago when a United Airlines jet
&gt;  lost all three engines simultaneous in flight over the Caribbean
&gt;  south of Miami....

&gt;     2.  The problem was really a false alarm, i.e., the oil 
&gt;  pressures were OK, just the sensor indications were wrong.

   No, the engines were really overheating because all the oil leaked
out past the (missing) seals.

&gt;  Oh, they did get one (or two?) of the engines restated, just in the
&gt;  nick of time, however, and limped into Miami.

     When the middle engine started to overheat, the pilot shut it
down, declared an emergency, and immediately headed back toward Miami,
grabbing for altitude.  When the other two engines showed overheat, I
think he cut the RPMs back so that engine failure would not be
catastrophic, but in any case ran them to failure.  When these two
engines failed he was on a straight in glide to Miami International,
with calculations showing that at best glide, the plane would hit the
water a mile short of the runway.  Passengers were told to prepare for
the possibility of a water landing.

     At an altitiude of 200 feet as planned (and apparently as
explained to the passengers) the crew restarted the middle engine
(which they had shut down remember) and got the hoped for two minutes
of life out of it, long enough to land and get off the main runway.
All three engines were damaged beyond repair.

     Risks (or lessons learned) from this and the Gimli Glider
incident?  First, airline pilots should be required to have glider
experience.  In both these cases, the pilots knew what to do, however
there have been several cases where the aircrew behavior during a
multiple engine shutdown has verged on panic, most recently a Chinese
747.  (There have been lots of such incidents, usually involving
flying through clouds volcanic origin.)

     Also, and much more important, but often overlooked, is the value
of experience in knowing when some condition is "new" unknown and the
trust which should be given to the pilots by their employers (and the
FAA) in such cases.  What would have happened if the pilot in this
case took his time about turning back to see if he had a "real"
ememrgency?  In this case he acted immediately to turn around--he
could always turn around again if the problem wasn't serious, and
expect the airline to back his judgement.  With some airlines, the
pressure is in the opposite direction (schedule ahead of safety) and
that was a contributing factor in the Gimli glider incident.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-78</DOCNO>
<DOCOLDNO>IA013-000135-B036-9</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.17.html 128.240.150.127 19970217042142 text/html 23713
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:19:46 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 17</TITLE>
<LINK REL="Prev" HREF="/Risks/11.16.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.18.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 17</H1>
<H2> Tuesday 26 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The RISKS of automatic payments 
</A>
<DD>
<A HREF="#subj1.1">
Olaf 'Rhialto' Seibert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
"Autopilot malfunction causes engines to break off"! 
</A>
<DD>
<A HREF="#subj2.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Re: Computer problems with MD-11 jumbo jet 
</A>
<DD>
<A HREF="#subj3.1">
Daniel Faigin
</A><br>
<A HREF="#subj3.2">
 Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Reliability extrapolation 
</A>
<DD>
<A HREF="#subj4.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Risks of EMI? 
</A>
<DD>
<A HREF="#subj5.1">
Finkel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Risks of radiation treatment of cancer 
</A>
<DD>
<A HREF="#subj6.1">
Clark Savage Turner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: Accuracy in Movies and Newspapers 
</A>
<DD>
<A HREF="#subj7.1">
John Richard Bruni
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: worse-is-better for the 1990s 
</A>
<DD>
<A HREF="#subj8.1">
Jerry Gitomer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Automatic download of patches 
</A>
<DD>
<A HREF="#subj9.1">
Bill J Biesty
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
Workshop on Designing Correct Circuits 
</A>
<DD>
<A HREF="#subj10.1">
Victoria Stavridou
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The RISKS of automatic payments
</A>
</H3>
<address>
&lt;<A HREF="mailto:rhialto@cs.kun.nl">
rhialto@cs.kun.nl
</A>&gt;
</address>
<i>
Mon, 25 Feb 91 15:39:16 +0100
</i><PRE>

De Volkskrant" (a national daily newspaper in the Netherlands), 22 Feb 1991:

"Inhabitant of Amsterdam lies dead in appartment for half a year"

  AMSTERDAM - In an apartment in Amsterdam-Southeast the police found the
remains of a 51-year old man, who turned out to have died half a year ago.
[...] The man, who lived alone, died a natural death.  The police discovered
the man accidentally.  A police officer heard from the caretaker of the
building that he recently removed a large pile of mail for the victim from his
mailbox.  The occupant, who did not wish to have contact with his neighbors,
had not been seen for a long time.  When the police forced the door of the man,
the inanimate body of the man was found. The skin of the man "looked like
leather".
  [This is the RISKy part:]
  Because the rent and [natural] gas [for heating] and electricity bills were
automatically transferred, nobody missed him. The man also automatically
received an amount transferred into his bank account every month.  Also, not
one institution missed the man."

Need I say more?

Olaf 'Rhialto' Seibert, University of Nijmegen, The Netherlands

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
"Autopilot malfunction causes engines to break off"!
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Tue, 26 Feb 91 11:07:33 GMT
</i><PRE>

According to Flight International [27 Feb-5 March 1991. Page 8]:

A Boeing KC-135 apparently had two engines break off, shortly after
take-off, during Desert Storm operations in the Gulf. Apparently, autopilot
malfunction overstressed the airframe, causing one engine to break away and
hit a second, which was also torn from the wing. The 'plane is repairable,
which says a lot for the pilot's skill!

According to the caption on the accompanying picture (of an undamaged,
4-engine USAF KC-135) "KC-135s have overstressed in the past because of
autopilot disconnects".

Apparently, the 'plane performed a dutch roll, which can lead to overstrain
of the airframe because of the divergent coupling of roll and yaw.

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   mct@praxis.co.uk

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Computer problems with MD-11 jumbo jet
</A>
</H3>
<address>
&lt;<A HREF="mailto:faigin@aerospace.aero.org">
faigin@aerospace.aero.org
</A>&gt;
</address>
<i>
Tue, 26 Feb 91 07:50:57 PST
</i><PRE>

Well, someone who did vendor software IV&amp;V on a minor subsystem does remember a
few "oddities" -- like the vendor for the main flight computer not conforming
to the system ICD, and everyone else rewriting all interface software during
integration testing (on a crash basis) because the flight control software was
so kluged that everybody including MD was afraid to touch it. And that one of
the hydraulic control LRUs does the ARINC bus monitor checks, and tells
everyone else when to ignore the system (main flight) computers...

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Computer problems with MD-11 jumbo jet
</A>
</H3>
<address>
&lt;<A HREF="mailto:henry@zoo.toronto.edu">
henry@zoo.toronto.edu
</A>&gt;
</address>
<i>
Tue, 26 Feb 91 11:49:34 EST
</i><PRE>

As an interesting, and perhaps ominous, sideline on MD-11 computer problems,
McDonnell Douglas recently decided that its next big airliner, the MD-12,
will be fly-by-wire.
                                         Henry Spencer at U of Toronto Zoology

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Reliability extrapolation
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mct@praxis.co.uk">
mct@praxis.co.uk
</A>&gt;
</address>
<i>
Thu, 21 Feb 91 14:57:35 GMT
</i><PRE>

Henry Spencer comments that many systems which we currently trust (such as
large buildings) rely on extrapolation as part of their safety case. He
suggests that it may be reasonable to do the same for computer systems.

Maybe. Isn't most extrapolation based on the assumption that the system
behaviour is continuous? Chaos aside, most physical materials do exhibit
continuous behaviour up to the point of catastophic failure, and materials
science gives us some insight into where the catastrophic failure may occur.
(And sometimes that insight turns out to be wrong ...). Digital systems are,
by their nature, discontinuous. You cannot easily justify extrapolation *or
interpolation* of behaviour. There are digital weighing machines which give
the correct weights *except for a few specific values*. How do you assess
the probability of failure of a weighing machine with these
characteristics?

So can we justify extrapolation? Under what circumstances? To what limits?

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Risks of EMI?
</A>
</H3>
<address>
&lt;<A HREF="mailto:finkel@tartan.com">
finkel@tartan.com
</A>&gt;
</address>
<i>
Fri, 22 Feb 91 16:38:57 EST
</i><PRE>

As a mechanical engineer with a diverse career path, I have a few insights into
the controversy over the "cancer causing" electromagnetic radiation. (I have
enough statistics, chemistry, and analysis software experience to almost,
sort-of, maybe know what I am talking about.)

1) POWER LINES CAUSE CANCER -- They most certainly do, but not because
	of EMR. To keep the access roads clear and to keep vines and other
	plants from growing around the power towers, the companies sprayed
	2-4D, commonly known as dioxin or Agent Orange. (If you live near a
	power tower you have probably been exposed to a lot of agent orange).
	The possible carcinogenic effects of this chemical are well known. 

2) HAIRDRYERS AND TVS CAUSE CANCER -- Again, I have no argument with
	the truth of this statement. However, the cause is likely a chemical
	one. A hairdryer, they have removed all asbestos, is still a potent
	source of vapors. The high heat release some amount of the
	plasticisers into the air. This vapor laden air is promptly breathed
	in. The vapors then reside in the lungs because the particles fall 
        into that marvelous size that only floats, never settles. 

	With TVs, you again have lump of plastic which give off continual
	emmissions. The transformer and "sealed" electronic components also
	give off toxic emissions. A warm PCB gives of a field of vapor that
	reaches a lot further than any stray RFI.

3) CRTS CAUSE CANCER -- The plastics argument still holds. All the
	hot cases and components on the PCBS give off toxic fumes. Yet
	another source of the vapors is the office itself. All those pretty
	sound deadening screens, particle-board desks, plastic counter tops,
	synthetic carpets, paint, ... give off significant amounts of vapor.

	The kicker is that a NON_SMOKING environment contributes to the
	problem.  The American Society of Heating and Refrigeration Engineers
	(ASHRAE) has established "safe" airflows for smoking and non-smoking
	areas. The non-smoking airflow is roughly 1/3 that of a smoking area.
	Therefore, filtration is also about 1/3. The ducts are also smaller,
	and so on. SOOO, all those cute chemicals have a lot of time to
	sit in your lungs. 

	The larger volume of air required for smokers also results in far more
	clean air coming into a building. Much of this new, clean air comes in
	by design, where air is drawn in by vents. Air also comes in through
	doors and windows. The increased incoming airflow also results in more
	air going out, along with all the stale, chemical laden air. Net
	result: smoking sort of helps air quality.

	Another direct CRT confound is that the screen creates an
	electrostatic field. This field draws particles (dust, stray
	plasticisers, ... ) which increase the concentration of hazardous
	chemicals around the CRT. The electrostatic field creates an airflow
	of garbage into your work environment.

	I have no easy solutions. Some of these links may be be tenuous, but
	they are no more tenuous than the possibly erroneous correlations
	already drawn. The only real difficulty with my arguments is that the
	problems are worse, more pervasive, and harder to fix than just
	setting up a Faraday cage around a terminal.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Risks of radiation treatment of cancer
</A>
</H3>
<address>
Clark Savage Turner - WA3JPG 
&lt;<A HREF="mailto:turner@ICS.UCI.EDU">
turner@ICS.UCI.EDU
</A>&gt;
</address>
<i>
Mon, 25 Feb 91 20:17:42 -0800
</i><PRE>

I am keenly interested in the details of the Zaragoza, Spain accidents.

I have spoken with Gordon Symonds of the Canadian Bureau of Radiation and
Medical Devices (who investigated the AECL Therac-25 early on....)  and he
surmises that since GE is mentioned in the news bits, that the culprit could be
the CGR Saturne.  He explains that GE recently bought out CGR.

The Saturne is the underpinning machine for the Therac-20, predecessor of the
Therac-25.  Of course, the Therac-25 is well known for its several elusive
problems which caused massive overdoses.  The Therac-20 is also known to have
problems similar to those of its successor.

Can anyone lend a hand in tracking down these incidents?

- Clark Savage Turner,   UC Irvine

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Accuracy in Movies and Newspapers
</A>
</H3>
<address>
&lt;<A HREF="mailto:John_Richard_Bruni@cup.portal.com">
John_Richard_Bruni@cup.portal.com
</A>&gt;
</address>
<i>
Tue, 26 Feb 91 09:59:13 PST
</i><PRE>

I can understand the frustration that people feel when watching TV stories
that extend into a field in which they are experts.  But remember, the 
frustration may not be due to the *people* covering the story so much as
the level of simplicity needed to convey a complex story to the general
public.  To claim the networks use ignorant people to cover the news is
itself an ignorant statement.  Speaking for my own network, it happens that
our science correspondent has a doctorate in Immunology from a top-level
school.  Not too shabby considering how many stories on AIDS we have to do.
One of our anchors is incredibly well-versed in statesmanship, coming from
a long line of experts in the field and with more qualifications than you
can imagine, both in terms of degrees and expertise.  If he ever retires I`m
sure any Political Science school in the country would vie for his time.
It`s an easy thing to criticize the press.  We don`t ballyhoo our credentials
all over town but many of us have `em.  How bright would you look in your
field if you had to explain all your subject matter so the general public
could understand you?

Actually, you`d be a darned good teacher if you could do this.  The best
lecture I ever heard on relativistic effects was explained in a way that made
the topic seem almost simple.  That was a talented professor who gave that
lecture!
                                        JRB

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: worse-is-better for the 1990s
</A>
</H3>
<address>
Jerry Gitomer
&lt;<A HREF="mailto:jerry@TALOS.UUCP ">
jerry@TALOS.UUCP 
</A>&gt;
</address>
<i>
26 Feb 91 16:14:49 GMT
</i><PRE>

Perhaps what we are seeing is Gresham's Law as applied to computers:

        The operating systems and languages of lesser intrinsic value
	will drive the operating systems and languages of greater
	intrinsic value out of circulation, because those of greater
	intrinsic value will be hoarded.  

Now if I could only figure out how to hoard an operating system or high-level
language :-)
	
Jerry Gitomer at National Political Resources Inc, Alexandria, VA USA
         (703)683-9090      (UUCP:  ...{uupsi,vrdxhq}!pbs!npri6!jerry

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Automatic download of patches
</A>
</H3>
<address>
Bill J Biesty
&lt;<A HREF="mailto:wjb@edsr.UUCP ">
wjb@edsr.UUCP 
</A>&gt;
</address>
<i>
Tue, 26 Feb 91 09:32:22 CST
</i><PRE>

&gt;From this week's Computerworld

"HDS downloads disk code"  by Jean S. Bozman

Santa Clara, Calif. - Hitachi Data Systems Corp. (HDS) is not content to let its 
disk drives "call home" when they are not feeling well.  Now, HDS engineering 
staff can send some prescription medicine down the modem line, the compandy said 
last week.
	HDS claimed that an enhanced version of its Hi-Track maintenance program 
adds the dimension of on-line repairs to a 5-year-old automatic failure-reporting 
system.  "We can apply many microcode changes without taking the customer site 
down," said Jeff German, manager of technical support at HDS.
	The new feature, called Dynamic Microcode Download, adds to Hi-Track's 
existing capability to monitor, detect, diagnose and repair failing storage 
systems before they crash.
	"If you're reacting to the threshold of pain that people at you customer 
sites have, then you won't prevent failures," German said.
	After notifying customers of a device's impending failure, HDS technicians 
can send patched the software down a deadicated telelphone line.  Payment for 
the Hi-Track service is included in the normal maintenance fee; the same automatic 
call-in service will be extended to the new generation of HDS EX mainframes later 
this year.
&lt;	Hi-Track is installed in 3,000 disk drive and tape storage systems world-wide, 
according to HDS.

The Right Approach?
	However, some industry analysts are unsure whether this kind of service
can build HDS's market share relative to IBM and Amdahl Corp.  "This feature is
not by itself going to convince a customer to buy an HDS 7380 or 7390 disk
drive," said Robert Callery, a senior storage analyst at Technology Investment
Strategies Corp. in Framingham, Mass.  Not all microcode changes will be simple
enough to transmit over the wire, Callery added.  [...]  IBM has a service
director plan that automatically relays disk drive errors to IBM field sevice
centers [... which when ] recieved, IBM calls the customer site to schedule
maintenance. [...] DEC and HP also offer automatic device-error tracking
services.... 
 ---

The competitive market place is making a bigger push for reduced costs (customer
service visits) and introducing greater risks.  It will be interesting to see if 
any of the problems with the new service get reported in the press.

Is anyone familiar witht he service and can give additional details about what kind
of changes can be downloaded?

I believe there was an earlier dicussion concerning the Prodigy service's ability 
to automatically download changes to the remote PC's communications software.

I currently subscribe to America On-Line (AOL).  We recently got a flyer in the
mail saying that new features were going to be made available soon to users.  I
never got a disk in the mail.  Then just last week when I signed on I got a
dialog box saying "Updating software database" (or close to that).  When I went
to read postings on a bulletin board, there were new buttons to implement the
announced features!  My guess is that the data base changes were just the icon
image and associated codes to transmit to the host computer rather than an
executable.  I haven't been able to find any documentation on this "feature"
(which I'm sure saves AOL a ton of money avoiding mailings and disk
duplication) much less an agreement that I permit AOL to change data on my disk
drive!

Bill Biesty, Electronic Data Systems Corp., Research and Advanced Development,
7223 Forest Lane, Dallas, TX 75230                  edsr.eds.com!wjb

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Workshop on Designing Correct Circuits     
</A>
</H3>
<address>
&lt;<A HREF="mailto:Victoria.Stavridou@prg.oxford.ac.uk">
Victoria.Stavridou@prg.oxford.ac.uk
</A>&gt;
</address>
<i>
Mon, 18 Feb 91 10:58:28 GMT
</i><PRE>

IFIP                WORKSHOP ON DESIGNING CORRECT CIRCUITS     IFIP
WG 10.5                      Call for Papers                   WG 10.2
                           Lyngby, 6-8 January 1992

The purpose of this workshop is to bring together researchers interested in the
design of provably correct hardware. The intention is to have a small informal
workshop with focus on formal methods for designing correct circuits. In
particular we would like to see presentations of methods that have been used in
real designs. To keep this focus we will discourage papers which primarily
discuss tools or the theoretical foundations. The program committee will be
asked to observe these guidelines in their selection.  Relevant topics include
but are not limited to:

           - formal hardware design languages,
           - hardware design by transformation,
           - computing-aided design and verification of hardware,
           - methods of designing testable circuits,
           - analysis of circuit descriptions,
           - experience of the application of these techniques,
           - experience (good or bad) with formal methods.
 
The workshop will be of interest to researchers in the area of formal methods
for hardware design, and to engineers in industry wishing to keep abreast of
this fast-moving and exciting field.

Programme committee: Joergen Staunstrup, Lyngby (chairman), Luc Claesen, IMEC,
Peter Denyer, Edinburgh, Hans Eveking, Darmstadt, Mike Fourman, Edinburgh,
Geraint Jones, Oxford, Tom Melham, Cambridge, Mary Sheeran, Glasgow, Robin
Sharp, Lyngby, P.A. Subrahmanyam, AT&amp;T

In addition to paper selection the program committee will find a "responder" to
each paper selected for presentation. The responder will give a 5-10 minute
criticism of a paper just after the presentation and the option of getting a
1-2 page contribution in the printed proceedings.

Call for papers: You are invited to submit a draft full paper on a relevant
subject by 15th August 1991. Four copies should be sent to the chairman of the
program committee: Joergen Staunstrup.  Notification of acceptance will be
posted by 15th October, and revised copies of full papers must be received by
1st December in order to be distributed at the workshop. The proceedings will
be published by North Holland.

Local arrangements: The workshop will meet at the Technical University of
Denmark in Lyngby.  Robin Sharp is in charge of local arrangements.  We intend
to keep the cost of the workshop, meals and accommodation around Dkr. 2000 (US$
350).  Questions about the subjects of the workshop and other technical
enquiries can be addressed to one of the organizers:

           J. Staunstrup or R. Sharp, 
           Department of Computer Science, Building 344 
           Technical University of Denmark, 
           DK-2800 Lyngby, Denmark 
   e-mail: jst@id.dth.dk  or robin@id.dth.dk 
 
   tel:    (+45) 45 93 33 32          fax:    (+45) 42 88 45 30

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-79</DOCNO>
<DOCOLDNO>IA013-000135-B036-21</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.18.html 128.240.150.127 19970217042152 text/html 21198
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:20:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 18</TITLE>
<LINK REL="Prev" HREF="/Risks/11.17.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.19.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 18</H1>
<H2> Thursday 28 February 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A weird error message -- old Cyber clock tale 
</A>
<DD>
<A HREF="#subj1.1">
Andrew Clayton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Tennis anyone? (name confusion) 
</A>
<DD>
<A HREF="#subj2.1">
anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Burden of Proof: name confusion in driver's license bureau 
</A>
<DD>
<A HREF="#subj3.1">
Steve Sears
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
But the computer person said it was OK! 
</A>
<DD>
<A HREF="#subj4.1">
Dick Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Dave Rotheroe's "Retail Sales Oversight -- No backup" note 
</A>
<DD>
<A HREF="#subj5.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: LINAC deaths at Zaragoza 
</A>
<DD>
<A HREF="#subj6.1">
Trevor Cradduck
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Multiple engine failures 
</A>
<DD>
<A HREF="#subj7.1">
Mary Shafer responding to David Lesher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Re: MD-12; Automatic download of patches 
</A>
<DD>
<A HREF="#subj8.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Re: Risks of EMI? 
</A>
<DD>
<A HREF="#subj9.1">
Bob Ayers
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A weird error message -- old Cyber clock tale
</A>
</H3>
<address>
Andrew Clayton
&lt;<A HREF="mailto:dac@prolix.pub.uu.oz.au ">
dac@prolix.pub.uu.oz.au 
</A>&gt;
</address>
<i>
25 Feb 91 11:43:46 GMT
</i><PRE>
Newsgroups: alt.folklore.computers,rec.humor (courtesy of spaf@cs.purdue.edu)

When NOS/BE finally got to a stable configuration (about two years after they
decided it was a dead O/S), three places in the world noticed a problem - if
the machine stayed up for 24 DAYS, the system time-of-day clock would go
haywire, and crash the system. :-)

The bug had never previously been found, because nobody had a Cyber running
NOS/BE that had stayed _up_ for 24 days continuously!

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Tennis anyone? 
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
26 Feb 91
</i><PRE>

   Svensson moves up after error spotted

   PARIS, Feb 26 (AFP) - Jonas Svensson of Sweden was the victim of the sort of
unintentional error he thought he had put behind him when this week's ATP
rankings were calculated.  Svensson, the beaten finalist in the Stuttgart
Classic at the weekend, originally appeared to have dropped from 13th to 17th.
But the error was due to the confusion over his tennis-playing namesake, and
the revised rankings reveal that he has actually moved up one place to 12th.
   Svensson dropped the initial B. from his original playing name Jonas B.
Svensson once the other Jonas Svensson on the circuit retired from the game and
the possibility of confusion seemed to have disappeared.  But when it came to
compiling the new rankings, someone apparently keyed in the points Svensson
earned in Stuttgart under the other Jonas Svensson's name.  That had the
additional effect of catapulting the now-retired Svensson into 140th place in
the rankings, which was even more surprising as during his entire career he
never rose higher than the 445th place he occupied in January 1984.  [...]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Burden of Proof: name confusion in driver's license bureau
</A>
</H3>
<address>
Steve Sears
&lt;<A HREF="mailto:sjs@iconsys.icon.com ">
sjs@iconsys.icon.com 
</A>&gt;
</address>
<i>
Wed, 27 Feb 1991 12:02:14 MST
</i><PRE>

The recent article by Robyn Grunberg reminded me of an experience I had in
1984.

I received notice from my insurance company that my automobile insurance was
being raised drastically (4X as I recall).  After deciphering the code that
gives the reason for a rate increase, I found that I had been booked for a DWI
(Driving While Intoxicated).  At first I found this amusing, as I don't drink
at all.

I called the insurance company to clear up what was an obvious mistake, and
found that not only did they disbelieve me, but was given a lecture on driving
and drinking!  In order for them to change, I had to supply them with proof
that I did not have a DWI, in triplicate, as well as a character witness.  They
made the mistake, yet I was given the burden of proof; not only of my not
having committed the alleged offense, but of my personal integrity as well.
And no, they had the facts and did not see any reason to verify them.

At the drivers license bureau, my record was as clean as I thought it to be.  I
got the printout (for a fee) and then had it notarized (for another fee).  It
was a slow day, and the clerk was amused by my little story, so he started
playing with my drivers license number to see if a juxtaposition mistake had
been made.  We finally found the offender, who has the same last name and hence
(in Utah), the same drivers license number but with an ADDITIONAL postfix
character.

After sending this information, along with a letter from a couple of people who
know me stating they had never seen me ingest alcohol, I was out $21 cash and
had missed a few hours of work.

I then received a call from the insurance company who, instead of apologizing
for the mistake, cross examined me on every point.  I finally broke off with
this person by threatening to sue unless they corrected their mistake.

Needless to say, I changed insurance companies.  I also finally received
notification that I had been reinstated to my previous status.  No apology.
The risk here comes down to a burden of proof sort of thing.  I can see myself
going broke in the event a large percentage of the companies I deal with all
made mistakes and put the burden of proof on me.

Rather than just switch insurance companies in the first place, it seemed to me
that if the record was not corrected, this disinformation would propagate and
leave me in a worse position than meeting them head on.

Steven J. Sears, Sanyo/Icon       sjs@iconsys.icon.com       (801) 226-8057

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
But the computer person said it was OK!
</A>
</H3>
<address>
&lt;<A HREF="mailto:rlw@ida.org">
rlw@ida.org
</A>&gt;
</address>
<i>
Thu, 28 Feb 91 12:46:55 E
</i><PRE>

Yesterday I went to the pharmacy to pick up a prescription that had been phoned
in.  When you pick up there, they make you sign across a computer-printed label
that is origianlly clipped to your prescription but which they peel off and
stick to a clip board for you to sign.  After signing, I noticed that I had
signed two identical labels that were sort of overlapping.  Seems bogus so I
asked the clerk, "Why two?"  Answer: "Sometimes the computer prints two
labels."

Abbreviating a longer interchange:
Me: I only got one prescription, tear one up.
Clerk: I can't
Me: Let me talk to pharmacist
Pharmacist:  Don't worry about it.
Me: I am worried.
Pharmacist to clerk: Tear it up
(Clerk goes on to serve next customer)
Me: ?
Clerk: I'll do it later.
Me (to manager): ...labels...
Manager: I'm too busy to worry about that now.

Next morning, I recount the story over the hone to the insurance company
who pays for my prescriptions.  Thanks.  They'll get back to me.

Several rounds of telephone tag.  Then a completely satisfactory
explanation:  "The computer person said they can't charge you twice for
the same prescription."  "But suppose they are charging for two
prescriptions."  "Don't worry, we have a numbering scheme that prevents
our being charged twice."

Repeat for frustration_level:= 1 to 4
	Me: but...
	Ins. Co.: the computer person said that can't happen
Taeper

Nuts.  Maybe the computer DOES accidently print two labels sometimes.
After all, I'm smarter than their computer and I make misteaks sometimes.

--Dick Wexelblat  (rlw@ida.org) 703 845 6601

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Dave Rotheroe's "Retail Sales Oversight -- No backup" note
</A>
</H3>
<address>
&lt;<A HREF="mailto:wex@PWS.BULL.COM">
wex@PWS.BULL.COM
</A>&gt;
</address>
<i>
Thu, 28 Feb 91 15:40:44 est
</i><PRE>

While Dave notes the technological problems and customer-relations problems
inherent in the situation he described, he only hints at what, to me, is the
biggest RISK of all.

The problem is that the automation of these positions has led to the
de-skilling of the workforce involved in them.  It takes much less initiative
and much less smarts that it used to: running something over a laser scanner,
pressing a few buttons, and getting the customer to sign a receipt is not
nearly as mentally or physically complex as the task used to be.

This is true not only for sales/retail positions, but for almost every job
which has been automated.  Where people have not been outright replaced by
machines, they've been replaced by people with lower skill levels and often
less experience and less education.

The result is a (you should pardon the phrase) dumbing down of the workforce.
This leads to more and more situations where the workers are unable to
understand/deal with/repair the machines with which they interact and are
unable to perform the machine's functions when it fails.

As I see it, this has two negative consequences (call them risks if you like).
There are situational problems such as customers being unable to get the
product or service they want (and possibly businesses failing as a result), and
there are societal problems such as loss of control, loss of motivation, loss
of our country's position in the world.

I recommend interested RISKS readers pick up a copy of Barbara Garson's THE
ELECTRONIC SWEATSHOP (Simon &amp; Schuster 1988 ISBN 0-671-53049-6).  She takes a
step-by-step look at a number of jobs which are being automated.  Even in
places like financial planning where we'd like the planners to be smart, she
shows how automated systems have led to dumber users.

--Alan Wexelblat			phone: (508)294-7485
Bull Worldwide Information Systems	internet: wex@pws.bull.com

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
LINAC deaths at Zaragoza
</A>
</H3>
<address>
Trevor Cradduck 
&lt;<A HREF="mailto:trevorc@uwovax.uwo.ca">
trevorc@uwovax.uwo.ca
</A>&gt;
</address>
<i>
Thu, 28 Feb 91 12:25:33 EST
</i><PRE>
Organization: Nuclear Medicine, U. Western Ontario, Canada

I am given to understand that the linear accelerator in Zaragoza that has given
rise to the recent deaths from radiation treatment is a Sagitar 35 manufactured
by CGR and marketed and serviced by GE.  Unlike the earlier tragedies involving
Theratrons from AECL, this machine does NOT have any computer control.  So far
as one can tell, this "accident" came about due to the machine having been left
in an improper condition for treatment following service for a fault, and the
improper condition was not detected before a number of patients had been
treated.  The case is due to go before the courts so that the parties involved
are (understandably) reluctant to release detailed information.

Trevor Cradduck, Dept. of Nuclear Medicine, Victoria Hospital, U. Western
Ontario, LONDON, Ontario, Canada, N6A 4G5 (519) 667-6574 TREVORC@UWOVAX.BITNET

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Multiple failures
</A>
</H3>
<address>
&lt;<A HREF="mailto:David Lesher <wb8foz@mthvax.cs.miami.edu>">
David Lesher &lt;wb8foz@mthvax.cs.miami.edu&gt;
</A>&gt;
</address>
<i>
Wed, 27 Feb 91 17:05:18 EST
</i><PRE>

Date: 27 Feb 91 17:48:49 GMT
Path: mthvax!news.miami.edu!ncar!ames!skipper!shafer
From: shafer@skipper.dfrf.nasa.gov (Mary Shafer)
Newsgroups: rec.aviation
Subject: Re: ref. to 3 holer/o -rings incident
Organization: NASA Dryden, Edwards, Cal.

(David Lesher) writes:

   I'm looking for a reference to tell me the date/carrier on that 727
   that took off from MIA without vital o-rings on the burners, and barely
   limped back in time, roaching the 3 fans in the process.

1.  Report No. NTSB/AAR-84/04

4.  Title and Subtitle: Aircraft Accident Report--Eastern Air Lines, Inc.,
Lockheed L-1011, N334EA, Miami International Airport, Miami, Florida, May 5,
1983.

16. Abstract: At 0856, on May 5, 1983, Eastern Air Lines, Inc., Flight 855, a
Lockheed L-1011, N334EA, with 10 crewmembers and 162 passengers on board,
departed Miami International Airport en route to Nassau, Bahamas.  About
0915:15, while descending through 15,000 feet, the low oil pressure light on
the No. 2 engine illuminated.  The No. 2 engine was shut down, and the captain
decided to return to Miami to land.

The airplane was cleared to Miami and began a climb to FL 200.  While enroute
to Miami, the low oil pressure lights for engines Nos. 1 and 3 illuminated.  At
0928:20, while at 16,000 feet, the No. 3 engine flamed out.  At 0933:20, the
No. 1 engine flamed out while the flightcrew was attempting to restart the No.
2 engine.

The airplane descended without power from about 13,000 feet to about 4,000
feet, at which time the No. 2 engine was restarted.  The airplane made a
one-engine landing at Miami International Airport at 0946.  There were no
injuries to the occupants.

The National Transportation Safety Board determines that the probable cause of
te accident was the omission of all the O-ring seals on te master chip detector
assemblies leading to the loss of lubrication and damage to the airplane's
three engines as a result of the failure of mechanics to follow the established
and proper procedures for the installation of master chip detectors in the
engine lubrication system, the repeated failure of supervisory personnel to
require mechanic to comply with strictly withe prescribed installation
procedures, and the failure of Eastern Air Lines management to assess
adequately the significance of similar previous occurrences and to act
effectively to institute corrective action.

Contributing to the cause of the accident was the failure of Federal Aviation
Administration maintenance inspectors to assess the significance of the
incidents involving master chip detectors and to take effective surveillance
and enforcement measures to prevent the recurrence of the incidents.  [...]

Mary Shafer  shafer@skipper.dfrf.nasa.gov  ames!skipper.dfrf.nasa.gov!shafer
NASA Ames Dryden Flight Research Facility, Edwards, CA

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: MD-12; Automatic download of patches (Biesty, <A HREF="/Risks/11.17.html">RISKS-11.17</A>)
</A>
</H3>
<address>
"Martin Minow, ML3-5/U26  26-Feb-1991 2248" 
&lt;<A HREF="mailto:minow@bolt.enet.dec.com">
minow@bolt.enet.dec.com
</A>&gt;
</address>
<i>
Wed, 27 Feb 91 15:04:19 PST
</i><PRE>

Henry Spencer writes that, irrespective of the MD-11 computer problems,
the MD-12 will be fly by wire.

This reminds me of the old joke:

  How many programmers does it take to change a light bulb?
  One, but you can never change it back again.

Bill Biestly writes about automatic download of patches in disk drives.
I've seen a lot of new hardware designed -- roughly -- as follows:

-- core functions in ROM or EPROM.
-- everything else loaded at boot time.

For example, a large part of the Macintosh system software is in ROM, but
much of it is patched by the operating system bootstrap.  I've also seen
disk drives where the ROM code is just smart enough to load the real disk
code from a manufacturer's "private" area on the disk.  These disks had
two ways to modify the firmware:

-- a "secret" sequence of SCSI commands could be used to read/write the
   private area.
-- there was an asychronous terminal line interface that could be connected
   to a debugging terminal.  This could be used to patch the firmware and/or
   dump internal tables and error logs.

I also know of a modem that can have its firmware updated over the phone
(I begged the manufacturer to put a jumper/switch on the board to prevent
this without direct user intervention.  I also recommended some sort
of signature mechanism that would allow users to verify that they 
have correct firmware.  This was not a Dec product, by the way.)

While I'm quite aware of the risks involved, one should also understand
that there benefits to the user.  Finding the tradeoff between trust,
mistrust, and convenience is a difficult problem, of course.  My real
worry is that these changes are being made without customers who may
have good reason not to use a re-configurable modem understanding the
issues involved.

Martin Minow			minow@bolt.enet.dec.com

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Risks of EMI?  (Finkel, <A HREF="/Risks/11.17.html">RISKS-11.17</A>)
</A>
</H3>
<address>
Bob Ayers
&lt;<A HREF="mailto:ayers@src.dec.com ">
ayers@src.dec.com 
</A>&gt;
</address>
<i>
Tue, 26 Feb 91 17:17:57 -0800
</i><PRE>

In RISKS 11.17, mister "enough statistics, chemistry, and analysis software
experience to almost, sort-of, maybe know what I am talking about" writes that

    1) POWER LINES CAUSE CANCER -- They most certainly do, but not because
	of EMR. To keep the access roads clear and to keep vines and other
	plants from growing around the power towers, the companies sprayed
	2-4D, commonly known as dioxin or Agent Orange. ... The possible 
        carcinogenic effects of this chemical are well known. 

Unfortunately, as they say, "that turns out not to be the case."  I have
enough chemistry background, and have done enough recent reading, to know
that dioxin, 2-4-D, and Agent Orange are three separate things:

    2-4-D: a chemical herbicide
    Agent Orange: a mixture of 2-4-D and 2-4-5-T, a second chemical herbicide
    Dioxin: a minor chemical contaminant (production byproduct) in 2-4-D.

And "the possible carcinogenic effects" of those chemicals (he means the
dioxin) is *not* well known.  The only bad effect of doixin on humans that has
been reasonable established is chloracne.

Zero for two.                                      Bob

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-80</DOCNO>
<DOCOLDNO>IA013-000135-B036-41</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.19.html 128.240.150.127 19970217042207 text/html 30387
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:20:35 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 19</TITLE>
<LINK REL="Prev" HREF="/Risks/11.18.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.20.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 19</H1>
<H2> Friday 1 March 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
About Risks in Believing AI Gurus 
</A>
<DD>
<A HREF="#subj1.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Re: Jim Horning's note on software warranties 
</A>
<DD>
<A HREF="#subj2.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
But the computer person said it was OK! 
</A>
<DD>
<A HREF="#subj3.1">
Steve Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Automatic Patching 
</A>
<DD>
<A HREF="#subj4.1">
Larry Nathanson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Risk from workstations with built-in microphones 
</A>
<DD>
<A HREF="#subj5.1">
Steve Greenwald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Specs for special equipment 
</A>
<DD>
<A HREF="#subj6.1">
Jim Purtilo
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: worse-is-better for the 1990s 
</A>
<DD>
<A HREF="#subj7.1">
Tim Chambers
</A><br>
<A HREF="#subj7.2">
 Mark McWiggins
</A><br>
<A HREF="#subj7.3">
    Flint Pellett
</A><br>
<A HREF="#subj7.4">
 Dan Franklin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
About Risks in Believing AI Gurus (M.Minsky)
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein@rz.informatik.uni-hamburg.dbp.de">
brunnstein@rz.informatik.uni-hamburg.dbp.de
</A>&gt;
</address>
<i>
1  Mar 91 17:45 +0100
</i><PRE>

On February 19-20, 1991, Borland collected, on the occasion of its 10th
anniversary, a rare collection of gurus, experts, engineers, artists in Munich
(Title: European Software Festival). On the program:

   - Niklaus Wirth on his Oberon language concept (lecture, workshop)
   - Bjarne Stoustrup (AT&amp;T) with 2 lectures on C++/Object Oriented Programming
   - Marvin Minsky: Lecture on Personal Software and Programs Who Know You
                    (but he really gave a survey of AI history)
                    plus Lecture on Artificial Animals
   - Philippe Kahn: Back to the Future
   - Joseph Weizenbaum against overestimation in research
   - Izumi Aizu: Hypernetwork Society

Some more could not come (Alan Kay should not use plane), others really did not
come (Cyberspace guru Jaron Lanier was only virtually present in a video)

One of the most stimulating (and generally uncomparable) events was a concert
of Tod Machover (composer, director MIT Media Lab) who demonstrated his
"conductor-aiding handglove" in a new composition, after having demonstrated
his concept of "hyperinstruments" with a piece from his opera "Valis".

Also some native German speakers:
   - Computer Art professor Herbert W. Franke on Experimental Esthetics
   - Thomas von Randow on Cryptosystems ("If Mary Stewart had applied crypto-
        logy..."
   - my own contribution was on Risky Paradigms in Informatics' Box of Pandora
        (starting from J.v.Neumann's assumption, that his EDVAC be equivalent
         to the human brain, with peripheral devices analog to "organs", I 
         analysed risks in misconceptions, errors in realisations, 
         misunderstanding on the users side, and malicious misuse, with 
         examples well known to Risk Forum readers).

For about 2,000 participants in gigantic Gasteig Philharmonic site, this must
have been a stimulating experience, but at least some of them will have
corrected (hopefully) their world model on trustable gurus when Marvin Minsky,
in a `press conference' was asked whether he would like to connect his nerves
and brain to a `desktop brain' machine. Following his lecture where he argued
that the human brain consists of about 40 neural machine each of which may have
a specific frame architecture (he represented theories of Darwin, Freud, Piaget
as specific search trees, and he discussed several types of frames representing
brain activities), he then exclaimed: Imagine that you install 400 neural
machines which will give 10 times the power of a brain! While Joseph Weizenbaum
sat on the other side very quietly, Marvin became even more explicit when he
discussed the possible role of philosophers (at most, those of the last 200
years seemed relevant to him) and religion (which he suggested to forbid as
religion does not contribute to problem-solving).

No surprise that philosophers such as Socrates are not discussed in AI circles:
following the relativity of knowledge (Oida ouden eidos! =I know that I do not
know!), a knowledge base is a self-contradiction! (I now understand why MIT
students were forbidden philosophy in Marvin's time as dean, as Joe Weizenbaum
remembers).

&gt;From a European point of view, the rational aspects, Human Information
Processing and its Informatics equivalent "Artificial Intelligence" were so
overemphasized that it became very difficult to believe that Marvin Minsky
really believed what he said. With his special inspiration, Joseph Weizenbaum
brought this to the real point when (summing up his experiences in discussions
at MIT) he mentioned a dream: "I dreamt that Marvin leaves at his end - which
is hopefully very far in the future a letter - saying: I never meant what I
said!"

Personally, I would feel much more comfortable if I knew that Marvin Minsky is
more conscious of the impact of his words; but I think that he just means what
he (and many others) says: that there is only a difference in material (dry
Silicium realisation of "intelligence" versus the evoluted wet Carbon-based
brain), and that it is only lack of contemporary knowledge why today's
machines' intelligence seems inferior to human one. And that the vanishing
difference between machine and brain will evolute in intelligence amplifiers
where human nervous system may be connected to a desktop machine. In my
analysis, it is this kind of misconceptions that are an esssential reason for
contemporary computer accidents - misconceptions of scientists (uncritically
following paradigms and unverified assumptions), top- and
medium-level-misconceptions, misimplementations, misunderstandings on the
users' side, conscious use of side effects and other misuse...

Klaus Brunnstein, University of Hamburg (March 1, 1991: 5 p.m. GMT)

PS: apologies to those who regard such philosophical discussions as mere
    speculations; I honestly do not wish to distract anybody from analysing
    real accidents on a realistic (that is, non-philosophical) basis.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Jim Horning's note on software warranties (RISKS DIGEST 11.16)
</A>
</H3>
<address>
&lt;<A HREF="mailto:wex@PWS.BULL.COM">
wex@PWS.BULL.COM
</A>&gt;
</address>
<i>
Fri, 1 Mar 91 13:21:57 est
</i><PRE>

While I don't want to turn this into a comp.software-eng flamefest, I would
like to disagree with something I think Horning is implying.  He says:

&gt; Software doesn't wear out, and hence doesn't need "maintenance" to cope
&gt; with physical wear.  Any defects were present at the outset.

This is true only in the most trivial sense.  "Defects" can be one of two
things.  Either:
	- a defect is a difference between the actual operation of the
program and some formal specification of its intended behavior; or
	- a defect is a difference between the actual operation of the
program and some expectation on the part of the users/designers/clients.

Now, in the first sense it's true that software doesn't come to have more
defects over time (though more may be discovered, obviously).  However, it's
important to remember that the latter definition is the one more commonly
used, and under that definition, programs will indeed "wear out."

That is, I assert we cannot think of a program only as having a static set of
defects which prevent it from meeting its intended purpose.  Rather, there is a
dynamic gulf between the expectations of the users and the operation of the
program.

This is why software engineers are taught "the specification is *never*
frozen."  This is why complex systems which take years to be delivered so often
fail.  It's not that they don't do what they were originally intended to do --
it's that they can't cope with all the additional things they were asked to do
during development (q.v. any number of military systems, command &amp; control
systems of all sorts).

As an aside, I don't like the analogy between software and books because books
are primarily inert conveyers of information; people expect programs to *do*
things.  It's one thing to complain that your on-line encyclopedia is "wrong"
and another thing entirely to complain that your aircraft-landing system is
"wrong."

--Alan Wexelblat, Bull Worldwide Information Systems	phone: (508)294-7485

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Faxing a horse
</A>
</H3>
<address>
&lt;<A HREF="mailto:JERRY@HMCVAX.CLAREMONT.EDU">
JERRY@HMCVAX.CLAREMONT.EDU
</A>&gt;
</address>
<i>
Fri, 1 Mar 1991 00:40 PST
</i><PRE>

Today I attended an "Adobe Technical Conference."  Contrary to its
name, this was mainly a marketing meeting.

One discussion examined PostScript Level 2.  One addition is the
ability to create forms that are cached in memory (or on disk.)  The
idea is that one will be able to call up a form that will have
already been imaged and thereby speed printer output.

Another discussion focused on the integration of PostScript and FAX
technology.  Adobe would like to see printers which have built in fax
send/receive capabilities.  Their idea is that with such a
printer/fax device one could have remote printing on any fax machine
in the world.  They have planned extensions to PostScript Level 1 &amp; 2
to permit a user to print a file with a phone number and have the
printer fax the file to the phone number.

In many ways, this is an attractive idea.  To push it further, they
would have these PostScript printer/fax machines recognize when they
had connected with another PostScript printer/fax device and in those
cases send PostScript files.  This is also an attractive idea when
you consider a) the visual improvement PostScript can add to faxes
and b) the compression in data of sending the PostScript over the
scanned bits (Adobe claimed reduction of transmission times by
factors of 2 to 25.)  Adobe demonstrated this benefit by stating that
1/2 of all phone calls from Japan to the United States are made by
fax machines.  You can imagine the money saved by reducing the length
of these phone calls by a factor of two.

The Adobe representative also portrayed what seemed to him an
excellent idea.  A company (a manufacturer for example) might cache
their purchase order form on a supplier's printer/fax machine's disk
and then reduce their fax transmittal times to the order itself, with
no time spent transmitting the form.

Later on, I cornered the Adobe representative in a hallway and spoke
of my concerns that some manufacturer could play tricks by ordering
parts for a competitor and use a competitors purchase order form to
make it all seem very legitimate.

Well, I didn't know the half of it.  The representative admitted that
security issues were great and offered a better scenario:

Imagine thieves faxing a trojan horse into another printer/fax
machine.  The receiver would be looking at an innocuous message,
something like, "Hello World.", or "Joe's Pizza is now open", but his
printer/fax would contain a PostScript program that copies future
output to disk and late at night faxes that output back to the
thieve's machine.

It's good to know that Adobe realizes the potential problems before
producing the product and is trying to install features to prevent
the abuse.  Still, Adobe has many "unsophisticated" users and it will
be interesting to see how they teach these users that their
printer/fax machines can become a corporate spy.

Jerry Bakin.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
But the computer person said it was OK!
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@ulysses.att.com">
smb@ulysses.att.com
</A>&gt;
</address>
<i>
Thu, 28 Feb 91 20:26:15 EST
</i><PRE>

That reminds me of an incident that happend to me a few Saturdays ago.  I
needed to pick up some 12-gauge electrical cable.  I browsed past the 14-gauge
coils, then picked up a 25' coil of 12-gauge.  The price was about twice what
the 14-gauge cost.  Odd, and unreasonable; I checked further.  The 25' coil of
12-gauge cost exactly the same as a 50' coil; that price in turn was slightly
more than the same length of 14-gauge.  Ah -- someone put the wrong sticker on
the 25' coil, I thought.  There was a clerk standing nearby; I pointed out the
error to him.  He consulted a handy printout.  ``Nope; it's priced correctly;
see?'' Sure enough, the printout showed that 25' and 50' of 12-gauge wire cost
the same thing.  I tried pointing out that that was unreasonable; he shrugged
and walked away.

Having a bit of time, I decided to tell the manager.  It took a bit of
explaining to get my point across; one of the two individuals I was speaking to
didn't understand anything I was saying.  After all, the computer had the price
as the sticker; what was the problem?  I finally made myself understood, but to
no avail -- store prices were set from the regional computer center a few towns
away, and nothing could be done until the office re-opened on Monday.  The
price was wrong, and absurd -- but there was no way for them to fix it.  (That
they didn't do anything else, such as pulling the erroneously- marked coils
from the shelf is another matter, of course.)
                                                    --Steve Bellovin

P.S.  The next time I was in, a few days later, the pricing had been corrected.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Automatic Patching
</A>
</H3>
<address>
Larry Nathanson
&lt;<A HREF="mailto:lan@bucsf.bu.edu ">
lan@bucsf.bu.edu 
</A>&gt;
</address>
<i>
Wed, 27 Feb 91 22:29:00 -0500
</i><PRE>

When I read the first half of the article on the Hi-Track Dynamic Microcode
Downloading, my thoughts turned immediately to America Online.

I can vouch for the fact that AOL is self patching- I've seen Macintosh and
Apple //e code come down the pike, into my computers.  Sometimes it's icons,
sometimes the inherent menu structure changes- sometimes new modules appear.  I
don't think there is any limit to what they can send over the lines- after all,
they have game modules available on an optional basis (for the //e anyhow)
which contain much code.

Nowadays, the patches are rather infrequent.  During beta testing they were
almost daily.  The risks of accepting executable code, straight off the line,
and executing it w/o giving the user a chance to virus check seems
nerveracking, and my first impulse was that it is a risk.  However, after some
thought I decided that it should be relatively safe.

There are 2 ways viral code could get through- an outside job, and an inside
job.  For an outside job, the hacker would have to figure out the communiction
code, (As a beta tester of the original Applelink Personal, let me tell you
that this is NOT easy to do.), AND dissassemle the entire communications
software- to find out where to patch.  Then our illustrious hacker would have
to establish a link to the user's pc.  To do this, #1) The user would have to
call the hacker's machine which would emulate a telenet node, or #2) the hacker
would have to take over one or more telenet nodes.  Neither is easy to
accomplish without either the user knowing, or telenet getting VERY upset
(i.e., litigious).

While anything is possible, I'm willing to bet that this is sufficiently
improbable that AO is safe to external hacks using the patch command to give me
a virus.  Remember that nothing is 100% safe.  Also- if they DID give me this
virus, then SAM should grab it as soon as it starts to go after another
application.

As for inside jobs, well, I don't know.  One would hope that a disgruntled
employee couldn't do anything alone that the 'gruntled' employees wouldn't
stop.  I know that 'freedom of hacking' is kept rather tight around Quantum-
sometimes the people who are supposed to be doing things run into trouble.  My
feeling is that they are aware of the risk, and have safeguards to prevent such
a thing - it would be the end of a very promising online system, if such a
scandal was to occur.  And the same caveat- while nothing is 100% safe, a
runtime infection checker should catch anything while it's on the move.

(NOTE- I am not an employee of Quantum Computer Inc, makers of America
Online, and other nifty things.  I am a former beta-tester and online
guide, with no current formal affiliation, except for lots of friends.)

--Larry Nathanson    lan@bucsf.bu.edu

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Risk from workstations with built-in microphones
</A>
</H3>
<address>
"Steve Greenwald" 
&lt;<A HREF="mailto:sjg@reef.cis.ufl.edu">
sjg@reef.cis.ufl.edu
</A>&gt;
</address>
<i>
Fri, 1 Mar 91 12:46:49 -0500
</i><PRE>

A lot of new workstations and personal computers now come with a built-in
microphone with hardware to digitize the microphone input.  Example
applications are digital signal processing and voice-annotation of software for
documentation purposes.  Many of these workstations are designed to be used as
stations on local area networks (LANs).  Additionally, it is quite common in
some organizations to have workstations in the offices of individuals.

One risk of this technology seems clear: it is entirely possible for a
determined person to write software that will activate the microphone and
digitizer without the knowledge of the workstation user.  The digitized
acoustic data could then either be locally stored in the workstation (say, on a
hard disk) for later retrieval, or, if the workstation is attached to a
network, the data could even be sent to the eavesdropper's location.  If the
network is used, it would be quite possible (given the throughput of modern
LANs) to send digitized voice.  Using common techniques, digitized voice data
requires a data rate in the neighborhood of 56 kilobits per second, while most
LANs have data rates in the area of megabits per second.  Of course, this
method would require that the eavesdropper somehow acquire access to the
workstation (perhaps with a trojan horse, or even physical access).  Naturally,
this would allow someone remote in time and/or space to eavesdrop on the area
around the workstation.

Some possible solutions:

1) Eliminate the microphones when not absolutely required.

2) Have a switch (either manual or software controlled) to turn the
   microphone circuitry on or off.  A problem with this solution is
   that it requires the user to remember to turn the microphone off
   when it is not in use, and would not eliminate eavesdropping while
   the microphone was turned on during periods when the user was not
   using it.  Additionally, if the switch were software controlled,
   the eavesdropper's software could simply turn it on if it detected
   it as being turned off.

3) Have some sort of indicator (say, an LED) which would clearly show
   when the microphone circuitry was active.  The indicator should be
   under the control of hardware only, to prevent it being disabled
   by the software of the eavesdropper.

4) Have an automatic logging function which would record the time and
   duration of each use of the microphone circuitry.  A problem is 
   that such a log would have to be frequently examined by the user,
   unless some sort of automated exception reporting were used.

5) Have some sort of sound-blocking cover which the user can put over
   the microphone when it is not being used.  A possible problem with
   this solution is that if the eavesdropper has physical access to
   workstation, it would be possible to replace the cover with a fake
   one which is not sound-blocking.  Therefore it would be desirable
   to have some sort of build-in facility which could test the operation
   of the cover.

6) Require some sort of user authentication whenever the microphone is
   to be used.  Even something as simple as a "dead man's switch" would
   work (although that could be annoying in practice).

Steve Greenwald, graduate student, Computer and Information Sciences
University of Florida, Gainesville, Florida               

               [The microphone problem was previously discussed in the 
               context of NeXT by E. Loren Buhle, Jr. in <A HREF="/Risks/10.65.html">RISKS-10.65</A>.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Specs for special equipment
</A>
</H3>
<address>
Jim Purtilo
&lt;<A HREF="mailto:purtilo@cs.UMD.EDU ">
purtilo@cs.UMD.EDU 
</A>&gt;
</address>
<i>
Wed, 27 Feb 91 00:54:53 -0500
</i><PRE>

I have just checked into the hotel wherein a large meeting of software folks is
held.  The meeting announcement stated "if you plan on bringing a PC for use in
the hotel room, then be sure to tell the hotel this when you make reservations.
They will have the special equipment for you to hook your modem to the hotel
phone system."  I did this when making reservations.

There are specs and then there are specs, of course.  At the desk, I asked
"do you have the equipment I asked for?" to which I received a cheery "of
course, Dr. Purtilo! We have your request entered right here in our computer."

Indeed.  

I find my room is spacious, and quite special.  It is well suited for a
person who is environmentally disadvantaged.  The front desk's reservation
system, it seems, allows a flag for "special equipment" to be set, which
refers to a room with all furniture placed for easy wheel-chair access. 
Mirrors, bath gear, toilets, etc, are all placed and oriented for someone
with much different patterns of mobility than I exhibit.

I have not quite decided whether this is a software design flaw (desired state
information not expressible in the system), user interface error, or just my
usual luck.

(I am, obviously, overcoming my own handicap in this room, namely, that a phone
cord is permanently fixed to the wall without nice modular jack for nethacking.
Screwdrivers, 'gator clips, and an attitude ... don't leave home without them!)

Jim

</PRE>
<HR><H3><A NAME="subj7.2">
Re:  worse-is-better for the 1990s (Newcomer, <A HREF="/Risks/11.16.html">RISKS-11.16</A>)
</A>
</H3>
<address>
Tim Chambers 
&lt;<A HREF="mailto:tbc@hp-lsd.cos.hp.com">
tbc@hp-lsd.cos.hp.com
</A>&gt;
</address>
<i>
Tue, 26 Feb 91 16:03:20 mst
</i><PRE>

&gt;From: "Joseph M. Newcomer" &lt;jn11+@andrew.cmu.edu&gt;
&gt;          There is a risk of accepting the barely adequate; you may have to
&gt;live with it for a long time.

I think the author misses Dick Gabriel's point.  By the way he chooses his
words, he is lamenting the fact that the world suffers from living with
"barely adequate" implementations.  The issue seems is more one of standards
than of what is The Right Thing.

The company I work for has a long-standing tradition of trying to Do the Right
Thing with technologies in our products.  A funny thing happened when we
ventured into larger and larger markets -- the slogan "standard is better than
better" began to catch on with engineers battling with competitors for shares
of billion-dollar markets.  We began to seek out standards and promote them in
our products.

I'd like to know if examples exist of cases where Right Thing technology *has
been* compatible with mass markets.  I can think of plenty of counter-examples:
VHS versus Beta; multi-process, high-cost-of-entry computers (UNIX workstations)
 versus single-process, low-common-denominator computers (PC); and technologies
used in television and power transmission.  In all cases, the poorer candidate
for being the Right Thing has more economic clout (i.e. it thrives in a larger
market than Right Thing alternatives).  (Perhaps FM radio is closer to the Right
Thing than AM -- I welcome comments from an expert of what an ideal radio
broadcast system would be so AM and FM could be compared to it.)

I don't see this as much of a lesson at all.  It's the natural order of things
in a competitive world.

</PRE>
<HR><H3><A NAME="subj7.3">
Re: worse-is-better for the 1990s (Newcomer, <A HREF="/Risks/11.16.html">RISKS-11.16</A>)
</A>
</H3>
<address>
Mark McWiggins
&lt;<A HREF="mailto:mark@intek01.UUCP ">
mark@intek01.UUCP 
</A>&gt;
</address>
<i>
Wed, 27 Feb 91 18:34:43 GMT
</i><PRE>

"Joseph M. Newcomer" &lt;jn11+@andrew.cmu.edu&gt; writes:
&gt; ...  There is a risk of accepting the barely adequate; you may have to
&gt;live with it for a long time.

Hear, hear.  Admiral Grace Hopper was quoted as saying "Well, it's not
really what we want, but we'll fix it in the next release" on the
occasion of the release of the original COBOL.

Mark McWiggins,	Integration Technologies, Inc. (Intek), 1400 112th Ave SE #202,
Bellevue WA 98004           +1 206 455 9935		 mark@intek.com

</PRE>
<HR><H3><A NAME="subj7.4">
Re: worse-is-better for the 1990s  (Gitomer, <A HREF="/Risks/11.17.html">RISKS-11.17</A>)
</A>
</H3>
<address>
Flint Pellett
&lt;<A HREF="mailto:flint@gistdev.gist.com ">
flint@gistdev.gist.com 
</A>&gt;
</address>
<i>
27 Feb 91 21:48:09 GMT
</i><PRE>

&gt;Perhaps what we are seeing is Gresham's Law as applied to computers: [...]
&gt;Now if I could only figure out how to hoard an operating system or high-level
&gt;language :-)

That's easy: you overprice it.  When you can get BASIC for free but have to
pay $100 for a C compiler, you end up with things that should have been in
C written in BASIC.  When it costs $400 for a bare-bones UNIX vs. $100 for
DOS, the lesser system pushes out the greater one quite often.

Flint Pellett, Global Information Systems Technology, Inc., 1800 Woodfield Dr.,
Savoy, IL 61874 (217) 352-1165 uunet!gistdev!flint flint@gistdev.gist.com

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: worse-is-better for the 1990s (Gitomer, <A HREF="/Risks/11.17.html">RISKS-11.17</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:dan@BBN.COM">
dan@BBN.COM
</A>&gt;
</address>
<i>
Wed, 27 Feb 91 10:53:41 -0500
</i><PRE>

If you're a hardware manufacturer, you can hoard your software by just not
letting it run on anybody else's hardware!  This is one reason that UNIX drove
out better, or at least better-adapted, operating systems: they couldn't run on
anything except their own vendor's hardware, and the vendor wasn't interested in
changing that situation since the greater intrinsic value was a competitive
advantage in selling hardware.

If you're not a hardware manufacturer, you can still accidentally "hoard" an OS
or high-level language by specializing it to a particular architecture so that
you can't easily move it onto newer hardware.  Multics and ITS are examples.  In
this case the problem is that operating systems and languages of greater
intrinsic value usually end up requiring hardware of greater intrinsic value or
specialization in order to do their job.  Multics had protection rings and true
dynamic linking, with specialized hardware to make them fast; UNIX has neither,
so it can run on machines without the extra hardware.

Fortunately, Gresham's Law need not apply if the creator of the software isn't
interested in hoarding it.  GNU Emacs and gcc are good counterexamples.

	Dan Franklin

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B35-81</DOCNO>
<DOCOLDNO>IA013-000135-B036-63</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/11.20.html 128.240.150.127 19970217042221 text/html 30677
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 04:20:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 11: Issue 20</TITLE>
<LINK REL="Prev" HREF="/Risks/11.19.html">
<LINK REL="Up" HREF="/Risks/index.11.html">
<LINK REL="Next" HREF="/Risks/11.21.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/11.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 11: Issue 20</H1>
<H2> Saturday 2 March 1991 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Red clocks run faster than green ones! 
</A>
<DD>
<A HREF="#subj1.1">
Paul Leyland
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Re: Faxing a horse 
</A>
<DD>
<A HREF="#subj2.1">
Ed Wright
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
Call for papers -- ACM SIGSOFT '91, REMINDER 
</A>
<DD>
<A HREF="#subj3.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Risks of naming a node 
</A>
<DD>
<A HREF="#subj4.1">
Rao V. Akella
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Plugging in in Singapore 
</A>
<DD>
<A HREF="#subj5.1">
WWeaver
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Singacard anyone? 
</A>
<DD>
<A HREF="#subj6.1">
JueyChong Ong
</A><br>
<A HREF="#subj6.2">
 Bill J Biesty
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Deskilling/dumbing-down 
</A>
<DD>
<A HREF="#subj7.1">
Peter Brantley
</A><br>
<A HREF="#subj7.2">
 Phil Agre
</A><br>
<A HREF="#subj7.3">
 Bob Rahe
</A><br>
<A HREF="#subj7.4">
 Edward Kittlitz
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Red clocks run faster than green ones!
</A>
</H3>
<address>
Paul Leyland
&lt;<A HREF="mailto:pcl@robots.oxford.ac.uk ">
pcl@robots.oxford.ac.uk 
</A>&gt;
</address>
<i>
Fri, 1 Mar 91 13:53:46 GMT
</i><PRE>

Copied from _The Times_, London, March 1 1991.

		   Speeding clocks cause for alarm

New street lighting systems in an East Midlands village have been playing
curious games with alarm clocks, causing them to race up to four hours ahead
while their owners slept.

Residents of Castle Donnington, Leicestershire, who own clocks with the
familiar red display [presumably LEDs -- pcl] had to call on the detective
skills of East Midlands Electricity Board staff to solve the problem.  Owners
of more sophisticated clocks with a green display [plasma discharge? -- pcl]
found they were sticking to Greenwich rather than Omani time.

An inspection of the local airport and voltage checks in houses and at
substations failed to disclose the cause.  Interference from cellular telephones
was also ruled out.

The culprits were finally tracked to signals being transmitted by electric
timers controlling local street lights that had recently been fitted by
Leicestershire county council.  Julian Evans, an electricity board spokesman,
said the timers had been replaced and things appeared to be "ticking along
nicely".

[ Can anyone explain why "red" clocks should be more susceptible to this form
of interference than "green" clocks?  ]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Faxing a horse (<A HREF="/Risks/11.19.html">RISKS-11.19</A>)
</A>
</H3>
<address>
Ed Wright 
&lt;<A HREF="mailto:edw@sequent.com">
edw@sequent.com
</A>&gt;
</address>
<i>
Fri, 1 Mar 91 12:31:21 PDT
</i><PRE>

I keep waiting for the day when someone releases a (postscript) laser printer,
that incorporates a scanner so that I can use it as a printer, a scanner, a
copier. Add fax to that concept and I think we would have a winner.  Ed Wright

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
call for papers -- ACM SIGSOFT '91 [REMINDER. ORIGINAL IN <A HREF="/Risks/10.57.html">RISKS-10.57</A>]
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@murphy.ICS.UCI.EDU">
nancy@murphy.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Mon, 29 Oct 90 17:45:06 -0800
</i><PRE>

                            CALL FOR PAPERS
 
                            ACM SIGSOFT '91 
                     Software for Critical Systems

                        New Orleans, Louisiana
                         December 4-6, 1991

Computer systems are beginning to affect nearly every aspect of our lives.
Examples include programs that control aircraft, shut down nuclear power
reactors in emergencies, monitor hospital patients, and execute banking
transactions.  Although such programs offer considerable benefits, they also
pose serious risks in that we are increasingly vulnerable to errors and
deficiencies in the software.                     [NO NEWS TO RISKS READERS!]

The SIGSOFT '91 conference seeks papers on all aspects of quality in critical
systems.  A critical system is a system that must exhibit, with very high
assurance, some specific qualities such as safety, reliability,
confidentiality, integrity, availability, trustworthiness, and correctness.
The conference will focus on such topics as architectures, design
methodologies, languages, analysis techniques, and processes that can increase
the likelihood that a system exhibits its required qualities.

Papers will be judged on relevance, significance, originality, correctness, and
clarity.  Papers will be read and evaluated by the program committee and must
not be under consideration (or published) elsewhere in the same or similar
form.  Papers are limited to 6,000 words, with full-page figures counting as
300 words.  A paper that significantly exceeds this limit is likely to be
rejected.

Authors should submit 6 copies of the full paper to:

   Peter G. Neumann, Computer Science Laboratory, SRI International, 
   Room EL-243, 333 Ravenswood Ave., Menlo Park, CA 94025

Persons submitting papers from countries in which access to copying machines is
difficult or impossible may submit a single copy.  Submissions should be
received by May 3, 1991 and should include a return mailing address.  Authors
will be notified of acceptance or rejection by July 12, 1991.  Full versions of
accepted papers must be received in camera-ready form by August 30, 1991.
Authors of accepted papers will be expected to sign a copyright release form.
Proceedings will be distributed at the conference and will subsequently be
available from ACM.

CONFERENCE CHAIR          PROGRAM Co-CHAIRS            
  Mark Moriconi             Nancy Leveson                 Peter Neumann
  SRI International         Univ. of California, Irvine   SRI International
  moriconi@csl.sri.com      leveson@ics.uci.edu           neumann@csl.sri.com

PROGRAM COMMITTEE
    David Barstow          Schlumberger
    Dines Bjorner          Technical University of Denmark
    Marie-Claude Gaudel    Universite de Paris - Sud
    Jim Horning            DEC Systems Research Center
    Bill Howden            University of California, San Diego
    Hermann Kopetz         Technical University of Vienna
    Carl Landwehr          Naval Research Laboratory 
    Bev Littlewood         City University, London
    Leon Osterweil         University of California, Irvine
    David Parnas           Queen's University
    Fred Schneider         Cornell University 
    Vicky Stavridou        University of London 
    Martyn Thomas          Praxis, Inc.
    Walter Tichy           University of Karlsruhe
    Elaine Weyuker         NYU Courant Institute

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Risks of naming a node
</A>
</H3>
<address>
"Rao V. Akella" 
&lt;<A HREF="mailto:RAO@moose.cccs.umn.edu">
RAO@moose.cccs.umn.edu
</A>&gt;
</address>
<i>
Tue, 26 Feb 91 15:50 CST
</i><PRE>

In addition to all the other problems associated with computers, have you ever
wondered about the risks of _naming_ one?  The study I work for has a
workstation called SUCKER (ugh! my system manager -- who is a fishing maniac --
named it after a lake in the Boundary Waters Canoe Area in northern Minnesota). 

Ever since we brought this machine up on the net, we haven't had a moment's
peace.  All the teenage wanna-be freshmen hackers from all the neighbouring
state colleges who have just got their first computer account and have read
"The Cuckoo's Egg" are drawn to it like a magnet.  There's rarely a Monday when
I come in and don't find breakin attempts on all the usual accounts: SYSTEM,
FIELD, DECNET, INGRES, GUEST, ANONYMOUS...you name it.  Fortunately, DECnet
provides a pretty good traceback to the originating point of the attempt, and
most system managers take such reports very seriously, so we've had about
half-a-dozen amateurs kicked off their systems (I say amateurs, because nobody
has gone beyond trying to guess passwords).

But then, we probably only have audit and intrusion trails for the ones that
failed...

Rao Akella, Research Assistant, Colon Cancer Control Study
University of Minnesota, Minneapolis

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Plugging in, in Singapore
</A>
</H3>
<address>
&lt;<A HREF="mailto:WWEAVER@cmsa.Berkeley.EDU">
WWEAVER@cmsa.Berkeley.EDU
</A>&gt;
</address>
<i>
Sun, 24 Feb 91  20:23 PST
</i><PRE>

In light of RISKS recent series on the Americard, I found the following
interesting.  Reprinted from the 24 Feb 91 Chronicle (Punch Section, page 5).
All typographical errors mine.

THE PUSH-BUTTON SOCIETY
In Singapore, 2.6 million people are coming on-line.
By Reginal Chua (Reuters)

Singapore is striving to become a push-button city.  From cashless shopping to
electronic paperwork and even a computerized pig auction, Singapore is plugging
its 2.6 million people into electronic grids linking the entire island nation.
In less than a decade, it plans to build computerized electronic pathways to
enable people to shop, book theater tickets, check information, and to allow
companies to send documents.

Singapore's small size and highly centralized bureaucracy has made it
relatively simple to establish the groundwork for the electronic society.  All
citizens carry a numbered identification card, allowing information about them
to be cross-indexed between ministries and government bodies.  Not all
Singaporeans are thrilled ath the prospect of life in this version of a brave
new world with an electronic ``Big Brother'' keeping tabs on them.

Some were unhappy to find that census takers calling at their homes already had
detailed information about them printed on the census forms.  ``It seems like
they know more about me than I do,'' one housewife said.

The advantages of being plugged in, however, have become obvious to many.
``The purpose... is to turn Singapore into an intelligent island in which IT
(information technology) will be fully exploited to improve business
competitiveness and, more importantly, to enhance the quality of life,'' said
Tay Eng Soon, minister of state for education.  A new master plan, IT 2000,
will be unveiled at the end of the year, Tay said.  Parts are already in place.

TradeNet -- which allows companies to submit documents electronically to the
state Trade Development Board -- now accounts for 90 percent of all trade
documentation, a board official said.  ``We're going to phase out the remaining
10 percent by the end of the year,'' she said.  Some freight forwarders have
reported productivity gains of up to 30 percent with the new system, she added.

Introduced only two years ago, the system handles 10,000 forms a day.  Each
takes 15 minutes to process, compared with as long as two days by the old
method.  Even payment for the service is electronic.  Shippers used to have to
paste revenue stamps on each form.  Now the board deducts the fee
electronically from their bank accounts.  ``Up-to-date knowledge and
information become of utmost importance when a country or company seeks to be
competitive in the international arena,'' Minister of Communications Yeo Ning
Hong said at the launch of a teletext system, Teleview.

The Network for Electronic Transfers, a cashless shopping system, has been in
operation for five years and is now used by more than a third of the population
and 1,500 stores.  Consumers have the cost of their purchases automatically
deducted from their bank accounts.  ``Certainly there was resistance at first.
There was a lot of resistance, primarily from the retailers,'' said the
network's general manager, Patrick Yi.  ``We now have a critical mass of
consumers and retailers.''

In the next five years, the network plans to expand to 6,000 outlets and boost
transactions from about $300 million last year to $1 billion in 1995.  Plans
also include an ``electronic purse,'' which could replace several electronic
cards being used at the moment.  ``The concept is that from a national
perspective, wouldn't it be nice if we could just have one card,'' Yi said.
[!! --ww]

There are also other electronic networks -- for air cargo (Star Net), medical
claims (MediNet) and company registry (LawNet).

The next futuristic concept is ``Smart Town,'' which envisions a national
electronic grid to which households would be linked.  ``The idea here is to
build into the town a whole range of IT services,'' Tay said.  ``People who
live and work in such a town will have maximum and convenient access to many
services.''

Even the local pig market has entered the microchip age.  Wholesalers at the
Hog Auction Market, or HAM, bid silently for swine on an electronic system
which deducts winning bids from traders' deposits.

Only the odor remains.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Singacard anyone?
</A>
</H3>
<address>
JueyChong Ong 
&lt;<A HREF="mailto:75216.726@compuserve.com">
75216.726@compuserve.com
</A>&gt;
</address>
<i>
25 Feb 91 00:09:00 EST
</i><PRE>

Having lived in Singapore for most of my life, I think I can comment on parts
of Bill J Biesty's article in RISKS 11.09.

NETS was set up by a number of banks in Singapore primarily as an ATM network
much like Cirrus or Plus System in the US. With one notable exception, if you
bank with a NETS member, you can use any ATM machine belonging to a bank that
is a NETS member (the notable exception being the Post Office Savings Bank,
which claims to have the most ATMs nationwide, and therefore does not need to
participate in the ATM network; but they do participate in the cashless
shopping service mentioned next).

The other thing you can do with NETS is that merchants can subscribe to the
service, and that allows NETS ATM card holders to use their ATM card as a debit
card at stores. Shoppers use the same PIN they use at the ATM, and they can
choose to have the purchase amount deducted from their checking or savings
account.

On a recent visit to Washington, DC, I noticed a similar service being
provided at a Safeway supermarket.

&gt;I think it was mentioned in Risks, but was mentioned in WSJ that Singapore
&gt;plans to install sensors in cars and roads and start taxing vehicle owners
&gt;based on usage rather than an average fee to cover maintenance costs of roads.

Depending on how much the government decides to charge for road usage after
implementing the sensors, it may turn out to be a welcome measure. Currently,
cars prices in Singapore are more than double the prices in the US because of
import taxes. Road taxes go for about US$600 a year now for a car with a
2-liter engine (more for bigger cars, less for smaller ones). The idea is to
prevent traffic congestion by making it difficult for people to afford even one
car. I don't think that's fair.

To reduce road usage during rush hours, there is a surcharge to enter the
downtown area/city center/business district.

Implementing Electronic Road Pricing (ERP) gives the government an alternative
to rapidly increasing vehicle import taxes, increasing rush-hour entry fees
and, recently, annual car sales quotas. The hope is that it will result in
fairer charging, and that they do not abuse the flexibility of ERP.

Incidentally, Singapore got interested in ERP because of its apparent success
in Hong Kong.

Also, you may also like to know that some people do not believe in being
charged "an average fee to cover maintenance costs of roads." The Feb. 1991
issue of New York Motorist (AAA Automobile Club of New York's newsletter) ran
two articles: one was about the Club urging lawmakers to reject legislation
that would put a flat-rate auto-use tax on vehicles in Westchester County.  The
Club vice-president said the tax was "regressive - levied on the owner of a
Rolls Royce at the same rate as on the owner of an old jalopy." While the main
reason for opposing the fee was that it was "essentially a second registration
fee" (and also a way for the county to raise more tax money in a bad year), I
also took it to mean that charging everyone an "average" fee isn't very popular
either.

The second articles was more interesting: the Port Authority of NY and the
Triborough Bridge and Tunnel Authority are trying out Automatic Vehicle
Identification (AVI) equipment to see if it could replace toll booths. A
transponder is mounted on the vehicle windshield. A transmitter at the toll
area generates a radio signal that is modified by the transponder when it is
within range, at speeds of up to 35mph, to "the tag's individual identification
code. The reflected signal with the new information is then transmitted to a
central computer" which would then deduct the proper amount of toll from the
vehicle owners account. I see a very blur distinction between this and
Singapore's ERP efforts. In fact, from the photograph accompanying the article
and the description, it seems uncannily similar to the system (or one of the
systems) that the Singapore government plans to try out. The article also
addresses several implications, among them: "A first step towards congestion
pricing (charging a higher rate for driving during peak periods and encouraging
off-peak use by lowering fees)", "Facilitating an expanded toll road system"
and a "Big Brother" potential for "governmental agencies to keep tabs on
citizens via their recorded passage through toll facilities". Sounds like
Singapore?
                                            --jc

</PRE>
<HR><H3><A NAME="subj6.2">
Re: Singacard anyone?
</A>
</H3>
<address>
Bill J Biesty
&lt;<A HREF="mailto:wjb@edsr.UUCP ">
wjb@edsr.UUCP 
</A>&gt;
</address>
<i>
Mon, 25 Feb 91 08:30:46 CST
</i><PRE>

[Pravin Kumar &lt;ppk@Sun.COM&gt; responds to my submission of a Wall Street Journal
article about the computerization of commerce in Singapore by pointing out that
the U.S. is close behind in implementing the same technologies.]

Dallas, Texas, USA has similar technologies in use.  The Dallas North Tollway, the
only toll road in Dallas, put the AVI system into effect last year.  I also have 
seen the use of ATM cards to pay for groceries and gasoline (whose risks were
discussed recently). 

One difference that does exist is that the Cirrus, Plus, and other ATM networks
are not run by the government but by independent businesses that manage the networks.

I submitted the article not only as a follow up to the Americard idea but also
the discussion of Margaret Atwood's "The Handmaid's Tale" where womens rights
were removed by removing their economic freedom.  This is risk that still exists
(but not just for women I'm sure) in Singapore.

Access fees for driving in certain areas can be handled by selling permits to
drive in congested areas.  Other drivers can take the risk of driving into the
area without the permit and getting a ticket.  This method avoids the loss of
freedom in letting some accounting system keep track of where you are.   

The Tollway incidentally provides a quicker access to downtown
as many drivers don't want to pay the tolls ($1.00 each way), in essence making
it an access fee or a service fee depending on how you want to look at it.

With a commercial network there's probably greater access to the information 
(similar to the dubious information security at credit reporting agencies) 
than there would be if it were under government control.  Or are they the same?
Is it better to have such "democratically" restricted access?  I think so.
It's pretty difficult to get the CIA to release uncensored information that
the (may) have collected about you.  With a commercial network you can (attempt
to) hire a cracker and at least be forewarned.

Bill Biesty, Electronic Data Systems Corp., Research and Advanced Development,
7223 Forest Lane, Dallas, TX 75230    (214) 661 - 6058    edsr.eds.com!wjb

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     Deskilling
</A>
</H3>
<address>
Peter Brantley 
&lt;<A HREF="mailto:BRANTLEP@ARIZVM1.BITNET">
BRANTLEP@ARIZVM1.BITNET
</A>&gt;
</address>
<i>
Fri, 01 Mar 91 09:13:16 MST
</i><PRE>

Alan Wexelblat notes that many instances of automation are involved in a
deskilling of the workforce.  There are many popular images of this effect, and
Alan notes a few.  The worry is that this process, extending through society,
will result in a "dumbing" of workers.

This thesis was most forcefully argued, not in Garson's _Electronic Sweatshop_,
which has more to do with surveillance, but in Harry Braverman's _Labor and
Monopoly Capital_.  Braverman advanced the deskilling hypothesis as an attempt
to understand what he perceived to be fundamental aspects of workplace
transformation in a particular stage of western capitalism.  The facts,
however, do not really support Alan or Braverman.

Braverman described deskilling as a historical process, particularly alive
today within the service sectors.  But it is questionable whether the service
sectors have been the targets of a "dumbing."  There have been many instances
where computerization has forced the lay off of newly redundant personnel, but
for those who receive or gain control of workplace automation, the story is
different.  They often experience a reskilling, or more explicitly, a
redefinition of their job tasks, with even greater required skills.  The
operation of machinery does not, and should not, require knowledge of
appropriate intervention, as Alan suggests.  Indeed, the very *point* of
automation is to remove these tasks from the province of the worker.  But this
is not necessarily a bad thing.  Automated workers may or may not be more
happy, but they are not likely to be more oppressed.  And as Braverman
accurately noted, the age of craft work -- where you could send Joe to "bang on
it a few times" to fix it are long gone.  Braverman did not note that the craft
work population of the U.S. was always *very* small.

Most any business publication discussing the future workplace broadcasts a note
of alarm about the lowering of available skills in the population as a whole.
The requisite skill level for many positions has risen to the point where many
large U.S. corporations are unable to find suitably educated workers in the
labor force.  Massive job training programs have been initiated to give workers
a minimum level of technological sophistication necessary to perform their
tasks.

The inclination of many writers, Braverman included, to posit a golden happy
age where workers knew their work and could fix/own their own machinery is a
dangerous misunderstanding of the nature of capitalism.  The economic system
has extensively organized work for centuries, and automation has only enlarged
to scope of this organization.  Workers were, are, and will be oppressed.

The danger is in failing to note the increasing skill stratification of the
workforce.  Those of us who understand technology are a very privileged lot.
The workplace demands more extensive skills with each passing year as more
information processing becomes required for culturally accepted business
practices.  If we fail to notice that the U.S. educational and social system
does not support the acquisition of these skills, then we have done a grave
disservice.  This is not something particular to automation, but to our social
system.  Automation is a neutral force.  Society is not.

Peter Brantley, Department of Sociology, University of Arizona, Tucson, 
AZ  85721  (602) 621-3804 Brantlep@Arizvm1.BITNET, Brantlep at Arizvm1.Ccit.Arizona.Edu

</PRE>
<HR><H3><A NAME="subj7.2">
Re: deskilling
</A>
</H3>
<address>
Phil Agre 
&lt;<A HREF="mailto:phila@cogs.sussex.ac.uk">
phila@cogs.sussex.ac.uk
</A>&gt;
</address>
<i>
Fri, 1 Mar 91 17:24:33 GMT
</i><PRE>

In an article in Risks 11.18, Alan Wexelblat (wex@pws.bull.com) mentions the
notion of deskilling in relation to computer-based automation.  He says:

    Where people have not been outright replaced by machines, they've been
    replaced by people with lower skill levels and often less experience and
    less education.

Though I am highly sympathetic to the idea that automation is not frequently
motivated by concern about the quality of workers' lives, the matter is fairly
complicated.  In particular, it would be a mistake to identify automation with
deskilling in terms of its effects on the total workforce.  (This may simply
be a clarification of AW's note.)  Rather than go on about it, here are some
references which lay out the issues in detail:

William O.~Lichtner, {\em Planned Control in Manufacturing}, New York: Ronald
Press, 1924.  A fascinating early manual of management rationalization.

Harry Braverman, {\em Labor and Monopoly Capital: The Degradation of Work in
the Twentieth Century}, New York: Monthly Review Press, 1974.  Origin of the
thesis of "deskilling".

Richard Edwards, {\em Contested Terrain: The Transformation of the Workplace
in the Twentieth Century}, New York: Basic Books, 1979.  A more complex view,
based on the evolving relationship between issues of efficiency and control
over the work process.

Barry Wilkinson, {\em The Shopfloor Politics of New Technology}, London:
Heinemann, 1983.  An ethnographic account of the organizational dynamics of
factory automation.

Ann Majchrzak, {\em The Human Side of Factory Automation: Managerial and
Human Resource Strategies for Making Automation Succeed}, San Francisco:
Jossey-Bass, 1988.  A practical guide for managers planning to automate.

Paul Thompson, {\em The Nature of Work: An Introduction to Debates on the
Labour Process}, second edition, London: Macmillan, 1989.  Good survey of
the development of sociological theories of automation since Braverman.

Phil Agre, University of Sussex

</PRE>
<HR><H3><A NAME="subj7.3">
     Re: Dumbing-down?
</A>
</H3>
<address>
Bob Rahe 
&lt;<A HREF="mailto:CES00661@UDELVM.bitnet">
CES00661@UDELVM.bitnet
</A>&gt;
</address>
<i>
Thu, 28 Feb 91 22:10:00 EST
</i><PRE>

  Alan Wexelbat in Risks 11.18 makes the point of automation of some jobs
causing the level of intelligence of the operators hired to do them to be
lowered.  How can this be ascertained as opposed to the scenario where the
quality of the applicants for the job has required a high-tech solution in
order to get it done.  Have you talked (English!) to a high school student
lately?  Tried to get into a discussion with one?  Definitely on a downward
spiral.
                                    Bob

</PRE>
<HR><H3><A NAME="subj7.4">
dumbing-down and dumbing-up
</A>
</H3>
<address>
Edward N Kittlitz
&lt;<A HREF="mailto:kittlitz@world.std.com ">
kittlitz@world.std.com 
</A>&gt;
</address>
<i>
Sat, 2 Mar 91 07:22:13 -0500
</i><PRE>

Alan Wexelblat discussed "dumbing down", whereby technology allow less trained
people to perform tasks which previously required skilled practitioners. We
must also remember that computer-aided processes can inspire contempt in those
who are familiar. An example is the oft-discussed failure of skilled persons to
follow automated checklist procedures because they know the system "well
enough".  The best (apocryphal?) example is the Soviet fighter pilot yelling
"don't tell me how to fly this plane" to a recorded voice intoning "pull up...
pull up". This must be "dumbing up".

PS to Steve Bellovin's note about 25 and 50 feet of wire going for the same
price: an inspired bargainer would purchase the 50-foot length, Solomon-style
cleave it in twain, and return one piece at the 25-foot price.
                                                                 E. N. Kittlitz

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/11.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.11.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/11.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
