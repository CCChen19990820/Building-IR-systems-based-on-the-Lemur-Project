<DOC>
<DOCNO>WT11-B27-1</DOCNO>
<DOCOLDNO>IA043-000785-B010-562</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/phttpd/ 128.240.150.127 19970305074031 text/html 3207
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Wed, 05 Mar 1997 07:36:17 GMT
Server: phttpd/0.99.73
Last-Modified: Mon, 24 Feb 1997 10:26:37 GMT
Content-Type: text/html
Content-Length: 3015
</DOCHDR>
<HTML>
<HEAD>
<LINK rel=made href="mailto:pen@signum.se">
<LINK rel=owns href="mailto:pen@signum.se">
<TITLE>The PHTTPD World Wide Web Server</TITLE>
</HEAD>
<BODY>

<H1 ALIGN=CENTER>
<IMG SRC="signum-logo.gif" ALT="">
<P>
The PHTTPD World Wide Web Server
</H1>

<H4 ALIGN=CENTER>
<A HREF="COPYING.html">Copyright</A> © 1994-1995
<A HREF="http://www.signum.se/~pen/">Peter Eriksson</A>
<A HREF="mailto:pen@signum.se">&lt;pen@signum.se&gt;</A>
</H4>

<BR>

Phttpd is a free multithreaded, lightweight & fast
<A HREF="http://www.w3.org/">World Wide Web</A>
server written by
<A HREF="http://www.signum.se/~pen/">Peter Eriksson</A>
of the free software company
<A HREF="http://www.signum.se/">Signum Support AB</A>
in
<A HREF="http://www.sunet.se/">Sweden</A>.
<P>
<I>
It is currently only available for computers running the SunOS 5.4
(Solaris 2.4) operating system (or later versions) from 
<A HREF="http://www.sun.com/">Sun</A>.
</I>


<H3>Features:</H3>
Phttpd uses features like multithreading, dynamic linking and
memory mapping to achieve quick response time, extensibility
and high transfer rates, without consuming huge system resources.


<H3>Conditions:</H3>
It is NOT public domain software, but is available under the
<A HREF="COPYING.html">GNU GPL v2</A> 
(GNU General Public License, version 2) license. Ie: you may
not sell binary copies of the software without also distributing
the source code to it. See the license for more information.


<H3>Availability:</H3>
You can always get a copy of the source code by anonymous FTP from:
<BLOCKQUOTE>
<A HREF="ftp://ftp.signum.se/pub/phttpd/">
ftp.signum.se:/pub/phttpd/
</A>
</BLOCKQUOTE>
or from:
<BLOCKQUOTE>
<A HREF="ftp://ftp.lysator.liu.se/pub/phttpd/">
ftp.lysator.liu.se:/pub/phttpd/
</A>
</BLOCKQUOTE>

or you can buy a precompiled and supported version from
<A HREF="http://www.signum.se/">Signum Support AB</A>.


<H3>Support:</H3>
As Phttpd is free software it is made available without any warranty
or support. However, if you need professional, commercial support (and
are willing to pay for it), don't hesitate to contact
<A HREF="http://www.signum.se/">Signum Support AB</A>.

<H3>Documentation:</H3>
The documentation is currently being written, and no <EM>final</EM>
version has yet been released. The work-in-progress can be read at:
<BLOCKQUOTE>
<A HREF="http://www.signum.se/phttpd/doc/">
http://www.signum.se/phttpd/doc/
</A>
</BLOCKQUOTE>

<H3>More information:</H3>
There is a mailing list for Phttpd-related information and announcements
which you can reach at:
<BLOCKQUOTE>
<A HREF="mailto:info-phttpd@signum.se">info-phttpd@signum.se</A>
</BLOCKQUOTE>
To be added to the list, send an email to:
<BLOCKQUOTE>
<A HREF="mailto:info-phttpd-request@signum.se">info-phttpd-request@signum.se</A>
</BLOCKQUOTE>
and state that you wish to be added.
<P>
All messages sent to the list are archived at:
 <BLOCKQUOTE>
<A HREF="http://www.signum.se/~pen/phttpd-archive.mbox">http://www.signum.se/~pen/phttpd-archive.mbox</A>

</BODY>
</HTML>

</DOC>
<DOC>
<DOCNO>WT11-B27-2</DOCNO>
<DOCOLDNO>IA012-000128-B041-31</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/phttpd/COPYING.html 128.240.150.127 19970216235426 text/html 19925
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Sun, 16 Feb 1997 23:52:53 GMT
Server: phttpd/0.99.72
Last-Modified: Tue, 26 Mar 1996 11:34:34 GMT
Content-Type: text/html
Content-Length: 19732
</DOCHDR>
<HTML>
<HEAD>
<LINK rel=made href="mailto:pen@signum.se">
<LINK rel=owns href="mailto:pen@signum.se">
<TITLE>GNU GENERAL PUBLIC LICENSE, v2</TITLE>
</HEAD>
<BODY>

<CENTER>
<H1>GNU GENERAL PUBLIC LICENSE</H1>
<H1>Version 2, June 1991</H1>
</CENTER>

<BLOCKQUOTE>
 Copyright (C) 1989, 1991 Free Software Foundation, Inc.
                          675 Mass Ave, Cambridge, MA 02139, USA<P>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.
</BLOCKQUOTE>

<A NAME="PREAMBLE">
<CENTER><H2>Preamble</H2></CENTER>
</A>

  The licenses for most software are designed to take away your
freedom to share and change it.  By contrast, the GNU General Public
License is intended to guarantee your freedom to share and change free
software--to make sure the software is free for all its users.  This
General Public License applies to most of the Free Software
Foundation's software and to any other program whose authors commit to
using it.  (Some other Free Software Foundation software is covered by
the GNU Library General Public License instead.)  You can apply it to
your programs, too.

<P>

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
this service if you wish), that you receive source code or can get it
if you want it, that you can change the software or use pieces of it
in new free programs; and that you know you can do these things.

<P>

  To protect your rights, we need to make restrictions that forbid
anyone to deny you these rights or to ask you to surrender the rights.
These restrictions translate to certain responsibilities for you if you
distribute copies of the software, or if you modify it.

<P>

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must give the recipients all the rights that
you have.  You must make sure that they, too, receive or can get the
source code.  And you must show them these terms so they know their
rights.

<P>

  We protect your rights with two steps: (1) copyright the software, and
(2) offer you this license which gives you legal permission to copy,
distribute and/or modify the software.

<P>

  Also, for each author's protection and ours, we want to make certain
that everyone understands that there is no warranty for this free
software.  If the software is modified by someone else and passed on, we
want its recipients to know that what they have is not the original, so
that any problems introduced by others will not reflect on the original
authors' reputations.

<P>

  Finally, any free program is threatened constantly by software
patents.  We wish to avoid the danger that redistributors of a free
program will individually obtain patent licenses, in effect making the
program proprietary.  To prevent this, we have made it clear that any
patent must be licensed for everyone's free use or not licensed at all.

<P>

<I>The precise terms and conditions for copying, distribution and
modification follow.</I>

<A NAME="CONDITIONS">
<CENTER>
<H2>GNU GENERAL PUBLIC LICENSE</H2>
<H2>TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION</H2>
</CENTER>
</A>

<DL COMPACT>
<DT><B>0.</B><DD>
This License applies to any program or other work which contains
a notice placed by the copyright holder saying it may be distributed
under the terms of this General Public License.  The "Program", below,
refers to any such program or work, and a "work based on the Program"
means either the Program or any derivative work under copyright law:
that is to say, a work containing the Program or a portion of it,
either verbatim or with modifications and/or translated into another
language.  (Hereinafter, translation is included without limitation in
the term "modification".)  Each licensee is addressed as "you".

<P>

Activities other than copying, distribution and modification are not
covered by this License; they are outside its scope.  The act of
running the Program is not restricted, and the output from the Program
is covered only if its contents constitute a work based on the
Program (independent of having been made by running the Program).
Whether that is true depends on what the Program does.

<A NAME="SECTION_1"> <P><DT><B>1.</B><DD> </A>
You may copy and distribute verbatim copies of the Program's
source code as you receive it, in any medium, provided that you
conspicuously and appropriately publish on each copy an appropriate
copyright notice and disclaimer of warranty; keep intact all the
notices that refer to this License and to the absence of any warranty;
and give any other recipients of the Program a copy of this License
along with the Program.

<P>

You may charge a fee for the physical act of transferring a copy, and
you may at your option offer warranty protection in exchange for a fee.

<A NAME="SECTION_2"> <P><DT><B>2.</B><DD> </A>
You may modify your copy or copies of the Program or any portion
of it, thus forming a work based on the Program, and copy and
distribute such modifications or work under the terms of
<A HREF="#SECTION_1">Section 1</A>
above, provided that you also meet all of these conditions:

<DL COMPACT>

<A NAME="SECTION_2_A"> <P><DT><B>a)</B><DD> </A>
    You must cause the modified files to carry prominent notices
    stating that you changed the files and the date of any change.

<A NAME="SECTION_2_B"> <P><DT><B>b)</B><DD> </A>
    You must cause any work that you distribute or publish, that in
    whole or in part contains or is derived from the Program or any
    part thereof, to be licensed as a whole at no charge to all third
    parties under the terms of this License.

<A NAME="SECTION_2_C"> <P><DT><B>c)</B><DD> </A>
    If the modified program normally reads commands interactively
    when run, you must cause it, when started running for such
    interactive use in the most ordinary way, to print or display an
    announcement including an appropriate copyright notice and a
    notice that there is no warranty (or else, saying that you provide
    a warranty) and that users may redistribute the program under
    these conditions, and telling the user how to view a copy of this
    License.  (Exception: if the Program itself is interactive but
    does not normally print such an announcement, your work based on
    the Program is not required to print an announcement.)
</DL>
<P>

These requirements apply to the modified work as a whole.  If
identifiable sections of that work are not derived from the Program,
and can be reasonably considered independent and separate works in
themselves, then this License, and its terms, do not apply to those
sections when you distribute them as separate works.  But when you
distribute the same sections as part of a whole which is a work based
on the Program, the distribution of the whole must be on the terms of
this License, whose permissions for other licensees extend to the
entire whole, and thus to each and every part regardless of who wrote it.

<P>

Thus, it is not the intent of this section to claim rights or contest
your rights to work written entirely by you; rather, the intent is to
exercise the right to control the distribution of derivative or
collective works based on the Program.

<P>

In addition, mere aggregation of another work not based on the Program
with the Program (or with a work based on the Program) on a volume of
a storage or distribution medium does not bring the other work under
the scope of this License.

<A NAME="SECTION_3"> <P><DT><B>3.</B><DD> </A>
You may copy and distribute the Program (or a work based on it,
under <A HREF="#SECTION_2">Section 2</A>) in object code or executable
form under the terms of Sections <A HREF="#SECTION_1">1</A> and
<A HREF="#SECTION_2">2</A> above provided that you also do one of
the following:

<DL COMPACT>
<A NAME="SECTION_3_A"> <P><DT><B>a)</B><DD> </A>
    Accompany it with the complete corresponding machine-readable
    source code, which must be distributed under the terms of Sections
    <A HREF="#SECTION_1">1</A> and <A HREF="#SECTION_2">2</A> above on
    a medium customarily used for software interchange; or,

<A NAME="SECTION_3_B"> <P><DT><B>b)</B><DD> </A>
    Accompany it with a written offer, valid for at least three
    years, to give any third party, for a charge no more than your
    cost of physically performing source distribution, a complete
    machine-readable copy of the corresponding source code, to be
    distributed under the terms of Sections <A HREF="#SECTION_1">1</A>
    and <A HREF="#SECTION_2">2</A> above on a medium
    customarily used for software interchange; or,

<A NAME="SECTION_3_C"> <P><DT><B>c)</B><DD> </A>
    Accompany it with the information you received as to the offer
    to distribute corresponding source code.  (This alternative is
    allowed only for noncommercial distribution and only if you
    received the program in object code or executable form with such
    an offer, in accord with <A HREF="#SECTION_3_B">Subsection b</A> above.)
</DL>
<P>

The source code for a work means the preferred form of the work for
making modifications to it.  For an executable work, complete source
code means all the source code for all modules it contains, plus any
associated interface definition files, plus the scripts used to
control compilation and installation of the executable.  However, as a
special exception, the source code distributed need not include
anything that is normally distributed (in either source or binary
form) with the major components (compiler, kernel, and so on) of the
operating system on which the executable runs, unless that component
itself accompanies the executable.

<P>

If distribution of executable or object code is made by offering
access to copy from a designated place, then offering equivalent
access to copy the source code from the same place counts as
distribution of the source code, even though third parties are not
compelled to copy the source along with the object code.

<A NAME="SECTION_4"> <P><DT><B>4.</B><DD> </A>
You may not copy, modify, sublicense, or distribute the Program
except as expressly provided under this License.  Any attempt
otherwise to copy, modify, sublicense or distribute the Program is
void, and will automatically terminate your rights under this License.
However, parties who have received copies, or rights, from you under
this License will not have their licenses terminated so long as such
parties remain in full compliance.

<A NAME="SECTION_5"> <P><DT><B>5.</B><DD> </A>
You are not required to accept this License, since you have not
signed it.  However, nothing else grants you permission to modify or
distribute the Program or its derivative works.  These actions are
prohibited by law if you do not accept this License.  Therefore, by
modifying or distributing the Program (or any work based on the
Program), you indicate your acceptance of this License to do so, and
all its terms and conditions for copying, distributing or modifying
the Program or works based on it.

<A NAME="SECTION_6"> <P><DT><B>6.</B><DD> </A>
Each time you redistribute the Program (or any work based on the
Program), the recipient automatically receives a license from the
original licensor to copy, distribute or modify the Program subject to
these terms and conditions.  You may not impose any further
restrictions on the recipients' exercise of the rights granted herein.
You are not responsible for enforcing compliance by third parties to
this License.

<A NAME="SECTION_7"> <P><DT><B>7.</B><DD> </A>
If, as a consequence of a court judgment or allegation of patent
infringement or for any other reason (not limited to patent issues),
conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot
distribute so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you
may not distribute the Program at all.  For example, if a patent
license would not permit royalty-free redistribution of the Program by
all those who receive copies directly or indirectly through you, then
the only way you could satisfy both it and this License would be to
refrain entirely from distribution of the Program.

<P>

If any portion of this section is held invalid or unenforceable under
any particular circumstance, the balance of the section is intended to
apply and the section as a whole is intended to apply in other
circumstances.

<P>

It is not the purpose of this section to induce you to infringe any
patents or other property right claims or to contest validity of any
such claims; this section has the sole purpose of protecting the
integrity of the free software distribution system, which is
implemented by public license practices.  Many people have made
generous contributions to the wide range of software distributed
through that system in reliance on consistent application of that
system; it is up to the author/donor to decide if he or she is willing
to distribute software through any other system and a licensee cannot
impose that choice.

<P>

<I>This section is intended to make thoroughly clear what is believed to
be a consequence of the rest of this License.</I>

<A NAME="SECTION_8"> <P><DT><B>8.</B><DD> </A>
If the distribution and/or use of the Program is restricted in
certain countries either by patents or by copyrighted interfaces, the
original copyright holder who places the Program under this License
may add an explicit geographical distribution limitation excluding
those countries, so that distribution is permitted only in or among
countries not thus excluded.  In such case, this License incorporates
the limitation as if written in the body of this License.

<A NAME="SECTION_9"> <P><DT><B>9.</B><DD> </A>
The Free Software Foundation may publish revised and/or new versions
of the General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

<P>

Each version is given a distinguishing version number.  If the Program
specifies a version number of this License which applies to it and "any
later version", you have the option of following the terms and conditions
either of that version or of any later version published by the Free
Software Foundation.  If the Program does not specify a version number of
this License, you may choose any version ever published by the Free Software
Foundation.

<A NAME="SECTION_10"> <P><DT><B>10.</B><DD> </A>
If you wish to incorporate parts of the Program into other free
programs whose distribution conditions are different, write to the author
to ask for permission.  For software which is copyrighted by the Free
Software Foundation, write to the Free Software Foundation; we sometimes
make exceptions for this.  Our decision will be guided by the two goals
of preserving the free status of all derivatives of our free software and
of promoting the sharing and reuse of software generally.

<P>

<A NAME="WARRANTY">
<CENTER><H3>NO WARRANTY</H3></CENTER>
</A>

<A NAME="SECTION_11"> <DT><B>11.</B><DD> </A>
BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
REPAIR OR CORRECTION.

<A NAME="SECTION_12"> <P><DT><B>12.</B><DD> </A>
IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
POSSIBILITY OF SUCH DAMAGES.

</DL>
<P>

<CENTER>
<H3>END OF TERMS AND CONDITIONS</H3>
</CENTER>

<HR>


<A NAME="APPENDIX">
<CENTER>
<H2>Appendix: How to Apply These Terms to Your New Programs</H2>
</CENTER>
</A>

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

<P>

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
convey the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

<P><PRE>
    <I>&lt;one line to give the program's name and a brief idea of what it does.&gt;</I>
    Copyright (C) 19yy  <I>&lt;name of author&gt;</I>

    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program; if not, write to the Free Software
    Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
</PRE>

Also add information on how to contact you by electronic and paper mail.

<P>

If the program is interactive, make it output a short notice like this
when it starts in an interactive mode:

<P><PRE>
    Gnomovision version 69, Copyright (C) 19yy name of author
    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.
</PRE>

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, the commands you use may
be called something other than `show w' and `show c'; they could even be
mouse-clicks or menu items--whatever suits your program.

<P>

You should also get your employer (if you work as a programmer) or your
school, if any, to sign a "copyright disclaimer" for the program, if
necessary.  Here is a sample; alter the names:

<BLOCKQUOTE>
  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
  `Gnomovision' (which makes passes at compilers) written by James Hacker.
<P>
  <I>&lt;signature of Ty Coon&gt;</I>, 1 April 1989<BR>
  Ty Coon, President of Vice
</BLOCKQUOTE>

This General Public License does not permit incorporating your program into
proprietary programs.  If your program is a subroutine library, you may
consider it more useful to permit linking proprietary applications with the
library.  If this is what you want to do, use the GNU Library General
Public License instead of this License.
</DOC>
<DOC>
<DOCNO>WT11-B27-3</DOCNO>
<DOCOLDNO>IA012-000128-B041-46</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Lindsay/pgp.html 128.240.150.127 19970216235437 text/html 1109
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Sun, 16 Feb 1997 23:53:10 GMT
Server: phttpd/0.99.72
Last-Modified: Mon, 08 Jan 1996 13:50:04 GMT
Content-Type: text/html
Content-Length: 918
</DOCHDR>
<HTML>
<HEAD>
<TITLE>Lindsay Marshall's PGP Key</TITLE>
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY BACKGROUND="/Images/Bg/whitgran.gif">
<H1>My <A HREF="http://www.mantis.co.uk/pgp/pgp.html">PGP</A> Public Key</H1>
<P>
-----BEGIN <A HREF="http://www.mantis.co.uk/pgp/pgp.html">PGP</A> PUBLIC KEY BLOCK-----<BR>
Version: 2.6<BR>
<P>
mQBNAi71nZsAAAECALKvowuygSt4imCkrmjCB+VikWnG7TB8wFQYTZAH8/+q9Fx2<BR>
7PxlmuHWh+1ojsuG5EfUORSLmbTyh7VmaL9ESPEABRG0NkxpbmRzYXkgRi4gTWFy<BR>
c2hhbGwgPExpbmRzYXkuTWFyc2hhbGxAbmV3Y2FzdGxlLmFjLnVrPg==<BR>
=rwCL<BR>
-----END <A HREF="http://www.mantis.co.uk/pgp/pgp.html">PGP</A> PUBLIC KEY BLOCK-----
<P>
<IMG SRC="/Images/Lines/colorline.gif" WIDTH="585" HEIGTH="1"
ALT="----------------------------------------------------">
<P>
<A HREF="/Lindsay.html"><IMG SRC="/Lindsay25.gif" ALT="Lindsay Marshall"
WIDTH="37" HEIGHT="39" BORDER="0"></A></BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-4</DOCNO>
<DOCOLDNO>IA012-000128-B041-91</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Admissions/profiles.html 128.240.150.127 19970216235519 text/html 4976
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Sun, 16 Feb 1997 23:53:51 GMT
Server: phttpd/0.99.72
Last-Modified: Thu, 23 Feb 1995 13:22:30 GMT
Content-Type: text/html
Content-Length: 4784
</DOCHDR>
<HTML><HEAD>
<TITLE> Student Profiles</TITLE>
</HEAD>
<BODY>

<H1>Student Profiles</H1>

<H2>Farah Qureshi</H2>
<IMG SRC="farrah.gif" ALT="" WIDTH="360" HEIGHT="232">
<P>
At present, I have completed my second year on the BSc Computing Science
degree, and am working for British Airways for a year on a student placement.
A year out in industry is not a pre-requisite of the course, but it has given
me an opportunity to gain valuable experience and to think about a career after
leaving university.
<p>
The first year was fairly flexible.  Lecture courses catered for varying
degrees of ability, while practical work began with simple projects and
developed to turn us into confident programmers.
<p>
My second year involved lectures in distinct areas of computing which, with
their associated project work, have proved very rewarding .  It is tempting to
dismiss a lot of the written theory of computing as a waste of time, but my
time with British Airways has shown the benefits of learning from more
experienced programmers, especially in software engineering.
<p>
For me, there were two main features of the second year.  The first was the
necessity to program in different languages.  At first this seemed rather
daunting, especially in parallel programming, but the satisfaction gained from
knowing that you can be flexible according to the task in hand, or at least
that you can recognise features of previously unfamiliar languages, is
priceless.  The second feature was the group project.  This put together people
of differing programming abilities and gave them a clearly defined programming
(and organizational) task.  We had the freedom to choose our own methods, but
the time constraints were those which would be imposed by a 'real life' client.
By the end of the project most of us knew a great deal more about software than
we had before.
<p>
Newcastle is my home town, but being a student here opened up a whole new world
of experiences.  The social structure of the university is well established
with societies for almost every interest, and a booming night life.  The city
is jam packed with opportunity if you get out there and look for it.


<h2>Phil Lisle : Second-Year Computing Science Student</h2>

After taking A levels, I couldn't decide upon a degree course and drifted into
a career in banking to give it further thought.  Seven years on I decided on
Computing Science.  I was very apprehensive at first, doubting my ability, and
fearing that seven years was too large a gap.  This was compounded when, in the
first maths lecture, I came last out of more than 200 students in a revision
quiz!!  Through hard work and determination I turned this around, and found
myself within the top 10 by the end of the year.  Concise lecturing and
excellent tutorials dispelled any early apprehension and self-doubt.
<p>
As far as programming was concerned it was all new - perhaps this was an
advantage: ie there were no bad habits to be lost.  Again I felt unsure, but
the lectures were very clear, accommodating both advanced and novice
programmers alike; extra help was always available.  Having worked for seven
years I feel I have an added determination and would certainly not discourage
anyone from working before taking a degree course.  I chose Newcastle because
of its reputation, not only in academic terms, but also because nowhere could
match it for social life.

<h2>Andrew Ferguson : BSc Hons Computer Science graduate, 1993</h2>

After working in the NHS as a technician for five years it was a major change
to become a student and go to University.  In the end I chose Newcastle
University for two reasons: the city and the course offered.
<p>
Newcastle offers a city where you can guarantee that a number of things are
always happening, and by Metro getting about is very easy and cheap.  Its other
advantages are the excellent night life and relatively cheap accommodation.  My
main reason for choosing this degree course was the emphasis placed on the
practical use of what is covered in lectures and the wide range of options
available in the third year.
<p>
The most interesting part of the course for me turned out to be the thesis in
the third year, which accounts for 20% of the degree mark.  The Department
provided a wide range of topics but I opted  to do a thesis based on my summer
job of 1992.  The subject was an appointment system for a hospital department
that was implemented using C++ and an object-oriented database under
MS-Windows.  For this work I won the Kotecha Prize for the best thesis of
1993.
<p>
Now I have graduated; I am working once more in the NHS but as a clinical
scientist where I am providing scientific and technical support for a team
researching blood flow in the brain of new-born babies.
</body>
</html>
</DOC>
<DOC>
<DOCNO>WT11-B27-5</DOCNO>
<DOCOLDNO>IA012-000128-B041-109</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Lindsay/reading.html 128.240.150.127 19970216235547 text/html 2181
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Sun, 16 Feb 1997 23:54:09 GMT
Server: phttpd/0.99.72
Last-Modified: Fri, 31 May 1996 12:30:40 GMT
Content-Type: text/html
Content-Length: 1989
</DOCHDR>
<HTML>
<HEAD>
<TITLE>Good Things to Read</TITLE>
</HEAD>
<BODY BACKGROUND="/Images/Bg/whitgran.gif">
<H1>Good Things to Read</H1>

<H2>Magazines</H2>
<DL>
<DT> <A HREF="mailto:idler@idler.demon.co.uk">The Idler</A>
<DD>essential reading for the very laid back.
<DT> <A HREF="http://www.wired.com"><I>WIRED</I></A>
<DD>essential reading for the un-laidback.
<DT> Mondo 2000
<DD> the future here today. Well, maybe.
<DT> <A HREF="http://www.zeitgeist.net/public/Boing-boing/bbw3/boing.boing.html">bOING bOING</A>
<DD>more cyber-jockey stuff. Good fun though.
<DT> <A HREF="http://forteana.mic.dundee.ac.uk/ft">Fortean Times</A>
<DD>news of the weird.
<DT> Mojo
<DD>well, I am enough of an old hippy to like this kind of stuff.
<DT> <A HREF="http://www.futurenet.co.uk/outdoors/mtbpro.html">MTB Pro</A>
<DD> The best <A HREF="/mtb/">MTB</A> magazine around (IMHO)
<DT> <A HREF="http://www.futurenet.co.uk/mbuk.html">MBUK</A>
<DD> The second best <A HREF="/mtb/">MTB</A> magazine around (IMHO)
<DT> The Vegetarian
<DD> The magazine of the <A NAME=9 HREF="http://www.veg.org/veg/org/VegSocUK/info.html">Vegetarian Society of the UK</A>
</DL>
<H2>Books</H2>
Some things I have read recently (This is never up to date as I read a lot...)
<UL>
<LI> <I>The Evolution of Everyday Things</I> by Henry Petrovski</LI>
<LI> <I>Speed Tribes</I> - a book about Japanese youth culture
<LI> <I>Virtual Communities</I> - by <A NAME=5 HREF="http://riceinfo.rice.edu/projects/RDA/VirtualCity/Rheingold/index.html">Howard Rheingold</A>
<LI> <I>Driving with Mohammed</I> - travel in the Yemen
<LI> <I>If on a Winter's Night a Stranger</I> by Italo Calvino
<LI> <I>When the Going Gets Weird</I> - a biogrpahy of HST.
<LI> and lots of other stuff as well
</UL>
<IMG SRC="/Images/Lines/colorline.gif" WIDTH="585" HEIGTH="1"
ALT="----------------------------------------------------">
<P>
<A HREF="/Lindsay.html"><IMG SRC="/Lindsay25.gif" ALT="Lindsay Marshall"
WIDTH="37" HEIGHT="39" BORDER="0"></A>
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-6</DOCNO>
<DOCOLDNO>IA012-000128-B041-122</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Lindsay/listening.html 128.240.150.127 19970216235556 text/html 1520
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Sun, 16 Feb 1997 23:54:29 GMT
Server: phttpd/0.99.72
Last-Modified: Mon, 08 Jan 1996 13:50:04 GMT
Content-Type: text/html
Content-Length: 1328
</DOCHDR>
<HTML><HEAD>
<TITLE>Good Things to Listen to</TITLE>
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD>
<BODY BACKGROUND="/Images/Bg/whitgran.gif">
<H1>Good Things to Listen to</H1>

(Ok, Good things to which to listen including whats playing in the
Marshall office/house/car at the moment.....)

<UL>
<LI> Sheryl Crow
<LI> Josuah Rifkin
<LI> Rodney Miller
<LI> Mallard
<LI> The Gin Blossoms
<LI> Counting Crows
<LI> The Cauld Blast Orchestra
<LI> Paco de Lucia
<LI> David Grisman
<LI> Bob Wills and his Texas Playboys
<LI> Blind Blake
<LI> Django Rheinhart
<LI> <A NAME=1 HREF="http://www.catalog.com/mrm/beefheart.html">Captain Beefheart and his Magic Band</A>
</UL>
<P>
I can play things with strings and frets - mainly mandolin/mandola - and
blues harmonica. Currently I am teaching myself the piano in a sort of
bluesy, jazzy, folky sort of style. I have dabbled with lots of things
including the Northumbrian Smallpipes. When I can find someone to
teach me, I will learn the Highland bagpipes so that I can finally get to
understand piobaireachd.
<IMG SRC="/Images/Lines/colorline.gif" WIDTH="585" HEIGTH="1"
ALT="----------------------------------------------------">
<P>
<A HREF="/Lindsay.html"><IMG SRC="/Lindsay25.gif" ALT="Lindsay Marshall"
WIDTH="37" HEIGHT="39" BORDER="0"></A>
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-7</DOCNO>
<DOCOLDNO>IA012-000128-B041-134</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Lindsay/watching.html 128.240.150.127 19970216235603 text/html 2361
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Sun, 16 Feb 1997 23:54:39 GMT
Server: phttpd/0.99.72
Last-Modified: Fri, 28 Apr 1995 11:28:17 GMT
Content-Type: text/html
Content-Length: 2169
</DOCHDR>
<HTML><HEAD>
<TITLE>Good Things to Watch</TITLE>
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY>
<H1>Good Things to Watch</H1>
<H2>Favourite Movies</H2>
Well, I like movies but dont like going to the cinema, so....
<UL>
<LI> <A NAME=3 HREF="http://www.cm.cf.ac.uk/cgi-bin/Movies/title-exact?+Tampopo">Tampopo</A>
<LI> <A NAME=3 HREF="http://www.cm.cf.ac.uk/cgi-bin/Movies/title-exact?+Diva">Diva</A>
<LI> <A NAME=3 HREF="http://www.cm.cf.ac.uk/cgi-bin/Movies/title-exact?+Discreet%20Charm%20of%20the%20Bourgeoisie,%20The">The Discrete Charms of the Bourgeoisie</A>
<LI> <A NAME=3 HREF="http://www.cm.cf.ac.uk/cgi-bin/Movies/title-exact?+Top%20Hat">Top Hat</A>
<LI> <A NAME=3 HREF="http://www.cm.cf.ac.uk/cgi-bin/Movies/title-exact?+Singin'%20in%20the%20Rain">Singin' in the Rain</A>
<LI> <A NAME=3 HREF="http://www.cm.cf.ac.uk/cgi-bin/Movies/title-exact?+Repo%20Man">Repo Man</A>
<LI> <A NAME=3 HREF="http://www.cm.cf.ac.uk/cgi-bin/Movies/title-exact?+Women%20on%20the%20Verge%20of%20a%20Nervous%20Breakdown">Women on the Verge of a Nervous Breakdown</A>
</UL>
<H2>Television</H2>
Well I loved Twin Peaks.  Frasier is good and so is Northen
Exposure. I always watch Have I Got News for You. That's about
it. Most TV is utter rubbish.
<P>
BTW, I hate Startrek in any shape, form or generation.
<H2>Painting, Photography etc.</H2>
<DL>
<DD><IMG SRC="/Images/palette4.gif" ALIGN=MIDDLE> Jackson Pollock
<DD><IMG SRC="/Images/palette4.gif" ALIGN=MIDDLE> Lawrence Alma-Tadema
<DD><IMG SRC="/Images/wave.gif" ALIGN=MIDDLE> Hiroshigi
<DD><IMG SRC="/Images/wave.gif" ALIGN=MIDDLE> Hokusai
<DD><IMG SRC="/Images/palette4.gif" ALIGN=MIDDLE> <A NAME=2 HREF="http://www.antaire.com/warhol/warhol.html">Andy Warhol</A>
<DD><IMG SRC="/Images/hammer.gif" ALIGN=MIDDLE> Henry Moore
<DD><IMG SRC="/Images/camera.gif" ALIGN=MIDDLE> <A NAME=1 HREF="http://bookweb.cwis.uci.edu:8042/AAA.html">Ansell Adams</A>
</DL>
<IMG SRC="/Images/Lines/colorline.gif" WIDTH="585" HEIGTH="1"
ALT="----------------------------------------------------">
<P>
<A HREF="/Lindsay.html"><IMG SRC="/Lindsay25.gif" ALT="Lindsay Marshall" WIDTH="37" HEIGHT="39"></A>
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-8</DOCNO>
<DOCOLDNO>IA012-000128-B041-146</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Lindsay/doing.html 128.240.150.127 19970216235613 text/html 907
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Sun, 16 Feb 1997 23:54:46 GMT
Server: phttpd/0.99.72
Last-Modified: Mon, 08 Jan 1996 13:50:03 GMT
Content-Type: text/html
Content-Length: 716
</DOCHDR>
<HTML>
<HEAD>
<TITLE>Lindsay Marshall's Things to do Page</TITLE>
</HEAD>
<BODY BACKGROUND="/Images/Bg/whitgran.gif">
<H1>I like to....</H1>
<BLOCKQUOTE>
<DL>
<DT>
<IMG ALT="o" SRC="/Images/juggler.gif" ALIGN="CENTER">
<A HREF="http://www.hal.com/services/juggle/">juggle</A>
<DT>
Practice <A HREF="http://zeta.cs.adfa.oz.au/Spirit/tai-chi.html">Tai Chi</A>
<P>
<DT>Ride my <A HREF="/mtb">mountain bike</A>
</DL>
And lots of other thigs as well....
</BLOCKQUOTE>
<IMG SRC="/Images/Lines/colorline.gif" WIDTH="585" HEIGTH="1"
ALT="----------------------------------------------------">
<P>
<A HREF="/Lindsay.html"><IMG SRC="/Lindsay25.gif" ALT="Lindsay Marshall"
WIDTH="37" HEIGHT="39" BORDER="0"></A>
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-9</DOCNO>
<DOCOLDNO>IA012-000128-B041-556</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/bin/risksindex 128.240.150.127 19970217000103 text/html 4405
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Sun, 16 Feb 1997 23:59:17 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML>
<HEAD>
<TITLE>RISKS-LIST: RISKS-FORUM Digest</TITLE>
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD>
<BODY>
<H2>Forum On Risks To The Public In Computers And Related Systems</H2>
<H3><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy,
<A HREF="http://www.csl.sri.com/neumann/neumann.html">Peter G. Neumann</A>,
moderator</H3>
The RISKS Forum is a moderated digest.  Its USENET equivalent is
<A href="news:comp.risks">comp.risks</A>.
<P>
This web version of Risks is maintained by
<A HREF="http://catless.ncl.ac.uk/Lindsay.html">Lindsay Marshall</A>. Please
<A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">report</A>
any problems you find to him.

<UL>
<LI><A HREF="http://catless.ncl.ac.uk/Risks/18.82.html">Latest Issue (Vol 18 Issue 82)</A> <I>Friday 14 February 1997</I>
<LI><A HREF="/Risks.data/search.html">Searching</A>
<LI><A HREF="/Risks.data/info.html#subs">Subscriptions</A>
<LI><A HREF="/Risks.data/info.html#contrib">Contributions</A>
<LI><A HREF="/Risks.data/info.html#archives">Archives</A>
</UL>
<HR>
<FORM METHOD="POST" ACTION="/bin/risksissue">
Volume number:
<INPUT TYPE="Integer" Name="VOLUME" SIZE="4">
Issue number:
<INPUT TYPE="Integer" Name="ISSUE" SIZE="4">
<INPUT TYPE="submit" VALUE="Get Specific Issue">
<INPUT TYPE="reset" VALUE="Reset">
</FORM>
<HR>
<H3>Indices</H3>
The dates and counts do not include the index issues for each volume.
<UL>
<LI><A HREF="/Risks/index.1.html">Volume 1</A>
( <I><A HREF="/Risks/1.1.html">1 Aug 1985</A> - <A HREF="/Risks/1.45.html">31 Jan 1986</A>, 45 issues </I>)
<LI><A HREF="/Risks/index.2.html">Volume 2</A>
( <I><A HREF="/Risks/2.1.html">1 Feb 1986</A> - <A HREF="/Risks/2.56.html">30 May 1986</A>, 56 issues </I>)
<LI><A HREF="/Risks/index.3.html">Volume 3</A>
( <I><A HREF="/Risks/3.1.html">4 Jun 1986</A> - <A HREF="/Risks/3.91.html">30 Oct 1986</A>, 91 issues </I>)
<LI><A HREF="/Risks/index.4.html">Volume 4</A>
( <I><A HREF="/Risks/4.1.html">2 Nov 1986</A> - <A HREF="/Risks/4.96.html">6 Jun 1987</A>, 96 issues </I>)
<LI><A HREF="/Risks/index.5.html">Volume 5</A>
( <I><A HREF="/Risks/5.1.html">6 Jun 1987</A> - <A HREF="/Risks/5.84.html">31 Dec 1987</A>, 84 issues </I>)
<LI><A HREF="/Risks/index.6.html">Volume 6</A>
( <I><A HREF="/Risks/6.1.html">2 Jan 1988</A> - <A HREF="/Risks/6.94.html">31 May 1988</A>, 94 issues </I>)
<LI><A HREF="/Risks/index.7.html">Volume 7</A>
( <I><A HREF="/Risks/7.1.html">1 Jun 1988</A> - <A HREF="/Risks/7.98.html">22 Dec 1988</A>, 98 issues </I>)
<LI><A HREF="/Risks/index.8.html">Volume 8</A>
( <I><A HREF="/Risks/8.1.html">4 Jan 1989</A> - <A HREF="/Risks/8.87.html">29 Jun 1989</A>, 87 issues </I>)
<LI><A HREF="/Risks/index.9.html">Volume 9</A>
( <I><A HREF="/Risks/9.1.html">6 Jul 1989</A> - <A HREF="/Risks/9.97.html">30 May 1990</A>, 97 issues </I>)
<LI><A HREF="/Risks/index.10.html">Volume 10</A>
( <I><A HREF="/Risks/10.1.html">1 Jun 1990</A> - <A HREF="/Risks/10.85.html">31 Jan 1991</A>, 85 issues </I>)
<LI><A HREF="/Risks/index.11.html">Volume 11</A>
( <I><A HREF="/Risks/11.1.html">4 Feb 1991</A> - <A HREF="/Risks/11.95.html">28 Jun 1991</A>, 95 issues </I>)
<LI><A HREF="/Risks/index.12.html">Volume 12</A>
( <I><A HREF="/Risks/12.1.html">1 Jul 1991</A> - <A HREF="/Risks/12.71.html">24 Dec 1991</A>, 71 issues </I>)
<LI><A HREF="/Risks/index.13.html">Volume 13</A>
( <I><A HREF="/Risks/13.1.html">6 Jan 1992</A> - <A HREF="/Risks/13.89.html">2 Nov 1992</A>, 89 issues </I>)
<LI><A HREF="/Risks/index.14.html">Volume 14</A>
( <I><A HREF="/Risks/14.1.html">4 Nov 1992</A> - <A HREF="/Risks/14.89.html">27 Aug 1993</A>, 89 issues </I>)
<LI><A HREF="/Risks/index.15.html">Volume 15</A>
( <I><A HREF="/Risks/15.1.html">2 Sep 1993</A> - <A HREF="/Risks/15.81.html">29 Apr 1994</A>, 81 issues </I>)
<LI><A HREF="/Risks/index.16.html">Volume 16</A>
( <I><A HREF="/Risks/16.1.html">2 May 1994</A> - <A HREF="/Risks/16.96.html">22 Mar 1995</A>, 96 issues </I>)
<LI><A HREF="/Risks/index.17.html">Volume 17</A>
( <I><A HREF="/Risks/17.1.html">27 Mar 1995</A> - <A HREF="/Risks/17.96.html">1 Apr 1996</A>, 96 issues </I>)
<LI><A HREF="/Risks/index.18.html">Volume 18</A>
( <I><A HREF="/Risks/18.1.html">5 Apr 1996</A> - <A HREF="/Risks/18.82.html">14 February 1997</A>, 82 issues </I>)
</UL></BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-10</DOCNO>
<DOCOLDNO>IA012-000128-B041-589</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2/index.html 128.240.150.127 19970217000123 text/html 36885
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Sun, 16 Feb 1997 23:59:46 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Index to Volume 2</TITLE>
<LINK REL="Pref" HREF="/Risks/1/index.html">
<LINK REL="Next" HREF="/Risks/3/index.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Index to Volume 2</H1>
<H2> Saturday, 31 May 1986 </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------">
<DL>
<DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.1.html">Volume 2 Issue 1 (1 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.1.html#subj1">  First Six Months of the Forum in Retrospect; *** Updated Disaster List ***    (Peter G. Neumann)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.2.html">Volume 2 Issue 2 (1 Feb 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/2.2.html#subj1">  More on Shuttle destruct systems (Martin J. Moore, Sean Malloy, Brint Cooper)</A>
<LI><A HREF="/Risks/2.2.html#subj2">  The Challenger [non]accident (Herb Lin)</A>
<LI><A HREF="/Risks/2.2.html#subj3">  Redundancy (D. Cook)</A>
<LI><A HREF="/Risks/2.2.html#subj4">  Galileo Plutonium power (Martin Schoffstall, James Tomayko)</A>
<LI><A HREF="/Risks/2.2.html#subj5">  VDT's and birth defects in mice (Dan Hoey)</A>
<LI><A HREF="/Risks/2.2.html#subj6">  ORCON dissemination constraint on RISKS 1.43 (Ted Lee)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.3.html">Volume 2 Issue 3 (1 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.3.html#subj1">  The possible vs the impossible (Dave Parnas)</A>
<LI><A HREF="/Risks/2.3.html#subj2">  RISKS generalizations (Jim Horning)</A>
<LI><A HREF="/Risks/2.3.html#subj3">  Challenger speculation (Henry Spencer)</A>
<LI><A HREF="/Risks/2.3.html#subj4">  Possible triggering of the self-destruct mechanism (Don Wegeng)</A>
<LI><A HREF="/Risks/2.3.html#subj5">  Redundancy in the Shuttle's Computers (Mark S. Day)</A>
<LI><A HREF="/Risks/2.3.html#subj6">  Galileo Plutonium power (Herb Lin)</A>
<LI><A HREF="/Risks/2.3.html#subj7">  Icing the Shuttle (Jim McGrath)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.4.html">Volume 2 Issue 4 (2 Feb 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/2.4.html#subj1">  Solid propellants (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.4.html#subj2">  Plutonium (Jim McGrath)</A>
<LI><A HREF="/Risks/2.4.html#subj3">  SRB Self-Destruct Mechanisms (Clive Dawson)</A>
<LI><A HREF="/Risks/2.4.html#subj4">  Details on the 1981 Quebec election -- a program bug (Jean-Francois Lamy)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.5.html">Volume 2 Issue 5 (3 Feb 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/2.5.html#subj1">  SRBs and What the Computers Should Monitor (Sean Malloy, Charley Wingate)</A>
<LI><A HREF="/Risks/2.5.html#subj2">  SRB survival (Bill Keefe)</A>
<LI><A HREF="/Risks/2.5.html#subj3">  Physical Security at the Cape (Tim Wicinski)</A>
<LI><A HREF="/Risks/2.5.html#subj4">  A hard rain is gonna fall, (Marc Vilain)</A>
<LI><A HREF="/Risks/2.5.html#subj5">  Correction re Galileo plutonium (James Tomayko)</A>
<LI><A HREF="/Risks/2.5.html#subj6">  Quebec Election (Dan Craigen)</A>
<LI><A HREF="/Risks/2.5.html#subj7">  SCRIBE time-bomb goes off! (Peter G. Neumann)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.6.html">Volume 2 Issue 6 (4 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.6.html#subj1">  Shuttle computers (Marc Vilain) -- from NY Times</A>
<LI><A HREF="/Risks/2.6.html#subj2">  SRBs and Challenger (Mike Iglesias) -- from LA Times</A>
<LI><A HREF="/Risks/2.6.html#subj3">  Galileo, Plutonium, Centaur, physical security [4 messages] (Henry Spencer)</A>
<LI><A HREF="/Risks/2.6.html#subj4">  RISKS-2.5 &amp; "Some simple calculations" (Bob Ayers)</A>
<LI><A HREF="/Risks/2.6.html#subj5">  A hard rain is gonna fall. (Herb Lin)</A>
<LI><A HREF="/Risks/2.6.html#subj6">  By the slip of a finger ... (Ted Lee)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.7.html">Volume 2 Issue 7 (6 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.7.html#subj1">  The lesson of Challenger (Barry Shein)</A>
<LI><A HREF="/Risks/2.7.html#subj2">  Mistaken Arrest due to computer error (Steve Rabin)</A>
<LI><A HREF="/Risks/2.7.html#subj3">  Denial of [Religious] Service (Chris Guthrie)</A>
<LI><A HREF="/Risks/2.7.html#subj4">  Earthquake Monitoring Systems (Gary T. Leavens)</A>
<LI><A HREF="/Risks/2.7.html#subj5">  Mice &amp; CRT Radiation (Ted Shapin)</A>
<LI><A HREF="/Risks/2.7.html#subj6">  SRBs, What the Computers Should Monitor, and Expert Systems? (Jim Giles)</A>
<LI><A HREF="/Risks/2.7.html#subj7">  Redundancy in the Shuttle's Computers (K. Richard Magill)</A>
<LI><A HREF="/Risks/2.7.html#subj8">  Nuclear Cargo in the Shuttle (Larry Shilkoff)</A>
<LI><A HREF="/Risks/2.7.html#subj9">  Software Protection Symposium (Barbara Zayas)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.8.html">Volume 2 Issue 8 (7 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.8.html#subj1">  Expert systems and shuttles (Michael Brown, Dave Platt)</A>
<LI><A HREF="/Risks/2.8.html#subj2">  Plutonium (Martin J. Moore)</A>
<LI><A HREF="/Risks/2.8.html#subj3">  Earthquake Monitoring Systems (Mike Raugh via Matt Bishop, Hal Murray,     Eugene Miya)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.9.html">Volume 2 Issue 9 (9 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.9.html#subj1">  Computerized train wreck?  ... Computer-induced stock-market swings.     (Martin Minow)
</A>
<LI><A HREF="/Risks/2.9.html#subj2">  Selectively Displaying Data -- Boeing 767 EFIS (Alan M. Marcum)</A>
<LI><A HREF="/Risks/2.9.html#subj3">  Cape Range Safety Display Systems (Lynne C Moore)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.10.html">Volume 2 Issue 10 (12 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.10.html#subj1">  Computerized aircraft collision avoidance (Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.10.html#subj2">  Computerized Feedback and the Stock Market (Eric Nickell)</A>
<LI><A HREF="/Risks/2.10.html#subj3">  Analyst Changes City Treasurer's Computer Code (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.10.html#subj4">  Plutonium on the Space Shuttle (Tom Slone)</A>
<LI><A HREF="/Risks/2.10.html#subj5">  Request to RISKS Readers from COMPASS 86 (COMPuter ASSurance) (Al Friend)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.11.html">Volume 2 Issue 11 (16 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.11.html#subj1">  SF Federal Reserve Bank 2 Billion Dollar Goof (SF Chron via Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.11.html#subj2">  Washington D.C. Analyst's Password Game (AP via Geoff Goodfellow)</A>
<LI><A HREF="/Risks/2.11.html#subj3">  Boeing 767 EFIS -- compare Airbus A320 (Rob Warnock)</A>
<LI><A HREF="/Risks/2.11.html#subj4">  Networks Pose New Threats to Data Security                                (InfoWorld-86/2/10 via Werner Uhrig)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.12.html">Volume 2 Issue 12 (18 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.12.html#subj1">  Risks in automobile microprocessors -- Mercedes 500SE (Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.12.html#subj2">  Train safeguards defeated (Chuck Weinstock)</A>
<LI><A HREF="/Risks/2.12.html#subj3">  Security Safeguards for Air Force Computer Systems (Dave Platt)</A>
<LI><A HREF="/Risks/2.12.html#subj4">  How can Alvin Frost fight City Hall? (Jim DeLaHunt)</A>
<LI><A HREF="/Risks/2.12.html#subj5">  More Plutonium/Shuttle (Martin J. Moore)</A>
<LI><A HREF="/Risks/2.12.html#subj6">  Computerized Voting -- talk by Eva Waskell (Wednesday eve, 19 February, MIT)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.13.html">Volume 2 Issue 13 (20 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.13.html#subj1">  Dec. 8 cruise missile failure caused by procedural problems (Martin J. Moore)</A>
<LI><A HREF="/Risks/2.13.html#subj2">  Computerized voting (Matt Bishop)</A>
<LI><A HREF="/Risks/2.13.html#subj3">  Non-science quotations on Plutonium (Bob Ayers) </A>
<LI><A HREF="/Risks/2.13.html#subj4">  Software Piracy (D.Reuben)</A>
<LI><A HREF="/Risks/2.13.html#subj5">  Air Force Security Safeguards (Stephen Wolff)</A>
<LI><A HREF="/Risks/2.13.html#subj6">  Shuttle Safety (NYTimes News Summary)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.14.html">Volume 2 Issue 14 (24 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.14.html#subj1">  Automotive Problems Intensify (Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.14.html#subj2">  A hard rain is gonna fall (around March 23) (Martin J. Moore)</A>
<LI><A HREF="/Risks/2.14.html#subj3">  Misdirected modems (Alan Silverstein)</A>
<LI><A HREF="/Risks/2.14.html#subj4">  Witch hunts, or Where does the buck stop? (M.L. Brown)</A>
<LI><A HREF="/Risks/2.14.html#subj5">  Spells and Spirits (Steve Berlin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.15.html">Volume 2 Issue 15 (25 Feb 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/2.15.html#subj1">  Software Safety Survey (Nancy Leveson)</A>
<LI><A HREF="/Risks/2.15.html#subj2">  Titanic Effect (Nancy Leveson)</A>
<LI><A HREF="/Risks/2.15.html#subj3">  F-18 spin accident (Henry Spencer)</A>
<LI><A HREF="/Risks/2.15.html#subj4">  Space shuttle problems (Brad Davis)</A>
<LI><A HREF="/Risks/2.15.html#subj5">  Misdirected modems (Matt Bishop)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.16.html">Volume 2 Issue 16 (25 Feb 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/2.16.html#subj1">  Volunteers to study security of computerized voting booths? (Kurt Hyde)</A>
<LI><A HREF="/Risks/2.16.html#subj2">  Our Economy Is Based On Electricity (Jared M. Spool)</A>
<LI><A HREF="/Risks/2.16.html#subj3">  Misdirected modems (Jared M. Spool)</A>
<LI><A HREF="/Risks/2.16.html#subj4">  The Titanic Effect (Earl Boebert)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.17.html">Volume 2 Issue 17 (28 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.17.html#subj1">  Replacing humans with computers? (Nancy Leveson)</A>
<LI><A HREF="/Risks/2.17.html#subj2">  Eastern Airlines stock (Steve Strassmann)</A>
<LI><A HREF="/Risks/2.17.html#subj3">  Computerized stock trading and feedback systems (Kremen)</A>
<LI><A HREF="/Risks/2.17.html#subj4">  Computer Voting Booths (Larry Polnicky)</A>
<LI><A HREF="/Risks/2.17.html#subj5">  Reliance on security (Jong)</A>
<LI><A HREF="/Risks/2.17.html#subj6">  AI risks (Nicholas Spies)</A>
<LI><A HREF="/Risks/2.17.html#subj7">  Data Encryption Standard (Dave Platt)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.18.html">Volume 2 Issue 18 (28 Feb 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.18.html#subj1">  Titanic and What did I overlook? (Hal Murray)</A>
<LI><A HREF="/Risks/2.18.html#subj2">  Titanic Effect (Jong)</A>
<LI><A HREF="/Risks/2.18.html#subj3">  Computers placing telephone calls (Art Evans)</A>
<LI><A HREF="/Risks/2.18.html#subj4">  Misdirected modems (Sam Kendall)</A>
<LI><A HREF="/Risks/2.18.html#subj5">  Modems and phone numbers (David Barto)</A>
<LI><A HREF="/Risks/2.18.html#subj6">  Misdirecting my modem (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.18.html#subj7">  Power-outages, &amp; other failures of central DP systems (Dave Platt)</A>
<LI><A HREF="/Risks/2.18.html#subj8">  Computer voting booths (Dave Platt)</A>
<LI><A HREF="/Risks/2.18.html#subj9">  Data Encryption Standard (Chris McDonald)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.19.html">Volume 2 Issue 19 (2 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.19.html#subj1">  A word from Isaac Asimov about Robots (Bryan)</A>
<LI><A HREF="/Risks/2.19.html#subj2">  AI risks (John Shore)</A>
<LI><A HREF="/Risks/2.19.html#subj3">  Replacing Humans with Computers (David desJardins)</A>
<LI><A HREF="/Risks/2.19.html#subj4">  On-line Slot Machines (Jeff Makey)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.20.html">Volume 2 Issue 20 (2 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.20.html#subj1">  Risks in Encryption (Jerry Saltzer)</A>
<LI><A HREF="/Risks/2.20.html#subj2">  NSA and encryption algorithms (Curtis Jackson)</A>
<LI><A HREF="/Risks/2.20.html#subj3">  Low-Tech Computerized Voting (Harry S. Delugach)</A>
<LI><A HREF="/Risks/2.20.html#subj4">  Risks in ballot-counting systems (Larry Campbell)</A>
<LI><A HREF="/Risks/2.20.html#subj5">  Misdirected modems (Richard H. Lathrop)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.21.html">Volume 2 Issue 21 (3 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.21.html#subj1">  The risks of (not) using Robots (Hal Murray)</A>
<LI><A HREF="/Risks/2.21.html#subj2">  Computerized Voting Booths (Larry Polnicky)</A>
<LI><A HREF="/Risks/2.21.html#subj3">  No-carrier detection by misdirected modems (Dave Platt)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.22.html">Volume 2 Issue 22 (5 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.22.html#subj1">  Voting receipt (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.22.html#subj2">  Voting booths (Jim McGrath)</A>
<LI><A HREF="/Risks/2.22.html#subj3">  Computerized Voting (Tom Benson)</A>
<LI><A HREF="/Risks/2.22.html#subj4">  Replacing humans with computers (Alan M. Marcum)</A>
<LI><A HREF="/Risks/2.22.html#subj5">  Electricity's power (Marianne Mueller)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.23.html">Volume 2 Issue 23 (6 Mar 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/2.23.html#subj1">  Computerized voting (Jeff Mogul, Larry Polnicky, Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.23.html#subj2">  ATM Ripoff (Dave Curry)</A>
<LI><A HREF="/Risks/2.23.html#subj3">  Internet importance/robustness (Tom Perrine)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.24.html">Volume 2 Issue 24 (8 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.24.html#subj1">  Computerized ballot stuffing (Andy Kegel)</A>
<LI><A HREF="/Risks/2.24.html#subj2">  Progress report on computerized voting (Kurt Hyde)</A>
<LI><A HREF="/Risks/2.24.html#subj3">  Wild Modems (Bjorn Benson)</A>
<LI><A HREF="/Risks/2.24.html#subj4">  Misdirected modems (Phil Ngai)</A>
<LI><A HREF="/Risks/2.24.html#subj5">  Power outages (Phil Ngai)</A>
<LI><A HREF="/Risks/2.24.html#subj6">  Earthquake problems with Nuclear Reactors (Lindsay F. Marshall)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.25.html">Volume 2 Issue 25 (10 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.25.html#subj1">  Balloting (Barbara E. Rice)</A>
<LI><A HREF="/Risks/2.25.html#subj2">  Canceling ballots (Jim McGrath)</A>
<LI><A HREF="/Risks/2.25.html#subj3">  Bank robbery (Curtis Jackson)</A>
<LI><A HREF="/Risks/2.25.html#subj4">  Earthquake problems with Nuclear Reactors (throopw)</A>
<LI><A HREF="/Risks/2.25.html#subj5">  Modems DON'T WORK AS SUPPOSED (Brent Chapman, Martin J. Moore, Phil Ngai)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.26.html">Volume 2 Issue 26 (14 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.26.html#subj1">  Integrity of the Electoral Process (Mark Jackson)</A>
<LI><A HREF="/Risks/2.26.html#subj2">  Ballot Secrecy (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/2.26.html#subj3">  Nuclear waste-land (Jerry Mungle)</A>
<LI><A HREF="/Risks/2.26.html#subj4">  Nuclear disasters (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/2.26.html#subj5">  103/212 modems (Ephraim)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.27.html">Volume 2 Issue 27 (15 Mar 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/2.27.html#subj1">  Overload of a different sort [Air traffic stoppage] (Ted Lee)</A>
<LI><A HREF="/Risks/2.27.html#subj2">  Cordless Phones Cry Wolf! (Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.27.html#subj3">  The Mob Breaks into the Information Age (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.27.html#subj4">  [Non]computerized train wreck (Mark Brader)</A>
<LI><A HREF="/Risks/2.27.html#subj5">  Ballot Integrity; Specialization in Decision-Making (Tom Benson)</A>
<LI><A HREF="/Risks/2.27.html#subj6">  Network Security, Integrity, and "Importance" (Kurt F. Sauer)</A>
<LI><A HREF="/Risks/2.27.html#subj7">  Modems (James R. McGowan)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.28.html">Volume 2 Issue 28 (17 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.28.html#subj1">  Risks of commission vs. risks of omission (Dave Parnas and Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.28.html#subj2">  The TIME is RIPE -- a clock problem (Peter Neumann)</A>
<LI><A HREF="/Risks/2.28.html#subj3">  Mailer Gone Mad? (Landrum)  </A>
<LI><A HREF="/Risks/2.28.html#subj4">  Money Talks (Matthew Kruk)</A>
<LI><A HREF="/Risks/2.28.html#subj5">  Another discourteous modem (Glenn Hyatt)</A>
<LI><A HREF="/Risks/2.28.html#subj6">  Will the modem discussions ever hang up? (Rob Austein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.29.html">Volume 2 Issue 29 (17 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.29.html#subj1">  Commission vs. Omission (Martin J. Moore plus an example from Dave Parnas)</A>
<LI><A HREF="/Risks/2.29.html#subj2">  A Stitch in Time (Jagan Jagannathan)</A>
<LI><A HREF="/Risks/2.29.html#subj3">  Clockenspiel (Jim Horning)</A>
<LI><A HREF="/Risks/2.29.html#subj4">  Cordless phones (Chris Koenigsberg)</A>
<LI><A HREF="/Risks/2.29.html#subj5">  Money talks (Dirk Grunwald, date correction from Matthew Kruk)</A>
<LI><A HREF="/Risks/2.29.html#subj6">  [Non]computerized train wreck (Mark Brader)</A>
<LI><A HREF="/Risks/2.29.html#subj7">  On-line Safety Database (Ken Dymond)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.30.html">Volume 2 Issue 30 (18 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.30.html#subj1">  Classes of Errors (Scott Rose)</A>
<LI><A HREF="/Risks/2.30.html#subj2">  Range Safety System (David desJardins)</A>
<LI><A HREF="/Risks/2.30.html#subj3">  Commission vs omission (Geoffrey A. Landis)</A>
<LI><A HREF="/Risks/2.30.html#subj4">  Stupid Clock Software (Dave Curry)</A>
<LI><A HREF="/Risks/2.30.html#subj5">  Control characters in headers from eglin-vax (Martin J. Moore)</A>
<LI><A HREF="/Risks/2.30.html#subj6">  Money Talks (Prasanna G. Mulgaonkar)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.31.html">Volume 2 Issue 31 (19 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.31.html#subj1">  Still more on shuttle destruct systems (Martin J. Moore)</A>
<LI><A HREF="/Risks/2.31.html#subj2">  Clock Synchronization (Andy Mondore)</A>
<LI><A HREF="/Risks/2.31.html#subj3">  Timestamp integrity at system startup (John Coughlin)</A>
<LI><A HREF="/Risks/2.31.html#subj4">  Danny Cohen on SDI (Charlie Crummer)</A>
<LI><A HREF="/Risks/2.31.html#subj5">  Two more mailer problems (Sidney Markowitz)</A>
<LI><A HREF="/Risks/2.31.html#subj6">  Marking money for the blind (Atrocity Joelll)</A>
<LI><A HREF="/Risks/2.31.html#subj7">  Why would anyone want to computerize voting? (Larry Campbell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.32.html">Volume 2 Issue 32 (20 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.32.html#subj1">  Om/Comm-ission, and analysis of risks (Niall Mansfield)</A>
<LI><A HREF="/Risks/2.32.html#subj2">  RSO's and IIP's (Dave Curry)</A>
<LI><A HREF="/Risks/2.32.html#subj3">  Complex systems ru(i|n)ning our cities (Mike Mc Namara)</A>
<LI><A HREF="/Risks/2.32.html#subj4">  Re: Two more mailer problems (Bernard S. Greenberg)</A>
<LI><A HREF="/Risks/2.32.html#subj5">  Banknotes for the visually handicapped (Nigel Roberts, Barbara E. Rice)</A>
<LI><A HREF="/Risks/2.32.html#subj6">  Psychological and sociological consequences (Harald Baerenreiter)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.33.html">Volume 2 Issue 33 (23 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.33.html#subj1">  RSO's and IIP's - Martin Moore's response (Dave Curry)</A>
<LI><A HREF="/Risks/2.33.html#subj2">  Omissions/commissions and missile destructs (Chris McDonald)</A>
<LI><A HREF="/Risks/2.33.html#subj3">  Blind and Paper Money (sdo)</A>
<LI><A HREF="/Risks/2.33.html#subj4">  Two Cases of Computer Burglary (NY Times)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.34.html">Volume 2 Issue 34 (27 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.34.html#subj1">  RSO's and IIP's - Martin Moore's response (Henry Spencer)</A>
<LI><A HREF="/Risks/2.34.html#subj2">  Range Safety: a final word (Martin Moore)</A>
<LI><A HREF="/Risks/2.34.html#subj3">  Someone really sophisticated, with a Ph.D... (Nigel Roberts, Keith F. Lynch)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.35.html">Volume 2 Issue 35 (30 Mar 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.35.html#subj1">  San Jose Library (Matthew P. Wiener, Ken Laws)</A>
<LI><A HREF="/Risks/2.35.html#subj2">  Inter-system crashes (Rich A. Hammond)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.36.html">Volume 2 Issue 36 (1 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.36.html#subj1">  Errant Clocks (Barry Shein)</A>
<LI><A HREF="/Risks/2.36.html#subj2">  Computer Illiteracy (Matthew P. Wiener)</A>
<LI><A HREF="/Risks/2.36.html#subj3">  San Jose Library (Dick Karpinski, Holleran)</A>
<LI><A HREF="/Risks/2.36.html#subj4">  Psychological and sociological consequences (Dave Benson)</A>
<LI><A HREF="/Risks/2.36.html#subj5">  More inter-system crashes (Henry Spencer)</A>
<LI><A HREF="/Risks/2.36.html#subj6">  COMPASS 86:  A Progress Report (Al Friend)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.37.html">Volume 2 Issue 37 (6 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.37.html#subj1">  Request for information about military battle software (Dave Benson)</A>
<LI><A HREF="/Risks/2.37.html#subj2">  Programming productivity (Henry Spencer)</A>
<LI><A HREF="/Risks/2.37.html#subj3">  Space Shuttle Software (via PGN)</A>
<LI><A HREF="/Risks/2.37.html#subj4">  Open-and-Shut Case Against Reagan's Command Plane (Geoffrey S. Goodfellow)</A>
<LI><A HREF="/Risks/2.37.html#subj5">  Computer Illiteracy (Matt Bishop)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.38.html">Volume 2 Issue 38 (8 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.38.html#subj1">  The UK Driving Vehicle Licensing Centre (Brian Randell)</A>
<LI><A HREF="/Risks/2.38.html#subj2">  Computer crime wave (Chris Hibbert)</A>
<LI><A HREF="/Risks/2.38.html#subj3">  Programming productivity (Herb Lin)</A>
<LI><A HREF="/Risks/2.38.html#subj4">  Request for information about military battle software (Scott E. Preece)</A>
<LI><A HREF="/Risks/2.38.html#subj5">  Aviation Week Technical Survey:  AI &amp; Aviation (Werner Uhrig)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.39.html">Volume 2 Issue 39 (11 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.39.html#subj1">  $36 million accounting mistake (Graeme Hirst)</A>
<LI><A HREF="/Risks/2.39.html#subj2">  Admissability of computer files as evidence? (Kathryn Smith)</A>
<LI><A HREF="/Risks/2.39.html#subj3">  "Rapid advance" of SDI software (Walt Thode)</A>
<LI><A HREF="/Risks/2.39.html#subj4">  Blame-the-computer syndrome (JAN Lee)</A>
<LI><A HREF="/Risks/2.39.html#subj5">  Hackensack Phone Snafu (Dirk Grunwald)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.40.html">Volume 2 Issue 40 (12 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.40.html#subj1">  GREAT BREAKTHROUGHS [Red Herrings swimming upstream?] (Dave Parnas)</A>
<LI><A HREF="/Risks/2.40.html#subj2">  Military battle software ["first use", "works"]    (James M Galvin, Herb Lin, Scott E. Preece, Dave Benson)
</A>
<LI><A HREF="/Risks/2.40.html#subj3">  First use - Enterprise (Lindsay F. Marshall)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.41.html">Volume 2 Issue 41 (13 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.41.html#subj1">  Computer Naivete (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/2.41.html#subj2">  Admissability of computer files as evidence (Scott E. Preece)</A>
<LI><A HREF="/Risks/2.41.html#subj3">  Programming productivity (Henry Spencer)</A>
<LI><A HREF="/Risks/2.41.html#subj4">  The San Jose Public Library [and responsibilities] (Sriram Vajapeyam)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.42.html">Volume 2 Issue 42 (14 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.42.html#subj1">  Robot safety (Ron Cain via Bill Park)</A>
<LI><A HREF="/Risks/2.42.html#subj2">  Use of computer files as evidence (Rob Horn)</A>
<LI><A HREF="/Risks/2.42.html#subj3">  Review of *Softwar* (Gary Chapman)</A>
<LI><A HREF="/Risks/2.42.html#subj4">  Computerized Voting -- No Standards and a Lot of Questions     (Summary of Eva Waskell's talk by Ron Newman)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.43.html">Volume 2 Issue 43 (17 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.43.html#subj1">  Re: Review of *Softwar* (Marvin Schaefer)</A>
<LI><A HREF="/Risks/2.43.html#subj2">  GREAT BREAKTHROUGHS (Herb Lin)</A>
<LI><A HREF="/Risks/2.43.html#subj3">  Star Wars software advance (AP)</A>
<LI><A HREF="/Risks/2.43.html#subj4">  Smart bombs in Libya (Washington Post)</A>
<LI><A HREF="/Risks/2.43.html#subj5">  Pacific Bell Bills (SF Chronicle)</A>
<LI><A HREF="/Risks/2.43.html#subj6">  BU joins the InterNet... (Barry Shein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.44.html">Volume 2 Issue 44 (21 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.44.html#subj1">  Why Simulation Is A Good Thing... (Lynne C. Moore)</A>
<LI><A HREF="/Risks/2.44.html#subj2">  Hacking &amp; forgery laws (Robert Stroud)</A>
<LI><A HREF="/Risks/2.44.html#subj3">  Strategic Systems Reliability Testing (Dan Ball)</A>
<LI><A HREF="/Risks/2.44.html#subj4">  SDI (Larry Campbell)</A>
<LI><A HREF="/Risks/2.44.html#subj5">  Cost of phone billing error (Dave Redell)</A>
<LI><A HREF="/Risks/2.44.html#subj6">  Normal Accidents and battle software (Dave Benson)</A>
<LI><A HREF="/Risks/2.44.html#subj7">  Psychological risks, part II (Dave Benson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.45.html">Volume 2 Issue 45 (28 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.45.html#subj1">  HBO gets Hacked:: We Interrupt This Program ... for a Viewer Protest.    (Geoff Goodfellow, Frank J. Wancho)
</A>
<LI><A HREF="/Risks/2.45.html#subj2">  Ball's contribution on Polaris and SDI (from Dave Parnas)</A>
<LI><A HREF="/Risks/2.45.html#subj3">  SDI Reliability Testing  - Offensive deterrent vs SDI (Jon Jacky)</A>
<LI><A HREF="/Risks/2.45.html#subj4">  What are the limits to simulation? (Eugene Miya)</A>
<LI><A HREF="/Risks/2.45.html#subj5">  Reference on admissibility of computer records (Bill Cox)</A>
<LI><A HREF="/Risks/2.45.html#subj6">  Phone billing error at Pacific Bell, etc. (John Coughlin)</A>
<LI><A HREF="/Risks/2.45.html#subj7">  Cracked Libya Defense (Udo Voges)</A>
<LI><A HREF="/Risks/2.45.html#subj8">  Challenger article (Ron Minnich)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.46.html">Volume 2 Issue 46 (29 Apr 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.46.html#subj1">  Martin J. Moore (on Challenger article)</A>
<LI><A HREF="/Risks/2.46.html#subj2">  TV "piracy" (Nicholas Spies)</A>
<LI><A HREF="/Risks/2.46.html#subj3">  HBO -- Hacked Briefly Overnight (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.46.html#subj4">  The dangers of assuming too much -- on TMI-2 (J. Paul Holbrook)</A>
<LI><A HREF="/Risks/2.46.html#subj5">  A POST Script on Nuclear Power (Peter G. Neumann)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.47.html">Volume 2 Issue 47 (1 May 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.47.html#subj1">  HBO hacking (Phil R. Karn, Dan Franklin)</A>
<LI><A HREF="/Risks/2.47.html#subj2">  What are the limits to simulation? (Herb Lin)</A>
<LI><A HREF="/Risks/2.47.html#subj3">  Strategic Systems Reliability Testing (Herb Lin)</A>
<LI><A HREF="/Risks/2.47.html#subj4">  Correction on Challenge Discussion (Jeff Siegal)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.48.html">Volume 2 Issue 48 (3 May 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.48.html#subj1">  Failure to Backup Data (James H. Coombs)</A>
<LI><A HREF="/Risks/2.48.html#subj2">  Computer detracting from effective communication? (Bruce A. Sesnovich)</A>
<LI><A HREF="/Risks/2.48.html#subj3">  Words, words, words... (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.48.html#subj4">  Copyright Laws (Matthew Kruk)</A>
<LI><A HREF="/Risks/2.48.html#subj5">  Re: Correction on Challenger (Martin J. Moore)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.49.html">Volume 2 Issue 49 (7 May 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.49.html#subj1">  Perrow on reactor containment vessels (Richard Guy)</A>
<LI><A HREF="/Risks/2.49.html#subj2">  Captain Midnight (Scott Dorsey, MRB)</A>
<LI><A HREF="/Risks/2.49.html#subj3">  NSA planning new data encryption scheme - they'll keep the keys (Jon Jacky)</A>
<LI><A HREF="/Risks/2.49.html#subj4">  Espionage (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.49.html#subj5">  The Star Wars Swindle (Dave Weiss)</A>
<LI><A HREF="/Risks/2.49.html#subj6">  Backups (Will Martin)</A>
<LI><A HREF="/Risks/2.49.html#subj7">  Interpreting Satellite Pictures (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/2.49.html#subj8">  Word-processing damages expression (Niall Mansfield, PGN)</A>
<LI><A HREF="/Risks/2.49.html#subj9">  Proofreading vs. computer-based spelling checks (Dave Platt)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.50.html">Volume 2 Issue 50 (8 May 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.50.html#subj1">  Refocus the discussion, please! (Bob Estell)</A>
<LI><A HREF="/Risks/2.50.html#subj2">  [Response.] Also, Delta rocket shutdown (Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.50.html#subj3">  Large systems failures &amp; Computer assisted writing (Ady Wiernik)</A>
<LI><A HREF="/Risks/2.50.html#subj4">  DESisting (dm, William Brown II)</A>
<LI><A HREF="/Risks/2.50.html#subj5">  Failure to Backup Data (Greg Brewster)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.51.html">Volume 2 Issue 51 (11 May 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.51.html#subj1">  Reliability limits (Brian Randell)</A>
<LI><A HREF="/Risks/2.51.html#subj2">  NSA assigning encryption keys (Jay Elinsky)</A>
<LI><A HREF="/Risks/2.51.html#subj3">  HBO pirate (Lauren Weinstein)</A>
<LI><A HREF="/Risks/2.51.html#subj4">  Failure to Backup Data, by James H. Coombs (Roy Smith)</A>
<LI><A HREF="/Risks/2.51.html#subj5">  Admissibility of legal evidence from computers (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.51.html#subj6">  Electronic document media (Mike McLaughlin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.52.html">Volume 2 Issue 52 (13 May 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.52.html#subj1">  Launch failures (Phil R. Karn)</A>
<LI><A HREF="/Risks/2.52.html#subj2">  Brittleness of large systems (Dave Benson)</A>
<LI><A HREF="/Risks/2.52.html#subj3">  HBO (Scott Dorsey, Dave Sherman)</A>
<LI><A HREF="/Risks/2.52.html#subj4">  Word processing -- reroute [reroot?] the discussion (Chuq Von Rospach)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.53.html">Volume 2 Issue 53 (16 May 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.53.html#subj1">  A late report on the Sheffield (AP [from Martin Minow], LA Times [Dave Platt]</A>
<LI><A HREF="/Risks/2.53.html#subj2">  News items [Lobsters; Eavesdropping] (Alan Wexelblat)</A>
<LI><A HREF="/Risks/2.53.html#subj3">  More Phone Bill Bugs... (Dave Curry)</A>
<LI><A HREF="/Risks/2.53.html#subj4">  Backup problems (Davidsen, Roy Smith)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.54.html">Volume 2 Issue 54 (25 May 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/2.54.html#subj1">  Meteorites (Larry West)</A>
<LI><A HREF="/Risks/2.54.html#subj2">  Meteorites, Chernobyl, Technology, and RISKS (Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.54.html#subj3">  London Stock Exchange Computer System Crash (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/2.54.html#subj4">  Backup (Fred Hapgood, Bruce O'Neel)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.55.html">Volume 2 Issue 55 (28 May 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.55.html#subj1">  Culling through RISKS headers; SDI (Jim Horning)</A>
<LI><A HREF="/Risks/2.55.html#subj2">  Blind Faith in Technology, and Caspar Weinberger (Herb Lin)</A>
<LI><A HREF="/Risks/2.55.html#subj3">  Risks of doing software quality assurance too diligently       (PGN from Chris Shaw and the Torrance Daily Breeze)
</A>
<LI><A HREF="/Risks/2.55.html#subj4">  Collegiate jungle (Mike McLaughlin)</A>
<LI><A HREF="/Risks/2.55.html#subj5">  Decease and Desist -- Death by Computer (Deborah L. Estrin)</A>
<LI><A HREF="/Risks/2.55.html#subj6">  The Death of the Gossamer Time Traveler (Peter G. Neumann)</A>
<LI><A HREF="/Risks/2.55.html#subj7">  Computer Ethics (Bruce A. Sesnovich)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/2.56.html">Volume 2 Issue 56 (30 May 86)</A>
<DD><UL>
<LI><A HREF="/Risks/2.56.html#subj1">  A joke that went wrong (Brian Randell)</A>
<LI><A HREF="/Risks/2.56.html#subj2">  Computer Program for nuclear reactor accidents (Gary Chapman)</A>
<LI><A HREF="/Risks/2.56.html#subj3">  On risks and knowledge (Alan Wexelblat) [Excerpt]</A>
<LI><A HREF="/Risks/2.56.html#subj4">  Technical vs. Political in SDI (Dave Benson)</A>
<LI><A HREF="/Risks/2.56.html#subj5">  Are SDI Software predictions biased by old tactical software? (Bob Estell)</A>
<LI><A HREF="/Risks/2.56.html#subj6">  Culling through RISKS headers (Jim Horning)</A>
</UL></DL>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-11</DOCNO>
<DOCOLDNO>IA012-000128-B042-48</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.2.html 128.240.150.127 19970217000156 text/html 54046
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:00:10 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/1.01.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 2</H1>
<H2>       Friday, 28 Aug 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Introduction; three more risk items 
</A>
<DD>
<A HREF="#subj1.1">
Peter Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Mariner 1 Irony 
</A>
<DD>
<A HREF="#subj2.1">
Nicholas Spies
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  RISKS Forum ... [Reaction] 
</A>
<DD>
<A HREF="#subj3.1">
Bob Carter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  RISKS Forum ... [An Air Traffic Control Problem] 
</A>
<DD>
<A HREF="#subj4.1">
Scott Rose
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Risks in AI Diagnostic Aids 
</A>
<DD>
<A HREF="#subj5.1">
Art Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Warning! ... [A Trojan Horse Bites Man] 
</A>
<DD>
<A HREF="#subj6.1">
Don Malpass
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  SDI 
</A>
<DD>
<A HREF="#subj7.1">
Martin Moore
</A><br>
<A HREF="#subj7.2">
 Jim Horning
</A><br>
<A HREF="#subj7.3">
 John McCarthy
</A><br>
<A HREF="#subj7.4">
 John McCarthy
</A><br>
<A HREF="#subj7.5">
 Peter Karp
</A><br>
<A HREF="#subj7.6">
 Dave Parnas
</A><br>
<A HREF="#subj7.7">
        Gary Martins
</A><br>
<A HREF="#subj7.8">
 Tom Parmenter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  The Madison Paper on Computer Unreliability and Nuclear War 
</A>
<DD>
<A HREF="#subj8.1">
Jeff Myers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Can a Computer Declare War? 
</A>
<DD>
<A HREF="#subj9.1">
Cliff Johnson
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">
Introduction, and more recent risk items
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL">
Neumann@SRI-CSL
</A>&gt;
</address>
<i>
27 Aug 1985 23:32:01-PST
</i><PRE>

I was away during the previous three weeks, which made it difficult to put
out another issue.  However, the newspapers were full of excitement relevant
to this forum:

  * A Federal district judge awarded $1.25 million to the families of
    three lobstermen who were lost at sea in a storm that the National
    Weather Service failed to predict because its parent organization 
    (the National Oceanic and Atmospheric Administration) had not repaired 
    a weather buoy for three months.  [NY Times 13 Aug 85]

  * Another Union Carbide leak (causing 135 injuries) resulted from a 
    computer program that was not yet programmed to recognize aldicarb
    oxime, compounded by human error when the operator misinterpreted
    the results of the program to imply the presence of methyl isocyanate
    (as in Bhopal).  A 20-minute delay in notifying county emergency
    made things worse.  [NY Times 14 and 24 Aug 85 front pages]  (There
    were two other serious Union Carbide incidents reported in August as 
    well, although only this one had a computer link.)

  * An untimely -- and possibly experiment-aborting -- delay of the intended 
    25 August launch of the space shuttle Discovery was caused when a
    malfunction in the backup computer was discovered just 25 minutes 
    before the scheduled launch.  The delay threatened to seriously
    compromise the mission.  [NY Times 26 August 1985]  The Times reporter
    John Noble Wilford wrote, "What was puzzling to engineers was that the
    computer had worked perfectly in tests before today.  And in tests after
    the failure, it worked, though showing signs of trouble."  Arnold
    Aldrich, manager of the shuttle program at Johnson, was quoted as saying
    "We're about 99.5% sure it's a hardware failure."  (The computers are
    state of the art as of 1972 and are due for upgrading in 1987.)  A
    similar failure of just the backup computer caused a one-day delay in
    Discovery's maiden launch last summer.

  * More details are emerging on possible computer hanky-panky in elections,
    including the recent Philippine elections.  There has been a series of
    articles in the past weeks by Peter Carey in the San Jose Mercury News
    -- which I haven't seen yet but will certainly hope to report on.

I expect that future issues of this RISKS forum will appear at a higher
frequency -- especially if there is more interaction from our readership.  I
will certainly try to redistribute appropriate provocative material on a
shorter fuse.  I hope that we can do more than just recapture and abstract
things that appear elsewhere, but that depends on some of you contributing.
I will be disappointed (but not surprised) to hear complaints that we
present only one side of any particular issue, particularly when no
countering positions are available or when none are provoked in response; if
you are bothered by only one side being represented, you must help to
restore the balance.  However, remember that it is often easier to criticize
others than to come up with constructive alternatives, and constructive
alternatives are at the heart of reducing risks.  So, as I said in vol 1 no
1, let us be constructive.

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
Mariner 1 irony
</A>
</H3>
<address>
&lt;<A HREF="mailto:Nicholas.Spies@CMU-CS-H.ARPA">
Nicholas.Spies@CMU-CS-H.ARPA
</A>&gt;
</address>
<i>
16 Aug 1985 21:23-EST
</i><PRE>
To: risks@sri-csl

My late father (Otto R. Spies) was a research scientist at Burroughs when
the Mariner 1 launch failed. He brought home an internal memo that was
circulated to admonish all employees to be careful in their work to prevent
similar disasters in the future. (I don't recall whether Burroughs was
directly involved with Mariner 1 or not.)  After explaining that a critical
program bombed because a period was substituted for a comma, the memo ended
with the phrase

		"... no detail is to [sic] small to overlook."

My father would be deeply pleased that people who can fully appreciate this
small irony are now working on ways to prevent the misapplication of
computers as foible-amplifiers.

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">
Forum on Risks to the Public in Computer Systems    [Reaction]
</A>
</H3>
<address>
_Bob 
&lt;<A HREF="mailto:Carter@RUTGERS.ARPA">
Carter@RUTGERS.ARPA
</A>&gt;
</address>
<i>
8 Aug 85  19:10 EDT (Thu)
</i><PRE>
To: RISKS@SRI-CSL

Thanks for the copy of Vol. I, No. 1.  Herewith a brief reaction.  This
is sent to you directly because I'm not sure whether discussion of the
digest is appropriate for inclusion in the digest.  

  1. Please mung RISKS so that it does not break standard undigestifying 
     software (in my case, BABYL).    

        [BABYL is an EMACS-TECO hack.  It seems to be a real bear to use,
         with lots of pitfalls still.  But I'll see what I can do.  
         Alternatively, shorter issues might help.  PGN]
    
  2. I think RISKS is clearly an idea whose time has come, but I'm not 
     entirely sure it has been sufficiently thought through.  

        [I should hope not!  It is a cooperative venture.  I just
         happen to be trying to moderate it.  PGN]

   (a.) You cast your net altogether too widely, and include some topics
        that have been discussed extensively on widely-read mailing lists.
        Star Wars, the Lin paper, the Parnas resignation, and related topics
        have been constructively discussed on ARMS-D.  I have considerable
        doubt about the utility of replicating this discussion.  (The
        moderators of HUMAN-NETS and POLI-SCI have both adopted the policy
        of directing SDI debate to that forum.  Would it be a good idea to
        follow that example?

           [To some extent, yes.  However, one cannot read ALL of the
            interesting BBOARDs -- there are currently hundreds on the
            ARPANET alone, many of which have some bearing on RISKS.  Also,
            browsers from other networks are at a huge disadvantage unless
            they have connections, hours of spare time, money, etc.  This is
            a FORUM ON RISKS, and should properly address that topic.  We
            certainly should not simply reproduce other BBOARDS, but some
            duplication seems tolerable.  (I'll try to keep it at the end
            of each issue, so you won't have to wade through it.)  By the
            way, I had originally intended to mention ARMS-D in RISKS vol 1
            no 1, but did not have time to check it out in detail.  For those
            of you who want to pursue it, next following is the essence of
            the blurb taken from the Network Information Center,
            SRI-NIC.ARPA:&lt;NETINFO&gt;INTEREST-GROUPS.TXT.  PGN]

          [  ARMS-D@MIT-MC:

             The Arms-Discussion Digest is intended to be a forum for
             discussion of arms control and weapon system issues.  Messages
             are collected, edited into digests and distributed as the
             volume of mail dictates (usually twice a week).

             Old digests may be FTP'ed from MIT-MC(no login required).  They
             are archived at   BALL; ARMSD ARCn   , where n is the issue no.

             All requests to be added to or deleted from this list, problems, 
             questions, etc., should be sent to Arms-D-REQUEST@MIT-MC.

             Moderator: Harold G. Ancell &lt;HGA@MIT-MC&gt;  ]

   (b.) You do not cover the topics which, in my opinion, are going
        to generate more law-making than anything you do touch on.  In
        particular, the health hazards (if any) of CRT use, and the working
        conditions (including automated performance testing) of "pink-collar" 
        CRT users are going to be among the most important labor-relations
        issues of the next few years.  Many people think these more imminent
        risks than those mentioned in the RISKS prospectus.

                              [Fine topic!  PGN]

  3. I think a digest is an animal that differs considerably from print
     media, but is no less important.  I get the feeling that you consider
     yourself a country cousin of the ACM publications and of SEN.  Wrong!
     You're not inferior, you are just editing in a different medium and as 
     you put your mind to the task, I hope you come to take them with a
     larger grain of salt.  In particular, 

      !  Chinese computer builder electrocuted by his smart computer after he 
         built a newer one. "Jealous Computer Zaps its Creator"!  (SEN 10 1)

     was a National Inquirer-style joke.  The editor of SEN should not have
     reprinted it, and you probably should not have included it in a
     serious list of computer-related failures.
        [The editor of SEN has sometimes been known to indulge in levity.  
         In this case it appears that a Chinese engineer was indeed
         electrocuted -- and that is an interesting case of computer-related
         disaster.  On the other hand, if someone can believe that an
         AI automatic programming routine can write many million lines of
         correct code, then he might as well believe that a smart computer
         system could express jealousy and cause the electrocution!  
         Actually, Bob used "PEN" throughout rather than "SEN", but
        "Software Engineering Notes" was the only sensible interpretation
        I could come up with, so I changed it.  Do I have a "PEN" pal?  PGN]

  4. It seems to me that it is precisely in the area of serious hardware
     and software failures that RISKS should make its mark.  Directing
     itself to that topic, it fills a spot no existing list touches on
     directly, and treats a matter that concerns every computer
     professional who is earning a decent living.  Litigation about
     defective software design and programming malpractice will be the
     inevitable consequence of risks, and RISKS is the only place to
     discuss avoiding them.  Please consider focussing the list more closely
     on that subject.

        [Bob, Thanks for your comments.  I heartily agree on the importance
         of the last item.  But, I do not intend to generate all of the
         material for this forum, and can only smile when someone suggests
         that this forum is not what it should be.  I look forward to your
         help! PGN]

[End of Bob Carter's message and my interspersions.]

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
RISKS forum              [including An Air-Traffic Control Problem]
</A>
</H3>
<address>
Scott M. Rose 
&lt;<A HREF="mailto:rose@uw-bluechip.arpa">
rose@uw-bluechip.arpa
</A>&gt;
</address>
<i>
16 Aug 85 21:06:39 PDT (Fri)
</i><PRE>

I had kind of hoped that somebody would submit something on the recent problem
  in Aurora Illinois, whereby a computer cable was cut that brought
  information from RADAR sensors to the regional air traffic control center
  there.  Supposedly, the system was designed to be sufficiently redundant to
  handle such a failure gracefully, but this turned out not to be the case:
  there were several close calls as the system went up and down repeatedly.
  There was information about the problem in the New York Times and the
  Chicago Tribune, at least... but not in very good detail.

I wonder if the forum is the right format for such a group.  The problem is
  that one may find oneself reluctant to report on such an incident that was
  widely reported in the popular press, and was current, for fear that a dozen
  others have done the same.  Yet in this case, the apparent result is that
  NOBODY reported on it, and I think such an event ought not pass without
  note on this group.  I might propose something more like the info-nets 
  group, where postings are automatically forwarded to group members.  If
  problems arose, then the postings could be filtered by the moderator... say,
  on a daily basis?  Just an idea...

	-S Rose

               [Please don't feel reluctant to ask whether someone has
                reported an interesting event before you go to any 
                potentially duplicate effort.  We'd rather not miss out
                entirely.]

</PRE>
<A NAME="subj5"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj5.1">
 Risks in AI Diagnostic Aids
</A>
</H3>
<address>
&lt;<A HREF="mailto:    Smith@UDel-Dewey.ARPA">
    Smith@UDel-Dewey.ARPA
</A>&gt;
</address>
<i>
Sun, 18 Aug 85 12:23:25 EDT
</i><PRE>

   I would enjoy a discussion on the legal and ethical problems that have
come up with the creation of AI diagnostic aids for doctors.  Who takes the
blame if the advice of a program causes a wrong diagnosis?  The doctor (if
so, then who would use such a program!?!?), the program's author(s) (if so,
then who would write such a program!?!?), the publishers/distributors of the
program (if so, then who would market such a program!?!?), ....  These
nagging questions will have to be answered before anyone is going to make
general use of these programs
    I would be very interested in hearing what other people think about this 
question.  It seems to me that it would be a suitable one for this bboard.

		art smith
		(smith@UDel-Dewey.ARPA)

        ****************************************************
        ** Following are several items on the Strategic   **
        ** Defense Initiative and related subjects.       **
        ****************************************************

</PRE>
<A NAME="subj6"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj6.1">
WARNING !!                    [A Trojan Horse Bites Man]
</A>
</H3>
<address>
Don Malpass
&lt;<A HREF="mailto:malpass@ll-sst ">
malpass@ll-sst 
</A>&gt;
</address>
<i>
Thu, 15 Aug 85 11:05:48 edt
</i><PRE>

Today's Wall St. Journal contained the following article.  I think
it is of enough potential significance that I'll enter the whole thing.
In addition to the conclusions it states, it implies something about
good backup procedure discipline.
	In the hope this may save someone,
		Don Malpass

		******************************************
			(8/15/85 Wall St. Journal)
				ARF! ARF!
	Richard Streeter's bytes got bitten by an "Arf Arf," which isn't
a dog but a horse.
	Mr. Streeter, director of development in the engineering department
of CBS Inc. and home-computer buff, was browsing recently through the
offerings of Family Ledger, a computer bulletin board that can be used by
anybody with a computer and a telephone to swap advice, games or programs -
or to make mischief.  Mr. Streeter loaded into his computer a program that
was billed as enhancing his IBM program's graphics; instead it instantly wiped
out the 900 accounting, word processing and game programs he had stored in
his computer over the years.  All that was left was a taunt glowing back
at him from the screen: "Arf! Arf! Got You!"
"HACKERS" STRIKE AGAIN
	This latest form of computer vandalism - dubbed for obvious reasons
a Trojan Horse - is the work of the same kind of anonymous "hackers" who
get their kicks stealing sensitive data from government computers or invading
school computers to change grades.  But instead of stealing, Trojan Horses
just destroy all the data files in the computer.
	Trojan Horse creators are nearly impossible to catch - they usually
provide phony names and addresses with their programs - and the malevolent
programs often slip by bulletin-board operators.  But they are becoming a
real nuisance.  Several variations of the "Arf! Arf!" program have made
the rounds, including one that poses as a "super-directory" that
conveniently places computer files in alphabetical order.
	Operators have begun to take names and addresses of electronic
bulletin-board users so they can check their authenticity.  When a
computer vandal is uncovered, the word is passed to other operators.
Special testing programs also allow them to study the wording of
submitted programs and detect suspicious commands.
INTERFACER BEWARE
	But while Al Stone, the computer consultant who runs Long Island
based Family Ledger, has such a testing program, he says he didn't have time
to screen the "Arf! Arf!" that bit Mr. Streeter.  "Don't attempt to run
something unless you know its pedigree," he says.
	That's good advice, because the computer pranksters are getting more
clever - and nastier.  They are now creating even-more-insidious programs
that gradually eat away existing files as they are used.  Appropriately
enough, these new programs are known as "worms".

			(8/15/85 Wall St. Journal)
		******************************************

</PRE>
<A NAME="subj7"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj7.1">
Software engineering and SDI
</A>
</H3>
<address>
&lt;<A HREF="mailto:mooremj@EGLIN-VAX">
mooremj@EGLIN-VAX
</A>&gt;
</address>
<i>
Mon, 19 Aug 85 13:56:21 CDT
</i><PRE>

[FROM Soft-Eng Digest         Fri, 23 Aug 85       Volume 1 : Issue  31]

Dr. David Parnas has quite accurately pointed out some of the dangers inherent
in the software to be written for the Strategic Defense Initiative.  I must
take exception, however, to the following statement from the Boston Globe
story quoted in Volume 1, Issue 29, of this digest:

        "To imagine that Star Wars systems will work perfectly
         without testing is ridiculous.  A realistic test of the
         Strategic Defense Initiative would require a practice
         nuclear war.  Perfecting it would require a string of such wars."

There are currently many systems which cannot be fully tested.  One example
is the software used in our present defense early warning system.  Another
example, one with which I am personally familiar, is the Range Safety Command
Destruct system at Cape Canaveral Air Force Station.  This system provides
the commands necessary to destroy errant missiles which may threaten populated
areas; I wrote most of the software for the central computer in this system.
The system can never be fully tested in the sense implied above, for to do so
would involve the intentional destruction of a missile for testing purposes
only.  On the other hand, it must be reliable:  a false negative (failure to
destroy a missile which endangers a populated area) could cause the loss of
thousands of lives; a false positive (unintentional destruction of, say, a
Space Shuttle mission) is equally unthinkable.  There are many techniques
available to produce fault-tolerant, reliable software, just as there are for
hardware; the Range Safety system was designed by some of the best people at
NASA, the U. S. Air Force, and several contractors.  I do not claim that a 
failure of this system is "impossible", but the risk of a failure, in my
opinion, is acceptably low.

"But ANY risk is too great in Star Wars!"  

I knew someone would say that, and I can agree with this sentiment.  The only
alternative, then, is not to build it, because any system at all will involve
some risk (however small) of failure; and failure will, as Dr. Parnas has 
pointed out, lead to the Ultimate Disaster.  I believe that this is what Dr.
Parnas is hoping to accomplish:  persuading the authorities that the risk
is unacceptable.

It won't work.  Oh, perhaps it will in the short run; "Star Wars" may not 
be built now, or ever.  But sooner or later, some system will be given 
life-and-death authority over the entire planet, whether it is a space 
defense system, a launch-on-warning strategic defense system, or something 
else.  The readers of this digest are the present and future leaders in
the field of software engineering.  It is our responsibility to refine the
techniques now used and to develop new ones so that these systems WILL be
reliable.  I fear that some first-rate people may avoid working on such
systems because they are "impossible"; this will result in second-rate
people working on them, which is something we cannot afford.  This is NOT 
a slur at Dr. Parnas.  He has performed an invaluable service by bringing
the public's attention to the problem.  Now it is up to us to solve that
problem.

I apologize for the length of this message.  The above views are strictly
my own, and do not represent my employer or any government agency.

                                      Martin J. Moore
                                      Senior Software Analyst
                                      RCA Armament Test Project
                                      P. O. Box 1446
                                      Eglin AFB, Florida  32542
                             ARPAnet: MOOREMJ@EGLIN-VAX.ARPA

</PRE>
<HR><H3><A NAME="subj7.2">
Trip Report: Computing in Support of Battle Management
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.ARPA ">
horning@decwrl.ARPA 
</A>&gt;
</address>
<i>
21 Aug 1985 1243-PDT (Wednesday)
</i><PRE>

[This is a relatively long report, because I haven't been able to come
up with a simple characterization of an interesting and informative day.]

Background:

On August 13 I travelled to Marina del Rey to spend a day with the
U.S. Department of Defense Strategic Defense Initiative Organization
Panel on Computing in Support of Battle Management (DoD SDIO PCSBM).

SDI is the "Star Wars" antiballistic missile system; PCSBM is the panel
Dave Parnas resigned from.

I wasn't really sure what to expect. As I told Richard Lau when he
invited me to spend a day with them, I'd read what Parnas wrote, but
hadn't seen the other side.  He replied that the other side hadn't been
written yet. "Come on down and talk to us. The one thing that's certain
is that what we do will have an impact, whether for good or for ill."

Summary:

The good news is that the panel members are not crazies; they aren't
charlatans; they aren't fools. If a solution to SDI's Battle Management
Software problem can be purchased for five billion dollars (or even
ten), they'll probably find it; if not, they'll eventually recognize
that it can't.

The bad news is that they realize they don't have the expertise to
solve the problem themselves, or even to direct its solution. They
accept Dave Parnas's assessment that the software contemplated in the
"Fletcher Report" cannot be produced by present techniques, and that
AI, Automatic Programming, and Program Verification put together won't
generate a solution. Thus their invitations to people such as myself,
Bob Balzer, and Vic Vyssotsky to come discuss our views of the state
and prospects of software technology.

I think a fair summary of the panel's current position is that they are
not yet convinced that the problem cannot be modified to make it
soluble. ("Suppose we let software concerns drive the system
architecture? After all, it is one of the two key technologies.") They
are trying to decide what must be done to provide the information that
would be needed in the early 1990s to make a decision about deploying a
system in the late 1990s.

Assumptions:

Throughout the day's discussions, there were repeated disconnects
between their going-in assumptions and mine. In fairness, they tried to
understand the sources of the differences, to identify their
assumptions, and to get me to identify and justify mine.

* Big budgets: I've never come so close to a trillion-dollar ($10**12)
project before, even in the planning stage. ("The satellite launches
alone will cost upwards of $500 billion, so there's not much point in
scrimping elsewhere.")

- I was unprepared for the intensity of their belief that any technical
problem could be steamrollered with a budget that size.

- They seemed surprised that I believed that progress in software
research is now largely limited by the supply of first-rate people, and
that the short-term effect of injecting vastly more dollars would be to
slow things down by diverting researchers to administer them.

* Big software: They were surprised by my observation that for every
order of magnitude in software size (measured by almost any interesting
metric) a new set of problems seems to dominate.

- This implies that no collection of experiments with million-line
"prototypes" can ensure success in building a ten-million-line system.
I argued that the only prototype from which they would learn much would
be a full-scale, fully-functional one. Such a prototype would also
reveal surprising consequences of the specification.
(The FIFTEENTH LAW OF SYSTEMANTICS: A complex system that works is
invariably found to have evolved from a simple system that works.)

- Only Chuck Seitz and Bijoy Chatterjee seemed to fully appreciate why
software doesn't just "scale up" (doubtless because of their hardware
design experience). It is not a "product" that can be produced at some
rate, but the design of a family of computations; it is the
computations that can be easily scaled.

* Reliability: I had assumed that one of the reasons Battle Management
software would be more difficult than commercial software was its
more stringent reliability requirement. They assume that this is one of
the parameters that can be varied to make the problem easier.

Discussion:

The Panel is still in the process of drafting its report on Battle
Management Systems. Although they take the need to produce such a
system as a given, almost anything else is negotiable. (In particular,
they do not accept the "Fletcher Report" as anything more than a
springboard for discussion, and criticize current work for following it
too slavishly. The work at Rome Air Development Center--which produced
estimates like 24.61 megalines of code, 18.28 gigaflops per weapons
platform--was mentioned contemptuously, while the Army work at Huntsville
was considered beneath contempt.)

The following comments are included merely to indicate the range and
diversity of opinions expressed. They are certainly not official
positions of the panel, and--after being filtered though my
understanding and memory--may not even be what the speaker intended.
Many of the inconsistencies are real; the panel is working to identify
and resolve them.

- The problem may be easier than a banking system, because: each
autonomous unit can be almost stateless; a simple kernel can monitor
the system and reboot whenever a problem is detected; there are fewer
people in the loop; more hardware overcapacity can be included.

- If you lose a state it will take only a few moments to build a new
state. (Tracks that are more than 30 minutes old are not interesting.)

- Certain kinds of reliability aren't needed, because: a real battle
would last only a few minutes; the system would be used at most once;
with enough redundancy it's OK for individual weapons to fail; the
system doesn't have to actually work, just be a credible deterrent; the
system wouldn't control nuclear weapons--unless the Teller "pop up"
scheme is adopted; the lasers won't penetrate the atmosphere, so even
if the system runs amok, the worst it could do would be to intercept some
innocent launch or satellite.

- We could debug the software by putting it in orbit five or ten years
before the weapons are deployed, and observing it. We wouldn't even
have to deploy them until the system was sufficiently reliable. Yes,
but this would not test the important modes of the system.

- Dependence on communication can be minimized by distributing
authority: each platform can act on its own, and treat all
communication as hints.

- With a multi-level fault-tolerance scheme, each platform can monitor
the state of its neighbors, and reboot or download any that seem to be
malfunctioning.

- In fifteen years we can put 200 gigaflops in orbit in a teacup. Well,
make that a breadbox.

- Space qualification is difficult and slow. Don't count on
microprocessors of more than a few mips in orbit. Well, maybe we could
use fifty of them.

- How much can we speed up computations by adding processors? With
general-purpose processors, probably not much. How much should we rely
on special-purpose space-qualified processors?

- Processor cost is negligible. No, it isn't. Compared to software
costs or total system costs it is. No, it isn't, you are
underestimating the costs of space qualification.

- 14 MeV neutron flux cannot effectively be shielded against and
represents a fundamental limitation on the switching-speed, power
product. Maybe we should put all the computationally intensive
components under a mountain. But that increases the dependence on
communication.

- Maybe we could reduce failure rates by putting the software in
read-only memory. No, that makes software maintenance incredibly
difficult.

- Flaccidware. It's software now, but it can become hardware when
necessary.

- Is hardware less prone to failure if switched off? Maybe we could
have large parts of the system on standby until the system goes on
alert. Unfortunately, the dominant hardware failure modes continue even
with power off.

- The software structure must accommodate changes in virtually all
component technologies (weapons, sensors, targets, communication,
computer hardware) during and following deployment. But we don't have
much technology for managing rapid massive changes in large systems.

Relation to Critics:

Dave Parnas's criticisms have obviously been a matter of considerable
concern for the panel. Chuck Seitz and Dick Lau both said explicitly
that they wouldn't be satisfied making a recommendation that failed to
address the issues Dave and other critics have raised. Chuck also
distributed copies of "The Star Wars Computer System" by Greg Nelson
and David Redell, commending it to the attention of the panel as
"Finally, some well-written and intelligent criticism."

Richard Lipton had a somewhat different attitude: How can they say that
what we are going to propose is impossible, when even we don't know
yet what we're going to propose? And why don't software researchers
show more imagination? When a few billion dollars are dangled in front
of them, the physicists will promise to improve laser output by nine
decimal orders of magnitude; computer scientists won't even promise one
or two for software production.

The minutes of the August 12 meeting contain the following points:

- Critics represent an unpaid "red team" and serve a useful function in
identifying weak points in the program.

- Critiques should be acknowledged, and areas identified as to how we
can work to overcome these problem areas.

- Throughout our discussions, and in our report we should reflect the
fact that we have accepted a degree of uncertainty as an inherent part
of the strategic defense system.

- How to get the system that is desired? This basic problem goes back
to defining requirements--a difficult task when one is not quite sure
what one wants and what has to be done.

Prospects:

After all of this, what do I think of the prospects for SDI Battle
Management Software? I certainly would not be willing to take on
responsibility for producing it. On the other hand, I cannot say flatly
that no piece of software can be deployed in the 1990s to control a
ballistic missile defense system. It all depends on how much
functionality, coordination, and reliability are demanded of it.

Unfortunately, as with most other computer systems, the dimension in
Gwhich the major sacrifice will probably be made is reliability. The
reality of the situation is that reliability is less visible before
deployment than other system parameters and can be lost by default. It
is also probably the hardest to remedy post facto. Of course, with a
system intended to be used "at most once," there may be no one around
to care whether or not it functioned reliably.

Despite these misgivings, I am glad that this panel is taking seriously
its charter to develop the information on which a deployment decision
could responsibly be based.

Jim H.

</PRE>
<HR><H3><A NAME="subj7.3">
Forum on Risks to the Public in Computer Systems 
</A>
</H3>
<address>
John McCarthy 
&lt;<A HREF="mailto:JMC@SU-AI.ARPA">
JMC@SU-AI.ARPA
</A>&gt;
</address>
<i>
13 Aug 85  1521 PDT
</i><PRE>

[An earlier SU-bboard message that prompted the following sequence of 
replies seemed like total gibberish, so I have omitted it.  PGN]


                              [but not To: RISKS...]

I was taking [as?] my model Petr Beckmann's book "The Health Hazards of not
Going Nuclear" in which he contrasts the slight risks of nuclear energy with
the very large number of deaths resulting from conventional energy sources
from, e.g. mining and air pollution.  It seemed to me that your announcement
was similarly one sided in its consideration in risks of on-line systems and
ignoring the possibility of risks from their non-use.  I won't be specific
at present, but if you or anyone else wants to make the claim that there are
no such risks, I'm willing to place a substantial bet.

   [Clearly both inaction and non-use can be risky.  The first two items at
    the beginning of this issue (Vol 1 no 2) -- the lobstermen and the Union
    Carbide case -- involved inaction.  PGN]

</PRE>
<HR><H3><A NAME="subj7.4">
IJCAI as a forum   
</A>
</H3>
<address>
John McCarthy 
&lt;<A HREF="mailto:JMC@SU-AI.ARPA">
JMC@SU-AI.ARPA
</A>&gt;
</address>
<i>
14 Aug 85  1635 PDT
</i><PRE>

	Like Chris Stuart, I have also contemplated using IJCAI as a forum.
My issue concerns the computer scientists who have claimed, in one case "for
fundamental computer science reasons" that the computer programs required
for the Strategic Defense Initiative (Star Wars) are impossible to write and
verify without having a series of nuclear wars for practice.  Much of the
press (both Science magazine and the New York Times) have assumed (in my
opinion correctly) that these people are speaking, not merely as
individuals, but in the name of computer science itself.  The phrase "for
fundamental computer science reasons" was used by one of the computer
scientist opponents.

	In my opinion these people are claiming an authority they do not
possess.  There is no accepted body of computer science principles that
permits concluding that some particular program that is mathematically
possible cannot be written and debugged.  To put it more strongly, I don't
believe that there is even one published paper purporting to establish
such principles.  However, I am not familiar with the literature on
software engineering.

	I think they have allowed themselves to be tempted into
exaggerating their authority in order to support the anti-SDI cause,
which they support for other reasons.

	I have two opportunities to counter them.  First, I'm giving
a speech in connection with an award I'm receiving.  Since I didn't
have to submit a paper, I was given carte blanche.  Second, I have
been asked by the local arrangements people to hold a press conference.
I ask for advice on whether I should use either of these opportunities.
I can probably even arrange for some journalist to ask my opinion on
the Star Wars debugging issue, so I wouldn't have to raise the issue
myself.  Indeed since my position is increasingly public, I might
be asked anyway.

	To make things clear, I have no position on the feasibility
of SDI, although I hope it can be made to work.  Since even the
physical principles that will be proposed for the SDI system haven't
been determined, it isn't possible to determine what kind of programs
will be required and to assess how hard they will be to write
and verify.  Moreover, it may be possible to develop new techniques
involving both simulation and theorem proving relevant to verifying
such a program.  My sole present point is that no-one can claim
the authority of computer science for asserting that the task
is impossible or impractical.

	There is even potential relevance to AI, since some of the
opponents of SDI, and very likely some of the proponents, have suggested
that AI techniques might be used.

	I look forward to the advice of BBOARD contributors.

</PRE>
<HR><H3><A NAME="subj7.5">
Verifying SDI software
</A>
</H3>
<address>
Peter Karp 
&lt;<A HREF="mailto:KARP@SUMEX-AIM.ARPA">
KARP@SUMEX-AIM.ARPA
</A>&gt;
</address>
<i>
Thu 15 Aug 85 00:17:09-PDT
</i><PRE>

John McCarthy: I argue CPSR's approach is reasonable as follows:

1) I assume you admit that bugs in the SDI software would be very
   bad since this could quite conceivably leave our cities open
   Soviet attack.

2) You concede software verification theory does not permit proof
   of correctness of such complex programs.  I concede this same
   theory does not show such proofs are impossible.

3) The question to responsible computer professionals then becomes:
   From your experience in developing and debugging complex computer
   systems, how likely do you believe it is that currently possible
   efforts could produce error-free software, or even software whose
   reliability is acceptable given the risks in (1) ?

Clearly answering (3) requires subjective judgements, but computer
professionals are among the best people to ask to make such 
judgements given their expertise.  

I think it would be rather amusing if you told the press what you
told bboard: that you "hope they can get it to work".


</PRE>
<HR><H3><A NAME="subj7.6">
sdi 
</A>
</H3>
<address>
John McCarthy 
&lt;<A HREF="mailto:JMC@SU-AI.ARPA">
JMC@SU-AI.ARPA
</A>&gt;
</address>
<i>
16 Aug 85  2200 PDT
</i><PRE>

I thank those who advised me on whether to say something about the
SDI controversy in my lecture or at the press conference.  I don't
presently intend to say anything about it in my lecture.  Mainly
this is because thinking about what to say about a public issue
would interfere with thinking about AI.  I may say something or
distribute a statement at the press conference.

I am not sure I understand the views of those who claim the computer
part of SDI is infeasible.  Namely, do they hope it won't work?  If
so, why?  My reactionary mind thinks up hypotheses like the following.
It's really just partisanship.  They have been against U.S. policy
in many areas including defense, that they automatically oppose any
initiative and then look for arguments.

</PRE>
<HR><H3><A NAME="subj7.7">
Re:  [John McCarthy &lt;JMC@SU-AI.ARPA&gt;: IJCAI as a forum   ]
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:vax-populi!dparnas@nrl-css ">
vax-populi!dparnas@nrl-css 
</A>&gt;
</address>
<i>
Thu, 15 Aug 85 13:01:46 pdt
</i><PRE>

McCarthy is making a classic error of criticizing something that 
he has not read.  I have not argued that any program cannot be written 
and debugged.  I argue a much weaker and safer position, that we cannot
know that the program has been debugged.  There are "fundamental computer
science reasons" for that, they have to do with the size of the smallest
representation of the mathematical functions that describe the behaviour
of computer software and our inability to know that the specifications
are correct.  

Dave


Date: Thu, 15 Aug 85 13:14:22 pdt
From: vax-populi!dparnas@nrl-css (Dave Parnas)
To: neumann@SRI-CSL.ARPA
Subject: Copy of cover letter to Prof. John McCarthy

Dear Dr. M

	A friend of mine, whose principal weakness is reading the junk mail 
posting on bulletin boards sent me a copy of your posting with regard to 
SDI.

	It is in general a foolish error to criticize a paper that you have
not read on the basis of press reports of it.

	Nobody has, in fact, claimed that any given program cannot be
written and "debugged" (whatever that means).  The claim is much weaker,
that we cannot know with confidence that the program does meet its
specification and that the specification is the right one.  There is both
theoretical (in the form of arguments about the minimal representation of
non-continuous functions) and empirical evidence to support that claim.  The
fact that you do not read the literature on software engineering does not
give you the authority to say that there are no papers supporting such a
claim.

	As I would hate to see anyone, whether he be computer scientist or AI
specialist, argue on the basis of ignorance, I am enclosing ...


</PRE>
<HR><H3><A NAME="subj7.8">
Speaking Out On SDI
</A>
</H3>
<address>
Gary Martins 
&lt;<A HREF="mailto:GARY@SRI-CSLA.ARPA">
GARY@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Thu 15 Aug 85 18:50:46-PDT
</i><PRE>
To: jmc@SU-AI.ARPA

Dear Dr. McC -

In response to your BB announcement:

1.  Given that IJCAI is by and large a forum for hucksters and crackpots of
various types, it is probably a poor choice of venue for the delivery of
thoughts which you'd like taken seriously by serious folks.

2. Ditto, for tying your pro-SDI arguments in with "AI"; it can only lower
the general credibility of what you have to say.

3.  You are certainly right that no-one can now prove that the creation of
effective SDI software is mathematically impossible, and that part of your
argument is beyond reproach, even if rather trivial.  However, you then
slip into the use of the word "impractical", which is a very different
thing, with entirely different epistemological status.  On this point,
you may well be entirely wrong -- it is an empirical matter, of course.


I take no personal stand on the desirability or otherwise of SDI, but
as a citizen I have a vested interest in seeing some discussions of
the subject that are not too heavily tainted by personal bias and
special pleading.


Gary R. Martins
Intelligent Software Inc.

 ------------------------------

       International Conference on Software Engineering
              28-30 August 1985, London UK
         Feasibility of Software for Strategic Defense
                    Panel Discussion
             30 August 1985, 1:30 - 3:00 PM

                       Panelists:       
        Frederick P. Brooks III, University of North Carolina
        David Parnas, University of Victoria
           Moderator: Manny Lehman, Imperial College

This panel will discuss the feasibility of building the software for the
Strategic Defense System ('Star Wars') so that that software could be
adequately trusted to satisfy all of the critical performance goals.  The
panel will focus strictly on the software engineering problems in building
strategic defense systems, considering such issues as the reliability of the
software and the manageability of the development.

    [This should be a very exciting discussion.  Fred has extensive hardware,
     software, and management experience from his IBM OS years.  David's
     8 position papers have been widely discussed -- and will appear in the
     September American Scientist.  We hope to be able to report on this
     panel later (or read about it in ARMS-D???).   Perhaps some of you
     will be there and contribute your impressions.  PGN]

</PRE>
<A NAME="subj8"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj8.1">

</A>
</H3>
<address>
Tom Parmenter 
&lt;<A HREF="mailto:parmenter@SCRC-STONY-BROOK.ARPA">
parmenter@SCRC-STONY-BROOK.ARPA
</A>&gt;
</address>
<i>
Mon, 15 Jul 85 11:05 EDT
</i><PRE>
From an article in Technology Review by Herbert Lin on the difficulty
(impossibility) of developing software for the Star Wars (Strategic
Defense Initiative) system:

  Are there alternatives to conventional software development?  Some defense
  planners think so.  Major Simon Worden of the SDI office has said that

    "A human programmer can't do this.  We're going to be developing new
     artificial intelligence systems to write the software.  Of course, 
     you have to debug any program.  That would have to be AI too."

</PRE>
<A NAME="subj9"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj9.1">

</A>
</H3>
<address>
Latitudinarian Lobster
&lt;<A HREF="mailto:uwmacc!myers@wisc-rsch.arpa ">
uwmacc!myers@wisc-rsch.arpa 
</A>&gt;
</address>
<i>
Wed, 14 Aug 85 18:08:57 cdt
</i><PRE>
To: risks@sri-csl.arpa 
Subject: CPSR-Madison paper for an issue of risks?

The following may be reproduced in any form, as long as the text and credits
remain unmodified.  It is a paper especially suited to those who don't already
know a lot about computing.  Please mail comments or corrections to:

Jeff Myers                              [Something was lost here...]
University of Wisconsin-Madison		reflect the views of any other
Madison Academic Computing Center	person or group at UW-Madison.
1210 West Dayton Street
Madison, WI  53706
ARPA: uwmacc!myers@wisc-rsch.ARPA
UUCP: ..!{harvard,ucbvax,allegra,heurikon,ihnp4,seismo}!uwvax!uwmacc!myers
BitNet: MYERS at MACCWISC

 -------------------------------------------------------------------------------

                   COMPUTER UNRELIABILITY AND NUCLEAR WAR

     Larry Travis, Ph.D., Professor of Computer Sciences, UW-Madison 
	      Daniel Stock, M.S., Computer Sciences, UW-Madison
	     Michael Scott, Ph.D., Computer Sciences, UW-Madison
	    Jeffrey D. Myers, M.S., Computer Sciences, UW-Madison
	      James Greuel, M.S., Computer Sciences, UW-Madison
James Goodman, Ph.D., Assistant Professor of Computer Sciences, UW-Madison
     Robin Cooper, Ph.D., Associate Professor of Linguistics, UW-Madison
	     Greg Brewster, M.S., Computer Sciences, UW-Madison

                               Madison Chapter
               Computer Professionals for Social Responsibility
                                  June 1984

           Originally prepared for a workshop at a symposium on the
                     Medical Consequences of Nuclear War
                         Madison, WI, 15 October 1983

  [The paper is much too long to include in this forum, but can be 
  obtained from Jeff Myers at the above net addresses, or FTPed from
  RISKS@SRI-CSL:&lt;RISKS&gt;MADISON.PAPER.  The section headings are as follows:

    1.  Computer Use in the Military Today, James Greuel, Greg Brewster
    2.  Causes of Unreliability, Daniel Stock, Michael Scott
    3.  Artificial Intelligence and the Military, Robin Cooper
    4.  Implications, Larry Travis, James Goodman

  ]

</PRE>
<A NAME="subj10"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj10.1">

</A>
</H3>
<address>
Clifford Johnson 
&lt;<A HREF="mailto:GA.CJJ@Forsythe">
GA.CJJ@Forsythe
</A>&gt;
</address>
<i>
Wed, 21 Aug 85 17:46:55 PDT
</i><PRE>
Subject:  @=  Can a computer declare war?

****************** CAN A COMPUTER DECLARE WAR?

Below is the transcript of a court hearing in which it is was argued by the
Plaintiff that nuclear launch on warning capability (LOWC, pronounced
lou-see) unconstitutionally delegates Congress's mandated power to declare
war.

The Plaintiff is a Londoner and computer professional motivated to act by
the deployment of Cruise missiles in his hometown.  With the advice and
endorsement of Computer Professionals for Social Responsibility, on February
29, 1984, he filed a complaint in propria persona against Secretary of
Defense Caspar Weinberger seeking a declaration that peacetime LOWC is
unconstitutional.  The first count is presented in full below; a second
count alleges a violation of Article 2, Part 3 of the United Nations Charter
which binds the United States to settle peacetime disputes "in such a manner
that international peace and security, and justice, are not endangered":

1.  JURISDICTION:  The first count arises under the Constitution of the
United States at Article I, Section 8, Clause 11, which provides that "The
Congress shall have Power ... To declare War"; and at Article II, Section 2,
Clause 1, which provides that "The President shall be Commander in Chief" of
the Armed Forces.

2.  Herein, "launch-on-warning-capability" is defined to be any set of
procedures whereby the retaliatory launching of non-recoverable nuclear
missiles may occur both in response to an electronically generated warning
of attacking missiles and prior to the conclusively confirmed commencement
of actual hostilities with any State presumed responsible for said attack.

3.  The peacetime implementation of launch-on-warning-capability is now
presumed constitutional, and its execution by Defendant and Defendant's
appointed successors is openly threatened and certainly possible.

4.  Launch-on-warning-capability is now subject to a response time so short
as to preclude the intercession of competent judgment by the President or by
his agents.

5.  The essentially autonomous character of launch-on-warning-capability
gives rise to a substantial probability of accidental nuclear war due to
computer-related error.

6.  Said probability substantially surrenders both the power of Congress to
declare war and the ability of the President to command the Armed Forces,
and launch-on-warning-capability is therefore doubly repugnant to the
Constitution.

7.  The life and property of Plaintiff are gravely jeopardized by the threat
of implementation of launch-on-warning-capability.

WHEREFORE, Plaintiff prays this court declare peacetime
launch-on-warning-capability unconstitutional.

****************** THE HEARING IN THE COURT OF APPEALS FOLLOWS 

[in the original message, and is too lengthy to include here.  I presume you
will find it in ARMS-D -- see my interpolation into the note from Bob Carter
above.  Otherwise, you can FTP it from SRI-CSL:&lt;RISKS&gt;JOHNSON.HEARING.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-12</DOCNO>
<DOCOLDNO>IA012-000128-B042-72</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.3.html 128.240.150.127 19970217000223 text/html 9585
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:00:47 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 3</TITLE>
<LINK REL="Prev" HREF="/Risks/1.02.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.04.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 3</H1>
<H2>       Friday, 30 Aug 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
          (Contributions to RISKS@SRI-CSL.ARPA)
<BR>
          (Requests to RISKS-Request@SRI-CSL.ARPA)
<BR>
          (This vol/no can be FTPed from SRI-CSL:&lt;RISKS&gt;RISKS-1.3)
<BR>
          (Issue n of vol 1 is in SRI-CSL:&lt;RISKS&gt;RISKS-1.n)      
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Miscellaneous comments on V1#2 
</A>
<DD>
<A HREF="#subj1.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer/hardship list 
</A>
<DD>
<A HREF="#subj2.1">
Jerome Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Medical KBES --  Some AI systems may need FDA approval
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Health hazards of CRT use 
</A>
<DD>
<A HREF="#subj4.1">
Robin Cooper
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">

</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@purdue-ecn.ARPA ">
davy@purdue-ecn.ARPA 
</A>&gt;
</address>
<i>
Thu, 29 Aug 85 21:22:44 EST
</i><PRE>
Subject: Miscellaneous comments on V1#2

Just some miscellaneous comments on some of the things in RISKS V1#2.
Hope this isn't too long.

1) Fishermen.  This sounds like a crock to me.  I wonder whether the
broken buoy or the fact that the storm was not predicted was the deciding
factor in the case.  Since the NWS/NOAA is providing a service, which
nobody is *required* to use, I can't understand how they can be sued for
not predicting a storm.  What would happen if they predicted a storm which
never showed up?  Could all the fishermen who stayed home sue for their
lost profits?  I can see it now....  "Cloudy Thursday, rain Friday -- use
this information at your own risk."

2) Union Carbide.  I always wonder in cases like this whether the plant is
actually having more accidents than usual, or if because of Bhopal we're
just hearing about it more because the press has a new victim to pick on.
The number of accidents at that plant is disgraceful.  Does anyone think
the government will shut it down?

3) Bob Carter's comments.  I think I agree with PGN on these... I would
prefer to see RISKS cover more or less anything related to computer
"hazards", rather than centering on one or two things.  There are plenty
of other lists which already take certain parts of this (e.g. SOFT-ENG for
"who's responsible" type stuff, ARMS-D for SDI).  I also like the SEN
quotes -- I don't personally read SEN, and even if some of the stuff is
dumb (computer kills scientist), overall I think the brief summary PGN
provided in V1 #1 gives a nice broad range of topics to discuss.

4) Medical programs.  I'm not sure I trust these fully yet.  I'd have no
qualms about my doctor using one to *suggest* things to him, but I would
draw the line at his accepting the program's diagnosis unless he could
verify on his own that it was correct.  For example, a heart specialist
interpreting a heart-diagnosis program's output would be good; a general
practicioner's taking it as gospel would not be good.  We need to make sure
the doctor is capable of knowing when the program is wrong.  (I saw a
comment about MYCIN once - "if you brought MYCIN a bicycle with a flat
tire, it would try like hell to find you an antibiotic.")

5) SDI.  I'm going to leave this for the experts.  I personally lean
towards Parnas's "side", but I don't know enough about it.  I do
like reading the comments on it though.  (BTW, for those of you who
haven't yet read Herb Lin's paper, it's excellent.)

Great list so far... keep it coming.  As a (possibly) new topic, did
anyone go to this AI show in San Diego (?) or wherever?  I saw a blurb on
it somewhere... how about a review of what the current toys are and what
risks they may take?  I remember seeing something about a program to
interpret the dials and gauges of a nuclear power plant....

--Dave Curry
davy@purdue-ecn

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">

</A>
</H3>
<address>
Rosenberg Jerome
&lt;<A HREF="mailto:jerome@wisc-rsch.arpa ">
jerome@wisc-rsch.arpa 
</A>&gt;
</address>
<i>
Thu, 29 Aug 85 14:00:58 cdt
</i><PRE>
Subject: Computer/hardship list

    Peter: One basis for a focussed discussion of risks would be to try to
establish a list of those computer systems whose failure would cause great
hardship --economic, political, social --to a significant number of our
citizens. For example, the failure of our computer-controlled electric
power grid or the failure of the Reserve's check clearance system.
              Your readers/participants could be asked to suggest the systems 
to be included on the list. Your forum could then discuss probabilies
of failure,costs of failures vs failure time, etc. etc..    
                          Jerry

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">

</A>
</H3>
<address>
Ave decus virginum!
&lt;<A HREF="mailto:goun%cadlac.DEC@decwrl.ARPA  ">
goun%cadlac.DEC@decwrl.ARPA  
</A>&gt;
</address>
<i>
Friday, 30 Aug 1985 05:37:48-PDT
</i><PRE>
Subject: Medical KBES

            Some AI systems may need FDA approval

    Expert systems come within the FDA ambit to the extent that
    they supplement doctor's work, according to Richard Beutal, a
    Washington D.C. attorney specializing in the legal aspects of
    technology. 

    An expert system may be defined as a computer program that
    embodies the expertise of one or more human experts in some
    domain and applies this knowledge to provide inferences and
    guidance to a user. some of the earliest and most
    sophisticated systems were developed for medical diagnosis:
    MCYIN, EMCYIN, CADUCEUS AND ATTENDING. [There are several
    more in use in Japan. --mjt] 

    Beutal called attention to proposed FDA regulations that, if
    implemented, would require medical expert systems to obtain
    FDA pre-marketing approval. Given that FDA approval for what
    are class 3 devices could take up to 10 years and that
    reclassifying such devices can take almost as long, these FDA
    regulations would virtually cause investment to dry up. 
      {Government Computer News Aug 16, 1985}

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">

</A>
</H3>
<address>
Robin Cooper
&lt;<A HREF="mailto:cooper@wisc-ai.arpa ">
cooper@wisc-ai.arpa 
</A>&gt;
</address>
<i>
Thu, 29 Aug 85 10:35:20 cdt
</i><PRE>
Subject: health hazards of CRT use

With respect to the introduction of the topic of the health hazards of
using video terminals, I would be particularly interested in seeing
discussion of risks to pregnant women and their unborn children. Both
Sweden and Canada have apparently introduced legislation which gives
pregnant women the right to change job assignments, whereas the
official US line seems to be that there is not sufficient risk to
warrant this. 

Robin Cooper

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-13</DOCNO>
<DOCOLDNO>IA012-000128-B042-94</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.4.html 128.240.150.127 19970217000237 text/html 11204
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:01:09 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 4</TITLE>
<LINK REL="Prev" HREF="/Risks/1.03.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.05.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 4</H1>
<H2>       Monday, 2 Sept 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
          (Contributions to RISKS@SRI-CSL.ARPA)
<BR>
          (Requests to RISKS-Request@SRI-CSL.ARPA)
<BR>
          (Issue n of vol 1 is in SRI-CSL:&lt;RISKS&gt;RISKS-1.n)      
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  The Case of the Broken Buoy 
</A>
<DD>
<A HREF="#subj1.1">
Matt Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Inaction; Buoys will be buoys; KAL 007; Malpractice 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Health Hazards of CRT Use 
</A>
<DD>
<A HREF="#subj3.1">
Brint Cooper
</A><br>
<A HREF="#subj3.2">
 Robin Cooper
</A><br>
<A HREF="#subj3.3">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Medical Software 
</A>
<DD>
<A HREF="#subj4.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Rolm's Hawk-32 
</A>
<DD>
<A HREF="#subj5.1">
Doug Bryan
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">
Inaction; Buoys will be buoys; KAL 007; Malpractice
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Mon 2 Sep 85 14:05:15-PDT
</i><PRE>
To: RISKS@SRI-CSLA.ARPA

The issue of the lobstermen indeed rested on the negligence of not repairing
the buoy.  (As noted in RISKS-1.2, the weather buoy went unrepaired for
three months.)  

Negligence and inaction in the presence of informed knowledge are likely to
be the source of more lawsuits in the future.  For example, the NY Times of
1 September 85 had an article by Richard Witkin on KAL 007.

  Evidence introduced in lawsuits filed in connection with the Soviet downing
  of the Korean Air Lines Flight 007 suggests that American radar operators
  knew hours beforehand that the jetliner was off course and heading into
  Soviet airspace.

  The words, "We should warn him", presumably referring to the plane's pilot,
  were heard at the Government's civil air-traffic control station in Alaska
  as the Boeing 747 strayed off course toward its fatal encounter with a
  Soviet fighter plane two years ago today, according to the documents.
  
  The documents were submitted Friday as evidence in damage suits filed
  against the United States Government by relatives of the 269 people who
  died in the incident.

Medical malpractice suits have been on the upswing, and doctors are taking
extraordinary measures to compensate -- such as higher prices and otherwise
unnecessary tests and drugs.  But the question of what constitutes
computer-related malpractice is likely to emerge as a very sticky one, e.g.,
faulty computer system design, life-critical application programming, and
sloppy computer operation.  And what about a debugger or maintainer who
notices something fishy but does not carry through?  A remarkable case of a
casual observer playing a significant role took place on 1 Sept 85 when a
passenger on People Express Flight 183 from Dulles to Newark noticed minutes
after take-off that a cowling was missing on one of the engines.  (The plane
returned to Dulles.)  Imagine a lawsuit against a company, which in turn
sues the programmer.  The potential for legal confusion relating to computer
systems is really quite awesome, and the confusion has just begun.  Suppose
the windshear-warning system is finally installed (with the 31 May 84
near-disaster on take-off of a UA 727 and the recent crash providing an
impetus), and suppose that program has a bug?  Suppose the computer is not
working on landing?  There are some very serious questions that must be
raised.  The incidence of high-award law suits elsewhere is likely to
provide a strong forcing function.

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">

</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Fri, 30 Aug 85 21:56:09 EDT
</i><PRE>
cc:       risks@sri-csl.ARPA
Subject:  Re:  health hazards of CRT use

To balance this discussion, we need to include risks to pregnant women
and their born and unborn children of television sets that run 18 hours
a day in the home.  

Keep in mind:  X-radiation is generally produced by the very high
voltages traditionally used in color television sets and composite-video
color monitors.  Many of the monochrome monitors need no such voltages
and, so, produce no such radiation.  

Since most folks are now buying color TVs for their homes, we need to
examine that aspect of safety as well, especially since many of them are
used as monitors for home computers and video games.

Brint Cooper

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">

</A>
</H3>
<address>
Robin Cooper
&lt;<A HREF="mailto:cooper@wisc-ai.arpa ">
cooper@wisc-ai.arpa 
</A>&gt;
</address>
<i>
Sun, 1 Sep 85 12:13:49 cdt
</i><PRE>
Cc: risks@sri-csl.ARPA
Subject: Re:  health hazards of CRT use

Yes, that seems right, though I wonder what the facts are concerning
how close one sits to the device. People spend more time a few feet
away from their terminals than their TVs.

Robin Cooper

</PRE>
<HR><H3><A NAME="subj3.2">
Re:  health hazards of CRT use
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Mon 2 Sep 85 21:10:33-PDT
</i><PRE>
To: RISKS@SRI-CSLA.ARPA

There is also discussion in the literature on physical and psychological
problems resulting from sitting in front of your terminal for hours, most
notably back and neck problems, tension, stress, anxiety, and subsequent
depression.  This forum is not really the place to discuss another relevant
aspect of the problem, but let me just mention it anyway and then discourage
further commentary on it:  the standard American junk-food diet of coffee,
colas, and caffeine generally, orange juice, sugar, chocolate (containing
both sugar and caffeine), refined white flour, fried foods, and so on, is
now being linked with making many of those problems worse.

</PRE>
<HR><H3><A NAME="subj3.3">

</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Fri, 30 Aug 85 22:00:55 EDT
</i><PRE>
cc:       risks@SRI-CSL.ARPA
Subject:  Medical Software

Actually, culpability for mistakes caused by medical diagnosis software
could be placed with the same person who is responsible for correct
interpretation of all diagnosis aids:  the physician him/herself.
Programmers, like authors of medical texts, are providing tools for the
physician, not replacing him or her.

What we CAN do as computer scientists, et al., is to educate the
medical profession to the limitations of these tools as well as to their
benefits.  For ourselves, the goals should include error and risk
reduction as we continue to discuss.

Brint

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
Rolm's Hawk-32
</A>
</H3>
<address>
Doug Bryan 
&lt;<A HREF="mailto:BRYAN@SU-SIERRA.ARPA">
BRYAN@SU-SIERRA.ARPA
</A>&gt;
</address>
<i>
Sat 31 Aug 85 22:58:00-PDT
</i><PRE>
To: risks@SRI-CSL.ARPA

Speaking of possible hazards due to hardware failure, has anyone out there
had any experience with Rolm's 32 bit Mil Spec machine the Hawk-32?  Since 
the Hawk is a Mil Spec machine, I'm sure it will be used in situations where
failure could lead loss of life.

I would be interested in hearing about the Hawk's environment limitations,
mean time between failures and any other experiences people have had with
the machine.

doug

    [POSTSCRIPT: A few of you complained that the first issue had too much
     of a military flavor.  It is interesting that except for this last
     item, this issue and the previous issue had almost none!  On the
     other hand, the problems we are dealing with are universal, and
     we should be able to learn from all relevant discussions...  

     I had some complaints about the format breaking your dedigestifying
     programs.  I hope this is better, but if it really is, your programs 
     must be pretty stupid.  I did not change anything except the trailer.
     So maybe I don't have it right yet?

     Others complained that the issues were too big and did not come out
     often enough.  (I explained why -- I wasn't around.)  Now you will
     undoubtably complain that that they are too small and too frequent.
     But it really depends on what contributions are available.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-14</DOCNO>
<DOCOLDNO>IA012-000128-B042-114</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.5.html 128.240.150.127 19970217000250 text/html 14134
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:01:20 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 5</TITLE>
<LINK REL="Prev" HREF="/Risks/1.04.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.06.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 5</H1>
<H2>      Wednesday, 4 Sep 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
          (Contributions to RISKS@SRI-CSL.ARPA)
<BR>
          (Requests to RISKS-Request@SRI-CSL.ARPA)
<BR>
          (FTP Vol 1 : Issue n from SRI-CSL:&lt;RISKS&gt;RISKS-1.n)      
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  The Strategic Defense Initiative 
</A>
<DD>
<A HREF="#subj1.1">
Joseph Weizenbaum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  1.5 million Ford engines need recall? 
</A>
<DD>
<A HREF="#subj2.1">
Hal Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks in CAD, etc. 
</A>
<DD>
<A HREF="#subj3.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  crt &amp; non-crt risks 
</A>
<DD>
<A HREF="#subj4.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Computerworld... on Union Carbide and NJ false arrests 
</A>
<DD>
<A HREF="#subj5.1">
Charlie Spitzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  More on false arrests 
</A>
<DD>
<A HREF="#subj6.1">
PGN
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">
1.5 Million Ford Engines Need Recall?
</A>
</H3>
<address>
Hal Murray
&lt;<A HREF="mailto:Murray.pa@Xerox.ARPA ">
Murray.pa@Xerox.ARPA 
</A>&gt;
</address>
<i>
Tue, 3 Sep 85 12:18:36 PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

This morning, my radio said something about a consumer group wanting
Ford to recall 1.5 million engines. Nobody knows what's wrong, but they
are blaming it on the computer. (I didn't get the fine print. I wasn't
awake.) Anybody know if that's the real problem or just a convenient
scapegoat?

  [The 4 Sept 85 NY Times has a note on the recall of 454,000 
   Chevy/Pontiac compacts for corroding pollution control equipment, and
   105,000 VW and Audi cars for faulty brake hoses, but nothing on Ford.  I
   would love to follow up on the 1.5 million Fords, but haven't found 
   anything yet.  PGN]

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">

</A>
</H3>
<address>
Eugene Miya
&lt;<A HREF="mailto:eugene@AMES-NAS.ARPA ">
eugene@AMES-NAS.ARPA 
</A>&gt;
</address>
<i>
3 Sep 1985 0859-PDT (Tuesday)
</i><PRE>
Subject: Risks in CAD, etc.

Something, I have been wondering about, perhaps for future discussion might
concern liabilities of CAD products.  It seems more merchandise I purchase
is shoddy, and I am beginning to wonder what some of the consequences of
"making the metal a bit thinner to save.."  could be.  I realize we are
using CAD and simulation tools to make things more efficient, perhaps the
case of the over efficient engine which flamed out when it flew through rain
[as reposted in SEN, I believe] might be a case in point.  What were our
margins of safety in the over-engineering we did in the past?  Any studies yet?

Lastly, regarding mail formats:  I have run on a gamut of different mailers
[my current one, mh, is not bad], but I can sympathize with those having
problems.  It seems Peter's comment about programs was a bit harsh.  I used
to read netmail on an IBM machine which concatentated all letters and was
destructive [read once mail].

--eugene miya
  NASA Ames Research Center

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">

</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Wed, 4 Sep 85 18:22:22 edt
</i><PRE>
Subject: crt &amp; non-crt risks

It is important we separate crt from non-crt risks.  X-rays, color-perception, 
&amp; possibly eye fatigue I see as crt related.  Posture may be, for a person 
tied to the tube for extended periods.  Junk food is a non-crt risk, but may 
be a denial-of-service risk, if introduced into certain apertures around the 
crt.  Might also be a hazard to your health, if conductive. 

X- &amp; like radiation:  I am done producing children, I hope.  So does my
wife.  Unless radiation reaches carcinogenic levels, I am not concerned for
me.  My children all use/will use crts, unless some other display becomes
more economical in the near future.  We have 5 children, all of age.  I am
concerned about them.

Posture:  As an occasional, voluntary, crt user, my posture is my problem. 
Take the paper out of my office; or give me a clerical/data entry type job; 
then I will see posture as a crt/computer risk.  Any obstetrician will worry 
about any woman who sits in any one position for long periods.  At one point 
in one pregnancy my wife had to fly home while I drove alone - solely so she 
would not have to sit still too long.  (Many years ago I was told that the 
blood supply to the brain passed through the peri-anal region.  This accounts 
for the number of dumb comments and sleeping attendees at various conferences 
with inadequate breaks.) 

Color-perception:  When I go home after dark tonight, the white line will be 
pink.  No, I'm not on anything.  If the screen were pink, the line would be 
green.  If color sensitivity mattered to me... say, if I performed color-
matching titrations in a hospital, or put color-coded resistors &amp; capicators
into non-ICs, I would worry about color perception.  

	Considering the liability discussion in V1 #4, perhaps we all should. 
In 1956 or 1957 I ran across the proceedings of something-or-other on human 
factors in submarine design.  Book was pretty beat up, so it had been around
for a while.  It cited some *railroad safety* research on color perception. 
I think the RR stuff was pre WW-II.  Said red &amp; green were neat colors for 
signal lights.  Also said *yellow symbols on a black background* were the 
best combination for a symbolic display... and that the reverse was the next 
best.  Hence, road signs.  Amber screens... ?  

Eye-fatigue:  Not crt-unique, but... look at anything long enough, your eyes 
will tire.  Look at anything slightly fuzzy, &amp; your eyes will tire quickly, as
they try to focus on the un-focusable.  

Summary:  If a tired terminal operator hits a tree on the way home, it might
be due to poor color perception, fatigue due to poor posture (read:
furniture), eye fatigue due to poor colors, poor contrast, fuzzy images.  It
might be a financial disaster for the firm that employed said deceased.
Some attorney might look closely into the work situation, and computers
would get a bad name when we are really talking about bad management of the
computer-workplace.

	- Mike

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
 Computerworld Aug 19 articles
</A>
</H3>
<address>
 Charlie Spitzer 
&lt;<A HREF="mailto:Spitzer%pco@CISL-SERVICE-MULTICS.ARPA">
Spitzer%pco@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Tue, 3 Sep 85 13:07 MST
</i><PRE>
To:  Risks@SRI-CSL.ARPA

Readers may be interested in 2 articles from Aug 19 Computerworld.

page 6. Union Carbide modeling program given wrong data.

  Discusses wrong information about gases input to a program that was
  supposed to model gas cloud dispersal.  Notable quote: "These programs
  have been sold to safety people as opposed to engineers, because [the
  systems] provide good [public relations], are attractive visually and
  can provide a fairly inexpensive way of dealing with a problem you hope
  you'll never have."

page 12. On-line crime suspect system implicated in false arrest.

  Discusses case of a NJ woman arrested, strip searched and jailed on two
  separate occasions because of inadequate information stored in the NCIC
  computer.

charlie

</PRE>
<A NAME="subj5"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj5.1">
More on False Arrests
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Tue 3 Sep 85 13:56:12-PDT
</i><PRE>
To: RISKS@SRI-CSLA.ARPA

  [For those of you who do NOT read the ACM SIGSOFT Software Engineering
  Notes, here are three items taken from my RISKS column in the July 1985
  issue on the subject of false arrests.  For those of you who have already
  read these items, you have come to the last message in this issue and need
  read no further.]

In the past quarter year, there were two different stories of people winding
up in jail due to computer-related snafus, and an earlier story that
serendipitously goes along with them.

1. The AnchoRages Of Sin

An article on page 17 of the 15 April 1985 issue of ComputerWorld  entitled

        ``DMV computer error puts innocent motorist in jail''

provides us with another software glitch with harmful side-effects.  (Brad
Davis [b-davis@@utah-cs.ARPA] was the first to point this one out to me.)

The article (by Kathleen Burton) details how a mistake in programming the
new Alaskan Department of Motor Vehicles computer system resulted in
a motorist spending a night in a Fairbanks jail.  The computer indicated 
(erroneously) that C. R. Griffin was driving with a suspended license.
The article also said that only by human intervention were 400 additional 
driver's licenses not erroneously suspended.  Apparently the database
kept records of all violations in the past @i[five] years, but was supposed
to search only over the last @i[two] years for motorists who should be
suspended.  A programmer was quoted as saying that ``the cost of correcting
the mistake [in the program] was insignificant.''

2. Shirley There Must Be a Way Out

And then, on 25 April 1985, the Associated Press ran a story about
congressional hearings on the FBI national crime computer.  Two incidents were
included.  The first involved an airline flight attendant who was falsely
arrested and detained because of incorrect information in the FBI's national
crime computer.  Sheila Jackson Stossier was arrested on 28 October 1983 at the
New Orleans airport, because a woman named Shirley Jackson was wanted by Texas
authorities.  She wound up in jail for the night and detained in Louisiana for
five days.  She now has an arrest record, and her married name Stossier is
listed in the computer as an alias.  Coincidentally, another Shirley (Jones)
was also wrongly arrested because another woman alias Shirley Jones was listed
in the computer -- despite the facts that they had different birthdays, were
six inches apart in height, and 70 pounds in weight.  ``Despite this, the
Sheriff's office refused to drop the charges.''  (To make matters worse, it was
later determined that the wanted Shirley was already in jail at the time!)

3. One in Five Warrant Records Were Wrong -- Poor Odds

David Burnham (NY Times News Service) reported the following 
related story on 12 Feb 1985.

  A Michigan man filed suit charging that he was wrongfully arrested five
  times in 14 months after an arrest warrant for a man using his name was
  placed in the national computer system of the FBI.  The man, Terry Dean
  Rogan, charged that four of the arrests occurred after Michigan police had
  made an unsuccessful effort to get the warrant changed.  Rogan contends and
  the police confirm that the man actually being sought was another person
  using Rogan's stolen identity and credit cards.  Rogan, who is 27 years old,
  is not wanted for any crime.  

[The rest of the last story (which goes on for another page) is in the July
issue of Software Engineering Notes.  It was also BBOARDed earlier, so I
did not think it should be recyled again!]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-15</DOCNO>
<DOCOLDNO>IA012-000128-B042-136</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.6.html 128.240.150.127 19970217000305 text/html 16739
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:01:33 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 6</TITLE>
<LINK REL="Prev" HREF="/Risks/1.05.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.07.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 6</H1>
<H2>      Friday, 6 Sep 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Joseph Weizenbaum's comments 
</A>
<DD>
<A HREF="#subj1.1">
Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Good Risks and Bad Risks 
</A>
<DD>
<A HREF="#subj2.1">
Dave Brandin
</A><br>
<A HREF="#subj2.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Hot rodding you AT 
</A>
<DD>
<A HREF="#subj3.1">
Dan Bower
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Hazards of VDTs and CRTs 
</A>
<DD>
<A HREF="#subj4.1">
Al Friend
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  crt &amp; non-crt risks 
</A>
<DD>
<A HREF="#subj5.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  The Case of the Broken Buoy 
</A>
<DD>
<A HREF="#subj6.1">
Herb Lin
</A><br>
<A HREF="#subj6.2">
 Matt Bishop
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">

</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:vax-populi!dparnas@nrl-css ">
vax-populi!dparnas@nrl-css 
</A>&gt;
</address>
<i>
Thu, 5 Sep 85 07:28:56 pdt
</i><PRE>
Subject: Joseph Weizenbaum's comments &lt;JOSEPH@MIT-XX.ARPA&gt;: sdi]

	Although there is a great deal of truth and wisdom in Weizenbaum's 
message, I believe that he overlooks the reason that SDI would be
destabilizing and another step in the Arms race.  It is not because
of the stated goals of the program (Reagan's March 1983 speech) but because
those goals are not achievable.  There would be nothing wrong with rendering
ICBMs and other weapons obsolete.  On the contrary, everyone should want to 
see every country, city, and town protected by an impenetrable shield that
would free it from the fear of the indiscriminate horror that rained down on
Nagasaki and Hiroshima.  It is because the SDIO efforts will not lead to 
technology of that sort, that SDI is the things that Weizenbaum says it is.

	 I agree with Weizenbaum that we need to seek non-technological
solutions.  Technology is not likely to provide solutions in a situation 
where we oppose a power with equally sophisticated technology.  

	I believe that SDI is one issue where both disarmament and armament
supporters could agree.  Both sides seek peace through different mechanisms,
but neither will find their goals advanced by an untrustworthy "shield".


Dave

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
Good Risks and Bad Risks
</A>
</H3>
<address>
Dave Brandin 
&lt;<A HREF="mailto:BRANDIN@SRI-AI.ARPA">
BRANDIN@SRI-AI.ARPA
</A>&gt;
</address>
<i>
Thu 5 Sep 85 11:40:30-PDT
</i><PRE>
To: Neumann@SRI-CSL.ARPA

Peter: I love your material that's being generated and produced, but I note
that it seems to weigh overwhelmingly against the computer.  Aren't people
sending you any GOOD stuff?  Like with the aid of a computer, 27 lives were
saved, etc.?  Like using the new NEC fingerprint computer, they were able to
match the Stalker's finger-prints in 3 minutes, etc?  Maybe you need a Call
for Good News?  

Dave

</PRE>
<HR><H3><A NAME="subj2.2">
Good Risks and Bad Risks
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Thu 5 Sep 85 23:32:45-PDT
</i><PRE>
To: RISKS@SRI-CSLA.ARPA
Cc: BRANDIN@SRI-AI.ARPA

Today's SF Chronicle had a nice article on "Computer Holds Promise in
Diagnosing Heart Disease", in greatly reducing the number of false
negatives.  But even there are significant risks.  Suppose you or your
doctor trusts the computer program more because it indeed has fewer false
negatives, and now you produce a false negative.  We are back to the case of
the woman who killed her daughter and tried to kill herself and her son
because the computer program had falsely produced an "incurable"
diagnosis.  (See the July 85 issue of Software Engineering Notes.)

Well, in the first issue of RISKS I recall saying there has got to be more
to this forum than just pointing out negative things.  I noted hope from the
research community, although one of the agonizing things that we have
observed in the ACM Special Interest Group on Software Engineering (SIGSOFT)
is the enormous gap between the research community and what is actually
being done in practice.  For critical systems, the ordinary software
development techniques are simply not good enough.

Yes, we should of course point out successes.  For example, the Shuttle
project has had many -- along with its much more visible problems.  

Peter

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:Dan_Bower%RPI-MTS.Mailnet@MIT-MULTICS.ARPA">
Dan_Bower%RPI-MTS.Mailnet@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 4 Sep 85 14:41:38 EDT
</i><PRE>
Subject: Hot rodding you AT

In a recent issue of PC Magazine, Peter Norton espoused the idea of
substituting a faster clock chip to enhance performance.  Now, according
to the folk on the Info-IBM PC digest, this may create problems.  An
off the shelf PC AT is composed of components guaranteed to work to
IBM spec, e.g. 6 Mhz.  If I increase the clock rate, then the whole
rest of the machine has to be up to snuff.  If not, a part dies and
I pay a nasty repair bill.

Now if I took Mr. Norton's word as gospel, swapped chips and set
my PC AT on fire, would he be liable?  How about the publisher?

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">

</A>
</H3>
<address>
Al Friend, Space and Naval Warfare Systems Command
&lt;<A HREF="mailto:friend@nrl-csr ">
friend@nrl-csr 
</A>&gt;
</address>
<i>
Thu, 5 Sep 85 15:23:05 edt
</i><PRE>
Subject: Hazards of VDTs and CRTs

When evaluating the risks associated with various forms of technology
it is sometimes useful to have in hand the available data.

The Food and Drug Administration published a study in 1981:

               An Evaluation of Radiation Emission
                              from
                     Video Display Terminals

                   HHS Publication FDA 81-8153

The ionizing, optical, RF and acoustic radiation from a number of
terminals was measured.  I will briefly quote some of the conclusions
of this study.

For ionizing radiation:

  3.5  DISCUSSION

  Sufficient research information is available to estimate a range of
  risks of injury from ionizing radiation exposure.  Delayed disease,
  such as heritable mutation or cancer, usually forms a basis for the
  estimation, expressed in terms of the instances of the effect per
  person per unit of radiation (rad,rem, or R).  The risk estimates
  form a basis for radiation protection guidelines.

  For a VDT operator, the radiation protection guideline for 
  individuals in the general population is appropriate.  The guideline
  -- 500 millirem per year -- is for man-made radiation exposures
  excluding medical use.  For both normal and Phase III operating
  conditions, the likely emission from a VDT is 0.1 mR per hour or less.
  Terminals capable of exceeding the 0.5 mR per hour regulatory limit
  receive special attention (see Section 3.2, above).  With assumptions
  of 6 hours of viewing per day, 5 days per week for 50 weeks per year,
  the annual radiation dose to an individual 2 inches from the front
  surface of a screen emitting 0.1 mR per hour would be 150 millirem.
  Note that 2 inches is an unrealistically short viewing distance; as
  one moves further away from the screen, the radiation exposure
  decreases correspondingly.
  
For RF radiation:

  4.5 DISCUSSION

  Research information on bioeffects for the frequency range 15kHz to
  125 kHz is lacking, so empirical estimates of injury are not possible.
  However, the radiation in this frequency region interacts only
  slightly with the human body, so that significant biological effects
  are unlikely.  At the present time, no standard or guideline has been
  adopted in the U.S. for grequencies below 10 MHz.

For ultrasound radiation:

  5.4 DISCUSSION

  When airborne ultrasound impinges on human skin less than 1 percent
  is absorbed, the remainder being reflected.  The ear, however, is an
  efficient coupler of acoustic energy from air into the human body.
  Therefore, investigations of the biological effects of ultrasound
  levels much higher than those found in the VDT survey have included
  temporary threshold shifts in hearing (6).  So-called subjective
  effects have also been associated with high levels of ultrasound
  exposure, and include fatigue, headache, tinnitis, instability, a
  "fullness" in the ear, and nausea.  One report (7) tentatively
  associates the subjective effects with audible high frequency
  components of sonic radiation.  The studies were performed in the
  exposure range 70-120 dB in an industrial setting, and at 150 dB.
  No long term effects or delayed injuries are known.

  No formal standard for ultrasound exposure presently exists in the
  U.S.  Among several voluntary guidelines available, the 
  recommendations of W.I. Acton of the United Kingdom were used to
  compare the VDT results, because they are the most conservative in
  this frequency range.  The highest acoustic measurement obtained
  from a VDT in this study was 68 dB, well below Acton's guideline
  of 75 dB, and well below the energies associated with biological
  effects.

For "ergonomic" factors:

  7. CONCLUSIONS AND RECOMMENDATIONS

  *****
  *****

  The word processing field has expanded much faster than has the
  understanding of its impact on people who use VDTs.  The impact
  may be felt in areas such as employee morale, compensation,
  work hours, and work conditions.  We suggest that work conditions
  be given serious conisideration as the primary cause of VDT-user
  complaints.  The problem is not simple, however.  An extensive
  review of stress factors in the word processing work area (10)
  identified five separate factors that contribute to fatigue:
  vision, posture, environment, task organization, and higher
  order items such as disease susceptibility.  As early as 1976,
  it was recognized that glare (room lighting reflecting from the
  VDT face plate), work position, ambient noise, and work duration
  (absence of breaks) could be the most important factors
  influencing the VDT worker's health (11).  The parallel
  between the 1976 and 1979 studies is sufficiently strong for
  us to suggest that efforts expended to reduce stress caused
  by these factors would also reduce the adverse impact on
  health.

The above quotes from the FDA document are some of its most important
conclusions.  References to additional work are provided in the
document.  There has been further work since the time of this report
(1981).  I do not have immediate access to these later references.  I
believe they tend to bear out the conclusions of this report.

From conversations with those closer to this field than I, I get the
impression that one of the major stress factors in commercial word
processing operations is the highly regimented work situation, and the
possibility of being fired, if the operator does not turn out a certain
minimum amount of mistake free work per hour.

</PRE>
<A NAME="subj5"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj5.1">

</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Thu, 5 Sep 85 11:55:42 EDT
</i><PRE>
cc:       RISKS@SRI-CSL.ARPA
Subject:  Re:  crt &amp; non-crt risks

Many of the crt/workplace issues you raise are shared by another group
whose members are quite diverse in their use of crt terminals:
secretaries. 

I know this is not quite the correct forum, but workplace rules and
legislation designed to "protect" users of terminals from problems of
posture, vision, and stress should consider this forgotten group of
workers as well.  Their problems are nearly the same.

Brint

</PRE>
<A NAME="subj6"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj6.1">
 The Case of the Broken Buoy
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MIT-MC.ARPA">
LIN@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Thu,  5 Sep 85 17:06:21 EDT
</i><PRE>
To: mab@RIACS.ARPA
cc: LIN@MIT-MC.ARPA, risks@SRI-CSL.ARPA

In response to:

       Dave Curry's right. I remember reading a newspaper report which
    said, in essence, that the NWS/NOAA lost because it had failed to
    predict the storm.  I didn't believe it, so I read on, and the report
    said that since they had known of a broken buoy, had failed to repair
    it (I think it had been broken for several months), and therefore failed
    to get the information needed to give a warning, they were guilty of
    negligence and had to pay.  Quite a far cry from what the story had
    begun as!

On the other hand, the NWS also said that even if the buoy had been
alive at the time, they would not have predicted the storm.  This
isn't to defend sloppy journalism, just to point out that the
newspaper was in essence correct in this instance.

</PRE>
<HR><H3><A NAME="subj6.2">

</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:mab@riacs.ARPA">
mab@riacs.ARPA
</A>&gt;
</address>
<i>
5 Sep 1985 2049-PDT (Thursday)
</i><PRE>
Address: Mail Stop 230-5, NASA Ames Research Center, Moffett Field, CA  94035
Phone: (415) 694-6363 [main office], (415) 694-6921 [my office]
To: Herb Lin &lt;LIN@MIT-MC.ARPA&gt;
Cc: risks@SRI-CSL.ARPA
Subject: Re: The Case of the Broken Buoy

Did the NWS say that (i.e., even if the buoy had been alive at the time,
they could not have predicted the storm) in testimony, or after the verdict?
If after the verdict, no comment.  But if as testimony, Herb, the jury (or
judge) apparently didn't believe the NWS testimony.  If you believe the NWS
claim, the headline was correct, but it's unfair to say the court ruled that
way when it explicitly based its ruling on negligence.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-16</DOCNO>
<DOCOLDNO>IA012-000128-B042-168</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.7.html 128.240.150.127 19970217000323 text/html 32717
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:01:49 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 7</TITLE>
<LINK REL="Prev" HREF="/Risks/1.06.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.08.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 7</H1>
<H2>      Sunday, 8 Sep 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  The risks of not using some technology 
</A>
<DD>
<A HREF="#subj1.1">
John McCarthy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  More on SDI 
</A>
<DD>
<A HREF="#subj2.1">
Joseph Weizenbaum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  SDI reliability 
</A>
<DD>
<A HREF="#subj3.1">
Martin Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Hazards of VDTs and CRTs 
</A>
<DD>
<A HREF="#subj4.1">
Bernie Elspas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Viruses, Trojan horses, and worms 
</A>
<DD>
<A HREF="#subj5.1">
Fred Hapgood
</A><br>
<A HREF="#subj5.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: The Case of the Broken Buoy 
</A>
<DD>
<A HREF="#subj6.1">
Herb Lin
</A><br>
<A HREF="#subj6.2">
 Matt Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Hot rodding you AT 
</A>
<DD>
<A HREF="#subj7.1">
Keith F. Lynch
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">
The risks of not using some technology 
</A>
</H3>
<address>
John McCarthy 
&lt;<A HREF="mailto:JMC@SU-AI.ARPA">
JMC@SU-AI.ARPA
</A>&gt;
</address>
<i>
07 Sep 85  1329 PDT
</i><PRE>
To:   risks@SRI-CSL.ARPA    

	The problem with a forum on the risks of technology is that
while the risks of not using some technology, e.g. computers, are
real, it takes imagination to think of them.  A further problem
with newspaper, magazine and TV discussion of technology is that
journalists and free-lance writers tend to run in intellectual
mobs.  This biases the discussion for everyone, especially when
the same journalists read each others writings and call it public
opinion.  Here are some illustrations.

1. Suppose some organization manages to delay interconnecting
police data systems on some specious civil liberty grounds.
Suppose some wanted murderer is stopped for a traffic offense
but not arrested, because he is wanted in a jurisdiction not
connected to the computer system used by the police officer.
He later kills several more people.  The non-use of computers
will not be considered as a cause, and no-one will sue the
police for not interconnecting the computers - nor will anyone
sue the ACLU.  The connection will not even be mentioned in
the news stories.

2. No relative of someone killed on U.S. 101 during the 10 years
the Sierra Club delayed making it a freeway sued the Sierra Club.

3. No non-smoker who dies of lung cancer in an area newly polluted by
wood smoke will sue the makers of "Split wood not atoms" bumper
stickers.

***

Based on past experience, I expect this question to be ignored, but here's
one for the risk-of-computers collectors.  Is a risk-of-computers
organization that successfully sues to delay a use of computers either
MORALLY or LEGALLY LIABLE if the delay causes someone's death?  Is there
any moral or legal requirement that such an organization prove that they
have formally investigated whether their lawsuit will result in killing
people?  As the above examples indicate, the present legal situation
and the present publicity situation are entirely unsymmetric.

***

	Here's another issue of the social responsibility of computer
professionals that has been ignored every time I have raised it.

The harm caused by tape-to-tape batch processing as opposed to on-line
systems.

From the earliest days of commercial computing people have complained
about seemingly uncorrectable errors in their bills.  The writers
don't know enough to connect this with the use of tape-to-tape
batch processing.  Under such a system when a customer complains,
the person who takes the complaint fills out a form.  A key puncher
punches the form on a card.  At the next file-update, this card
goes to tape, and a tape-to-tape operation makes the correction.
If there is any error in the form or in the key punching, the
correction is rejected, and the customer gets the wrong bill again.
On-line systems permit the person who takes the complaint to make
the correction immediately.  Any errors in making the correction
show up immediately, and the person can keep trying until he gets
it right or ask for help from a supervisor.  Not only is the customer
better off, but the complaint-taker has a less frustrating job.

My own experience with the difference occurred in 1979 when my
wallet was stolen, and I had to tell American Express and Visa.
American Express had an on-line system, and the person who took
the call was even able to give me a new card number on the spot.
The Visa complaint-taker had to look it up on a micro-fiche file
and call back, and still they got it wrong.  They gave me a new
account number without cancelling the old one.

Perhaps this issue is moot now, but I suspect there are still
many tape-to-tape systems or systems using modern equipment that
still emulate the old systems.  Shouldn't computer professionals
who pretend to social responsibility take an interest in an
area where their knowledge might actually be relevant?

Once upon a time, beginning perhaps in the middle nineteenth
century, scientific organizations were active in pressuring
government and business to use new technology capable of
reducing risk and promoting the general welfare.  I have in
mind the campaigns for safe water supplies and proper sewage
disposal.  Here's a new one that involves computer technology.

Theft can be reduced by introducing the notion of registered
property.  When you buy a television, say, you have the option
of buying a registered model, and the fact that it is registered
is stamped on it.  Whenever someone buys a piece of used registered
property he has the obligation of telephoning the registry to
check whether the property with that serial number has been reported
stolen and recording his ownership.  Repairmen are also obliged
to telephone either by voice or by keyboard.

Unfortunately, too many computer people imagine their social
responsibility to consist solely of imagining risks.

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
More on SDI (reply to comments on RISKS-1.5 statement)
</A>
</H3>
<address>
Joseph Weizenbaum 
&lt;<A HREF="mailto:JOSEPH@MIT-XX.ARPA">
JOSEPH@MIT-XX.ARPA
</A>&gt;
</address>
<i>
Sat 7 Sep 85 16:30:11-EDT
</i><PRE>
To: Neumann@SRI-CSL.ARPA

I've received a number of responses to the remark I made that I would not
support the SDI program even if I thought it could be made to work.  I have
the feeling that,  if I try to respond globally, a full blown debate
may ensue.  That I really don't want to conduct with the bboard as the
medium of expression.  Nevertheless, I feel obligated to say just a few
words in an attempt to clarify some ideas that have probably been 
misunderstood.

I said that my attitude derives from what I called a "quasi pacifist"
position.  One writer thought that pacifists are opposed to all forms of
self defense.  Actually pacifists are often the first to come to the
defense of justice being trampled.  But the form of their resistance to
wrongs is non-violent.  It ought also not to be confused with "passive"
resistance - Gandhi often pointed out, usually by his own example, that there
is nothing passive about non-violent resistance.  My use of the term "quasi
pacifist" also elicited comment:  Am or am I not a pacifist?  Let me say I
strive to become a pacifist, to grow up to be one.  One isn't an adult by
virtue of merely wishing or claiming to be one.  Just so with being a
pacifist.  I am still far from the goal.

People apparently believe that, were the SDI technically feasible there
could be no reasonable objections to its development and deployment.
Wouldn't it be comforting if every region, every city and village in
America had, so to speak, an invisible shield over it which guarded against
the invasion of hostile missiles, they ask.  Speaking entirely in practical
terms, I would remind them that every year tons (perhaps kilotons) of
marijuana are smuggled past the U.S. Coastguard and the custom service.
Now that technical progress allows the construction of nuclear "devices"
smaller than a moderately sized overnight bag, a determined enemy could
destroy American cities without "delivering" war heads by air mail at all ! 
If I were responsible for national security, I would worry if, a few days
before the President's traditional State of the Union message, usually
delivered to the assembled leadership of all three branches of our
government, some foreign embassy evacuated all its personel.  Perhaps a
nuclear device of moderate size had made its way to Washington and is about
to decapitate the government.  We can no more bring peace to this globe by
putting impenetrable domes over nations than we can halt the violence in
our cities by providing everyone with bulletproof clothing.  Human problems
transcend technical problems and their solutions.

But suppose we could solve the smuggled bomb problem.

I would still oppose SDI.

SDI is an attempt at a technological solution to problems which have
their roots in and are social, political, economic, cultural, in other
words, human problems.  It is an attempt to find solutions under the the
light provided by technology when in fact we know them to reside only in
the human spirit.  That is what guarantees the failure of SDI more surely
than its complexity or the impossibility of its being tested.

Beyond all that is the fact that we live in a world of finite resources.
The scarcest resource of all is human talent and creativity.  The military
already commands the time and energy of most American scientists and
engineers.  Money is another scarce resource on which the military has first
call. On the other hand, social services of all kinds
are being cut back.  Meanwhile  the country faces social problems
of horrendous dimensions:  There is massive, deep poverty in the land.
Adequate health care is beyond the reach of millions of citizens and
ruinously expensive for many more millions.  The schools are spewing out "a
rising tide of mediocrity" while a huge fraction of our youth is functionally
illiterate.  The conditions that brought on the riots in American cities,
for example in Watts, have never been attended to - they silently tick
away, time bombs waiting to go off.

When resources are limited they must be distributed on the basis of a
widely based consensus on priorities.  To silently consent to lowering
still further the priorities our society assigns to the people's health and
education in favor of spending the billions of dollars required above and
beyond the already huge military budget for only the first stages of SDI,
is, it seems to me, to condone the continuing impoverishment and
militarization of not only America, but of the whole world. Ever more
scientists and engineers will be occupied with military work.  Ever more
industrial workers of many different kinds will be enmeshed in the
militarized sectors of society by, for example, being required to have
military security clearances.  There is a danger that, in the process of the
growing militarization of society, a certain threshold, hard to define but
terribly real, will be crossed and that, once crossed, there will be no ready
road back to a civilian society.  

	Joseph Weizenbaum

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">
SDI reliability
</A>
</H3>
<address>
&lt;<A HREF="mailto:mooremj@EGLIN-VAX">
mooremj@EGLIN-VAX
</A>&gt;
</address>
<i>
Fri, 06 Sep 85 14:54:52 CDT
</i><PRE>
To: risks@sri-csl

[Peter, I have also posted this to SOFT-ENG.  If you think the duplication
is reasonable, please include it in RISKS as well. -- mjm]

I've been thinking about the SDI system and how it will be implemented.  
Specifically, I've been looking at a system composed of N independent 
platforms, each of which performs its own detection, decision making, and
response.  Given this type of system, we can reach a few conclusions about
the reliability of the whole system, based on the reliability of a single
platform.  I've crunched a few numbers: nothing profound, just some basic
statistics.

Definitions:

1. A "false positive" is an attack response by a platform when such a response
   is not justified.
2. A "false negative" is failure of a platform to attack when an attack 
   response is justified.

Let's look at the false positive case first.  How likely is the system to
experience a false positive, based on the probability for each platform?

             N:    50        100        200        500       1000       2000
Pp:         +------------------------------------------------------------------
  1.000E-12 |  5.000E-11  1.000E-10  2.000E-10  5.000E-10  1.000E-09  2.000E-09
  1.000E-11 |  5.000E-10  1.000E-09  2.000E-09  5.000E-09  1.000E-08  2.000E-08
  1.000E-10 |  5.000E-09  1.000E-08  2.000E-08  5.000E-08  1.000E-07  2.000E-07
  1.000E-09 |  5.000E-08  1.000E-07  2.000E-07  5.000E-07  1.000E-06  2.000E-06
  1.000E-08 |  5.000E-07  1.000E-06  2.000E-06  5.000E-06  1.000E-05  2.000E-05
  1.000E-07 |  5.000E-06  1.000E-05  2.000E-05  5.000E-05  1.000E-04  2.000E-04
  1.000E-06 |  5.000E-05  1.000E-04  2.000E-04  4.999E-04  9.995E-04  1.998E-03
  1.000E-05 |  4.999E-04  9.995E-04  1.998E-03  4.988E-03  9.950E-03  1.980E-02
  1.000E-04 |  4.988E-03  9.951E-03  1.980E-02  4.877E-02  9.517E-02  1.813E-01
  1.000E-03 |  4.879E-02  9.521E-02  1.814E-01  3.936E-01  6.323E-01  8.648E-01

Pp is the probability that a given weapons platform will experience a false 
positive.  N is the number of platforms in the system.  The entries in the
table give the probability that a false positive will occur on at least one
platform (and one may be enough to start a war.)  For example, if there are
1000 platforms, and each one has a one-millionth (1.000E-6) probability of
experiencing a false positive, then the cumulative probability that some 
platform will do so is 9.995E-4, or .09995%.  Looking at the table, I'd say
the numbers in the lower right corner are rather disquieting, to say the least.

Now let's look at the false negative case.  The table is structured a little
differently here.  In the false positive case, a single failure is disastrous;
in the false negative case, it's not.  The probability of a false negative
should be many orders higher than that of a false positive, simply because the
protections against a false positive will actually enhance the chances of a
false negative.  This table deals with a 100-platform system (that being the
most my binomial coefficient routine can handle). 

   Pn:  .001    .01     .05     .1      .2      .3      .4      .5
N:  +---------------------------------------------------------------
 30 | 1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000
 35 | 1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  0.9991
 40 | 1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  0.9824
 45 | 1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  0.9991  0.8644
 50 | 1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  0.9832  0.5398
 55 | 1.0000  1.0000  1.0000  1.0000  1.0000  0.9995  0.8689  0.1841
 60 | 1.0000  1.0000  1.0000  1.0000  1.0000  0.9875  0.5433  0.0284
 65 | 1.0000  1.0000  1.0000  1.0000  0.9999  0.8839  0.1795  0.0018
 70 | 1.0000  1.0000  1.0000  1.0000  0.9939  0.5491  0.0248  0.0000
 75 | 1.0000  1.0000  1.0000  1.0000  0.9125  0.1631  0.0012  0.0000
 80 | 1.0000  1.0000  1.0000  0.9992  0.5595  0.0165  0.0000  0.0000
 85 | 1.0000  1.0000  1.0000  0.9601  0.1285  0.0004  0.0000  0.0000
 90 | 1.0000  1.0000  0.9885  0.5832  0.0057  0.0000  0.0000  0.0000
 95 | 1.0000  0.9995  0.6160  0.0576  0.0000  0.0000  0.0000  0.0000
100 | 0.9048  0.3660  0.0059  0.0000  0.0000  0.0000  0.0000  0.0000

Pn is the probability that a given platform will experience a false negative.
N is the minimum number of platforms (out of 100) which respond correctly.
The table entries give the probability that at least N platforms respond
correctly.  For example, if the probability of a given platform experiencing
a false negative is 0.1 (10%), then the probability is 99.92% that at least
80 out of 100 platforms respond correctly, 58.32% that at least 90 respond
correctly, and so on.

Some of the Pn's and Pp's may strike you as much too high.  I don't think so. 
The two tables were constructed on the simplifying assumption that Pn and Pp
are constants; actually, they are reliability functions.  The longer a platform
is in service, the more likely it is to malfunction.  If we assume that the
time-to-failure rate of a platform is some form of Weibull distribution
[a*B*t**(B-1) * e**(-a*t**B)], then the reliability function is given by Z(t)
= a*B*t**(B-1).  I did not use this in constructing the tables in order to
keep from drowning in figures, and because I don't really know how to choose
a, B, and unit t, until we get a history of actual performance (and by then it
may be too late...)  Suggestions are welcome. 

                                  Martin Moore (mooremj@eglin-vax.arpa)

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
Hazards of VDTs and CRTs 
</A>
</H3>
<address>
Bernie 
&lt;<A HREF="mailto:ELSPAS@SRI-CSLA.ARPA">
ELSPAS@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Fri 6 Sep 85 15:45:16-PDT
</i><PRE>
To: RISKS@SRI-CSLA.ARPA
RE:  RISKS contribution from friend@nrl-csr (Al Friend, Space and 
     Naval Warfare Systems Command); RISKS-1.6

The 1981 FDA study cited by Friend probably contains much useful (albeit
rather "soothing") information about VDT *radiation* hazards (ionizing,
RF, and acoustic).  One should observe carefully, however, that the 
quoted material fails to mention other kinds of hazards, nor does its 
title reflect any others.  One should, therefore, not assume that 
*radiation* hazards are the whole story for VDTs.  I would have felt 
more relieved at the data presented had it included some other, more 
obvious, risk factors such as visual effects.

In particular, recent studies show that at least two visual effects may
be quite important as factors producing severe eye fatigue.  The first,
visual flicker (resulting from the screen refresh rate), is probably
well understood (from extensive psychovisual experimentation in
connection with TV viewing).  The higher screen refresh rates used on 
some computer graphic displays seem to minimize this problem.  However,
60 fields/sec (50, in Europe) is standard for most personal computers.

[Flicker depends on many factors: rate, ambient light, screen contrast, 
brightness, subject motion, color, etc.  More seems to be known about the 
conditions for minimal *perceptible* flicker than about those that can
produce visual fatigue, eyestrain, headaches, etc.  Also, there is a
fairly large variation among different subjects even for minimal
perceptible flicker, and flicker may be noticeable (and annoying) in 
the "fringe visual field" (off to the side) even when it is not detectable 
for the object directly ahead.]

The second factor is connected with the fact that the human eye is not 
chromatically corrected, i.e., its focal accommodation is different for
different colored objects.  The result is that when the eye is focused
correctly on a blue object, a nearby red object will be slightly out of
focus.  One study [1] indicates that the discrepancy is about 0.5
diopters (for a viewing distance of 50 cm).  According to one report
I've seen (sorry, I can't find the reference!), this means that in a
multicolored display the eye will automatically be making rapid
focus adjustments in scanning the screen.  Even worse, the effect can
also exist in some monochrome displays, i.e., where the character 
color (white, say) is achieved by a mixture of two differently colored 
phosphors separated substantially in wavelength.  In the latter situation 
it appears that (at least for some people) the eye may undergo extremely 
rapid focus oscillations in the futile attempt to bring both component 
colors into focus.   Quite understandably this may result in severe eye 
fatigue, even though the subject may not be consciously aware of what 
is happening.  This occurs mostly when the two phosphors radiate nearly 
pure spectral lines.  Single-phosphor displays and those where the 
component pure colors are close enough in wavelength seem not be prone 
to this disturbing effect.  I recall seeing the statement that AMBER 
displays are not objectionable for this reason, and that one nation
(Sweden or West Germany, I think) has specified amber displays for 
extended-time industrial use.

It seems to me that the chromatic refocusing effect is probably the more
serious of the two cited, especially on high resolution displays.  The
fact that it seems not to have been noticed on conventional (analog)
color TV displays may be accounted for by their relatively poor
resolution (low bandwidth).  Thus, the brain expects to see a sharper image
on a high-resolution (RGB) display than on a conventional TV (where
everything--especially the reds and oranges--is pretty blurred anyway).

In summary, in concentrating on the "serious" potential hazards of 
X-rays, etc., from VDTs, we should not thereby overlook the more obvious
factors concerned with the visual process itself.


1. G.M. Murch, "Good color graphics are a lot more than another pretty
   display," Industrial Research and Development, pp. 105-108 (November
   1983).

Bernie Elspas

[Material inside [...] may be deleted at editor's option.  Bernie]
                      [The editor decided to leave it in.  PGN]

</PRE>
<A NAME="subj5"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj5.1">

</A>
</H3>
<address>
"Fred Hapgood" 
&lt;<A HREF="mailto:SIDNEY.G.HAPGOOD%MIT-OZ@MIT-MC.ARPA">
SIDNEY.G.HAPGOOD%MIT-OZ@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Fri 6 Sep 85 22:55:13-EDT
</i><PRE>
Subject: Viruses, Trojan horses, and worms
To: RISKS@SRI-CSL.ARPA

	I would like to see a discussion by the members of this list
of the degree to which computer users, whether individuals or
organizations, are vulnerable to worms and Trojan Horses. These
terms, which first appeared in this list in #3, refer to programs
designed to inflict some form of unpleasantness on the user, up to
and including the destruction of the system. Typically they erase
all files in reach. I have read discussion, in Dvorak's column in
*Infoworld*, of the possibility that such programs might modify the
operating system as well such that when the unfortunate user tries
to restore the destroyed files from backup disks, those too would be
erased.  One can also imagine, vaguely, programs that are insidious
rather than calamitious, that introduce certain categories of error,
perhaps when strings of numbers are recognized. These might be able
to do even more damage over the long run.

	There are two issues with these programs. The first is what
they might do, once resident. The second is the nature of the
vector, to borrow a medical term. Worms can be introduced directly,
by 'crackers', or surreptiously, by hiding them inside a legitimate
program and waiting for an unsuspecting user to run that program on
his system, thus activating the 'Trojan Horse'. The article cited in
#3 had to do with a program camouflaged as a disk directory that was
circulated on the download BBSs. One could imagine a spy novel
devoted to the theme: perhaps it was the KGB, and not Ben Rosen, who
provided the money to launch Lotus. Inside every copy of 1-2-3 and
Symphony is a worm which, every time it is run, checks the system
clock to see if it was later than, say, October 1, 1985. On that
date the commercial and industrial memory of the United States dies.
The CIA suspects something is up, but they don't know what.
Unfortunately the director of the team working on the problem is a
KGB mole.  Fortunately there is this beautiful and brilliant female
computer genius ...

	Anyway, I have a specific question: can anyone imagine a
circumstance in which a program appended to a piece of text in a
system could get hold of the processor? It would appear not, which
is a good thing, because if such circumstances did exist, then it
would become possible to spread worms by pigyybacking them on a
telecommunicated piece of text. The right piece of text -- some
specialized newsletter, or even a crazily attractive offer from
a 'Computer Mall'-- might find itself copied into thousands of
systems. But I am not a technical person, and cannot establish
to my satisfaction that such an eventuality is truly impossible.

	Is it? 

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Viruses, Trojan horses, and worms
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Sat 7 Sep 85 23:59:24-PDT
</i><PRE>
To: SIDNEY.G.HAPGOOD%MIT-OZ@MIT-MC.ARPA
Cc: RISKS@SRI-CSLA.ARPA 

Absolutely not.  It is quite possible.  However, I can assure you that
this issue does not now include a virus -- although some message systems 
tend to permit you to edit a message before resending it, with no
indication that it has been altered.  Thus, even in the presence of all
of those routing headers, you can never be sure you really have picked
up or been forwarded the original message.  The example of squirreled
control characters and escape characters that do not print but cause
all sorts of wonderful actions was popular several years ago, and
provides a very simple example of how a message can have horrible
side-effects when it is read.

Worms, viruses, and Trojan horses from their technical aspects are probably
best discussed elsewhere -- e.g., in SECURITY@RUTGERS.  (See also Fred
Cohen's paper in the 7th DoD/NBS Computer Security Conference in 1984.)
From the RISKS point of view, they are definitely important to this forum
-- and they present a very serious risk to the public.  PGN]

</PRE>
<A NAME="subj6"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj6.1">
 The Case of the Broken Buoy
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MIT-MC.ARPA">
LIN@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Fri,  6 Sep 85 16:01:38 EDT
</i><PRE>
To: mab@RIACS.ARPA
cc: risks@SRI-CSL.ARPA

    Did the NWS say that (ie, even if the buoy had been alive at
    the time, they could not have predicted the storm) in testimony,
    or after the verdict?  If after the verdict, no comment.

I believe it was during testimony, but I am not certain.

    But
    if as testimony, Herb, the jury (or judge) apparently didn't
    believe the NWS testimony.  If you believe the NWS claim, the
    headline was correct, but it's unfair to say the court ruled
    that way when it explicitly based its ruling on negligence.

But it is not clear that the court understands that the significance
of "missing data" is context-dependent.  Sometimes it matters, and
sometimes it doesn't.  This is a point that non-scientists have a very
hard time understanding.

I am not defending the NWS; they should have repaired the buoy.  But
given limited resources, how are they to set priorities in deciding
what to repair first?  The implications of the verdict are to me
frightening, placing NWS and all other similar organizations in a
double bind: all equipment must be functional even when they don't
have sufficient dollars to keep it that way.

</PRE>
<HR><H3><A NAME="subj6.2">

</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:mab@riacs.ARPA">
mab@riacs.ARPA
</A>&gt;
</address>
<i>
6 Sep 1985 1359-PDT (Friday)
</i><PRE>
Cc: risks@SRI-CSL.ARPA
Subject: Re: The Case of the Broken Buoy

    But it is not clear that the court understands that the significance
    of "missing data" is context-dependent.  Sometimes it matters, and
    sometimes it doesn't.  This is a point that non-scientists have a very
    hard time understanding.

At this point I'm going to bow out of the discussion, since I am not
familiar enough with the decision to know if the court understood that
point.  The NWS certainly should have made its position very clear, so
the court could make an informed decision (about whether or not
negligence was involved.)

</PRE>
<A NAME="subj7"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj7.1">
Re: Hot rodding you AT
</A>
</H3>
<address>
Keith F. Lynch 
&lt;<A HREF="mailto:KFL@MIT-MC.ARPA">
KFL@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Fri,  6 Sep 85 09:24:39 EDT
</i><PRE>
To: RISKS@MIT-MC.ARPA

    Date: Wed, 4 Sep 85 14:41:38 EDT
    From: Dan_Bower%RPI-MTS.Mailnet@MIT-MULTICS.ARPA
    Subject: Hot rodding you AT

    In a recent issue of PC Magazine, Peter Norton espoused the idea of
    substituting a faster clock chip to enhance performance.  Now, according
    to the folk on the Info-IBM PC digest, this may create problems.  An
    off the shelf PC AT is composed of components guaranteed to work to
    IBM spec, e.g. 6 Mhz.  If I increase the clock rate, then the whole
    rest of the machine has to be up to snuff.  If not, a part dies and
    I pay a nasty repair bill.

    Now if I took Mr. Norton's word as gospel, swapped chips and set
    my PC AT on fire, would he be liable?  How about the publisher?

I doubt this would break anything.  The machine would simply cease
working above a certain speed, and resume working below that speed.

I know of a couple people who have done this on APPLE computers,
tried various speeds so as to run their machine at the highest speed
it will go.

Also, I once did the same thing with a synchronous link, i.e. hooked
up an external clock and cranked it up to the highest speed it would
work reliably at.

Also, I have done this with my Hayes modem.  The standard duration for
touchtone pulses is 70 ms.  The phone system here will accept as short
at 38 ms.
								...Keith
</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-17</DOCNO>
<DOCOLDNO>IA012-000128-B042-197</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.8.html 128.240.150.127 19970217000340 text/html 24105
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:02:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 8</TITLE>
<LINK REL="Prev" HREF="/Risks/1.07.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.09.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 8</H1>
<H2>     Sunday, 8 Sep 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                   Peter G. Neumann, moderator
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Risks of omission 
</A>
<DD>
<A HREF="#subj1.1">
Nancy Leveson
</A><br>
<A HREF="#subj1.2">
 Nicholas Spies
</A><br>
<A HREF="#subj1.3">
 Herb Lin
</A><br>
<A HREF="#subj1.4">
 Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Hot rodding you AT and the weather 
</A>
<DD>
<A HREF="#subj2.1">
John McCarthy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re:  Good Risks and Bad Risks 
</A>
<DD>
<A HREF="#subj3.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  SDI reliability 
</A>
<DD>
<A HREF="#subj4.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Viruses, Trojan horses, and worms 
</A>
<DD>
<A HREF="#subj5.1">
Herb Lin
</A><br>
<A HREF="#subj5.2">
 PGN
</A><br>
<A HREF="#subj5.3">
 Herb Lin
</A><br>
<A HREF="#subj5.4">
 PGN
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">

</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@uci-icsd">
nancy@uci-icsd
</A>&gt;
</address>
<i>
08 Sep 85 14:58:56 PDT (Sun)
</i><PRE>
Subject: Risks of omissions

I had not intended to get involved in the RISKS Forum discussions, but
despite my great respect for John McCarthy's accomplishments, I just cannot
let his latest message (RISKS-1.8, Sept. 8) pass without comment.

Some important points that need to be considered:

1) Nothing is completely safe.  All activities and technologies involve
risk.  Getting out of bed is risky -- so is staying there.  Nitrates have
been shown to cause cancer -- not using them may mean that more people will
die of food poisoning.

2) Technology is often introduced for the mere sake of using the "latest,"
sometimes without considering the fact that the situation may not really be
improved.  For example, everybody seems to be assuming lately that machines
will make fewer mistakes than humans and there is a frantic rush to include
computers and "artificial intelligence" in every new product.  Where speed
is the determining factor, then they may be right.  Where intelligent
decision making in the face of unforeseen situations and factors is
foremost, then it may not be true.  Some electro-mechanical devices may be
more reliable than computers.  Since I am identified with the area of
"software safety," I am often consulted by those building safety-critical
software systems.  It is appalling how many engineers insist that computers
do not make "mistakes" and are therefore safer than any other human or
electro-mechanical system.  We (as computer scientists) have often been
guilty of condoning or even promoting this misconception.  Often it seems
that the introduction and use of non-scientific and misleading terminology
(e.g. "intelligent," "expert", "proved correct") has far outstripped the
introduction of new ideas.

3)  Technology introduced to decrease risk does not always result in 
increased safety.  For example, devices which have been introduced into
aircraft to prevent collisions have allowed reduced aircraft separation
with perhaps no net gain in safety (although there is a net gain in efficiency 
and profitability).  There may be certain risk levels that people are
willing to live with and introducing technological improvements to reduce
risks below these levels may merely allow other changes in the system which
will bring the risks up to these levels again.

4) Safety may conflict with other goals, e.g. productivity and efficiency.
Technology that focuses on these other goals may increase risk.

John McCarthy suggests that people ignore the risks of not using technology.
I would suggest that it is not that these risks are ignored, but that they
are known and we have learned to live with them while the risks of using new
technology are often unknown and may involve great societal upheaval in
learning to adapt to them.  Yes, wood smoke may cause lung cancer, but note
that recent studies in Great Britain show that the incidence of prostate
cancer in men who work in atomic power plants is many times that of the
general population.  To delay introducing technology in order to assure that
greater risks are not incurred than are currently borne by the population
seems justifiable.  Yes delay may cause someone's death, but the
introduction may cause even more deaths and disruption in the long-run.

The solution is to develop ways to assess the risks accurately (so that
intelligent, well-informed decision-making is possible) and to develop ways
to reduce the risk as much as possible.  Returning to the topic of computer
risk, citizens and government agencies need to be able to make informed
decisions about such things as the safety of fly-by-wire computer-controlled
commercial aircraft or between computer-controlled Air Traffic Control with
human-assistance vs. human-controlled Air Traffic Control with computer
assistance.  To do this, we need to be able to assess the risks and to
accurately state what computers can and cannot do.

Forums like this one help to disseminate important information and promote
the exchange of ideas, But we also need to start new initiatives in computer
science research and practice.  I have been writing and lecturing about this
for some time.  For example,

  1) we need to stop considering software reliability as a matter of
     counting bugs.  If we could eliminate all bugs, this would work.  But
     since we cannot at this time, we need to differentiate between the
     consequences of "software failures."

  2) Once you start to consider consequences of failures, then it is possible
     to develop techniques which will assess risk.  

  3) Considering consequences may affect more aspects of software than just
     assessment.  Some known techniques, such as formal verification and
     on-line monitoring, which are not practical to detect all faults may be
     applied in a cost-effective manner to subsets of faults.  Decisions may
     be able to be made about the use of competing methodologies in terms of
     the classes of faults that they are able to detect, remove, or tolerate.
     But most important, by stating the "software problem" in a different way 
     (in terms of consequences), it may be possible to discover new approaches
     to it.  My students and I have been working on some of these.  Most
     software methodologies involve a "forward" approach which attempts to
     locate, remove, or tolerate all software faults.  An alternative is to
     take a backward approach which considers the most serious failures and
     attempts to determine if and how they could occur and to protect the
     software from taking these actions.

If using some of these techniques (or despite their use), it is determined
that the software would be more risky than conventional systems or is above
a minimum level of acceptable risk, then we can present decision makers with
these facts and force them to consider them in the decision-making process.
Just citing horror stories or past mistakes is not enough.  We need ways of
assessing the risk of our systems (which may involve historical data
presented in a statistically proper manner) and ways to decrease that risk
as much as possible.  Then society can make intelligent decisions about
which systems should and should not be built for reasons of acceptable or
unacceptable risk.

</PRE>
<HR><H3><A NAME="subj1.2">
Risks of omissions
</A>
</H3>
<address>
&lt;<A HREF="mailto:Nicholas.Spies@CMU-CS-H.ARPA">
Nicholas.Spies@CMU-CS-H.ARPA
</A>&gt;
</address>
<i>
8 Sep 1985 12:00-EST
</i><PRE>
To: JMC@SU-AI
Cc: risks@sri-csl

The question of responsibilities for non-use of computers are largely
meaningless in terms of law unless the dangers of non-use were known to
substantially increase the probability of greater harm. In the case of your
three short examples:

(1) If the ACLU had acted in good faith in seeking to limit sharing of
police information and a court had looked favorably on their argument after
weighing the possible risks, then the court is responsible because only the
judge had the ability to decide between two courses of action. To make the
ACLU responsible would be to deny it and its point of view access to due
legal process. To make it necessary for the ACLU to anticipate the court's
response to its bringing suit would have the same chilling effect on our
legal system.

(2) The same argument applies to the Sierra Club and US 101.  If US 101 had
been built and then some people were killed, one could as easily conclude
that the Sierra Club (or anyone else) might be sued for NOT obstructing the
highway!

(3) The "Split Wood not Atoms" poster-vendor might be sued if it could be
conclusively proven that he was a knowing party to a conspiracy to give
people lung cancer. But we might assume that his motivation was actually to
prevent a devastating nuclear accident that might have given 10,000 people
lung cancer...

Again, a risks-of-computers organization can only present its case to court
and people and, so long as no malfeasance is involved, cannot be held
responsible for its failure to predict future consequences. There are far
more important "unsymmetric" relationships than that of the press vs. the
legal system that pertain to issues of responsibility, namely, that of past
vs. future and known vs. unknown. I feel that you are correct in pointing
out how computer people would do well to apply their expertise to solving
problems of society. In this case the moral imperitives are quite clear.

</PRE>
<HR><H3><A NAME="subj1.3">
 Risks of omissions (not using some technology)
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MIT-MC.ARPA">
LIN@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Sun,  8 Sep 85 15:51:44 EDT
</i><PRE>
To: JMC@SU-AI.ARPA
cc: RISKS-FORUM@MIT-MC.ARPA, risks@SRI-CSL.ARPA

    	The problem with a forum on the risks of technology is that
    while the risks of not using some technology, e.g. computers, are
    real, it takes imagination to think of them....

You raise an interesting point that deserves more discussion.
However, as one who is concerned that the major problem arises from an
uncritical acceptance of technology, I strongly disagree with your
suggestion that the scales are stacked AGAINST those who are
"pro-technology".  The reason that anyone adopts any given technology
is that it provides benefits that he can see; the problem is getting
those individuals to see that there are costs as well.  In other
words, the bias in the system is towards acceptance of technology, not
rejection of it.  It is this general bias that "risks" people are
trying to correct.

    ...Is a risk-of-computers
    organization that successfully sues to delay a use of computers either
    MORALLY or LEGALLY LIABLE if the delay causes someone's death?  Is there
    any moral or legal requirement that such an organization prove that they
    have formally investigated whether their lawsuit will result in killing
    people?  As the above examples indicate, the present legal situation
    and the present publicity situation are entirely unsymmetric.

There are such precedents; organizations can be held liable for using
technology that that is not as up to date as is "generally
applicable".  On the more general point, it is much harder to
establish liability as the result of someone's inaction as compared to
the result of someone's action; this does happen, but it is harder to
prove. 

    The harm caused by tape-to-tape batch processing as opposed to on-line
    systems.

I like this example; let's have more discussion of it.  There was a
time when on-line systems were totally unreliable, but I think that
time has past.

    Shouldn't computer professionals
    who pretend to social responsibility take an interest in an
    area where their knowledge might actually be relevant?

This is a cheap shot unworthy of pioneers in computer science.  More
than anyone else, computer professionals are the ones who are in the
best position to assess the limits as well as the promises of
technology.  You once said that the responsibility of the scientist is
to take his science whereever it may lead.  I agreed with you then,
and I agree with that now.  But science is part of a social and
cultural context, and cannot be separated as cleanly as one might
imagine.  If it is proper for the developers of science and technology
to propose new applications of their work (because they see these
potential applications as beneficial to society), it is also
appropriate for them to suggest possible consequences of their use as
well. 

</PRE>
<HR><H3><A NAME="subj1.4">

</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:vax-populi!dparnas@nrl-css.arpa ">
vax-populi!dparnas@nrl-css.arpa 
</A>&gt;
</address>
<i>
Sun, 8 Sep 85 09:06:10 pdt
</i><PRE>
Subject: Risks of omissions; Weizenbaum's message
ReSent-To: risks@SRI-CSLA.ARPA

1.  McCarthy's contribution can be summarized simply,  "Life is 
full of tough decisions about when to use technology; we have to
consider both sides."  Those who have been concerned with the risks
of computer technology have been saying, "There are risks to using
computer technology; we have to consider both sides".  I sense 
agreement on the obvious conclusion.

2.  I can disagree only with one aspect of Weizenbaum's contribution.
He says that he would be against SDI even if it would work, but his arguments
mainly show even more reasons why it won't "make nucelar weapons impotent
and obsolete."  It is probably useless to argue about how we would feel 
about the system if it would work, but I feel the decision would be much 
harder to make than it is now.

    While I would prefer not to waste technological resources on such a thing,
I would see some truth in the argument that the non-technological solutions 
also have a clear risk of failure.  

 Dave

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
Hot rodding you AT and the weather
</A>
</H3>
<address>
John McCarthy 
&lt;<A HREF="mailto:JMC@SU-AI.ARPA">
JMC@SU-AI.ARPA
</A>&gt;
</address>
<i>
08 Sep 85  1108 PDT
</i><PRE>
To:   risks@SRI-CSL.ARPA    

Assuming, contrary to fact, that putting a faster clock
in your AT would cause it to catch fire, the RISKS contributors are
quite wrong about who would be sued.  According to the new legal
doctrine of  bursae profundae,  it isn't the poor BBOARD operator
that would have to pay but rich IBM.  It wouldn't take much of a lawyer
to figure out that IBM should have anticipated that someone might
do this and warned against it or even somehow made it impossible.

Changing the subject, consider the effect of the court decision that
NOAA was liable for not fixing the buoy.  Up to now weather predictions
have been offered as a non-guaranteed service with the user taking
responsibility for the extent to which he relies on it.  The court
has said that this is no longer possible.  Any institution with
"deep pockets" cannot safely offer information on a user responsibility
basis.  What if Stanford University has negligently failed to
replace a stolen book from its medical library, and someone dies
who would have been saved had his doctor found the book?  Stanford's
lawyers should advise Stanford to deny access to its medical library
to practicing physicians.

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">

</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Sun, 8 Sep 85 11:23:16 EDT
</i><PRE>
cc:       BRANDIN@SRI-AI.ARPA
Subject:  Re:  Good Risks and Bad Risks

Another example of "good news/bad news" is the use of
computerized axial tomography (CAT scans) as a substitute for
exploratory surgery in the head and body.

	Advantages:  elimination of much surgical risk;
		     negative diagnoses (disease NOT present) without surgery
		       much lower cost

	Disadvantages:  because of the advantages, CAT scans may be over-used;
		        increased exposure to X-rays which, itself, can be 
                          disease-enhancing

Brint

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
 SDI reliability
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MIT-MC.ARPA">
LIN@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Sun,  8 Sep 85 15:58:27 EDT
</i><PRE>
To: mooremj@EGLIN-VAX.ARPA
cc: RISKS-FORUM@MIT-MC.ARPA, risks@SRI-CSL.ARPA

My primary complaint about your otherwise interesting table is that it
assumes independent failure modes.  I think it is much more likely
that the effects of coupled failures are larger.  In particular, given
the failure of one platform, it is more likely that more than one will
fail.

</PRE>
<A NAME="subj5"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj5.1">
 Viruses, Trojan horses, and worms
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MIT-MC.ARPA">
LIN@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Sun,  8 Sep 85 16:02:40 EDT
</i><PRE>
To: Neumann@SRI-CSL.ARPA
cc: LIN@MIT-MC.ARPA, RISKS-FORUM@MIT-MC.ARPA, RISKS@SRI-CSL.ARPA,
    SIDNEY.G.HAPGOOD@MIT-OZ

    .....  The example of squirreled
    control characters and escape characters that do not print but cause
    all sorts of wonderful actions was popular several years ago, and
    provides a very simple example of how a message can have horrible
    side-effects when it is read.

But if *I* have designed my operating system to display only what it
receives, how is this possible? 

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Viruses, Trojan horses, and worms
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Sun 8 Sep 85 13:35:05-PDT
</i><PRE>
To: LIN@MIT-MC.ARPA

The example of squirreled non-printing characters is of course just 
one example; that one was relatively easy to fix once it was recognized. 
But until you have discovered a flaw, you are vulnerable.  And you never
know how many flaws remain undiscovered.

Sure, *you* may be smart, but large operating systems generally have many
security flaws.  *You* probably aren't smart enough to design and build a
system that has none.  (In fact, your solution is not quite good enough
by itself -- without some other assumptions on the rest of your system.)

Peter

    [By the way, let me add before someone comments, a message that causes
     grief when read would be a Trojan horse.  A message that propagates itself
     -- as in the case of the ARPANET collapse on 27 Oct 1980 -- would be
     a virus.  A BBOARD message that is innocently moved to another system 
     by third parties for others to get clobbered by has aspects of both --
     a virus-propagated Trojan horse .  PGN]

</PRE>
<HR><H3><A NAME="subj5.3">
 Viruses, Trojan horses, and worms
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MIT-MC.ARPA">
LIN@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Sun,  8 Sep 85 16:40:44 EDT
</i><PRE>
To: Neumann@SRI-CSL.ARPA
cc: LIN@MIT-MC.ARPA
In-reply-to: Msg of Sun 8 Sep 85 13:35:05-PDT from Peter G. Neumann &lt;Neumann at SRI-CSLA.ARPA&gt;

    Sure, *you* may be smart, but large operating systems generally have many
    security flaws.  *You* probably aren't smart enough to design and build a
    system that has none.  (In fact, your solution is not quite good enough
    by itself -- without some other assumptions on the rest of your system.)

I certainly recognize that operating systems have security flaws in
them, having been an OS hacker myself at one time.  But for the
problem of messages (as opposed to programs) doing bad things to my
system, I guess I never figured out a way of doing that.

My naive model is that I have a special program that intercepts the
raw bit stream that comes in from my communications port.  It then
translates this into ASCII, and then prints it on my screen.  

If this is all that my program does, I can't see what harm can be
done.

Now, if my program writes the message to disk, then I can see
potential problems.  So I simply count the characters that are sent to
me over the line, and save exactly that many characters on disk.

What am I missing?

</PRE>
<HR><H3><A NAME="subj5.4">
Re: Viruses, Trojan horses, and worms
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Sun 8 Sep 85 14:47:21-PDT
</i><PRE>
To: LIN@MIT-MC.ARPA

Herb, Indeed your model is a bit naive, in that you are looking at the
problem much to narrowly, and assuming that *everything* *else* works fine.
Suppose that your special program would work as you wish in intercepting the
raw bit stream.  Suppose, however, that there is an operating system flaw
that lets me change your special program to do what I wish! (There are many
examples of how this might happen.)  Now your program can be effectively
bypassed.  The point is NOT whether you can seal off one hole, but rather
that you are dealing with the tip of an iceberg and there may be titanic
holes you don't even know about.  Besides, as I said earlier, the message
squirreling is only one example -- and hopefully completely cured.  So I
hope you don't reply that you could use seals to guarantee that your program
is unchanged.  That would still miss the broader point.  PGN

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-18</DOCNO>
<DOCOLDNO>IA012-000128-B042-217</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.9.html 128.240.150.127 19970217000351 text/html 10178
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:02:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 9</TITLE>
<LINK REL="Prev" HREF="/Risks/1.08.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.10.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 9</H1>
<H2>      Monday, 9 Sep 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  McCarthy, Weizenbaum on SDI  
</A>
<DD>
<A HREF="#subj1.1">
Douglas Schuler
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Why I'm against even a reliable SDI 
</A>
<DD>
<A HREF="#subj2.1">
Jeffrey Mogul
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risk Assessment and Risk Management 
</A>
<DD>
<A HREF="#subj3.1">
Edward V. Berard
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risks in displaying a file containing control characters 
</A>
<DD>
<A HREF="#subj4.1">
Keith F. Lynch
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">

</A>
</H3>
<address>
douglas schuler
&lt;<A HREF="mailto:bcsaic!douglas@uw-june ">
bcsaic!douglas@uw-june 
</A>&gt;
</address>
<i>
Mon, 9 Sep 85 09:34:15 pdt
</i><PRE>
Subject: McCarthy, Weizenbaum on SDI

Joseph Weizenbaum states that he would be against SDI "even if it worked."
I agree.  The premise that "IF the SDI could work, then we must have it (at
any price)" is naive.  It seems that many people are willing to accept that
premise hoping that it will anchor the discussion in the technical area.

One factor which is rarely addressed is that of intermediate systems which
the SDI will spawn.  There is a tendency to think of the SDI system as being
one big system that one day appears overhead as a whole, integrated system.
I have little doubt that the SDI plan includes many deliverables along the
way.  These intermediate systems will both be arguably non-defensive and
pose a large problem for integration.  I.e., the system must not only be
trustworthy when "fully deployed" but at a multitude of intermediate steps.
Thus risks will exist in advance of the full delivery (if there ever is to
be one).

Another factor is the so-called defensiveness of the system.  If two people
are armed with guns and one suddenly dons a bullet proof vest this act will
be perceived as an offensive act.

Pro-SDI people almost always accuse SDI critics of being politically
motivated.  Given the immense (and possibly impossible) technical task of
getting the system to work, and the guarenteed proliferation of offensive
weapons (designed to penetrate the system), it is very, very difficult for
me to believe that the pro SDI folk are not motivated primarily from
political (and economic!!) grounds.

  - Doug Schuler

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
Why I'm against even a reliable SDI
</A>
</H3>
<address>
Jeffrey Mogul 
&lt;<A HREF="mailto:MOGUL@SU-SCORE.ARPA">
MOGUL@SU-SCORE.ARPA
</A>&gt;
</address>
<i>
Mon 9 Sep 85 16:40:02-PDT
</i><PRE>
To: risks@SRI-CSL.ARPA

To quote from RISKS Vol 1 #8:
    2.  I can disagree only with one aspect of Weizenbaum's contribution.
    He says that he would be against SDI even if it would work, but his
    arguments mainly show even more reasons why it won't "make nucelar weapons 
    impotent and obsolete."  It is probably useless to argue about how we
    would feel about the system if it would work, but I feel the decision
    would be much harder to make than it is now. [Dave Parnas]

I think this touches on the crux of the matter: what problem is SDI meant to
solve?  If we could guarantee that SDI would not only "make nuclear weapons
impotent and obsolete", but would in fact reduce the risks associated with
war (not necessarily the same thing) then I would not be against SDI.
However, I argue (and I suspect this is Weizenbaum's point, too) that an SDI
that worked according to the current specification would actually increase
risks, even though the system performed "flawlessly".

This is not the place to discuss the strategic implications of SDI, but I
think it's important to realize that there are those of us who believe both
that SDI is not likely to meet its current specification, nor that it would
be a good idea even if it did.

    [I] would see some truth in the argument that the non-technological
    solutions also have a clear risk of failure.  [Parnas]

I am afraid that there is no failure-proof solution, technological or not,
to the problem of "war".  John McCarthy is right that we must compare
the risks of the technological solution (e.g., SDI) to its non-use.  My
fear is that, in this case, the problem is not that the use of technology
might fail to solve the problem, but that it might actually make things
worse.

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">
Risk Assessment and Risk Management
</A>
</H3>
<address>
Edward V. Berard 
&lt;<A HREF="mailto:EBERARD@USC-ECLB.ARPA">
EBERARD@USC-ECLB.ARPA
</A>&gt;
</address>
<i>
Mon 9 Sep 85 08:16:07-PDT
</i><PRE>
To: risks@SRI-CSL.ARPA

There has been some discussion of comparing alternative risks on the
RISKS mailing list lately. For example, what is the risk associated
with the introduction of a new technology versus not introducing the
technology? Risk assessment and risk management need not be
"guesstimates" nor "a number picked out of the air."

The insurance industry has had to assess and manage risks for years.
In fact, they have made quite a science out of these two areas. I
would recommend that those who wish to find out more about risk
management and risk assessment read:

   RISK MANAGEMENT AND INSURANCE, Fourth Edition, by C. Arthur
   Williams, Jr. and Richard M. Heins, McGraw-Hill, 1981.

Don't let the title put you off. Virtually the entire book is
dedicated to risk management, with only a few pages on insurance. You
will also find that there are entire professional societies dedicated
to managing and assessing risk, e.g., the American Risk and Insurance
Association and the Risk and Insurance Management Society.	

  		-- Ed Berard
				   EBerard at ECLB
				   (301) 251 - 1626

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
Risks in displaying a file containing control characters
</A>
</H3>
<address>
Keith F. Lynch 
&lt;<A HREF="mailto:KFL@MIT-MC.ARPA">
KFL@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Mon,  9 Sep 85 00:26:04 EDT
</i><PRE>
To: LIN@MIT-MC.ARPA
cc: Risks@SRI-CSL.ARPA, Security@RED.RUTGERS.EDU

    Date: Sun,  8 Sep 85 16:40:44 EDT
    From: Herb Lin &lt;LIN@MIT-MC.ARPA&gt;

    My naive model is that I have a special program that intercepts the
    raw bit stream that comes in from my communications port.  It then
    translates this into ASCII, and then prints it on my screen.  

    If this is all that my program does, I can't see what harm can be done.

Several kinds of terminals are programmable from the host, in that
certain escape sequences can be sent to them to get them to perform
actions such as defining the terminal's function keys.

If a user inserts the appropriate escape sequences in a mail message
to his system manager, or into a file which will be displayed by the
manager, when the manager reads that mail message it will reprogram
a function key on the manager's terminal, which the manager may have
programmed to do some common harmless function, to instead do some
other command such as give the user unauthorized privileges.

This is a fairly well known bug, and many mail systems are now
protected against it, in that they will not transmit any control
characters or escape sequences to the terminal.

The moral is that there are many subtle ways to break security,
and even things that seem to be quite safe may not really be.
								...Keith

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-19</DOCNO>
<DOCOLDNO>IA012-000128-B042-244</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.10.html 128.240.150.127 19970217000405 text/html 12414
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:02:33 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 10</TITLE>
<LINK REL="Prev" HREF="/Risks/1.09.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.11.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 10</H1>
<H2>      Thursday, 12 Sep 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Weizenbaum, etc.; even if SDI worked.... 
</A>
<DD>
<A HREF="#subj1.1">
John Shore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  SDI 
</A>
<DD>
<A HREF="#subj2.1">
John McCarthy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  More on SDI reliability 
</A>
<DD>
<A HREF="#subj3.1">
Martin Moore
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">
Weizenbaum, etc.; even if SDI worked....
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
12 Sep 85 11:11:13 EDT (Thu)
</i><PRE>
From: John Shore &lt;epi-dc!shore@nrl-css.arpa&gt;

It's tempting to respond to Weizenbaum by arguing against the general
proposition, "Don't do it if there's a way around it".  After all, should we
refuse to develop bullet proof vests and to equip police officers with them
just because a criminal might approach from behind and stab them in the ass?

Assuming that a proposed defensive system will work, the relevant question
is what is the cost of developing it compared to the cost of getting around
it?

In the case of SDI, one should distinguish between defense against a few
missiles vs. defense against a massive attack.  Either defense would be
enormously expensive to develop.  If the goal of the attacker is to detonate
a few bombs (or threaten to do so), then it is obviously easier and cheaper
to get around SDI than through SDI.  Here, Weizenbaum is probably right.  If
the goal is massive or total destruction (including destruction of our
missile forces), then getting around SDI (assuming SDI works) does not
appear to be either easy or inexpensive.  Here, Weizenbaum is probably
wrong.  In this case, however, the premise is most likely also wrong.

Moreover, suppose that the premise is right -- i.e. SDI works perfectly.  As
Parnas has pointed out, there's no way for anyone to establish this fact,
which shows the absurdity of arguments like "give us SDI and we will
dismantle our missiles".

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
SDI 
</A>
</H3>
<address>
John McCarthy 
&lt;<A HREF="mailto:JMC@SU-AI.ARPA">
JMC@SU-AI.ARPA
</A>&gt;
</address>
<i>
12 Sep 85  0057 PDT
</i><PRE>
To:   risks@SRI-CSL.ARPA    

	Some remarks of mine about SDI on Stanford BBOARD have been referred
to.  For the benefit of non-readers of that BBOARD, they mainly concerned
whether I, like Chris Stuart, should use the IJCAI platform to say something
about it.  I said nothing in my lecture, but in my press conference, added
to my remarks on AI, the remark that there was no principle of computer
science that says that programs of any particular task cannot be written and
debugged.  Not much interest was shown by the assembled press; there was
exactly one question on that point.

	At the suggestion of Robert Jastrow, who is one of the main
scientific defenders of SDI, I made the same point in letters to three
Congressmen, said to be influential in the matter of SDI appropriations.

	Now I shall say my opinion about SDI.

	1. If it can be done, it should.  If it affords complete protect,
that's great, and if it affords partial protection, that's good.  The
balance of terror is a bad thing.  Here are answers to some counter
arguments to its desirability.  (a) Joe Weizenbaum says that it attempts a
technological solution to a problem that should be solved morally.  Alas,
moral progress has been so slow that almost the only moral problems to be
even partially solved are those that can at least partially been turned into
technological problems.  For example, the technology of contraception has
greatly reduced human unhappiness.  (b) It is argued that the Soviets would
have to attack at the first sign of deployment.  Every past imminent advance
by either side has in principle given the other side some temptation to
strike before it can be deployed.  So far as we know, neither side has even
come close to giving in to such temptation.  One reason is that the effect
of any advance is always subject to a probabilistic estimate, so temporizing
has always looked better than attacking.  Even if SDI works very well, it
may be that no-one will be able to be sure that it is that good.

	However, most likely the main reason has been is that neither side
ascribes the very worst intentions to the other with certainty.  Each side
has always said, "Perhaps they don't actually mean to attack us.  Why have a
nuclear war for sure instead of only a certain probability?"  Anyway the
Soviets have experienced a period in which we had complete nuclear
superiority and didn't attack them.

2. My opinion is that if the physics of the problem permits a good
anti-missile defense the programs can be written and verified.  However, it
will be quite difficult and will require dedicated work.  It won't be done
by people who are against the whole project.  Computer checked proofs of
program correctness will probably play some role.  So will anticipating what
kind of bugs would be most serious and putting the biggest effort into
avoiding them.  Having many people go over and discuss all the critical
parts of the program will also be important.

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">
More on SDI reliability
</A>
</H3>
<address>
&lt;<A HREF="mailto:mooremj@EGLIN-VAX">
mooremj@EGLIN-VAX
</A>&gt;
</address>
<i>
Tue, 10 Sep 85 13:56:45 CDT
</i><PRE>
To: risks@sri-csl.arpa
Cc: soft-eng@mit-xx, lin@mit-mc, mooremj@eglin-vax

&gt; From: Herb Lin &lt;LIN@MIT-MC.ARPA&gt;
&gt; My primary complaint about your otherwise interesting table is that it
&gt; assumes independent failure modes.  I think it is much more likely
&gt; that the effects of coupled failures are larger.  In particular, given
&gt; the failure of one platform, it is more likely that more than one will
&gt; fail.

Good point.  My original post did concern only statistically independent
failures.  If I can be forgiven one more table, I'll address coupled failures.

Independent failures are caused by events isolated to a single platform,
e.g., electrical component failures.  The occurrence of such a failure in
platform J does not affect the probability of a similar failure in platform K,
i.e., P(K|J) = P(K|~J) = P(K).

Coupled failures are failures such that the probability of failure is low in
any platform, but is greatly increased in all platforms when it occurs in
any one of them.  For example, consider that a hostile power might develop a 
new method for its missiles to escape detection.  The probability that it will 
fool any one platform may be low; but if it fools one platform it is likely to
fool more than one, perhaps all.  For arbitrary platforms J and K, P(K|J) &gt;&gt;
P(K|~J). 

The original false positive table is not affected by this, since it showed 
the probability that at least one platform would fail.  Coupled failures
do not change that probability, only the probability that if one fails, others 
will (although it is true that while this country might be able to explain
away a single false positive, explaining a whole bunch of them could be a lot 
tougher!)

The false negative case is where the kicker really comes in.  The original
false negative table applies to independent failures.  The following table
is structured similarly, but instead of using the probability of failure (Pn),
it uses the degree of coupling, Pn(K|J).  This table shows, for a 100-platform
system, the probability of various numbers of successful responses, given
that at least one system has experienced a coupled failure.

Pn(K|J):  .5      .6      .7      .8      .9      .95     .99
      +-------------------------------------------------------
N:  0 | 1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000
    5 | 1.0000  1.0000  1.0000  1.0000  0.9746  0.5550  0.0033
   10 | 1.0000  1.0000  1.0000  0.9973  0.5355  0.0265  0.0000
   15 | 1.0000  1.0000  0.9998  0.9123  0.0677  0.0001  0.0000
   20 | 1.0000  1.0000  0.9896  0.5200  0.0017  0.0000  0.0000
   25 | 1.0000  0.9993  0.8740  0.1204  0.0000  0.0000  0.0000
   30 | 1.0000  0.9822  0.5116  0.0097  0.0000  0.0000  0.0000
   35 | 0.9988  0.8525  0.1465  0.0003  0.0000  0.0000  0.0000
   40 | 0.9781  0.5054  0.0176  0.0000  0.0000  0.0000  0.0000
   45 | 0.8426  0.1574  0.0008  0.0000  0.0000  0.0000  0.0000
   50 | 0.5000  0.0219  0.0000  0.0000  0.0000  0.0000  0.0000
   55 | 0.1574  0.0013  0.0000  0.0000  0.0000  0.0000  0.0000
   60 | 0.0219  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
   65 | 0.0012  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
   70 | 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000

For example, if the degree of coupling is 0.7 -- that is, if something that
causes failure in one platform has a 70% chance of causing failure in any
other platform -- then the probability is 51.16% that at least 30 of 100
platforms will respond correctly, 14.65% that at least 35 will, and so on,
GIVEN THAT THIS TYPE OF FAILURE OCCURS IN THE "FIRST" PLATFORM.  Don't forget
that the probability that the first platform will fail is UNRELATED to the
probabilities in this table! 

As far as the relative probabilities of independent and coupled failures,
I haven't a clue.  The independent failures are the easiest to get a handle
on through reliability theory; the coupled failures may be the result of
unknown shortcomings in design, or due to unknown hostile actions.  (There
is an old saying that there are always more unknown errors than known errors,
because known errors are limited, but unknown errors are unbounded by 
definition!)
                                            Martin Moore
                                            mooremj@eglin-vax.arpa

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-20</DOCNO>
<DOCOLDNO>IA012-000128-B042-272</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.11.html 128.240.150.127 19970217000433 text/html 18023
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:02:55 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 11</TITLE>
<LINK REL="Prev" HREF="/Risks/1.10.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 11</H1>
<H2>Friday, 13 Sep 1985</H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
Peter G. Neumann, moderator
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  SDI and John McCarthy 
</A>
<DD>
<A HREF="#subj1.1">
Charlie Crummer
</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">SDI and
Safeguard</A>
<DD>
<A HREF="#subj2.1">
John Mashey
</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A
HREF="#subj3">SDI and Robert Jastrow</A>
<DD><A HREF="#subj3.1">Herb Lin</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">Some
financial disaster cases from Software Engineering Notes</A>
<DD><A HREF="#subj4.1">three contributions totalling five reports</A>
</DL>
<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1"></A>
</H3>
<ADDRESS>Charlie Crummer &lt;<A HREF="mailto:crummer@AEROSPACE.ARPA">crummer@AEROSPACE.ARPA</A>&gt;
</address>
<i>
Thu, 12 Sep 85 19:00:29 PDT
</i><PRE>
Subject: SDI and John McCarthy

&gt;Date: 12 Sep 85  0057 PDT
&gt;From: John McCarthy &lt;JMC@SU-AI.ARPA
&gt;Subject: SDI 
&gt;To:   risks@SRI-CSL.ARPA    
&gt;
&gt;... there [is] no principle of computer
&gt;science that says that programs of any particular task cannot be written and
&gt;debugged.  

  Computer Science does not contain or deal with the principles operative 
  in the writing and debugging of large, nay, HUGE, eclectic, software 
  programs.  This is the realm of Software Engineering.  By a similar token
  there is no principle of the theory of random processes that says that
  the works of Shakespeare cannot be written by 1,000,000 monkeys pounding
  1,000,000 typewriters either, in fact in principle that would be one way
  of reproducing these works.  No serious student of Shakespeare who knew
  something about random processes would propose such an undertaking, of 
  course.  A mathematician who knew nothing about typewriters and little
  about Shakespeare, however, might if Ronald Reagan pursuaded him that
  the problem should be worked by assigning 1,000,000,000,000 monkeys to
  1,000,000,000,000 typewriters.  In software engineering as well as 
  mechanical engineering there is the concept of feasibility to be considered.


 
&gt;	Now I shall say my opinion about SDI.
&gt;
&gt;If it can be done, it should.

  If you had a gun wouldn't you be more afraid to face a gunman with
  a bullet-proof vest than one without?  If he began deliberately to
  put this vest on as he stood before you with his gun leveled at you
  wouldn't you be inclined to fire before he got the vest on?

&gt;If it affords complete protection that's great, 
&gt;and if it affords partial protection, that's good.

  You speak in the present tense but "it" does not exist!  How can
  a non-existence afford anything?  At least one of the basic questions
  is whether it can be made at all.

&gt;The balance of terror is a bad thing.  

  Yes, and SDI would only enhance the terror.  The "civilized" world has
  no defensive answer to the terrorists in such mundane places as on airliners,
  let alone in space, and such is not in the offing.

&gt;Here are answers to some counter
&gt;arguments to its desirability.  (a) Joe Weizenbaum says that it attempts a
&gt;technological solution to a problem that should be solved morally.  

  MUST be solved between the terrorizer and terrorizee.  When someone's
  out to get you there's no place to hide.  (D. Corleone)

&gt;Alas,
&gt;moral progress has been so slow that almost the only moral problems to be
&gt;even partially solved are those that can at least partially been turned into
&gt;technological problems.  

  Not true, viz. cannibalism and slavery.

&gt;For example, the technology of contraception has
&gt;greatly reduced human unhappiness.  

  What evidence do you have of that?

&gt;(b) It is argued that the Soviets would
&gt;have to attack at the first sign of deployment.  Every past imminent advance
&gt;by either side has in principle given the other side some temptation to
&gt;strike before it can be deployed.  So far as we know, neither side has even
&gt;come close to giving in to such temptation.  One reason is that the effect
&gt;of any advance is always subject to a probabilistic estimate, so temporizing
&gt;has always looked better than attacking.  Even if SDI works very well, it
&gt;may be that no-one will be able to be sure that it is that good.

  You may be safe in saying that but I hope our leaders are not so cavalier.
  Most serious strategy is based on "worst case" scenarios.

&gt;	However, most likely the main reason has been is that neither side
&gt;ascribes the very worst intentions to the other with certainty.  Each side
&gt;has always said, "Perhaps they don't actually mean to attack us.  Why have a
&gt;nuclear war for sure instead of only a certain probability?"  Anyway the
&gt;Soviets have experienced a period in which we had complete nuclear
&gt;superiority and didn't attack them.
&gt;
&gt;2. My opinion is that if the physics of the problem permits a good
&gt;anti-missile defense the programs can be written and verified.  However, it
&gt;will be quite difficult and will require dedicated work.  It won't be done
&gt;by people who are against the whole project.  Computer checked proofs of
&gt;program correctness will probably play some role.  So will anticipating what
&gt;kind of bugs would be most serious and putting the biggest effort into
&gt;avoiding them.  Having many people go over and discuss all the critical
&gt;parts of the program will also be important.
&gt;

  Whether the physics of the problem admits a good anti-missile defense
  is a paramount question.  It will take much more than dedicated climbing
  of the automatic proof of correctness "tree" to get to the "moon" of
  an "astrodome" over the U.S. a la Reagan's definition of strategic
  defense.


  --Charlie

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">

</A>
</H3>
<ADDRESS>
John Mashey
&lt;<A HREF="mailto:mips!mash@glacier ">
mips!mash@glacier 
</A>&gt;
</address>
<i>
Thu, 12 Sep 85 22:56:02 pdt
</i><PRE>
Subject: SDI and Safeguard

I used to work with many of the people at Bell Labs who worked on the
Safeguard ABM; they were competent people who knew how to build complex
systems.  Maybe there were some who believed that it was actually possible
to build a reliable, deployable, maintainable ABM that one could expect to
work in real use; if so, I never met any; most folks did not so believe,
and said so. [They did believe that you could shoot down missiles in
well-controlled tests, because they'd done it; they just didn't believe
it would work when it needed to.]

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">
 SDI and Robert Jastrow
</A>
</H3>
<ADDRESS>
Herb Lin 
&lt;<A HREF="mailto:LIN@MIT-MC.ARPA">
LIN@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Thu, 12 Sep 85 20:08:22 EDT
</i><PRE>
To: JMC@SU-AI.ARPA
cc: LIN@MIT-MC.ARPA, risks@SRI-CSL.ARPA

    From: John McCarthy &lt;JMC at SU-AI.ARPA&gt;

    	At the suggestion of Robert Jastrow, who is one of the main
    scientific defenders of SDI, I made the same point in letters to three
    Congressmen, said to be influential in the matter of SDI appropriations.

Robert Jastrow is certainly a defender of the SDI, but he has admitted
publically in his own Congressional testimony that he does NOT carry
out scientific analyses of anything related to SDI.  He hardly counts
as a "scientific defender."

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
Some financial disaster cases from Software Engineering Notes
</A></H3><ADDRESS>Peter G. Neumann &lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA</A>&gt;</address>
<i>Fri 13 Sep 85 00:22:19-PDT</i>
I hope that the RISKS Forum will not degenerate into only an SDI Forum, so I
thought I would counterbalance this issue with a new topic.  I have
resurrected a contribution from the July 1985 SIGSOFT SEN, and also preview
some newer cases that will appear in the October 1985 SEN (which is just
about ready to go to press).  (The few of you who are ACM SIGSOFT members
please pardon me for the duplications.)
<P>
[FROM ACM Software Engineering Notes vol 10 no 3, July 1985]
<P>
Disasters Anonymous 1: A Rose is Arose is (Three) Z-Rose
<P>
Now and then I get a story that I cannot print.  (I do have a few, but don't
ask.  I have of course conveniently forgotten them all.)  Here, is one that can
be printed -- although its author must remain anonymous.  Note that the case of
the three extra zeroes resulting from two different assumptions about the human
interface bears an eerie resemblance in cause to the case of the shuttle laser
experiment, which follows after this one.  [PGN]
<BLOCKQUOTE>
  A group within my company had a policy of dealing only in multiples
  of one thousand dollars, so they left off the last three digits in
  correspondence to the wire transfer area to make their job easier.
  Other groups, however, had to write out the full amount since they did
  not always deal with such nice round numbers.  One day, a transaction
  was processed that had a value of $500,000.  The person who entered the
  transaction thought that it was from the group who dealt in multiples
  of $1000 and entered it as $500,000,000.  Of course, this was not the case,
  so a $500,000 transaction became a $500,000,000 one.
<P>
  The only thing that prevented a disaster was that it was sent to a small
  company that called back to verify the amount, and the error was then
  caught.  However, this was a Federal Reserve transaction and the funds
  had been transferred, but the timing was good and the transaction was
  backed out before it became a disaster.  My opinion is that such critical
  software should have caught the error before the wire was sent to the
  Federal Reserve.
<P>
  Another error in a Federal Reserve transfer had to do with multiple
  transactions per communications transfer.  In this case, the Federal
  Reserve software put a pair of nulls in the data that should have been
  translated as blanks.  However, they were stripped out and a $200,000,000
  incoming wire lost.  To maintain the Fed balance, money was purchased
  to cover a deficit that didn't exist -- since the money was a credit.
  This was a substantial monetary loss because of inadequately tested
  software.
</BLOCKQUOTE>
[FROM ACM Software Engineering Notes vol 10 no 5, October 1985]
<P>
Disasters Anonymous 2: Financial Losses
<P>
Our anonymous contributor from SEN 10 3 (July 1985) has come through again.
<BLOCKQUOTE>
  Since I sent some disaster reports to you in May, another one has occurred.
  This one caused some financial loss and acute headaches among managers.
<P>
  Most large banks subscribe to the Federal Reserve's funds transfer system,
  frequently referred to as "Bankwire".  Our system that connects to Fedwire
  was being upgraded with a new DDA interface to the host to help protect
  against overdrafts.  During a review, it was determined that the software
  was not quite ready, but should be okay to put into production two days
  later.  I cautioned them against doing so since not all of the bugs had been
  resolved, and the software had not been "stress tested" (or whatever phrase
  you wish to use about testing that ensures that it will work in production).
<P>
  The first day of production went fine.  However, the main file in the new
  software was an ISAM file that had degraded significantly during the first
  day.  On the second day, that file continued to fragment and started to
  consume a large amount of the system resources.  This slowed response time
  so much that by the end of the banking day, we still had hundreds of wires
  to send to the Federal Reserve.  We had to request extensions every half
  hour for hours to try and squeeze the transactions through the system so
  that the money would get to our customers.
<P>
  In addition, the response-time problem and other bugs in the software
  prevented us from knowing our Federal Reserve balance.  Since we must
  maintain some 150 million dollars in our Fed "checking account", this lack
  of information could cause significant financial loss as 1.5 billion dolars
  were posted that day and we were off by hundreds of millions of dollars at
  first.
<P>
  Another part of this disaster is that the slow response time caused one
  program to assume that the host was down.  When a transaction finally went
  through, our system would transmit the DDA information, but the host did not
  acknowledge that they already had the wire.  Thus a large number of wires
  were being "double posted" (money sent twice).  At the end of the day, tens
  of millions had been double posted.
<P>
  As of this writing, the Fed balance had been straightened out, but not all
  of the double postings had been recovered.  Note that at current interest
  rates, a bank loses $350 per day per million dollars of unused money.
</BLOCKQUOTE>
[FROM ACM Software Engineering Notes vol 10 no 5, October 1985]
<P>
Disasters Anonymous 3: Insurance, Reinsurance, and Rereinsurance
<P>
Perhaps anonymity is contagious.  Re: reinsurance, here is
another letter from a different contributor. 
<BLCOKQUOTE>
  I'm newly receiving SEN and found the ``war stories'' quite interesting.
  Here are three more.  I would prefer anonymity should you choose to print 
  these.
<P>
  This first is hearsay (from a former co-worker).  Apparently he and his
  wife had a joint account with a $300 balance.  They needed $200 in cash, but
  due to miscommunication they both made $200 withdrawals - she at a teller's
  window (cage?) and he at an ATM (automatic teller machine) - within minutes
  of each other.  When the dust settled they found that their account had a
  zero balance:  the first $200 withdrawal left a $100 balance, the second
  should have left a negative balance of $100, but the computer generated a
  $100 credit to offset the shortfall.  The icing on the cake was my friend's
  inability to explain/convince the bank of this situation and have them accept
  restitution.
<P>
  I need to be circumspect about this second story -- it might well have
  involved fraud.  While a consultant, I was hired to review a reinsurance
  agreement.  The reinsurance industry is an old-boys, ``handshake is my bond''
  industry as insurors frequently offset their risk by selling it (reinsuring)
  to other insurors.  That is, I insure your building for $10,000,000 and
  re-sell all or part of that risk to another firm.  Apparently, late one
  Monday morning (nearly 11:00 a.m. EST), my client got notice across his
  computer network from another firm that it was reinsuring (i.e. off-loading
  risk) to my client to the tune of several million dollars.  The message was
  time-dated Friday evening (6:00 P.M., WST).  As ``luck'' would have it the
  property in question had suffered a catastrophic loss over the weekend.  The
  bottom line was that the message had been sent directly (not through any of
  the store-and-forward services) and the time-date was thus determined by the
  clock-calendar on the sender's computer.  Need I say more?
<P>
  Finally, a story told to me ``out of school'' by a friend at one of the
  nation's largest insurance companies.  They apparently are involved in so
  many reinsurance deals that it turned out that they were reinsuring
  themselves.  I.e., Jones reinsured with Smith who reinsured with Brown who
  reinsured with White who reinsured with Smith.  Smith, it turned out was
  paying both Brown and White commissions for accepting his own risk.  The
  computer system was not designed to look beyond the current customer,
  neglecting the loop.
</BLOCKQUOTE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-21</DOCNO>
<DOCOLDNO>IA012-000128-B042-292</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.12.html 128.240.150.127 19970217000507 text/html 379
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:03:32 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML>
<HEAD>
<TITLE>Risks Digest</TITLE>
</HEAD>
<BODY>
<H1>Bad request</H1>
"/RISKS/1.12.html" is not a valid issue of Risks.
<HR>
<ADDRESS>
<A HREF="http://catless.ncl.ac.uk/Lindsay.html">Lindsay.Marshall@newcastle.ac.uk</A>
</ADDRESS>
</BODY>
</HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-22</DOCNO>
<DOCOLDNO>IA012-000128-B042-311</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.13.html 128.240.150.127 19970217000528 text/html 14888
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:03:56 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 13</TITLE>
<LINK REL="Prev" HREF="/Risks/1.12.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.14.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 13</H1>
<H2>    Saturday, 14 Sep 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Risks in RISKS 
</A>
<DD>
<A HREF="#subj1.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Preserving rights to Email messages 
</A>
<DD>
<A HREF="#subj2.1">
Larry Hunter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risk Comparisons 
</A>
<DD>
<A HREF="#subj3.1">
T. Tussing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risks history/philosophy 
</A>
<DD>
<A HREF="#subj4.1">
Nicholas Spies
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">

</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Sat 14 Sep 85 23:18:42-PDT
</i><PRE>
Subject: Risks in RISKS 

The text of the message that follows this one is taken verbatim from the
HUMAN-NETS Digest (HUMAN-NETS@RUTGERS), 11 Sep 1985, Volume 8 : Issue 29, on
the topic of risks in EMAIL.  That topic is of vital significance to the
RISKS Forum, for at least two reasons:

  (1) You should recognize the risks that might be incurred by you in 
      submitting messages to this forum, and in sending on-line messages 
      in general.

  (2) The free propagation of messages not copyrighted can itself lead
      to significant risks to the contributor and to the RISKS Forum,
      if those messages were false or libelous, or if they are altered.

In general, you and I must assume that any message on this forum may be
forwarded indefinitely and read by anyone, and could appear in print in all
sorts of strange places.  (If something worthy of inclusion in the ACM
Software Engineering Notes is at all controversial, I ask for explicit
permission before publishing it.)

What is even RISKIER is that your message can be trivially altered along the
way as it traverses the network of networks, possibly drastically changing
your intended meaning.  Use of check sums and crypto seals can reduce the
risk of undetected alteration, but does not solve the problem entirely.

Peter G. Neumann 

(This message is not copyrighted.)

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
preserving rights to Email messages.
</A>
</H3>
<address>
Larry Hunter 
&lt;<A HREF="mailto:Hunter@YALE.ARPA">
Hunter@YALE.ARPA
</A>&gt;
</address>
<i>
Tue, 3 Sep 85 11:08:31 EDT
</i><PRE>

Copyright-by: Larry Hunter, 1985

After consulting with several lawyer friends, the conclusion I
reach is that anything you send out over the nets is public
property -- ie, anyone can reproduce it verbatim, for profit
and the author has no right to control its use.  There is,
however, a very simple way to preserve the author's rights to
control the use his messages are put to.  The courts have
held that practically any clear attempt of an author to
preserve his/her rights to a written work are sufficient
to actually preserve them.  No need to add the 'circled c'
to ASCII, just add a 'Copyright-by:' line to the header of your
local mailer and voila! your rights are preserved.

                                               Larry

PS. I am not a lawyer and this is only my opinion - if you have
a vital interest in some related matter, talk to a real lawyer!

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">

</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
13 Sep 85 13:27:12 PDT (Friday)
</i><PRE>
From: TTussing.es@Xerox.ARPA
Subject: Risk Comparisons
To: RISKS@SRI-CSL.ARPA

Someone sent me this and I thought the people on this mailing list might
be interested.

Excerpt from a pamphlet by Dow Chemical Corp, entitled Life is in the
Balance:

Dr. richard Wilson, who is professor of physics at Harvard, has devised
a mathematical formula that measures risks in terms of the minutes and
seconds of life lost.  Taking the average person of 30 who has a
life-span in the United States of approximately 73 years, Wilson says
that statistical person cuts time from his life in the following ways:

Smoking one cigarette - minus 12 minutes
Drinking a diet soft drink - minus about 9 seconds
Driving without a seat belt - 6 seconds for each trip
Being an unmarried male - minus 1800 days
Being male rather than female - minus 2700 days

We can also view risks by figuring which risks are qeual.  For example,
the following items all pose an equal risk of increasing the likelihood
of death by one chance in a million:

Drinking half a liter of wine
Spending three hours in a coal mine
Living two days in New York
Traveling six minutes by canoe
Riding 10 miles on a bicycle
Driving 300 miles in a car
Flying 1000 miles by jet

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
Risks history/philosophy
</A>
</H3>
<address>
&lt;<A HREF="mailto:Nicholas.Spies@CMU-CS-H.ARPA">
Nicholas.Spies@CMU-CS-H.ARPA
</A>&gt;
</address>
<i>
14 Sep 1985 01:06-EST
</i><PRE>
To: risks@sri-csl

This is definitely old news, but then again the facts behind the case have
only recently seen the light of day. In his recent biography "Alan Turing:
the enigma" (Simon &amp; Schuster) Andrew Hodges reveals in some detail the
inner workings of the German Enigma encryption device (arguably a
"computer") which contributed (backhandedly) to the development of computers
as we know and love them today. (If you're interested in Turing, computers
or WWII history read it, if you haven't already.)

The portion of the book devoted to Turing's stint at Bletchley Park is
peppered with lost opportunities on the German side.  Apparently with little
additional effort the Germans could have rendered the "Bletchley bombes"
completely useless. In fact the only reason the Germans were not careful was
their unswerving faith in the Enigma device. Even when there was ample
evidence pointing to a message-security problem the integrity of Enigma was
never seriously questioned by the Germans. There were, of course, countless
other factors, but the German faith in their technological answer was in
large measure responsible for their losing the U-boat war and very likely
the war itself.

Another anecdote, not related to computers (recounted in either "The Ultra
Secret", Winterbotham or "Bodyguard of Lies", A. Cave Brown, two other
excellent books on the secret war) gave one reason for the German atomic
bomb project not really getting off the ground.  It seems that a German
professor of the old school was in charge of finding a material for
moderating a chain reaction (by absorbing neutrons). Graphite was tried but
failed which meant that deuterium (heavy water) was thought to be needed.
When it was suggested that the graphite might not be pure enough (which, as
it turned out, was the reason the test failed) the professor reacted with
rage that his authority was being questioned and he effectively derailed
German research in reactor design. (Later the plant for making heavy water
built in Norway was sabotaged by British agents which made a reactor
impossible which preventing the manufacture of fissile material.)

These examples suggest that excessive reliance on either technological
solutions or "authoritative opinion" may carry grave risks, albeit in these
cases for an evil regime. The question facing us is whether we (or the
Soviets, for that matter) have fallen into the same traps. I would say that
we (both) definitely have, for the means to power are now more than ever
technological (as opposed to political or diplomatic) and one or another
"expert" is routinely trotted out to "prove" the efficacy of this or that
technological scheme.

Indeed, how can it be otherwise? Hitler opened the Pandora's Box of applying
high-tech to warfare and it worked (at least until a higher-tech response
prevailed). After WWII a new era was born in which global political power no
longer rested on moral authority but on a command of the new applied
sciences and scientists. Engineers had provided political leaders with
instruments of war for centuries, but now scientists are looked upon as the
fountainhead of political power, by dictators, politicians and the people
alike. It may now be said truly that Knowledge is Power.

To some the risks of technology are the inevitable consequence of the
inexorable "progress" that technology itself represents. It seems to me that
this view places too great an emphasis on the growth of "technology" itself
at the expense of our ability to integrate it with human wants and needs.
It's almost to say that "technology" has a virtual life of its own that we
have no control over. This is manifestly untrue because "technology" is the
mere summation of the creative acts and compulsions of a great number of
people enamored of the idea of "technology". But if "technology" does have a
life of its own it must be based on a willing denial of responsibility on
the part of each member involved in furthering it, particularly when large
populations or the world are put at risk by introducing a new "technological
development". It seems, therefore, self-evident that morality and technology
are intimately interwoven.

In the largest sense, the risks of computers are the risks of having an
increasing number of computer experts that are in a position to tell people
what computers can be safely used for.  Their expert opinions may be well
thought out or erroneous, as the case may be, but they are in fact the only
opinions that the public, financial institutions, military establishments or
politicians can depend on. The fact that any or all may place a value on
this expert information and act on it puts a heavy moral burden on the
providers of this information, whether they like it or not.

The only population that I have had direct contact with who have faced this
primal issue of the risks of technology are the Amish-Mennonites of Ontario;
I made a film about their 150th Anniversary in Canada. (I have also edited
films about the Amish in Lancaster Co., PA.) The trigger for the Amish was
rubber-tired wheels on carriages around the 1870's because this allowed the
young of courting age to "go to town" more easily, with a perceived
disruption of Amish life not far behind. To this "improvement" they said
"No". Subsequently, the Amish have taken great care to keep the increasing
technological developments surrounding them at bay, but not by pure
rejection. In short, they have evaluated the risks of adopting technologies.

For instance, gasoline engines are permitted for stationary use (and also on
horse-drawn wagons) for harvesting, threshing, bailing and for powering milk
refrigerators.  There's no contradiction in using a valuable power source so
long as it isn't applied to providing the means for increased contact with
the outside world. Electricity is used if generated within the farm; and
public telephones may be used as well; as long as wires (i.e. connections)
to the outside world are avoided there is no reason to avoid using the
technology. The oddity of the Amish is based on common sense when their
objectives are known.

Although the Amish reaction to technology may strike many as merely "quaint"
they do show that it is possible to stop short the "inevitable" growth of
technology. (The Amish are renowned for their success in farming, which is
not the case for many others that have embraced modern technological ways.)

I am not advocating a general return to Amish ways (indeed this only makes
sense within the context of Amish values), but I will say that we all face a
similar confrontation with a technology that may do us great harm on many
fronts.  Unfortunately we are prone to treat our own creations (be they
buildings, cars, chemicals or computers) as if they are as benevolent as the
products of 5 billion years of co-adaptive evolution. As increasingly
complex and interdependent as our creations become, the more they will
reveal themselves as ill-suited to the tasks they were meant to perform; it
only stands to reason because of the lack of a truly global feedback in the
design process. And also, how are we to judge the efficacy of our machines
if we have lost sight of the reason we have created them?

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-23</DOCNO>
<DOCOLDNO>IA012-000128-B042-341</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.14.html 128.240.150.127 19970217000544 text/html 15529
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:04:14 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 14</TITLE>
<LINK REL="Prev" HREF="/Risks/1.13.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.15.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 14</H1>
<H2>      Monday, 16 Sep 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Pitfalls of a Fail-Safe Mail Protocol? 
</A>
<DD>
<A HREF="#subj1.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Some Ruminations on an Ideal Defense System 
</A>
<DD>
<A HREF="#subj2.1">
Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  SDI, feasibility is irrelevant 
</A>
<DD>
<A HREF="#subj3.1">
Gopal
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">
Pitfalls of a Fail-Safe Mail Protocol?
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Mon 16 Sep 85 20:25:57-PDT
</i><PRE>
To: RISKS@SRI-CSLA.ARPA

After reading the case of the double posting of hundreds of millions of
dollars in <A HREF="/Risks/1.11.html">RISKS-1.11</A>, some of you apparently experienced the multiple
posting of <A HREF="/Risks/1.13.html">RISKS-1.13</A> -- all original mailings time-stamped Sat 14 Sep 85
23:43:07-PDT, all complete, and all identical.  Brint Cooper, for example,
received THREE identical copies at various time intervals.

  Received: from brl-aos.arpa by TGR.BRL.ARPA id aa20274; 15 Sep 85 3:23 EDT
  Received: from sri-csl.arpa by AOS.BRL.ARPA id a017885; 15 Sep 85 3:18 EDT

  Received: from brl-aos.arpa by TGR.BRL.ARPA id a021160; 15 Sep 85 4:47 EDT
  Received: from sri-csl.arpa by AOS.BRL.ARPA id a018065; 15 Sep 85 4:35 EDT

  Received: from brl-aos.arpa by TGR.BRL.ARPA id a022055; 15 Sep 85 6:31 EDT
  Received: from sri-csl.arpa by AOS.BRL.ARPA id a018257; 15 Sep 85 6:17 EDT

The new ARPANET message protocols are supposed to be fail-safe (never losing
a message, retrying sensibly after a failure, and eventually returning
undeliverable mail with a NAK), network-efficient (transmitting single
copies to each host and letting that host redistribute), and reliable (never
garbling a message) -- although they cannot guarantee message authenticity
in the presence of tampering.

After consulting with my Foonly-TOPS-20 gurus (Geoff Goodfellow, Mark
Lotter, and Dwight Hare), we discovered that just after I mailed <A HREF="/Risks/1.13.html">RISKS-1.13</A>
late Saturday night, Foonly's David Poole brought our system down and up
(several times?) after midnight PDT for installation of a 100% memory
increment.  Each time he brought it back up, the mailer seems to have
restarted sending some of the previously queued messages -- how many I do
not know.  It is NOT SUPPOSED TO DO THAT, but that is the most plausible
explanation at the moment.  If you again receive multiple copies, please
remail them back in their entirety to Geoff@SRI-CSL (and we'll hope that you
don't blow his mailbox).  Geoff insists the protocol is sound, so let's let
him in on the glitch-hunt!  Meanwhile, we'll follow a bunch of possibilities.

Analogous to the time-out problem described in <A HREF="/Risks/1.11.html">RISKS-1.11</A> causing
double-posting of millions of dollars, a similar problem can arise in the
ARPANET if a receiving host does not acknowledge soon enough, causing a
time-out and retry -- even though the message was successfully received.
This has been known to happen, but probably not repeatedly, as in the
<A HREF="/Risks/1.13.html">RISKS-1.13</A> duplication.

Sorry for the inconvenience.  We will take several measures to try to
prevent a recurrence, but if there is a real bug in the protocols or in
their implementation, then we will just have to slug it out until it is found.

Peter

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
Some Ruminations on an Ideal Defense System
</A>
</H3>
<address>
&lt;<A HREF="mailto:estell@NWC-143B">
estell@NWC-143B
</A>&gt;
</address>
<i>
Mon, 16 Sep 85 12:21:52 PDT
</i><PRE>
To: risks@sri-csl.arpa

SOME RUMINATIONS on AN IDEAL DEFENSE SYSTEM	         16 SEP 85 [RGE]

WHAT ARE THE CHARACTERISTICS OF AN IDEAL DEFENSE SYSTEM?
(Never mind that it does NOT exist - and likely will not in my lifetime.)

1. Useful ONLY on the defensive; incapable of use as an offensive weapon.
2. Effectiveness: 100%.
3. Reliability: 100%.
4. Cost: Cheap.  So economical to manufacture and deploy that everyone who
   needs one (or two) could have it.
5. Simple to use; requires no training; requires no "technology base."
6. Easy to maintain; essentially never wears out, or breaks.
7. Side effects of use or possession: None.

EXAMPLES OF SYSTEMS THAT DO NOT MEET THE IDEAL REQUIREMENTS.

1. Planes, ships, tanks, guns, and bombs - of any size.
2. Chemicals, gas, germs, etc.

EXAMPLES OF SYSTEMS THAT MIGHT - or might not - SUFFICE.
(They clearly won't satisfy all the above requirements.)

1. SDI - whatever that turns out to be, a few billion $ from now.
2. MX - NOT the expensive "new" systems recently voted, but simple
   modifications of older, reliable, affordable technology.  The key
   is the nature of the modifications.  This isn't the place to say more.

WHY THIS PROPOSAL IS WORTH LOOKING AT.

1. The technology is mature, affordable, and operational.
2. The super-powers can USE this proposal, this year, or next.
   Not just the USA and the USSR; but a few other nations, too.
3. The "trouble makers" who haven't yet demonstrated the maturity to
   abstain from rash use of a "doomsday" device can't use this idea.
4. It saves money; and buys time - precious time, in which we can
   learn to trust each other, and to respect our differences -
   accepting the fact that "... east is east and west is west,
   and never the twain shall meet ..." [Kipling]

WHY THIS PROPOSAL WILL BE RESISTED - perhaps EVEN DISCARDED.

1. Not many vendors will win multi-year, multi-billion contracts to
   develop and manufacture these systems.  That has largely been done.
2. Not many career officers and bureaucrats will get multiple promotions
   for the development and deployment of these systems; again, that's done.

SOME CONFESSIONS ABOUT MY MOTIVES.

I believe that Americans and Russians, Christians, Moslems, Jews, Buddhists,
atheists, agnostics, capitalists, communists, socialists, pacifists, hawks,
doves, owls, and others CAN live together; not in "harmony" - but in some
civility, with respect.  My belief is based on two facts:

1. The lion and the lamb may never lie down together, but the lion and the
   antelope presently share the veldt; blood is shed, but genocide does not
   occur.  It's elsewhere called the "balance of nature."  There is even some
   evidence that the process improves the strain of antelope - and lion.

2. I cannot accept gross demeaning judgments made about a people who produce
   some of the world's really great classical music.  Tchaikovsky, Borodin,
   and others have composed the best - in my opinion.  I believe that the
   Russians love their country, their families, their music, and the Almighty
   - by whatever name He may be called - just as we do; and, like us, they fear
   (or at least don't enjoy the thought of) death, starvation, disease, hatred,
   suspicion, etc.  Why are they so "defensive" - an enigma wrapped in a
   mystery, surrounded by a riddle? (or whatever exact phrase Churchill
   turned in '48)  Their land was invaded twice in the lifetime of their most
   recent leaders - men born before WWI.  The losses of life were catastrophic;
   almost 25% of the adult male population died each time - though the WWI 
   figures get blurred with the totals from their own revolution.  And those 
   weren't the first times; Napoleon did it in the 19th century, and the 
   Mongols did it earlier.  That plus the oppressive cold of a lingering 
   winter give them a somewhat different world view.  
   But in a quarter century, they, like us, have NOT pushed the button.  That 
   speaks well for their responsibility.

Our REAL problem - in the USA and the USSR and the third world - indeed in the
entire world - is NOT communists, not Arabs, not any organized government, nor
religion; it is terrorists - criminals; men of desperation, who when armed will
extract their needs by violence, and damn the consequences.  We have more than
our share of such trouble-makers; they have attacked many of our prominent
citizens recently: John and Robert Kennedy, Martin Luther King, Jr., Ronald
Reagan, Patty Hearst, and Malcolm X are examples easily remembered.

If some of the money spent now on weapons can be re-invested in research in 
medicine, in electronics for space exploration, in agriculture, etc. there will
be no loss of income for the scientists and business men now supplying the 
Pentagon.  True, many of them will have to adapt; but then, they do that now.
The arms of WWII just don't sell today.  A Technology Base that supports 
sophisticated weapons to kill people can adapt to kill viruses; to guide 
rockets to the distant galaxies, instead of missiles to distant cities; to 
detect bombs of terrorists, instead of bombs of military commandos.  I will 
have to be one of those who adapt; my employer, the Naval Weapons Center, must 
adapt too.  We are intellectually capable of doing that.

   RGE

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">
Re: SDI, feasibility is irrelevant (Response to McCarthy)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
16 Sep 85 11:09:56 PDT (Monday)
</i><PRE>
From: Gopal &lt;Gopal.es@Xerox.ARPA&gt;

	Your analogy to SDI of a duelling gunman putting on a bullet-proof vest
seems slightly flawed, but your overall point is well taken:
 
	The vest is far from being bullet proof...and the vest dose not
exist yet. The gunman has just thought about making one, after many
fruitless years of holding guns at each other. It is likely that he may not
succeed in making a vest that stops any bullet. The other gunman knows this.
	
	 But IF he should succeed, THEN, the status quo is broken immediately:
the very fact of possession of a bullet proof vest indicates that he can
turn the outcome decisively in his favor. This clearly will be perceived
as an act of hostility by the worst-case-strategists at the Kremlin. If
I were them, I would not sit by idly, twiddling my thumb: I would launch.
	 
	Sure, the gunman trying to make the vest has promised to give one to
the other gunman also, so there would be no hostility. But, WHEN he has
one, he would not give it away. The strategists do not plan on the basis
of goodwill. They would wait until a 'crisis' develops that forces them
to make a hard choice: share SDI or die.
	
	Would they get rid of the guns, once each one has a vest to stop
bullets? Not likely. We all know that when he was the only gunslinger in
town, he opted to keep that gun in case the other guy gets hold of
one...but now he can't get rid of his gun BECAUSE the other guy has one
too! If there is enough goodwill to get rid of the guns with vests, it
should be even more feasible to get rid of them now, without having to
incur the cost of the vests. Such goodwill simply does not exist while
there is also fear.   
	   
	If SDI should succeed, even partially, (that is, if the monkey should
reach the moon, at least partially, by climbing the tree) then the only
option would be to share SDI with the other guy.  Even after sharing
SDI, we are still bound by fear, of a different kind: what if one
develops a way to take out the other guy's SDI somehow by first strike
and tip the scales in his favour? Another president will come along to fund
this project, because the other side "already started on it and we don't
want to compromise national security". The other side, of course, needs
no excuses like this. And, history will repeat...and repeat.
	
	SDI does not solve the basic nature of the conflict in purpose that
national leaders must exhibit: They must get rid of the guns to make
peace and rid their people of fear, and they must protect national
security. These are clearly not compatible goals in a world of hostile
Governments. The Governments of the world hold the people hostage to
fear and insecurity, much like a handful of gun-slinging gangsters
holding a vast majority hostage to fear of crime.
	
	I admit that it is much easier to shoot down an idea (like SDI) than to
offer an easy alternative in a complex problem like this. But let this
not be a reason to adopt a faulty approach like SDI. 
	
	Well, 'nuff  ramblin' on SDI. By the way, October issue of Science '85
magazine has a cover story on "RISKS: How it is perceived" and I thought
it was quite thought-provoking and may help us understand how
SDI-like-risk is perceived by the people. I highly recommend reading it.
	
Gopal

        [This message is marginally on the subject -- assuming the original
         message was.  I'm not sure whether it sharpens or blunts the
         would-be analogy, but let's blow the whistle on the bullet-proof 
         vest at this point.  Thanks.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-24</DOCNO>
<DOCOLDNO>IA012-000128-B042-370</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.15.html 128.240.150.127 19970217000602 text/html 17614
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:04:30 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 15</TITLE>
<LINK REL="Prev" HREF="/Risks/1.14.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.16.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 15</H1>
<H2>     Friday, 20 Sep 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
                 Peter G. Neumann, moderator
<BR>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  SDI Panel at 8th ICSE in London 
</A>
<DD>
<A HREF="#subj1.1">
David Weiss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks to the Moderator 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Mailer Protocol Woes 
</A>
<DD>
<A HREF="#subj3.1">
Marty Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Another Horror Story -- Sidereal Time Rollover 
</A>
<DD>
<A HREF="#subj4.1">
Marty Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Article: Health Hazards of Computers 
</A>
<DD>
<A HREF="#subj5.1">
Ted Shapin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Two More SDI Related Queries 
</A>
<DD>
<A HREF="#subj6.1">
douglas schuler
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  CAL ID -- computerized fingerprint system 
</A>
<DD>
<A HREF="#subj7.1">
douglas schuler
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">
SDI Panel at 8th ICSE in London
</A>
</H3>
<address>
David Weiss 
&lt;<A HREF="mailto:wanginst!weiss@nrl-css.arpa">
wanginst!weiss@nrl-css.arpa
</A>&gt;
</address>
<i>
Wed 18 Sep 1985 16:51:10 EST
</i><PRE>

    Panel Discussion on the Strategic Defense Initiative at the 8th
         International Conference on Software Engineering

One of the more interesting sessions at the 8th International
Conference on Software Engineering was a discussion of software for
the Strategic Defense Initiative (SDI).  The moderator was Manny
Lehman and the panelists were Fred Brooks, David Parnas, and Alan
Perlis.  The discussion was originally intended to be a debate, but
Fred Brooks was not willing to participate in a debate because he had
not yet reached a resolution of the issues.  (I understand that
volunteers for the position of opposing Parnas in a debate on SDI
were hard to find.  Dr. Brooks deserves credit for being willing to
engage in a public exploration of touchy issues about which he feels
unsettled in concert with a strongly opinionated colleague in an
effort for both audience and panel to learn more.)  

The discussion started with a presentation by Parnas of the technical
reasons why reliable SDI software cannot be built.  (Readers of this
newsletter will be familiar with many of the arguments put forth by
Parnas.  A complete discussion in hard-copy is available from him at
the University of Victoria, Department of Computer Science, P.O.  Box
1700, Victoria, B.C., Canada.)  

Brooks responded with reasons why he thought we could build such a
system.  His major point was that we have built similar systems in
the past.  He identified the Apollo missions software as an example,
suggesting that we start with such a system and incrementally build
from it towards an SDI system, using what's learned along the way.

Perlis then added a few comments, explaining why SDI software would
be more complex than existing software and why it is of the hardest
type of software to build.  His argument was that the SDI system
represents a moving target in terms of requirements and design.

Following some further discussion among the panelists the floor was
opened to technical questions from the audience.  

The major place in which Parnas and Brooks seemed to disagree was
whether or not similar systems have been built.  Brooks tried to use
the Apollo and Space Shuttle as examples.  Parnas's point was that in
those systems everything can be predicted in advance.  In an
anti-missile system, the number, shape, and trajectories of launched
missiles can't be predicted.  In addition, the system must
distinguish decoys from real warheads.  Finally, the defense system
itself will be under attack.  As a result, realistic tests and
simulations of operating conditions for such a system could not be
conducted.  

All the discussants seemed to agree that an SDI system could not be
built error-free, and that it would not be completely reliable.
Nonetheless, there were advocates of building it on such grounds as
that it would only be needed for a short time, and could be turned
off the rest of the time, or that we now place our trust in systems
that are also untested and probably unreliable.  

In summary, there were no good responses to any of the questions that
Dave Parnas raised.  Nonetheless, there were arguments put forth for
the construction of an SDI system on the grounds that it need not be
completely reliable.  

David Weiss
Wang Institute of Graduate Studies

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
Risks to the Moderator!
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Thu 19 Sep 85 17:40:08-PDT
</i><PRE>
To: RISKS@SRI-CSLA.ARPA

<A HREF="/Risks/1.15.html">RISKS-1.15</A> was ready to go out Wednesday night.  Murphy hit in spades.  The
SRI MICOM switch for dial-up access was unavailable for two days, and is
still down.  An alternative route might have been available through the only
system that receives dial-ups directly from a split-speed modem, but that
system went down for five hours.  Several other more circuitous alternative
routes all ran into broken gateway, which resulted from a power failure
Tuesday night.  It would not have helped to drive back to SRI, because the
SRI-CSLA (which kept running through all this) was out of net contact as a
result of a gateway problem.  All of the gurus were invisible.  If you ever
get this issue, you will know that things have improved.  Peter

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">
Mailer Protocol Woes
</A>
</H3>
<address>
&lt;<A HREF="mailto:mooremj@EGLIN-VAX">
mooremj@EGLIN-VAX
</A>&gt;
</address>
<i>
Tue, 17 Sep 85 07:40:58 CDT
</i><PRE>

Receiving 2 or 3 duplicate messages is a minor annoyance.  Receiving over
a hundred is a *major* annoyance.  A few weeks ago, a message from SECURITY
(a non-digest, re-mail distribution list) contained a record that was too
long for our mailer to handle.  The result was that the message would be
transmitted from Rutgers, and our mailer would have a problem with the long
record.  The message would not be successfully acked, but the mailer would
send me the partial message up to the problem.  Since the message was not
acked, Rutgers kept remailing it to me.  Before the Rutgers wizards flushed
the message, I had received 173 (I think) copies of the partial message;
at times I was receiving one every 15 minutes!  This happened just before I
left on vacation, and I was seriously concerned about returning to work and
finding my disk quota used up by N*1000 copies of the busted message...

                                     Marty Moore (mooremj@eglin-vax.arpa)

    [I'm glad we're not the only ones!  I think the protocols really
     need further ruggedization.  Thanks.  PGN]

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
Another Horror Story -- Sidereal Time Rollover
</A>
</H3>
<address>
&lt;<A HREF="mailto:mooremj@EGLIN-VAX">
mooremj@EGLIN-VAX
</A>&gt;
</address>
<i>
Tue, 17 Sep 85 12:41:04 CDT
</i><PRE>

How many of you real-time programmers have been bitten by time rollover at 
midnight?  How about *sidereal* time rollover?  It happened like this:

In the late 70's I worked on the USNS Redstone, which is the primary tracking 
and support ship for at-sea test launches of the Trident Submarine Launched
Ballistic Missile.  I wrote a section of program which took telemetry data
from the Trident's Inertial Guidance Unit and reduced it to provide track 
data.  Now, Inertial Guidance is like the little girl in the famous rhyme:
when it's good, it's very very good, but when it's bad, it's very very bad.
As such, we had some fairly extensive reasonableness checks on the data.
One in particular took the data's time tag (in sidereal hour angle format),
differenced it with a reference hour angle computed at program initialization, 
converted the answer to seconds, and compared this to the program's running
time.  If the two times were dissimilar, the IG data was rejected.  This
check worked beautifully on numerous tests, with both simulated and actual 
input data.

Unfortunately, the programmer (blush, cringe, hang head in shame) completely 
overlooked the possibility that the sidereal hour angle could reach 2*pi
radians and roll over during the mission.  This eventually happened on a "2+2" 
test launch.  In a "2+2" launch, two missiles are launched close together,
then two more are launched close together after a lengthy delay.  The sidereal 
hour angle rolled over about five minutes before the first missile was 
launched.  The program decided that the IG data had a bad time tag and promptly
rejected it.  Fortunately, other devices were tracking the missiles; mission 
rules stated that if no track data was received for a certain period, missiles
in flight must be destroyed.

During the delay between the first and second missile pairs, I carefully -- 
very, very carefully -- patched the running program to disable the time check.
On the second pair of missiles, the IG data was great, which was a good 
thing, because for about 40 seconds, no other device tracked them; if the IG
had also failed, the missiles would have been destroyed.  If the sidereal 
rollover had occurred *between* the two pairs of launches...(gulp)

The moral: the check worked great on numerous tests, until a peculiar set of
conditions occurred.  When the bug bit, we were able to save the test; but
with just a small change in conditions, we could have destroyed two Trident 
missiles unnecessarily.  I don't know what they cost, but I'm sure it's at 
least $10,000,000 each.

                                   Marty Moore (mooremj@eglin-vax.arpa)

</PRE>
<A NAME="subj5"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj5.1">
Article: Health Hazards of Computers
</A>
</H3>
<address>
Ted Shapin 
&lt;<A HREF="mailto:BEC.SHAPIN@USC-ECL.ARPA">
BEC.SHAPIN@USC-ECL.ARPA
</A>&gt;
</address>
<i>
Wed 18 Sep 85 15:59:24-PDT
</i><PRE>

"The Health Hazards of Computers" edited by Art Kleiner. Pages 80-93,
Whole Earth Review, No. 48, Fall 1985, $4.50. PO Box 15187, Santa Ana, CA.
92705, or your news-stand.

   "This amalgamation of information, conjecture, experiment, and reporting is
    the end of a 12-month odyssey.  It started last June, when we were planning
    the 'Computers as Poison' issue (Fall '84 WER)."

   "We really should have something on the health hazards of video-display 
    terminals (VDTs)." I said to Kevin and Stewart. "After all, it's a major 
    uncertainty. You sit with you nose squeezed up against the beast for hours 
    every day; you hear vague reports of cataracts and birth defects; you hear,
    on the other hand, industry groups saying there's nothing wrong with the 
    machines .... Whom should you believe?"

  A tip from Mike Castleman of  Medical Self-Care Magazine  led me to the
  Center for Investigative Reporting in San Francisco.  A reporter there named
  Diana Hembree had already been investigating VDT radiation health hazards
  for several months, with a particular interest in its effects on women
  workers -- most VDT terminal grunt workers, such as airline reservation
  clerks and data- entry operators are women. At my request, she assembled a
  group of investigators to look into potential radiation hazards from
  personal computers.

  Their original article arrived in time for the Computers as poison issue,
  but because it reported on a situation that was simultaneously
  controversial, extremely technical, and inconclusive, we didn't feel
  comfortable printing the article without scientific review.

  Thus we held it and sent it to two dozen physicists, radiologists,
  biophysicists, and doctors -- all people with a preestablished interest in
  this topic. Diana's original theme wasn't particularly incendiary; it
  basically said, "There seems to be a cause for concern, but nothing
  conclusive; more research is needed."  We got back a dozen replies, some
  complimentary and other criticizing us for everything from hysterical
  sensationalism to underplaying the danger. Some of those replies led to
  further interviews that supplemented Diana's already exhaustive research.
  Meanwhile, discussion of the EIES computer network began turning up comment
  from other people who had investigated the issue.

  Ultimately, I edited Diana's article, plus some of the replies and other 
  comments into these 14 pages.

The article ends with a bibliography and notes.  Ted.

</PRE>
<A NAME="subj6"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj6.1">

</A>
</H3>
<address>
douglas schuler
&lt;<A HREF="mailto:bcsaic!douglas@uw-june ">
bcsaic!douglas@uw-june 
</A>&gt;
</address>
<i>
Thu, 19 Sep 85 12:41:36 pdt
</i><PRE>
Subject: Two More SDI Related Queries

I have two queries   r e l a t e d   to SDI but (I hope) of general
risks interest.

1.  Does anybody have rough heuristics for comparing the complexity of
    large projects?  I'd like to see a matrix where several very large 
    projects were compared feature by feature (e.g. person-years, LOC, 
    cost, function, etc)

2.  I would be very curious to see the results of using Boehm's estimating 
    techniques (_Software Engineering Economics_) on the SDI software.  The 
    techniques were developed at TRW and, hence, may be applicable to SDI.

	Doug Schuler     (206) 763-5295
	{allegra,ihnp4,decvax}uw-beaver!uw-june!bcsaic!douglas
	uw-june!bcsaic!douglas@washington.arpa

</PRE>
<A NAME="subj7"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj7.1">
CAL ID -- computerized fingerprint system
</A>
</H3>
<address>
douglas schuler
&lt;<A HREF="mailto:bcsaic!douglas@uw-june ">
bcsaic!douglas@uw-june 
</A>&gt;
</address>
<i>
Mon, 16 Sep 85 07:55:43 pdt
</i><PRE>

This isn't really a submission, just a noteworthy subject that I heard on
NPR this morning.  The "CAL ID" computer system is a $40 million system
(from NEC) for storing and retrieving finger prints.  The system has not
been officially accepted as of yet as only 2 million of the 2.5 million
fingerprinted California citizens are stored.  It is still being tested.
The system was used successfully to identify the "nightstalker" from
fingerprints.  Only males born since 1960 had been included.  Ramirez was
born in February, 1960.  It was estimated that the new system will result in
20,000 additional arrests per year in California.

        [I thought this was worth including.  There are all sorts of 
         associated risks.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-25</DOCNO>
<DOCOLDNO>IA012-000128-B042-393</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.16.html 128.240.150.127 19970217000625 text/html 17204
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:04:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 16</TITLE>
<LINK REL="Prev" HREF="/Risks/1.15.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.17.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 16</H1>
<H2> Thursday, 26 Sep 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Intellectual honesty and the SDI 
</A>
<DD>
<A HREF="#subj1.1">
Bill Anderson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  RISKy Stuff 
</A>
<DD>
<A HREF="#subj2.1">
Mike Padlipsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Mailer Protocol Woes 
</A>
<DD>
<A HREF="#subj3.1">
Rob Austein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risks in Synchronizing Network Clocks 
</A>
<DD>
<A HREF="#subj4.1">
Ann Westine for Jon Postel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Moral vs. Technological Progress 
</A>
<DD>
<A HREF="#subj5.1">
Joel Upchurch
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Risk Contingency Planning -- Computers in Mexico 
</A>
<DD>
<A HREF="#subj6.1">
Mike McLaughlin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Intellectual honesty and the SDI
</A>
</H3>
<address>
&lt;<A HREF="mailto:WAnderson.wbst@Xerox.ARPA">
WAnderson.wbst@Xerox.ARPA
</A>&gt;
</address>
<i>
18 Sep 85 15:48 EDT
</i><PRE>
Courtesy-of: minow%rex.DEC@decwrl.ARPA  (Martin Minow, DECtalk Engineering)

FROM AIList Digest       Friday, 20 Sep 1985      Volume 3 : Issue 125

At the recent IJCAI at UCLA I picked up a couple of papers at the GE
exhibit booth.  One of these,  entitled "A Tutorial on Expert Systems
for Battlefield Applications," (delivered at a meeting of the Armed
Forces Communications and Electronics Association last May) states that
"AI systems that incorporate human expertise may be the only way" to
fill the gap between availability of people and complexity of military
hardware.  In defense of this strategy the author states:

        - In contrast with humans, AI systems are good at handling the myriad
details of complex situations, such as often occur in military settings.

        - In contrast with other computational approaches that are more formal
and algorithmic, AI systems are more robust:  they are designed to deal
with problems exhibiting uncertainty, ambiguity, and inaccuracy.

I find it appalling (and frightening) that statements like this can be
presented in a technical paper to military personnel.   The author
(according to the references) has contributed widely to the AI field at
many conferences. It's simply ludicrous to state that current AI systems
are better in battlefield situations than humans.  What was the last AI
system that could drive a tank, carry on a conversation, and fix a
broken radio whilst under enemy fire?  The second comment is equally
misleading.  To  contrast "formal and algorithmic" with "robust" seems
to imply that algorithms and formal procedures are inherently not
robust.  On what is this claim based?  (There is no reference attached
to either statement.)  It sounds like a recipe for unreliable software
to me.

How can someone write this stuff?  I know, to make money.  But if this
is the kind of information that is presented to the military, and upon
which they make decisions, then how can we expect any kind of fair
assessment of the possible projects in the Strategic Computing (and
Defense) Initiatives?  How can this kind of misinformation be rebutted?

Bill Anderson

P.S. The full reference is available on request.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
RISKy Stuff
</A>
</H3>
<address>
&lt;<A HREF="mailto:PADLIPSKY@USC-ISI.ARPA">
PADLIPSKY@USC-ISI.ARPA
</A>&gt;
</address>
<i>
20 Sep 1985 18:33:30 EDT
</i><PRE>
To:   neumann@SRI-CSL.ARPA

... I suppose I might as well succumb to temptation and offer a couple 
of comments on stuffgoneby:

The most striking omission, to my mind, in the SDI discussion is (unless I
missed spotting it) the failure to draw the parallel to SAGE.  For those who
don't remember/know, the Semi-Automated Ground Environment was the
grandfather of the big, "man-machine" system, certainly in DoD and most
probably in the field as a whole.  It was intended to allow for the
interception of manned bombers.  It is widely acknowledged to have spun off
a lot of what became the state of our art (collective art, that is-- i.e.,
what I call the computer racket).  Like SAGE, SDI is probably dealing with
the wrong threat (since things don't have to go through the air to go boom
... and since things don't even have to go boom to rack up megadeaths).
Also like SAGE, SDI might have useful spinoffs (a 20-years-younger colleague
claims to be for it because it should help get him off this planet).
Unfortunately, unlike SAGE it seems to possess a real potential for
stampeding the presumed Bad Guys into doing something ... unfortunate. 

What a good thing we Men of Science know better than to reason
from analogy, eh?

...  muted cheers, map

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Mailer Protocol Woes
</A>
</H3>
<address>
Rob Austein 
&lt;<A HREF="mailto:SRA@MIT-XX.ARPA">
SRA@MIT-XX.ARPA
</A>&gt;
</address>
<i>
Fri, 20 Sep 1985  14:36 EDT
</i><PRE>

I was actually a culprit in a similar mailer lossage earlier this
week.  The whole thing actually started out when I was dialed up to XX
on a noisy connection.  Improbable as it seems (although not quite on
the order of monkeys and Shakespeare), the random line noise managed
to generate the 7 character command sequence necessary to send off my
entire mail file as a single message to a major mailing list.  All 110
pages (=281600 bytes) worth of it.  Fortunately for the network (but
unfortunately for my reputation) the list happened to be the TOPS-20
maintainers' mailing list, so the message got killed off in pretty
short order.  I have since put in a couple of safeguards into my mail
reader environment so that this particular lossage can't happen again,
but since the real culprit was transmission line noise I have been
kind of nervous about reading my mail over dialups ever since....

--Rob

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Risks in Synchronizing Network Clocks (RFC956 Now Available)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
25 Sep 1985 09:07:47 PDT
</i><PRE>
From: Ann Westine &lt;WESTINE@USC-ISIB.ARPA&gt;
Plucked-From: Request-For-Comments-List: ;

A new Request for Comments is now available from the Network Information
Center in the &lt;RFC&gt; directory at SRI-NIC.ARPA.

RFC 956:

   Title:       Algorithms for Synchronizing Network Clocks 
   Author:      D. L. Mills
   Mailbox:     Mills@USC-ISID.ARPA
   Pages:       26      
   Characters:  68868

      pathname: &lt;RFC&gt;RFC956.TXT

   This RFC discussed clock synchronization algorithms for the 
   ARPA-Internet community, and requests discussion and suggestions for 
   improvements.  The recent interest within the Internet community in 
   determining accurate time from a set of mutually suspicious network 
   clocks has been prompted by several occasions in which errors were 
   found in usually reliable, accurate clock servers after thunderstorms
   which disrupted their power supply.  To these sources of error should
   be added those due to malfunctioning hardware, defective software and
   operator mistakes, as well as random errors in the mechanism used to 
   set and synchronize clocks.  This report suggests a stochastic model 
   and algorithms for computing a good estimator from time-offset 
   samples measured between clocks connected via network links.  
   Included in this report are descriptions of certain experiments which
   give an indication of the effectiveness of the algorithms.  
   Distribution of this memo is unlimited.

Public access files may be copied from the &lt;RFC&gt; directory at 
SRI-NIC.ARPA via FTP with username ANONYMOUS and password GUEST.

   The normal method for distribution of RFCs is for interested parties 
   to copy the documents from the NIC online library using FTP.  
   Requests for special distribution should be addressed to either the 
   author of the RFC in question or to NIC@SRI-NIC.ARPA.  Unless 
   specifically noted otherwise on the RFC itself, all RFCs are for 
   unlimited distribution.

Submissions for Requests for Comments should be sent to POSTEL@USC-ISIB.ARPA.

Requests to be added to or deleted from this distribution list should be
sent to NIC@SRI-NIC.ARPA.

--jon.

      [I include this item in the RISKS Forum for a very obvious reason:
       one of the nastiest of all problems in distributed computer systems
       and networks is the synchronization problem.  That so many
       seemingly correct algorithms have in fact been flawed is a very
       important consideration here.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Moral vs. Technological Progress
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Wednesday, 25 Sep 1985 16:27-EDT
</i><PRE>
X-From: joel@peora.UUCP (Joel Upchurch)

   &gt;Actually  McCarthy's  original  comment  presupposes  that  moral  and
   &gt;technological  progress  are comparable.  It is that assumption that I
   &gt;disagree with.  Ethics and the attendant morality provide the  context
   &gt;within  which  all activity, and in particular technological progress,
   &gt;exists.  Morality and technology are not substitutes for  one  another
   &gt;and  moral  progress  is  not  dependent on technology nor vice versa.
   &gt;There is always technological progress  attendant  to  moral  progress
   &gt;just because there is always technological progress.

I don't think that there is any such thing as an absolute moral standard.
Morality is simply a set of customs that evolves by trial and error to
improve the survival chances of the social group (family, tribe, nation
whatever).  Notice that this has has little to do individual survival and
that a moral principle, such as patriotism, may cause the individual to get
killed.

Now I think it fairly easy to see that the capacity to put group survival
ahead of self-interest is an important genetic trait and that tribes of
people that had this trait would be more likely to survive that tribes that
didn't.  That is not to say that this moral capacity doesn't vary greatly
from one person to the next or that even that it may not be more fully
realized in one person than another because of upbringing.  It is even
possible that, because of some genetic error, some people may be born
without a moral capacity, just like they might be born without arms or legs.

The point I'm trying to make is although there will always be these survival
customs we call morality, the nature of the customs is heavily dependent on
the context they evolve in.  Thus the morals of a herding society may be
greatly different from those of an agrarian one.  Even two societies in
similar contexts may evolve different moral solutions to the same problems.
This implies that if the context in which a society operates changes, then
the morals of that society will have to change too.  In recent centuries the
most important changes in the social context have been caused by technology.
Thus the morals appropriate to a agrarian society are not always appropriate
to an industrial one or those of an industrial society to a post-industrial
one.

Moral progress means the evolution of survival customs more appropriate to
the current context.  The trouble in recent centuries has been that our
ability to evolve new technology has outstripped our capacity to evolve the
appropriate morality for it.  There is a strong tendency to stick to the
morality that one learns as a child, even if it not appropriate to the
current situation.

Our current problem is that we have a technology that supplies us with ICBMs
and a morality that includes national patriotism.  Now it is obvious to any
thinking person that this is a serious dilemma.  Some people argue that we
should adopt a new morality, more appropriate to this technology, and indeed
in the long term they are correct, although one can argue what is the most
effective moral solution to this problem.

The trouble is that moral solutions evolve slowly.  Even today much of our
morality is left over from our nomadic and agrarian heritage and has limited
relevance in our modern society.  In order to apply the long term solution,
we must first survive in the short term, and in that short term technical
band-aids, like the SDI, are appropriate.  Technology put us into this
situation and I don't see why we can't ask technology to assist us in the
solution.  To think that we can solve the problem by an overnight revolution
in human nature is wishful thinking of the most dangerous sort.

     Joel Upchurch
     Perkin-Elmer Southern Development Center
     2486 Sand Lake Road/ Orlando, Florida 32809/ (305)850-1031
     {decvax!ucf-cs, ihnp4!pesnta, vax135!petsd}!peora!joel

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Risk Contingency Planning -- Computers in Mexico
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Sat, 21 Sep 85 13:25:25 edt
</i><PRE>

This is not info, but a call for info.  I have no idea how bad the computer
bug has bit in Mexico, but the current news &amp; TV coverage of the disaster
suggest that whatever computing/networking is going on must have been
affected.  If any RISKS reader knows some statistics or details about
computer usage in Mexico, and can give insights as to what happened, what
backup and alternative modes were in place, how well they worked... etc.  It
would certainly help me, and perhaps many others in planning for the
disaster that we hope never comes.  Perhaps we could discuss just what we
want to find out, and then go after the answers formally, if there are no
informal contacts on the net.  - Mike

       [This item may seem a little odd for the RISKS Forum, but when you 
        realize that Mike's Navy job involves expecting the unexpected risks 
        in computer and network usage, and planning what to do, it is indeed
        relevant.  By the way, in Mexico, as usual in times of disaster, the
        ham-radio buffs lept in to help.  Computer networks and internets
        also have a role to play.  I'm ready with my battery-operated
        portable terminal.  (This issue is being sent from DC.)  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-26</DOCNO>
<DOCOLDNO>IA012-000128-B042-414</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.17.html 128.240.150.127 19970217000639 text/html 17596
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:05:06 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 17</TITLE>
<LINK REL="Prev" HREF="/Risks/1.16.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.18.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 17</H1>
<H2> Friday, 27 Sep 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
SDI debate announcement
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Minor risk to the pocket book 
</A>
<DD>
<A HREF="#subj2.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Social Impacts of Computing: Graduate Study at UC-Irvine 
</A>
<DD>
<A HREF="#subj3.1">
Rob Kling
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Friendly enemy test teams 
</A>
<DD>
<A HREF="#subj4.1">
John Mashey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  More protocol goofs 
</A>
<DD>
<A HREF="#subj5.1">
Dave Curry
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
SDI debate announcement
</A>
</H3>
<address>
&lt;<A HREF="mailto:genrad!teddy!lkk@mit-eddie.MIT.EDU">
genrad!teddy!lkk@mit-eddie.MIT.EDU
</A>&gt;
</address>
<i>
26 Sep 1985 17:48-EST
</i><PRE>
To: risks@sri-csl.arpa

Dear Colleague,

Computer technology plays an ever-increasing role in the arms race.
The Strategic Defense Initiative (`Star Wars') is a leading example
of a military system in which almost complete reliance will be placed
on computerized decision making.  The feasibility and desirability of
this system are currently undergoing serious public debate.

On Monday, the 21st of October, at 8:00 pm in M.I.T.'s Kresge Auditorium, the
M.I.T. Laboratory for Computer Science and Computer Professionals for Social
Responsibility are co-sponsoring a public forum designed to raise many of the
technical issues surrounding the Strategic Defense Initiative (SDI).

Professor Michael Dertouzos, Director of the M.I.T. Laboratory for Computer
Science, will moderate a debate on the feasibility of software development
for the SDI project.  Dr. Danny Cohen (Director of the Systems Division at
the University of Southern California's Information Sciences Institute and
Chairman of the Strategic Defense Initiative Organization panel on Computing
in Support of Battle Management (SDIO/CSBM)) and Professor Charles Seitz
(Professor of Computer Science, California Institute of Technology and
member, SDIO/CSBM)) will speak in favor of the SDI proposal.  Professor
David Parnas (Lansdowne Professor of Computer Science, University of
Victoria, Canada) and Professor Joseph Weizenbaum (Professor of Computer
Science, Massachussetts Institute of Technology) will take the position that
such a software development project is infeasible.

Professor Parnas' resignation from the SDIO/CSBM panel in June of
this year, and the set of memos he wrote discussing the infeasibility
of the SDI project attracted extensive press coverage in June of this
year.

CPSR will be holding a reception for the speakers at La Groceria (853
Main Street in Cambridge) between 6:30 and 7:30.  Please join us for
dinner and an opportunity to meet some of the panelists.  The $25 per
plate donation will help us cover expenses for this forum and related
projects.  Please RSVP to Mark Vilain at (617) 648-4325.

Earlier that afternoon, the M.I.T. Technology and Culture Seminar
will sponsor a talk by Dr. James Ionson, Director of the Office of
Innovative Science and Technology for the SDIO.  After Dr. Ionson
describes the general research goals of SDI, two M.I.T. professors
will respond with varying views on why they have chosen to accept or
refuse funding for research from the SDIO.  A student representative
will report on student reaction to Star Wars projects on campus.
This talk will be held at MIT in building 9, room 150 at 4:00 p.m.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Minor risk to the pocket book
</A>
</H3>
<address>
Eugene Miya
&lt;<A HREF="mailto:eugene@AMES-NAS.ARPA ">
eugene@AMES-NAS.ARPA 
</A>&gt;
</address>
<i>
26 Sep 1985 1652-PDT (Thursday)
</i><PRE>

Here is a minor man-machine risk which occurred today (9/26) in the Silicon
Valley at El Torito [popular Mexician food chain] at lunch.  We arrived for
a late lunch and found that our bill was 50% over what appeared in the menu.
The cash register [one of those computer systems where they press buttons
rather than prices] was running on the dinner menu prices rather than the
lunch menu prices.  Since we arrived late, everybody else [e.g., hundreds of
people] were over-charged for lunch that day and perhaps earlier.  This
implies several things about the way customers in Si Valley treat their
bills [rich?  no verification? ...]  What about the restaurant?

From the Rock of Age Home for Retired Hackers:

--eugene miya,   NASA Ames Research Center,   eugene@ames-nas.ARPA

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Technology and Morality
</A>
</H3>
<address>
Benjamin Thompson
&lt;<A HREF="mailto:munnari!mulga.oz!bjpt@seismo.CSS.GOV ">
munnari!mulga.oz!bjpt@seismo.CSS.GOV 
</A>&gt;
</address>
<i>
Fri, 27 Sep 85 12:01:18 EST
</i><PRE>
Organization: Computer Science, University of Melbourne

Nicholas Spies writes [in <A HREF="/Risks/1.13.html">RISKS-1.13</A>]:

  &gt;             ...                 Hitler opened the Pandora's Box of applying
  &gt;high-tech to warfare and it worked (at least until a higher-tech response
  &gt;prevailed).

Technology has been successfully applied to warfare for millenia.  Alexander
the Great didn't win through having a bigger army (he didn't); he had better
weapons (e.g. he found out that ballistae propel spears faster than people do).
(and he had better trained soldiers etc. - education and technology basically).

  &gt;	     After WWII a new era was born in which global political power no
  &gt;longer rested on moral authority but on a command of the new applied
  &gt;sciences and scientists.

Nothing could be further removed from morality than the way in which global
political power is grabbed and maintained.  It has always been based upon
physical strength (which usually, but not always, corresponds to technological
strength).  History is a never-ending sequence of examples.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Social Impacts of Computing: Graduate Study at UC-Irvine
</A>
</H3>
<address>
Rob-Kling 
&lt;<A HREF="mailto:Kling%UCI-20B@UCI-ICSA">
Kling%UCI-20B@UCI-ICSA
</A>&gt;
</address>
<i>
26 Sep 1985 0920-PDT
</i><PRE>
To: risks@SRI-CSL
                                CORPS:
                        Graduate Education in
            Computing, Organizations, Policy, and Society
               at the University of California, Irvine

     This graduate concentration at the University of California,
Irvine provides an opportunity for scholars and students to
investigate the social dimensions of computerization in a setting
which supports reflective and sustained inquiry.

     The primary educational opportunities are PhD concentrations in
the Department of Information and Computer Science (ICS) and MS and
PhD concentrations in the Graduate School of Management (GSM).
Students in each concentration can specialize in studying the social
dimensions of computing.

     The faculty at Irvine have been active in this area, with many
interdisciplinary projects, since the early 1970's.  The faculty and
students in the CORPS have approached them with methods drawn from the
social sciences.

     The CORPS concentration focuses upon four related areas of inquiry: 

 1.  Examining the social consequences of different kinds of computerization
     on social life in organizations and in the larger society.

 2.  Examining the social dimensions of the work and organizational
     worlds in which computer technologies are developed, marketed,
     disseminated, deployed, and sustained.

 3.  Evaluating the effectiveness of strategies for managing the
     deployment and use of computer-based technologies.

 4.  Evaluating and proposing public policies which facilitate the
     development and use of computing in pro-social ways.


     Studies of these questions have focussed on complex information
systems, computer-based modelling, decision-support systems, the
myriad forms of office automation, electronic funds transfer systems,
expert systems, instructional computing, personal computers, automated
command and control systems, and computing at home.  The questions
vary from study to study.  They have included questions about the
effectiveness of these technologies, effective ways to manage them,
the social choices that they open or close off, the kind of social and
cultural life that develops around them, their political consequences,
and their social carrying costs.

     CORPS studies at Irvine have a distinctive orientation -

(i) in focussing on both public and private sectors,

(ii) in examining computerization in public life as well as within
      organizations,

(iii) by examining advanced and common computer-based technologies "in
      vivo" in ordinary settings, and

(iv) by employing analytical methods drawn from the social sciences.


         Organizational Arrangements and Admissions for CORPS

     The CORPS concentration is a special track within the normal graduate
degree programs of ICS and GSM.  Admission requirements for this
concentration are the same as for students who apply for a PhD in ICS or an
MS or PhD in GSM.  Students with varying backgrounds are encouraged to apply
for the PhD programs if they show strong research promise.

     The seven primary faculty in the CORPS concentration hold appointments
in the Department of Information and Computer Science and the Graduate
School of Management.  Additional faculty in the School of Social Sciences,
and the program on Social Ecology, have collaborated in research or have
taught key courses for CORPS students.  Our research is administered through
an interdisciplinary research institute at UCI which is part of the Graduate
Division, the Public Policy Research Organization.

Students who wish additional information about the CORPS concentration
should write to Professor Rob Kling (Kling@uci-icsa), Department of
Information and Computer Science, University of California, Irvine, Irvine,
Ca. 92717, 714-856-5955 or 856-7548, or Professor Kenneth Kraemer
(Kraemer@uci-icsa), Graduate School of Management, University of California,
Irvine, Irvine, Ca. 92717, 714-856-5246.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Friendly enemy test teams
</A>
</H3>
<address>
John Mashey
&lt;<A HREF="mailto:mips!mash@glacier ">
mips!mash@glacier 
</A>&gt;
</address>
<i>
Wed, 25 Sep 85 01:17:53 pdt
</i><PRE>

John McCarthy &lt;JMC@SU-AI.ARPA&gt; writes in <A HREF="/Risks/1.10.html">RISKS-1.10</A>:

  &gt; 2. My opinion is that if the physics of the problem permits a good
  &gt; anti-missile defense the programs can be written and verified.  However, it
  &gt; will be quite difficult and will require dedicated work.  It won't be done
  &gt; by people who are against the whole project.  Computer checked proofs of
  &gt; program correctness will probably play some role. So will anticipating what
  &gt; kind of bugs would be most serious and putting the biggest effort into
  &gt; avoiding them.  Having many people go over and discuss all the critical
  &gt; parts of the program will also be important.
  
Perhaps the best way to make it work WOULD be to have a test team of
people (who might be skeptics, at least) trying to break it.  Most large
complex projects that actually worked, at least that I've seen, have
succeeded at least partly because they had a large test team who didn't
believe anything worked until it could get past the worst of their tests.
I don't know what the ratio is elsewhere, but many complex ATT/BTL projects
allocated 30-50% of the staff to building test frameworks designed to stress
the system under test.  Consider the recent history of evaluation of
new military systems (like the Sergeant York).  It's very hard for the
builders of something to evaluate it well; you need a good enemy for that.

     [Tiger teams have indeed had some success in finding the more obvious
      program bugs, but in general many flaws may remain.  This topic has been 
      raised superficially in past issues.  Perhaps we are ready for some
      detailed discussions on the strengths and limitations of testing.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
More protocol goofs
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@purdue-ecn.ARPA ">
davy@purdue-ecn.ARPA 
</A>&gt;
</address>
<i>
Thu, 26 Sep 85 22:29:41 EST
</i><PRE>

    [The original message contained 8576 characters, almost exclusively
     headers.  I have pruned it to give just the flavor.  PGN]

I'm forwarding this as a wonderful example of protocols getting
completely hosed... this mail of mine bounced for some unexplained
reason.  I resent the message the same day this came back, and it
went through just fine.

Looking at the headers should make the problem more than obvious...

--Dave Curry

Return-Path: &lt;decvax!mcnc!unc!unc!unc!unc!unc!unc!unc!unc!mailer-daemon&gt;
Received: from ee.ECN by ec.ECN; Thu, 6 Sep 84 19:48:01 est (4.12/5.20)
From: decvax!mcnc!unc!unc!unc!unc!unc!unc!unc!unc!mailer-daemon
Received: by ee.ECN; Thu, 6 Sep 84 19:47:35 est (4.12/5.20)
Return-Path: &lt;decvax!mcnc!unc!unc!unc!unc!unc!unc!unc!unc!mailer-daemon&gt;
Received: by decvax.UUCP (4.12/1.0)
	id AA24764; Thu, 6 Sep 84 02:25:55 edt
Received: by mcnc (4.12/4.7) id AA00613; Wed, 5 Sep 84 18:51:54 edt
Original-From: &lt;unc!unc!unc!unc!unc!unc!unc!unc!mailer-daemon@mcnc&gt;
     [... and so on iteratively, ad nauseum, down to... ]
Received: by unc (4.12/4.7) id AA06045; Wed, 5 Sep 84 09:07:16 edt
Original-From: &lt;mailer-daemon@mcnc&gt;
Received: by mcnc (4.12/4.7) id AB15479; Wed, 5 Sep 84 08:01:18 edt
Date: Sat, 1 Sep 84 10:03:51 est
Original-From: Mail Delivery Subsystem &lt;MAILER-DAEMON@mcnc&gt;
Subject: Returned mail: Unable to deliver mail
To: mcnc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!pur-ee!davy@unc

   ----- Transcript of session follows -----
554 sendall: too many hops (30 max)

   ----- Unsent message follows -----
Received: by mcnc (4.12/4.7) id AA15479; Wed, 5 Sep 84 08:01:18 edt
From: &lt;mcnc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!pur-ee!davy@unc&gt;
Received: by unc (4.12/4.7) id AA03055; Wed, 5 Sep 84 07:04:54 edt
Original-From: &lt;mcnc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!unc!mcnc!pur-ee!davy@mcnc&gt;
   [...]

   [I am reminded of the tale of the unattended British power station
    equipped with an automatic calling unit to report troubles.  When it
    finally had to dial the emergency reporting number, it received a
    recorded message that the number it had dialed was not valid.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-27</DOCNO>
<DOCOLDNO>IA012-000128-B042-434</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.18.html 128.240.150.127 19970217000655 text/html 17185
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:05:21 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 18</TITLE>
<LINK REL="Prev" HREF="/Risks/1.17.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.19.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 18</H1>
<H2> Friday, 4 Oct 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Lack of a backup computer closes stock exchange 
</A>
<DD>
<A HREF="#subj1.1">
Marty Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
   DPMA survey on computer crime offenses 
</A>
<DD>
<A HREF="#subj2.1">
J.A.N. Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
   Ethics vs. morality 
</A>
<DD>
<A HREF="#subj3.1">
Marty Cohen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
   The Mythical Man-Month of Risk 
</A>
<DD>
<A HREF="#subj4.1">
Stavros Macrakis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
   Risk Assessment by real people 
</A>
<DD>
<A HREF="#subj5.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
   CRTs again, solution to one eye-problem 
</A>
<DD>
<A HREF="#subj6.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
   Failure of Mexican Networks 
</A>
<DD>
<A HREF="#subj7.1">
Dave Flory
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
   Technical Reports Lists 
</A>
<DD>
<A HREF="#subj8.1">
Laurence Leff
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Lack of a backup computer closes stock exchange
</A>
</H3>
<address>
&lt;<A HREF="mailto:mooremj@EGLIN-VAX">
mooremj@EGLIN-VAX
</A>&gt;
</address>
<i>
Mon, 30 Sep 85 11:44:49 CDT
</i><PRE>
To: risks@sri-csl.arpa

When Hurricane Gloria was approaching the New York area, the New York and 
American Stock Exchanges did not open.  The Midwest Exchange, located in
Chicago, opened on schedule; unfortunately, it had to close 40 minutes later,
when its nationwide computer system failed.  Where is the central computer
of that system located?  New York, of course.  The Director of the Exchange
was quoted as saying, "Well, this has got to change."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 DPMA survey on computer crime offenses
</A>
</H3>
<address>
    Jan Lee 
&lt;<A HREF="mailto:janlee%vpi.csnet@CSNET-RELAY.ARPA">
janlee%vpi.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Wed, 2 Oct 85 15:39 EST
</i><PRE>

Peter ... here are the proper figures on Computer Crime Offenses as reported
by the DPMA from a survey taken by COMP-U-FAX (TM) and reported 1985 May 27:

(It doesn't say how many people were surveyed -- just that DPMA is an
organization of 50,000 members.)

21% reported one or more abuses in past 3 years in their workplace.  2% of
these offenses were committed by outsiders (so much for the Hacker myth!!).
The reasons for the abuses were:

  27% ignorance of proper professional conduct
  26% playfulness
  25% personal gain
  22% maliciousness

Only 45% of respondents worked for a company who had a full-time
or part-time data security person.

Only 2.2% of abuses were reported publicly (does that mean
reported to the news media or the legal authorities?).

The surveyor was Detmar Straub, Grad. School of Business Admin.,
Indiana University.

(In a note I got from Donn Parker, Donn seems to cast some aspersions
on the validity of this survey, but I haven't had chance to do anything
other than read the press release myself.)

JAN

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Ethics vs. morality
</A>
</H3>
<address>
Marty Cohen 
&lt;<A HREF="mailto:mcohen%NRTC@USC-ECL.ARPA">
mcohen%NRTC@USC-ECL.ARPA
</A>&gt;
</address>
<i>
Fri, 27 Sep 85 13:18:47 PDT
</i><PRE>

  "Morals: Society's code for individual survival"
  "Ethics: An individual's code for society's survival"

From Theodore Sturgeon, "More Than Human" ("Baby is Three" is one 
part of the book), page 177 of the Ballentine books paperback.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The Mythical Man-Month of Risk
</A>
</H3>
<address>
Stavros Macrakis
&lt;<A HREF="mailto:macrakis@harvard.ARPA ">
macrakis@harvard.ARPA 
</A>&gt;
</address>
<i>
Thu, 3 Oct 85 19:14:56 EDT
</i><PRE>

In reference to the discussion on the Wilson article:
   &gt; ... formula that measures risks [as] ... seconds of life lost ...

In discussing risks, whether from computer systems or other causes, it
would surely be desirable to have some reasonable guidelines.
Wilson's basic point was that we should be able to calculate costs and
benefits; a point with which I am in fundamental agreement.  However,
this calculation has many difficulties.  In this note, I should like
to sketch (in a somewhat disorganized way) some of these difficulties.

It is often useful to reduce complicated facts to simple unidimensional
measures for comparison.  But such reduction loses a great deal of
information in general; and also ignores variation in personal utility
functions.  For that matter, statistical measures should differentiate
between associations and causation.

Among the figures cited, there were several misleading measures along
these lines.

For instance, although perhaps cigarette smokers ought to allocate 12
minutes of their lives per cigarette, a lung cancer death is typically far
harder than an automobile accident death.  On the other hand, car accidents
subtract years by killing fewer, younger, people; cancer by killing more,
but older, people.  How to compare 5 x (lifespan 25-70) with 25 x (lifespan
63-70)?  Is each 175 man-years?  I have no answer, although I have certain
intuitions--in particular, `losing' the 69 man-years 1-70 seems far less
tragic than losing the 69 man-years 3 x (47-70) (`struck down in the prime
of life'): but the Wilson extract did explicitly talk only of 25+-year-olds.
Economics has various answers: discounted productivity contribution; market
value attached to hazardous jobs; ....  None is satisfactory, but all are
useful for separating grossly different risks.

As for correlations, why is it that living in New York is hazardous?
Perhaps it is the pollution.  But if it is the poverty or the street crime,
then poverty or bad neighborhoods (regardless of city) probably relate far
better statistically and surely causally than does residence.  New York just
has many poor people and bad neighborhoods.  A statistical analysis that
excludes such correlated hazards is surely non-trivial.

`Post hoc ergo propter hoc' seems especially implicated in the case of
unmarried males.  There are likely advantages to being married, but
perhaps inability to find or keep a wife indicates other problems.

Then there is the presumption of linear additivity.  Even the risks which
are not strongly correlated may combine: consider asbestosis and smoking.

Of course, in other cases the unidimensional metrics may be far more useful.
In the case of the costs of unreliable funds transfer, the cost to the bank
can be calculated quite precisely.  In cases where these errors affect
customers, it may also be reasonable to estimate that damage (e.g., you may
lose $100 of annual profits per error of type X if a retail customer takes
his business elsewhere).  If you're a materials supplier to a just-in-time
manufacturer, the monetary consequences may be far more serious: still, a
monetary measure may be meaningful.

In conclusion, it seems to me useful to develop a range of measures of cost
and benefit, and not try to reduce them to single numbers.  If one wishes to
be ultra-cautious, one will then weigh the minimum expected benefit against
the maximum expected cost.  If one is a `rational' gambler, perhaps the
average benefit against average cost.  If one is an optimist or a gambler,
perhaps the maximum benefit against the minimum cost.  I believe Howard
Raiffa (among others) discusses such issues (although I'm afraid I can't
provide a reference).

Risk-free systems are unlikely.  We need good ways of evaluating risks
and benefits.
	-s

------------------------------ 

Date: Sat, 28 Sep 85 16:05:48 edt
From: mikemcl@nrl-csr (Mike McLaughlin)
To: RISKS@SRI-CSLA.ARPA
Subject: Risk Assessment by real people

Ellen Goodman's column in The Washington Post, Saturday, 28 Sep 85, (c) 1985,
The Boston Globe Newspaper Company, is worth reading.  Title is: "AIDS: The 
Risks We'll Take."  No, it doesn't mention computers.  It really isn't much 
about AIDS, either.  

What it is about is people, and how risks are assessed by real people - not
by computers, or calculators, but by the folks that would die of boredom
reading this forum... or might die of something else if *we* do not
understand how *they* evaluate risks.

"In California, members of a family cut back on sugar in the decaffeinated 
coffee they drink in their house - on the San Andreas fault."  

"Another friend drinks only bottled water these days, eats only meat un- 
touched by steroids and spends weekends hang-gliding."  

"The AIDS story... is a tale about experts and the public, about the gap 
between our skepticism and our longing for certainty."  

Ms. Goodman also quotes an article in October's Science '85: "We may be much 
more willing to accept higher risks in activities over which we have control, 
such as smoking, drinking, driving or skiing, than things over which we have 
little control, such as industrial pollution, food additives and commercial 
airlines." 

Her summation is very relevant to *us*, who read and write about SDI, the use 
and non-use of computers, and so on: "This is, after all, a country that bans 
saccharin and builds nuclear bombs.  We argue and will go on arguing about 
risk in two different languages: numbers and emotions, odds and anxieties." 

If *we* cannot make ourselves understood by *them* when we discuss what 
matters for the survival of *all of us*, then this forum is just a
modern form of omphaloskepsis.  

- Mike 

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
CRTs again, solution to one eye-problem
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Sat, 28 Sep 85 16:25:57 edt
</i><PRE>

CRTs can cause eye strain in users who wear glasses.  Distance lenses won't 
focus at closer than arm's length.  Reading lenses focus too close.  Bifocals 
require you to hold your head in one of two specific positions... neither of 
which works.  What to do?  

I already done it.  Several years ago.  So much a part of my computerized 
life that I didn't think of it while reading/writing via computer about CRT
usage.  Got "intermediate lenses" - an Rx for glasses optimized for my CRT/
VDT viewing habits.  Got comfy in front of the tube &amp; keyboard, had a friend 
measure distance from bridge of nose to CRT screen.  Averaged several tries. 
Gave the distance to my opthamologist - he turned out an Rx in short order.  

Bought frame &amp; lenses.  Expensive.  Use them *only* at office computer - don't 
take them home (don't have a computer at home).  Declared them as a non-
reimbursed business expense.  IRS content, helped reduce cost.  

Did NOT get tri-focals, because: 
  1.  They force you into an even more rigid head position - and I believe 
that rigid posture is a major cause of computer-fatigue.  
  2.  They confused the IRS issue, which was quite clear with intermediate-
only glasses.  
  3.  I'm not old enough to wear TRI-focals, for heaven's sake!  

Suggestion: 
  Employers requiring use of CRT should consider paying for intermediates; 
should resist paying for trifocals (or even the incremental cost of tri- over 
bi-focals).  
  An acceptable alternative might be bifocals, distance/intermediate or inter- 
mediate/reading, depending upon the user's eye condition and job content.  

	- Mike 

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Failure of Mexican Networks
</A>
</H3>
<address>
Shadow 
&lt;<A HREF="mailto:Z.HXWY-FLORY-DAVID%CRNL20A.BITNET@UCB-VAX.Berkeley.EDU">
Z.HXWY-FLORY-DAVID%CRNL20A.BITNET@UCB-VAX.Berkeley.EDU
</A>&gt;
</address>
<i>
Wed 2 Oct 85 13:43:03-EDT
</i><PRE>
To: Risks@sri-csl.arpa

This doesn't refer to computer networks, but it is similar.

According to Fred Goldstein on Telecom Digest (Telecom-Request@MIT-MC.ARPA),
phone service from most of the world to Mexico City was destroyed by the
collapse of the building containing the switches, frames, etc. for Mexico
City's international gateway switch.

Sites which are major network nodes collapsing due to earthquake/etc could
result in a similar effect.

David Flory

ARPANET ---&gt; flory@CORNELL-GVAX.ARPA or shadow@RU-AIM.ARPA
BITNET ----&gt; z.hxwy-f@CRNL20A.BITNET

    [Good engineering tends to avoid sensitivity to single-point failures 
     and to avoid singly connected nodes.  Designing for massive failures
     and disasters is of course much more difficult.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Technical Reports Lists
</A>
</H3>
<address>
Laurence Leff 
&lt;<A HREF="mailto:leff%smu.csnet@CSNET-RELAY.ARPA">
leff%smu.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Fri, 27 Sep 85 13:38:21 cdt
</i><PRE>
To:  [... all sorts of lists...]

   [Here is what could be a useful service if suitable indexing occurs.  I
    have stripped Laurence's message down.  SEND to him for the original.
    This is of course more general in scope than just RISKS, but seemed
    worth including. -- in case you missed it elsewhere.  Respond to him,
    not me.  PGN]

I have volunteered to organize an electronic mechanism for the distribution
of technical report lists from Universities and R&amp;D labs.  Some (and
hopefully all) of the people producing technical reports would send a copy
of the list to me.  I would then send these to a moderated group on USENET
as well as a mailing list for those sites on the INTERNET who do not get
news (ARPANET, CSNET, etc.).

I need two things from you:
  1) if your organization prepares technical reports and sends them
      out to interested parties (perhaps for a fee), please arrange
      to have electronically readable copy of your lists sent
      to trlist%smu@csnet-relay.  
  2) if people at your organization would like to receive lists
     of tech reports produced by universities and R&amp;D labs, please
     provide me an electronic address to send them to (if you are not
     on USENET).  Send such administrative mail to trlist-request%smu@
     csnet-relay.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-28</DOCNO>
<DOCOLDNO>IA012-000128-B042-459</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.19.html 128.240.150.127 19970217000715 text/html 14428
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:05:40 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 19</TITLE>
<LINK REL="Prev" HREF="/Risks/1.18.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.20.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 19</H1>
<H2> Monday, 7 Oct 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Emanations and interference in the civil sector 
</A>
<DD>
<A HREF="#subj1.1">
Peter Neumann
</A><br>
<A HREF="#subj1.2">
Jerry Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Administrivia -- Escaped Mail and Delays 
</A>
<DD>
<A HREF="#subj2.1">
Mark S. Day
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer databases 
</A>
<DD>
<A HREF="#subj3.1">
Andy Mondore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Friendly test teams 
</A>
<DD>
<A HREF="#subj4.1">
John Mashey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: CRTs again, solution to one eye-problem 
</A>
<DD>
<A HREF="#subj5.1">
Brint Cooper
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Emanations and interference in the civil sector
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSLA.ARPA">
Neumann@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Sun 6 Oct 85 15:16:38-PDT
</i><PRE>
To: RISKS@SRI-CSLA.ARPA

I have had several queries about risks in the civil sector concerning
electronic emanations from and electronic interference upon computer systems
and networks -- and of course also about what can be done to protect oneself
or one's company.  For example, Martin Lee Schoffstall &lt;schoff%rpi.csnet
@csnet-relay.arpa&gt; wondered along these lines:

	If you were building a hospital from scratch, would you consider
	shielding for your computer room, how many electron volts would
	you shield for, etc.?

	In general I would like some feedback for us civilians...

This subject is generally a technically intricate one, but some guidance is
clearly necessary for the civil sector.  Thus, it seems worthwhile to note
several examples that represent varying degrees of risk to the public.
(Since microprocessor-controlled systems are becoming ubiquitous, related
problems are likely to recur in other guises.  But let us not quibble about
whether THESE examples are sufficiently computer-related.)  The first three
examples involve interference; all but the third involve emanations.

  Transmit: Microwave oven emanations
  Receive:  "Externally reprogrammable" heart pacemaker --  interference;
            pacemaker reset by microwaves to 214 beats per minute
  Result:   Dead patient (See Software Engineering Notes vol 5 no 1 Jan 1980.)

  Transmit: Anti-theft device emanations
  Receive:  Heart pacemaker -- interference
  Result:   Patient OK (See Software Engineering Notes vol 10 no 2 Apr 1985,
            but I have seen nothing more recent.)

  Transmit: Active radar jammer (in speeder's auto)
  Receive:  Police radar receiver
  Result:   In one currently popular device, the jammer simulates a fault
            mode common in the design of many police radars systems.
            (... a program bug or an electronic interface problem?)

  Transmit: Police radar transmitters
  Receive:  Radar signals (received by transmitter, and by targetted autos)
  Result:   With passive detector, driver can avoid arrest.

  Transmit: Microwave telephone transmitters (telephone company)
  Receive:  Capture telephone conversations and data (observer)
  Result:   Compromise

  Transmit: Radiating CRT or keyboard (unsuspecting computer user)
  Receive:  Recreate screen image or typed input remotely (observer)
  Result:   Compromise  (Unclassified technology for doing this has
            recently been described in a European defense magazine.)
            [The RISKS Forum has discussed CRT radiation with respect
            to possible health hazards, so I won't list that again.]

The radar detector and jammer are marginally computer-relevant, and are
included here primarily because they are illustrative of deeper problems --
fielding a computer system and its surrounding environment that can be
defeated in some relatively simple way.  [By the way, this forum does not
endorse or promote illegal activities -- we merely need to point out their
existence.]  (I have not included in this list the garage-door openings and
closings triggered by the orbiting Sputnik, which happened to be on the
right frequency.)

Emanations and interference may be accidental or intentional.  Passive
techniques for detection may require some computing as in the case of
unscrambling multiplexed communications.  Active techniques (e.g., for
intentional jamming) are at this point much less common, but are likely to
present greater risks in the future.  There are all sorts of more or less
relevant laws, but they are probably neither complete enough nor concise
enough.  There are also all sorts of commonly available devices for those
who want to break the laws.

This note is intended to help raise the general level of awareness.  With
pretenses of corporate secrecy being what they are, it would be nice to be
able to assess the real risks.  In the past, many of these risks have seemed
obscure, but that seems to be changing.  Suggestions on how to avoid those
risks are welcome.  (There are of course also nonelectronic forms of
emanations; various penetrations are reported to have begun with information
-- including passwords -- gained by reading the contents of dumpsters.)

The answers to Marty Schoffstall's hospital query, and other such questions,
depend on the perceived risks against which you think you are defending.
For Marty's example, are you trying to provide survival of the hospital
computers and communications against nuclear attack? or something less
serious such as intentional jamming or accidental interference?  Might you
be worried about compromises of privacy resulting from wire-taps and
microwave pickups of computer information?  Each threat suggests a variety
of possible measures or countermeasures.   PGN

</PRE>
<HR><H3><A NAME="subj1.2">
Emanations and interference in the civil sector
</A>
</H3>
<address>
 Saltzer@MIT-MULTICS.ARPA 
&lt;<A HREF="mailto:Jerry Saltzer">
Jerry Saltzer
</A>&gt;
</address>
<i>
Fri, 4 Oct 85 18:02 EDT
</i><PRE>
To:  Neumann@SRI-CSL [in response to a query]

Concern for Electromagnetic Compatibility is indeed beginning to become an
important design consideration in consumer products.  These days, TV sets
are beginning to clean up their act, but the average FM tuner just can't
cope with being in a substantial RF field.  As consumers start to collect a
walkman, TV, cable converter, FM tuner, stereo amplifier, VCR, CD player,
cordless phone, remote control light switches, microwave oven, and
garage-door opener under one roof, more and more people are becoming aware
of the problems, and discovering that some manufacturers didn't put the
right effort in.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Administrivia -- Escaped Mail and Delays
</A>
</H3>
<address>
Mark S. Day 
&lt;<A HREF="mailto:MDAY@MIT-XX.ARPA">
MDAY@MIT-XX.ARPA
</A>&gt;
</address>
<i>
Thu 3 Oct 85 20:07:38-EDT
</i><PRE>

[ Excerpted-From: Soft-Eng Digest    Sat,  5 Nov 85    Volume 1 : Issue  34 ]

XX was a victim of Hurricane Gloria; it had multiple head crashes when it
was restarted after the storm.  The heroic efforts of the staff here brought
the machine back to life after a marathon of restoring files, which
unfortunately left the alias for this list in a strange state.  Instead of
going into my mailbox, everything sent to "Soft-Eng" was immediately
redistributed.  Fortunately, only one message got out between the time XX
came up and the time I noticed the problem.  Anyway, sorry for the
difficulties.  No doubt this will now appear in the RISKS mailing list as an
example of an unreliable computer system...  

   [SURE.  WHY NOT??!! Recovery and reinitialization are a vital part of
    keeping a system running properly.  How many times have you put in a
    patch or fix only to find that it somehow disappeared, e.g., not 
    surviving a crash or not getting propagated back into the source code?  
    But in this case you got left in an unsafe state!  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer databases
</A>
</H3>
<address>
&lt;<A HREF="mailto:Andy_Mondore%RPI-MTS.Mailnet@MIT-MULTICS.ARPA">
Andy_Mondore%RPI-MTS.Mailnet@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Sat, 28 Sep 85 16:20:46 EDT
</i><PRE>

One topic I have not seen discussed here is that of computer databases.  I
am Systems Coordinator for the Registrar's Office here so I am in charge of
a fairly large database containing (obviously) student grade and course
information as well as addresses, demographic information, etc.  I'd like to
see a discussion of the risks of having incorrect information in a database,
information being seen or accessed by the unauthorized individuals, etc.
Thanks.

    [Ah, yes.  This is a wonderful topic.  The state of the art of database
     management systems that can handle sophisticated privacy/compromise and
     data integrity problems is rather abysmal.  However, the risks of
     people gleaning information by drawing inferences from a database are
     considerable.  For starters, see Dorothy Denning's book, Cryptography
     and Data Security, Addison Wesley, 1982.  As to risks, Software
     Engineering Notes has had a bunch of stories on the effects of misuse
     or mininterpretation of police data.  The Air New Zealand catastrophe
     was an example of what can happen if a change is not propagated
     properly.  As always, contributions are welcome.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Friendly test teams
</A>
</H3>
<address>
John Mashey
&lt;<A HREF="mailto:mips!mash@glacier ">
mips!mash@glacier 
</A>&gt;
</address>
<i>
Sat, 28 Sep 85 22:31:18 pdt
</i><PRE>

It might be good to ask for pointers to published data on bug histories,
effort levels, robustness in large hardware/software systems.  I suspect
these may be hard to find for SDI-like systems; I couldn't dig up any old
Safeguard info.  Although not in the same class of difficulty, ATT's new #5
ESS switch is fairly complex (300+ engineers).  A good reference is:  H.A.
Bauer, L.M. Croxall, E.A. Davis, "System Test, First-Office Application, and
Early Field Experience", ATT Technical Journal, vol 64, No 6, Part 2
(Jul-Aug 1985), 1503-1522.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Re:  CRTs again, solution to one eye-problem
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Sun, 6 Oct 85 12:59:18 EDT
</i><PRE>

     [We started out keeping one eye on this problem, but it does not
      want to stay out of sight.  Will this be the last message?  PGN]

A cheaper but similar solution was suggested by my opthalmalogist when I
attained that stage of life wherein my arms are too short.

Since I needed a small, positive correction (about +1.0) in each eye, I
purchased, at his suggestion, "reading glasses" from the local pharmacy for
about $12.00.  Since then, my eyes have worsened a little and I need about
+1.25 to +1.5 diopters for reading.  But this is too strong for the terminal
(an AT&amp;T 5620 with rather small font), so I retained the old +1.0 diopter
lenses for the terminal at work.  At $12.00 each, I can afford to have a
pair at the office, a pair at home, and a pair to carry.

Note:  This won't work if one has astigmatism or if one needs widely
different corrections in each eye.  But ask your doc.  You can buy a lot of
OTC glasses for $200.

Oh yes, it is a small nuisance to switch glasses from terminal lenses to
reading lenses, but one learns quickly to minimize the hassle.

Brint

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-29</DOCNO>
<DOCOLDNO>IA012-000128-B042-477</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.20.html 128.240.150.127 19970217000728 text/html 15936
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:05:56 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 20</TITLE>
<LINK REL="Prev" HREF="/Risks/1.19.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.21.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 20</H1>
<H2> Wednesday, 9 Oct 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks using robots in industry 
</A>
<DD>
<A HREF="#subj1.1">
Bill Keefe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Computer databases 
</A>
<DD>
<A HREF="#subj2.1">
Matt Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Registrar's databases; Database risks - census data 
</A>
<DD>
<A HREF="#subj3.1">
Hal Murray
</A><br>
<A HREF="#subj3.2">
 2 messages
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The winners of evolution... 
</A>
<DD>
<A HREF="#subj4.1">
William McKeeman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks using robots in industry
</A>
</H3>
<address>
Bill Keefe
&lt;<A HREF="mailto:keefe%milrat.DEC@decwrl.ARPA  ">
keefe%milrat.DEC@decwrl.ARPA  
</A>&gt;
</address>
<i>
Tuesday,  8 Oct 1985 07:26:03-PDT
</i><PRE>

I don't know who to credit with typing this in.  I was going to summarize,
but it's too easy to take some points out of context. It brings up many 
questions as to who bears the responsibility (liability?) to protect people 
from such occurrences.
 
                   --------------------------------

            In The Lion's Cage"      [Forbes  Oct. 7, 1985]

On July 21, 1984, at about 1 p.m., a worker at Diecast Corp. in Jackson, Mich.
found Harry Allen, 34, a diecast operator pinned between a factory pole and the 
back of an industrial robot. But Allen's co-worker couldn't come to his aid. 
Using the robot's controller, the company's director of manufacturing finally 
unpinned Allen, who was alive but in cardiac arrest. He died in a hospital 
five days later.

Allen had entered a restricted area,  presumably to clean up scrap metal from 
the floor. While there, he got in the way of the robot's work, and thus became 
the first - and so far only - U.S. victim of an industrial robot-related 
accident.

That's not a bad safety record, considering that 17,000 robots are now 
installed in the U.S. But the bet is he won't be the last. The Japanese, who 
lead the world in robot installations, also lead in robot-related fatalities: 
There have been reports of at least 5, and possibly as many as 20, such deaths 
in Japan.

That's only fatalities. In this country, companies are not required to report 
injuries related to specific equipment, so no reliable data are available. But 
in Sweden, a pioneer in the use of industrial robots, one study estimates that 
there is 1 accident a year for every 45 robots. By 1990, when the number of 
robots installed in American Industry could climb as high as 90,000, the 
number of injuries could climb accordingly. That's because robots move quickly 
and are programmed to go through a series of motions without stopping. A 
worker who gets in the way can be struck, pushed aside, crushed or pinned to 
a pole as Allen was.

How will industry minimize the risk to its workers? Probably with difficulty. 
Robots don't easily accommodate safeguards. Whereas most machinery operates 
within a fixed set of boundaries, robots have a large "striking distance" - the 
reach of their mobile arms within three dimensions. In automotive assembly 
plants, maintenance workers often collide with robots adjacent to the ones 
they're servicing because they don't realize they are in another robot's work 
area. A robot may perform one task five times and then start on a completely 
different  activity, and with it a different set of motions. Also, a robot can 
sit idly for a time and then come to alive again, threatening injury to a 
worker who mistakenly thought it was shut down.

What's being done to make robots safer? Right now, not much. "The extent of 
most safety precautions are signs saying, 'Restricted Area: Keep Out,' or 
maybe a guardrail," says Howard Gadberry of the Midwest Research Institute in 
Kansas City, Mo. Indeed, the most common safeguards - perimeter barriers such 
as guardrails and electric interlocked gates, which automatically shut down 
the robot when opened - don't protect those maintenance workers and programmers 
who must enter the lion's cage. Presence-sensing devices, such as 
pressure-sensitive mats and light curtains, both of which automatically cut 
off a robot's power, also don't seem to offer as much protection as is needed, 
if only because workers are even more unpredictable in their movements than 
robots. They may not step on the mat when feeding parts to a robot, or they 
may not break a light curtain's beam.

That's not to say that robots can't be made safer. Researchers at the 
Renssalaer Polytechnic Institute, for example, recently completed a research 
prototype for several large U.S. companies of a four-sensor safety system that 
continuously monitors the area around a robot. Using ultrasonic, infrared, 
capacitance and microwave sensors, the RPI system is designed to stop a robot 
in its tracks if a worker gets too close. Cost?  Five thousand dollars 
in production, according to Jack Meagher, a senior project manager at RPI.

The National Bureau of Standards has also been working with ultrasonic sensors 
on robot arms similar to the system at RPI. They both have developed a 
secondary, or watchdog, computer to monitor the actions of the robot and its 
microprocessor. After all, if the robot's computer goes berserk, how can it 
monitor itself? That's more important than you might think, 30% of robot 
accidents seem to be caused by runaways, according to John Moran, director of 
research at the National Institute for Occupational Safety &amp; Health.

While such systems slowly make the transition form research to the factory 
floor, industry is trying to put basic safety standards into practice. 
Recently, the Robotic Industries Association proposed a set of national safety 
standards for robots that could go into effect as early as next summer.

Would such standards have prevented Harry Allen's death? Maybe not. The robot 
at the Diecast plant was surrounded by a safety rail with an electric 
interlocked gate that automatically shut down the robot when the gate was 
opened. However, there were two gaps in the rail that allowed workers to 
easily bypass the safeguard; that has since been corrected by the company.

Says Allan Harvie, deputy director of the Michigan Department of Labor's 
bureau of safety and regulation, "I could only presume Harry Allen thought he 
could go in and do what he intended to do without having to shut the robot 
down."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Computer databases
</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:mab@riacs.ARPA">
mab@riacs.ARPA
</A>&gt;
</address>
<i>
8 Oct 1985 1123-PDT (Tuesday)
</i><PRE>

   I guess I'll start the ball rolling on this discussion.

   I think the greatest risk is not from the technological end but the
human end.  For instance, there was a case a couple of weeks back where
someone got stopped for a traffic ticket.  Call this gentleman John Lee
Jones (I've forgotten his real name.)  A routine computer check showed
James Lee Jones was a fugitive from an LA warrent, and the description
of James Lee Jones was pretty close to what John Lee Jones looked like.
So the SFPD hauled him downtown, and ran a fingerprint check to see
if there was anything else they could find out about John Lee Jones.
Turned out he had used several aliases in the past -- so the SFPD
notified the LAPD they had arrested James Lee Jones, and would the LAPD
please come up and get him?  The LAPD obliged, took him down to LA,
and notified the prosecutors.

   Throughout all this, Mr. Jones was (vehemently) denying he was James
Lee Jones.  About a week after he had first been locked up, his public
defender persuaded the judge to order the police to compare John Lee
Jones' fingerprints with James Lee Jones' fingerprints.  They didn't
match.  End of case.

   What's so surprising is that the people throughout the whole
proceeding did not question whether the data the computer gave them was
relevant.  True, it was accurate (so far as I know.)  But it was used
incorrectly.  In other words, in this case the technology didn't fail;
the human safeguards did.  (Incidentally, in defense of the police,
when this came out an investigation was begun to see why the
fingerprint comparison was not made immediately; according to police
procedure it should have been.)  And no amount of database security can
guard against this type of breach of security.

[Caveat -- I read the newspaper story I outlined above a couple
 of weeks ago in the S.F. Chronicle.  I have undoubtedly misremembered
 some of the details, but the thrust of it is correct.]

Matt Bishop

    [Add that to the database-related cases of false arrest reported in 
     RISKS-1.5.   PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Registrar's databases
</A>
</H3>
<address>
&lt;<A HREF="mailto:Murray.pa@Xerox.ARPA">
Murray.pa@Xerox.ARPA
</A>&gt;
</address>
<i>
Tue, 8 Oct 85 06:59:25 PDT
</i><PRE>
To: RISKS@sri-csl.arpa

Just mentioning grades, computers and risks, all in the same paragraph
instantly brings to my mind visions of hackers who are flunking freshman
English smiling anyway, knowing that they have figured out how to get an A.

I've always assumed that everybody "knew" that students and grades couldn't
really coexist on the same machine. Does anybody know of a school
brave/silly enough to do it?

It seems like a great opportunity for somebody who makes a secure system to
get a LOT of publicity, one way or the other. Has anybody ever been
confident enough to try it? What happened?

Changing the topic slightly... Security on an ethernet is clearly
non-existent unless you encrypt everything you care about. Our personnel
people upstairs take the problem seriously. The solution is simple. They
have their own section of coax. It's not even gatewayed to the rest of our
network.

</PRE>
<HR><H3><A NAME="subj3.2">
Database risks - census data
</A>
</H3>
<address>
&lt;<A HREF="mailto:Murray.pa@Xerox.ARPA">
Murray.pa@Xerox.ARPA
</A>&gt;
</address>
<i>
Tue, 8 Oct 85 07:15:28 PDT
</i><PRE>
To: RISKS@sri-csl.arpa

The census bureau distributes their data broken down to quite small areas. I
don't know the details, but I'm pretty sure it gets down to "neighborhood"
sized regions, and it may even get down to the block.  When the sample size
gets small enough, there are obviously opportunities for gleaning
non-statistical information by using carefully crafted querys to read
between the lines.

I remember somebody telling me that they worked pretty hard to make sure
this couldn't happen. Anybody know what they actually do? Is it written up
someplace? Does it work well enough? Any war stories? Are the techniques
simple once you know the trick? ....

   [As I noted in <A HREF="/Risks/1.19.html">RISKS-1.19</A>, Dorothy Denning's book is a good source.
    The Census Bureau tries to add phony data that preserves all of the
    overall statistics but that prevents inferences...   PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The winners of evolution...
</A>
</H3>
<address>
William McKeeman 
&lt;<A HREF="mailto:mckeeman%wang-inst.csnet@CSNET-RELAY.ARPA">
mckeeman%wang-inst.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Tue 8 Oct 1985 10:00:15 EST
</i><PRE>
To: risks@sri-csl

A recent submission included the following paragraphs on evolution
of morals...

	 Now I think it fairly easy to see that the capacity to put
	 group survival ahead of self-interest is an important genetic
	 trait and that tribes of people that had this trait would be
	 more likely to survive that tribes that didn't.  That is not
	 to say that this moral capacity doesn't vary greatly from one
	 person to the next or that even that it may not be more fully
	 realized in one person than another because of upbringing.  It
	 is even possible that, because of some genetic error, some
	 people may be born without a moral capacity, just like they
	 might be born without arms or legs.

	 Moral progress means the evolution of survival customs more
	 appropriate to the current context.  The trouble in recent
	 centuries has been that our ability to evolve new technology
	 has outstripped our capacity to evolve the appropriate
	 morality for it.  There is a strong tendency to stick to the
	 morality that one learns as a child, even if it [is] not
	 appropriate to the current situation.

Evolution is being used with its Darwinian meaning but with an
interpretation that includes the more ordinary progress of mankind.  The
central mechanism of evolution is the failure of the less successful forms
to reproduce -- often for failing to live long enough.  Evolution is never
fast enough to avoid bloodshed -- it is bloodshed that activates it.  Until
disaster strikes the adapted and unadapted survive undifferentiated.

My point is that if we treat the present sad state of affairs as a problem
in evolution rather than politics or technology, we are implicitly planning
on rebuilding a world with the (apparently) adapted survivors of WWIII.

W. M. McKeeman            mckeeman@WangInst
Wang Institute            decvax!wanginst!mckeeman
Tyngsboro MA 01879

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-30</DOCNO>
<DOCOLDNO>IA012-000128-B042-511</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.21.html 128.240.150.127 19970217000745 text/html 23642
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:06:09 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 21</TITLE>
<LINK REL="Prev" HREF="/Risks/1.20.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.22.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 21</H1>
<H2> Thursday, 10 Oct 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Public Accountability 
</A>
<DD>
<A HREF="#subj1.1">
Jim Horning
</A><br>
<A HREF="#subj1.2">
 Peter Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The Titanic Effect 
</A>
<DD>
<A HREF="#subj2.1">
JAN Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Databases, Grades, etc. 
</A>
<DD>
<A HREF="#subj3.1">
Brian Borchers
</A><br>
<A HREF="#subj3.2">
 Andy Mondore
</A><br>
<A HREF="#subj3.3">
 Mark Day [twice]
</A><br>
<A HREF="#subj3.4">
    Alan Wexelblat
</A><br>
<A HREF="#subj3.5">
 Ross McKenrick
</A><br>
<A HREF="#subj3.6">
 Randy Parker
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Public Accountability
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.ARPA ">
horning@decwrl.ARPA 
</A>&gt;
</address>
<i>
10 Oct 1985 1244-PDT (Thursday)
</i><PRE>

It has now been more than a year since the ACM Council passed its
resolution on computer systems and risks to the public. Quoting from
RISKS-1.1:

  The second part of the resolution includes a list of technical questions
  that should be answered about each computer system.  This part states that:

    While it is not possible to eliminate computer-based systems failure
    entirely, we believe that it is possible to reduce risks to the public
    to reasonable levels.  To do so, system developers must better
    recognize and address the issues of reliability.  The public has the
    right to require that systems are installed only after proper steps
    have been taken to assure reasonable levels of reliability.

    The issues and questions concerning reliability that must be addressed
    include:

    1. What risks and questions concerning reliability are involved when
       the computer system fails?

    2. What is the reasonable and practical level of reliability to
       require of the system, and does the system meet this level?
  
    3. What techniques were used to estimate and verify the level of
       reliability?

    4. Were the estimators and verifiers independent of each other
       and of those with vested interests in the system?

In the intervening year, I am not aware that the developers of ANY
computer system have made public their answers to these four questions.
Readers of this forum will surely not leap to the conclusion that no
computer system presents risks to the public worthy of discussion.

I would like to start a discussion on how we can change this.
What can we do as professionals to make it the norm for system
developers to present risk assessments to the public?

  * What can we do to make it more attractive to present a risk assessment?

    - Explicitly invite developers of particular systems to publish draft
      assessments here in the RISKS Forum, with the promise of constructive
      feedback.

    - Inaugurate a section in CACM for the publication of refined risk
      assessments of systems of great public interest or importance.

    - Publish the risk assessments without refereeing. This gives the
      developers "first shot," gets the material out more quickly, and lowers
      the barrier to publication, without limiting the opportunity for public
      discussion and debate.

    - Encourage developers to also address John McCarthy's question:
    
        5. What are the risks inherent in the best available alternative
           to the system in question?

    - Encourage the exploration of legal steps that would make
      Risk Assessments as routine as Environmental Impact Statements.
      (This could be useful even if most of the former are as pro forma and
      unenlightening as most of the latter; they provide a starting point.)

  * What can we do to make it less attractive not to present a risk assessment?

    - First, make it very clear that we, as a profession, believe that it
      is incumbent on system developers to present their risk assessments,
      and that delay or refusal amounts to malpractice of a very high order.

    - Periodically publish (and publicize) the status of all outstanding
      invitations to present risk assessments.

    - Bring cases of persistent noncompliance to the attention of ACM
      Council for appropriate action.

I present these suggestions as a springboard for discussion, not as a
definitive program for action. I welcome suggestions for improvement.

Jim H.

</PRE>
<HR><H3><A NAME="subj1.2">
Public Accountability
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Thu 10 Oct 85 13:30:24-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA
cc: Horning@DECWRL.DEC.COM

Perhaps we can learn something from some steps that have been taken by the
National Computer Security Center (although for security and not
reliability).  The NCSC (formerly the DoD CSC) has established a set of
criteria for trusted computer systems, in the form of a range of
increasingly stringent requirements.  They have evaluated various systems
against those criteria.  They have also explored what kinds of applications
should have which requirements.  To date, two systems have been accorded
high rankings:  (1) the highest existing rating [A1] to the Honeywell SCOMP
-- whose kernel design and trusted subsystems have undergone formal design
proofs demonstrating that the kernel specifications satisfy a security
condition of no adverse flow, and that the trusted subsystems satisfy other
relevant properties involving privilege, integrity, and functional
correctness; (2) a somewhat lower rating [B2] to Multics, which has not been
subjected to any formal analysis, but which satisfies certain of the
hardware and software-engineering criteria and which has withstood extensive
penetration attacks.  Other systems have also been evaluated, but given
lesser ratings -- implying greater potential security risks.  (The NCSC also
publishes an Evaluated Products List.)  The literature on this subject is
extensive, but I note a few items here on the Criteria and on the SCOMP
proofs.  Other than that, you can look at the IEEE Proceedings for the
Security and Privacy conferences each April and the National Computer
Security Conferences held at NBS roughly once a year (previously called the
DoD/NBS Computer Security Conference).

I of course need to add that the work on secure and trusted computing
systems is only a very small part of that addressing the potential "risks to
the public", which of course also involve reliability in various forms,
human safety, timely responsiveness, etc.  But my point is that some steps
in the right direction are actually being taken in the security community --
although those are still only small steps with respect to the overall
problem.  Nevertheless, something can be learned from the security work
in addressing the ACM goals that Jim has reminded us of once again.

So, let us try to address some of Jim's points specifically in the future.


REFERENCES:

  CRITERIA: Department of Defense Trusted Computer System Evaluation
  Criteria, CSC-STD-001-83.  Write to Sheila Brand, National Computer
  Security Center, Ft Geo G Meade MD 20755.  (SBrand@MIT-Multics)

  SCOMP KERNEL DESIGN PROOFS:  J.M. Silverman, Reflections on the Verification
  of the Security of an Operating System, Proceedings of the 9th ACM Symposium
  on Operating Systems Principles, October 1983, pp. 143-154.

  SCOMP TRUSTED SUBSYSTEM DESIGN PROOFS: T.C.V. Benzel and D.A. Tavilla,
  Trusted Software Verification: A Case Study, Proceedings of the 1985
  Symposium on Security and Privacy, IEEE Computer Society, Oakland CA, April
  1985, pp. 14-31.

(Note: In a proof of design consistency, the proof must show that a formal
specification satisfies a set of requirements, e.g., for security or fault
tolerance.  The difference between requirements and specifications in that
case is generally that the former tend to be simply-stated global
properties, while the latter tend to be detailed sets of constraints defined
[e.g.,] functionally on state transitions or algebraically on inputs and
outputs.)

----------------------------------------------------------------------

Date:     Tue, 8 Oct 85 16:26 EST
From:     Jan Lee &lt;janlee%vpi.csnet@CSNET-RELAY.ARPA&gt;
To:       RISKS@sri-csl.arpa
Subject:  The Titanic Effect

THE TITANIC EFFECT  (Source unknown):

    The severity with which a system fails is directly proportional
    to the intensity of the designer's belief that it cannot.

COROLLARY:

    The quantity and quality of built-in redundancy is directly
    proportional to the degree of concern about failure.


JAN

----------------------------------------------------------------------

Date: Wed, 9 Oct 85 09:43:20 EDT
From: Brian_Borchers%RPI-MTS.Mailnet@MIT-MULTICS.ARPA
To: risks@sri-csl.arpa
Subject: Databases, Grades, etc. 

Here at RPI, The Registrar's database, as well as the Bursar's systems are
on the same machine that we use for academic work.  We've put a lot of
effort into making MTS secure...

   [By the way, some of this issue's discussions on the low risks of putting
    grades on student computers reflect overall a benevolent naivete about
    the system security risks.  I have not tried to comment on each message
    individually, but find them intriguing.  One could turn the students
    loose to see how many flaws they can find, perhaps as a part of a
    course: give them all F's in the database, and let them try to earn 
    their A's by breaking in!  On the other hand, you might find the last
    one who breaks changes some of the A's to F's!  It is dangerous to
    announce in public that you as an administrator believe you have made 
    unauthorized alterations difficult or impossible; knowing how badly
    flawed most of the systems are, that is a very large red flag to wave.
    But then you apparently need to be shown that you are wrong.  Audit trails 
    are great too, but watch out for the penetrated superuser interface.
    (This comment only touches the tip of the iceberg.  Judging from this
    issue's contributions, I imagine the discussion might run for a while.
    Let's get down to specific cases if we can, but not just students' 
    grades -- which are only an illustrative problem.)  PGN]  

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Databases, Grades, etc. 
</A>
</H3>
<address>
&lt;<A HREF="mailto:Andy_Mondore%RPI-MTS.Mailnet@MIT-MULTICS.ARPA">
Andy_Mondore%RPI-MTS.Mailnet@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 9 Oct 85 11:36:54 EDT
</i><PRE>

Hal Murray in <A HREF="/Risks/1.20.html">RISKS-1.20</A> asks whether any schools are "brave/stupid enough"
to have students and grades on the same computer.  Well, that is the
situation here.  Administrators and students use the same mainframe.
Administrative here generally use several extra layers of security such as
extra passwords, allowing sign-ons to certain accounts only from specific
terminals, and logging all successful and unsuccessful sign-ons to our
accounts.  So far, we in the Registrar's Office have not detected any
unauthorized sign-ons (and we have never noticed any strange changes to
files) although we occasionally detect an unsuccessful sign-on attempt from
an unauthorized location.  Generally, changing passwords frequently and
using non-words and special characters for passwords seems to take care of
the unauthorized access problem.

One thing that Hal did not mention is security problems when students and
grades are on separate computers but on the same network, perhaps to share a
special device or certain files. It seems to me that there could be almost
as many potential security problems with this configuration as with my
configuration. Does anyone have experience with this type of configuration
and if so, what problems have you had?

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Databases, Grades, etc. 
</A>
</H3>
<address>
Mark S. Day 
&lt;<A HREF="mailto:MDAY@MIT-XX.ARPA">
MDAY@MIT-XX.ARPA
</A>&gt;
</address>
<i>
Wed 9 Oct 85 09:50:12-EDT
</i><PRE>
To: risks@SRI-CSL.ARPA

I tend to think that stories about crackers changing their grades should be
taken with a fairly large dose of salt.

I once had the occasion to interview a vice-chancellor at my undergraduate
university, and he explained the system there in some detail.  Basically,
they handled grades the way a bank handles money -- that is to say, there
were 'audit trails' and paper copies of everything.

Discrepancies between what was in the computer and what was in the paper
records would eventually get caught, even if there was a period of time when
the wrong grades would show up on an official transcript.  Correctly faking
ALL the records so as to escape an audit would have required a great deal of
knowledge (basically, it would have to be an inside job -- and they didn't
have students working in these offices).

--Mark

</PRE>
<HR><H3><A NAME="subj3.2">
Databases, Grades, etc.
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Wed 9 Oct 85 11:39:54-PDT
</i><PRE>
To: MDAY@MIT-XX.ARPA
cc: Neumann@SRI-CSL.ARPA

Mark, I find myself disbelieving some of what you say.  Manual comparisons
tend to get done (if at all) when the data is entered.  Auditing tends to
get slighted, since people often tend to assume the computer is right! (The
Santa Clara inmate who changed his release date did get caught, but perhaps
only because a guard overheard him bragging about how he was going to get
out early.)  Most vice-chancellors (and many administrators) would probably
tell you they are doing things right, and better than everyone else.  That
is the head-in-the-sand view of computing -- everything is just fine.  But
audit trails and paper copies of everything are not sufficient, even if they
are diligently used.  "Discrepancies ... would eventually get caught" is
certainly hopeful, at best.  Peter

</PRE>
<HR><H3><A NAME="subj3.3">
Databases, Grades, etc.
</A>
</H3>
<address>
Mark S. Day 
&lt;<A HREF="mailto:MDAY@MIT-XX.ARPA">
MDAY@MIT-XX.ARPA
</A>&gt;
</address>
<i>
Wed 9 Oct 85 14:51:40-EDT
</i><PRE>
To: Neumann@SRI-CSL.ARPA

Peter,

I still maintain that the scenario of "student changes grades to A's and
lives happily ever after" seems dubious.  It seems to be one of these
apocryphal stories where everyone knows about someone who's done it, but
there's little evidence floating around about it (sort of like stories about
people putting cats in microwave ovens to dry them).

Your other comments are well-taken.  It certainly requires administrators,
etc., to have a perception of the problem; that was one reason I was
impressed by my interview with the vice-chancellor.  Several years ago,
crackers were not yet in the public eye, so I was pleasantly surprised to
find out that anyone cared about the overall integrity of the grades
database and talked about the need to regularly audit it.

--Mark

</PRE>
<HR><H3><A NAME="subj3.4">
Databases, Grades, etc.
</A>
</H3>
<address>
Alan Wexelblat 
&lt;<A HREF="mailto:wex@mcc.ARPA">
wex@mcc.ARPA
</A>&gt;
</address>
<i>
Wed, 9 Oct 85 12:40:43 cdt
</i><PRE>

The University I attended had its database on a computer that student
courses used.  However, it was (is) a very well-kept secret.  It is hard
(under the OS of this system) to find out what people *might* log on.  Also,
it seems that hacker-types don't get the work-study jobs in the registrar's
office.  I'm not sure how long they can keep it up, but it's worked well for
at least 5 years.  (I only found out because I got to be good friends with
the facilities people, and one of them happened to mention it.)

I guess this just reinforces the belief that human beings can make a risky
or less-risky depending on how they use it.  --Alan Wexelblat  WEX@MCC.ARPA

------------------------------ 

Date:    Wed, 09 Oct 85 16:12:15 EDT
From:    Ross McKenrick  &lt;CRMCK%BROWNVM.BITNET@WISCVM.ARPA&gt;
To:      RISKS@SRI-CSL.ARPA
Subject: Databases, Grades, etc.

Students and grades can exist on the same machine.  Attempting to partition
the students' and administrations' computing environments is a crude form of
security which eliminates the possibility of providing students online
services such as class lists and registration changes.

We take a two-fold approach to database security at Brown University:
1) prevention and 2) detection.  We minimize our window of vulnerability
by making it nearly impossible to gain unauthorized access to the
programs which update grades, etc, and by making it nearly impossible
to change a grade (even when authorized) without generating audit
records, security log entries, and notifications slips for the professor.

We are not dealing with an EFT-type environment where "smash-and-grab" might
work.  A student is at Brown for four years, and his/her transcript is
maintained by the Registrar forever.  A student could theoretically change
his/her grade for a day or two *in the computer database* (which does not
mean that the grade, which is intangible, was actually changed).  However, a
system of checks and balances, built into and outside of the computer
system, would eventually result in discovery, correction, and punishment.

Suppose I could design a security system which was 90% (OK, 80%) secure.
Then, rather than spend more time making it more secure (point of
diminishing returns), I could spend my time on a recording/ reporting system
which was 80% secure.  Now, I finish by dovetailing the two systems to make
it very unlikely that a hacker could survive both levels.  Meanwhile, the
Registrar, who is rightfully suspicious of computer security anyway, devises
manual checks and balances which adds another level of security beyond the
computer entirely.

Wouldn't it simply be easier for the hacker to forge a grade change slip
from his/her professor?  Now, considering all of this, you've got certain
expulsion and prosecution under Rhode Island State Law hanging over your head.

Why would someone who's got all of this figured out have trouble passing
courses, anyway?

A collegue of mine likens a malicious hacker in a fairly-well-secured
computer environment to a bull in a china shop.  The china is replaceable,
the bull is dead meat.

Now comes the auto-theft-prevention-device philosophy: why pick on
a fairly-well-secured environment when there are so many unsecured
environments to fool with?

Security in computer-recordkeeping is a very serious subject.  But
you must keep it in perspective with the alternatives: manual record-
keeping, locked doors and desks, etc.

</PRE>
<HR><H3><A NAME="subj3.5">
Databases, Grades, etc.
</A>
</H3>
<address>
Randy Parker 
&lt;<A HREF="mailto:PARKER@MIT-REAGAN.ARPA">
PARKER@MIT-REAGAN.ARPA
</A>&gt;
</address>
<i>
Thu, 10 Oct 85 09:34 EDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Regarding the subject of the risks of computer technology (in general)
and large databases (FBI's NCIC, TRW, NSA, tenant/landlord database in
California, and the Census), there is a reporter from the New York Times
who has done quite a bit of research into it.  His name is David
Burnham, and his results a few years back are published in his book "The
Rise of the Computer State" (paper/hardback).

The book is a call to arms to the millions who don't realize the serious
threat to our freedom that this poses.  Its shortcoming, as such, is
that it is mostly a quite comprehensive series of anecdotal reports on
various errors and abuses (incorrect warrants, Nixon abuse of phone
company records, abuse by politicians, etc) of large informations
stores.  However, if you need convincing that this is a problem, you
will find it in this book.

Burnham spoke here this past Tuesday and updated his list of "horror
stories", as he puts it.  One number he gave, if my notes are right, is
that an FBI audit of their NCIC showed that ~10% of the warrants proposed
by this system are somehow based on incomplete or invalid information.
He also mentioned proposals to increase the NCIC to include a White
Collar Crime Index that would specifically contain the names of SUPPOSED
white collar criminals and their ASSOCIATES.  As Burnham pointed out, if
they can't maintain the actual criminal information properly, what are
the consequences when they start accumulating hearsay and gossip?

A serious problem is that no one has a real interest in keeping this
information very correct, except for the falsely accused citizen, and,
as Burnham pointed out, he doesn't have any way to correct it.  I also
agree quite heartily with Matt Bishop that "the greatest risk is not
from the technological end but the human end."  The technology itself is
not to blame, but we need, especially as computer professionals whose
opinions in the matter would be seriously regarded, to recognize the
growing threat to our liberties and to act accordingly.

Randy Parker
MIT AI Lab
PARKER@MIT-REAGAN

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-31</DOCNO>
<DOCOLDNO>IA012-000128-B042-538</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.22.html 128.240.150.127 19970217000802 text/html 26876
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:06:26 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 22</TITLE>
<LINK REL="Prev" HREF="/Risks/1.21.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.23.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 22</H1>
<H2> Wednesday, 16 Oct 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Administratrivia 
</A>
<DD>
<A HREF="#subj1.1">
Friedrich von Henke
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Medical software incidents 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  European activities  
</A>
<DD>
<A HREF="#subj3.1">
Udo Voges
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Robots are different 
</A>
<DD>
<A HREF="#subj4.1">
Jerry Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Automobile computer control systems 
</A>
<DD>
<A HREF="#subj5.1">
Bennett Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Police computers 
</A>
<DD>
<A HREF="#subj6.1">
Dave Dyer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Electronic Surveillance 
</A>
<DD>
<A HREF="#subj7.1">
Geoffrey S. Goodfellow / Bill Keefe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Network Mailer Woes 
</A>
<DD>
<A HREF="#subj8.1">
Lynne Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Databases, grades, etc. 
</A>
<DD>
<A HREF="#subj9.1">
Karl Kluge
</A><br>
<A HREF="#subj9.2">
 Andy Mondore
</A><br>
<A HREF="#subj9.3">
 Mark Sienkiew
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Administratrivia
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
From: Friedrich von Henke (vonHenke@SRI-CSL)

I am temporarily acting as guest moderator of the Risks Forum.
Peter Neumann had to go rather abruptly on an overseas trip, and
the transition happened a bit disorderly.  My apologies to all of
you who were eagerly awaiting their twice-weekly cost of RISKS readings
but had to go without.  I hope to have things under control now.

Apparently the hiatus has had the effect of slowing down the stream of
contributions to a merely trickle; please don't hesitate to get the flow
going again!

			Friedrich von Henke

----------------------------------------------------------------------

Date: 11 Oct 85 19:39:27 PDT (Fri)
From: Nancy Leveson &lt;nancy@UCI-ICSD.ARPA&gt;
To: RISKS@sri-csl.ARPA
Subject: medical software incidents

I was just on a panel concerned with Software Safety at an IEEE
conference on Computers in Medicine and heard about some more
incidents involving software faults.  

The first was cited in a recent RISKS forum message (about the
programmable implanted pacemaker which was inadvertently reprogrammed by
emitted magnetic fields from an anti-theft device in a retail store),
but the patient
was cited as having survived.  Unfortunately, his weakened heart was
unable to stand the increased pace, and he died.

Other recalls by the FDA involve:

1)  An infusion-pump (used for insulin) had a software problem which
caused the infusion of insulin or dextrose to be delivered at the
maximum rather than the lower intended rate.  This occurred when certain
valid data was entered according to user instructions.

2)  A programmable pacemaker "locked-up" when being reset by an
external programming device.  Luckily this occurred in a doctor's office,
and the doctor was able to revive the patient.

3)  A multiple-patient monitoring system was recalled because the software
got patients' names mixed up with the wrong data.

4)  An algorithm was incorrectly programmed in a diagnostic lab instrument
which caused certain patient data to be reported erroneously as all zeros.

The reference for these incidents (for those who want to quote them) is:
  H. Bassen, J. Silberberg, F. Houston, W. Knight, C. Christman, and
  M. Greberman.  "Computerized Medical Devices:  Usage Trends, Problems,
  and Safety Technology," in Proc. 7th Annual Conference of IEEE 
  Engineering in Medicine and Biology Society, Sept. 27-30, 1985, 
  Chicago, Illinois, pp. 180-185.

Nancy Leveson
University of Calif. Irvine

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
       European activities
</A>
</H3>
<address>
          Udo Voges 
&lt;<A HREF="mailto:voges@LOCUS.UCLA.EDU">
voges@LOCUS.UCLA.EDU
</A>&gt;
</address>
<i>
Fri, 11 Oct 85 11:38:57 PDT
</i><PRE>

I would like to bring some activities to your attention which are
going on in Europe, especially within and triggered by EWICS TC 7.

   The European Workshop on Industrial Computer Systems (EWICS), TC on
   Systems Reliability, Safety and Security (TC 7) is working since about
   10 years in this area, having some 100 members from industry, research
   and university. Previous work resulted in Position Papers on

       Development of safety related software
       Hardware of safe computer systems
       Guidelines for verification and validation of safety related software
       Guidelines for documentation of safety related computer systems
       Techniques for verification and validation of safety related software
       System requirements specification for safety related systems

   Current working areas include:

       System integrity
       Software quality assurance and metrics
       Design for system safety
       Reliability and safety assessment

   Besides conducting about four working meetings a year the TC is organizing
   the IFAC/IFIP Workshop on Achieving Safe Real-Time Computer Systems
   (Safecomp'79, '82, '83, '85, '86).

   The results of the work of TC 7 are introduced into the standardisation
   process (IEC, ISO, and national bodies) as well as used by companies
   and licensing authorities.

   Those interested in more information can either contact me or the
   current Chairman of TC 7: Mr. J.M.A. Rata, Electricite de France,
   1 Avenue du General de Gaulle,  F-92141 CLAMART   FRANCE.

   There exists an American counterpart to EWICS TC 7, but it was not
   possible to attract enough interested persons to keep it alive.
   The Japanese counterpart is also active, but due to the language
   barrier communication is minimal.

Udo

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Robots are different
</A>
</H3>
<address>
&lt;<A HREF="mailto: Saltzer@MIT-MULTICS.ARPA">
 Saltzer@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Sat, 12 Oct 85 01:30 EDT
</i><PRE>
To:  risks@SRI-CSL.ARPA

When someone gets pinned to the wall by a robot, something different is going
on as compared to when someone gets gunned down by an FBI agent operating
under incorrect information retrieved from the NCIC.  Both cases may lead to
specific tragedies, yet the example of risks from robots seems to me to be
qualitatively different from many other computer-use risks.

The difference is that robots are used primarily in environments where
mechanically-oriented people are accustomed to balancing the risks of new
machinery against the benefits.  These people have, over the years, learned to
deal with risks from gear trains and drive belts, from swinging tailends on
steamshovels, from runaway elevators, from inadequately supported cranes.
They watch out, they learn from accidents, their insurers offer advice, they
make mistakes and take risks, and they learn.  To a first approximation, an
industrial robot presents a risk similar in kind to other new machinery, and
there is a moderately well-working system in place that is accustomed to
watching for the risks.  If anything, the average mechanic is suspicious of a
new piece of machinery in direct proportion to its complexity, newfangledness,
and gadgetry level, so is probably expecting the robot to screw up in
marvelous ways.  One might wish to argue with the particular balance that an
industry has struck between risks and benefits, but it is unusual to find one
in which mechanical risks are not understood at least moderately well.

The mechanic's suspicion of the new gadget is the essence of what seems to be
missing in many other applications of computers, and why it is so important to
raise awareness of the need to assess risks.  I'm not convinced we need to
harass our colleagues in the robot business with risk-consciousness-raising.
We should be instead talking to their installers to find out what we can
learn.

                                                  Jerry Saltzer

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Automobile computer control systems susceptible to interference
</A>
</H3>
<address>
Bennett Smith
&lt;<A HREF="mailto:ircam!bks@seismo.CSS.GOV ">
ircam!bks@seismo.CSS.GOV 
</A>&gt;
</address>
<i>
Wed, 23 Oct 85 11:14:29 -0100
</i><PRE>

By chance I saw an article in an issue of the
"Journal of Environmental Engineers" (published in England, date of
issue about 10 months ago, I believe) about the sensitivity of
a microprocessor-controlled automobile control system to external
electromagnetic radiation.  As I recall, a CB transmitter near the car
could, at the right frequency, make the engine slow down or speed up.
Perhaps this article would interest some of your contributors.

Bennett Smith					
IRCAM
31, Rue Saint Merri
75004 Paris, France		{seismo,philabs,decvax}!mcvax!ircam

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
The human element
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
15 Oct 1985 23:42:01 PDT
</i><PRE>
From: Dave Dyer       &lt;DDYER@USC-ISIB.ARPA&gt;
To: risks@SRI-CSL.ARPA


 The human element really is where the action is, and it is
a completely two-edged sword;  Human actions which have the
power to "fix" something almost inherently also give the power
to "break" things equally severely.  Conversely, weighty
check and balance systems intended to prevent abuse end up
preserving the status quo, however good or bad that may be.

 The "police computer horror story" I'm most familiar
with is illustrative.  This is a well documented case
I've been reading about in ACLU publications.   

 It seems some poor soul had his wallet stolen, and some criminal
adopted his identity and later was involved in a robbery/murder.  
Through some circumstances peculiar to the case, the stolen
identity, but not the culprit, were known to the LAPD.  The
detectives working on the case put the stolen identity into
a national police computer.   Our hero was stopped for
a routine traffic citation, the computer coughed his 
name up, and he ended up on ice for a few days as a
murder suspect.  

  So far, this is pretty harmless and understandable.  Eventually
the guy's identity and and non-involvement were establishd and
he was turned loose.   Then it happened again.  And Again.
The guy began carrying a letter from the local chief of police,
saying he wasn't the guy the computer said was wanted, but
that didn't cut it when he traveled.

  The problem was that the LAPD detectives who put in the
original "want" refused to remove it.   Eventually the
guy (and the ACLU) got the courts to mandate expunging 
the computer.   I think the detectives involved and the 
LAPD are being sued.   Quite rightly.

  The point is, it is &lt;&lt;hard&gt;&gt; to design a system that
can do its intended job, permit discovery and correction
of errors, and resist unautherized or inappropriate use.
I can't imagine a system that can do all three.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Electronic Surveillance.
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
24 Oct 1985 11:17-PDT
</i><PRE>
From: the tty of Geoffrey S. Goodfellow &lt;Geoff@SRI-CSL.ARPA&gt;
 
	[forwarded to RISKS by  Bill Keefe &lt;keefe%milrat.DEC@decwrl.DEC.COM&gt;
	 from TELECOM Digest Volume 5, Issue 55, October 24, 1985]


Americans' Privacy Exposed by New Technology, Congress Told
 
By LEE BYRD - Associated Press Writer
 
    WASHINGTON (AP) - The explosion in communications technology has so
outpaced privacy laws that Americans have little or no protection
against a plethora of new ways for government or private adversaries
to pry into their lives, a congressional agency reported today.
    The non-partisan Office of Technology Assessment found that 35 out
of 142 domestic federal agencies use or plan to use various
electronic surveillance methods, including modern devices not
governed by a landmark 1968 law that circumscribed the use of
wiretaps and bugs - concealed microphones.
    The agency said 36 agencies, not counting those in foreign
intelligence, already use a total of 85 computerized record systems
for investigative or intelligence purposes, and maintain 288 million
files on 114 million people. The report raised the ''technically
feasible'' specter of these being linked into a single data base
network that could track untold numbers of citizens without due
cause.
    The report, requested by House and Senate committees, noted that
many new and uncontrolled methods of surveillance are made possible
by the very technologies of which more and more Americans are
availing themselves - electronic mail, computer conferencing,
cellular and cordless telephones, beepers and electronic pagers.
Intercepting such devices is easy, and ''the law has not kept pace,''
the agency said.
    But other devices, such as miniature television cameras and pen
registers - which monitor the numbers called on a given telephone
line - have enabled new ways to spy on people even if their own
communications habits are more old-fashioned, the agency noted.
    Rep. Robert W. Kastenmeier, D-Wis., chairman of the House Judiciary
subcommittee on courts and civil liberties, said the study ''shows
how the law in this area has broken down; it is up to Congress to fix
it. If we fail to act, the personal and business communications of
Americans will not have the privacy protection they deserve.''
    Sen. Charles McC. Mathias, R-Md., said the report ''documents how
new and more intrusive forms of snooping have followed in the wake of
the exciting advances in communications technology,'' and agreed
Congress must ''bring federal privacy laws up to date.'
    Rep. Don Edwards, D-Calif., chairman of the House Judiciary
subcommittee on civil and constitutional rights, said, ''While the
attorney general of the United States is claiming that the civil
liberties granted by the Constitution should be limited to the
'original intentions' of the framers, the technological possibilities
for government surveillance have exploded. The framers knew nothing
of closed-circuit television, wiretapping and computer data banks.''
    The report noted that the Fourth Amendment, which protects ''the
right of the people to be secure in their persons, houses, papers and
effects, against unreasonable searches and seizures,'' was written
''at a time when people conducted their affairs in a simple direct,
and personalized fashion.''
    Neither, said the report, has Title III of the Crime Control and
Safe Streets Act of 1968, which was designed to protect the privacy
of wire and oral communications, kept pace.
    ''At the time Congress passed this act,'' the report said,
''electronic surveillance was limited primarily to simple telephone
taps and concealed microphones. Since then, the basic communications
infrastructure in the United States has been in rapid technological
change.''
    The congressional agency said it could not estimate the extent of
electronic surveillance in the private sector, saying only ''it is
probable that many forms ... go undetected, and if detected, go
unreported.''
    But in its survey of the federal bureaucracy, OTA found 35 agencies,
mostly in the Justice, Treasury and Defense departments, used or
planned to use:
    -Closed circuit television, 29 agencies.
    -Night vision systems, 22.
    -Miniature transmitters, 21.
    -Electronic beepers and sensors, 15.
    -Telephone taps, recorders, and pen registers, 14.
    -Computer usage monitoring, 6.
    -Electronic mail monitoring, 6.
    -Cellular radio interception, 5.
    -Satellite interception, 4.
    As for the 85 computerized record systems that could be used for
surveillance purposes, none of the operators provided statistics
requested by the OTA on record completeness and accuracy.
    Under the 1968 law, wiretaps and bugs are prohibited without a court
order based on the affirmation of a high-ranking prosecutor that a
crime has occurred, that the target of the surveillance is involved,
and that other means of investigation would be ineffective.
    According to the Administrative Office of the U.S. Courts, federal
and state judges approved 801 out of 802 requests last year for
electronic surveillance, primarily wiretaps and hidden microphones,
at an average cost of $45,000.
    The agency said that while there is some promise in emerging
techniques for low-cost data encryption or other means to protect
communication systems from eavesdropping, ''there is no immediate
technological answer ... against electronic surveillance.''
    Foreign intelligence cases are governed by a separate law, so the
CIA, National Security Agency and Defense Intelligence Agency were
not included in the survey.
 
</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Network Mailer Woes...
</A>
</H3>
<address>
"UV2::MOOREL" 
&lt;<A HREF="mailto:moorel@uv2.decnet">
moorel@uv2.decnet
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT	    [sic! ed.]
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

	In a recent issue of one of the digests on the net, there was a problem
mentioned that seems to have a bearing on risks on computer systems, particu-
larly as use of computer networking increases in the future. At their request, 
the names have been changed to preserve anonymity.

	        Apparently for the past month, the people who reside on the
	bitnet have been unable to receive [this digest].  There is a long
	story behind this [...]. This story is also a *lot*
	of guesswork as to what happened.
	        At the beginning of September, [our system] changed its host 
	name to conform to the new domain name standards.  The site we
	were using to get to bitnet, did not recognize the new name and
	began rejecting all mail from [our system].  We did not become
	aware of this because we were not receiving any rejections or errors
	back from the gateway.  We were however, receiving mail *from* the 
	people on Bitnet who were asking what happened to their [...] digest.
	        We attempted to contact the people at [the gateway] but of 
	course the mail failed and they never did anything to correct the 
	problem which they, of course, were not aware of because nobody was
	complaining.  (Sounds like a Catch-22 situation if I ever heard
	one).
	        In any case, the problem has now been resolved.
	Unfortunately, these people have missed close to 50 digests.  There
	is no way I can tie up the mailer at [either the host or the gateway] 
	in order to remail the messages.  I also understand that there is no 
	way to use FTP from the bitnet. 

It appears that several incidents conspired together to cause the loss of this 
information, and although the loss was not critical, it will take much time and
effort for the people involved to catch up. If this had been a more critical 
information transfer, it might have been corrected faster; however, there is a 
good chance that it would have gone undetected anyway. It seems to be one more 
reason for information about any potential changes to be passed on to any sites
that may be affected and to be thoroughly checked on both ends to prevent this 
kind of thing from reoccurring.

	Lynne C. Moore (Moorel@Eglin-Vax.Arpa)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Grade changing.
</A>
</H3>
<address>
&lt;<A HREF="mailto:Karl.Kluge@G.CS.CMU.EDU">
Karl.Kluge@G.CS.CMU.EDU
</A>&gt;
</address>
<i>

</i><PRE>

Some doubt has been expressed in this forum recently about people
changing grades and living happily ever after. I can't talk about
college systems, but in high school all the grades, attendence, etc.
for my high school and several other high schools were kept on a
mainframe in a centralized location. There is a system in Michigan
called MOIS for vocational data, and on the back of my MOIScript on
computer science was the transcript of a terminal session between the
attendance people and the computer. The login message gave the phone
number of the mainframe. The password was overprinted, but that is
useless -- you can learn to read through almost any overprinting.
Access to the grading, course scheduling, and attendance programs was by
providing a social security number which was echoed and not overprinted.
I thus found myself able to do really miraculous things. Being sixth in
my high-school class, I had no real motivation to use my knowledge
maliciously, and informed the administration. Some safeguards were added
(old social security numbers retired, certain social security numbers
only giving access to certain programs, restricting access to certain
programs to certain accounts), but I'm sure those could have been
circumvented with minimal effort -- I was a fairly good systems hack on
the operating system, and there were people who could hack rings around
me. The operating system was a simple three-tier ring system, and a lot
of the features put in for the sake of usability made it very insecure.

I send this to give first-hand evidence to those who have been posting
doubts that such things happen.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Databases, grades, etc.
</A>
</H3>
<address>
&lt;<A HREF="mailto:Andy_Mondore%RPI-MTS.Mailnet@MIT-MULTICS.ARPA">
Andy_Mondore%RPI-MTS.Mailnet@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 16 Oct 85 17:11:36 EDT
</i><PRE>

One of the systems programmers here at RPI made a point about
administrators and students sharing the same computer:  You
really aren't that much more secure when you have administrators
and students on separate computers if there is a network or dial-up
connection to the administrative computer than you are when
administrators and students are on the same computer.  If you have
network or dial-up connections to an administrative computer, it
isn't too difficult for a student with an autodial modem to write
a program on a PC that simply tries all possible phone numbers
for certain telephone exchanges and record the numbers that
produce a carrier tone.  Then the student could have another
program that tries passwords unless the system disconnects the
line after a certain number of unsuccessful tries.  The major
advantage of separating administrators and students is that
it might be more difficult for a student to access an administrative
file from a student account assuming the administrative file has the
proper protection set.

</PRE>
<HR><H3><A NAME="subj9.2">
 Database, Grades, etc...
</A>
</H3>
<address>
&lt;<A HREF="mailto:    Sienkiew@louie.udel.EDU">
    Sienkiew@louie.udel.EDU
</A>&gt;
</address>
<i>
Mon, 21 Oct 85 0:44:24 EDT
</i><PRE>


You can create an extremely effective audit trail if you think about it for a
while.  That just makes the problem more "challenging".

Suppose you do your auditing one day and find that there were unauthorized
grade changes made for every student in the CS department and 1/2 of them
requested (incorrect) printed transcripts.  It seems unlikely that everybody
independently broke in on the same day.  So who do you penalize?  How many
transcripts have been mailed out already?

Suppose no grades were changed but there is a trojan horse waiting to raise
the grade only under certain circumstances?

My point is that the data doesn't have to stay changed forever.  And you can't
check the auditing records for every transaction, if you expect to gain by
using the computer.  You need to do as much as you can, of course, but beware
of the false sense of security...

			Mark.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-32</DOCNO>
<DOCOLDNO>IA012-000128-B042-560</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.23.html 128.240.150.127 19970217000817 text/html 19440
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:06:43 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 23</TITLE>
<LINK REL="Prev" HREF="/Risks/1.22.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.24.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 23</H1>
<H2> Tuesday, 19 Nov 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Expecting the unexpected 
</A>
<DD>
<A HREF="#subj1.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Safety Group Activities in the U.S. 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Automobile computer control systems susceptible to interference 
</A>
<DD>
<A HREF="#subj3.1">
Bennett Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Irresponsible computer "game"; BBS Legislation 
</A>
<DD>
<A HREF="#subj4.1">
Ted Shapin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  SDI Debate at MIT 
</A>
<DD>
<A HREF="#subj5.1">
John L. Mills
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Expecting the unexpected
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Mon 18 Nov 85 12:57:03-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

We have been talking about risks to the public in the use of computer
systems in this forum since 1 August, and trying to keep the discussions
mostly technical -- but not political or polemical.  On the other hand, I
have noted on various occasions that it is sometimes hard to exclude
nontechnical arguments.  This message may initially seem off the mark, but I
think it has some subliminal relevance that might help put into perspective
the importance of the underlying assumptions that we make and the need to
anticipate essentially all possible unusual circumstances.

On 13 October 1985, in Florence, Italy, at about 10:05 PM, European Standard
Time, my apparently very healthy 19-year-old son Chris -- never having had a
medical problem in his life -- suddenly had his heart stop and died within
moments.  Resuscitation attempts failed.  The autopsy found no discernible
apparent cause of death.  A neurophysiologist friend who joined me in
Florence suggested ventricular fibrillation as the most likely actual cause.
The heart muscles receive signals from distributed sources via independent
paths, and normally all of the signals arrive sufficiently synchronously to
trigger heart contraction.  Under fibrillation, the signals arrive
incoherently, and cannot be integrated sufficiently to trigger contraction.
So, why do I mention this in a RISKS Forum?  Well, even in an apparently
completely healthy person there exists some risk of spontaneous malfunction.
It seems to me that in making arguments about how hardware and software will
operate correctly or will continue to operate correctly if they once did, we
make all sorts of implicit underlying assumptions that may be true most of
the time, but that may indeed break down -- particularly in times of stress.
The nastiest problems of all seem to involve unanticipated conditions in
timing and sequencing, in both synchronous and ansynchronous systems, and
particularly in distributed systems.  We have seen various problems in the
past -- the ARPANET collapse (due to an accidentally propagated virus, after
years of successful operation) and the first shuttle launch immediately come
to mind as specific well-documented examples.  In some cases there is also
signal inference -- as in the pacemaker problems (see Nancy Leveson's
message in <A HREF="/Risks/1.22.html">RISKS-1.22</A>).  I think that in our lives as in computer systems,
we tend to make unjustified or oversimplified assumptions.  In life, this
makes it possible for us to go on living without inordinate worrying.
However, in computer systems, greater concern is often warranted.  So, my
point in introducing this message into the RISKS Forum is to urge us to try
to make our assumptions both more explicit and more realistic.  Basing a
system design on assumptions that are almost but not quite always true may
seem like a close approximation, but may imply the presence of enormous
unanticipated risks.  In systems such as those involved in Strategic
Defense, for example, every one of the potentially critical assumptions must
be sufficiently correct.

                 Peter G. Neumann (back again on the net)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Safety Group Activities in the U.S.
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@ICSD.UCI.EDU">
nancy@ICSD.UCI.EDU
</A>&gt;
</address>
<i>
09 Nov 85 13:04:51 PST (Sat)
</i><PRE>

Udo wrote about the EWICS TC7 in a previous RISKS forum and said that
such a group died through lack of interest in the U.S.  Actually, there
is a similar group which has been active in the U.S. for about three
years.  It is called the Software System Safety Working Group and was
started by the Air Force although it is now a tri-service group.  Although
sponsored by the DoD, it is not limited to military applications and has
participants from other branches of the government and industry.  The latest
meeting was held in conjunction with a conference on computers in medicine.

Meetings are held approximately twice a year and usually have from 50-200
participants.  One of the products of the group is a Software Safety Handbook
which is meant to accompany the recent MIL-STD-882b (System Safety) update.  
The main purpose of the group has been to meet and discuss new techniques,
share experiences, exchange ideas, etc.  There is tentatively a meeting
planned for January in Washington D.C.  Anybody interested in the group should
contact me (nancy@uci.edu) or Al Friend (friend@nrl-css) who is with the Navy 
and is currently chairing the group.  A future plan is to have an on-line
safety database which will reside at the SRI NIC.  

Other activities in which I have been asked to participate and which might
be of interest to readers of this forum are a conference on safety
which will be held in Washington D.C. next July and a workshop on safety and
security sponsored by the Center for Software Reliability in England next
September.  I am also considering organizing a workshop in California on safety
which would be held right before the next International Conference on Software
Engineering in Spring 1987.  Anyone interested in more information on any
of these activities can again contact me and I will direct you to the
right people.
 
Nancy Leveson
University of California, Irvine

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Automobile computer control systems susceptible to interference
</A>
</H3>
<address>
Bennett Smith
&lt;<A HREF="mailto:ircam!bks@seismo.CSS.GOV ">
ircam!bks@seismo.CSS.GOV 
</A>&gt;
</address>
<i>
Wed, 23 Oct 85 11:14:29 -0100
</i><PRE>

By chance I saw an article in an issue of the
"Journal of Environmental Engineers" (published in England, date of
issue about 10 months ago, I believe) about the sensitivity of
a microprocessor-controlled automobile control system to external
electromagnetic radiation.  As I recall, a CB transmitter near the car
could, at the right frequency, make the engine slow down or speed up.
Perhaps this article would interest some of your contributors.

Bennett Smith					
IRCAM
31, Rue Saint Merri
75004 Paris, France		{seismo,philabs,decvax}!mcvax!ircam

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Irresponsible computer "game"
</A>
</H3>
<address>
Ted Shapin 
&lt;<A HREF="mailto:BEC.SHAPIN@USC-ECL.ARPA">
BEC.SHAPIN@USC-ECL.ARPA
</A>&gt;
</address>
<i>
Mon 18 Nov 85 11:54:52-PST
</i><PRE>
To: risks@SRI-CSL.ARPA, human-nets@RED.RUTGERS.EDU
Phone: (714)961-3393; Mail:Beckman Instruments, Inc.
Mail-addr: 2500 Harbor Blvd., X-11, Fullerton CA 92634

From a Toys R Us ad in the L.A. Times, 11/17/85:

Activision
HACKER
Makes you feel like you've unlocked someone else's computer system!
For C-64, C-128. $24.97.

[And on the package:]

TEMPTATION
HACKER
To stumble into somebody else's computer system.  To be someplace
you're really not supposed to be.  And to get the strange feeling
that it really does matter.  "LOGON PLEASE" is all you get to
start with. That's it.  From there, it's up to you.  If you're
clever enough and smart enough, you could discover a world you've
never before experienced on your computer. Very temptimg.
- - -

This "product" is socially irresponsible!  It leads young people
to think breaking into unknown systems is OK. The "world" they
discover may be the world of the penal system!

Ted Shapin

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
BBS Legislation
</A>
</H3>
<address>
Ted Shapin 
&lt;<A HREF="mailto:BEC.SHAPIN@USC-ECL.ARPA">
BEC.SHAPIN@USC-ECL.ARPA
</A>&gt;
</address>
<i>
Thu 14 Nov 85 10:34:50-PST
</i><PRE>
To: human-nets@RED.RUTGERS.EDU, risks@SRI-CSL.ARPA

I have remailed several messages on pending BBS legislation to
INFO-LAW@sri-CSL.  One is a draft of a bill by Senator Leahy's aid Podesta
which is a good bill.  People interested in preserving open communcation via
BBS's may wish to read these items.  Ted Shapin.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Arms-Discussion Digest V5 #8 [EXCERPT: SDI Debate]
</A>
</H3>
<address>
Moderator 
&lt;<A HREF="mailto:ARMS-D-Request%MIT-MC.ARPA@MIT-XX.ARPA">
ARMS-D-Request%MIT-MC.ARPA@MIT-XX.ARPA
</A>&gt;
</address>
<i>
29 Oct 85 09:33-EST
</i><PRE>
To: ARMS-D%MIT-MC.ARPA@MIT-XX.ARPA
Reply-To: ARMS-D%MIT-MC.ARPA@MIT-XX.ARPA

EXCERPTED FROM Arms-Discussion Digest Tuesday, October 29, 1985 9:33AM
Volume 5, Issue 8 
                  [There is sufficient NONOVERLAP in our readerships to
                   warrant reproducing this.  Apologies to those who have
                   read it already.  PGN]

Date:  Mon, 28 Oct 85 10:58 EST
From:  Mills@CISL-SERVICE-MULTICS.ARPA
Subject:  SDI Debate

This is a summary of my impressions of the panel discussion/debate
entitile "Star Wars: Can the Computing Requirements be Met?" This
took place on Monday October 21 at MIT.  The panelists where Danny
Cohen, David L Parnas, Charles L Seitz, and Joseph Weizenbaum. The
moderator was Michael L Dertouzos.

I was basically disappointed in this panel discussion.  I was hoping
to hear a good counter to the the arguments Dr Parnas had put forth
in his papers.  Dr Cohen started what looked like an organized attack
on Dr Parnas' "Octet", refering to the series of eight papers Dr
Parnas presented his arguments in.  Dr Cohen correctly dismissed the
eighth paper,"Is SDIO An Efficient Way To Fund Worthwhile Research",
as being outside the bounds of the current discussion.  Unfortunately
Dr Cohen only further discussed one of the other papers.  The other
six where dealt with with some minor hand waving.  I have to admit I
don't remember which paper Dr Cohen "went into detail" on.  This is
because the detail amounted to a one slide outline of the major six
points of this paper.  This slide was up for no more than one minute
with some more hand waving that none of these points were true.

Back to the side claiming the software is not feasable, Dr Weizenbaum
didn't realy add much of anything to Dr Parnas' arguments.  He thought
that Dr Parnas had done a wonderful job and there wasn't much he
could add.  He gracefully didn't take up much time saying this either.
Dr Parnas basically presented the material in his papers.  He added
the new point that even if we build this thing and it "tested OK",
we could never realy trust it and would be forced not to rely on it.

Charles Seitz made no attempt to directly attack Dr Parnas' argument.
He focused his presentation on a simplistic hierarchal structure the
software for SDI could take.  Unfortuanately this looked like a highly
centralized form of controlling all the weapons and sensors resulting
in a high degree of complexity and size.

Both Dr Cohen and Seitz hit upon the point that the software for SDI
is not necessarily as large and complex as some people might think.
They claimed that it could be built of smaller fairly independant
parts.  To me this appeared contradictory to Dr Seitz's hierarchal
control structure.  It did come through that If you had enough
totally independant platforms shotting things down, you stood a good
change of hitting most the targets.  It is also clear that you would
need a very high level of overkill to make this work since the other
platforms don't know who else is shotting at what.

Back to Dr Parnas' points,  I did get the feeling that there is some
general agreement that there is a limit to the scale and complexity
our software engineering can handle.  Dr Parnas furthered this point
by saying  large advances in the mathematics of discreet functions
are going to be a major stumbling block in the furthering software
engineering.  He doesn't expect these large advances on the grounds
that if you simplify the equations to much you are loosing
information.  A discreet function can only represent so many bits.
I may not have this argument exactly right.  He also went thru his
standing arguments against AI or automatic programing helping very
much.

    [ I think the argument is that we need concise, manipulable
    discrete functions modelling software in order to achieve what
    other fields of engineering can do with concise, manipulable
    continuous functions.  However, such concise representations may
    not be possible due to information-theoretic constraints on the
    number of bits that can be represented by a certain number of
    symbols.  --MDAY@MIT-XX ]

    [I didn't get quite this impression, though I agree with it.  Rather, I
    thought Parnas was saying that the problem was in the fact that with
    software that is fundamentally digital, there is no such thing as a
    continuous function, and that therefore the usual engineering
    assumption valid in most of the world that small changes in input or
    in correctness necessarily mean small changes in output or result
    simply isn't valid in the software engineering world.  Until it is
    possible to analyze software in terms of approximately correct
    functions, graceful software degradation (in terms of an approximately
    correct program always doing approximately correct things) is not
    really possible. -- LIN@MIT-MC]

Both sides came up with a number of interesting and colorful
analogies.  The most relavent is the Space Shuttle.  Dr Cohen claims
that the Space Shuttle works.  This is obviously true in some sense.
However, it was also pointed out that there have been times when the
software on the shuttle has not worked within seconds of launch.  It
seems that it would be impractical to ask the Soviets to wait 15
minutes while we reboot the system.

    [Indeed, Seitz conceded that under certain circumstances plausible in
    the context of a nuclear missile attack, it might be necessary to
    re-boot the system.  He then proceeed to ignore the consequences of
    that; he did not even say that there are ways to eliminate the need
    for re-booting. -- LIN@MIT-MC]

In summary it seems that there are very real limits on what our
software engineering can handle reliably.  We are actually not that
far from those limits in some of our current efforts.  If SDI is to
work its architecture must be dictated by what is doable by the
software.  It is unclear that SDI is feasably from a material cost point
of view if the platforms are small and independant enough to be
reliable from the software standpoint.

In closing I would like to say that I don't think either side did a
particularly good job sticking to just the software feasibility
issue.  One other interesting thing happened.  Dr Parnas claimed to
have asked some person with authority over SDIO whether "No, we can't
do this" was an acceptable answer.  He did this for the first time at
this debate because he did not want to say this behind this person's
back.  Unfortunately, I don't remember this other person's name, but
he was in the audience.  Dr Parnas claims that the answer was, "No is
not an accepatble answer" and challenged the other person to deny
this.  The other person promptly stood up and did exactly
that.

    [If you mean that it was political, that's certainly true.  But
    politics is really the determinant of the software specifications at
    the top level.  That is how it should be, and people who want to
    ignore that are ignoring the most important part of the problem.

    However, in other instances, the Administration has noted that the SDI
    is central to future US defense policy.  In addition, it has never
    specified what evidence it would consider adequate or sufficient to
    turn off the SDI.

    -- LIN@MIT-MC]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-33</DOCNO>
<DOCOLDNO>IA012-000128-B042-582</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.24.html 128.240.150.127 19970217000835 text/html 20483
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:06:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 24</TITLE>
<LINK REL="Prev" HREF="/Risks/1.23.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.25.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 24</H1>
<H2> Wednesday, 20 Nov 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Doing Something About Risks in Computer Systems 
</A>
<DD>
<A HREF="#subj1.1">
Brad Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Space Program Software 
</A>
<DD>
<A HREF="#subj2.1">
Jerome Rosenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Susceptibility to interference 
</A>
<DD>
<A HREF="#subj3.1">
John Brewer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Expecting the unexpected  
</A>
<DD>
<A HREF="#subj4.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Philip W. Anderson's "Case Against Star Wars" 
</A>
<DD>
<A HREF="#subj5.1">
Pete Kaiser
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Doing Something About Risks in Computer Systems
</A>
</H3>
<address>
Brad Davis
&lt;<A HREF="mailto:b-davis@utah-cs.arpa ">
b-davis@utah-cs.arpa 
</A>&gt;
</address>
<i>
Tue, 19 Nov 85 11:05:34 MST
</i><PRE>

Often the discussion has touched on failure of software and hardware, but
rarely on levels and methods of protection that should be built into these
systems.  Is is good to trade cycles for protection?  What are the best ways
to recover from failures?  Does anyone have real experiance with these
questions?
				Brad Davis

    [Clearly these are leading questions!  We have indeed mentioned many
     good techniques of software engineering that help.  But there are no
     easy answers -- especially in the absence of specific requirements.
     But let's see if any of our readers wants to take a crack at this one.
     PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Space Program Software
</A>
</H3>
<address>
Rosenberg Jerome
&lt;<A HREF="mailto:jerome@rsch.wisc.edu ">
jerome@rsch.wisc.edu 
</A>&gt;
</address>
<i>
Tue, 19 Nov 85 14:46:49 CST
</i><PRE>

           We have heard a great deal about the great successes of the space
  program but we rarely hear about the difficulties that have to be overcome
  with great effort and dedication. I suggest you direct your readers to the 
  current issue of DATAMATION for an article by Edward Joyce entitled "The
  Art of Space Software". Its subtitle tells a far different story than
  some hand-waving protagonists of the SDI tell about the Space software.
  The subtitle  -- The complicated software labyrinth behind the shuttle is
  still far from error-free -- tells the story. The article should serve to
  alarm those who are quick to discount the sincere critics of the SDI
  software problems.                     jerome @rsch.wisc.edu

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Susceptibility to interference
</A>
</H3>
<address>
too busy for bureaucracy -John 5522026
&lt;<A HREF="mailto:brewer%ace.DEC@decwrl.DEC.COM  ">
brewer%ace.DEC@decwrl.DEC.COM  
</A>&gt;
</address>
<i>
Tuesday, 19 Nov 1985 10:21:51-PST
</i><PRE>

	RE: Bennett Smith's comments of emi-rfi susceptibility in automobile
control applications... cb's are low power, limited frequency devices. As an
Amateur radio operator, one has to be aware of much higher output power, as
well as a much wider bandwidths. Amateur Radio frequency allocations include
segments from 1.8Mhz to Ghz ranges.

	As I remember, some of the control modules are also pretty good
emitters of Emi/Rfi hash as well. Typical (legal) output power of a CB is 5
watts or less. A typical ham radio mobile transmitter output power is
100-200 watts.

	Something to think about!
	-John

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Expecting the unexpected
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MIT-MC.ARPA">
LIN@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Tue, 19 Nov 85 15:10:41 EST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Regarding your comments about spontaneous failure: The Russians have a
saying regarding rifles used on stage in plays: once every decade an
unloaded gun will fire; once every century a rake will fire.

      [Perhaps that is what prompted Stravinsky to stage
       "The Rake's Progress".  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Philip W. Anderson's "Case Against Star Wars"
</A>
</H3>
<address>
Pete Kaiser, 225-5441, HLO2-1/N10
&lt;<A HREF="mailto:kaiser%furilo.DEC@decwrl.ARPA  ">
kaiser%furilo.DEC@decwrl.ARPA  
</A>&gt;
</address>
<i>
Wednesday,  2 Oct 1985 21:32:34-PDT
</i><PRE>

    [The following message was put aside for evaluation before my absence.
     With the reminder that we of course would like to see more informed
     pro-SDI contributions in RISKS as well, Anderson's article seems
     worth including -- not because it breaks new ground, but because it
     represents a position for discussion.  PGN]

The article below, by Professor Philip W. Anderson of Princeton University,
appeared in the Princeton Alumni Weekly of September 25, 1985, and is reprinted
here with the author's permission.  Professor Anderson won the Nobel Prize for
Physics in 1977, and was awarded the National Medal of Science in 1982.

Although what Professor Anderson has to say is couched partly in specific terms
of Princeton University and the discipline of academic physics, it seems to me
relevant to basic research in general, and to computer science research and the
discipline of computer science in particular.  To me, for instance, it seems to
be very personally a social consequence of the military funding of computer
science research that, while I've worked with computers, there have been many
kinds of work which I couldn't conscientiously do because, although they may be
very interesting, they are done essentially only for military purposes and with
military funding.

Finally, Professor Anderson points out that a great deal of sensible thought can
be brought to social issues even by someone who "isn't ... fascinated by the
technical details."  Agreed.  We must remember that we're not priests.

---Pete

Kaiser%BELKER.DEC@decwrl.arpa
{allegra|decvax|ihnp4|ucbvax}!decwrl!dec-rhea!dec-belker!kaiser
DEC, 77 Reed Road (HLO2-1/N10), Hudson MA 01749  617-568-5441

                    ----------------------------------

			The Case Against Star Wars
                      Philip W. Anderson, Princeton

I am not an expert on strategic weapons.  I'm a theoretical physicist who has
been involved in almost all of physics except atomic bombs.  I have not done
classified work since 1945, and that was on radar.  My total contribution to the
laser -- a major technical component of the Strategic Defense Initiative, which
is better known as Star Wars -- was roughly that when one of the scientists at
Bell Laboratories who originated the things asked me to predict whether a
certain seminal version of it would work if they built it, I said "Well, maybe."

Fortunately, most of the scientific issues that come up in discussing Star Wars
are very simple ones which require neither specialized nor especially technical
-- and therefore classifiable -- knowledge.  One needs to know that it costs
everyone about the same amount to put a ton of stuff into a given orbit and that
this is a major portion of the cost of any space system; that signals can't
travel faster than the speed of light; that it takes roughly as much chemical
fuel to burn through a shield with a laser as the shield itself weighs; that
Americans are not measurably smarter than Russians; and a few other simple, home
truths.  Given these, almost everyone comes to much the same conclusions.

If you go through the enormously detailed kinds of calculations on specific
configurations which Richard Garwin and his fellow opponents of SDI felt
necessary to convince the stubborn, you leave yourself open to the kind of
errors of factors of 2 or 4 which Martin Muendel '86 found in his widely
publicized junior paper last spring [Princeton Alumni Weekly, May 8] and which
then -- to the lay person -- seem to weaken the whole structure.  This is a
particularly tough game because Star Wars advocates do not themselves propose
specific configurations and present specific calculations that can be shot down;
their arguments are given in terms of emotional hopes and glossy presentations.
This is why I think it is good for the argument against SDI to be made by a
mentally lazy, non-expert person like myself who isn't particularly fascinated
by the technical details.

The reasons for not building Star Wars are essentially identical to those which
led both us and the Russians to abandon, for practical purposes, the antibal-
listic missile in 1972 and to sign a treaty restricting ABMs.  It is important
to understand that reasoning -- and perhaps it is less emotionally charged than
Star Wars since it is now history and not even controversial history anymore.
Why would anyone feel that a defense against missiles was useless and, in fact,
dangerous and destabilizing?

There are three stages, each more certain than the last: (1) It probably
wouldn't work, even under ideal conditions.  (2) It almost certainly wouldn't
work under war conditions.  This puts us in the dangerous and unstable situation
of the gunfighter who doesn't know if his gun is loaded.  (3) Most certain and
conclusive of all, *each defensive system costs, inescapably, at least 10 times
more than the offensive system it is supposed to shoot down*.  Thus it pays the
other side to increase its offensive arsenal until the defender is bankrupt, and
the net result is an *increase* in armaments and a far more dangerous situation,
without any increase in safety.

The offense has, inescapably, enormous advantages: its missiles are sent at
will, in any desired sequence and quantity, with any number of decoys and other
deceptive countermeasures, preprogrammed at leisure to hit their targets; the
defense has to find them, sort them out, get into space at a time not of its own
choosing, and then kill the warheads it finds with nearly perfect accuracy.  In
the case of ABM, there were other problems, such as that the explosions were
over the defending side and that the first few explosions probably blacked out
the whole shooting match, but that was sufficient argument against.

As far as almost everyone in and out of the Defense Department was concerned,
until March 1983 this situation was an accepted fact.  No technical breakthrough
had or has changed those realities.  The change has been purely political and
emotional, and hence now financial.  President Reagan's March 1983 speech, as
far as anyone can ascertain, was not preceded by any serious technical review,
but quite the opposite: the most recent and urgent internal study of antimissile
defenses had come out negative on all possible schemes.

Apparently, the President based his speech and his subsequent program on a
collection of rather farfetched suggestions -- farfetched but by no means secret
and previously unknown -- which, to the outside scientific observer, seem to
deserve the oblivion that the last pre-Star Wars study consigned them to.  These
schemes amount to a way for the defense to spend more per missile and still let
through a large fraction of the offensive missiles.  The defensive hardware that
has to be got up into space still has to have roughly the same mass as the
offense; in many schemes it has to get there faster; and it still has to be much
more sophisticated and therefore vulnerable and delicate.  Key components, in
most schemes, have to be left in space indefinitely, inviting the enemy to track
them with space mines, perhaps the most dangerous tripwire mechanism for stating
a war that one can possibly imagine.


Some Star Wars advocates will protest that I do not mention the one idea which
doesn't founder just on the problem of total mass in space.  This is the scheme
of exploding hydrogen bombs in space and directing the explosive energy of the
bombs with lasers to kill very many missiles per bomb -- several hundred to
several thousand, if one is to kill an equivalent cost in missiles! If I could
think of any way such a monstrosity could work as opposed to the many ways it
could not work or be frustrated, I would take it more seriously.  Apparently
there has been some good and interesting science done on these lasers, but
unfortunately it is classified; no one, however, seems to claim that it helps
much with the technical problem.  I cannot, incidentally, see any way to do
meaningful development on such a weapon without exploding H-bombs in space, a
terrible pollution as well as a violation of what treaties we have.

I think the above would represent reasonably well the views on the technical
realities of most trustworthy physicists to whom I have spoken, in or out of
academia and in or out of the Star Wars program.  In academic physics depart-
ments, which receive relatively little support from the DOD, a pledge form has
been circulating stating that the signer opposes SDI as unworkable and will not
seek SDI funds; this has had a high percentage of signers everywhere it has been
circulated and its preliminary circulation in Princeton over the summer encoun-
tered only a few holdouts.  Those who do not sign feel, primarily, that research
in any guise shouldn't be opposed, while agreeing personally that the systems
proposed are unworkable and destabilizing.

Perhaps it would be worthwhile, therefore, for me to explain why I feel the
large increment of research funds earmarked by President Reagan for SDI is a
very bad thing for the research community, as well as for the country as a
whole.  You will note that I said *increment*; every year before Star Wars, we
spent $1 billion in ABM research and development.  My main reason is that, on
the whole, Star Wars will represent a further acceleration of three extremely
disturbing trends in the direction of research funding in this country.

First, we are seeing a decrease in basic research relative to mission-oriented,
applied research.  The basic research agencies -- National Science Foundation,
Basic Energy Sciences in the DOE, and National Institutes of Health -- have been
maintained at level funding while their missions have been gently skewed toward
applications and engineering by piling more applied responsibilities on them.
At the same time, while the Administration has cut back on development in some
civilian sectors, it has more than compensated by increasing the amount of
applied work for the military.

Second, there is a trend away from scientific administration of federal research
money -- mostly done by the system of "peer review" -- to micromanagement either
by bureaucrats, or, increasingly, by Congress, with all the logrolling possibil-
ities that entails.  The three institutions mentioned above, especially NSF and
NIH, operate by subjecting each grant to a jury or other scientists.  Like most
democratic procedures, this system is worse than everything except the alterna-
tives; its effect has been reviewed repeatedly and there is no serious doubt
that it works.  Military "research," on the other hand, has always operated on
the arbitrary whim of the contracting officers.  In the early days after World
War II this administration was a benevolent despotism, but the adjective has
long since lost its meaning.  Most of the in-house DOD laboratories have been
rather a scandal in the research community.  The dominant motivation in this
system seems to be the standard bureaucratic one of "empire building."

Third, from the point of view of the country as a whole, perhaps the most
dangerous trend is the shift from civilian to military dominance of our federal
research and development spending.  Under the Reagan Administration, this has
grown to 72 percent military, up from about 50 percent a decade ago.  Everyone
has been told -- and DOD sees to that -- of the great economic benefits of
"spin-off" from military development, but if they exist (and I have never found
an economist who believes in them), they are not evident in our recent economic
performance vis-a-vis Japan and Germany.  In fact, in a country like ours with a
serious shortage of trained engineers and scientists, a shortage which would be
crippling if we did not attract great numbers of them from overseas to staff our
universities and research laboratories, the waste of our precious technical
expertise on military hardware is a serious economic debit.

From Princeton's point of view, all of these trends are disturbing.  As a top-
flight research university, a heavy percentage of our funding is in individual
support of independently functioning basic scientists, mainly peer-reviewed and
to a large extent from the agencies mentioned above.  We have not had to resort
to logrolling political tactics, nor have we had to accept micromanagement, DOD
control of publications, or limitations on citizenship of students to keep our
research funded.  SDI control of funding, and in general the shift of research
funding to the military, is a serious danger to the independence of Princeton as
a research university.

Of course, this is a narrow and slightly parochial view, but it is nonetheless
serious.  Certainly it is more important that the naive emotional appeal of the
Star Wars concept is being used so blatantly to defuse the country's strong
desire for nuclear disarmament, and to turn this emotional pressure into yet
another excuse for enriching the arms manufacturers and building up a dangerous
and worthless arsenal of nonsensical armaments.  To paraphrase Murph Goldber-
ger's testimony on the ABM: Star Wars is "spherically" senseless -- that is,
silly no matter how you look at it.

            [End of Philip Anderson's statement, and of Pete Kaiser's Message.]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-34</DOCNO>
<DOCOLDNO>IA012-000128-B042-604</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.25.html 128.240.150.127 19970217000852 text/html 14934
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:07:20 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 25</TITLE>
<LINK REL="Prev" HREF="/Risks/1.24.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.26.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 25</H1>
<H2> Sunday, 1 Nov 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Some Thoughts on Unpredicted Long-Term Risks 
</A>
<DD>
<A HREF="#subj1.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer snafu halts treasury 
</A>
<DD>
<A HREF="#subj2.1">
Peter G. Trei
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Hacker" Game 
</A>
<DD>
<A HREF="#subj3.1">
Ken Brown; Keith F. Lynch
</A><br>
<A HREF="#subj3.2">
 Werner Uhrig
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Some Thoughts on Unpredicted Long-Term Risks
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Sun 1 Dec 85 16:00:32-PST
</i><PRE>

This is a short note on the subject of how little we understand or are
willing to admit about long-term effects (whether eventually very obvious
effects or sometimes long-hidden side-effects) -- and of how, even if a risk
is known, it may be suppressed.

The front page of today's NY Times (Sunday 1 Dec 85) has two articles on
Bhopal, one year after.  Stuart Diamond's article begins, "Medical studies
conducted in the year since the chemical leak ... indicate that the chemical
responsible for the accident causes serious long-term health problems that
were unknown before the disaster."  Furthermore, the Bhopal problems appear
to have been due not just to the pesticide ingredient methyl isocynate, but
to an unforeseen chemical reaction that transformed some of it to hydrogen
cyanide.  (An antidote to the latter chemical was therefore not used until
months afterwards.)

In various past issues of the RISKS Forum we have noted risks such as
side-effects of pacemaker interference; auto microprocessor bugs; command
and control computer problems; and so on -- perhaps ad nauseum to some of
you -- and the dangers of making a finite set of assumptions that underly
proper system behavior.  I have also alluded occasionally to lessons that we
might learn from environmental risks such as toxic substances in our food,
drink, and environments; some of those risks were known in advance but
ignored -- e.g., for commercial reasons; others came as "surprises"
(thalidomide, for example), but probably represented a lack of care and
long-term testing.  In some cases the risks were thought of, but considered
minimal.  In other cases, the risks were simply never considered.

At the beginning of the holiday season, this note merely adds a plaintive
cry for greater humility.  Science (especially computer science) does not
have ALL the answers.  Furthermore, the absence of any one answer (and
indeed ignorance of a question that should have been asked) can be damaging.
But, as we see from the nature of the problems to date, some of us too often
keep our heads in the sand -- even after being once (or multiply) burned.
Eternal vigilance is required of all of us.  Bureaucrats and technocrats who
say "don't worry, nothing can go wrong" must be exposed.  But technocrats
who say "we can't do it at all" need to be very careful in their statements
-- locally anything is possible.  However, we must remember that it is in
the global system integration and in operation under conditions of stress
that things tend to break down -- and also where rational arguments tend to
break down.

I am now finally back in California after 7 weeks on the road.  It is good
to be back (I think), but it is time to get RISKS rolling again.  I hope
that this forum is helping to increase our awareness of the problems and of
what we can (and cannot) do to improve our computer systems and their use.
But the useful perpetuation of RISKS -- and the application of your
knowledge in real systems -- depends on you.

PGN

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer snafu halts treasury
</A>
</H3>
<address>
Peter G. Trei 
&lt;<A HREF="mailto:OC.TREI@CU20B.COLUMBIA.EDU">
OC.TREI@CU20B.COLUMBIA.EDU
</A>&gt;
</address>
<i>
Fri 29 Nov 85 00:43:47-EST
</i><PRE>
 
       From the Wall Street Journal,  Monday 25 November 1985
                     [quoted without permission]

       A Computer Snafu Snarls the Handling of Treasury Issues
               by Phillip L. Zweig and Allanna Sullivan
              Staff reporters of the Wall Street Journal

   NEW YORK- A computer malfunction at Bank of New York brought the
Treasury bond market's deliveries and payments systems to a near-
standstill for almost 28 hours Thursday and Friday.
   Although bond prices weren't affected, metal traders bid up the
price of platinum futures Friday in the belief that a financial crisis
had struck the Treasury bond market. However, Bank of New York's
problems appeared to be more electronic than financial.
   The foul-up temporarily prevented the bank, the nation's largest
clearer of government securities, from delivering securities to buyers
and making payments to sellers - a service it performs for scores of
securities dealers and other banks.
   The malfunction was cleared up at 12:30 p.m. EST Friday, and an
hour later the bank resumed delivery of securities.
   But Thursday the bank, a unit of Bank of New York Co., had to
borrow a record $20 billion from the Federal Reserve Bank of New York
so it could pay for securities received. The borrowing is said to be
the largest discount window borrowing ever from the Federal Reserve
System. Bank of New York repaid the loan Friday, Martha Dinnerstein, a
senior vice president, said.
   Although Bank of New York incurred an estimated $4 million interest
expense on the borrowing, the bank said any impact on its net income
"will not be material." For the first nine months this year, earnings
totaled $96.7 million. Bank of New York stock closed Friday at
$45.125, off 25 cents from the Thursday, as 16,500 shares changed
hands in composite trading on the New York Stock Exchange.
   Bank of New York said that it had paid for the cost of carrying the
securities so its customers wouldn't lose any interest.
   Bank of New York's inability to accept payments temporarily left
other banks with $20 billion on their hands. This diminished the need
of many banks to borrow from others in the federal funds market. Banks
use the market for federal funds, which are reserves that banks lend
each other, for short-term funding of certain operations. The cash
glut caused the federal funds rate to plummet to 5.5% from 8.375%
early Thursday.
   The electronic snafu is by far the largest of computer problems
that periodically have bedeviled the capital markets.
   Almost all goverment securities transactions are settled
electronically through the New York Federal Reserve Bank. In this
system, computers of clearing banks are linked to one another through
a central computer, to enable banks to settle purchases and sales of
securities by customers.
   According to Wall Street sources, the malfunction occurred at 10
a.m.  Thursday as Bank of New York was preparing to change software in
a computer system and begin the days operations. Until Friday
afternoon, Bank of New York received billions of dollars in securities
that it couldn't deliver to buyers. The Fed settlement system, which
officially closes at 2:30 p.m., remained open until 1:30 a.m. Friday
in the expectation that technicians would be able to solve the
problem.
   Rumors about bank problems often send commodity traders scurrying
to buy precious metals. In the platinum pit at the New York Mercantile
Exchange, the price for January delivery surged $12.40 an ounce to
$351.20 Friday on volume of 11,929 contracts, a 29-year record.
   Reports that the Fed was investigating transfer problems at Bank of
New York prompted the platinum buying.

                          [end of quotation]

   I talked to a friend of mine who was peripherally involved in the
recovery from this 'snafu', and it seems that the primary error
occured in a messaging system which buffered messages going in and out
of the bank.  The actual error was an overflow in a counter which was
only 16 bits wide, instead of the usual 32. This caused a message
database to become corrupted.  The programmers and operators, working
under tremendous pressure to solve the problem quickly, accidently
copied the corrupt copy of the database over the backup, instead of
the other way around.

     One thing I have often noticed is that the 'normal run' code of
software packages tends to get much more through testing then the
code for error recovery; not only is it more difficult to test, but
the general feeling of 'this code will never execute' demotivates
programmers. In this case, it sounds like the people at BONY never
held a 'fire drill' to figure out how to handle a corrupt primary
database. Does anyone else have examples where attempts at error
recovery magnified problems?
							Peter Trei
							oc.trei@cu20b

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Hacker" Game
</A>
</H3>
<address>
Ken Brown x254
&lt;<A HREF="mailto:decwrl!Glacier!oliveb!felix!birtch!ken@ucbvax.berkeley.edu ">
decwrl!Glacier!oliveb!felix!birtch!ken@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Thu, 21 Nov 85 14:27:34 pst
</i><PRE>

     --------------------
     This is in response to Ted Shapin's article regarding the
     'irresponsible' game, HACKER (<A HREF="/Risks/1.23.html">RISKS-1.23</A>).
     --------------------

The game HACKER, is just a game.  It has nothing to do with the
trying to make people (read kids) try to break into a computer
system.  I know.  I helped write the IBM PC version of the game.
The name of the game, HACKER, just deals with the initial 'screen'
of the game, where one simulates trying to logon to a system.  It
is not very realistic (MY_VIEW) of an actual logon sequence.
The rest of the game has NOTHING to do with 'hacking', as I view
the term hacking.

However, I do agree with you about the packaging blurbs, regarding
the "not caring," but I am not the one who wrote that blurb.  The
game is strictly for entertainment purposes.  It will not teach
people how to break in to remote (or local) systems.  Just about
anything you type will get you past the "security system."

Ken Brown	[... !trwrb!scgvaxd!felix!birtch!ken]

These ramblings are my own, and probably do not reflect those of my
employer or fellow employees.

</PRE>
<HR><H3><A NAME="subj3.2">
Hacker game
</A>
</H3>
<address>
"Keith F. Lynch" 
&lt;<A HREF="mailto:KFL@MIT-MC.ARPA">
KFL@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Sat, 23 Nov 85 11:28:22 EST
</i><PRE>

    Date: Mon 18 Nov 85 11:54:52-PST
    From: Ted Shapin &lt;BEC.SHAPIN@USC-ECL.ARPA&gt;

    Activision
    HACKER
    Makes you feel like you've unlocked someone else's computer system!
    ...

    This "product" is socially irresponsible!  It leads young people
    to think breaking into unknown systems is OK. The "world" they
    discover may be the world of the penal system!

  I don't see what's wrong with this.  This is better than cracking
for real, and I doubt that anyone will learn any useful cracking
techniques from this game.
  Do you also think that toy guns should be banned?  What about
Adventure, Zork, and Dungeons and Dragons, which teach people to kill
and to steal?
  I think fantasy role playing games are of great benefit.  They give
people of all ages a chance to 'get it out of their system' in a
harmless way.
								...Keith

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"Hacker" Game: Is game simulating security of *REAL* machines?
</A>
</H3>
<address>
Werner Uhrig  
&lt;<A HREF="mailto:CMP.WERNER@R20.UTEXAS.EDU">
CMP.WERNER@R20.UTEXAS.EDU
</A>&gt;
</address>
<i>
Sat 23 Nov 85 13:28:39-CST
</i><PRE>

I wouldn't be surprised if this game actually simulates the security features
(or lack thereof) of some real-life systems ...

... in which case, it's *REALLY* time to be alarmed.  On the other hand, this
just might cause a lot of sites to decide to pay attention to improving
their security, or cause efforts which advance the state of the art of
security, which wouldn't be that bad, when you think about it.

Has someone with access to the game and knowledge of the security features
of different minis/mainframes checked this out yet?

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-35</DOCNO>
<DOCOLDNO>IA012-000128-B043-6</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.26.html 128.240.150.127 19970217000907 text/html 15333
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:07:34 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 26</TITLE>
<LINK REL="Prev" HREF="/Risks/1.25.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.27.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 26</H1>
<H2> Wednesday, 4 Dec 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Humility 
</A>
<DD>
<A HREF="#subj1.1">
Matt Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Reliable Computer Systems 
</A>
<DD>
<A HREF="#subj2.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Electromagnetic Interference 
</A>
<DD>
<A HREF="#subj3.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Hackers 
</A>
<DD>
<A HREF="#subj4.1">
Thomas Cox
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  "The Hacker Game": Is it simulating security of *REAL* machines? 
</A>
<DD>
<A HREF="#subj5.1">
Ted Shapin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Unexpected load on telephone trunks 
</A>
<DD>
<A HREF="#subj6.1">
Ted Shapin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Humility
</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:mab@riacs.ARPA">
mab@riacs.ARPA
</A>&gt;
</address>
<i>
2 Dec 1985 0926-PST (Monday)
</i><PRE>

   In Risks 1.25, you wrote a very good article pleading for greater
humility.  I'd like to add a little to that. Very often a solution is
proposed which alleviates the symptom, but aggravates the cause, of the
problem.  (Draw your own examples, folks -- the best ones are political, and
I'm not touching THOSE with a ten-foot pole!) Unfortunately, those are often
the most appealing because they let us forget, for a time, that the problem
exists.  When it returns, the symptoms are different but the root cause is
still there -- and more rotten than ever.

   As another thought, I've found that in order to ask the question that
leads to a solution for a problem you have to know most of the answer
already -- it's merely a matter of synthesizing the various parts into a
whole.  (As an example, Riemannian geometry existed before Einstein put it
to use; it was a mathematical toy, done to prove the Fifth Postulate was
just that, a postulate.)  But for all non-technical problems, science alone
cannot provide the answers -- it can provide techniques for solving the
technical components, but no more.  And when people forget this, disaster
follows, because science is used to treat the result, rather than the cause.
(Incidentally, "science" is not the culprit.  The same thing happens in
spheres where science takes a back seat to ethics and morality -- and what I
said still applies.  No one discipline can provide a complete answer to any
non-technical problem.  Unfortunately, an incomplete, but complete-looking,
answer can usually be obtained from any discipline -- and this is what we
must avoid doing!)

Matt

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Reliable Computer Systems
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
2 Dec 1985 1354-PST (Monday)
</i><PRE>

Although reliability is only part of risk assessment, it is an important
one. I would like to bring to the attention of this forum a book to which I
made a modest contribution.

``Reliable Computer Systems: Collected Papers of the Newcastle
Reliability Project,'' edited by Santosh K. Shrivastava,
Springer-Verlag, 1985, xii + 580 pages, ISBN 0-387-15256-3 (New York)
and 3-540-15256-3 (Berlin).

This volume brings together in one place more than 30 papers by more than 20
authors reporting more than a decade of research on reliability. It contains
papers that survey the issues, define terminology, propose partial
solutions, and assess the state of the art.

Jim H.

                -------------------------

From the introduction by Brian Randell:

"The origins of the project can be readily traced back ... to my
participation in the 1968 NATO Conference on Software Engineering.  Quite a
number of the attendees have since remarked on the great influence this
conference had on their subsequent work and thinking.  This was certainly
true in my case. ... One major theme of the conference was the great
disparity between the level of reliance that organizations were willing to
place on complex real time systems and the very modest levels of reliability
that were often being achieved-- for example, it was also at about this time
that there was considerable public debate over the proposed Anti-Ballistic
Missile System, which we understood was to involve relying completely on a
massively complicated computer system to position and detonate a nuclear
device in the upper atmosphere in the path of each incoming missile!

"At the NATO Conference there was thus much discussion about improved
methods of software design, though there was a mainly implicit assumption
that high reliability was best achieved by making a system fault-free,
rather than fault-tolerant. Another much-debated topic concerned the
practicality of attempting to provide rigorous correctness proofs for
software systems of significant size and complexity. Such discussions, I am
sure, played a large part in ensuring that ... I was seeking to do something
constructive about the problems of achieving high reliability from complex
computing systems, and yet, was feeling rather pessimistic about the
practicality of proving the correctness of other than relatively small and
simple programs. ...

"From the start, our aim was to study the general problems of achieving high
reliability from complex computing systems, rather than concentrate on
problems specific to a particular application area or make of computer.
Quoting from the original project proposal: `The intent is to investigate
problems concerned with the provision of reliable service by a computing
system, notwithstanding the presence of software and hardware errors. The
approach will be based on the development of computer architecture and
programming techniques which facilitate the structuring of complex computing
systems so that the existence of errors can be detected and the extent of
their ramifications be determined automatically, and so that uninterrupted
service (albeit probably of degraded quality until the faulty hardware or
software is repaired) can be provided. ... It is clear that for the
foreseeable future, the designers of large-scale computing systems will not
be able to achieve adequate system reliability by depending entirely on the
reliability of the hardware and software components which make up their
system.' ...

"We started by studying the problems of difficult faults in (relatively)
simple systems and then gradually increased the difficulty of the systems
that we were prepared to consider."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Electromagnetic Interference
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Wed 4 Dec 85 17:11:18-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

On page 30 of the Dec 85 issue of the IEEE Spectrum is an article entitled
"Taming EMI in microprocessor systems".  It begins as follows.

  It was late one summer afternoon in 1983, near the end of the day shift at a
  steel plant in the eastern United States.  An operator using a new radio
  link was guiding the last ladle of molten steel as it moved along an
  overhead track from the blast furnace to the ingot molds.  Soon the
  end-of-shift horn would sound.  Without warning, the ladle tipped
  prematurely as it neared the molds, pouring hot steel on the floor and on
  some of the workers.  One worker was killed, and four were seriously injured
  in this accident.  After an investigation, electromagnetic interference
  (EMI) was blamed for the tipping of the ladle.

Reflections from a scaffolding reinforced the field produced by the
transmitter's antenna, producing a signal that was received by a drop cord
acting as an antenna, interpreted by the cord's switch circuitry, which
triggering the switch circuit to pour the molten steel.  This sounds a
little like Rube Goldberg, but is another example of the EMI problems
discussed in <A HREF="/Risks/1.19.html">RISKS-1.19</A> and revisited in .23 and .24.

PGN

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Hackers
</A>
</H3>
<address>
Thomas Cox
&lt;<A HREF="mailto:ihnp4!gargoyle!sphinx!benn@ucbvax.berkeley.edu ">
ihnp4!gargoyle!sphinx!benn@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Tue, 3 Dec 85 18:58:11 cst
</i><PRE>

	Over the course of the year I have been reading thousands of articles
from all print sources that relate to computers.  Hundreds have been on crime
and security.  Dealing with these articles is part of a job I hold.  
	The "cracking" done by so-called hackers, i.e. young computer
hobbyists, falls into a very few categories.

1. a non-password-secured system is "broken into".
2. a password is stolen.
3. a credit card number is transmitted VIA COMPUTER for illegal use.
4. a particular string of crackings was perpetrated by some young people who
     systematically searched for computer mainframes of a certain make and
     model.  They then used the factory-installed password "system" (or some
     such) that was not removed by the end-user support staff.
5. bypassing telephone company billing circuits to make "free" calls.

Please notice that

1. no password-protected system is EVER likely to be broken into by so-called
     hackers.  They can sit and guess, just like they can try and guess the 
     combination to my bike lock.  I'm not worried about it.
2. most so-called computer crime has been nothing other than the
     TRANSMISSION of illegally-attained credit card numbers, Sprint account
     numbers, and the like.  

The claims regarding "encouraging kids to hack" is simply garbage.
Encourage them all you want.  They will eventually give up, because it isn't
going to work.  That is what the behavioral scientists call "extinction" of
a behavior:  it never works, and eventually isn't repeated any more.  Like
trying to jump so you can fly.

Sincerely,
  Thomas Cox   ...ihnp4!gargoyle!sphinx!benn

     [This is likely to generate various responses -- from hackers whose
      good name is being besmirched &lt;forget it -- we've already been through
      that&gt;, from serious crackers and secure operating systems folks who 
      know that most operating systems are so vulnerable that they can be
      cracked in many ways other than those mentioned above, and more.
      But you should all beware of the head-in-the-sand view that everything
      is just fine &lt;"There are no real risks!"&gt;, which you might continue
      to hold until you are ostrichized for shortsightedness following a
      technologically based breakin.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"The Hacker Game": Is it simulating security of *REAL* machines?
</A>
</H3>
<address>
Ted Shapin 
&lt;<A HREF="mailto:BEC.SHAPIN@USC-ECL.ARPA">
BEC.SHAPIN@USC-ECL.ARPA
</A>&gt;
</address>
<i>
Mon 2 Dec 85 10:34:02-PST
</i><PRE>
To: CMP.WERNER@R20.UTEXAS.EDU
cc: risks@SRI-CSL.ARPA, human-nets@RED.RUTGERS.EDU
Phone: (714)961-3393; Mail:Beckman Instruments, Inc.

No, I heard the game is a maze type game, not a simulation of security on
any real system.  The advertisement is just hype to sell the game.  Ted.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Unexpected load on telephone trunks
</A>
</H3>
<address>
Ted Shapin 
&lt;<A HREF="mailto:BEC.SHAPIN@USC-ECL.ARPA">
BEC.SHAPIN@USC-ECL.ARPA
</A>&gt;
</address>
<i>
Tue 3 Dec 85 14:07:40-PST
</i><PRE>
To: risks@SRI-CSL.ARPA, telecom@MIT-XX.ARPA
Phone: (714)961-3393; Mail:Beckman Instruments, Inc.
Mail-addr: 2500 Harbor Blvd., X-11, Fullerton CA 92634
Message-ID: &lt;12164247581.25.BEC.SHAPIN@USC-ECL.ARPA&gt;

    In the previous posting, which I forgot to include here, a complaint
was raised about BYTEnet Listings, BYTE magazine's BBS system, indicating
that the person was unable to get through.  Only too true! BYTEnet Listings
was responsible for shutting down the long-distance access to the ENTIRE
state of New Hampshire some months ago, due to the enormous number of calls
they received.
    To get the Public Domain HOPE or PROLOG, you should first try your local
BBS systems, or the BBS run by Computer Languages magazine...

           Mike Farren
           uucp: {dual, hplabs}!well!farren
           Fido: Sci-Fido, Fidonode 125/84, (415)655-0667
           USnail: 390 Alcatraz Ave., Oakland, CA 94618

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-36</DOCNO>
<DOCOLDNO>IA012-000128-B043-38</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.27.html 128.240.150.127 19970217000930 text/html 60171
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:07:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 27</TITLE>
<LINK REL="Prev" HREF="/Risks/1.26.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.28.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 27</H1>
<H2> Saturday, 7 Dec 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Summary of Groundrules:
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The RISKS Forum is a moderated digest.  To be distributed, submissions should
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  be relevant to the topic, technically sound, objective, in good taste, and 
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  coherent.  Others will be rejected.  Diversity of viewpoints is welcome.  
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Please try to avoid repetition of earlier discussions.
</A>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: RISKS digests
</A>
</H3>
<address>
Elliott S. Frank
&lt;<A HREF="mailto:hplabs!amdahl!esf00@ucbvax.berkeley.edu ">
hplabs!amdahl!esf00@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Fri, 6 Dec 85 11:49:54 PST
</i><PRE>

I'm attaching a cross posting from one of our other internal BBS systems.
You may have seen it before, and it may well be worth excerpting (or, even
posting) to the net.     [Elliott]

      [Although there is some old stuff here, it is interesting to have it
       all in one place.  Thus, I am sending this out intact.  Besides, it
       would take me longer than I have to try to edit it.  PGN]

===============================================================================

From nzm10 Thu Dec  5 15:26:10 1985
Relay-Version: version B 2.10.2 9/18/84; site amdahl.UUCP
Posting-Version: version B 2.10.2 9/18/84; site amdahl.UUCP
Path: amdahl!nzm10
From: nzm10@amdahl.UUCP (Neal Macklin)
Newsgroups: amdahl.general
Subject: worms and viruses (long)
Date: 5 Dec 85 23:26:10 GMT
Date-Received: 5 Dec 85 23:26:10 GMT
Distribution: amdahl
Organization: Amdahl Corp, Sunnyvale CA

This came off the VM conf system, and I thought it was interesting.
The first part is posted outside my office, so those of you that have
read that should go to line 530 (approx).

(I hate people who say "enjoy".....Neal)

   ------------------------------------------------------------------

 
* TOPIC: RUMOR -  "RUMOR Interesting tidbits about the company"
--&gt; Item 15 from AJP30 on 12/02/85 at 16:22:58
 
 
This is part one of a two part series written by Gary North about software
worms and viruses.  Gary North is an investment newsletter publisher and
presents an interesting perspective of the problem from a non-technical
point of view.  Enjoy.
 
                                   Andrew J. Piziali, x8584.
 
 
   ---------------------------------------------------------------------------
 
                          Gary North's Remnant Review
                                                                  Matt. 6:33-34
   ---------------------------------------------------------------------------
 
Vol. 12, No. 20                      379                       November 1, 1985
  
 
What you are about to read will shock you.  It shocked me as I did the  research
on the project.  It so completely shocked me that I am lifting the copyright  on
this issue and the one to follow.  Reprint them in any form you choose.
 
Second, I am  sufficently scared about  what I've uncovered  that I am  going to
make this  request.  I  will pay  $1,000 to  the first  person who  blows what I
regard as significant holes in my thesis, and who consents to a 90-minute  taped
interview for  FIRESTORM CHATS.   If you  can't do  this, but  you can put me in
contact  wth  anyone  who  can  refute  me  or  show an effective way out of the
problems I  raise, I  WILL GIVE  YOU A  ONE YEAR  RENEWAL TO  REMNANT REVIEW FOR
LOCATING THE FIRST SUCH PERSON FOR ME,  AND I WILL PAY THE INDIVIDUAL $1,000  TO
DO THE 90-MINUTE TAPED INTERVIEW WITH ME, plus provide supporting evidence.  And
let  me  say,  it  will  be  the  happiest  check-writing session of my life.  I
DESPERATELY WANT TO BE PROVED WRONG.  Mail me your (his) outline.
 
I am going public with this  story because it is unlikely that  any conventional
news source will touch  it, unless pressure is  brougth to bear.  The  reason is
this:  the  problems  are  too  horrendous  even  to be discussed by appropriate
officials, unless they have specific  answers.  But they don't.  What  I present
here  cannot  be  smoothed  over  by  a  press  release  abount  having set up a
blue-ribbon study panel.
 
I literally stumbled into this information.  I had read about one tiny aspect of
it.  I made a  few extrapolations.  Then I  got worried.  The problem  looked as
though it would have major implications.  Little did I know!
 
Every dark cloud has a silver  lining, they say.  Well, every silver  lining has
its  dark  cloud.   This  is  a  "dark  cloud" report about the high tech silver
lining.
 
I am not trying to be deliberately gloomy, but this problem can only get  worse,
unless someone (and I don't know who) can figure out an answer.  I don't like to
present problems in  REMNANT REVIEW for  which I have  no answers.  This  time I
have to do what I don't like to do.  If you've got some answer, WRITE!
 
I am hoping that by going to my  reader I may locate one or more people  who can
provide decent counsel.  Congress hasn't the foggiest idea of the threat that is
now developing to the whole Western world.  When I began this research  porject,
neither did I. Those who  know the facts are so  close to the problem that  they
may have grown jaundiced --  or else they are people  who are the source of  the
problem,  and  they  don't  want  it  solved.  The technicians remain silent, or
discuss  it  only  in  "the  inner  circles"  where  the  issues are understood.
Policy-makers need to know.
 
 
 
                           ELECTRONIC AIDS (Part I)
 
 
Scenario: Paul Volcker is handed a telegram as he enters the monthly meeting  of
the Federal Open Market  Committe.  Every other member  of the FOMC, which  sets
monetary  policy  for  the  U.S.,  is  also  handed  an identical telegram.  The
telegram reads as follows:
 
    THIS MORNING (a rural  bank is named) SUFFERED  A MAJOR FAILURE IN  ITS
    COMPUTER SYSTEM   STOP  ALL  DATA IN  THAT COMPUTER  HAS BEEN SCRAMBLED
    BEYOND RECOGNITION  STOP   WHEN BANK OFFICIALS  ATTEMPT TO CALL  UP THE
    RECORDS FROM ITS BACK UP COMPUTER TAPES THEY WILL FIND THAT THESE  BACK
    UP TAPES  ARE ALSO  SCRAMBLED  STOP   ON MONDAY  AFTERNOON THREE  OTHER
    SMALL BANKS WILL SUFFER  THE SAME FATE  STOP   ONE WILL BE IN  NEW YORK
    CITY  STOP  ONE WILL  BE IN LOS ANGELES   STOP  ONE WILL BE  IN CHICAGO
     STOP  PLEASE MEET AGAIN ON  TUESDAY AFTERNOON  STOP  WE WILL  GIVE YOU
    INSTRUCTIONS AT THAT TIME
 
Volcker  calls  the  appropriate  bureaucrat  at  the  Federal Reserve Systems's
headquarters, and he asks if there are  any reports from the named bank.  A  few
minutes later,  the official  calls back.   The bank's  management confirms  the
breakdown.  The bank is attempting to install the back-up tapes.  Volcker orders
him to call back  and stop the tapes  from being installed.  The  bank complies.
The tapes are then shipped to the Federal Reserve Bank under armed guard.   When
the FED's  computer specialists  acquire the  same operating  system and  try to
bring up the data, the system crashes.  No usable data.
 
Tuesday  morning,  one  by  one  three  banks  call  the  FED, the FDIC, and the
Comptroller of  the Currency's  office, each  with the  same frantic tale.  They
have been  working all  night, but  their computer  records are scrambled.  They
cannot open at 10 a.m.  They have only an hour to make a decision.  What  should
they do?  The FED instructs them to remain closed.  They are also instructed  to
keep their mouths equally closed.
 
The T.V. networks are tipped off, but  no one at any bank says anything.   Lines
appear in front of each bank.  Governers in all three states call frantically to
Washington.  They all remember Ohio and Maryland.  What is the FED going to do?
 
The FOMC, the Board of Governors of the FED, each regional president, and a team
of  computer  experts  meet  at  the  New  York  FED's offices.  At three in the
afternoon, a telegram is delivered to Volcker.  It is brief.  It says:
 
                                     WORMS
 
"What the @%* is this?" he yells to no one in particular.  The computer men turn
white.   They  do  their  best  to  tell  him  what it means.  They are finished
answering his  questions in  about 45  minutes.  Another  telegram arrives.   It
says:
 
    ON FRIDAY AFTERNOON THE CHASE MANHATTAN BANK WILL EXPERIENCE A  SIMILAR
    COMPUTER  FAILURE   STOP   ITS  BACK  UP  TAPES WILL BE EQUALLY USELESS
     STOP   IT  WILL  NOT  BE  ABLE  TO  REOPEN ON MONDAY MORNING  STOP  ON
    TUESDAY  MORNING  CITICORP  WILL  SUFFER  A  SIMILAR  FAILURE  STOP  ON
    WEDNESDAY MORNING BANK OF AMERICA AND THREE OTHER MAJOR BANKS WILL ALSO
    SUFFER A BREAKDOWN   STOP  WE CAN  PROVIDE YOU WITH  THE CORRECTION FOR
    EACH  COMPUTER   STOP   THE  PRICE  WILL  BE  THE REMOVAL OF DIPLOMATIC
    RECOGNITION OF THE  ILLEGITIMATE STATE OF  ISRAEL BY THE  UNITED STATES
    AND AN END TO ALL ECONOMIC AID TO ISRAEL  STOP  TO PROVE THAT WE CAN DO
    THIS WE WILL  SCRAMBLE ALL THE  RECORDS OF CHASE  MANHATTAN BRANCH BANK
    XYZ TOMORROW MORNING  STOP
 
 
The next morning, all of the records of Chase Manhattan's branch bank are turned
into random numbers.  That afternoon, the President of the United States  breaks
off diplomatic relations  with the state  of Israel.  The  banks stay open.   No
crash of the data occurs.  This time.
 
This is hypothetical scenario.  It is NOT hypothetical technologically.  This is
the terrifying message of this issue  the REMNANT REVIEW. what I have  described
here is  conceivable technologically.   On a  small scale,  it has  already been
threatened.  Let's start with the historical and then go the the possible.
 
 
 
                                     WORMS
 
 
Earlier this year, I read a  very interesting article on a major  problem racing
computer software (programs) development companies.   A program comes on one  or
more 5.25-inch plastic discs.  It takes only a few seconds to copy a program  on
one disc to  a blank disc  which costs $3.   Yet these programs  normally run at
least $250, and usually  sell at $495, and  sometimes cost thousands.  Very  few
are less than $100.  So you have a major temptation: make a $500 asset out of  a
$3 asset.  Insert the $500 program into  drive A, write "COPY A:*.* B:" and  hit
the "enter key"; sixty seconds later, you have a $500 program in drive B.
 
There are  ways to  make this  copying more  difficult.  The  companies code the
programs, and force you to have a  control disc in drive A at all  times.  These
"copy protected" programs are a hassle for users.  We cannot put them on a "hard
(big) disc" easily, and sometimes the  control disc dies for some reason.   Then
what?  Your data are locked in your hard disc or on a floppy disc, but you can't
get  to  the  data  because  the  control  disc is not functioning.  You order a
replacement.  Weeks go by.
 
Last year, several firms came up with a solution.  It is called a WORM.  A  worm
is a command which is built deep into the complex code which creates the program
itself.  These are incredibly complex codes, and it is easy to bury a command in
them.  They cannot be traced.
 
What does the worm  do?  It "eats" things.   Say that you are  a software thief.
You  make  a  copy  of  a  non-copy-protected  disc,  either  to use on a second
computer, or to give (or sell) to a friend.  The programs works just fine.   But
when the programs is copied to a new disc, the worm is "awakened."  It bides its
time, maybe for many months, maybe for years.  The programs's user is blissfully
unaware that a monster lurks inside his pirated program.  He continues to  enter
data, make correlations, etc.  HE BECOMES COMPLETELY DEPENDENT ON THE PROGRAM.
 
Then, without warning, the worm strikes.  Whole sections of the data  dispppear.
Maybe the data storage  disc is erased.  Maybe  it is just scrambled.   Even his
back-up data discs have worms in them.  Everything he entered on those discs  is
gone.  Forever.
 
Can you imagine  the consternation of  the user?  He  has become dependent  on a
booby-trapped program.  His business could simply disappear.  For the savings of
$500 (stolen program), he could lose everything he has.
 
Several firms  threatened to  insert worms  into their  programs.  But then they
backed  off.   They  are  afraid  that  lawsuits initiated against them might go
against them in court.   The could be hit  for damages suffered by  the thieving
victims.  Juries might  decide that the  punishment (a bankruptcy)  was too much
for the crime (a $500 theft).
 
So far, no worms are lurking in any commercial software programs -- as far as  I
know and the industry knows, anyway.  But what if a disgruntled programmer  were
to hide one  in a master  copy of, say,  Lotus 1-2-3, the  most popular business
program on the  market?  What if  ten thousand copies  a month go  out for, say,
three years?  Then, without warning,  every company that has started  using them
loses three years of data?  They sue Lotus.  Lotus goes bankupt paying  lawyers.
NO  COMPANY  IN  THE  INDUSTRY  IS  WILLING  TO  TALK ABOUT THIS SABORAGE THREAT
PUBLICLY.  Obviously.
 
 
 
                                  LARCENISTS
 
 
I just happened to  stumble across an article  on worms in a  computer magazine.
It occurred to me that it might be possible to use the worm technique as a  form
of deliberate sabotage rather that just  as a copy protection device.  But  what
did I know?  I'm not a computer expert.
 
I know a computer expert, however.  I mean, a REAL expert -- one of those people
you occasionally read  about.  In the  world of business,  they're called "space
cadets."  They operate somewhere in between the asteroid belt and Jupiter.   But
this one is different.  He's a businessman, too.
 
I got him to sit  down with me to discuss  the problem of worms.  It  turned out
that he  has a  real fascination  for the  topic.  He  tells me  that there  are
advanced  design  worms,  called  'viruses'  by  'hackers'  --  computer   freak
programming genuises.   "The software  virus is  the most  terrifying thing I've
ever come across," he told me.  And then he showed me why.  My initial  scenario
is based on only a portion of his estimation of the treat.  It gets a lot worse.
 
He gave me a 90-minute FIRESTORM CHAT interview.  He must remain anonymous.   He
used to be a software developer for programs that were used in the U.S.  banking
system, by  is now  employed in  a highly  sensitive job  in a related industry.
Therein lies his problem.  IF HE WERE TO TELL THE STORY OF WHAT HE IS CAPABLE OF
DOING TO THESE BANKS, HIS FIRM MIGHT LOSE A LOT OF SALES.  He can't "go public."
Let's call him Tom.
 
Let me summarize briefly some of the details he gave to me.  they floored me.
They're going to floor you.
 
 
 
1.  JACKPOTTING
 
 
The rush is  on in the  banking world to  get automated teller  machines (ATM's)
into shopping malls, supermarkets, and in  front of every bank.  We've all  seen
them.  Just walk up, punch in your card number, ask for cash, and you get it.
 
In a busy location, one of these machines can hold as much as $250,000 in  cash,
mostly small bills.  These machines are controlled by computer.  They are hooked
up to the bank's computer system, usually by phone lines.  This local line,  Tom
tells me,  is what  computer freaks  call THE  LOOP.  The  loop is  wide open to
tampering.  He says that what computer thieves  are doing is to hook up a  cheap
Apple II computer, tie into the phone  lines, break into the ATM, and get  it to
empty itself.  This is "jackpotting."
 
He tells me that banks are  getting hit by ATM thieves continually,  but nothing
is getting to the press.  The banks have yet to show a profit with the ATM's  so
far, which is understandable.  They are  hoping to get their machines placed  in
key locations, so "market share" is crucial to their plans.  They are  suffering
horrendous losses in the  short run in the  hope that long-run profits  will pay
off, if and when a defense is developed.
 
The banks are  saying nothing because  of their fear  that if the  extent of the
losses gets into the press, they  will be forced by pressure from  depositors --
bank runs  -- to  cancel the  ATM's.  The  losses are  horrendous, he  says.  At
present, there is no known defense, given the communications technology.
 
 
 
2.  ROUNDING OFF
 
 
This is the "preferred" computer bank  theft system.  Someone on the inside  who
has access  to the  software, takes  advantage of  the banks'  need to round off
numbers.  The programs carry numbers out to 13 places.  Banks can't use all that
space. so when they balance the books (interest rates at, say, 9.873), they just
don't count  every tenth  of a  cent.  The  program is  assumed to round off the
numbers randomly.   What does  the bank  care?  But  the thief  has set  up bank
accounts that absorb those random tenths  or hundredths of a cent.  In  millions
of dollars  worth of  transactions (federal  funds, etc.),  programmers in  some
cases have stashed away  hundreds of thousands of  dollars -- maybe millions  --
over a few years.  No one knows how much of this goes on.
 
How could a bank spot this?  The  books would always balance to the penny.   How
would the accountants ever know?
 
I think of a story the Adam  Osborne tells in his paperback book, RUNNING  WILD.
The president of a large firm was looking out his window one day, and he noticed
two Rolls Royce cars parked next to  each other.  He enquired as to the  owners.
They  were  two   men  in  the   data  processing  department.    He  called  in
investigators, and the cars  and the men disappeared.   They fled to Brazil  and
took their cars with them; Brazil has no extradition treaty with the U.S.  Years
later, as Osborne was writing the story, the firm still hadn't figured out  what
they has done.
 
 
 
                                   ARSONISTS
 
 
These  are  the  fearful  ones,  far  more  than  the larcenists.  These are the
practical jokers who get into a major  data bank and trash things.  It's a  kind
of multimillion dollar "Kilroy was here" graffiti.
 
How easy is it to get in?  Incredible easy.  The boy in "War Games" really could
have broken  into most  firms telephone-connected  computers.  Computer programs
exist that allow the user to hook  up his computer to a phone line  and randomly
dial numbers until they  hear the tell-tale whine  of a computer line.   It then
notes the phone number and goes on its way, searching out more lines.
 
They can do it by long distance, free of charge.  The phone company has a  tough
time  tracing  those  who  use  various  sorts  of electonic black boxes to call
anywhere on earth at no charge.  Some people get caught, of course.  "The tip of
the iceberg," says Tom.
 
How do they get in?  Easy; few systems are protected, once you locate the  line.
If one is, he says, you create a deliberate error.  Most programs then  collapse
the protective  shell, and  the hacker  finds himself  inside the  heart of  the
system.  Tom  has designed  a program  which keeps  this from  happening to  his
company's programs, but few companies have anything like it.
 
It's very easy  to get in  if someone has  "logged on" --  opened his terminal's
connection to the main  computer -- if the  system is connected to  phone lines.
Or anyone in the company can just tap in, if someone has left his desk and  left
the computer on.  It's common to forget and leave an open terminal.
 
He showed  me.  He  says anyone  can get  fired for  leaving a  computer on.  He
demonstrated his point.  With  40 computers on line,  he ran a quick  search and
found two of them "logged on," despite  the fact that it was after hours.   "All
the security in the  world can't do anything  if a computer line  is open.  It's
like a burglar alarm; it's worthless if you leave the door unlocked or leave the
keys lying around."  That janitor you hired.  Is he a computer illiterate?  Or a
plant?
 
Once inside, what  can you do?   Steal a fortune?   Yes, if you  really know the
system.  He told me he could easily steal $3 million from a local bank, even  as
an outsider.  He would then offer to give it back AND KEEP HIS MOUTH SHUT  ABOUT
HOW EASY IT WAS if the bank would pay him 10% of the take.  He thinks most banks
would capitulate  for fear  of the  publicity.  In  any case,  he knows  that he
probably wouldn't get caught.
 
How about creating a new identity?   The grade-changing scene in "War Games"  is
true.  You cound even  create a new identity,  give yourself high grades  in any
academic discipline, just by breaking  into a university's data base.   There is
very little security here, he says.
 
But for sheer  vindictiveness, for sheer  envy, consider the  possibilities of a
virus-implanter.  He gets  inside the computer  for a major  communication link:
telephones, large information data base, bank wire transfer, or whatever.   Then
he lays the egg: a tiny, untraceable brief instruction.  Inside a huge data base
are just  a few  characters.  These  float inside  a system,  seeking to  devour
certain kinds of data, or executing certain routines.
 
There  is  a  game  played  by  computer  freaks called "Core War."  They try to
implant these killer messages, which seek out each other and battle one another.
If you find one morning that yours has been consumed, you lost the battle.  That
was probably the origin of worms and viruses.
 
 
 
                                   TERRORISM
 
 
Say that  a revolutionary  terrorist group,  or some  anti-Zionist group  gets a
"ringer" into the system.  He might  be a computer genius type.  Everyone  knows
they are either orientals, dark-skinned people with accents, or teenagers.   The
firms don't hire teenagers, but they hire a lot foreigners.  They may even check
the guy's credentials.  Electronic credentials.  (Ha!).  Then they turn the  guy
loose in the system.
 
The virus is implanted  deep inside the system.   It can then be  transferred to
any other bank's computer by means of EFT (electronic funds transfer).  Maybe it
is triggered when someone with a peculiar and and address opens a bank  account.
Three days later: bam.   The data disappear.  They  haul out the back-up  tapes.
Bam. The virus is  on them, too.  It  is a process of  INFECTION, CONTAMINATION,
AND INCUBATION.  There is no known defense.  Not yet.  This is the bottom line.
 
 
 
                                  ANTIBODIES
 
 
The  designer  of  a  virus  can  also  design an "antibody".  The antibody is a
counter-virus  agent  which  seeks  it  out  and  destroys  it.   But like other
antibodies, it must be specific.  The only way today that an antibody system can
be created is to know what kind of a virus is involved beforehand.
 
Tom says that  people are now  selling antibodies at  very high prices.   Who is
paying?  Big  companies that  suspect that  there is  a virus  present in  their
computers.   In  all  probability,  THE  GUY  SELLING  THE  ANTIBODY CREATED AND
INJECTED THE  VIRUS.  But  how can  any businessman  prove it?   So he  pays the
blackmail.
 
 
 
                               NATIONAL DEFENSE
 
 
A Soviet agent or American spy working for the Soviets penetrates any of a dozen
computers used by the military.  He plants a virus.  The computers talk to  each
other, and the virus spreads to all of them.  It tells them to execute a certain
routine when  a certain  command is  entered at  a missile-controlling terminal.
That  command  might  interfere  with  a  routine  which  activates a missile or
launches it.  Upon reading that command,  the virus shuts down the computer,  or
scrambles the  executing program,  or scrambles  the data.   No more  "launch on
warning."  No more launch at all.  Dead metal.
 
Scenario: The President of  the United States receives  a telephone call on  the
"red  phone"  --  the  direct  link  to  Moscow.  He lifts the receiver and says
"Hello."
 
"Mr.  President,  this is  Michael Gorbachev.   You must  recognize my voice.  I
have very little time.  I will come directly to the point.  You have refused  to
back down on  your threat to  implement your Strategic  Defense Initiative.  You
intend to go ahead with space-based weapons.  My military staff informs me  that
they think that the United States  has the technology to implement it,  and that
it would place my nation's military  strategy in jeopardy.  We cannot allow  you
to do this."
 
"If we  allow you  to deploy  the SDI,  it will  be too  late for  us to respond
effectively.  Therefore, we  are taking the  initiative today.  I  issued orders
this morning to put Soviet military units on immediate alert.  We are abiding by
your biblical rule  to announce the  initiation of hostilities  before striking.
Neither the Japanese nor the Germans gave us this courtesy.  If you do not  come
to terms with  us, we will  launch a first  strike against your  nation in three
hours.  We will delay  for one day, if  you agree to follow  a precise procedure
that I will outline shortly."
 
"At one time we feared nuclear retaliation.  We no longer do.  Within two hours,
you will know why not.  I suggest that you instruct your ballistic missile  team
to prepare your missiles  for a strike.  Then,  to prove to yourself  that we no
longer are concerned about retaliation, launch one or two of them.  As far as  I
am concerned,  launch all  of them.   But please  instruct your  senior military
commanders to report back to you concerning the effects of their instruction.  I
suggest that you  try launching three  or four as  a test.  We  don't care which
ones."
 
"Mr.  President, let  me tell you  what is going  to happen.  As  soon as anyone
attempts to launch a missile, that missile's computer guidance system will  shut
down.  It will lock up tight, and you  will not be able to unlock it within  the
time you need to respond to our attack.  Two hours and thirty minutes from  now,
you finally unlock your frozen computers."
 
"I suggest that you contact your senior officers now.  You will have to mobilize
them  within  60  minutes.   The  test  should  take  about  30 minutes.  I will
telephone you again in 90 minutes to present our terms of surrender."  Click.
 
The President calls the Joint Chiefs.  If he is lucky, he will be able to locate
two of the three in time.  They will be paralyzed.  Who wouldn't be?  But in all
likelihood, they will at least test Gorbachev's theory.  They will order one  or
two missiles launched.  The computer guidance system on both will shut down  the
system.  They  will try  two or  three more,  with the  same result.   They will
attempt to launch one from a submarine, with the same result.
 
The President brings in senior  Congressional officials and the remaining  Joint
Chiefs member to the White House.
 
Exactly 90 minutes after he had hung up, Gorbachev telephones back.  He presents
his list of demands.  First, the  immediate removal of U.S. troops from  Europe.
Second,  the  withdrawal  of  personnel  from  Diego Garcia Island in the Indian
Ocean.  Third, the breaking of  diplomatic relations with Red China  and Taiwan.
Fourth, the removal of all troops from Korea.  Fifth, a moratorium on all  debts
owed  to  U.S.  banks  by  the  Soviet  Union and its client states.  Sixth, the
removal of all Minuteman III missiles from their silos.  Seventh, the return  of
all U.S. submarines to port.  If he agrees, and the orders are delivered  within
two hours, the Soviet Union will delay launching a first strike.  The  President
complies.
 
They might do it with our communications satellites, Tom says.  You might do  it
with any aspect  of U.S. data  transmission.  The virus  could sit dormant  in a
system for years, and no one would know.  Triggered, it would then strike.
 
 
 
                           THE WEST'S VULNERABILITY
 
 
The  West  has  become  increasingly  dependent  on computers.  We can no longer
function without them.  The Third World hasn't.  Neither has the U.S.S.R.  Their
technology is still pre-computer.  They  are inefficient, but they are  far less
vulnerable.
 
Tom  says  that  the  world  of  computers  presumes  that  almost  everyone  is
essentially honest, and that all the brightest programmers must be honest.  They
aren't.  Thus,  the entire  system --  banks, national  defense, large and small
businesses, public utilities -- have opened themselves to attack.  The attackers
are invisible.
 
"Nothing I have  seen in all  my years of  computers scares me  as much as  this
does," he says.  "The system  has been designed in terms  of a far older set  of
standards, especially with respect to security.  It is totally vulnerable."
 
He  compares  it  to  plague,  or  venereal  disease.   People copy each other's
software to  save a  few bucks.   They use  public access  data bases.  They use
"loops"-- the  phone lines.   Yet these  transmission belts  of information  can
become transmission belts of collapse.
 
This is what I have harped on for twenty years: the potential for a collapse  of
the division of labor.  We become  rich by means of a brilliant  technology, yet
we become dependent on it to an extent that no previous society ever has.
 
Centralized  institutions  are  most  vulnerable,  but  because  we  use  public
transmission lines, from microwave transmissions  to cables in the ground,  each
local unit is vulnerable.  Those who would choose to bring down the system  need
only plant electronic  viruses in a  handful of major  common-use data bases  or
transmission sources, and five years or ten years later, the disease hits.
 
It could  brings down  the system  if technological  defenses are not developed.
Nothing on the immediate horizon points to a solution, he says.  The silence  of
those who should know what to do indicates that they don't know what to do,  but
they don't want panic to spread.
 
* TOPIC: SUGGEST -  "CCC Open Suggestion Box"
--&gt; Item 64 from AJP30 on 12/05/85 at 06:49:47
 
 
This is part two of a two part series written by Gary North about software
worms and viruses.  Gary North is an investment newsletter publisher and
presents an interesting perspective of the problem from a non-technical
point of view.  Enjoy.
 
                                   Andrew J. Piziali, x8584.
 
 
-------------------------------------------------------------------------------
 
                          Gary North's Remnant Review
                                                                  Matt. 6:33-34
-------------------------------------------------------------------------------
 
Vol. 12, No. 20                      380                      November 15, 1985
 
 
 
                           ELECTRONIC AIDS (PART 2)
 
 
(Again, note that this issue  of REMNANT REVIEW is not  copyrighted.  Reproduce
it in any form you choose.  This information needs wide dispersal.)
 
Maybe you saw the article buried somewhere in your newspaper.  I saw it in  the
New York Times (Oct. 19):
 
         A group of at least  23 teen-age computer users broke  into a
         Chase Manhattan  Bank computer  installation by  telephone in
         July and August and "significantly damaged" bank records, the
         Federal Bureau of Investigation said yesterday.
 
And where were  these teenagers located?   In San Diego,  ACROSS THE CONTINENT!
It gets even more ludicrous:
 
         Federal  officials  said  that  most  of  the  offenders were
         probably too young to be prosecuted.
 
         Robert D.  Rose, the  Asst.  United  States Attorney handling
         the case, said: "We're not yet sure what we are going to  do.
         But these things  can get out  of hand --  it did get  out of
         hand -- and we have to treat them seriously."
 
Treat WHAT  seriously.  "These  THINGS?"  What  things?  If  they can't legally
treat the electronic trespassers seriously, just what is the man talking about?
He is talking about the topic, above all other topics, that bank and government
officials don't want to face: THE VULNERABILITY OF THEIR COMPUTER RECORDS.
 
I have  seen no  follow-up on  this story  in the  conventional press.  A brief
article did appear in the  computer-oriented tabloid, INFOWORLD (Oct. 28).   It
turns out that the students had broken into the files of Interactive Data Corp.
of Waltham, Massachusetts, which  maintains the bank's financial  records.  The
break-ins were discovered  in late July.   They had obtained  the toll-free 800
number which was restricted (ha!) to Interactive data subscribers.  As late  as
October 9, an illegal  entry was observed.  In  short, IT TOOK TEN  WEEKS AFTER
THE BREAK-INS WHERE DISCOVERED TO PUT A STOP TO THEM.
 
The response of the bank's bureaucracy was predictable.  It will ever be  thus:
"Bank  officials  are  claiming  that  the  FBI  exaggerated  the nature of the
activities of the  suspected individuals.  A  spokesperson for Chase  Manhattan
said  that  Interactive's  customers  were  not  prevented from accessing their
accounts and that none of Interactive's data was altered or manipulated in  any
way."  In  response, FBI  supervisory agent  John Kelso  said that  the FBI has
sworn affidavits  from bank  officials that  say data  has been  manipulated or
damaged.  "That sounds pretty serious to me," he volunteered.
 
Here is the capper: Interactive Data  has 25,000 subscribers who are tied  into
that toll-free phone line.  Try keeping tight security on a system with  25,000
users.  Chase Manhattan couldn't.  If they can't, who can?
 
And if Chase Manhattan Bank was vulnerable to 23 teenagers who are too young to
prosecute, consider its vulnerability to JUST ONE ENVY-DRIVEN GENIUS who  knows
all about electronic viruses.  The  students who did this were  apparently just
goofing around.  But what if just one malevolent computer freak decided to "get
even" with  Chase Manhattan?   What if  he had  phoned in  just once  or twice,
implanted a long-dormant data-killing virus, and quit?  What if he had tied its
detonation to, say, a calendar clock  in the Interactive computer?  If it  took
security forces  from July  until early  October 15  to raid  the 23  students'
homes, they would never have spotted one break-in.  They could not have  traced
it, either.  Conclusion: we have a risk-free opportunity for electronic  arson.
We face  a potential  electronic epidemic.   AND WHEN  I SAY  "WE," I  MEAN THE
ENTIRE FINANCIAL SYSTEM OF THE WEST.
 
Sure, all the bank  "spokespersons" in the world  will tell you, "no  problem."
But there is a problem.  A horrendous problem.
 
At  this  point,  it  REALLY  gets  interesting.  Chase Manhattan Bank has just
announced that we will  be able to set  up our own personal  electronic banking
facilities with  them by  buying an  expanded version  of Managing  Your Money,
Andrew Tobias' home financial management program.  Citicorp and Bank of America
have opted for  Dollars and Sense,  a rival program.   You will be  able to pay
monthly bills electronically, balance your "checkbook," monitor your net worth,
buy  and  sell  stocks,  etc.,  etc.,  etc.,  just be dialing Citicorp or Chase
Manhattan.  Fantastic!  But despite all the assurances, I get nervous.  Yes,  I
know no  one will  be able  to break  in and  tamper with  the numbers.  But 23
teenagers shouldn't have  been able to  do it, either.   And now we're  talking
about a lot more subscribers than 25,000.
 
Obviously,  the  master  program  used  by  the banks will prohibit easy entry.
Unfortunately, someone has to write the program.  Can you imagine the blackmail
possibilities?   Some  hot-shot  programmer  could  build  in  a bomb, and then
threaten to detonate it.  In fact,  he could merely pretend to have  inserted a
virus.  Who would want to call his bluff?  Not Chase Manhattan, I would bet.
 
 
 
                             CORE WARS REVISITED
 
 
In May  of 1984,  A.K. Dewdney  published an  article in  Scientific American's
"Computer Recreations" column.   It was a  light-hearted piece on  how computer
experts  can  get  involved  in  playing  this  exciting  game of "blow up your
opponent's defenses."  You know: RECREATION!  In the March 1985 issue, he wrote
a follow-up.  It begins:
 
         When the column about Core War appeared last May, it had  not
         occurred  to  me  how  serious  a  topic  I  was raising.  My
         descriptions of  machine-language programs,  moving about  in
         memory and trying  to destroy each  other, struck a  resonant
         chord.   According  to  many  readers,  whose stories I shall
         tell, there are abundant examples of worms, viruses and other
         software  creatures  living  in  every  conceivable computing
         environment.   SOME  OF  THE  POSSIBILITIES ARE SO HORRIFYING
         THAT I HESITATE TO SET THEM DOWN AT ALL (emphasis added.)
 
It turns out that  the French have been  enjoying a novel on  the international
implications, SOFTWAR: LA GUERRE DOUCE,  by Breton and Beneich.  A  translation
is  scheduled  for  publication  here  by  Holt, Rinehart &amp; Winston.  The study
revolves around the  sale of a  high-power computer to  the Soviet Union.   The
U.S. allows its export because it has  a "software bomb" in it.  When the  U.S.
Weather Service  announces a  certain temperature  at St.  Thomas in the Virgin
Islands, the program proceeds to subvert every piece of software in the  Soviet
Union.
 
A pair of Italian programmers  were "inspired" by the translation  of Dewdney's
original article to dream up a virus (a virus is a computer-to-computer killer,
whereas a worm is  resident in one man's  computer).  They figured out  that by
infecting a  disk operating  system disk  (these start  computers and tell them
what to do with programs and electronics), and then installing it on disks used
by the biggest computer shop in the city, they could create an epidemic.   They
decided not to do it.  In short, the only restraint is SELF-RESTRAINT.
 
A high school student in Pittsburgh wrote a virus which was more subtle than  a
data-destroying virus, which  at least tells  us that we  have a problem.   His
virus created  a plague  of very  subtle errors  in the  disk operating system.
"All of this seems pretty juvenile," he wrote, but "Oh woe to me!  I have never
been able to get rid of my electronic plague.  It infested all of my disks, and
all  of  my  friends'  disks.   It  even  managed to get onto my math teacher's
graphing disks."  He wrote a program  to destroy the virus (an "antidote")  but
it is not anywhere near as effective as the virus is.
 
Warning: do not copy disks from your friends' copies.  This act of piracy could
cost you plenty.
 
 
 
                              A COMMERCIAL WORM
 
 
Just a few days after I wrote "Electronic AIDS, Part I," I read a column in the
WASHINGTON TIMES, the conservative  (Moonie-owed) daily newspaper.  One  of the
reporters  has  a  computer.   He  had  purchased a newly released program from
Microsoft Co., called  "Access."  Understand that  Microsoft supplies the  disk
operating system which is used by  the IBM PC, the most popular  microcomputer.
In other words,  this is no  backyard company.  It  is one of  the two or three
software  giants  in  the  U.S.  (Its  owner  is  under age 30, which tells you
something about who is pinoeering the microcomputer revolution.)
 
As he was setting up his computer to take advantage of this  telecommunications
program, a  warning flashed  on his  screen: "The  weed of  crime bears  bitter
fruit.  Now  trashing your  program disk."   Wham!  He  lost all  his files  --
probably a couple of year's worth of work.  Sure, he was probably smart  enough
to have made back-up copies, but think of the risk.  And what if it had been  a
worm that kept silent for a few years, infecting all of his back-up disks?
 
He called Microsoft, and they gave him the runaround.  They told him that  they
were not  responsible.  Some  programmer had  put in  the worm  in order to zap
program pirates,  but the  journalist insisted  that he  was an original buyer.
Tough luck, they told him.  Obviously, they didn't know that he was a reporter.
 
Then  he  published  his  article.   All  of  a sudden, the victim was not some
average buyer.  He  was big trouble.   Things started moving.   INFOWORLD (Oct.
28) reports that Microsoft has admitted that a programmer put in the worm,  but
without permission.  The offending text  has now been removed, we  are assured.
But what if it had sat in the master for three years?  HERE IS THE PREMIER FIRM
IN THE SOFTWARE BUSINESS, AND IT HAD AN UNAUTHORIZED PROGRAMMER INSERT A  WORM.
This  is  not  idle  speculation.   It  has  already  happened,  verfiying   my
hypothetical scenario within a few days after I published it.
 
Can you imagine the absolute havoc that a dormant worm or virus could create if
it were imbedded in  all updates of Microsoft's  masters of PC DOS  and MS DOS,
the  operating  systems   for  all  IBM   microcomputers  and  IBM   compatible
microcomputers?   It   could  cost   the  U.S.   economy  billions,   and  some
microcomputer-dependent firms  wouldn't survive.   Any Microsoft  spokesman who
says, "it's impossible; it  could never happen" has  to explain how it  already
did happen to "Access."
 
 
 
                            ADAM OSBORNE'S WARNING
 
 
You may  know the  name Adam  Osborne.  He  invented the revolutionary portable
computer, the  Osborne 1.   Before there  was an  Osborne 2,  the company  went
bankrupt.  Compaq, the  most successful first-year  firm in U.S.  history (over
$100  million  in  sales  in  its  12  months  of  operations) and others built
imitations that were far superior.
 
That isn't my point,  however.  Adam Osborne was  "present at the creation"  of
the microcomputer industry.  He created Osborne publications, and then sold out
to McGraw Hill.  He knows what is going on.  In his delightful paperback  book,
RUNNING WILD, which  is a history  of the microcomputer  (desk top) revolution,
1975-82,  he  offers  this  warning.   He  says  that three areas should not be
allowed to be computerized: 1) bank  money transfers; 2) the stock market;  and
3) elections.
 
All three are just about fully computerized.  Another ten years, or maybe five,
and they will be 100%  computerized.  Several firms allow microcomputer  buying
and selling of stock (e.g., Charles Schwab), and New York Stock Exchange  floor
transactions eventually will  be fully computerized,  at which time  it will be
pressured to get rid of  the "specialists" who make (and  sometimes manipulate)
the market, short-term  -- Richard Ney's  hated "Wall Street  Gang" -- but  the
price of getting rid of them may turn out to be horrendously high.
 
"The  great  fortunes  of  the  21st  century,"  Osborne predicts, "will be the
legacies of the great computer thieves of the 20th."
 
Three years ago, I used a firm to supply computer services I needed.  The  head
of it was a  former businessman, quite young,  and a true "space  cadet."  I've
quoted him  in the  last issue.   I call  him Tom.  He operated  in a world far
removed mentally from the rest of us.  He is a nice fellow, a Christian, and  a
moral philosopher of sorts.
 
He ran the operations of the local elections.  He did it fairly  inexpensively.
He told me why: "I want to keep these elections honest.  It would be incredibly
simple to rig the program to produce whatever outcome I wanted in close  races.
If I can do it, anyone with enough skill to set up the system could do it."
 
I asked him  if he thought  Osborne was correct  in his predictions  about bank
theft.  "It would be a piece of cake for me to steal three or four million from
any local bank.  I could  go in the next week,  offer to give 90% of  the money
back, keep 10% as a finder's fee, and promise not to tell the press how easy it
was to steal.  They would probably pay me my 10% just to keep me quiet."
 
Look, these people  are geniuses.  Worse,  they are geniuses  in a vary  narrow
field technically, which is now  being used to control darned  near everything.
This  unique  intellectual-technical  skill  is  the  possession of literally a
handful of people,  mostly under 35  years of age.   They are "fooling  around"
with Chase Manhattan Bank's  computers.  What happens when  a few of them  stop
fooling around and get deadly serious?
 
Computer program designers keep telling us that there is no 100% secure way  to
defend data banks.  Maybe  there will be a  98% secure system someday,  but not
now.  THE SYSTEM RELIES ON THE INTEGRITY OF YOUTH TO DEFEND ITSELF.  In  short,
SELF-GOVERNMENT is the major defense.
 
And where have they learned self-discipline?  In the public schools?
 
 
 
                            "NOW YOU'VE DONE IT!"
 
 
About four years ago, I read an article in the ROLLING STONE, the tabloid aimed
at rock music fans.   It was the only  article I ever read  in that periodical.
It was a gem.
 
It described a subculture of students at Stanford University, "hackers."  These
people are computer freaks.  The mainframe computer at Stanford was cheaper  to
use after midnight, so from midnight  to 6 a.m., the hackers gathered  at their
terminals.  They lived on candy bars, junk food, and high-technology dreams.
 
One of the games they played  was breaking into each other's programs.   It was
considered the mark  of a master  hacker to be  able to crack  another hacker's
defenses.  They would spend hours trying.  They were "hacker-crackers."
 
One bright fellow then designed a classic booby trap.  He wrote a program which
warned  trespassers  not  to  tamper  withit.   This,  of course, alerted every
would-be electronic safe-cracker to the  challenge.  It was a complex  program,
and it took days  to crack it.  Then,  after repeated warnings, the  successful
trespasser got a surprise.  Japanese  letters appeared on his screen.   Roughly
translated, the words proclaimed, "Now you've done it!"
 
At that point, the victim's computer screen went blank.  Then the names of  all
his own  computer files  appeared on  the screen  -- files  that may have taken
years to assemble.  One  by one, they blipped  off the screen.  In  horror, the
victim would stare at the screen, unable to stop the process.
 
As it turned out, the booby trap  was only a practical joke.  It really  didn't
erase all the victim's files.  It only listed the NAMES, and then erased  them.
But for a horrifying few minutes, the victim wouldn't know this.
 
Hackers play games.  Very interesting games.
 
The kind of  people who spend  six hours, midnight  to 6 a.m.,  trying to break
into each  other's programs  are different  from the  rest of  us.  Among their
ranks are some highly individualistic  people.  Some of them are  libertarians.
I mean anarchists.  They  are electronic "don't tread  on me" sorts of  people.
They do not appreciate bureaucracy.   They appreciate being pushed around  even
less.
 
The folks  at Chase  Manhattan really  do have  a problem.   Do you  attempt to
prosecute a  legally unprosecutable  kid?  A  kid who  has already cracked your
computer  system?   I  don't  think  you  do.   You  play the role of stern but
appreciative banker.  "Son, I  am impressed by your  ability to break in.   But
understand, we are honest people.  There is a code of honor here.  You wouldn't
want to break that code -- of honor, I mean -- would you?"  Because if this kid
gets angry, he can do it again.  Quietly.  And next time, he deposits a virus.
 
Of course, Chase may hire a  programming team to create an unbreakable  system.
Sure.  "Hire fox  A. Give him  chain link fence  B. Hire him  to build fence  B
around chicken coop C."
 
 
 
                                TEEN CHALLENGE
 
 
Suppose that the  public gets wind  of the threat  to the whole  banking system
which is posed by  viruses?  What do the  bankers (or anyone else)  announce to
the public?  "We want to assure you that our computer program is  impenetrable.
No one can break in.  It is foolproof."
 
Here is a challenge -- rather like the Stanford program that announced: "Do not
trespass."  These kids see breaking in  as a challenge, a kind of  sport.  They
do not regard it as vandalism, even  if it costs a company millions of  dollars
to unscramble.  They may be ethical in other respects, but they think of  "core
wars" as a game.
 
How would you like  to be the 60-year-old  banker who doesn't know  a byte from
usury, but  whose public  relations department  tells him  to inform the public
that nobody can crack his bank's code?  To cite Mr. T in "Rocky III," that bank
is dead meat.  So are its depositors.
 
But if he keeps quiet, and the story still gets out about the vulnerability  of
the system, one or two small "virus-demolished" banks could trigger a  collapse
of the  system, as  people do  the only  smart thing:  run for CASH.  The whole
fractional  reserve  banking  system  would  deflate;  only  the FED's printing
presses could "save the day," in a wave of fiat money.
 
What I  am saying  is this:  I THINK  THAT WE  WILL SEE  THE END  OF FRACTIONAL
RESERVE BANKING IN OUR DAY. At the very least, I think we will see it subjected
to tremendous shocks.   People will lose  faith in electronic  promises made by
bureaucrats who do  not know anything  about the monsters  that their efficient
computers can be turned into.
 
 
 
                            ATTACK ON MARTINSBURG
 
 
Now, let's take it a step  farther.  Some day some state or  Federal bureaucrat
is going  to step  on the  toes of  some genius  entrepreneur who has created a
software development firm.  The bureaucrat  will try to wrap this  enterpreneur
in red tape.  Or maybe -- just maybe -- he will try to sock him with a tax bill
that the entrepreneur regards as unfair.
 
In Martinsburg,  West Virginia,  there is  a large  computer.  It  is owned and
operated by the Internal Revenue Service.   Into it, over the next five  years,
the IRS apparently intends to deposit all the records it can assemble on  every
US taxpayer.  This computer data base will be the biggest in the world.  It  is
the tool by which  the IRS hopes to  increase taxpayer compliance.  And  it may
succeed.  For a while.
 
This is  one reason  for saving  all letters  to and  from the  IRS. If the IRS
becomes  dependent  on  its  computer   system,  which  is  likely,  then   any
short-circuiting of its  data base could  create havoc for  tax collecting.  If
word gets  out that  a major  failure has  hit the  IRS, the  tax revolt  could
multiply overnight.  You would see the deficit become astronomical.  If the IRS
continues  to  tie  its  "voluntary"  compliance  program  to  the myth of "the
all-seeing computer," then news of the computer's scrambling could backfire.
 
It is  possible that  the story  of the  IRS data  base is  a myth.  Maybe they
aren't going to build it.  But if the public believes that such computer  power
is at the disposal of the IRS, and taxpayers then learn either that the  system
has been blown, or  that it was mythical  from the start, the  tax revolt could
spread like  an epidemic.   The elctronic  epidemic could  trigger a tax revolt
epidemic.
 
He who lives on the cutting  edge of technology eventually dies on  the cutting
edge of technology.
 
 
 
                         "PEOPLE ARE BASICALLY GOOD"
 
 
Let's return to my  taped interview with "Tom."   In a 90-minute interview,  we
covered a lot  of ground.  But  one topic which  stands out in  my mind is  our
discussion of the  presupposition which goes  into the creation  of a computer-
based  society.   The  computer  people  have  all adopted the assumption which
undergirds modern  science, namely,  that participants  are well-meaning,  that
they  will  not  fake  their  experiments,  and  that  they will play fair.  If
scientists  had  to  check  every  aspect  of  every article, science could not
advance very fast.
 
What about the computer  industry?  The whole system  rests on faith: "Men  are
not malevolent..  They are not envy-driven.  They will not deliberately seek to
destroy the  work of  some random  victim."  Tom  says categorically  thay this
assumption is false.  There are bad people with tremendous computer skills, and
that modern society has not  restructured its economic institutions to  protect
itself.
 
Here is one example  of a break-in technique.   Someone phones into a  computer
which has been left open temporarily  by some user.  The lock is  unlatched; he
needs no  key to  get in.   He then  seeks to  penetrate te  inner core  of the
program, such as a  bank's program.  He creates  a deliberate error, which  all
too  ofter  triggers  a  kind  of  electronic  explosion.  The protective shell
self-destructs, and the invader now finds himself inside the system, where  far
fewer defense mechanisms exist.
 
Tom  designed  his  own  firm's  defense  against  this  tactic.   His  program
automatically records the source of the  error, and throws the user out  of the
program.  The  program has  protection against  deliberate errors,  but most of
them don't, he says.  A major error simply simply collapses the program's outer
shell.
 
In my previous issue, I speculated  that a Soviet spy or agent  could penetrate
U.S.  computers.   Note:  I  did  not  assume  that he would simply phone in; I
assumed  that  a  disloyal  programmer,  or  a  team,  could plant the virus as
insiders.  From there, the virus would spread though the system through  normal
telecommunications.  Several people have written  in to tell me that  a wrecker
cannot destroy  the system  by penetrating  it from  the outside.   They may be
correct.  But when informed  that I am assuming  an INSIDE JOB by  someone with
access  to  a  major  computer,  the  critics  have admitted that this might be
possible.
 
The weed of crime bears bitter fruit: FOR HONEST, COMPUTER-DEPENDENT PEOPLE.
 
 
 
                                FEDERAL FUNDS
 
 
The Federal Funds  bank transfer lines  allow banks to  borrow money overnight.
Hundreds of billions of dollars go  across these lines every working day.   The
bank's   computers   communicate   with   each   other   by   means   of   this
telecommunications hook-up.  What if someone  were to plant a long-delay  virus
in  the  software  which  operates  these  transfers?  And what banker ahs even
thought about this problem?
 
What if this scenario  were to take place:  A virus triggers the  disruption of
bank records -- not a total  breakdown initially, but disruptions in the  data?
It  might  be  weeks  or  months  before  auditors recognized the extent of the
problem.
 
As rumors begin to leak  out about complex accounting or  other data-management
problems of major banks all  over the U.S. (including off-shore  branches), the
various banking regulatory  agencies would be  swamped with crises  and outside
rumors.  Then, all at once, bank computers begin breaking down.
 
The rumors then explode.  The lines appear in front of banks.  The only  answer
at this point is to print up paper money.  It would be printed by the  hundreds
of billions in  order to offset  the deflationary effects  of bank runs  (paper
money which is pulled out but redeposited in another bank).
 
YOU COULD TOPPLE THE FRACTIONAL RESERVE BANKING SYSTEM ALL OVER THE WORLD.  The
entire  payments  system  could  easily  become  engulfed in chaos.  Debits and
credits would  no longer  be meaningful.   A pure  paper money  inflation would
replace  the  manipulated  "fine-tuned"  monitary  inflation  of modern central
banking.
 
All of a  sudden, market-created alternative  currencies would be  revived.  It
would  the  be  METALLIC  CASH  that  talks  loudest.   Silver  dimes  are  not
electronic.  They can't be infected electronically.  They still circulate  when
banks are "temporarily closed, due to circumstance beyond our control."
 
The  loss  of  efficiency  would  be  initially horrendous, I would guess.  The
division of labor would break down.   You could that have the crash  that lurks
in the minds and suspicions of average depositors.  Who says it cannot  happen?
A lot of public relations firms  hired by the banks -- computer  illiterates in
high places?
 
What  we  have is  AN  INTERNATIONAL  BANK  MONEY  WIRE SYSTEM which is TOTALLY
VULNERABLE to  some vindictive  programmer.  There  is little  doubt in my mind
that the bankers are desperatesly fearful of this sort of vandalism.  It  could
topple  people's  confidence  in  the  fractional  reserve  banking system, and
confidence is the only thing which keeps it going.
  
 
                                  CONCLUSION
 
 
Technologically, there  is no  solution at  this point.   I have  no heartening
message.  Maybe later; not now.  Keep precious metal coins.  Don't assume  that
it  an't  happen  here.   It  can.   The  only  thing  holding  it  back is the
restraining  hand   of  God,   through  the   temporary  self-restraint   of  a
technological priesthood.

				Neal Macklin
				(408) 737-5214
				...{hplabs,ihnp4}!amdahl!nzm10

              [There are no opinions expressed in this article].

=========================================================================

Elliott S Frank    ...!{ihnp4,hplabs,amd,nsc}!amdahl!esf00     (408) 746-6384

[the above opinions are strictly mine, if anyone's]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-37</DOCNO>
<DOCOLDNO>IA012-000128-B043-56</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.28.html 128.240.150.127 19970217000945 text/html 16416
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:08:11 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 28</TITLE>
<LINK REL="Prev" HREF="/Risks/1.27.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.29.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 28</H1>
<H2> Sunday, 8 Dec 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Viruses and Worms 
</A>
<DD>
<A HREF="#subj1.1">
Mark S. Day
</A><br>
<A HREF="#subj1.2">
 Aaron M. Ellison
</A><br>
<A HREF="#subj1.3">
 Ted Lee
</A><br>
<A HREF="#subj1.4">
 Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Electromagnetic Interference 
</A>
<DD>
<A HREF="#subj2.1">
Chuq Von Rospach
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Crackers 
</A>
<DD>
<A HREF="#subj3.1">
Peter Reiher
</A><br>
<A HREF="#subj3.2">
 Matt Bishop
</A><br>
<A HREF="#subj3.3">
 Dave Dyer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Viruses and Worms
</A>
</H3>
<address>
Mark S. Day 
&lt;<A HREF="mailto:MDAY@MIT-XX.ARPA">
MDAY@MIT-XX.ARPA
</A>&gt;
</address>
<i>
Mon 9 Dec 85 14:57:40-EST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Hysterical panic about viruses in programs is at least as annoying as
the more common complacent stupor about risks from computers.  The
author of <A HREF="/Risks/1.27.html">RISKS-1.27</A> seems to be dead set on Software Apocalypse Now.
We swing from viruses in software to unencrypted data links on bank
machines to teen-aged kids cracking systems.  Also, the usual screams
of "mad genius hackers playing sick games" can be heard... sigh,
programmers are so misunderstood...

The discussion about viruses is actually sort of interesting, the
others fall into the category of "there are fixes which have a certain
cost; you have to decide whether it's worthwhile."  Encryption and
tighter security systems raise the cost of the system and also raise
the cost of breaking the system.  The question is, for the data and
functions being provided, what is an appropriate level of protection?  
I'm not going to panic because many bicycles have cheap locks or no locks;
some bikes aren't worth stealing, and in some areas there's relatively little
theft of bicycles.  If I have data worth protecting, I should be prepared to
protect it.  I will agree that far too few people are aware of the hazards
or of what they can do to protect themselves, but that is far from saying 
that I want to pay for security I don't need.

On viruses, etc.: it is certainly the case that you only want software
which is written by people you trust (and ENTIRELY by people you trust
-- see Ken Thompson's Turing Award Lecture for a further discussion of
this).  But is that different from needing to have bookkeepers
and treasurers that you trust in order to avoid embezzlement?  If
bankers and national security types don't take steps to ensure that
they have good software, then they certainly have a problem, but not a
hopeless one.  There have been previous proposals to have independent
"software certification agencies" to ensure software quality, but I
don't know if they would really be able to solve this problem.

The "solitary programmer" mentality is at least partly to blame for
things like "unauthorized worms" -- if people expect to have their
code read by others, who may question the reasons for doing certain
things, it becomes enormously harder to conceal unauthorized features
(unless the programmer can convince the inspector(s) to join in a
conspiracy).  I am still surprised at how many companies do not ask
programmers to read each other's code.  Quite apart from security
worries, having inspections or walkthroughs seems to sharply improve
maintainability and finds a number of bugs and design flaws.

I have little or no sympathy for people who illegally copy a program
and then find one day that it's trashed their data.  Serves 'em right.

--Mark

P.S. The term "worm" was not coined in a Scientific American column.  I
believe John Brunner used it in his novel The Shockwave Rider and 
Shoch and Hupp picked up the term for a paper in Communications of the ACM.
It may have been used earlier than that; I don't know.

</PRE>
<HR><H3><A NAME="subj1.2">
     viruses, worms and history
</A>
</H3>
<address>
          Aaron M. Ellison  
&lt;<A HREF="mailto:BI467000%BROWNVM.BITNET@WISCVM.ARPA">
BI467000%BROWNVM.BITNET@WISCVM.ARPA
</A>&gt;
</address>
<i>
Mon, 09 Dec 85 08:56:27 EST
</i><PRE>

Regarding Neal Macklin's "expose" of virus technology, I would only
add that the idea is not at all new. John Brunner, a well-known
speculative fiction writer, wrote a novel called "Shockwave Rider"
over 10 years ago(!) predicting the blackmailing of a then corrupt
U.S. government by a morally-upright computer hacker. Although I share
Neal's concerns, I am not at all convinced (even as a credit-card and
ATM-card-carrying young and aspiring academic) that under certain
circumstances, the collapse of the fractional reserve system, the
banking system, and the credit markets would be an awful event. Sure
there would be chaos, but who knows what could arise from the rubble.
...I would add that reading Shockwave Rider when I was in high school
prompted me to learn about computers, and although I have not the
competence to develop tapeworms and viruses, if it's just now getting
out to the "hacker world" that viruses exist, you can bet that the
NSA may already have developed one (pardon the paranoia).

Aaron Ellison
Graduate Program in Ecology &amp; Evolutionary Biology
Brown University
Providence, Rhode Island 02912

</PRE>
<HR><H3><A NAME="subj1.3">
[The Worm Turns in His Gravy?]
</A>
</H3>
<address>
&lt;<A HREF="mailto: TMPLee@DOCKMASTER.ARPA">
 TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Sat, 7 Dec 85 22:25 EST
</i><PRE>
To:  Neumann@SRI-CSL.ARPA [adapted for RISKS]

I suppose it would be nice to tell the original author of the long issue
about viruses, etc., that there ARE technical solutions, although not
necessarily within his lifetime if he's using IBM systems, which most
financial institutions do ...  Ted Lee

</PRE>
<HR><H3><A NAME="subj1.4">
Re:  <A HREF="/Risks/1.27.html">RISKS-1.27</A>
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:vax-populi!dparnas@nrl-css.arpa ">
vax-populi!dparnas@nrl-css.arpa 
</A>&gt;
</address>
<i>
Mon, 9 Dec 85 07:23:03 pst
</i><PRE>
Cc: nrl-css!neumann@SRI-CSL.ARPA

Peter,
	Risks is supposed to be a digest.  The huge article that just
ate up my time like worm could have been digested and the summary
put in a few lines.  Worms have their place.  Eating up stories
like that one is one of their good uses.  Worms digest waste.

Dave          [and I got THREE copies of Dave's message.  Oh, well.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Electromagnetic Interference
</A>
</H3>
<address>
Chuq Von Rospach
&lt;<A HREF="mailto:sun!plaid!chuq@ucbvax.berkeley.edu ">
sun!plaid!chuq@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Thu, 5 Dec 85 08:29:09 pst
</i><PRE>

I was listening to a radio station the other day whose studio is on the San
Francisco Bay. In the early afternoon, the station started getting a
re-occuring noise over the air that sounded vaguely like a burp, which
distracted the DJ no end. It turned out after investigation by their
engineers that it was being caused by a Navy Aircraft Carrier that had just
entered the bay on the way to Alameda. Every time the radar pointed at the
studio, it caused the stations electronics to go bonkers (that's a powerful
radar...). I wonder what other electronics those things would interfere
with?

chuq

      [Perhaps the squawks were emitted by a carrier pitch-in?  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
       crackers
</A>
</H3>
<address>
          Peter Reiher 
&lt;<A HREF="mailto:reiher@LOCUS.UCLA.EDU">
reiher@LOCUS.UCLA.EDU
</A>&gt;
</address>
<i>
Wed, 4 Dec 85 22:30:33 PST
</i><PRE>

I imagine you will have numerous postings making the following point, but,
if you don't, someone should say it.  

&gt; Thomas Cox writes:

&gt;1. no password-protected system is EVER likely to be broken into by so-called
&gt;     hackers.  They can sit and guess, just like they can try and guess the 
&gt;     combination to my bike lock.  I'm not worried about it.

This all depends on how loosely you define "stealing a password".  Does
a person who hangs around your printer room, picking up loose header
sheets with people's account names and real-world names on them stealing 
passwords?  Someone who does so can break into many systems, as many people
will choose passwords equal to their login ids or first or last names.
If the person communicated with people via email at your site, or was able
to guess what their login id is (not a hard job in many places), then the
same vulnerability exists.  The problem is exacerbated if the cracker can get
access to a list of your users.  On most UNIX systems, once he is in at all,
this is trivial.

     [Not to mention the fact that passwords are usually transmitted 
      unencrypted within local nets and externally as well...  PGN]

In fact, barring fairly stringent rules on password choices, and/or physical
security preventing intruders from accessing terminals (and, possibly,
modem features to discourage brute force guessing), most computer systems
can be broken into once a few user ids are known, provided the cracker has
the modicum of expertise and equipment necessary to write a program to
test all dictionary words against the user ids' passwords.   The recent
Bell Systems Technical Journal issue on UNIX had a discouraging article
on how easy it is to break into the majority of UNIX systems, given a list
of user ids, testing only twenty or forty possible passwords per user id.

Perhaps you don't consider a lax password system a password system at all,
but, barring that, your statement is demonstrably false.
 
        			Peter Reiher
				reiher@LOCUS.UCLA.EDU
        			{...ihnp4,ucbvax,sdcrdcf}!ucla-cs!reiher

       [Unfortunately, discussions of the risks of relying on passwords
        need to held over and over again.  If you have not thought deeply
        or been burned, it is too easy to be naive.  The sophisticated
        crackers -- as opposed to the simplistic ones -- find very few
        boundaries they cannot get through (or go around).  PGN]

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Hackers (aka "Head in the Sand")
</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:mab@riacs.ARPA">
mab@riacs.ARPA
</A>&gt;
</address>
<i>
5 Dec 1985 0959-PST (Thursday)
</i><PRE>

   I think Thomas Cox's article ("Hackers", Risks V1N26) is optimistic
in the extreme:

&gt; 1. no password-protected system is EVER likely to be broken into by so-called
&gt;      hackers.  They can sit and guess, just like they can try and guess the 
&gt;      combination to my bike lock.  I'm not worried about it.

Sorry, but I am.  When you say "password-protected", I interpret that
to mean the user setting his or her password to anything other than the
site/manufacturer default.  Turns out a lot of people set it to their
name, login, spouse's name, etc.  (See Morris and Thompson, "Password
Security: A Case History", CACM 22(11), pp.594-597 (Nov. 1979) for more
information about this claim.)  If you know anything about the system
you're attacking, such as whose account you're trying to get into,
this makes the account rather a sitting duck.  So I'd disagree with
your statement above.
   Of course, if you mean something else by "password-protected", could
you be more explicit?  My opinion could very well be inapplicable ...
   (Incidentally, bear in mind the "bike" is worth maybe a half million,
considering the information stored on it, so if you just trust the
"lock", and don't take off a wheel, you're inviting trouble ...)

Matt

</PRE>
<HR><H3><A NAME="subj3.3">
Hackers' guessing passwords
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
8 Dec 1985 14:21:50 PST
</i><PRE>
From: Dave Dyer       &lt;DDYER@USC-ISIB.ARPA&gt;
To: risks@SRI-CSL.ARPA

In Response to Thomas Cox in Risks 1.26:
	
  "1. no password-protected system is EVER likely to be broken into by 
     so-called hackers.  They can sit and guess, just like they can try 
     and guess the combination to my bike lock.  I'm not worried about it."

This is patently untrue.   I have personally guessed passwords on
several occasions;  It isn't even hard unless you want some particular 
password.   One of the recent, widely publicised "hacker" cases
involved exactly what you say is impossible;  the perpetrator
was merely making a sport of guessing passwords, and changing them
as a warning to the account owner.  In addition to guessing,
there are multitudes of ruses to obtain passwords, some technical,
but many simply exploiting human weaknesses.    

It is certainly true that "unguessable" passwords exist, but any 
enforced mechanism for assuring unguessable passwords will also
be regarded as "unrememberable", and therefore more vulnerable
to non-guessing methods.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Hackers, Crackers, and Snackers
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Mon 9 Dec 85 15:52:42-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

I received an anonymous phone call this morning from someone who felt
inspired by the last two issues of RISKS to relate some experiences he/she
had had while working for the Texas Commerce bank.  Apparently the computer
maintenance staff had fun with the wire-transfer programs, using passwords
that had been taped under a desk.  They would randomly transfer various
amounts ($100,000 was mentioned as typical) from one account to anothe, just
for kicks.  They were astounded that no one every caught on, and the
passwords were never changed.  When I asked whether all such transactions
had been reversed, the answer was probably yes.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-38</DOCNO>
<DOCOLDNO>IA012-000128-B043-84</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.29.html 128.240.150.127 19970217001003 text/html 22853
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:08:28 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 29</TITLE>
<LINK REL="Prev" HREF="/Risks/1.28.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.30.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 29</H1>
<H2> Thursday, 12 Dec 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer-compared prescriptions 
</A>
<DD>
<A HREF="#subj1.1">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  SDI: Danny Cohen and Eastport Group comments 
</A>
<DD>
<A HREF="#subj2.1">
Gary Chapman via Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Worms, etc. 
</A>
<DD>
<A HREF="#subj3.1">
Keith F. Lynch
</A><br>
<A HREF="#subj3.2">
 Stavros Macrakis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Passwords, etc. 
</A>
<DD>
<A HREF="#subj4.1">
King Ables
</A><br>
<A HREF="#subj4.2">
 Dave Curry
</A><br>
<A HREF="#subj4.3">
 Dan Bower
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks re computer-compared prescriptions
</A>
</H3>
<address>
Dave Platt 
&lt;<A HREF="mailto:Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA">
Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Tue, 10 Dec 85 09:50 PST
</i><PRE>
Random-Quote: The race is not always to the swift, nor the battle to the strong
              -- but that's the way to bet.      (DAMON RUNYON)

Recently, an increasing number of pharmacies have been putting greater
amounts of drug information "on line".  As I understand it, they will keep
track of all of a particular customer's prescriptions, and will alert the
pharmacist if they should be asked to fill a prescription that conflicts
with any other medication that the customer is taking.  The rationale is, I
believe, that if a person is receiving prescriptions from two different
doctors (different specialists, perhaps), then neither of the doctors would
necessarily be aware of the drugs that the other had prescribed, or of any
possible unfortunate interactions between the drugs.  Normally, I assume
that the pharmacist would inform the consumer and contact the prescribing
doctor for further instructions.

Several concerns come to mind:

-  Where is the database of drug conflicts derived from?  Manufacturers'
   data files?  FDA reports?  Articles in recent medical journals?  Just
   how complete is it?

-  Does the database cover only drug-to-drug interactions, or is it more
   complete?  Might it, for example, contain counter-indication information
   for specific drugs (e.g., don't take this if you're pregnant)?  How about
   reports of unusual symptoms or side effects?

-  How "intelligent" (sorry!) is the logic that compares a new prescription
   with a person's medical/drug history?  Is there any AI/expert-system
   capability, or is it simply a look-up-a-list-of-conflicts?  Might the
   code be capable of, for example, warning a person who's receiving
   medication for asthma not to take doses of a specific brand of antibiotic
   because that particular brand is preserved with a sulphite compound that
   has been reported to trigger asthma attacks in sensitive individuals?

-  If a pharmacy advertises their new drug-checking software (and some do
   mention it in their ads), are they assuming any degree of responsibility
   or liability for either (a) false "conflict exists" warnings that cause
   a consumer not to take a necessary drug prescribed for them, or (b)
   any failure to alert a customer to a conflict that does exist?

-  Will doctors, pharmacists, and/or consumers begin to depend on the
   correct functioning systems such as this, at the expense of studying
   the issues involved themselves?

This particular issue is similar to the one discussed several issues back,
concerning AI/KE/expert-system tools such as MYCIN that "diagnose"
illnesses from symptoms or "suggest" treatments.  However, this system
is one step further away from the doctor and closer to the consumer;
there might be a greater tendency for people to "take it at its word"
rather than simply using it as a tool.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
SDI: Danny Cohen and Eastport Group comments
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
11 Dec 1985 1340-PST (Wednesday)
</i><PRE>
              [Forwarded With Permission from Gary Chapman]

Date: Tue, 10 Dec 85 16:14:34 pst
From: Gary Chapman &lt;PARC-CSLI!chapman@SU-Glacier.ARPA&gt;
Subject: Danny Cohen and Eastport group report

COHEN SAYS SDI CRITICS ARE "STAGNANT SUBCULTURE"

Danny Cohen, chairman of the so-called "Eastport group," told the Senate
Armed Services Subcommittee on Strategic and Theater Nuclear Weapons that
the discipline of software engineering is "an institutionalized and stagnant
subculture."  He said that Dave Parnas' criticisms were misrepresenting the
facts by claiming that there are "scientific arguments" and "fundamental
mathematical" obstacles that lead to the conclusion that reliable BM/C3
software cannot be built.

However, Cohen said in his testimony that the so-called "horserace"
architecture studies have only paid "lip service" to potential battle
management problems, and he criticized these studies harshly.

Cohen said that software engineers have a fetish with mathematical
correctness, and that they "try to mimic mathematics at any cost, even if it
means sacrificing functionality and relevance.  This sect grossly overrates
the perfection of Swiss clockwork, and strives to achieve it."  Cohen said
that the SDI should look to the telephone system as a model of a large
system that works well with distributed, autonomous components.  He said,
"The communications approach copes with imperfections and corrects for them,
rather than attempting to achieve an unattainable perfection."

Apparently the example of the telephone system is also featured in the first
chapter of the Eastport group's report to the SDIO.  A December 1 draft of
the report was obtained by the editors of Military Space, and reviewed in
the December 9 issue.  The report's conclusions are summarized in the
observation that computing resources and battle management software "are
within the capabilities of the hardware and software technologies that could
be developed within the next several years...with the tradeoffs necessary to
make the software tractable in the system architecture."

The panel criticized the ten Phase 1 system architecture contractors for
downplaying the problems of battle management software.  The panel
apparently recommends that the SDIO conduct a broader system architecture
study, with an eye toward an "unconventional architecture whose program is
within the anticipated limits of software engineering, without overreliance
on radical software development approaches."

The panel rejects the "tight coordination" implied in the Fletcher
Commission report of 1984.  The panel recommends a loose coordination, with
"robustness, simplicity and the ability to infer the performance of small
parts of the system.  Otherwise, the U.S. could not test a full-scale
deployment short of actual use."

The panel also says in the report that "innovative approaches" are necessary
for managing the software development of the SDI.  The panel report
recommends an independent research and technical support organization to
supervise the program, and a high-speed communications network to support
SDI contractors.

Cohen also told the editors of Military Space that he believes differences
in opinion about the SDI within the computer science community come from
different conceptualizations about the problem.  Cohen said, "Critics like
Parnas take the approach they're traditionally familiar with as software
engineers--a 'waterfall' or 'top-down' approach.  They look at battle
management software as one single, gigantic 'bounded' problem requiring
all-new software--instead of seeing it as a dynamic federation of many
different networks and nodes, much of which may already be out there now.

"The implication of viewing battle management as a federated network--rather
than as a monolithic, rigidly centralized process prone to single-point
software collapse and "Trojan horses'--comes down to this:  the issue is not
software, it's *protocols* between many different networks.  It's
inter-computer or inter-network communications--not single-system software."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Worms, etc.
</A>
</H3>
<address>
"Keith F. Lynch" 
&lt;<A HREF="mailto:KFL@MIT-MC.ARPA">
KFL@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Tue, 10 Dec 85 01:10:21 EST
</i><PRE>
To: MDAY@MIT-XX.ARPA
cc: RISKS@SRI-CSL.ARPA

    From: Mark S. Day &lt;MDAY@MIT-XX.ARPA&gt;

    The "solitary programmer" mentality is at least partly to blame for
    things like "unauthorized worms" -- if people expect to have their
    code read by others, who may question the reasons for doing certain
    things, it becomes enormously harder to conceal unauthorized features
    (unless the programmer can convince the inspector(s) to join in a
    conspiracy).

  I disagree.  How does one guarantee that the source code shown is in
fact what was compiled?

    I have little or no sympathy for people who illegally copy a program
    and then find one day that it's trashed their data.  Serves 'em right.

  Does the punishment fit the crime?  What if it was some employee who
illegally copied the program, which then destroys irreplacable company
data?  How certain is it that this 'protection' scheme will not go off
by accident?  If it does, who is liable?  Can the company which uses
it simply disclaim all liability?

    From:           Aaron M. Ellison  &lt;BI467000%BROWNVM.BITNET@WISCVM.ARPA&gt;

    Regarding Neal Macklin's "expose" of virus technology, I would only
    add that the idea is not at all new. John Brunner, a well-known
    speculative fiction writer, wrote a novel called "Shockwave Rider"
    over 10 years ago(!) predicting the blackmailing of a then corrupt
    U.S. government by a morally-upright computer hacker. ...

  The idea is older than that.  I don't have any references, but I
recall reading about 'computer viruses' before 1970.
								...Keith

</PRE>
<HR><H3><A NAME="subj3.2">
`Gary North's Remnant Review' (Worms, etc.)
</A>
</H3>
<address>
Stavros Macrakis
&lt;<A HREF="mailto:macrakis@harvard.HARVARD.EDU ">
macrakis@harvard.HARVARD.EDU 
</A>&gt;
</address>
<i>
Tue, 10 Dec 85 18:04:07 EST
</i><PRE>

This overly-long message appears to say nothing new.  We are treated to some
sort of breathless and misinformed paranoia about `anti-Zionists', Soviets,
and foreigners in general, not to mention hackers.  We get thriller-novel
political scenarios with countless pointless (and hardly verisimilitudinous)
details.  (See below for a textual analysis of North's tract.)

We all know that computer security is hard.  We know that banks and other
important institutions have often failed to apply even the most elementary
security precautions.  We even know about `trapdoors', `worms', and
`viruses' (which were discussed during the design of Multics, if not
earlier).  We also know that both technical people and users of computers
must become more aware of security issues.

What does North contribute?:  a vision of a horrible secret hidden from the
public by frightened bankers whose livelihood depends on hoodwinking the
public into believing that paper money and bank deposits have value -- a
secret which will be taken advantage of by Godless Communists, dark-skinned
terrorists, and evil foreigners in general.

Does North's article tell us something about public attitudes towards
computers?  No, I don't think so.  It's just the standard apocalyptic,
conspiratorial vision applied to computers.

	-s

Paranoia about the news media:
  I am going public with this story because it is unlikely that any
  conventional news source will touch it, unless pressure is brought
  to bear.  The reason is this: the problems are too horrendous even
  to be discussed by appropriate officials, unless they have specific
  answers.  But they don't.  What I present here cannot be smoothed
  over by a press release abount having set up a blue-ribbon study panel.

Stumbling into a terrible secret:
  I literally stumbled into this information.  I had read about one
  tiny aspect of it.  I made a few extrapolations.  Then I got
  worried.  The problem looked as though it would have major
  implications.  Little did I know!

Blatant racism and xenophobia:
  Everyone knows [computer genius types] are either orientals,
  dark-skinned people with accents, or teenagers.  The firms don't
  hire teenagers, but they hire a lot foreigners.

Fortune-telling by `authorities':
  "The great fortunes of the 21st century," [Adam] Osborne predicts,
  "will be the legacies of the great computer thieves of the 20th."

A major source whose qualifications are:
  ... a former businessman, quite young, and a true "space cadet."
  ... a nice fellow, a Christian, and a moral philosopher of sorts.

Phobia of paper money:
  the various banking regulatory agencies would be swamped with crises
  and outside rumors.  Then, all at once, bank computers begin
  breaking down....  The lines appear in front of banks.  The only
  answer at this point is to print up paper money.  It would be
  printed by the hundreds of billions in order to offset the
  deflationary effects of bank runs....

Gold-bug-ism:
  All of a  sudden, market-created alternative  currencies would be
  revived.  It would  the  be  METALLIC  CASH  that  talks  loudest.
  Silver  dimes  are  not electronic.  They can't be infected
  electronically.  They still circulate  when banks are "temporarily
  closed, due to circumstance beyond our control." 

Misunderstanding of the nature of banks: (ALL banks are `fractional reserve')
  ... the bankers are desperatesly fearful of this sort of vandalism.
  It could topple people's confidence in the fractional reserve
  banking system, and confidence is the only thing which keeps it
  going.

He concludes with an apocalyptic vision:
  Maybe later; not now.  Keep precious metal coins.  Don't
  assume that it an't happen here.  It can.  The only thing holding it
  back is the restraining hand of God, through the temporary
  self-restraint of a technological priesthood.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
a few more words on password guessing
</A>
</H3>
<address>
King Ables
&lt;<A HREF="mailto:ables%mcc-pp@mcc.arpa ">
ables%mcc-pp@mcc.arpa 
</A>&gt;
</address>
<i>
Mon, 9 Dec 85 20:53:51 cst
</i><PRE>

I hate to add to the "slippage" of the Risks forum into one of
security issues, but I feel strongly that a couple of points have
not been made that need to be.  I've had experiences on BOTH sides
of this fence...

You can't keep people from getting user names (as pointed out with
Unix and other systems with mail headers and output thrown in the
trash).  So we have to protect the passwords (that's why we call
them PASSwords).

I've seen people get passwords out of trash cans from Decwriters
and teletypes (although this doesn't happen much anymore due to smarter
login programs that black out the paper).  As pointed out, it's real
easy to guess if you use your name, initials, or words from a 
dictionary, etc.  However, even if you use nonsensical anacronyms
(nonsensical to anyone else, that is), this doesn't make it "unguessable."
In fact, I don't accept the statement that unguessable passwords exist.
It depends on who's doing the guessing.  Passwords that are unguessable
in a certain amount of time, I'll buy.  The guy trying to steal your bike
trying different combinations has a finite amount of time he can work
before someone sees him and becomes suspicious.  If he were invisible,
he could sit there indefinitely (at least until you came and moved it)
and try combinations.  His chances of success that way would be MUCH
greater.  Somebody with a home computer on a phone line to your machine is
fairly invisible to you (unless you have certain other mechanisms in
place to watch out for this sort of thing).  An old favorite computer
system of my early days used to have 3 letter passwords composed of
letters (upper case only) or digits.  36**3 possibilities.  At 5
seconds per try (a conservative estimate since there was no automatic
delay for wrong passwords), it would take a password guessing program
less than 65 hours (about 2.7 days) to try EVERY password in
the system.  OK, I'll admit things are better these days, longer passwords,
more possible characters, delays during login attempts, etc.  BUT, the
point is that someone who wants to remain invisible and is very patient
may very well break ANY password.  Passwords alone are insufficient.
You HAVE to have some other mechanisms to slow down what a password
guesser will be doing and hopefully some mechanism for spotting what's
happening and reporting it to someone before things progress very far.

Get one of those 3-digit combination bike locks and lock a $500 bike
in a secluded area for a week and see if it's still there when you come
back ('course, they'd probably just cut the lock off in that case, but
you see my point).

-King
(ables@mcc.ARPA)

</PRE>
<HR><H3><A NAME="subj4.2">
quick comment on passwords
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@purdue-ecn.ARPA ">
davy@purdue-ecn.ARPA 
</A>&gt;
</address>
<i>
Mon, 9 Dec 85 22:02:48 EST
</i><PRE>

Re: the thought that no password systems can be broken into...

As part of beefing up the passwd(1) program on our local UNIX systems, I
wrote a simple program which tries 12 passwords per account (stuff like
login name, first name, last name, using forwards, backwards, and
variations in case).

Anyway, I ran this program overnight (ran for about 6 hours on a
maxxed-out Gould PN9080) on 15,832 accounts and picked up 169 accounts.
That's 1% of the user population.  Not bad for an evening's work.  This
was the second time we ever ran this, the first time we got about 400
from a list of 10,000 (4%).  Those people were informed they should
change their passwords; most did.  This group of 169 has shown up in the
last 12 months.  Most of the passwords were either the person's first
name or his login name, all lower case, forwards or backwards.

Now, if I can write something as trivial as this program (it's only about
250 lines long) in an hour, imagine what some "cracker" (I refuse to use
the term "hacker" to describe these jerks) could do with a weekend and
some real creativity.  My guess is that by adding some more fairly
simplistic guesses and using a few evenings of processor time I could
probably pick up at least 1500 accounts (that's 10% of our entire user
population, folks).  At the rate of over a hundred accounts per evening,
it certainly wouldn't take too long.

Care to rephrase the "what, me worry?" statement?

--Dave Curry
Purdue Engineering Computer Network

P.S. - We aren't using the beefed up password program anymore, but anyone
who wants the code is welcome to it.  It prevents using login, first,
last names in the above permutations as well as disallowing dictionary
words, license plate and phone numbers, and optionally any word having the
characteristics of an English word.  If you want it, use anonymous ftp
and grab it from ee.purdue.edu in "pub/password.ar".  Look at the
password.c source before installing it though -- ours is probably
different than yours (it uses the 4.3BSD ndbm(3) password file databases,
as well as a local gecos field format).

</PRE>
<HR><H3><A NAME="subj4.3">
Passwords.
</A>
</H3>
<address>
&lt;<A HREF="mailto:Dan_Bower%RPI-MTS.Mailnet@MIT-MULTICS.ARPA">
Dan_Bower%RPI-MTS.Mailnet@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Thu, 12 Dec 85 03:09:00 EST
</i><PRE>

Many cases of 'guessed' passwords are when someone looks over your shoulder
as you type.  Hunt and peck typists are especially prone to this.  Also, one
version (or is it many versions?) of PR1MOS requires passwords to be keyed
in directly after the account code AS CONTROL CHARACTERS.  (I.e., you type
in your account, then hold down the control key and type your password.)
This forces you to hunt and peck.  Anyhow, keep in mind that it is NOT
impolite to ask someone to turn away as you log in on a terminal.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-39</DOCNO>
<DOCOLDNO>IA012-000128-B043-116</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.30.html 128.240.150.127 19970217001017 text/html 13902
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:08:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 30</TITLE>
<LINK REL="Prev" HREF="/Risks/1.29.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.31.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 30</H1>
<H2> Monday, 16 Dec 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Request for Cases, Settled or Decided 
</A>
<DD>
<A HREF="#subj1.1">
George S. Cole
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
 Risks of job displacement from computerization 
</A>
<DD>
<A HREF="#subj2.1">
Fred Hapgood
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
 Risks re computer-compared prescriptions 
</A>
<DD>
<A HREF="#subj3.1">
Richard Lamson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
 Legal bootlegs [a case against worms] 
</A>
<DD>
<A HREF="#subj4.1">
K.Richard Magill
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
 Passwords 
</A>
<DD>
<A HREF="#subj5.1">
ircam
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
 Verifying source code vs. executable code 
</A>
<DD>
<A HREF="#subj6.1">
Martin J. Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
 Seminar - SDI Debate (SU) 
</A>
<DD>
<A HREF="#subj7.1">
Joan Feigenbaum
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Request for Cases, Settled or Decided
</A>
</H3>
<address>
&lt;<A HREF="mailto:cole.pa@Xerox.ARPA">
cole.pa@Xerox.ARPA
</A>&gt;
</address>
<i>
14 Dec 85 09:04 PST
</i><PRE>


	There has been little legal analysis concerning the "computer
revolution"; partly because there have been few cases that have been
decided by the appellate courts. 
	I have started researching this area and would appreciate very much any
pointers to cases -- threatened, settled, decided by trial and not
appealed, or appealed -- that involve questions of:
	(1) liability for unsuspected "bugs";
	(2) liability for program design flaws;
	(3) liability for disgruntled programmers taking "revenge" upon their
corporation at the expense of the customers; or,
	(4) liability for harm (personal or economic) caused by a human making
computer-aided decisions. This could be anything from a medical decision
using MYCIN, PUFF, ONCOCIN et. al. to an automobile designer using
CAD/CAM.

	I am not looking for situations where the vendor/programmer promised
what he knew he could not deliver, outright fraud, or contractual
disputes about the value delivered; I am trying to find situations where
fault lay in the human-computer interaction. 

	There are a number of possible legal theories that may apply to the
present range of problems; I also am examining theories that may apply
as more "independant" and extensive AI applications, that involve less
computer-friendly users, become part of everyday life. Some of these
theories should extend to cover analagous situations; some will probably
not; the questions I am interested in are WHY and HOW any theory should
apply.

	Again, I would be very grateful for any information from any of you.
When this study is completed I will report that to this forum.

				George S. Cole, Esq.

N.B.: This task is part of the research project I am working on while
attending Stanford's C.S. Master's program, at Xerox PARC. I am a
licensed attorney (temporarily suspending practice to gain the Master's
Degree) and am extremely interested in attempts to combine the practices
in these two fields.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of job displacement from computerization
</A>
</H3>
<address>
"Fred Hapgood" 
&lt;<A HREF="mailto:SIDNEY.G.HAPGOOD%MIT-OZ@MIT-MC.ARPA">
SIDNEY.G.HAPGOOD%MIT-OZ@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Mon 16 Dec 85 07:24:18-EST
</i><PRE>
To: risks%MIT-OZ@MIT-MC.ARPA

	Is anybody keeping track on an on-going basis, of the job
categories being destroyed by the computer? A recent example is that
of "presentation photographer" -- who, at the minimum, shot pix
of graphs and graphics for presentations, and at the limit, 
designed and assembled those graphics. Not a big category, nor
one with a set of skills whose loss leaves civilization that much
poorer, but probably representative.

	Anyway, I would very much like to reach the technology-and-
society scholar (surely there must be one somewhere) who is
paying attention to this issue.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks re computer-compared prescriptions
</A>
</H3>
<address>
Richard Lamson 
&lt;<A HREF="mailto:rsl@RUSSIAN.SPA.Symbolics.COM">
rsl@RUSSIAN.SPA.Symbolics.COM
</A>&gt;
</address>
<i>
Fri, 13 Dec 85 15:26 PST
</i><PRE>

    Date: Tue, 10 Dec 85 09:50 PST
    From: Dave Platt &lt;Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA&gt;

    Recently, an increasing number of pharmacies have been putting greater
    amounts of drug information "on line".
[...]
    Several concerns come to mind:

    -  Where is the database of drug conflicts derived from?  Manufacturers'
       data files?  FDA reports?  Articles in recent medical journals?  Just
       how complete is it?

That's a very good question.  It turns out that the database on drug
interactions is very sparse, even for the simple case of two different
drugs.  There are a lot of common combinations which have never been
adequately tested.

    -  Does the database cover only drug-to-drug interactions, or is it more
       complete?  Might it, for example, contain counter-indication information
       for specific drugs (e.g., don't take this if you're pregnant)?  How 
       about reports of unusual symptoms or side effects?

Again, this database is also very sparse.  Many drugs these days carry
the warning that they haven't been tested in pregnant women, and
therefore the physician should think twice (or more) before prescribing
them to pregnant women (or those of "childbearing age", in many cases).
One of the reasons drugs have not been adequately tested during
pregnancy is that manufacturers are frightened of testing them in
pregnant women, and, in fact, many drugs are not tested in "childbearing
age" women at all, just in case they might be or become pregnant during
the study!

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
legal bootlegs (a case against worms)
</A>
</H3>
<address>
rich 
&lt;<A HREF="mailto:@CSNET-RELAY.ARPA,@case.CSNET:rich@rexago1.uucp">
@CSNET-RELAY.ARPA,@case.CSNET:rich@rexago1.uucp
</A>&gt;
</address>
<i>
Fri, 13 Dec 85 11:04:08 est
</i><PRE>

As I understand the paper work that comes with most micro software
packages (big machine software is a different arena) what I buy is
not a program but a right to use a given program.  The mode of
transmission is generally not specified.  It could be my original
distribution diskette, telephone, or a friend's legitimate copy.

If I scramble my original and then copy his,  what have I done
illegal?  If I see a worm, you can bet my lawyer will hear about it.

K. Richard Magill

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Passwords
</A>
</H3>
<address>
mf
&lt;<A HREF="mailto:ircam!mf@seismo.CSS.GOV ">
ircam!mf@seismo.CSS.GOV 
</A>&gt;
</address>
<i>
Mon, 16 Dec 85 11:07:26 -0100
</i><PRE>

If you leave a $500-bike locked and unattended for a week (as one of the
readers put it) it is likely not to be there when you return, but not because
a thief would have had the patience to try all combinations: he probably would
wait for a quiet moment and break the lock or cut the chain.

And so it is with passwords: trying all possible combinations is theoretically
feasible, but not very practical.  A very simple method (and here the analogy
with bikes stops) -- described for Unix but easily transportable -- is to run
a [c]shell command file that fakes the login procedure, i.e., prints the login
msg on a terminal, asking for the account and password (in no echo mode), and
then printing "login incorrect" and exiting (after having recorded the
password).

An unsuspecting user will think he mistyped his password and will try again.
How does one protect against such booby traps?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
verifying source code vs. executable code
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT     [SIC!]
</i><PRE>

Re: Keith Lynch's question about knowing that the source code matches the
executable, here is something simple that we did to support configuration
control and to guard against EPROM decay when I worked at Cape Canaveral:

Whenever one of our programs was compiled and an executable file was
generated, we ran a program to checksum the executable file (just a simple
addition, but you could get much fancier with CRC if you wanted).  This
checksum was programmed into a fixed location in the EPROM.  All of the
programs contained code that, when the program was initialized, would
run the same procedure on the program itself, compare the computed result
to the stored result, and halt with an error message if there was a
difference.  Whenever a new program was installed, the stored checksum
was recorded with the configuration control data, and the customer
occasionally pulled surprise audits to make sure that the correct set of
EPROMS was in use; they would come in, look at the stored checksum in
the EPROM, and compare it to the recorded information.  Since we had
seven different instrumentation sites, each with slightly different
configurations, and usually two or three versions of the program floating
around, keeping track of the EPROM sets was a headache -- until we
adopted this scheme, which worked beautifully.

If anyone wants specific details of the code (the processors were LSI-11s)
I will be happy to send them to you.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Seminar - SDI Debate (SU)
</A>
</H3>
<address>
Joan Feigenbaum 
&lt;<A HREF="mailto:JF@SU-SUSHI.ARPA">
JF@SU-SUSHI.ARPA
</A>&gt;
</address>
<i>
Fri 13 Dec 85 17:56:01-PST
</i><PRE>

                ``SDI: How Feasible, How Useful, How Robust?''

This will be a technical debate, covering both hardware and software aspects
of SDI.

Sponsor: Stanford Computer Science Department
Date: December 19, 1985
Time: 8:00 p.m.
Place: Terman Auditorium
Organizer: Barbara Simons, IBM-SJ

Moderator:  Dr. Marvin L. Goldberger, President of Cal Tech.
Former member of President's Science Advisory Committee
and Consultant on Arms Control and International Security.

Panelists:

Advocates:
Professor Richard Lipton, Professor of Computer Science at Princeton
University, Current member of SDIO's Panel on Computing and Support of Battle
Management.

Major Simon Peter Warden, the Special Assistant to the Director of the SDIO
and Technical Advisor to the Nuclear and Space Arms Talk with the USSR
in Geneva.

Opponents:
Dr. Richard L. Garwin, IBM Fellow and Adjunct Professor of Physics at
Columbia University, Physicist and Defense Consultant.

Professor David Parnas, Lansdown Professor of Computer Science at the
University of Victoria, Former member of the SDI Organization's
Panel on Computing and Support of Battle Management.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-40</DOCNO>
<DOCOLDNO>IA012-000128-B043-138</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.31.html 128.240.150.127 19970217001030 text/html 18058
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:08:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 31</TITLE>
<LINK REL="Prev" HREF="/Risks/1.30.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.32.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 31</H1>
<H2> Thursday, 19 Dec 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Enough on passwords? Pharmacy systems 
</A>
<DD>
<A HREF="#subj1.1">
Elizabeth Willey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks re computer-compared prescriptions 
</A>
<DD>
<A HREF="#subj2.1">
Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Oops 
</A>
<DD>
<A HREF="#subj3.1">
Marty Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  $32 Billion Overdraft Resulted From Snafu 
</A>
<DD>
<A HREF="#subj4.1">
Washington Post
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Enough on passwords? Pharmacy systems
</A>
</H3>
<address>
"Elizabeth Willey" 
&lt;<A HREF="mailto:ELIZABETH%MIT-OZ@MIT-MC.ARPA">
ELIZABETH%MIT-OZ@MIT-MC.ARPA
</A>&gt;
</address>
<i>
Mon 16 Dec 85 18:00:52-EST
</i><PRE>
To: risks@SRI-CSL.ARPA

Could that discussion [on passwords] go over to SECURITY@RUTGERS (mail to
SECURITY-REQUEST@RUTGERS to join)?  Passwords have been discussed there
before.  
        [It could.  We have made the point that passwords are frequently
         misused.  But everyone has an opinion on them, so it is only
         natural that there are lots of contributions on that subject!  
         Actually, I rejected two messages on the subject for this issue,
         both of which would have required me to add caveats on the 
         soundness of those messages.  But there are still risks in relying 
         on passwords that are worth including here.  PGN]

About the pharmacy systems:  people are essentially lazy.  They will
certainly become dependent on a computer program that tells them conflicts
and stop noticing the conflicts themselves! Unless you formatted the program
as a teacher, too: PHARMACIST, TWO OF THIS PATIENT'S CURRENTLY PRESCRIBED
MEDICATIONS WILL REACT BADLY WITH THE NEW PRESCRIPTION.  CAN YOU TELL ME
WHICH ONES?

         ["Sorry.  I did not know the answer, but I did not want to admit it
          &lt;because I understand that some crusader like Ralph Nader has
          Trojan-horsed your program and is surveying how many pharmacists
          don't know the answers&gt;.  Unfortunately, the patient died
          yesterday of side-effects."  (Prototypical pharmacist's reply) PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Re:  Risks re computer-compared prescriptions
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Mon, 16 Dec 85 20:52:56 EST
</i><PRE>

Risks of putting prescriptions "on-line" must be compared to the risks
of NOT putting them on-line;i.e., to the risks of doing things as they
now are done.  It is tempting to compare them to the risks of doing
things as we wish they were done, but this is unrealistic.

Now let's consider Dave Platt's well-founded concerns, keeping in mind
that it is ALREADY the responsibility of the pharmacist to protect the
patient/consumer from harmful drug interactions and the like:

	The database of drug conflicts comes from wherever it now comes
from.  Package inserts (or the PDR) contain some of this information;
this is mandated by law.  Even if the automated database is less
complete than the present human-maintained database, an automated system
is much more likely to consult every relevant item.  A human can forget!

	Information beyond drug-drug interactions should be included if this
is within the responsibility of the pharmacist.  Otherwise, it should not be
unless the medical and pharmaceutical professions consciously decide
otherwise.  Programmers should not redefine the practice of the professions
of others.

	Clearly, the first step is a non-intelligent database system.
The example of an asthmatic taking another med containing sulphites
should be covered by the database on medicine-medicine interactions.

	Regarding degrees of responsibility, if the sources of
information in the database are the same as at present, and if the
pharmacist is using the database as a "decision aid," then I don't see
how anyone's responsibility has been changed by a change in
recordkeeping systems.

&gt;	-  Will doctors, pharmacists, and/or consumers begin to depend
&gt; on the correct functioning systems such as this, at the expense of
&gt; studying the issues involved themselves?
	
	My problem with this question is that it assumes that doctors,
pharmacists, and consumers presently study the issues involved.  To the
extent that an automated system provides a professional with free time,
it will enable him/her to spend more time studying.  But an automated
system is not necessarily good or bad for anyone's habits!

	Sure!  People may come to rely on an automated Physician's Desk
Reference (tm), but many people take their pharmacist's word as gospel
right now.  And too many pharmacists spend so much time as business
managers selling cosmetics, stationary, motor oil, jewelry, books, and
flowers that their "expertise" is anything but.  At least a
well-functioning database doesn't "forget" what it has learned.

Brint

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Oops!
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

[I have abridged Marty's message.  He pointed out that I did not complete
the editing of <A HREF="/Risks/1.30.html">RISKS-1.30</A>, leaving the banner line as
    RISKS-LIST: RISKS-FORUM Digest  Thursday, 13 Dec 1985  Volume 1 : Issue 29
instead of 
    RISKS-LIST: RISKS-FORUM Digest  Monday, 16 Dec 1985  Volume 1 : Issue 30
He also noted that "the table of contents seems to be rather skimpy this
issue."  (I left it out.)  "I guess even RISKS is not immune to glitches!"
(But it was a HUMAN error, not a computer-related error!)  On the
other hand, nobody complained that Friday the 13th fell on Thursday in
<A HREF="/Risks/1.29.html">RISKS-1.29</A>, for those of you who remember Pogo.  PGN]

   [By the way, William Daul reported getting as many as 10 copies of
    <A HREF="/Risks/1.29.html">RISKS-1.29</A>.  Another forum to which I belong recently had an issue where
    the system crashed repeatedly during mailing, and some users got as many
    as six copies, others getting none.  I hope there is a way for the
    network people to fix this problem.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
$32 Billion Overdraft
</A>
</H3>
<address>
Al Friend
&lt;<A HREF="mailto:friend@nrl-csr ">
friend@nrl-csr 
</A>&gt;
</address>
<i>
Wed, 18 Dec 85 15:47:45 est
</i><PRE>

From: Al Friend - SPAWAR
To: Risks Forum

  Here is an interesting article out of the Washington Post.  It seems that 
there is a very real potential for financial disaster lurking in the 
electronic banking jungle:

[Washington Post, 13 December 1985, p. D7]

Computer Snarled N.Y. Bank
--------------------------
$32 Billion Overdraft Resulted From Snafu
-----------------------------------------
By John M. Berry, Washington Post Staff Writer
----------------------------------------------

  The Bank of New York, the nation's 18th largest, had a brief $32 billion 
overdraft on its cash account at the New York Federal Reserve Bank when a 
computer failure last month snarled thousands of government securities 
transactions, a congressional committee was told yesterday.
  By the end of the day, the overdraft had been reduced to $24 billion, and 
the bank actually had to borrow that amount from the New York Fed -- pledging 
all of its assets -- in order to balance its accounts overnight. 
  Aside from the unprecedented scale of the borrowing, and the spillover 
effects on the government securities market, the incident intensified concern 
at the Federal Reserve over the vulnerability of the nation's financial 
payments system to a technological glitch that could have disastrous 
consequences.
  Federal Reserve Chairman Paul A. Volcker and New York Fed President 
E. Gerald Corrigan went before a House Banking subcommittee yesterday to 
describe how the computer failure occurred and how the Fed and the bank 
dealt with the crisis it caused. 
  On Wednesday, Nov. 20, transactions involving more than 32,000 different 
government securities issues poured into the Bank of New York, one of the 
largest processors of such deals on behalf of others.
  The bank's computer system was supposed to be able to cope with up to 
36,000 issues, but a programming glitch developed and, unknown to anyone,
the computer began to "corrupt" the transactions and make it impossible 
for the bank to keep them straight.
  Because of the computer system breakdown, the bank could not instruct 
New York Fed where to send the securities arriving at the Fed on behalf of 
the bank's clients, and therefore could not get paid for them.  The New 
York Fed was automatically taking money out of the Bank of New York's cash 
account to pay the sellers for the incoming securities, all of which are 
represented simply by computer records, rather than the familiar paper 
bonds still used by most corporations. 
  By Thursday evening, as hundreds of employes at a host of banks and 
government securities dealers tried to sort out the problems caused by the 
failure of the intricate and largely automatic network handling these 
transactions, the bank had a $32 billion overdraft on its cash account at the 
New York Federal Reserve Bank. 
  The bank's computer specialists finally came up with a "patch" for its 
 computer program -- a process described yesterday by its chairman, 
J. Carter Bacot, as the electronic equivalent of patching a tire -- that 
allowed it to begin to clear some of the backlog.  But just after midnight, 
the patch failed too, after the overdraft had been whittled down to about 
$24 billion. 
  The Fed kept both its nationwide wires for securities and cash transactions 
open in the early hours of Friday morning.  When the patch failed, the Bank 
of New York was still able to borrow $700 million from other banks.  The rest 
was covered by a $23.6 billion loan from the New York Fed.  As collateral, 
the bank pledged all its domestic assets and all its customers' securities 
it was allowed to use for such purposes.  Altogether, the collateral was 
worth #36 billion, according to the Fed.
  The drama was not over.  Around 5 a.m. Friday, the bank finally completed 
reconstruction of its customers' transactions from Wednesday.  By 10 a.m., 
it had done the same for the Thursday deals.  But, meanwhile, the rest of the 
government securities industry had begun its Friday activities, and securities 
and an overdraft were piling up again in the Bank of New York's account at the 
New York Fed. 
  "Faced with this situation," New York Fed President Corrigan told the 
banking subcommittee, "at about 11:30 a.m., we temporarily stopped accepting 
securities transfers for the account of Bank of New York in an attempt to 
stabilize the situation somewhat and to see whether it was practical to 
prevent further increases in the overdraft without causing excessive 
disruption in the market more generally. . . . 
  "Operationally, this meant that holders of government securities who had 
contracts to deliver those securities . . . to the Bank of New York for
one of its customers [in return for payment] were temporarily unable to make 
delivery under those contracts," Corrigan said. 
  The stoppage lasted only for about 90 minutes that afternoon, and news of it 
did not spread widely for nearly an hour.  Yet that disruption at the clearing 
bank was enough, Corrigan said, to make some market participants unwilling to 
trade securities among themselves.  "Perhaps most importantly, there was also 
some evidence that investors were beginning to seek to break trades and 
financing transactions with dealers serviced by the Bank of New York." 
  Shortly after noon, the Bank of New York was able to begin handling the 
Friday transactions that had been piling up, and the Fed was again able to 
accept securities destined for the bank.  By that point the bank was operating 
with a computer system that had undergone a major overhaul in less than 24 
hours.
  The crisis was over, but its final bill is still mounting. 
  The Bank of New York was out of pocket about $5 million, an amount equal to 
about 7 percent of its earnings in the first nine months of this year, to pay 
interest on the money it had to borrow that Thursday.
  It is still negotiating with many of the parties who may have sustained 
losses in transactions that were not completed on time.  Such negotiations are 
common, said an official of one major securities dealer, because a few 
transactions are always going awry.  This time it was thousands. 
  Some customers walked away in better shape.  "Indeed, those individuals and 
intistutions who bought securities in question received a windfall in that 
they received interest for a day [on the securities], but did not incur any 
cost of financing," Corrigan noted. 
  But any loss or gain in dollars, even with millions of dollars at stake, is 
not the real issue.  What worries both Federal Reserve officials and 
participants in the government securities market is the potential for a 
failure of the system. 
  On the average day, about $200 billion worth of government securities 
transactions take place involving about 27,000 separate transactions, Corrigan 
said.  Some days the totals are far larger. 
  "Like it or not," Volcker told the subcommittee, "computers and their 
software systems -- with the possibility of mechanical or human failure -- 
are an integral part of the payments mechanism.  The scale and speed of 
transactions permit no other approach. 
  "In the last analysis, no mechanical system can be entirely 'fail-safe' 
and also be commercially viable," he said.  "The costs would simply be too 
high, and the money and Treasury securities markets could not operate at the 
present level of efficiency."
  The Fed chairman pointed out that, in this case, the Fed was available to 
lend the $23.6 billion, on good collateral. "The effects in this instance 
were of unprecedented magnitude, measured by the amount of the overnight 
loan," he said.  "But the effects in terms of market performance and risk 
were well contained. . . .  I believe it would be wrong to overdramatize this 
incident."
  Corrigan in his more detailed testimony sounded more notes of concern.  "I 
believe our actions were prudent, disciplined and appropriate.  In saying 
this, I should also confess that in some respects we were a bit lucky," he 
said.
  Part of the luck was that the bank was able to get its computer going again 
as soon as it did.  Another part, Corrigan said, was that Thursday was not an 
especially heavy day for securities transactions. 
  One government securities trader summed up the situation this way. 
  "We're all afraid something will go bump and send the market into a tailspin. 
. . .  The Fed is working night and day to figure out what it can do.  The 
banks are working night and day.  But the amount of [trading] in financial 
markets is so large that we feel this is the No. 1 financial problem of the 
next few months.  Banks have to be able to make settlements with each other." 


</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-41</DOCNO>
<DOCOLDNO>IA012-000128-B043-156</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.32.html 128.240.150.127 19970217001048 text/html 13889
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:09:11 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 32</TITLE>
<LINK REL="Prev" HREF="/Risks/1.31.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.33.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 32</H1>
<H2> Monday, 23 Dec 1985 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Can Bank of New York Bank on Star Wars? 
</A>
<DD>
<A HREF="#subj1.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Cohen's AT&amp;T SDI Software Analogy 
</A>
<DD>
<A HREF="#subj2.1">
Richard A. Cowan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Failure probabilities in decision chains 
</A>
<DD>
<A HREF="#subj3.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Ten-year any-worseries 
</A>
<DD>
<A HREF="#subj4.1">
Dan Hoey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Multiple digests as a result of crashed systems 
</A>
<DD>
<A HREF="#subj5.1">
Rob Austein
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Can Bank of New York Bank on Star Wars? [PGN's retitling]
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
20 Dec 1985 1413-PST (Friday)
</i><PRE>

Read <A HREF="/Risks/1.31.html">RISKS-1.31</A> only this morning. Found the detailed story on the Bank
of New York fiasco extremely ironic. Last night in the debate at Stanford
on the technical feasibility of the SDI, Richard Lipton chose the
financial network as an example of the advantages of a distributed
system (such as he is proposing for SDI) over a centralized one. "There
have been no catastrophes."  [What about the ARPANET collapse?  PGN]

More generally, I am interested in reactions to Lipton's proposal that
SDI reliability would be improved by having hundreds or thousands of
"independent" orbiting "battle groups," with no communication between
separate groups (to prevent failures from propagating), and separately
designed and implemented hardware and software for each group (to
prevent common design flaws from affecting multiple groups). He said
that the SDIO/PCSBM panel had concluded that the integrated Battle
Management and Command, Communcation, and Control (C3) software called
for in the Fletcher Report could never be made trustworthy, but that a
"meta-system" of simple, non-communicating components might be.

Jim H.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Cohen's AT&amp;T SDI Software Analogy 
</A>
</H3>
<address>
Richard A. Cowan 
&lt;<A HREF="mailto:COWAN@XX.LCS.MIT.EDU">
COWAN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu 19 Dec 85 19:04:45-EST
</i><PRE>
To: risks@SRI-CSL.ARPA

As pointed out at the SDI economic debate at MIT 11/19, all the other
computer software systems (and predictions of technological failure
that have proven wrong) were problems of man against nature.  SDI
software, as Parnas also pointed out, is a problem of man against man.

All historical analogies to SDI that involve successes in
technological problems of man against nature are therefore worthless.
If it were in the Soviet Union's vital interest to wreck the operation
of the phone system, and they were willing to spend a few billion a
year to do so, of course they could do it.  (Remember how the mass Transit
system in Tokyo was shut down by 50 terrorists a few weeks ago?)

By the way, the economic debate I referred to was quite interesting.
Panelists were Bernard O'Keefe, CEO of Nuclear weapons contractor
EG&amp;G, Lester Thurow, MIT economist, and Leo Steg, former manager of
GE's Space systems division.  O'Keefe's company does Star Wars
research, yet he ridiculed the Star Wars concept and pointed out the
economic dangers.  Thurow didn't give an opinion on Star Wars, but he
pointed out the problems of diversion of talent, the new competition
from other countries, and the fallacy of thinking that we can spend
the Soviet Union into the ground.  Steg was pro-technology, pro-SDI,
pro-spinoffs.  The Boston Globe had an article about it on the front
page of the Business Section, (11/21), but I felt the article was
shallow and biased.

If you'd like to judge for yourself, I have a TAPE of the discussion,
AND a TRANSCRIPT.  If interested, please contact me and I'll be happy
to send you one of these (but you'll have to pay what it costs).

-Rich  (cowan@mit-xx)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Failure probabilities in decision chains
</A>
</H3>
<address>
    Will Martin 
&lt;<A HREF="mailto:wmartin@BRL.ARPA">
wmartin@BRL.ARPA
</A>&gt;
</address>
<i>
Thu, 19 Dec 85 14:58:42 EST
</i><PRE>

One of our Directors has asked me to inquire about a reputed Bell labs
study from 7 or so years ago, which he heard about at a conference. This
study was on "failure probabilities"; one of the statements or
conclusions he recalls was that if you have a string of five sequential
decisions, one after the other, each based upon the preceeding, the
reliability of the result is at the 59% level. I don't really have much
other than this to go on, so, if this comment rings a bell with you, and
you know the study (or studies) that this sort of conclusion came out
of, I would greatly appreciate it if you could mail me a reference. If
you know of work being done in this area by other organizations or
particular researchers, any comments or rumors or hearsay or pointers to
published work or theses would be welcomed.

If any documents related to this area of research exist on-line and are
not proprietary, please feel free to mail me copies of anything you
think might be relevant. The context of this is to provide some sorts of
standards of comparison or generally-acceptable figures to use when
evaluating the quality of a very complex and involved large software
system.

Please e-mail responses to one of the addresses below. Thank you.

Will Martin
US Army Materiel Command Automated Logistics Mgmt Systems Activity

UUCP/USENET: seismo!brl-bmd!wmartin   or   ARPA/MILNET: wmartin@almsa-1.ARPA

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Ten-year any-worseries [Plucked off the BBOARDS]
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
19-Dec-1985 2140
</i><PRE>
From: Hoey@NRL-AIC (Dan Hoey)

    hoey@NRL-AIC.ARPA 12/14/85 03:54:44 Re:  Software alert:  DATE-86
    Received: from nrl-aic by MIT-MC.ARPA 11 Dec 85 10:59:57 EST
    Date: 11 Dec 1985 09:55:47 EST (Wed)
    From: Dan Hoey &lt;hoey@nrl-aic.ARPA&gt;

    Early this year a message appeared on ARPANET-BBOARDS commemorating the
    ten-year anniversary of DATE-75.  A somewhat more ominous anniversary
    will occur in four weeks, on 9 January 1986.  Users of the TOPS-10
    operating system should beware of software failures beginning on that
    date.

    DATE-75 is the name of a set of program modifications applied to the
    TOPS-10 operating system, running on DEC PDP-10 computers.  Before the
    modifications, the TOPS-10 system could only represent dates between 1
    January 1964 and 4 January 1975.  The DATE-75 modifications added three
    more bits to the representation of dates, so that dates up to 1
    February 2052 could be represented.  To maximize compatibility with
    existing software, the three extra bits were taken from several unused
    positions in existing data structures.  The change was announced in
    mid-1974, and several tens of person-years went into updating software
    to recognize the new dates.

    Unfortunately, reassembling these bits into an integer representing the
    date was somewhat tricky.  Also, some programs had already used the
    spare bits for other purposes.  There were a large number of bugs that
    surfaced on 5 January 1975, the first day whose representation required
    the DATE-75 modification.  Many programs ignored or cleared the new
    bits, and thought that the date was 1 January 1964.  Other programs
    interpreted the new bits incorrectly, and reported dates in 1986 or
    later.  Date-related program bugs were frequent well into the Spring of
    1975.

    On 9 January 1986, the second bit of the DATE-75 extension will come
    into use.  Users of software developed in the 60's and early 70's on
    the TOPS-10 operating system should beware of problems with testing and
    manipulation of dates.  Beware especially of programs that were patched
    after manifesting bugs in 1975, for in the rush to fix the bugs it is
    possible that some programs were modified to assume that the date was
    between 1975 and 1986.  Any date that is off by a multiple of eleven
    years and four days is probably caused by this type of bug.

    Dan Hoey

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
multiple digests as a result of crashed systems
</A>
</H3>
<address>
Rob Austein 
&lt;<A HREF="mailto:SRA@XX.LCS.MIT.EDU">
SRA@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 21 Dec 1985  13:50 EST
</i><PRE>

Once upon a time (when Rutgers.ARPA was flakey and I got five copies
of SF-LOVERS in one hour), I discussed this problem with Mark Crispin
(who maintains the Twenex mailer daemon, MMAILR).  There are some
real-world constraints that make it difficult to do things exactly as
one would like here.  I will use MMAILR for an example because it is
the only mailer who's internals I have examined in detail.

Firstly, it is obviously preferable to send twice than to send not at
all (in the general case anyway, obviously everybody has some examples
of things they would rather not receive at all :-)), so typically the
*last* thing that happens is that the message is marked sent and the
queued disk copy either deleted or updated.  So there's a window there
during which a system crash will cause a duplicate.  The size of this
window is increased in MMAILR because it only does this marking on a
per message basis, not a per recipient basis (ie, if you have a
message that is going to 25 different recipients on different
machines, the disk copy only gets updated after all the recipients
have been tried).  I was a little puzzled by this, so I asked Mark.
The theory is that if your system is crashing a lot, the last thing
you want to do is increase the amount of I/O to the disk copy of the
queued message (thus increasing the chance that the system will crash
while the update to disk is in progess, thus maybe trashing the
message file).  One could conceivably argue that the mailer should
update between recipients when each recipient takes a non-negligable
amount of time, but how do you know?  Doing this for, say, Arpanet
mail might be reasonable, but doing it for a fast local net wouldn't
(it would spend most of its time doing disk I/O).  Furthermore, for
any given net the delay is a factor of the current load, which is
difficult to determine except by trying to use it.  By this point you
are spending more time trying to special-case your way around the
problem than you are delivering mail, so you lose anyway.

One thing that might help prevent this sort of thing on a flakey
system would be to delay startup of the mailer daemon for a little
while after system boot.  I expect that most of these cases of ten
copies to a single person are cases where the system crashes within
five or ten minutes of being rebooted.

--Rob

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-42</DOCNO>
<DOCOLDNO>IA012-000128-B043-183</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.33.html 128.240.150.127 19970217001106 text/html 13359
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:09:34 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 33</TITLE>
<LINK REL="Prev" HREF="/Risks/1.32.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.34.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 33</H1>
<H2> Wednesday, 1 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Star Wars and Bank of NY 
</A>
<DD>
<A HREF="#subj1.1">
Brint Cooper
</A><br>
<A HREF="#subj1.2">
 Chris Hibbert
</A><br>
<A HREF="#subj1.3">
 Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Lipton and SDI 
</A>
<DD>
<A HREF="#subj2.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  The robot sentry 
</A>
<DD>
<A HREF="#subj3.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Murphy is watching YOU 
</A>
<DD>
<A HREF="#subj4.1">
Rob Austein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Failure probabilities in decision chains 
</A>
<DD>
<A HREF="#subj5.1">
Stephen Wolff
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Re:  Can Bank of New York Bank on Star Wars? [PGN's retitling]
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Mon, 23 Dec 85 17:38:18 EST
</i><PRE>

The idea of independent, non-communicating "battle groups" for an SDI
system sounds great.  But what about the "fratricide" problem?

Brint

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Can Bank of New York Bank on Star Wars? [PGN's retitling]
</A>
</H3>
<address>
&lt;<A HREF="mailto:Hibbert.pa@Xerox.ARPA">
Hibbert.pa@Xerox.ARPA
</A>&gt;
</address>
<i>
Mon, 30 Dec 85 12:00:25 PST
</i><PRE>
To: RISKS FORUM (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;
cc: horning@decwrl.DEC.COM (Jim Horning)

  -------------------------------------
  From: horning@decwrl.DEC.COM (Jim Horning)
  Date: 20 Dec 1985 1413-PST (Friday)
  To: RISKS@SRI-CSL.ARPA
  Subject: Can Bank of New York Bank on Star Wars? [PGN's retitling]

  Last night in the debate at Stanford on the technical feasibility of the
  SDI, Richard Lipton chose the financial network as an example of the
  advantages of a distributed system (such as he is proposing for SDI)
  over a centralized one. "There have been no catastrophes."  [What about
  the ARPANET collapse?  PGN] 
  -------------------------------------

The ARPANET collapse is a good contrasting case to show what Lipton was
talking about.  His point about the financial "network" is that it isn't
a monolithic system, but a set of many (dozens?, scores?, hundreds?)
independant systems.  Any one of the systems could fail (even
catastrophically) and it wouldn't be much of a problem for the whole
system.  ARPANet is a single monolithic system, centrally designed and
administered.  Most bugs manifest at exactly the same  provocations at
widely separated parts of the net.

There are at least a couple of separate national networks of automatic
teller machines, and if any one of them dies, it shouldn't have any
effect on the others, or on any of the banks with only local networks,
or no networks at all.  It would take a collapse of the phone system to
put them all out of commission. 

ARPANet on the other hand is a monolithic system.  There is one protocol
that all parts of the system must share, a common medium is used, and in
there are only a few implementations of the protocols.  It doesn't take
much to blow the whole system out of the water.  (For the most part it's
as reliable as it is is only because it gets constant use, and new
parts aren't put in until they are shown to work most of the time.)

What Lipton was proposing at the Stanford debate was that we make an
anti-missile shield from many separately designed and implemented parts
so that their failure modes are more independant.  This is a good idea,
and if it were done, I would have plenty of faith in the system.
However, that's not the way government gets things done.  Since the DOD
is running the program there's no way there would be more than three
"separate" designs, and they would all go through the same approval
process, removing many of the differences they started with.

Back to the ARPANet example, if you look at a larger system than just
ARPA, including UUCP, DECNet, IBM's internal network, as well as the
SOURCE, TYMNet, Compuserve, etc., you find the same robustness.  ARPANet
may die and be out of commission for a long time, and most people will
still be able to get work done through some other medium, since only a
fraction of the people using computer networks depend on any one of
them.

Chris

</PRE>
<HR><H3><A NAME="subj1.3">
Re: Can Bank of New York Bank on Star Wars? [PGN's retitling]
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
30 Dec 1985 1419-PST (Monday)
</i><PRE>

Chris,

I agree with many of your comments, and feel that the $38 billion
problem at Bank of New York is much more typical of how problems in
nominally "independent" systems can propagate because of the intrinsic
need to communicate. (As an example of a non-obvious interaction,
recall its effects on the platinum futures market.)

In addition to the problems you cite, Lipton's scheme suffers from a
few other flaws, including:

- The "simulation" that indicates that "only 5-10% extra bullets" would
be needed apparently makes two dubious assumptions:
	1) Independent "battle groups" (with sufficient "teraflops") can
	pinpoint targets as accurately as a cooperating distributed
	system.
	2) Each "battle group" is able to recognize all "kills" by
	any battle group. I.e., the "extra bullets" counted are only
	those that are fired simultaneously at a target. With many
	of the proposed weapons, targets would be disabled, rather
	than disintegrated; with kinetic weapons, a single target
	could disperse to form a threat crowd.
	(Note that observation of kills is a form of communication
	intrinsic to the problem.)

- There were good systems reasons (completely outside of the computing
requirements) that led the Fletcher commision to propose
cradle-to-grave tracking (especially for RV vs. decoy discrimination)
and a layered defense. Lipton gave no evidence of understanding
those reasons, let alone making credible alternate proposals.

- The systems that you cite, and that he cited, are all ones where each
component is in routine use under the exact circumstances that they
must be reliable for. No matter how many independent subsystems the
Lipton SDI is divided into, NONE of them will get this kind of routine
use under conditions of saturation attack where reliability will be
most critical. Thus there is a high probability that each of them would
fail (perhaps in independent ways!).

Jim H.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Lipton and SDI
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 23 Dec 85 18:09:59 EST
</i><PRE>
To: horning@DECWRL.DEC.COM
cc: LIN@MC.LCS.MIT.EDU, RISKS@SRI-CSL.ARPA

    From: horning at decwrl.DEC.COM (Jim Horning)

    More generally, I am interested in reactions to Lipton's proposal that
    SDI reliability would be improved by having hundreds or thousands of
    "independent" orbiting "battle groups," with no communication between
    separate groups (to prevent failures from propagating), and separately
    designed and implemented hardware and software for each group (to
    prevent common design flaws from affecting multiple groups). 

That is absurd on the face of it.  To prevent propagation of failures,
systems must be truly independent.  To see the nonsense involved,
assume layer #1 can kill 90% of the incoming threat, and layer #2 is
sized to handle a maximum threat that is 10% of the originally
launched threat.  If layer 1 fails catastrophically, you're screwed in
layer #2.  Even if Layers 1 and 2 don't talk to each other, they're
not truly independent.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
The robot sentry
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%rex.DEC@decwrl.DEC.COM ">
minow%rex.DEC@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
Friday, 27 Dec 1985 13:11:28-PST
</i><PRE>

The following appeared on USENET net.general today (Dec 27).  Martin.

                     --------
 
   "A much more sinister arrival on the robot scene is named Prowler.
Created by Robot Defense Systems in Colorado, Prowler has been designed
for use as a sentry to guard military installations, warehouses and
other sites where security is important.  When made available in the
near future, this squat, sturdy, mobile device will carry
microcomputers, software and sensors capable of locating intruders.
Chillingly, buyers will be able to arm Prowler with machine guns and
grenade launchers; they'll also be able to program the robot to fire at
will.  The manufacturer claims that interest in Prowler has been high,
both among domestic companies who see it as a comparatively low-cost
replacement for 24-hour human security, and certain foreign countries
where government officials might prefer guards that will never revolt."
 
                                        -- US Air magazine
 
-- JP Massar, Thinking Machines Corporation, Cambridge, MA
-- ihnp4!godot!massar, massar@think.com.arpa 
-- 617-876-1111
 
Posted Fri 27-Dec-1985 16:08 Maynard Time. Martin Minow MLO3-3/U8, DTN 223-9922

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Murphy is watching YOU
</A>
</H3>
<address>
Rob Austein 
&lt;<A HREF="mailto:SRA@XX.LCS.MIT.EDU">
SRA@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 23 Dec 1985  16:45 EST
</i><PRE>

About six hours after sending that message about mailers [<A HREF="/Risks/1.32.html">RISKS-1.32</A>], I
found myself with the pleasant task of doing bit level reconstruction of
XX's MAILQ: directory with DDT, because the system had crashed while MMAILR
was in the middle of a disk transfer.  Talk about ironic postscripts....

Cheers, Rob

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Re: Failure probabilities in decision chains
</A>
</H3>
<address>
    Stephen Wolff 
&lt;<A HREF="mailto:steve@BRL.ARPA">
steve@BRL.ARPA
</A>&gt;
</address>
<i>
Mon, 23 Dec 85 17:33:15 EST
</i><PRE>

* IF the overall decision is correct if and only if all five
  sub-decisions are correct, and
* IF the sub-decisions are statistically independent, and
* IF the probability that each sub-decision is correct is 0.9,
* THEN the probability that the overall decission is correct is
  0.9^5 = .59049 (vide any textbook in probability)

which is *suspiciously* close to "59%".  But when Bill Walsh
mentioned this problem to me in LA he was adamant that this was
NOT the explanation he wanted.		-s

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-43</DOCNO>
<DOCOLDNO>IA012-000128-B043-203</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.34.html 128.240.150.127 19970217001124 text/html 18739
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:09:48 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 34</TITLE>
<LINK REL="Prev" HREF="/Risks/1.33.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.35.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 34</H1>
<H2> Saturday, 4 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
C&amp;P Computer Problems Foul 44,000 D.C. Phones 
</A>
<DD>
<A HREF="#subj1.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Putting the Man in the Loop 
</A>
<DD>
<A HREF="#subj2.1">
Jim McGrath
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Testing SDI 
</A>
<DD>
<A HREF="#subj3.1">
Jim McGrath
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Independent Battlestations  
</A>
<DD>
<A HREF="#subj4.1">
Jim McGrath
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Failure probablities in decision chains... independence 
</A>
<DD>
<A HREF="#subj5.1">
Edward Vielmetti
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Pharmacy prescription systems 
</A>
<DD>
<A HREF="#subj6.1">
Normand Lepine
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Masquerading 
</A>
<DD>
<A HREF="#subj7.1">
Paul W. Nelson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 C&amp;P Computer Problems Foul 44,000 D.C. Phones
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Sat, 4 Jan 86 13:52:34 est
</i><PRE>

(Excerpted from Washington Post, Friday, 3 Jan 86, pp D1 &amp; D4)
	By Elizabeth Tucker, Washington Post Staff Writer

	Up to 44,000 business and residential phone lines in the District 
(of Columbia) did not work or worked intermittently (Thursday, 2 Jan 86) 
because of computer problems at Chesapeake &amp; Potomac Telephone Co. (C&amp;P)
	C&amp;P... said the ... company had equipment trouble in its central 
office... between 2:20 and 4 pm.  The problem was fixed when (the company)
shut off connections to the 44,000 lines for a split second, and then 
turned the connections back on.  
	C&amp;P has more than 780,000 phone lines in (DC). 
	(For) nearly two hours... customers often were unable to make or 
receive calls... The telephone company had not diagnosed the precise 
cause of the problem late yesterday....
	Neither the White Hourse nor the General Services Administration...
reported problems...
	(GWU) Hospital experienced a delay in getting dial tones, but only 
for about 10 minutes... 
	...the Associated Press... could receive calls but not make them 
between 2 and 4 pm.... 
	"You don't know what's going on in terms of news... I thought 
someone cut the cables.  I was worried." (AP spokesman)  
	The Washington Post Co. also experienced problems... 
	One State department official ... "... heard corridor gossip 
[that people] weren't getting calls in or out."  
	The DC police... reported no problems in receiving 911 emergency 
calls, and sid there was no appreciable drop off in calls... C&amp;P... said 
some people may have experienced problems reaching 911... "It could be 
that no one had problems with 911."...
	The problem is not considered usual... "They don't know what caused
the problem, but it's up and working fine . . . For all intents and purposes
they reset the system, turned off all the connections and then turned them 
back on again -- LIKE RESETTING A COMPUTER." (EMPHASIS supplied) 
	"They are researching and analyzing the tapes to see what caused 
the problem."... such problems can occur when heavy calling is taking place
... but that such was not the case (2 Jan 86).  
	"We ruled it out . . . A lot of people aren't working downtown... 
calling volumes are down dramatically."  The telephone system "sometimes
can get confused," and think there is heavy calling when there isn't...
			# # # 
(parentheses and close up ... are mine) 
[brackets and spaced . . . are the Post's, as are "quotes"] 
I restrained myself from editorial comments, except where I just had to go 
all caps for emphasis.   Mike McLaughlin

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Putting the Man in the Loop
</A>
</H3>
<address>
"Jim McGrath" 
&lt;<A HREF="mailto:MCGRATH@OZ.AI.MIT.EDU">
MCGRATH@OZ.AI.MIT.EDU
</A>&gt;
</address>
<i>
Thu 2 Jan 86 21:43:54-EST
</i><PRE>

I found the calculations involving SDI reliability interesting.  As
well the debate on SDI software.  But it appears as if people may be
making some aspects of the problem too hard.  Hoping that I have not
missed this part of the conversation....

Obviously some problems (precise aiming of weapons for instance)
demand computer control.  And the time constraints involved in boost
phase interception may require computer control.  But other aspects
(such as initial activation of weapons for mid-course and terminal
phase interception, target discrimination, neutralization of
counter-measures) could be made with substantial human input.  Thus no
need for monster AI programs to cope with all possible contingencies -
humans are ready made for that purpose.

The model to think of is a sophisticated computer game.  The human
operator(s) would take care of truly strange cases (rising moons,
flocks of interplanetary geese) and either determine strategy and/or
provide input parameters for the actual computer controllers (e.g.
"Looks like they are using dummy decoys of the DUMDUM class - better
change certain probabilities in your expert systems target
discriminator in the following manner").  The trade off here is
decreased reliance on sophisticated AI programs that we all concede
that state of the art is not capable of producing and increased
reliance on software that provides an excellent interface to the human
operator.  That would seem to be the easier task (we already have
experience in designing control systems for high performance jet
fighters).

Of course, this increases the problems associated with real time
secure communications, but you were going to have to face them anyway.

Jim

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Testing SDI
</A>
</H3>
<address>
"Jim McGrath" 
&lt;<A HREF="mailto:MCGRATH@OZ.AI.MIT.EDU">
MCGRATH@OZ.AI.MIT.EDU
</A>&gt;
</address>
<i>
Thu 2 Jan 86 21:45:01-EST
</i><PRE>

From Risks, Volume 1 : Issue 33:

&gt; From: horning@decwrl.DEC.COM (Jim Horning)
&gt; - The systems that you cite, and that he cited, are all ones where each
&gt; component is in routine use under the exact circumstances that they
&gt; must be reliable for. No matter how many independent subsystems the
&gt; Lipton SDI is divided into, NONE of them will get this kind of routine
&gt; use under conditions of saturation attack where reliability will be
&gt; most critical. Thus there is a high probability that each of them would
&gt; fail (perhaps in independent ways!).

This seems to be a common problem with any modern weapon system (or
even not so modern - it took WWI for the Germans to realize that the
lessons of the 1880's concerning rapid infantry fire (and thus the
rise of infantry over calvary) did not take artillery development
adequately into account).  But this might be easier to manage than
most.

What if, after suitable advance notice, the SDI system was fully
activated and targeted against one of our periodic meteor swarms?
While not perfect targets, they would be quite challenging (especially
with respect to numbers!), except for boost phase, and CHEAP.  If the
system was regenerative (i.e. you only expended energy and the like),
then the total cost would be very low.

Meteors are just a casual example.  My point is that the costs of
partial (but system wide) testing does not have to lie with the
targets (which many people seem to assume) as much as with weapons
discharge - which may be quite manageable.

Jim

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Independent Battlestations
</A>
</H3>
<address>
"Jim McGrath" 
&lt;<A HREF="mailto:MCGRATH@OZ.AI.MIT.EDU">
MCGRATH@OZ.AI.MIT.EDU
</A>&gt;
</address>
<i>
Thu 2 Jan 86 21:45:43-EST
</i><PRE>

From Risks, Volume 1 : Issue 33:

&gt; From: Herb Lin &lt;LIN@MC.LCS.MIT.EDU&gt;
&gt;&gt; From: horning at decwrl.DEC.COM (Jim Horning)
&gt;&gt; More generally, I am interested in reactions to Lipton's proposal that
&gt;&gt; SDI reliability would be improved by having hundreds or thousands of
&gt;&gt; "independent" orbiting "battle groups," with no communication between
&gt;&gt; separate groups (to prevent failures from propagating), and separately
&gt;&gt; designed and implemented hardware and software for each group (to
&gt;&gt; prevent common design flaws from affecting multiple groups). 
&gt; That is absurd on the face of it.  To prevent propagation of failures,
&gt; systems must be truly independent.  To see the nonsense involved,
&gt; assume layer #1 can kill 90% of the incoming threat, and layer #2 is
&gt; sized to handle a maximum threat that is 10% of the originally
&gt; launched threat.  If layer 1 fails catastrophically, you're screwed in
&gt; layer #2.  Even if Layers 1 and 2 don't talk to each other, they're
&gt; not truly independent.

True but his solution WOULD reduce the probability of the propagation
of "hard" errors (i.e. corrupting electronic communications), and the
whole independence approach should lead to increased redundancy so as
to deal with "soft" propagation of errors such as you cite.

Remember, you do not need to PREVENT the propagation of errors, just
reduce the probability enough so that your overall system reliability
is suitably enhanced.  I think the approach has merit, particularly
over a monolithic system, and should not be shot down out of hand.

Jim

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Failure probablities in decision chains and decision independence
</A>
</H3>
<address>
&lt;<A HREF="mailto:Edward_Vielmetti%UMich-MTS.Mailnet@MIT-MULTICS.ARPA">
Edward_Vielmetti%UMich-MTS.Mailnet@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Thu, 2 Jan 86 21:32:32 EST
</i><PRE>

&gt; * IF the overall decision is correct if and only if all five
  sub-decisions are correct, and
&gt; * IF the sub-decisions are statistically independent, and
&gt; * IF the probability that each sub-decision is correct is 0.9,
The weak link in the derivation of failure rates in decision chains is
the assumption that failure probablities are statistically independent.
I think that it could be argued that the failure probabilities are
corelated; that is, if sub-system A fails because of event X, sub-
systems B, C, D, and E will be more likely to fail than if A survives
the event.   This corellation could come about as a result of proximity,
similar hardware or software, or a general design likeness.  The effect
would be to increase the probability that the overall decision is
correct.  In the case where B is 9 times as likely to fail if A fails,
the probability of the system failing is 11%, not 19% :

           ! B fails ! B survives ! total !
-----------!---------!------------!-------!
A fails    !   0.09  !    0.01    !  0.10 !   P(A &amp; B) = 0.89
A survives !   0.01  !    0.89    !  0.90 !   P(A) * P(B) = 0.81
-------------------------------------------
 total     !   0.10  !    0.90    !  1.00 !

Edward Vielmetti
University of Michigan
Edward_Vielmetti%UMich-MTS.Mailnet@MIT-Multics.ARPA

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Pharmacy prescription systems
</A>
</H3>
<address>
Normand Lepine 225-6715
&lt;<A HREF="mailto:lepine%why.DEC@decwrl.DEC.COM  ">
lepine%why.DEC@decwrl.DEC.COM  
</A>&gt;
</address>
<i>
Friday,  3 Jan 1986 09:54:49-PST
</i><PRE>

Dave Platt raises a number of issues concerning the use of automated systems
in pharmacies for checking drug-interactions, counter-indications, etc.
Most of the points he has raised need careful consideration.  Any automated
medical or pharmaceutical system provides a useful tool to physicians,
pharmacists, and other health-care workers.  The usefulness of the tool is
directly related to the construction and maintenance of the data base (or
knowledge base in expert system implementations) as Dave correctly notes.
The awareness that such a system is a tool must also be recognized by those
using it to avoid the unthinking dependency that can develop, but provision
of tools that enable a pharmacist to check on items that might otherwise be
overlooked is valuable.  And the area of liability, reliablity, etc. must be
further studied.

I do however take exception to Dave's statement that he is concerned even
more by such systems than by MYCIN et.al. because they are one step closer
to the consumer.  Medical expert systems, diagnosis aids, etc. are no
further removed from the consumer than a pharmacy system is.  Each of the
two types of systems are used as aids by trained practitioners (the issue of
competancy aside).  Pharmacists currently provide an extra step in the
presciption chain by manually doing what the automated systems assist with.
Their education and experience is a valuable adjunct to the prescribing
physician and is only supplemented by these systems.  The consumer is no
more involved as a user of these systems than as a user of the medical
expert systems.

Normand Lepine

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Masquerading
</A>
</H3>
<address>
&lt;<A HREF="mailto:ssc-vax!ssc-bee!nelson@uw-beaver.arpa">
ssc-vax!ssc-bee!nelson@uw-beaver.arpa
</A>&gt;
</address>
<i>
Fri, 3 Jan 86 13:31:39 pst
</i><PRE>

   In course of the password issue being discussed in RISKS, the
question of faking login procedures was raised.  This really
brings up the issue of non-system or untrusted software
masquerading as system software.  One method around this problem
is to implement a trusted communication path between the system
and the user.

   Trusted path communications is described in the DoD Trusted
Computer System Evaluation Criteria, (CSC-STD-001-83).  A few
definitions are in order.  The evaluation criteria defines a
trusted computing base (TCB) as "The totality of protection
mechanisms within a computer system ...".

A trusted path is defined as:
      "A mechanism by which a person at a terminal can
   communicate directly with the Trusted Computing Base. This
   mechanism can only be activated by the person or the Trusted
   Computing Base and cannot be imitated by untrusted software."

An implementation of a trusted path could have a terminal driver
look for a combination of keystrokes from the user that would be
defined to mean "enter trusted path".  When the keystrokes are
received the handler would switch to a trusted function that
would process user requests such as logging in.  In this case the
terminal driver would be considered part of the trusted computing
base.  When users want to log in they enter the keystrokes for
the trusted path and could then log in with some greater
assurance that they are not being duped.

   This approach does not eliminate possibilities for
masquerading but makes it more difficult.  The bad guys would
most likely need some hardware installed in the terminal link to
steal passwords, making the trusted path ineffective ( or any
other mechanism for that matter ).  Installing masquerading
hardware on single systems should be a difficult proposition if
the systems are physically protected.  However, when networking
is involved the possibilities are enormous.  Any node in a path
could have bad guys duping unsuspecting users.  Users would be
asked to trust an awful lot more hardware and software.

   I saw a TV show where the bad guys attempt to steal funds
electronically transferred via satellite link by masquerading as
the receiver after disabling the real receiver.  We were asked to
believe that they used a small dish antenna and a Radio Shack
portable computer, but still...  Masquerading is definitely a
risk to society when the bad guys are determined enough.

                Paul W. Nelson (..ssc-vax!ssc-bee!nelson)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-44</DOCNO>
<DOCOLDNO>IA012-000128-B043-234</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.35.html 128.240.150.127 19970217001141 text/html 30545
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:10:05 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 35</TITLE>
<LINK REL="Prev" HREF="/Risks/1.34.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.36.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 35</H1>
<H2> Monday, 5 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
SDI -  Meteors as substitutes for nuclear war 
</A>
<DD>
<A HREF="#subj1.1">
Jim Horning
</A><br>
<A HREF="#subj1.2">
 Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  SDI -  Putting a Man in the Loop 
</A>
<DD>
<A HREF="#subj2.1">
Jim McGrath
</A><br>
<A HREF="#subj2.2">
 Herb Lin
</A><br>
<A HREF="#subj2.3">
 JM again
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  SDI -  Testing SDI 
</A>
<DD>
<A HREF="#subj3.1">
Herb Lin
</A><br>
<A HREF="#subj3.2">
 Jim McGrath
</A><br>
<A HREF="#subj3.3">
 HL again
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  SDI -  Independent Battlestations 
</A>
<DD>
<A HREF="#subj4.1">
Herb Lin
</A><br>
<A HREF="#subj4.2">
 Jim McGrath
</A><br>
<A HREF="#subj4.3">
 HL again
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  SDI -  The Goal of SDI; Politicians 
</A>
<DD>
<A HREF="#subj5.1">
Jim McGrath
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Pharmacy prescription systems 
</A>
<DD>
<A HREF="#subj6.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  How to steal people's passwords 
</A>
<DD>
<A HREF="#subj7.1">
Roy Smith
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Meteors as substitutes for nuclear war
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
4 Jan 1986 1536-PST (Saturday)
</i><PRE>

Jim,

Thanks for your comments. However, I do have to disagree with your
cheerful assessment of the chances for REALISTIC testing of any SDI
system or major subsystem. The problem is not that there is no testing
that could be done, but that any substantial change in the system's
environment is likely to provoke a new set of unexpected behaviors.

Certainly, an SDI that failed to shoot down a meteor swarm could be
judged faulty. (And certainly any experienced software engineer would
predict that it WOULD fail to shoot down its first meteor swarm.) But
what reason is there to believe that an SDI that had shot down every
meteor swarm since its deployment would act in the intended manner when
faced with a full-scale nuclear attack, which would certainly be
accompanied by both attacks on the SDI system itself and by extensive
counter-measures?

It is in the nature of counter-measures that you cannot be sure
in advance that you have full knowledge of the counter-measures that
your opponent will throw at you--especially in a first engagement.
Thus, there is in principle no way to adequately test your system's
response to counter-measures.

It is in the nature of distributed and real-time systems that the most
catastrophic failures tend to come in periods of heaviest load. Thus
the results small-scale testing can't be extrapolated with confidence.

It is in the nature of destructive testing (which a full-scale nuclear
attack on an SDI certainly would be) that you can't test the thing that
you will ultimately rely on. However, it had better be something so
assuredly similar to the ultimate system that you can be confident in
the extrapolation.

Finally, one brief non-software point:  I read a column the other day (Tom
Wicker?) that pointed out that every technology that would be effective
against ballistic missiles would be far more effective, far sooner, as an
anti-satellite system, since the behavior of satellites is more predictable,
and the attacker can pick his moment. Even without SDI, the US is far more
dependent on satellites for both defense and civilian uses than the USSR.
And any space-based SDI would make a very tempting ASAT target. So
developing the technology needed for the system INCREASES the risk of
relying on the system.

Jim H.

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Meteors as substitutes for nuclear war
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:vax-populi!dparnas@nrl-css.arpa ">
vax-populi!dparnas@nrl-css.arpa 
</A>&gt;
</address>
<i>
Sat, 4 Jan 86 16:50:35 pst
</i><PRE>
Cc: nrl-css!horning@decwrl.ARPA

  The comments that you reported on testing SDI, proposing that we test
it by shooting at periodic meteor swarms make me wonder how many of 
the people in our profession have trouble discriminating between 
real problems and arcade games.  Shooting at an easily predictable
non-evasive meteor has about the same relation to the real job of 
SDI as shooting at a target in a booth at a county fair has to
shooting at woods in heavy brush from a moving airplane.  

	If I had a computer program that had been tested by controlling a 
weapon at a county fair, I would not have much confidence in its performance
the first time that the B.C. Government tried to use it in its periodic 
wolf kills from light planes.  In fact, I hope someone sells that idea
to them.
	
Dave

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Putting a Man in the Loop
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@Epic">
J.JPM@Epic
</A>&gt;
</address>
<i>
Sat 4 Jan 86 19:24:35-PST
</i><PRE>
To: "arms-d@mc"@Sushi
cc: "lin@mc"@Sushi
Reply-to: mcgrath%mit-oz@mit-mc.arpa

    From: Herb Lin &lt;LIN@MC.LCS.MIT.EDU&gt; [Date: Sat, 4 Jan 86 18:52:04 EST]
                                        [Herb's message is embedded.  PGN]

        From: Jim McGrath &lt;MCGRATH at OZ.AI.MIT.EDU&gt;
        The model to think of is a sophisticated computer game.  The 
        human operator(s) would take care of truly strange cases
        (rising moons, flocks of interplanetary geese)..

    But the major problem is not the things that the computer isn't
    sure about, but rather the things that it is sure about that are
    not true.  How would the human ever know to intervene?

I thought a bit about that, and have a suitable elaboration.
Basically, you require a "two key" system, with the computer holding
one key and a human operator/monitor another.  This is primarily for
the "go/no go" decision.  After an attack is acknowledged, you concede
the possibility of overkilling by the computer (taking out third party
satellites and the like) in return for the more immediate response to
attack provided by the computer.

This takes care of the computer going off half cocked.  If you are
worried about the computer missing an actual attack, you can now set
the sensitivity low, trusting to the human monitor to not activate
when appropriate.

Actually, this is too simple.  What you really want is to have the
hardware/software under a set of human operators, perhaps partitioned
to provide zone coverage.  The humans act as before, mainly as
checkpoints for activation decisions, overseeing strategy, sending
expert information to the computers as the situation unfolds so that
the software does not have to be a tactical genius.  Now a set of
human supervisors sit on top of the operators.  They have another
"key," and so can break ties on activation decisions (or even override
lower level decisions).  Their other missions are to advise operators
on developing strategy, keep the command authorities informed, and to
act as "free safety."  That is, they will have the authority to
override operator commands so that targets that find seams in the
zones (or similarly defy the operator/computer teams) will be
targetted for attack.  Normally they will access information at a much
higher level than an operator (the former will have to deal with
thousands of targets - the latter tens of low hundreds).

Other concepts can be advanced: advance/retard the ease of a go/no go
decision according to alert status and the like.  The main point is
that a man in the loop is a big win, since you get a proprogrammed
general purpose computer which can take care of those "higher level"
decisions.  Response time is not a concern - seconds are not vital if
you have 20 minutes.  Only for boost phase interception do you run
into difficulties.

Jim

</PRE>
<HR><H3><A NAME="subj2.2">
Re: Putting a Man into the Loop
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@Epic">
J.JPM@Epic
</A>&gt;
</address>
<i>
Sat 4 Jan 86 21:47:31-PST
</i><PRE>
To: "lin@mc"@Sushi
cc: "arms-d@mc"@Sushi, "Risks@sri-csl"@Sushi, "mcgrath%oz@mc"@Sushi

    From: Herb Lin &lt;LIN@MC.LCS.MIT.EDU&gt;
    ...
        "go/no-go"

    You mean fire/don't fire?

I mean weapon activation.  Firing decisions for specific targets will
be made by computer, but the weapons themselves will be inert until
activated.

        After an attack is acknowledged, you concede the possibility
        of overkilling by the computer (taking out third party
        satellites and the like) in return for the more immediate
        response to attack provided by the computer.

    So your solution is that you kill everything, and don't do
    discrimination?

No.  I meant exactly what I said.  You concede that you might make a
mistake in firing (which was your original objection).  You do not aim
for making a mistake.  I explicitly said in the same message that one
of the jobs of human operators is to assist in real time parameter
adjustment so that the computer controlled weapons would be able to
discriminate better.

As I said earlier, boost phase poses a particular problem.  The only
thing I can see to do now is to trust in AI to give you a good initial
screen, and to argument this with a human authorized to override the
problem in a few seconds.  This could work well for limited periods of
time (such as alerts), but I have problems with it for extended
periods.

Jim

</PRE>
<HR><H3><A NAME="subj2.3">
 Testing SDI
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat,  4 Jan 86 18:54:43 EST
</i><PRE>
To: MCGRATH@OZ.AI.MIT.EDU
cc: LIN@MC.LCS.MIT.EDU, "RISKS-LIST:"@MC.LCS.MIT.EDU,
    ARMS-D@MC.LCS.MIT.EDU, risks@OZ.AI.MIT.EDU

    From: Jim McGrath &lt;MCGRATH at OZ.AI.MIT.EDU&gt;

    This [full-scale system testing -- HL] seems to be a common problem with 
    any modern weapon system (or
    even not so modern - it took WWI for the Germans to realize that the
    lessons of the 1880's concerning rapid infantry fire (and thus the
    rise of infantry over calvary) did not take artillery development
    adequately into account).

And there have been disasters.  Only here, the disaster is bigger.

    What if, after suitable advance notice, the SDI system was fully
    activated and targeted against one of our periodic meteor swarms?
    While not perfect targets, they would be quite challenging (especially
    with respect to numbers!), except for boost phase, and CHEAP.  If the
    system was regenerative (i.e. you only expended energy and the like),
    then the total cost would be very low.

Interesting example, but problematic.  No kill assessment for one,
under some circumstances.  Entirely different signatures for another.

    Meteors are just a casual example.  My point is that the costs of
    partial (but system wide) testing does not have to lie with the
    targets (which many people seem to assume) as much as with weapons
    discharge - which may be quite manageable.

But if the tests are to be realistic, then the right targets are
essential, especially since a counter-measure is to try to fool with

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Testing SDI
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat,  4 Jan 86 22:45:25 EST
</i><PRE>
To: mcgrath@OZ.AI.MIT.EDU
cc: LIN@MC.LCS.MIT.EDU, ARMS-D@MC.LCS.MIT.EDU, risks@SRI-CSL.ARPA
In-reply-to: Msg of Sat 4 Jan 86 19:36:57-PST from Jim McGrath &lt;J.JPM at Epic&gt;
Message-ID: &lt;[MC.LCS.MIT.EDU].773136.860104.LIN&gt;

    From: Jim McGrath &lt;MCGRATH at OZ.AI.MIT.EDU&gt;

    remember that the major cost of the target simulation is in
    the boost phase.  Once the targets are in sub-orbit, it makes no
    difference whether they were fired independently by hundreds of
    expensive boosters or were accelerated from orbital velocity, after
    having been place there originally through more economical means.
    Terminal phase tests are especially easy to do this way.  Only boost
    phase is intrinsically expensive.

I agree with your technical point.  But successful boost phase is what
SDI is all about.  The technology for dealing with mid-course and
terminal is ALREADY here.  You need boost phase so that you can thin
out the midcourse and terminal.

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Testing SDI
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@Epic">
J.JPM@Epic
</A>&gt;
</address>
<i>
Sat 4 Jan 86 19:36:57-PST
</i><PRE>
To: "arms-d@mc"@Sushi, "risks@sri-csl"@Sushi
cc: "lin@mc"@Sushi, "mcgrath%oz@mc"@Sushi
Reply-to: mcgrath%mit-oz@mit-mc.arpa

    From: Herb Lin &lt;LIN@MC.LCS.MIT.EDU&gt;
       
        From: Jim McGrath &lt;MCGRATH at OZ.AI.MIT.EDU&gt;

        What if, after suitable advance notice, the SDI system was fully
        activated and targeted against one of our periodic meteor swarms?

    Interesting example, but problematic.  No kill assessment for one,
    under some circumstances.  Entirely different signatures for another.

It would test some aspects of the system on a system wide level (such
as detection and tracking), and would even provide good kill estimates
in some cases (KE weapons and small targets).  But as I said:

        Meteors are just a casual example.  My point is that the costs of
        partial (but system wide) testing does not have to lie with the
        targets (which many people seem to assume) as much as with weapons
        discharge - which may be quite manageable.

    But if the tests are to be realistic, then the right targets are
    essential, especially since a counter-measure is to try to fool
    with the targets that the defense sees.

True, but remember that the major cost of the target simulation is in
the boost phase.  Once the targets are in sub-orbit, it makes no
difference whether they were fired independently by hundreds of
expensive boosters or were accelerated from orbital velocity, after
having been place there originally through more economical means.
Terminal phase tests are especially easy to do this way.  Only boost
phase is intrinsically expensive.

(That's two messages where I've come up with approaches to problems
that work on all phases except boost phase.  Although initially
attractive, perhaps concentrating more on mid-course and terminal
defense will ultimately prove more beneficial.)

Jim

</PRE>
<HR><H3><A NAME="subj3.3">
 Independent Battlestations
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat,  4 Jan 86 18:59:03 EST
</i><PRE>
To: MCGRATH@OZ.AI.MIT.EDU
cc: LIN@MC.LCS.MIT.EDU, "RISKS-LIST:"@MC.LCS.MIT.EDU,
    risks@OZ.AI.MIT.EDU

    &gt; From: Herb Lin &lt;LIN@MC.LCS.MIT.EDU&gt;
    &gt;&gt; From: horning at decwrl.DEC.COM (Jim Horning)
    &gt;&gt; More generally, I am interested in reactions to Lipton's proposal that
    &gt;&gt; SDI reliability would be improved by having hundreds or thousands of
    &gt;&gt; "independent" orbiting "battle groups,"..
    &gt; That is absurd on the face of it.  To prevent propagation of failures,
    &gt; systems must be truly independent.  To see the nonsense involved,
    &gt; assume layer #1 can kill 90% of the incoming threat, and layer #2 is
    &gt; sized to handle a maximum threat that is 10% of the originally
    &gt; launched threat.  If layer 1 fails catastrophically, you're screwed in
    &gt; layer #2.  Even if Layers 1 and 2 don't talk to each other, they're
    &gt; not truly independent.

    True but his solution WOULD reduce the probability of the propagation
    of "hard" errors (i.e. corrupting electronic communications), and the
    whole independence approach should lead to increased redundancy so as
    to deal with "soft" propagation of errors such as you cite.

    Remember, you do not need to PREVENT the propagation of errors, just
    reduce the probability enough so that your overall system reliability
    is suitably enhanced.  I think the approach has merit, particularly
    over a monolithic system, and should not be shot down out of hand.

This is the fundamental point of disagreement.  If SDI is just another
defensive system, then all that you say is right.  But it isn't.  I
will stop beating the perfect system horse when the SDI supporters
acknowledge that large-scale population defense can never be made
certifiably reliable.  

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Independent Battlestations
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@Epic">
J.JPM@Epic
</A>&gt;
</address>
<i>
Sat 4 Jan 86 19:52:46-PST
</i><PRE>
To: "risks@mc"@Sushi, "arms-d@mc"@Sushi
cc: "lin@mc"@Sushi, "mcgrath%oz@mc"@Sushi

What do you mean by "certifiably reliable?"  While politicians may
talk about 100% reliability, we are all scientists and engineers here
- we know that nothing, including such things as the sun rising, is
100% reliable.  You must really mean X% reliable, where X is a high
number (perhaps high enough so as to reduce to a very low probability
the chance of a single warhead getting through).  In that case,
independent battlestations, and other measures, might give you the
number you need.  I submit that it is too early to dismiss these
approaches out of hand, since you are really talking about a
quantative difference and we do not have good numbers yet.

Anyway, I am arguing for a highly reliable, but by no means perfect,
system.  My X would probably be lower than yours.  I really do think
that there is a difference between a few million dead (horrible, on
the scale of WW II) and hundreds of millions dead (utterly
unprecedented).  And while I am certain that we all, including the
public, would like as high an X as possible, they would agree that
losing a city or two and some missile bases/airfields would be a lot
better than losing everything.

Besides, complaints that politicians are lying do not sit well with
me.  Of course they are lying.  WE WANT THEM TO LIE.  Politicians who
tell the truth get kicked out of office.  Our entire posture of
extended deterrence is a joke, since we do not have the capability to
creditably back it up.  But you try to get someone elected promising
to reinstate the draft, raise the defense budget further, or pull back
our troops and cut Europe/Japan loose.

We have to make do with what we have.   

Jim

     [Do we have to have it just because we can make do with it?  PGN]

</PRE>
<HR><H3><A NAME="subj4.2">
 Independent Battlestations
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat,  4 Jan 86 23:03:58 EST
</i><PRE>
To: mcgrath@OZ.AI.MIT.EDU
cc: ARMS-D@MC.LCS.MIT.EDU, LIN@MC.LCS.MIT.EDU,
    RISKS@MC.LCS.MIT.EDU

    From: Jim McGrath &lt;J.JPM at Epic&gt;

    What do you mean by "certifiably reliable?"

A system whose performance is known in advance to be adequate to the
task.  I don't care if the number for reliability isn't 100%, just
high enough so that no one dies.

    We all, including the
    public, would like as high an X as possible, they would agree that
    losing a city or two and some missile bases/airfields would be a lot
    better than losing everything.

But that is not the goal of the SDI.

    Besides, complaints that politicians are lying do not sit well with
    me.  Of course they are lying.  WE WANT THEM TO LIE.  [...]

    We have to make do with what we have.

So you condone lying to the public as a tool of public policy?  How
would you like to acknowledge that publically in a letter to the NY
Times?  Don't forget to add that you support SDI, and that truth
doesn't matter when you try to justify a weapon system -- never mind
what it actually does.  We can say that we will spend millions of
dollars on AIDS research since that will save lives, and spend the
money instead on nerve gas, which will also help to eliminate AIDS (by
killing homosexual soldiers).

Sorry; I believe that elected leaders have a responsibility to tell
the truth to the public, and to educate them away from fairy tales.  I
would rather see precious defense dollars go to create good anti-tank
weapons; that would have some chance of improving extended deterrence.

</PRE>
<HR><H3><A NAME="subj4.3">
The Goal of SDI
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@Epic">
J.JPM@Epic
</A>&gt;
</address>
<i>
Sat 4 Jan 86 21:52:13-PST
</i><PRE>
To: "lin@mc"@Sushi
cc: "arms-d@mc"@Sushi, "risks@sri-csl"@Sushi, "mcgrath%oz@mc"@Sushi

    From: Herb Lin &lt;LIN@MC.LCS.MIT.EDU&gt;

        We all, including the public, would like as high an X as
        possible, they would agree that losing a city or two and some
        missile bases/airfields would be a lot better than losing
        everything.

    But that is not the goal of the SDI.

Which does not mean it should not be supported for that reason.  Most
government programs have consequences (sometimes good, sometimes bad)
never conceived of in their initial purpose.  That does not mean you
ignore them when evaluating the program.

I simply do not follow your logic at all.  Do you want to score points
against Reagan and Company?  Or do you want to discuss strategic
defense, and SDI as it is developing?  I'm not interested in defending
Reagan, just developing defense and seeing that it is done the best
way possible.

Jim

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Politicians
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@Epic">
J.JPM@Epic
</A>&gt;
</address>
<i>
Sat 4 Jan 86 22:12:56-PST
</i><PRE>
To: "lin@mc"@Sushi
cc: "arms-d@mc"@Sushi, "risks@sri-csl"@Sushi, "mcgrath%oz@mc"@Sushi

    From: Herb Lin &lt;LIN@MC.LCS.MIT.EDU&gt;

        Besides, complaints that politicians are lying do not sit well
        with me.  Of course they are lying.  WE WANT THEM TO LIE.
        Politicians who tell the truth get kicked out of office....

    So you condone lying to the public as a tool of public policy? [...]

You are arguing from emotion (almost hysterically), not reason, which
I do not expect of you. I stated a fact: public officials must lie on
many (not all) issues in order to retain office.  (I could have said
"evade," or just "keep quiet about" if the word "lie" hits you so hard
- I see no functional distinction.)  This is one thing that everyone,
no matter what their policy perspective, agrees on (this comes from
several graduate seminars, and personal experience).  I did not say
that I liked that state of affairs much.  But I do not find it
reasonable to blame the politicians.  Rather, the fault lies with the
voters.

Unlike many of my friends in the social sciences, I do not
concentrates on the "oughts" of the world.  I focus on the empirical
evidence.  Perhaps it is the scientist in me.  So when I observe a
political system that punishes frank and honest talk about some issues
(usually those, like nuclear war and taxes, that are too horrible to
contemplate), I acknowledge this as a fact, and do not waste time
decrying it.  My decrying it is not (to the first approximation) going
to change human nature.  Thus my comment "we have to make do with what
we have."

    Sorry; I believe that elected leaders have a responsibility to
    tell the truth to the public, and to educate them away from fairy
    tales.  I would rather see precious defense dollars go to create
    good anti-tank weapons; that would have some chance of improving
    extended deterrence.

Come on now.  Leaders can only lead where people are, ultimately,
willing to go.  Just look at the nuclear freeze movement.  This is the
level at which the public thinks of nuclear war when it is forced to
think.

Finally, your last sentence shows that you missed my entire point.
Congress (i.e. the people) will not budget for the necessary increases
in conventional weapons (let alone the Europeans).  Ultimately it does
not matter what you or I like, it is what the people will accept.  And
if they act "irrationally," then I feel we cannot just sit back and
demand that out "leaders" make them change their minds, or that the
people change their stripes.  Instead we should focus on the possible
- which is, afterall, what politics is all about.

Jim

----------------------------------------------------------------------

Date: 5 Jan 86 17:52:32 PST (Sunday)
From: Hoffman.es@Xerox.ARPA
Subject: Re: Pharmacy prescription systems
To: RISKS FORUM (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;
cc: Hoffman.es@Xerox.ARPA

Not speaking legally, but just morally, I think any professional who
relies on a single source of advice when more are available is derelict.
In any life-critical situation, information should always be tested or
cross-checked whenever possible.

Would you exonerate a pharmacist (or a physician, for that matter) who
relied completely on a particular reference book which had a critical
error in it?  Or on the tape-recorded lecture of some (human,
less-than-perfect) instructor?  Or, in the case under consideration, on
some expert computer system?  I certainly wouldn't.

The pharmacist does not shoulder all the moral burden in this
hypothetical case.  Some of it belongs to the information source
(publisher, human instructor, or expert computer system).  Just not all
of it.  As the other commenters on the subject have noted, the user must
be carefully trained against unthinking dependency.  That's the single
most important factor.  

This is another instance of the urgent necessity to debunk the popular
myth of computer infallibility.  People are all too eager to stop
thinking and let others (parents, teachers, priests, politicians,
computers) make all their decisions.  And the others usually love the
role, too.  In the case of computer systems, we their builders are in
this seductive position and we must remember the inherent perils.

--Rodney Hoffman  

----------------------------------------------------------------------

Date: Sun, 5 Jan 86 16:56:19 est
From: allegra!phri!roy@seismo.CSS.GOV (Roy Smith)
To: allegra!seismo!sri-csl.arpa!risks@seismo.CSS.GOV
Subject: How to steal people's passwords
Cc: roy@seismo.CSS.GOV

	In Volume 1, Issue 34, nelson@uw-beaver.arpa talked about faking
login procedures and non-system software masquerading as system software.
Well, an interesting thing just happened to me along those lines.

	We've got several modems used for both dial-in and dial-out.  To
place an outgoing call, you disable logins on a line (a program, acucntrl
does this for you) and use kermit to talk to the modem.  I had just done
this when somebody called in.  The modem, of course, didn't know logins
were disabled and answered the phone.

	At this point, nothing much prevented me from pretending to be a
login process and prompting the unsuspecting user for his login name and
password, then faking a burst of noise and breaking the connection so s/he
wouldn't suspect anything out of the ordinary.

	Our PBX allows you to forward all your calls by dialing "12 NNN".
Until canceled, all incoming calls get routed to xNNN.  I could have had
the modem forward all its calls to my office phone.  Plug an Apple-II
w/modem into my phone line, and I'm all set to steal passwords for a night.
Fix it up in the morning, and nobody would suspect anything worse than a
modem temporarily going bonkers, which happens often enough.

Roy Smith &lt;allegra!phri!roy&gt;
System Administrator, Public Health Research Institute
455 First Avenue, New York, NY 10016

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-45</DOCNO>
<DOCOLDNO>IA012-000128-B043-264</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.36.html 128.240.150.127 19970217001156 text/html 19931
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:10:22 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 36</TITLE>
<LINK REL="Prev" HREF="/Risks/1.35.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.37.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 36</H1>
<H2> Tuesday, 7 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
PLEASE READ Weapons and Hope by Freeman Dyson. 
</A>
<DD>
<A HREF="#subj1.1">
Peter Denning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Wolves in the woods 
</A>
<DD>
<A HREF="#subj2.1">
Jim Horning
</A><br>
<A HREF="#subj2.2">
 Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Certifiable reliability" and the purpose of SDI 
</A>
<DD>
<A HREF="#subj3.1">
Michael L. Scott
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Putting a man in the loop 
</A>
<DD>
<A HREF="#subj4.1">
Michael L. Scott
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  SDI Testing 
</A>
<DD>
<A HREF="#subj5.1">
Jim McGrath
</A><br>
<A HREF="#subj5.2">
 Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Dec. 85 IEEE TSE: Special Issue on Software Reliability--Part I 
</A>
<DD>
<A HREF="#subj6.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Masquerading 
</A>
<DD>
<A HREF="#subj7.1">
R. Michael Tague
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
PLEASE READ Weapons and Hope by Freeman Dyson.
</A>
</H3>
<address>
Peter Denning 
&lt;<A HREF="mailto:pjd@RIACS.ARPA">
pjd@RIACS.ARPA
</A>&gt;
</address>
<i>
Tue, 7 Jan 86 10:26:44 pst
</i><PRE>

A number of correspondents have brought up points analyzed in great detail
and with great clarity by Dyson in WEAPONS AND HOPE.  Examples:  Dyson
argues against building cases for or against particular defense systems by
counting the dead or the living.  The number who may survive or die is
incalculable and arguments based on such calculations are meaningless.
Dyson analyzes in some depth the fact that satellites are easy prey compared
to missiles.  His objections to Star Wars have little to do with the
technical points raised by most computer scientists.  They are based on an
analysis of many possible U.S. strategic strategies arrayed against Soviet
and other strategic strategies.  Dyson believes that there is a place for
nonnuclear ABMs in a nuclear free world, an argument that CPSR should
familiarize themselves with (CPSR has issued position statements against SDI
based on the premise that SDI is nothing more than an ABM system).  Dyson
argues that the ``soldiers'' are the ones to be won over to new pursuasions
about weaponry, which leads to the interesting conclusion that closer ties
between academic researchers and DoD middle managers would be beneficial,
rather than separation as now advocated by some academicians.  I recommend
that Risks Forum correspondents who wish to comment on weapons systems risks
begin by reading WEAPONS AND HOPE before entering the debate.  That way,
some new ground might get covered.

Peter Denning

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re:  <A HREF="/Risks/1.34.html">RISKS-1.34</A>, Wolves in the woods
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
6 Jan 1986 1032-PST (Monday)
</i><PRE>

Dave,

I'm sure you meant "shooting at wolves" rather than "shooting at woods"?

Jim H.

</PRE>
<HR><H3><A NAME="subj2.2">
Re:  <A HREF="/Risks/1.34.html">RISKS-1.34</A>, Wolves in the woods
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:vax-populi!dparnas@nrl-css.arpa ">
vax-populi!dparnas@nrl-css.arpa 
</A>&gt;
</address>
<i>
Mon, 6 Jan 86 13:06:20 pst
</i><PRE>

	I am glad that you are sure.  I did mean wolves and not woods.  I hope
that everyone else is sure too.  We aim for perfection but we don't do to vel.

Dave

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Certifiable reliability" and the purpose of SDI
</A>
</H3>
<address>
&lt;<A HREF="mailto:scott@rochester.arpa">
scott@rochester.arpa
</A>&gt;
</address>
<i>
Tue, 7 Jan 86 07:29:21 est
</i><PRE>

Jim McGrath's comments on reliability worry me quite a bit.  He seems to
understand, as do most of the technically literate, that there is no chance
of protecting population centers with enough certainty to eliminate the
Soviet incentive to own missiles.  Yet this is precisely what the public
thinks SDI is all about, and it is what our president proposed when he asked
us to make nuclear weapons "impotent and obsolete."

At the risks forum at last month's ACM SOSP, someone pointed out that one of
the most important responsibilities of a scientist or engineer is to MANAGE
THE CUSTOMER'S EXPECTATIONS.  It is both dishonest and EXTREMELY dangerous
to proceed with SDI research if we and the public have fundamentally
different understandings of the nature of that work.

It seems perfectly plausible to me that we could build space-based
installations that would disable enough incoming missiles to, say,
significantly increase the survivability of our own land-based defenses.
Such installations seem to be the most likely product of SDI research.  They
may or may not be a good idea on strategic, economic, political, or social
grounds.  Any decision to proceed with their development should be preceded
by public discussion and debate.  Unfortunately, current debate is being
focussed on the entirely different goal of omnipotent nuclear defense.  We
are marketing a product that we have no intention to deliver in order to
build a product that we did not want to market.

Michael L. Scott, University of Rochester  (716) 275-7745
scott@rochester.arpa         {decvax, allegra, seismo, cmcl2}!rochester!scott
scott%rochester@CSNET-RELAY

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Putting a Man in the Loop
</A>
</H3>
<address>
&lt;<A HREF="mailto:scott@rochester.arpa">
scott@rochester.arpa
</A>&gt;
</address>
<i>
Tue, 7 Jan 86 07:03:08 est
</i><PRE>

I find it remarkable that this suggestion is taken seriously.  Time scales
simply do not permit it.  As has been pointed out by previous contributors,
human intervention during boost phase is out of the question, since it's all
over in a minute or two.  But even for later phases of missile flight, it is
ridiculous to expect competent, cool-headed behavior from human operators
who 1) have presumably been watching their consoles for years with no
action, 2) have the fate of the world in their hands, and 3) have only a few
minutes in which to make their decisions.

Michael L. Scott

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: SDI Testing
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@LOTS-A">
J.JPM@LOTS-A
</A>&gt;
</address>
<i>
Mon 6 Jan 86 18:24:44-PST
</i><PRE>
To: "risks@sri-csl"@Sushi
cc: "horning@decwrl.DEC.COM"@Sushi

    From: horning@decwrl.DEC.COM (Jim Horning)
    Thanks for your comments. However, I do have to disagree with your
    cheerful assessment of the chances for REALISTIC testing of any
    SDI system or major subsystem. The problem is not that there is no
    testing that could be done, but that any substantial change in the
    system's environment is likely to provoke a new set of unexpected
    behaviors.... (Several very valid points are made about the
    difficulty of realistically testing SDI).

You are, of course, correct.  The problem is that your points could
also be (and are) made about any complex weapons systems (or indeed,
any complex system at all).  It is NEVER possible to fully test ANY
system until it is actually used in battle (and even then it can fail
in future battles).

While the size of SDI makes some testing problems harder, others may
be made easier.  Specifically, SDI operates in a far more predictable
environment that any earth based weapons system.  Enemy
countermeasures, so often cited as a problem, are a problem for ANY
battle system, and once again the possible modes of response by the
enemy need not be correlated to the size of the SDI system.  Thus I
would expect that a "realistic" (i.e. to a certain acceptable degree
of reliability) testing of the Aegis carrier defense system to be as
hard as testing SDI, even though the later is perhaps an order of
magnitude smaller than the former. (note that software and system
testing are not the same thing.)

My point was more that SDI (always excepting boost phase) could be
tested according to the same type of standards we currently use to
test other complex weapon systems (or computer systems, etc...).  That
is, the SDI testing problem is indeed a problem, but not one radically
different from those that have already been encountered (and
"solved"), or those likely to be encountered in the future.  Thus
attention should be focused on HOW to do the tests, not on decrying
that the testing problem is somehow inherently impossible to solve.

Jim [McGrath, that is]

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Testing SDI
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@LOTS-A">
J.JPM@LOTS-A
</A>&gt;
</address>
<i>
Mon 6 Jan 86 18:40:51-PST
</i><PRE>
To: "risks@sri-csl"@Sushi
cc: "horning@decwrl.DEC.COM"@Sushi, "vax-populi!dparnas@nrl-css.arpa"@Sushi

    From: vax-populi!dparnas@nrl-css.arpa (Dave Parnas)
    The comments that you reported on testing SDI, proposing that we
    test it by shooting at periodic meteor swarms make me wonder how
    many of the people in our profession have trouble discriminating
    between real problems and arcade games.  Shooting at an easily
    predictable non-evasive meteor has about the same relation to the
    real job of SDI as shooting at a target in a booth at a county
    fair has to shooting at woods in heavy brush from a moving
    airplane.

It is fairly obvious that Professor Parnes did not read my original
message, nor the follow up messages.  The original message dwelt on
the COST of testing, and used meteor swarms as a simple example, not a
serious proposal for exhaustive testing (as was clear in the context
of the message).  Indeed, I specifically stated that the example given
would be good primarily for a basic test of tracking and "hard kill"
capability.

Moreover, in more recent contributions I made clear that my central
point is that testing of SDI is not somehow impossible, if you accept
that we can test such systems as Aegis.  Particularly, I think it
incredibly naive to equate size of code with system complexity.  (see
my previous message on this).

Now, one can dispute that such systems as Aegis are testable.  Or one
can hold SDI to higher reliability standards than systems such as
Aegis.  Both are defendable positions.  But the first removes SDI from
some unique class, and the second is quite debatable (depending upon
your mission definition for each system).

Jim

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: SDI Testing
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
6 Jan 1986 1911-PST (Monday)
</i><PRE>

Jim,

If you think that I consider that the kind of testing that is done for
present weapons systems is acceptable for a system of the importance,
power, and risks of SDI, then we have been failing to communicate at a
very fundamental level.

The kind of risk that is acceptable for the loss of an aircraft carrier
and for the loss of all of human civilation are many orders of
magnitude apart. The complexity of SDI and Aegis (and hence the
difficulty of adequate testing) are many orders of magnitude apart. And
the military hasn't done so well at testing in the past (DIVAD, Bradley
Fighting Vehicle, plus the examples you cite) that I am willing to
trust them to decide what testing would suffice here.

I do not consider arcade games to be a suitable model for this
excercise.

Jim H.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Dec. IEEE TSE: Special Issue on Software Reliability--Part I
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
6 Jan 1986 1903-PST (Monday)
</i><PRE>

[This note is primarily for that small fraction of Risks that may not
be regular readers of IEEE Transactions on Software Engineering.  --Jim H.]

The December 1985 issue of TSE is devoted to software reliability. As
has been noted many times in this forum, unreliable software is one of
the principal sources of risks from computer systems.

A few things that caught my eye in this issue:

  "The occurrence of major software failures is strongly correlated with the
  type and level of workload prior to the occurrence of a failure.  This
  indicates that software reliability models cannot be considered
  representative unless the system workload environment is taken into account.
  The effect of workload on software reliability is highly nonlinear; i.e.,
  there is a threshold beyond which the software reliability rapidly
  deteriorates. ... Although we may intuitively expect to find a higher
  software error rate with higher workload (partly attributable to greater
  execution), there appears to be no fundamental reason why both software and
  hardware should exhibit a similar nonlinear increase in the load-hazard with
  increasing workload."

  "Recognizing the problem is only the first step; knowing what to do to
  achieve high confidence software still remains elusive. This is especially
  true in the area of software reliability, one of the prime factors affecting
  confidence (or lack of it) in software systems.  Current DOD development
  programs are unable to achieve satisfactory software reliability in a
  consistent fashion because of the lack of understanding of what conditions
  truly affect reliability. This situation is compounded when you consider
  that software reliability requirements for future DOD systems will be much
  higher as functional demands on the software become more complex, as
  criticality of the software increases and as system components become more
  distributed."

  "Abstract--When a new computer software package is developed and all
  obvious erros [sic] removed, a testing procedure is often put into
  effect to eliminate the remaining errors in the package."

  "Successful Missions ... Proportion of fault-tolerant runs which
  completed without failing: 56 percent; Proportion of nonfault-tolerant
  runs which completed without failing: 47 percent."

  "An intensity function, called the intensity of coincident errors, has
  a central role in this analysis. This function describes the propensity
  of programmers to introduce design faults in such a way that software
  components fail together when executing in the application environment.
  ... We study some differences between the coincident errors model ...
  and the model that assumes independent failures of component verions [sic].

  "Certain intensity functions can result in an N-version system, on
  average, being more prone to failure than a single software component.
  ... The effects of coincident errors, as a minimum, required an
  increase in the number of software components greater than would be
  predicted by calculations using the combinatorial method which assumes
  independence. ... It is clear we need empirical data to truly assess
  the effects of these errors on highly reliable software systems."

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re: Masquerading
</A>
</H3>
<address>
&lt;<A HREF="mailto: Tague@CISL-SERVICE-MULTICS.ARPA">
 Tague@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Mon, 6 Jan 86 11:39 MST
</i><PRE>
To:  Risks@SRI-CSL.ARPA

In Risks Volume 1 Issue 34 it was suggested that a "trusted path" could
be implemented by having trusted terminal driver software recognize "a
combination of keystrokes from the user that would be defined to mean
'enter trusted path'." I would like to suggest that if one were to
implement such a mechanism that one should make the "enter trusted path"
signal be a single keystroke, i.e., one character or the out-of-band
BREAK/ATTENTION key signal, not a "combination of keystrokes".

The reason is that it would be relatively easy for a malicious program
to interfere with a multi-character signal.  For example:  most
terminals can be made to send an answerback string to the host, a
program that is trying to not be defeated by an "enter trusted path"
signal could be constantly be sending answerback requests to the
terminal.  The terminal device driver would then not be able to
recognize the combination of keystrokes that make up the "enter trusted
path" signal due to the interleaving of answerback messages.

I suggest to anyone implementing such a trusted path mechanism that they
use the out-of-band BREAK/ATTENTION key signal for the "enter trusted
path" signal so that the user and applications will still have the full
character set to work with.  Whatever character/signal is used one
should not be able to change or disable it.

                              Tague@CISL

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-46</DOCNO>
<DOCOLDNO>IA012-000128-B043-293</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.37.html 128.240.150.127 19970217001211 text/html 19018
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:10:38 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 37</TITLE>
<LINK REL="Prev" HREF="/Risks/1.36.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.38.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 37</H1>
<H2> Thursday, 9 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
IEEE TSE Special Issue on Reliability -- Part 1 
</A>
<DD>
<A HREF="#subj1.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  SDI Testing 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<A HREF="#subj2.2">
 Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Multiple redundancy 
</A>
<DD>
<A HREF="#subj3.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  On Freeman Dyson 
</A>
<DD>
<A HREF="#subj4.1">
Gary Chapman
</A><br>
<A HREF="#subj4.2">
 Jon Jacky
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re:  IEEE TSE Special Issue on Reliability -- Part 1
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@ICSD.UCI.EDU">
nancy@ICSD.UCI.EDU
</A>&gt;
</address>
<i>
07 Jan 86 19:54:29 PST (Tue)
</i><PRE>

With regard to the note by Jim Horning about the special issue of IEEE TSE
on Software Engineering - Part 1.  He cites the following:

  "An intensity function, called the intensity of coincident errors, has
  a central role in this analysis. This function describes the propensity
  of programmers to introduce design faults in such a way that software
  components fail together when executing in the application environment.
  ... We study some differences between the coincident errors model ...
  and the model that assumes independent failures of component verions [sic].

  "Certain intensity functions can result in an N-version system, on
  average, being more prone to failure than a single software component.
  ... The effects of coincident errors, as a minimum, required an
  increase in the number of software components greater than would be
  predicted by calculations using the combinatorial method which assumes
  independence. ... It is clear we need empirical data to truly assess
  the effects of these errors on highly reliable software systems."

Jim, in the next issue of TSE (part 2 of the special issue on software
reliability) my paper with John Knight appears in which we describe our
experiment (involving 27 programmers and two universities) which provides
some of this empirical data.  We found that independently produced software
showed much higher coincident failures than would be expected assuming
statistical independence.  In later papers which have looked at the actual
bugs (faults) in the software which was produced in the experiment, we found
that people tended to make very similar mistakes or, at the least, to make
mistakes on the same hard parts of the problem which lead to the programs
failing on the same input data.  In summary, our data supports the use of
the coincident errors model rather than the independent failures model.  The
first paper on this will appear in February, two others are still in
preparation or review.

All experimental evidence that I have seen to date does not support the
conclusion that software with ultra-high reliability can be achieved by
producing independent versions and voting the results although some
reliability improvement may be possible.  The question is whether enough is
gained to justify the enormous added cost.  Or whether the money and
resources could better be spent in other ways.

We are just about to start another experiment which will attempt to get some
data on whether people are able to write self-test statements (acceptance
tests, assertions, exceptional conditions) which will detect errors at
execution time.  We will then be able to compare this type of fault
detection with voting.

Nancy Leveson
University of California, Irvine

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
SDI Testing
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@ICSD.UCI.EDU">
nancy@ICSD.UCI.EDU
</A>&gt;
</address>
<i>
07 Jan 86 20:19:06 PST (Tue)
</i><PRE>

   &gt;From: Jim McGrath &lt;J.JPM@LOTS-A&gt;
   &gt;I would expect that a "realistic" (i.e. to a certain acceptable degree
   &gt;of reliability) testing of the Aegis carrier defense system to be as
   &gt;hard as testing SDI, even though the later is perhaps an order of
   &gt;magnitude smaller than the former. (note that software and system
   &gt;testing are not the same thing.)

After speaking to some of the people working on Aegis, I would not use
that as an example of a reliable system.  I have heard that Aegis is anything
but reliable.  What is your source that shows it is highly reliable?  

You seem to imply that because we have a system and it has been 
tested that it is reliable.  Unfortunately, my experience has not
supported this hypothesis.  There are some that have argued that our
current ABM and early warning systems are so complex that there is very
little chance that they will ever work if so called upon.  For example,
in "Normal Accidents:  Living With High Risk Technology" by Charles
Perrow, he states about our current launch-on-warning systems:
  "...if there were a true warning that the Russian missiles were coming,
   it looks as if it would be nearly impossible for there to be an intended
   launch, so complex and prone to failure is this system.  It is an 
   interesting case to reflect upon: at some point does the complexity
   of a system and its coupling become so enormous that a system no longer
   exists?  Since our ballistic weapons system has never been called upon
   to perform (it cannot even be tested), we cannot be sure that it really
   constitutes a viable system.  It just may collapse in confusion!"
   [Perrow, pg. 257-258]

It does not seem to be a very convincing argument that SDI can be tested
by citing other systems which have been tested but never used enough to
measure their reliability.  How do we know how effective that testing
has been?  If you could give me a system which exists, is equivalent, AND
has been in use enough to have good information on its reliability,
then I would have to listen to you.

     &gt;My point was more that SDI (always excepting boost phase) could be
     &gt;tested according to the same type of standards we currently use to
     &gt;test other complex weapon systems (or computer systems, etc...).  That
     &gt;is, the SDI testing problem is indeed a problem, but not one radically
     &gt;different from those that have already been encountered (and
     &gt;"solved"), or those likely to be encountered in the future.  

If you have information on the solution to the testing (i.e. software
reliability) problem, please tell me.  I could make a fortune because
no one I know of seems to know that it has been solved or knows the
solution.  I have been involved in research in the area of software reliability
and safety for many years because I thought it was an unsolved problem.   
Could you provide some references to the solution? (I will split my first 
million dollars in consulting fees with you.)

     &gt;Moreover, in more recent contributions I made clear that my central
     &gt;point is that testing of SDI is not somehow impossible, if you accept
     &gt;that we can test such systems as Aegis.  Particularly, I think it
     &gt;incredibly naive to equate size of code with system complexity.  (see
     &gt;my previous message on this).

Of course you can test any system.  That is not the point.  The question
is whether the testing is complete and effective.  For that, we need to
know not whether Aegis was tested, but what is the reliability of Aegis.

     &gt;Now, one can dispute that such systems as Aegis are testable.  Or one
     &gt;can hold SDI to higher reliability standards than systems such as
     &gt;Aegis.  Both are defendable positions.  But the first removes SDI from
     &gt;some unique class, and the second is quite debatable (depending upon
     &gt;your mission definition for each system).

I can believe that Aegis is not testable without removing SDI from the unique
class.  I don't understand your logic -- one has nothing to do with the
other.  No one is arguing that SDI is unique solely because it is
untestable.  Most complex software systems can not be made ultra-reliable
using our current technology and, more important, there is no known way
to verify or measure that these systems are ultra-reliable even if they
are.  That does not mean that they do not involve unique problems or 
that they are of equal difficulty to build.  They may all have
different reliability -- but none of them can be proven to be ultra-reliable.

Moreover, I am not concerned about holding SDI to higher reliability
standards than systems such as Aegis or others.  I am concerned about just
meeting those standards.  My work is in the area of safety-critical systems 
where reliability requirements range from 10^(-5) to 10^(-9).  There exist
no current software technologies which will guarantee that the software
meets these requirements or can be used to accurately measure software
reliability in this range.

Nancy Leveson
University of California, Irvine

</PRE>
<HR><H3><A NAME="subj2.2">
SDI Testing
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:vax-populi!dparnas@nrl-css.arpa ">
vax-populi!dparnas@nrl-css.arpa 
</A>&gt;
</address>
<i>
Tue, 7 Jan 86 17:40:32 pst
</i><PRE>

	I regret that I gave Jim McGrath the impression that I had not read
his many submissions to RISKS before I responded to his suggestion that 
meteors could be used to test SDI-like systems.  I wish to assure him
that I had read them twice.  

	Given the importance of discrimination between legitimate warheads
and decoys in a "Star Wars" battle, I would consider the defensive system
to have failed if it fired at meteors.  The capability to shoot down 
meteors could be considered, by normal engineering standards, an overdesign
as well.

	It is a mistake to consider "testable" as a predicate.  Some
systems are easy to test, others are hard to test.  Systems like Aegis
are difficult to test, but SDI would be more difficult.  Further, the 
SDI requirements are stricter.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Multiple redundancy
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!henry@ucbvax.berkeley.edu">
ihnp4!utzoo!henry@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
Thu, 9 Jan 86 12:14:34 PST
</i><PRE>

Advocates of multiple redundancy through independently-written software
doing the same job might be interested in an incident involving complete
failure of such a scheme.

During the development of the De Havilland Victor jet bomber, roughly a
contemporary of the B-52, the designers were concerned about possible
problems with the unusual tailplane design.  They were particularly
worried about "flutter" -- a positive feedback loop between slightly-flexible
structures and the airflow around them, dangerous when the frequency of the
resulting oscillation matches a resonant frequency of the structure.  So
they tested for tailplane flutter very carefully:

	1. A specially-built wind-tunnel model was used to investigate the
	flutter behavior.  (Because one cannot scale down the fluid properties
	of the atmosphere, a simple scale model of the aircraft isn't good
	enough to check on subtle problems -- the model must be carefully
	built to answer a specific question.)

	2. Resonance tests were run on the first prototype before it flew,
	with the results cranked into aerodynamic equations.

	3. Early flight tests included some tests whose results could be
	extrapolated to reveal flutter behavior.  (Flutter is sensitive to
	speed, so low-speed tests could be run safely.)

All three methods produced similar answers, agreeing that there was no
flutter problem in the tailplane at any speed the aircraft could reach.

Somewhat later, when the first prototype was doing high-speed low-altitude
passes over an airbase for instrument calibration, the tailplane broke off.
The aircraft crashed instantly, killing the entire crew.  A long investigation
finally discovered what happened:

	1. The stiffness of a crucial part in the wind-tunnel flutter model
	was wrong.

	2. One term in the aerodynamic equations had been put in wrongly.

	3. The flight-test results involved some tricky problems of data
	interpretation, and the engineers had been misled.

And by sheer bad luck, all three wrong answers were roughly the same number.

Reference:  Bill Gunston, "Bombers of the West", Ian Allen 1977(?).

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,linus,decvax}!utzoo!henry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Reply to Dr. Denning on Freeman Dyson
</A>
</H3>
<address>
Gary Chapman 
&lt;<A HREF="mailto:PARC-CSLI!chapman@glacier">
PARC-CSLI!chapman@glacier
</A>&gt;
</address>
<i>
Tue, 7 Jan 86 18:07:26 pst
</i><PRE>
To: glacier!RISKS@SRI-CSL.ARPA

I have considered Dr. Peter Denning's thoughts on strategic defense with
some care, and I have appreciated the thought he has put into the issue.  I
also have a great deal of respect for Freeman Dyson, whose book, Weapons and
Hope, Dr.  Denning recommended we all read, and particularly those of
connected with the policies of CPSR.

I would like to respond to some of those comments.  First, the concept of an
anti-ballistic missile defense in a "non-nuclear" world is contradictory.  If
nuclear weapons and ICBMs have been eliminated, there is no need for an ABM
system with all its expense and uncertainties.  Dr. Dyson says in his book that
he favors a strategic defense only after a radical cut in offensive nuclear
weapons on both sides.  Very few critics of the SDI would quarrel with this,
including me.  But we are so far from the kind of cuts that Dr. Dyson and Dr.
Sidney Drell, who also favors this goal, feel are required before strategic
defense is considered that it is hardly worth considering at all at this point.
It is particularly dangerous to consider upsetting the strategic balance by
developing and deploying a strategic defense before those cuts are made.

What CPSR has said is that the software problems inherent in the development
of an SDI-type ABM battle management system contribute to strategic
instability, and therefore the deployment of the SDI will leave us worse off
than without it.  An ABM system that is deployed AFTER achievement of
substantial and trustworthy strategic stability would not have the same
mission as the SDI.  It would be an added insurance of a stability already
achieved by other means, it would be a safeguard against ICBM accidents and
against third-party powers.  It would not be a radical change in the
strategic balance the way the SDI would be if it were to be deployed in the
current strategic situation.

Despite the good will of the President and his honorable intentions, the SDI is
clearly a war-fighting program.  I have never gotten the impression from Dr.
Dyson that he is in favor of such an effort.  CPSR has opposed the SDI for the
program that it is, not for the program that it could be.

						Gary Chapman
						Executive Director, CPSR

</PRE>
<HR><H3><A NAME="subj4.2">
Peter Denning on WEAPONS AND HOPE
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@uw-june.arpa ">
jon@uw-june.arpa 
</A>&gt;
</address>
<i>
Wed, 8 Jan 86 20:56:23 PST
</i><PRE>

&gt; (Peter Denning writes: )
&gt; ...CPSR has issued position statements against SDI based on the premise that
&gt; SDI is nothing more than an ABM system...

I think the point of those statements was that systems with limited 
capabilities, such as defense of hardened missile silos, fall far short of
the sort of comprehensive defense implied by the SDI's stated goal of 
"eliminating the threat posed by nuclear ballistic missiles." 

&gt; Dyson argues that the 'soldiers' are the ones to be won over to new 
&gt; pursuasions about weaponry, which leads to the interesting conclusion
&gt; that closer ties between academic researchers and DoD middle managers
&gt; would be beneficial, rather than separation as now advocated by some 
&gt; academicians.

I am not aware of any academicians who say that soldiers and scholars should
not try to understand each other.  Some do argue that developing capabilities 
for future weapons systems should not be the primary motivation for funding
scholarly research, and that it is incorrect to portray such projects as 
basic research.

Jonathan Jacky

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-47</DOCNO>
<DOCOLDNO>IA012-000128-B043-318</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.38.html 128.240.150.127 19970217001224 text/html 16871
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:10:52 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 38</TITLE>
<LINK REL="Prev" HREF="/Risks/1.37.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.39.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 38</H1>
<H2> Friday, 10 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Ad-hominem SDI discussion 
</A>
<DD>
<A HREF="#subj1.1">
Mike McLaughlin [and Peter Neumann]
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Men in the loop 
</A>
<DD>
<A HREF="#subj2.1">
Martin J. Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Failure probabilities in decision chains 
</A>
<DD>
<A HREF="#subj3.1">
Jim Miller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Testing SDI 
</A>
<DD>
<A HREF="#subj4.1">
Karl Kluge
</A><br>
<A HREF="#subj4.2">
 Robert Goldman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Summing Up on SDI 
</A>
<DD>
<A HREF="#subj5.1">
Jim McGrath
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Ad-hominem SDI discussion
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Wed, 8 Jan 86 05:48:49 est
</i><PRE>

I note with dismay the ad-hominem phraseology that is appearing in the 
SDI discussions.  It is understandable but unacceptable.  The issue is 
too important.  I request that the participants review their inputs 
prior to submission, and edit out phraseology that is not relevant to 
the issue.  It is not fair to expect the forum's moderator to be a 
censor.  - Mike McLaughlin                                 [Thanks.  PGN]
 
     [I have received various complaints about some of the recent SDI
      verbiage -- its quality, accuracy, relevance to RISKS, what right has
      RISKS to distribute SRI discussion when it should be in ARMS-D, etc.
      In general, I have to hope that our contributors exert some good sense.
      Some of the nit-picking should clearly be resolved privately.  In some
      cases I might request two antagonists get together and write a single
      position statement to which they both agree -- but that seldom works.

      So, at this point I would like to elevate the quality of SDI
      discussion -- but not to stifle meaningful discussion that is really
      RISKS-related.  SDI remains one of the most important issues
      confronting us, and open &lt;but informed&gt; discussion of the computer
      risks therein is clearly vital.  

      This issue omits a bunch of further McGrath-Lin discussions, but
      I point out above they can be found in ARMS-D or in the &lt;RISKS&gt; 
      directory.  PGN]

----------------------------------------------------------------------

Date: 0  0 00:00:00 CDT
From: "MARTIN J. MOORE" &lt;mooremj@eglin-vax&gt;
Subject: Men in the loop
To: "risks" &lt;risks@sri-csl&gt;

Talking about men in the loop for SDI:

&gt; From: scott@rochester.arpa
&gt; I find it remarkable that this suggestion is taken seriously.  Time scales
&gt; simply do not permit it.  

There are at least several minutes in which to respond.  While this is
certainly too short for any chain-of-command processing, I believe (for
reasons which are detailed below) that it is plenty of time for a trained
individual, responsible for a single battlestation (or a jointly commanded
small group of battlestations) to respond. 

&gt; As has been pointed out by previous contributors, human intervention during
&gt; boost phase is out of the question, since it's all over in a minute or two. 

For SLBMs, or missiles aimed at Europe from the western Soviet Union, I'll 
grant the point.  But for land-launched missiles aimed at the US, I estimate
at least a five-minute boost.  If this is wrong, someone please correct me! 

&gt; But even for later phases of missile flight, it is ridiculous to expect
&gt; competent, cool-headed behavior from human operators who 1) have presumably
&gt; been watching their consoles for years with no action, ...

No real action...but plenty of simulated action designed to train that
operator to make the correct response almost automatically.  For several years
I had the privilege(?) of observing the training of Range Safety Officers at
Cape Canaveral.  These officers monitor the launch of a missile in real time,
and if the missile endangers a populated area, they destroy it.  Of course, if
that missile is a Space Shuttle, they would either destroy the Shuttle and its
flight crew...or they would fail to destroy it and possibly kill several
thousand bystanders.  I would not like to have that job!  One of the RSOs is
selected as the Training Officer on a rotating basis.  He sets up launch
simulations, realistic in every detail, to train his fellow officers.  In
addition to the missile going awry, various equipment failures, communication
outages, etc., are thrown at the officers during some simulations; other
simulations are completely nominal.  Some of the simulations I've seen were
much, much rougher than the worst actual launch.  On the very rare occasions
when a flight termination has been necessary, it has been handled cooly and
correctly. 

I'll save someone the trouble of pointing out that there has never yet been 
a termination of a manned launch.  This is true.  But I believe, based on 
my observations, that even in this case the Range Safety Officers would make
the correct decision -- and make it fast. 

&gt; ... 2) have the fate of the world in their hands, ...

This will slow them down?  I think it would make them most conscious of the 
need for timely action.  If you are suggesting that the responsibility would 
be too great, and the operator would freeze up...I suppose it's possible, but
I doubt such a person would be in the job in the first place. 

&gt; ... and 3) have only a few minutes in which to make their decisions.

Ten minutes is a long time.  In the early stages of a missile launch from
the Cape, the missile is perhaps ten seconds from impact in Cocoa Beach.  
There, the men in the loop have worked very well; when they've had to throw
the switches, they've done it well before those seconds ticked away.  No
missiles in Cocoa Beach yet!  (Lest someone mention the famous incident early
in the Cape's history when a missile impacted in the Banana River just
offshore from a trailer park -- that missile did not carry a destruct
device...it was the last missile launched at the Cape not to carry one.) 

Generally speaking, until the day when a computer system can be made 100%
reliable (not just 99.999...9%), I strongly believe that *any* system capable
of causing harm to human life must have a man in the loop.  He may do no more
than press a YES/NO switch when the computer selects an action, but he *must*
be there.  This transcends SDI or any other weapons system...it applies
generally!

These views are strictly my own and do not necessarily agree with those of my 
employer or any of its customers.

                                    Martin J. Moore
                                    mooremj@eglin-vax.arpa

----------------------------------------------------------------------

Date: Wed 8 Jan 86 15:37:24-CST
From: Jim Miller &lt;HI.JMILLER@MCC.ARPA&gt;
Subject: Re: Failure probabilities in decision chains
To: wmartin@BRL.ARPA
cc: Soft-Eng@MIT-XX.ARPA, Risks@SRI-CSL.ARPA, walsh@ALMSA-1.ARPA
US-Mail: MCC, Human Interface Program, 9430 Research, Austin TX 78759 
Phone:   512-834-3342

Well, if you assume that each decision has a 90% likelihood of being
correct (or, a 10% chance of being wrong), and that all of the five
decisions are independent of each other, and all that other
statistical stuff, then the probability that all five decisions will
be correct is .9^5, or .59.  However, how you would go about
determining in a real-life situation what the actual probabilities of
those decisions being correct really are, or whether the decisions are
really independent, is beyond me.  This sounds like one of those
statistics that people love to quote, regardless of whether it has any
validity.

Jim Miller
MCC Human Interface

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Testing: Differences between SDI and other systems.
</A>
</H3>
<address>
&lt;<A HREF="mailto:Karl.Kluge@G.CS.CMU.EDU">
Karl.Kluge@G.CS.CMU.EDU
</A>&gt;
</address>
<i>
7 Jan 1986 22:41-EST
</i><PRE>
Message-Id: &lt;505539701/kck@G.CS.CMU.EDU&gt;

&gt; Date: Mon 6 Jan 86 18:24:44-PST
&gt; From: Jim McGrath &lt;J.JPM@LOTS-A&gt;
&gt; 
&gt; You are, of course, correct.  The problem is that your points could
&gt; also be (and are) made about any complex weapons systems (or indeed,
&gt; any complex system at all).  It is NEVER possible to fully test ANY
&gt; system until it is actually used in battle (and even then it can fail
&gt; in future battles).

1) The consequences of failure of an SDI system are orders of magnitude
   greater than the consequences of failure of a "normal" weapons system.
   We damn well should be orders of magnitude more confident in it.

2) Which is really irrelevant, since the function of the SDI is to enhance
   deterrence, not replace it. The SDI system doesn't have to work, it just
   has to create reasonable worry that it might work in the mind of a potent-
   ial attacker. This makes it different from most systems, which are built
   to be used. If the SDI system ever has to be used then it has failed, 
   which means...

(* rest of message on ARMS-D.  Karl *)  [THANKS... PGN]

My opinion, of course, in no way reflects the opinion of anyone I'm
associated with.  Karl

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Testing SDI
</A>
</H3>
<address>
    Robert Goldman 
&lt;<A HREF="mailto:rpg%brown.csnet@CSNET-RELAY.ARPA">
rpg%brown.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
8 Jan 86 (Wed) 15:26:18 EST
</i><PRE>

In <A HREF="/Risks/1.34.html">RISKS-1.34</A> Jim McGrath discusses testing the SDI.  A common objection to
the SDI is that it could not realistically be tested.  

McGrath correctly points out that this is true of any modern weapon system.
I agree with this basic point, but of course, some weapons systems are
easier to test than others.  For example, Mr. McGrath points out

	it took WWI for the Germans to realize that the
	lessons of the 1880's concerning rapid infantry fire (and thus the
	rise of infantry over calvary) did not take artillery development
	adequately into account
This is correct, but dodges the point that at that time, modern artillery,
rifles and machine guns HAD all been fired in anger.  The almost universal
inability to profit from the experience was due to institutional failures,
rather than lack of raw data.

I need hardly point out that ICBMs and SLBMs have NOT been tested in wartime
conditions, and that we have reason to believe that there won't be a second
chance to correct any mistakes.

Mr. McGrath goes on to suggest that the SDI might be tested against meteor
storms.  I question this for three reasons:
1.  As I understand it, the particle-beam weapons of the SDI are not
intended to destroy warheads outright, but rather prevent them from reaching
their targets and detonating.  How would one judge that a meteorite's fusing
and guidance mechanisms had been destroyed?
2.  Meteorites are not human-made objects which are designed with an eye to
penetrating enemy defenses:  they do not drop chaff, employ electronic
counter-measures, etc.
3.  Meteorites have a wholly different flight pattern.  As I understand it,
ICBMs have a boost phase, a cruising phase and a re-entry phase.  Doesn't a
missile's detectability and vulnerability depend on which of these phases it
is in?
					Robert Goldman

     [I deleted a paragraph on what might happen "if the SDI accidentally
      (or on purpose) shot down a Soviet reconnaissance satellite?"  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Summing Up on SDI
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@Epic">
J.JPM@Epic
</A>&gt;
</address>
<i>
Thu 9 Jan 86 22:45:57-PST
</i><PRE>
To: "risks@sri-csl"@Sushi
Reply-to: mcgrath%mit-oz@mit-mc.arpa

        [Reminder: I have omitted a bunch of McGrath-Lin messages.  
         If you wish to read them, see aove.  PGN]

From all these messages, I've come to two conclusions.  First, that on
the whole, I tend to feel that SDI is a more complex system (mainly
because of its mission size) than existing ones, such as Aegis.  But I
could be wrong (either way).  And I do not believe that it is "orders
of magnitude" more complex than existing systems.  Thus it would seem
that it could be built to existing system performance standards.

The second question is whether these standards are "adequate," and if
not can we improve upon them?  It is clear that existing systems are
not being tested as fully as possible (Herb Lin's report on the Aegis
tests makes them appear to be a joke).  I've already pointed out that
substantial testing of mid-course and terminal phases, far more
extensive testing than any of our other systems have received, can be
carried out.  Thus, provided we have a proper commitment, even our
current testing technology can be better applied (with better results)
than we have done up until now.

To a large extent the standard you require depends upon your
definition of the mission of the system.  Clearly the system was never
designed to make OUR nuclear weapons obsolete (just the Soviet's).  So
under any mission we would probably retain a force sufficient to
destroy the USSR, and so can always fall back on MAD.  Any reasonable
performance level would protect our weapons to a significant extent
(and if not, you can always keep a sub force).  So the real question
is whether it can protect cities.

I would tend to doubt it, under a full and unimpeded Soviet attack.
But there are many scenarios (from accidental launch to a limited
(decapitation or counterforce) strike to a second strike (the first
perhaps going to Europe and/or China)) where it quite possibly could.

In any event, I am certainly not sure enough to either commit to SDI
deployment nor to terminate research.  Since all SDI is at the moment
is research, I have no problem with the existing program.  Still,
knowing how programs have a tendency to outlive their usefulness, I
think strong scrutiny is appropriate.  But not mindless opposition.

Jim

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-48</DOCNO>
<DOCOLDNO>IA012-000128-B043-333</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.39.html 128.240.150.127 19970217001233 text/html 8744
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:11:04 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 39</TITLE>
<LINK REL="Prev" HREF="/Risks/1.38.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.40.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 39</H1>
<H2> Monday, 13 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Real-time responsibility 
</A>
<DD>
<A HREF="#subj1.1">
Dave Wade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Big Brother 
</A>
<DD>
<A HREF="#subj2.1">
Jim McGrath
</A><br>
<A HREF="#subj2.2">
 Peter Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Men in the SDI loop 
</A>
<DD>
<A HREF="#subj3.1">
Herb Lin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Real-time responsibility 
</A>
</H3>
<address>
Dave Wade
&lt;<A HREF="mailto:djw%a@LANL.ARPA ">
djw%a@LANL.ARPA 
</A>&gt;
</address>
<i>
Fri, 10 Jan 86 14:38:54 mst
</i><PRE>

I am just a programmer; however, for three and a half years I worked
at CTR Division here at Los Alamos.  I augmented ( in a very minor way, )
and maintained the control system for a series of Magnetic Fusion Energy
experiments.  

The programs ran in "real time" and attempted to use magnets to "contain" and
shape a plasma.  The plasma is very like the ball of gas in your neon light
over your desk, but instead of neon, we used a vacuum and a tiny amount of
sulfur-hex... ( that same stuff that was in the tank in Oklahoma that the
workmen dropped because it was overfull ).  The plasma is started by
discharging a huge arc across a quartz bottle that contains the vacuum and
the sulphur-hex.  The computer controls the point at which huge capacitors
discharge through the quartz bottle.  There are many independent power
supplies that discharge through different portions of the quartz bottle.
The computer program controls "precisely" when each power supply or
capacitor bank discharges into the quartz tube.  These power supplies/
capacitor banks are placed by the physicists such that the ball of
lightning ( plasma ) formed inside the quartz tube is kept from touching
the inside of the tube.  The power supplies form a magnetic bottle inside
the quartz tube ( the quartz tube is about 14 inches across, ) and under
computer control have kept the plasma alive and away from the edge of the
14 inch wide tube for more that 3/100 ths of a second.  Now the tube has
been made about twenty feet long and the ball of plasma has been created,
stabilized, and then slowly ( different time frame ) moved to the other
end of the tube;  controlled by a Pr1me 300 ( I'd guess that is about the
same as any of the 68000-based micros ).  The Pr1me did all of this stuff
remotely over a fiber-optic CAMAC highway.

The point of this was that any failure of the control system was capable
of killing personnel.  The "man in the loop" who was running the control
system was not necessarily knowledgeable about what he was controlling
( sometimes this was me... ).  The software was much smarter than the
operator and certainly swifter.  There is no way that I could hit the
"kill" switch before the plasma got loose.  The "kill" switch was used
as a mechanical lockout ( in conjunction with the software lockout and
the "key switch" we had installed ) while we were testing the control
system.

I sit here and am bored by endless arguments on Unix "news" that the
Strategic Defense Initiative contains portions which "can't be
programmed" because they have this or that seemingly insurmountable
characteristic.  I look at my friends MacIntosh and think fondly of the
days when I helped with the payroll and accounting for a 2000 person
company on an IBM 1411 which wasn't the machine that the Mac is...  What
may be "impossible" for me is resting forgotten in one of the software
libraries down the hall.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Big Brother
</A>
</H3>
<address>
Jim McGrath 
&lt;<A HREF="mailto:J.JPM@Epic">
J.JPM@Epic
</A>&gt;
</address>
<i>
Wed 8 Jan 86 19:53:41-PST
</i><PRE>
To: "risks@sri-csl"@Sushi
Reply-to: mcgrath%mit-oz@mit-mc.arpa

Has anyone noticed the proposals made in the article "Security Without
Identification: Transaction Systems to Make Big Brother Obsolete" by David
Chaum in the October issue of Communications of the ACM (vol 28, # 10,
10330-1044)?  If so, what is the response?  Basically, he asserts that it
would be in the interests of both individuals and organizations to adopt a
system whereby transactions would be essentially unforgeable and untraceable.

Jim

</PRE>
<HR><H3><A NAME="subj2.2">
Re: Big Brother
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Thu 9 Jan 86 21:34:07-PST
</i><PRE>
To: mcgrath%mit-oz@MIT-MC.ARPA

What you suggest might indeed be an improvement.  However, remember that
nothing is guaranteed unforgeable.  You will always have some points of
vulnerability, and you have risks of spoofing, clever system programmers,
embedded Trojan horses in hardware and software, etc.

If you were to rely blindly on such a system, you would be making yourself
even more vulnerable!  You can indeed come closer to having an unforgeable
communication, but believing that you have it may actually increase the risk.

Peter

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
  Men in the SDI loop
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 11 Jan 86 17:54:43 EST
</i><PRE>
To: mooremj@EGLIN-VAX.ARPA
cc: LIN@MC.LCS.MIT.EDU, risks@SRI-CSL.ARPA

    &gt; As has been pointed out by previous contributors, human
      intervention during
    &gt; boost phase is out of the question, since it's all over in a
      minute or two. 

    From: mooremj@eglin-vax

    For SLBMs, or missiles aimed at Europe from the western Soviet Union, I'll 
    grant the point.  But for land-launched missiles aimed at the US, 
    I estimate
    at least a five-minute boost.  If this is wrong, someone please
    correct me! 

Currently, the SS-18 has boost phase of about 5 minutes = 300 sec.  MX
has a boost phase of 180 sec.  Probably 120 sec boost isn't impossible
if you really tried to do it (as the Sovs will undoubtedly do if we
ever deploy SDI).  Indeed, the US is studying fast burn boosters even
as I write this.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-49</DOCNO>
<DOCOLDNO>IA012-000128-B043-351</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.40.html 128.240.150.127 19970217001243 text/html 10663
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:11:14 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 40</TITLE>
<LINK REL="Prev" HREF="/Risks/1.39.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.41.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.39.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.41.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 40</H1>
<H2> Friday, 17 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Big Brother 
</A>
<DD>
<A HREF="#subj1.1">
Jim Ziobro
</A><br>
<A HREF="#subj1.2">
 Keith Lynch
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Multiple redundancy 
</A>
<DD>
<A HREF="#subj2.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  COMPASS 86: System Integrity: Process Security and Safety 
</A>
<DD>
<A HREF="#subj3.1">
Al Friend
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Big Brother (Chaum's articel, CACM vol 28, #10, 1030-1044)
</A>
</H3>
<address>
Jim Ziobro
&lt;<A HREF="mailto:rocksvax!z@rochester.arpa ">
rocksvax!z@rochester.arpa 
</A>&gt;
</address>
<i>
Fri, 17 Jan 86 13:39:48 est
</i><PRE>

I believe the point of Chaum's article was to show how computer technology
might prevent invasions of privacy by unauthorized parties.  He did not give
specific algorithms.  The challenge is now to develop secure algorithms and
to get public acceptance.  All in all I thought it was a very good article.

As PGN points out, a completely secure algorithm is impossible.  But
all we really need do is get one that is better than our current coupon
system.  How secure is our coupon system (Dollars and coins)?  Well at least
one person in Xerox can make money (given the proper paper) that will fool
most of the population.  A friend in printing says that passable money is
quite easy to do but this particular individual had better things to do with
his time.

The privacy of currency is hard to beat.  But already many people prefer
credit cards to the vulnerability of cash.  In that case they trade off
security for allowing nearly anyone at their bank to see where they shop
and how much they spend.  People are also willing to spend the $20/year
for the credentials/security that credit cards offer.

I think public acceptance increases by one everytime someone receives a
false transaction on their credit card or even when their Social Security
check is stolen in the mail.  At that rate Chaum's vision of the future
may be with us before 2000.

//Z\\
James M. Ziobro
Ziobro.Henr@Xerox.ARPA
{rochester,amd,sunybcs,ihnp4}!rocksvax!z

</PRE>
<HR><H3><A NAME="subj1.2">
Big Brother
</A>
</H3>
<address>
"Keith F. Lynch" 
&lt;<A HREF="mailto:KFL@MC.LCS.MIT.EDU">
KFL@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 13 Jan 86 21:33:27 EST
</i><PRE>
To: mcgrath@OZ.AI.MIT.EDU
cc: KFL@MC.LCS.MIT.EDU, &lt;RISKS@SRI-CSL.ARPA

    Date: Wed 8 Jan 86 19:53:41-PST
    From: Jim McGrath &lt;J.JPM@Epic&gt;

    ... David Chaum ... asserts that it
    would be in the interests of both individuals and organizations to adopt a
    system whereby transactions would be essentially unforgeable and
    untraceable.

  I agree that this would be great.  I doubt that it will happen.  The
character of people in government today is very different from 200
years ago.  It is obvious that the signers of the constitution would
have extended their protections of papers and places to computer files
and disks, had they heard of such things.  Confiscation of CBBS
computers is just as wrong as confiscation of printing presses.
'Fairness' rules concerning radio and TV are just as unreasonable as
similar rules concerning newspapers and magazines would be.  The only
reason why the printed media get preferred treatment is that they were
explicitly mentioned in the constitution.  Had radio, TV, electronic
funds transfer systems, and telephones been around in the days of
Jefferson and Washington, I am sure that they would enjoy similar
constitutional protection.
  There are many good reasons why it is in the government's interest
to be able to track each individual's finances, phone usage,
electronic mail usage, etc.  Mainly to fight crime, especially the new
bugaboo of terrorism.  But this same reasoning could have been used by
the writers of the constitution, but it wasn't.  It was believed that
the benefits of having a free society outweighed the problems of some
people abusing these freedoms.  Two hundred years later, comparing our
country with countries that made the opposite decision, I think we did
the right thing.
  I believe that this is probably the greatest risk of computers.
That by phasing out the media that are mentioned in the constitution,
that we are also phasing out the protections long enjoyed by their
users.
								...Keith

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Multiple redundancy
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!henry@ucbvax.berkeley.edu">
ihnp4!utzoo!henry@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
Mon, 13 Jan 86 19:49:18 PST
</i><PRE>

A correction and an addendum to my earlier contribution about multiple
redundancy...

Correction:  It was not the "De Havilland Victor" but the "Handley Page
Victor".  Blush.  That's like calling Boeing "McDonnell Douglas".

Addendum:  The full reference is  Bill Gunston, "Bombers of the West",
Ian Allan, London 1973, page 92.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,linus,decvax}!utzoo!henry

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
COMPASS 86 Call for Papers
</A>
</H3>
<address>
Al Friend
&lt;<A HREF="mailto:friend@nrl-csr ">
friend@nrl-csr 
</A>&gt;
</address>
<i>
Tue, 14 Jan 86 10:19:26 est
</i><PRE>

                             COMPUTER ASSURANCE
                System Integrity: Process Security and Safety

                             *******************
                             * CALL FOR PAPERS *
                             *******************

  Important Dates                              Date &amp; Location
  ---------------                              ---------------
  March 31, 1986                               July 7 - 11, 1986
    3 Copies of Abstract Submitted             The George Washington University

  April 30, 1986                               Washington, D.C.
    Authors Notified of Acceptance             Accomodations available in Dorms

  May 30, 1986
    Camera Ready Manuscripts Due

                 Keynote Address by:  David Lorge Parnas

                 Sponsored by:        WASHINGTON SECTION IEEE
                 Conference Name:     COMPASS 86 (COMPuter ASSurance)


Our safety, health and welfare as individuals and as a nation are increasingly
dependent on the correct use of computers.  However it is usual to find major
"bugs" and untrustworthy operation in critical computer controlled systems,
despite advances in software engineering and computer system design.  New
approaches are needed.  The purpose of this conference is to discuss these
needs, and to encourage the presentation of possible new approaches.  Abstracts
presenting innovative new ideas are encouraged, even if the ideas have not been
fully developed.  Our goal is not to sell old ideas but to encourage new ones.
Abstracts of 5 to 10 pages are encouraged.

&lt;=============================================================================&gt;

                                                 XXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Subject Areas Include (but are not limited to): X For information contact:    X
----------------------------------------------- X Albert W. Friend, Prog. ChmnX
                                                X COMPASS, P.O. Box 3815      X
* Specifications                                X   Gaithersburg, MD 20878    X
* Processes                                     X    friend@nrl-csr           X
* Assessment and Measurement                    X                             X
* Formal methods and tests                      X   NAME_____________________ X
* Human limitations                             X   Affiliation______________ X
* Implementations                               X   Address__________________ X
* Kernels                                       X   City, State, Zip_________ X
                                                X     _______________________ X
All submissions reviewed by program committee    XXXXXXXXXXXXXXXXXXXXXXXXXXXXX

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.39.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.41.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-50</DOCNO>
<DOCOLDNO>IA012-000128-B043-369</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.41.html 128.240.150.127 19970217001301 text/html 13858
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:11:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 41</TITLE>
<LINK REL="Prev" HREF="/Risks/1.40.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.42.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 41</H1>
<H2> Sunday, 19 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
On a Clear Day You Can See Forever ... or Nothing At All 
</A>
<DD>
<A HREF="#subj1.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Unreleased SDIO Computing Panel Report: Specialists Fault `Star Wars' Work
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Man in the loop and magnetic bottles 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
On a Clear Day You Can See Forever ... or Nothing At All
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Sun 19 Jan 86 16:29:27-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

This issue of RISKS once again concerns the topic of SDI, both in its own
right and as being illustrative of a collection of risks from which we can
learn for other applications.  The problems that arise in considering SDI
are some of the most fundamental problems affecting our lives at the moment.
The news item that follows this message was probably seen by most of you who
read newspapers.  It is included here for the record, and for any of you who
missed it.

Occasionally I get a complaint that the RISKS Forum seems biased.  Some of
those comments have come from proponents of SDI.  I continually seek to
include both sides of any critical issue.  If only one side is willing to
speak out, RISKS may appear biased to those who do not want to get drawn
into the discussion.  That is unfortunate, particularly if one side can
eschew debate and then complain that the debate is rigged.  Oh, well, we are
damned if we do, and damned if we don't.  Our ACM sponsorship stated at the
outset of this Forum that we should make every attempt to be nonpartisan.  I
have on various occasions offered RISKS as an outlet to the SDI panel, but
have been rebuffed with "RISKS is biased".  Too bad.  It looks as if some
serious though went into the report that is described below, and it should
certainly have the benefit of exposure to the social process.  But if the
proponents of SDI are hiding under a protective shield other than the one
they are trying to create, then that is an anti-social process instead.

As I have noted earlier, it is certainly easier to criticize others than to
offer alternatives.  Generally, the proof of the pudding is in the eating.
Since the pudding has not jelled yet (indeed, it has not been cooked, which
is fortunate in that suitable recipes do not yet exist), discussion is based
on such things as dietary customs, a liking for untasted goodies, bad
experiences with the effects of overly rich food, or allergy to pudding.
De gustibus non disputandem est.

It is significant that software problems are explicitly identified in the
cited report as being critical to SDI.  (That conclusion was certainly
self-evident a priori, but its being emphasized will certainly point to many
problems that must be addressed -- not just for SDI).  The risks therein are
enormous, and I hope that RISKS will objectively discuss them (along with
other risks) and what can be done to avoid them.  SOFT-ENG should also have
much valuable material on the techniques and role of software engineering.

However, as a meta-issue that is certainly relevant here, it is a tragedy of
our times that software engineering techniques are still not widely used by
the commercial developers of critical software.  Some of those developers
are literally many years behind the state of the art.  The fault is probably
distributed in many places, such as researchers who do not make their
research and development tools really amenable to realistic use; software
developers who take too many short-cuts and are too concerned with profits;
government administrators who do not insist on higher-quality software with
carefully preestablished requirements, and who do not follow through with
strict control measures and penalties; politicians who create and perpetuate
the bureaucracy; and the general public -- which puts up with it all.  The
waste is enormous -- not only in dollars, but in human resources and
misplaced efforts.  (I am referring here generically to a wide class of
developments, not to SDI alone.)

Peter

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Unreleased SDIO Computing Panel Report
</A>
</H3>
<address>
Walter Hamscher 
&lt;<A HREF="mailto:hamscher@MIT-HTVAX.ARPA">
hamscher@MIT-HTVAX.ARPA
</A>&gt;
</address>
<i>
Sat, 18 Jan 86 12:07:27 est
</i><PRE>

&gt;From the Boston Globe, page 1, Saturday, 18 Jan 1986

		 SPECIALISTS FAULT `STAR WARS' WORK

			   By Fred Kaplan
			    Globe Staff

WASHINGTON - In a report commissioned by the Pentagon's Strategic
Defense Initiative Office, a group of top computer software experts
concludes that the SDI office is going about the task of building a
`star wars' missile-defense system the wrong way.

The report does say developing a proper software program for SDI is
feasible.  However, it says the SDI office and its defense
contractors are assuming they can develop the `star wars' weapons
and sensors first and write its computer software afterward - when,
in fact, an effective defense will be impossible unless this order
is reversed.

The authors of the report, all avowed supporters of the SDI program,
met for 17 days last summer and held further discussions before
writing the report.  The report was submitted to the SDI office last
month, and has not been released publicly.

Software must be programmed to enable automatic communication
between the satellites that detect Soviet missiles and the SDI
weapons that will shoot the missiles down; between these weapons and
other sensors that can distinguish missiles from decoys and assess
whther the target was hit or missed; and between this entire network
and political authorities on the ground.  Hundreds of satellites,
battle stations, sensors, giant space mirrors and other devices
would be involved.  Computations must be made, and orders must be
given, in a matter of microseconds, with continuous updates and
revisions.

The report says all the various designs for strategic defense
systems proposed thus far demand "excessively sophisticated
software" that "cannot be adequately tested."  A design "that cannot
be tested ... is of no value," the report says.  And "excessively
complex software cannot be produced at any cost."

John Pike of the Federation of American Scientists, a critic of SDI
who did not serve on the panel that wrote the report, puts the
problem this way: "It's like buying a home computer first and then
discovering that the software you need won't run on it.  Or it's
like buying a Betamax and then discovering that your favorite movies
are only on VHS.

"This report," Pike continues, "says a lot of the money in the [SDI]
budget now is wasted because you'll end up buying the wrong
machines."

The report emphasizes that computer software programming is still a
young field with many unknown elements.  The report states, "The
panel expects no technological breakthrough that would make it
possible to write the celebrated `10 million lines of error-free
code,'" which SDI officials have acknowledged are necesary to make
the system, as currently envisioned, work.

Moreover, "there are no laws or formulae that can accurately predict
the successs or failure of a large software development."  Nor is it
possible today, the report says, to measure whether a software
program can be applied to an SDI battle-management system.

The report says these problems are not impossible to solve.
However, it says it will take at least two decades - and then only
if the organization of the program is radically changed.  Assuming
these fundamental uncertainties can be resolved, the report cites
other computer and software difficulties.  Among them:

* Flights of the space shuttle have frequently been delayed because
of computer problems found at the last moment.  Yet whereas the
shuttle's computers are designed to reain in operation for 1,000
hours without breaking down, the computers on board the satellites
used in an SDI system would have to be built to break down only once
every 100,000 hours.

David Parnas, a software specialist at the University of Victoria in
British Columbia, also says the experience of several shuttle
flights has allowed NASA to work out programming "bugs" over time.
"This kind of thing couldn't possibly work with SDI," he says.  "You
can't call the Russians in the middle of a war and say, `Wait a
minute, we have to recalculate some things.'"

Parnas was appointed a member of the panel that wrote the report.
However, he resigned a few weeks after its formation, saying its
work was pointless because SDI's software requirements were
impossible to fulfill.

Stephen Berlin of MIT's Laboratory for Computer Sciences [sic],
notes another difference between SDI and the shuttle: "The space
shuttle is not being shot at.  An SDI system almost certainly would
be."

* The system would be highly vulnerable not only to direct attack
but to nuclear weapons exploded in space as far as 1,000 kilometers
away.  "The high-energy neutron flux from a nuclear explosion is
expected to `erase' volatile semiconductor memory," the report says.
"Effective shielding is difficult."

The report recommends new ways of dealing with strategic defense
that organize the various components of an SDI system in a "loose
hierarchy," with tasks "delegated to and localized within parts of a
system."  Such a system would involve less complex and more testable
software, and could be adapted more easily to change.

The authors of the report - all software specialists at top
universities - acknowledge that it is not clear how to do all this,
and that the SDI office should "use independent contractors" who
could "tap the talent of leading researchers in the scientific
community," to study the problem further.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Man in the loop and magnetic bottles
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@uw-june.arpa ">
jon@uw-june.arpa 
</A>&gt;
</address>
<i>
Sat, 18 Jan 86 16:37:24 PST
</i><PRE>

&gt; (Dave Wade writes...)
&gt; I ... maintained the control system for a series of Magnetic Fusion Energy
&gt; experiments. The programs ran in "real time" and attempted to contain and
&gt; shape a plasma. ... The point of this was that any failure of the control
&gt; system was capable of killing personnel. ... The software was much smarter 
&gt; than the operator and certainly swifter.   There was no way that I could
&gt; hit the "kill" switch before the plasma got lose.

With all respect, I am having trouble accepting that there is not some 
misunderstanding or overdramatization in this account.  Are we to believe 
that people stood around where they could have gotten killed if the 
control system failed?  If this is true, the risks in question were certainly
unnecessary.  Why on earth were the operators not protected behind some kind 
of blast shield?  What assurances did they require to convince themselves that
the software was sufficiently bug-free that they could trust their lives with 
it?

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-51</DOCNO>
<DOCOLDNO>IA012-000128-B043-392</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.42.html 128.240.150.127 19970217001318 text/html 7216
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:11:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 42</TITLE>
<LINK REL="Prev" HREF="/Risks/1.41.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.43.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 42</H1>
<H2> Tuesday, 28 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Space Shuttle Challenger 
</A>
<DD>
<A HREF="#subj1.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  When you start an engine at 40 below, you could be injured...  
</A>
<DD>
<A HREF="#subj2.1">
David Wade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Brazil" and Risks to the Public 
</A>
<DD>
<A HREF="#subj3.1">
Martin Minow
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The Space Shuttle Challenger
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Tue 28 Jan 86 09:45:12-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

For those of you who haven't heard, the Challenger blew up this morning, 1
minute and 12 seconds after launch, during maximum thrust.  Everything
appeared to be working properly.  TV pictures show one of the solid rocket
boosters on the side going first, then everything.  (There had been some
concern because the temperature went below 28 degrees Fahrenheit during the
night at Canaveral, and that temperature is considered critical because of
ice formation.)  The Challenger had consistently been the most reliable of
all the shuttles.

One unvoiced concern from the RISKS point of view is the presence on each
shuttle of a semi-automatic self-destruct mechanism.  Hopefully that
mechanism cannot be accidentally triggered.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
When you start an engine at 40 below, you could be injured...
</A>
</H3>
<address>
David Wade
&lt;<A HREF="mailto:djw%f@LANL.ARPA ">
djw%f@LANL.ARPA 
</A>&gt;
</address>
<i>
Tue, 21 Jan 86 10:42:37 mst
</i><PRE>

I did not intentionally deceive you or overdramatize the risks taken during
checkout of "my" Fusion experiments.  ( I say "my" because I'm proud of them
and they are the only ones I've ever worked on. ) 

People were normally behind blast walls during operation.  However, certain
individuals became familiar enough with the "normal" operation of the machine
( and, at times, frustrated with certain types of idiosyncratic behavior )
did put themselves at risk in order to trace down short circuits.

People became convinced ( with time ) that the software was reliable.  Note
that routine operation after "checkout" was complete was a lot different
than operation during "checkout".

We normally operated behind blast walls with 2-3 video cameras ( and finally
got a vcr ).  One video camera was hung where it could "see" most of the power
supplies.  That camera had a zoom lense and it was routed through a "frame
grabber" which was triggered off the master trigger.  Many times that camera
would "bloom" with the most dramatic evidence of a direct short.

Visitors see the remains of the capacitor which exploded years ago on the CTX
experiment.  The safety record is excellent, but it could be ruined at any
time by stupidity.

None of the articles I've seen have criticised the SDI on the basis of the
stupidity of the operators, so I wasn't "flaming" that point.  I personally
believe that the stupidity is evidenced by the lack of a world concensus
for exploration of space and demilitarization of the world situation.

Perhaps this is just "liberal crap" left over from my youth in the 60's;
perhaps I should re-examine my beliefs,  but I think back on my life as an
"Air Force Brat" whose father was in SAC ( the Strategic Air Command ) in the
50's, and I remember "the bay of pigs" week.  That's probably one of the
closest "near-death" experiences you've ever had,  aren't you thankful that
you made it?  How did you feel?  Did it hurt?  Did you feel any different
when you packed your sleeping bag and your tent in the station wagon and left
for the mountains with the rest of the kids and moms that you knew?  Do you
think that people have that same feeling now when they discuss survivability?

I think that SDI has given the flower children their first hope since 1957.
If it does only that, it has helped the world by forcing negotiations.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Brazil" and Risks to the Public
</A>
</H3>
<address>
Martin Minow, DECtalk Engineering ML3-1/U47 223-9922
&lt;<A HREF="mailto:minow%rex.DEC@decwrl.DEC.COM  ">
minow%rex.DEC@decwrl.DEC.COM  
</A>&gt;
</address>
<i>
Monday, 20 Jan 1986 05:43:12-PST
</i><PRE>

Readers of the RISKS Forum might enjoy seeing the new movie, Brazil,
which has been described as 1984 redone by Monty Python.

Martin Minow
minow%rex.dec@decwrl.arpa

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-52</DOCNO>
<DOCOLDNO>IA012-000128-B043-413</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.43.html 128.240.150.127 19970217001331 text/html 18156
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:11:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 43</TITLE>
<LINK REL="Prev" HREF="/Risks/1.42.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.44.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 43</H1>
<H2> Wednesday, 29 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Reliability of Shuttle Destruct System (Martin J. Moore) 
</A>
<DD>
<A HREF="#subj1.1">
LONG MESSAGE
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Challenger lost (and note on self-destruct mechanism) 
</A>
<DD>
<A HREF="#subj2.1">
Earle S. Kyle
</A><br>
<A HREF="#subj2.2">
 jr.
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Challenger ICING !!! 
</A>
<DD>
<A HREF="#subj3.1">
Werner Uhrig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Big Brother, again 
</A>
<DD>
<A HREF="#subj4.1">
Col. G. L. Sicherman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Reliability of Shuttle Destruct System [LONG]
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
28 Jan 86 14:06:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;
Reply-To: "MARTIN J. MOORE" &lt;mooremj@eglin-vax&gt;

Copyright (c) 1986 Martin J. Moore          [COMMENT: READERS -- PLEASE OBSERVE
                                             THE RESTRICTIONS ON THIS MESSAGE
                                             AT THE END OF THE MESSAGE.  PGN]

&gt; From: Peter G. Neumann &lt;Neumann@SRI-CSL.ARPA&gt;
&gt; For those of you who haven't heard, the Challenger blew up this morning...
&gt; One unvoiced concern from the RISKS point of view is the presence on each
&gt; shuttle of a semi-automatic self-destruct mechanism.  Hopefully that
&gt; mechanism cannot be accidentally triggered.  [COMMENT: I did not intend
                                              to imply that as the cause --
                                              only to raise concern about the
                                              safety of such mechanisms.  PGN]

Peter, I assume that you are talking about the Range Safety Command Destruct
System, which is used to destroy errant missiles launched from Cape Canaveral. 
From 1980 to 1983 I was the lead programmer/analyst on the ground portions of
that system, and I am the primary author of the software which translates the
closing of destruct switches into the RF destruct signals sent to the vehicle.
I think I can address the question of whether the system can be accidentally
triggered; worrying about that gave me nightmares off and on for months
while I was on the project.  I'd like to tell you a little about the system
and why I think the answer is No.  Note that my information is now three years
old, and some details may have changed; there may also be minor errors in 
detail due to lapses in my memory, which isn't as good as my computer's!

On board the vehicle, there are five destruct receivers: one on the external 
tank (ET) and two on each of the solid rocket boosters (SRBs).  There is no
receiver or destruct ordnance on the Orbiter; it is effectively just an 
airplane.  The casing of each SRB is mined with HMX, a high explosive; the ET 
contains a small pyrotechnic device which causes its load of liquid hydrogen 
and liquid oxygen to combine and combust.  The receivers and explosives are
connected such that the receipt of four proper ARM sequences followed by 
a proper FIRE sequence by any of the receivers will explode the ordnance.

The ARM sequence and FIRE sequence must come from the ground; they cannot be
generated aboard the vehicle.  These sequences are transmitted on a frequency 
which is reserved, at all times, for this purpose and this purpose alone.
There are several transmitters around the Eastern Test Range which can be used
to transmit the codes.  These transmitters have a power of 10 kw (continuous 
wave).  The ARM and FIRE sequences consist of thirteen tone pairs (different
for each command and changed for each launch).  There are eight possible 
tones, resulting in 28 possible tone pairs; thus, there are (28^13) or
slightly over 6.5E18 correct sequences.

The Range Safety Officer has two switches labeled "ARM" and "DESTRUCT".
When he throws a switch, it generates an interrupt in the central processor
(there are actually two central processors running and receiving all inputs,
but only one is on-line at any time; in case of software or hardware error
the backup is switched in.  And yes, they have different power sources.)
The central program checks for the correct code on each of two different
hardware lines (the correct code is different for each line); if correct,
and all criteria are met to allow the sequence to be sent, the central program
requests the tone pairs for that sequence from another processor.  That 
processor (like everything else in the system, actually redundant processors)
has only one function: to store and deliver those tone pairs.  The processor
resides in a special vault and can only be accessed in order to program the
tone pairs (which are highly classified) before each launch.  The data line
between the central processor and the storage processor is electrically
connected ONLY when the ARM or DESTRUCT switch is actually thrown; this
prevents a wild program from retrieving the tone pairs. 

When the central program has retrieved the tone pairs, it formats a message
to the currently selected remote transmitter.  As the final step before 
sending the message, the program checks the switch hardware one more time 
to make sure the command is, in fact, requested.  If so, the message is sent
to the site on two modems (with different power supplies and geographically 
diverse communications paths) and, after sending the message, erases the tone 
paris from its memory.  The remote site, until this time, does not know the
tone pairs.  When the site receives and validates the message, it sends a
request for confirmation back to the central processor.  When Central
receives this request, it checks the switch hardware again and retrieves a 
fresh copy of the tone pairs from the storage processor to make sure that the 
site got the correct tone pairs.  If all these checks pass, Central issues
a go-ahead message to the site, which then (if the message is validated) 
actually transmits the sequence to the vehicle.  During this sequence of 
messages, if any message fails, it is retransmitted, with a check of the 
switch hardware before each transmission.

Let's look at some areas that could cause an accidental trigger:

1. Failure of switch hardware.  This would take at least six circuits failing 
   to the "1" state, while 12 others connected to them would have to NOT fail.

2. Central software error.  There is a lot of reliabilty checking, details of
   which are too long to repeat here; but even if there is a hole through it,
   the central program cannot get the tone pairs unless the switch is thrown!

3. Site software error.  Doesn't have the tone pairs until sent by Central.

4. Destruct receiver failure.  I didn't work with this directly (being 
   strictly on the ground side) but everything I've seen makes them look
   very reliable and fail-safe.

5. External sabotage.  A hostile agent would have to (1) steal the tone pairs,
   and (2) overpower our 10 kw CW transmitters which are saturating the
   destruct receivers with a 70 dB margin.  Alternatively, if someone tried
   to overpower the central area, I think they would fail.  Security is TIGHT
   around the central control area;  I don't think I can go into detail without
   upsetting NASA and the Air Force.

7. Internal sabotage.  One thing I did was to imagine that I was a saboteur
   and think of a way that I could program in a Trojan Horse to send a false
   command.  Eventually, the system was such that I could not do it.  NASA
   also hired an independent contractor to perform reliability analyses.
   NOBODY can send a command except the Range Safety Officer when he throws
   the switch.

The Challenger explosion was NOT caused by the Range Safety system, either
intentional or accidental.

I am really sorry about the length of this message, but I wanted to get all of 
that in.  All information contained herein is UNOFFICIAL and furnished for
information purposes only.  It is in no way official information from my
employer (RCA), the U.S. Air Force, NASA, or any other government agency.

Due to the sensitive nature of this incident, this article is not for 
reproduction or retransmittal without the express permission of the author.
Permission is hereby granted to Peter G. Neumann to include this material
in the RISKS electronic mail digest.

                                      Martin J. Moore
                                      mooremj@eglin-vax.arpa

[MARTIN: MANY THANKS FOR THIS EXTRAORDINARY MESSAGE.  
 READERS: PLEASE OBSERVE THE ABOVE CAVEAT SCRUPULOUSLY.  PGNeumann]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: news: Challenger lost (and note on self-destruct mechanism)
</A>
</H3>
<address>
&lt;<A HREF="mailto:kyle.wbst@Xerox.COM       ">
kyle.wbst@Xerox.COM       
</A>&gt;
</address>
<i>
29 Jan 86 12:41:53 EST
</i><PRE>
To: Werner Uhrig &lt;CMP.WERNER@R20.UTEXAS.EDU&gt;
cc: aviation@R20.UTEXAS.EDU, neumann@SRI-CSL.ARPA
                             [I presume this is from Earle S. Kyle, Jr... PGN]

Your mention of a destruct mechanism on airliners to foil hijackers
raises the question of possible terrorist activity in the shuttle
explosion. With the recent flap involving Libya, how certain are we that
the radio code that the Air Force range safety officer uses to destruct
shuttles gone astray was not compromised?

Although the slow motion video indicates some other mechanism besides on
board explosives initiating the destruction of the vehicle,  I'm
wondering if a high powered rifle bullet hit either the main fuel tank
or one of the solid boosters shortly after launch if that could have
given the same result we saw yesterday.  What makes me think of that is
the following: When I went to the 4th shuttle launch (STS-4), I noticed
that things were quite different in the press site area (where I was)
than it was for the two Apollo launches I attented (A-11, &amp; A-17) in
that same area. The difference at STS-4 was the large number of armed
guards. When I asked about that, the reply was something to the effect
that there had been some intelligence that someone with a high powered
rifle might try to shoot at the thing during takeoff. As the shuttle
flights got more routine, I'm wondering if the security at the site got
a bit lax?

Does anyone know if a rifle shot on the big tank would be enough to
structurally weaken it such that during that portion of the launch with
maximum stress the thing might rupture?

</PRE>
<HR><H3><A NAME="subj2.2">
Challenger ICING !!!
</A>
</H3>
<address>
Werner Uhrig  
&lt;<A HREF="mailto:CMP.WERNER@R20.UTEXAS.EDU">
CMP.WERNER@R20.UTEXAS.EDU
</A>&gt;
</address>
<i>
Tue 28 Jan 86 14:42:45-CST
</i><PRE>
To: aviation@R20.UTEXAS.EDU
cc: neumann@SRI-CSL.ARPA

From TV-news coverage, I have the impression as if there might not have been
adequate attention paid to icing which is supposed to have occurred this
morning on the launch-pad.  Now while I have a healthy scepticism of
news-coverage, and the highest respect for NASA-efforts and diligence, I
still keep pondering the following news-tidbits:

1)  ICICLES (!!!), several inches long, were shown, supposedly filmed on the
	launch pad or launch-vehicle this morning.

2)  NASA sources were quoted as not being concerned very much any more when
	temperature rose above freezing around 10am.

3)  NASA was quoted as having been concerned about icicles breaking off
	during flight and puncturing some part of the craft during launch.
	No mention was made of any concern either about "the extra weight"
	or "the effect on flight surfaces".

4)  Some observers were commenting that the launch seemed to lift slower than
	usual (extra weight ??).

5)  The explosion seemed to occur when the shuttle's 3 engines were switched
	to "maximum - or 104% - thrust", and on my TV, seemed to occur at
	the point where Challenger is connected to the external tank.
	Could there have been an extra stress imposed on connecting
	fuel-lines due to a "larger than usual differential of acceleration
	push excerted by the solid-fuel-rocket asembly, to which the external
	tank is (solidly) connected, and the shuttle vehicle, due to the
	additional weight of ice on the vehicles?

I assume you all are similarly puzzled about things and, maybe, made other
observations that escaped me, which I, for one, would be most interested to
reading ....

	I sure hope it wasn't icing, the main killer of pilots ....

		NO cheers today from me,	)-:	Werner

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Big Brother, again
</A>
</H3>
<address>
"Col. G. L. Sicherman" 
&lt;<A HREF="mailto:colonel%buffalo.csnet@CSNET-RELAY.ARPA">
colonel%buffalo.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Wed, 29 Jan 86 11:43:25 EST
</i><PRE>

I sympathize with Keith Lynch (KFL@MC.LCS.MIT.EDU)'s argument (1:40).
All the same, some of his assumptions can be challenged.  For example:

&gt;          The character of people in government today is very
&gt; different from 200 years ago.  It is obvious that the signers
&gt; of the constitution would have extended their protections of
&gt; papers and places to computer files and disks, had they heard
&gt; of such things. ... Had radio, TV, electronic funds transfer
&gt; systems, and telephones been around in the days of Jefferson
&gt; and Washington, I am sure that they would enjoy similar
&gt; constitutional protection.

The structure of the U.S. government is formed for a people who get
most of their information from the press.  When most communication
was oral, federal government was unthinkable, because nobody knew
or cared about what was going on 1,000 miles away!  At the same
time, there was little need to "protect" expression that consisted of
talking to a few friends.  It was a form of communication that
disappeared instantly except in the minds of one's friends; there was
no enduring record to catch the eye of a jealous ruler or set before
a court.

The novel idea that the government ought not to prosecute _anything_
one printed arose naturally from the nature of print consumption.
Reading is something one does in _private;_ it allows one to weigh
conflicting ideas without getting caught up in rhetoric.  (Print
has often been blamed for the decay of rhetoric!) Moreover, books
as a medium have no side effects.  If a book insults you, you can
shut it up--something you cannot always do to a patron in a bar or
on the Net.

So I agree that the founding fathers would have protected the new media,
but only because they would not have understood the media's implications.
Printing was always an instrument of _mass_ communication: one person
talking to thousands.  There's an inherent, even ridiculous imbalance
in such a medium.  Nevertheless, it was adopted as the basis of U.S.
democracy because it was an improvement over word of mouth, and clearly
"here to stay"--until something better came along.

Electronic communication is instantaneous and ephemeral.  To the men
of 1789, it was "obvious" that the press (and public speech) ought to
be protected, and that checks and balances were needed in a representative
government.  To users of the Net, it is just as "obvious" that we can
govern ourselves, instead of electing weirdos and crooks to "represent"
us.

Col. G. L. Sicherman
UU: ...{rocksvax|decvax}!sunybcs!colonel
CS: colonel@buffalo-cs
BI: csdsicher@sunyabva

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-53</DOCNO>
<DOCOLDNO>IA012-000128-B043-439</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.44.html 128.240.150.127 19970217001344 text/html 8022
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:12:15 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 44</TITLE>
<LINK REL="Prev" HREF="/Risks/1.43.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.45.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 44</H1>
<H2> Wednesday, 29 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Shuttle SRB/MFT self-destruct mechanisms    
</A>
<DD>
<A HREF="#subj1.1">
Dusty Bleher
</A><br>
<A HREF="#subj1.2">
 Herb Lin
</A><br>
<A HREF="#subj1.3">
 Martin Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Challenger speculation 
</A>
<DD>
<A HREF="#subj2.1">
Herb Lin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Shuttle SRB/MFT Self-destruct mechanisms 
</A>
</H3>
<address>
Dusty [snake] Bleher
&lt;<A HREF="mailto:decwrl!pyramid!amiga!dusty@ucbvax.berkeley.edu ">
decwrl!pyramid!amiga!dusty@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Wed, 29 Jan 86 09:50:10 pst
</i><PRE>
Organization: Commodore-Amiga Inc., 983 University Ave #D, Los Gatos CA 95030

[PGN wrote

  &gt;One unvoiced concern from the RISKS point of view is the presence on each
  &gt;shuttle of a semi-automatic self-destruct mechanism.  Hopefully that
  &gt;mechanism cannot be accidentally triggered.   ]

Please Note, and cease to spread your unfounded rumor!
  ONLY the SRBs and the MFT/mate assy have a destruct mechanism.  The shuttle
  is NOT provided with such a mechanism, any more then an L-1011 is!

Dusty Bleher  (@@) (408) 395-6616 x265 (wkdays PST)

                [Yes, Martin Moore noted that in <A HREF="/Risks/1.43.html">RISKS-1.43</A>.  Fortunately
                 L-1011's do not have to take off amidst Solid Rocket
                 Boosters and External Fuel Tanks!  Thanks.  PGN]

</PRE>
<HR><H3><A NAME="subj1.2">
 Reliability of Shuttle SRB/MFT self-destruct mechanisms 
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 29 Jan 86 17:54:23 EST
</i><PRE>
To: mooremj@EGLIN-VAX.ARPA
cc: "RISKS-LIST:"@MC.LCS.MIT.EDU, risks@SRI-CSL.ARPA

Thanks for your piece.  Can you discuss at all the actual devices used on
the SRBs and the External Tank to set off explosions?  What ensures that
they work as expected?

</PRE>
<HR><H3><A NAME="subj1.3">
Reliability of Shuttle SRB/MFT self-destruct mechanisms 
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "lin" &lt;lin@mit-mc&gt;
cc: &lt;risks@sri-csl&gt;

Unfortunately, I really can't (as opposed to "won't") amplify much on the
actual destruct hardware; as I said, I worked strictly on the ground system,
and I have little knowledge of explosives.  My exposure to it was pretty
much limited to having one of the engineers on that side show me a block
diagram of the system and point out the salient characteristics...like
everything else that I ever saw in this system, there were double (or more)
backup paths for everything.  Sorry I can't be of more help here.

The one all-pervading factor that I encountered in various mission-critical 
systems at Cape Canaveral is redundancy.  Aside from double and triple 
circuitry and paths, there are two complete systems for everything; both run
at all times, accepting all inputs, but only one is "on-line" with respect
to outputs; if the on-line system fails (say in a power failure), the backup 
takes over.  Or a switchover can be requested manually, or the on-line program
can deliberately request a switchover if it encounters a hardware or software
error.

From time to time system redundancy was tested by running a mission simulation 
and suddenly cutting off one power source completely.  The other set of 
systems was fully capable of supporting the entire mission (of course, the
first time we tried this -- long before the first live use of the system --
we did find some problems, e.g., one system had all of its modems on the
same power source.  Its backup processor ran, but was deaf and dumb!)
Having seen this done -- first with one power source and then the other,
thus shutting down every piece of equipment at some point -- I can say 
that I *know* there is no single point of failure among the major system 
components.  I would also say that unless you run such a test, you *can't*
know it; you may think it, but you can't know it. 

                                     mjm

     [Of course, even if you run such a test, you still may not KNOW IT...
      You may never know that the test was complete.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Challenger speculation
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 29 Jan 86 18:18:19 EST
</i><PRE>
To: kyle.wbst@XEROX.COM
cc: LIN@MC.LCS.MIT.EDU, "RISKS-LIST:"@MC.LCS.MIT.EDU,
    aviation@R20.UTEXAS.EDU, CMP.WERNER@R20.UTEXAS.EDU,
    neumann@SRI-CSL.ARPA

    From: kyle.wbst at Xerox.COM

    Does anyone know if a rifle shot on the big tank would be enough to
    structurally weaken it such that during that portion of the launch with
    maximum stress the thing might rupture?

It is obvious that at the time of the explosion, no rifle bullet hit
it.  Thus, any shot must have been fired much sooner.  The rifle shot
must then be timed in such a way that it is fast enough to weaken the
casing, but not strong enough to penetrate it.  It seems that that
window is pretty small.

If you are into pure, unadulterated speculation, another possibility
is that a bullet was fired into an SRB while it was on the ground, and
lodged there.  When the fuel burned to that point, a jet leaked out,
and triggered an explosion.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-54</DOCNO>
<DOCOLDNO>IA012-000128-B043-472</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.02.html 128.240.150.127 19970217001409 text/html 54046
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:12:25 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 1: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/1.01.html">
<LINK REL="Up" HREF="/Risks/index.1.html">
<LINK REL="Next" HREF="/Risks/1.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/1.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 1: Issue 2</H1>
<H2>       Friday, 28 Aug 1985     </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I><P><B>
</B><H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
  Introduction; three more risk items 
</A>
<DD>
<A HREF="#subj1.1">
Peter Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Mariner 1 Irony 
</A>
<DD>
<A HREF="#subj2.1">
Nicholas Spies
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  RISKS Forum ... [Reaction] 
</A>
<DD>
<A HREF="#subj3.1">
Bob Carter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  RISKS Forum ... [An Air Traffic Control Problem] 
</A>
<DD>
<A HREF="#subj4.1">
Scott Rose
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Risks in AI Diagnostic Aids 
</A>
<DD>
<A HREF="#subj5.1">
Art Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Warning! ... [A Trojan Horse Bites Man] 
</A>
<DD>
<A HREF="#subj6.1">
Don Malpass
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  SDI 
</A>
<DD>
<A HREF="#subj7.1">
Martin Moore
</A><br>
<A HREF="#subj7.2">
 Jim Horning
</A><br>
<A HREF="#subj7.3">
 John McCarthy
</A><br>
<A HREF="#subj7.4">
 John McCarthy
</A><br>
<A HREF="#subj7.5">
 Peter Karp
</A><br>
<A HREF="#subj7.6">
 Dave Parnas
</A><br>
<A HREF="#subj7.7">
        Gary Martins
</A><br>
<A HREF="#subj7.8">
 Tom Parmenter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  The Madison Paper on Computer Unreliability and Nuclear War 
</A>
<DD>
<A HREF="#subj8.1">
Jeff Myers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Can a Computer Declare War? 
</A>
<DD>
<A HREF="#subj9.1">
Cliff Johnson
</A><br>
</DL>

<A NAME="subj1"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj1.1">
Introduction, and more recent risk items
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL">
Neumann@SRI-CSL
</A>&gt;
</address>
<i>
27 Aug 1985 23:32:01-PST
</i><PRE>

I was away during the previous three weeks, which made it difficult to put
out another issue.  However, the newspapers were full of excitement relevant
to this forum:

  * A Federal district judge awarded $1.25 million to the families of
    three lobstermen who were lost at sea in a storm that the National
    Weather Service failed to predict because its parent organization 
    (the National Oceanic and Atmospheric Administration) had not repaired 
    a weather buoy for three months.  [NY Times 13 Aug 85]

  * Another Union Carbide leak (causing 135 injuries) resulted from a 
    computer program that was not yet programmed to recognize aldicarb
    oxime, compounded by human error when the operator misinterpreted
    the results of the program to imply the presence of methyl isocyanate
    (as in Bhopal).  A 20-minute delay in notifying county emergency
    made things worse.  [NY Times 14 and 24 Aug 85 front pages]  (There
    were two other serious Union Carbide incidents reported in August as 
    well, although only this one had a computer link.)

  * An untimely -- and possibly experiment-aborting -- delay of the intended 
    25 August launch of the space shuttle Discovery was caused when a
    malfunction in the backup computer was discovered just 25 minutes 
    before the scheduled launch.  The delay threatened to seriously
    compromise the mission.  [NY Times 26 August 1985]  The Times reporter
    John Noble Wilford wrote, "What was puzzling to engineers was that the
    computer had worked perfectly in tests before today.  And in tests after
    the failure, it worked, though showing signs of trouble."  Arnold
    Aldrich, manager of the shuttle program at Johnson, was quoted as saying
    "We're about 99.5% sure it's a hardware failure."  (The computers are
    state of the art as of 1972 and are due for upgrading in 1987.)  A
    similar failure of just the backup computer caused a one-day delay in
    Discovery's maiden launch last summer.

  * More details are emerging on possible computer hanky-panky in elections,
    including the recent Philippine elections.  There has been a series of
    articles in the past weeks by Peter Carey in the San Jose Mercury News
    -- which I haven't seen yet but will certainly hope to report on.

I expect that future issues of this RISKS forum will appear at a higher
frequency -- especially if there is more interaction from our readership.  I
will certainly try to redistribute appropriate provocative material on a
shorter fuse.  I hope that we can do more than just recapture and abstract
things that appear elsewhere, but that depends on some of you contributing.
I will be disappointed (but not surprised) to hear complaints that we
present only one side of any particular issue, particularly when no
countering positions are available or when none are provoked in response; if
you are bothered by only one side being represented, you must help to
restore the balance.  However, remember that it is often easier to criticize
others than to come up with constructive alternatives, and constructive
alternatives are at the heart of reducing risks.  So, as I said in vol 1 no
1, let us be constructive.

</PRE>
<A NAME="subj2"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj2.1">
Mariner 1 irony
</A>
</H3>
<address>
&lt;<A HREF="mailto:Nicholas.Spies@CMU-CS-H.ARPA">
Nicholas.Spies@CMU-CS-H.ARPA
</A>&gt;
</address>
<i>
16 Aug 1985 21:23-EST
</i><PRE>
To: risks@sri-csl

My late father (Otto R. Spies) was a research scientist at Burroughs when
the Mariner 1 launch failed. He brought home an internal memo that was
circulated to admonish all employees to be careful in their work to prevent
similar disasters in the future. (I don't recall whether Burroughs was
directly involved with Mariner 1 or not.)  After explaining that a critical
program bombed because a period was substituted for a comma, the memo ended
with the phrase

		"... no detail is to [sic] small to overlook."

My father would be deeply pleased that people who can fully appreciate this
small irony are now working on ways to prevent the misapplication of
computers as foible-amplifiers.

</PRE>
<A NAME="subj3"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj3.1">
Forum on Risks to the Public in Computer Systems    [Reaction]
</A>
</H3>
<address>
_Bob 
&lt;<A HREF="mailto:Carter@RUTGERS.ARPA">
Carter@RUTGERS.ARPA
</A>&gt;
</address>
<i>
8 Aug 85  19:10 EDT (Thu)
</i><PRE>
To: RISKS@SRI-CSL

Thanks for the copy of Vol. I, No. 1.  Herewith a brief reaction.  This
is sent to you directly because I'm not sure whether discussion of the
digest is appropriate for inclusion in the digest.  

  1. Please mung RISKS so that it does not break standard undigestifying 
     software (in my case, BABYL).    

        [BABYL is an EMACS-TECO hack.  It seems to be a real bear to use,
         with lots of pitfalls still.  But I'll see what I can do.  
         Alternatively, shorter issues might help.  PGN]
    
  2. I think RISKS is clearly an idea whose time has come, but I'm not 
     entirely sure it has been sufficiently thought through.  

        [I should hope not!  It is a cooperative venture.  I just
         happen to be trying to moderate it.  PGN]

   (a.) You cast your net altogether too widely, and include some topics
        that have been discussed extensively on widely-read mailing lists.
        Star Wars, the Lin paper, the Parnas resignation, and related topics
        have been constructively discussed on ARMS-D.  I have considerable
        doubt about the utility of replicating this discussion.  (The
        moderators of HUMAN-NETS and POLI-SCI have both adopted the policy
        of directing SDI debate to that forum.  Would it be a good idea to
        follow that example?

           [To some extent, yes.  However, one cannot read ALL of the
            interesting BBOARDs -- there are currently hundreds on the
            ARPANET alone, many of which have some bearing on RISKS.  Also,
            browsers from other networks are at a huge disadvantage unless
            they have connections, hours of spare time, money, etc.  This is
            a FORUM ON RISKS, and should properly address that topic.  We
            certainly should not simply reproduce other BBOARDS, but some
            duplication seems tolerable.  (I'll try to keep it at the end
            of each issue, so you won't have to wade through it.)  By the
            way, I had originally intended to mention ARMS-D in RISKS vol 1
            no 1, but did not have time to check it out in detail.  For those
            of you who want to pursue it, next following is the essence of
            the blurb taken from the Network Information Center,
            SRI-NIC.ARPA:&lt;NETINFO&gt;INTEREST-GROUPS.TXT.  PGN]

          [  ARMS-D@MIT-MC:

             The Arms-Discussion Digest is intended to be a forum for
             discussion of arms control and weapon system issues.  Messages
             are collected, edited into digests and distributed as the
             volume of mail dictates (usually twice a week).

             Old digests may be FTP'ed from MIT-MC(no login required).  They
             are archived at   BALL; ARMSD ARCn   , where n is the issue no.

             All requests to be added to or deleted from this list, problems, 
             questions, etc., should be sent to Arms-D-REQUEST@MIT-MC.

             Moderator: Harold G. Ancell &lt;HGA@MIT-MC&gt;  ]

   (b.) You do not cover the topics which, in my opinion, are going
        to generate more law-making than anything you do touch on.  In
        particular, the health hazards (if any) of CRT use, and the working
        conditions (including automated performance testing) of "pink-collar" 
        CRT users are going to be among the most important labor-relations
        issues of the next few years.  Many people think these more imminent
        risks than those mentioned in the RISKS prospectus.

                              [Fine topic!  PGN]

  3. I think a digest is an animal that differs considerably from print
     media, but is no less important.  I get the feeling that you consider
     yourself a country cousin of the ACM publications and of SEN.  Wrong!
     You're not inferior, you are just editing in a different medium and as 
     you put your mind to the task, I hope you come to take them with a
     larger grain of salt.  In particular, 

      !  Chinese computer builder electrocuted by his smart computer after he 
         built a newer one. "Jealous Computer Zaps its Creator"!  (SEN 10 1)

     was a National Inquirer-style joke.  The editor of SEN should not have
     reprinted it, and you probably should not have included it in a
     serious list of computer-related failures.
        [The editor of SEN has sometimes been known to indulge in levity.  
         In this case it appears that a Chinese engineer was indeed
         electrocuted -- and that is an interesting case of computer-related
         disaster.  On the other hand, if someone can believe that an
         AI automatic programming routine can write many million lines of
         correct code, then he might as well believe that a smart computer
         system could express jealousy and cause the electrocution!  
         Actually, Bob used "PEN" throughout rather than "SEN", but
        "Software Engineering Notes" was the only sensible interpretation
        I could come up with, so I changed it.  Do I have a "PEN" pal?  PGN]

  4. It seems to me that it is precisely in the area of serious hardware
     and software failures that RISKS should make its mark.  Directing
     itself to that topic, it fills a spot no existing list touches on
     directly, and treats a matter that concerns every computer
     professional who is earning a decent living.  Litigation about
     defective software design and programming malpractice will be the
     inevitable consequence of risks, and RISKS is the only place to
     discuss avoiding them.  Please consider focussing the list more closely
     on that subject.

        [Bob, Thanks for your comments.  I heartily agree on the importance
         of the last item.  But, I do not intend to generate all of the
         material for this forum, and can only smile when someone suggests
         that this forum is not what it should be.  I look forward to your
         help! PGN]

[End of Bob Carter's message and my interspersions.]

</PRE>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj4.1">
RISKS forum              [including An Air-Traffic Control Problem]
</A>
</H3>
<address>
Scott M. Rose 
&lt;<A HREF="mailto:rose@uw-bluechip.arpa">
rose@uw-bluechip.arpa
</A>&gt;
</address>
<i>
16 Aug 85 21:06:39 PDT (Fri)
</i><PRE>

I had kind of hoped that somebody would submit something on the recent problem
  in Aurora Illinois, whereby a computer cable was cut that brought
  information from RADAR sensors to the regional air traffic control center
  there.  Supposedly, the system was designed to be sufficiently redundant to
  handle such a failure gracefully, but this turned out not to be the case:
  there were several close calls as the system went up and down repeatedly.
  There was information about the problem in the New York Times and the
  Chicago Tribune, at least... but not in very good detail.

I wonder if the forum is the right format for such a group.  The problem is
  that one may find oneself reluctant to report on such an incident that was
  widely reported in the popular press, and was current, for fear that a dozen
  others have done the same.  Yet in this case, the apparent result is that
  NOBODY reported on it, and I think such an event ought not pass without
  note on this group.  I might propose something more like the info-nets 
  group, where postings are automatically forwarded to group members.  If
  problems arose, then the postings could be filtered by the moderator... say,
  on a daily basis?  Just an idea...

	-S Rose

               [Please don't feel reluctant to ask whether someone has
                reported an interesting event before you go to any 
                potentially duplicate effort.  We'd rather not miss out
                entirely.]

</PRE>
<A NAME="subj5"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj5.1">
 Risks in AI Diagnostic Aids
</A>
</H3>
<address>
&lt;<A HREF="mailto:    Smith@UDel-Dewey.ARPA">
    Smith@UDel-Dewey.ARPA
</A>&gt;
</address>
<i>
Sun, 18 Aug 85 12:23:25 EDT
</i><PRE>

   I would enjoy a discussion on the legal and ethical problems that have
come up with the creation of AI diagnostic aids for doctors.  Who takes the
blame if the advice of a program causes a wrong diagnosis?  The doctor (if
so, then who would use such a program!?!?), the program's author(s) (if so,
then who would write such a program!?!?), the publishers/distributors of the
program (if so, then who would market such a program!?!?), ....  These
nagging questions will have to be answered before anyone is going to make
general use of these programs
    I would be very interested in hearing what other people think about this 
question.  It seems to me that it would be a suitable one for this bboard.

		art smith
		(smith@UDel-Dewey.ARPA)

        ****************************************************
        ** Following are several items on the Strategic   **
        ** Defense Initiative and related subjects.       **
        ****************************************************

</PRE>
<A NAME="subj6"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj6.1">
WARNING !!                    [A Trojan Horse Bites Man]
</A>
</H3>
<address>
Don Malpass
&lt;<A HREF="mailto:malpass@ll-sst ">
malpass@ll-sst 
</A>&gt;
</address>
<i>
Thu, 15 Aug 85 11:05:48 edt
</i><PRE>

Today's Wall St. Journal contained the following article.  I think
it is of enough potential significance that I'll enter the whole thing.
In addition to the conclusions it states, it implies something about
good backup procedure discipline.
	In the hope this may save someone,
		Don Malpass

		******************************************
			(8/15/85 Wall St. Journal)
				ARF! ARF!
	Richard Streeter's bytes got bitten by an "Arf Arf," which isn't
a dog but a horse.
	Mr. Streeter, director of development in the engineering department
of CBS Inc. and home-computer buff, was browsing recently through the
offerings of Family Ledger, a computer bulletin board that can be used by
anybody with a computer and a telephone to swap advice, games or programs -
or to make mischief.  Mr. Streeter loaded into his computer a program that
was billed as enhancing his IBM program's graphics; instead it instantly wiped
out the 900 accounting, word processing and game programs he had stored in
his computer over the years.  All that was left was a taunt glowing back
at him from the screen: "Arf! Arf! Got You!"
"HACKERS" STRIKE AGAIN
	This latest form of computer vandalism - dubbed for obvious reasons
a Trojan Horse - is the work of the same kind of anonymous "hackers" who
get their kicks stealing sensitive data from government computers or invading
school computers to change grades.  But instead of stealing, Trojan Horses
just destroy all the data files in the computer.
	Trojan Horse creators are nearly impossible to catch - they usually
provide phony names and addresses with their programs - and the malevolent
programs often slip by bulletin-board operators.  But they are becoming a
real nuisance.  Several variations of the "Arf! Arf!" program have made
the rounds, including one that poses as a "super-directory" that
conveniently places computer files in alphabetical order.
	Operators have begun to take names and addresses of electronic
bulletin-board users so they can check their authenticity.  When a
computer vandal is uncovered, the word is passed to other operators.
Special testing programs also allow them to study the wording of
submitted programs and detect suspicious commands.
INTERFACER BEWARE
	But while Al Stone, the computer consultant who runs Long Island
based Family Ledger, has such a testing program, he says he didn't have time
to screen the "Arf! Arf!" that bit Mr. Streeter.  "Don't attempt to run
something unless you know its pedigree," he says.
	That's good advice, because the computer pranksters are getting more
clever - and nastier.  They are now creating even-more-insidious programs
that gradually eat away existing files as they are used.  Appropriately
enough, these new programs are known as "worms".

			(8/15/85 Wall St. Journal)
		******************************************

</PRE>
<A NAME="subj7"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj7.1">
Software engineering and SDI
</A>
</H3>
<address>
&lt;<A HREF="mailto:mooremj@EGLIN-VAX">
mooremj@EGLIN-VAX
</A>&gt;
</address>
<i>
Mon, 19 Aug 85 13:56:21 CDT
</i><PRE>

[FROM Soft-Eng Digest         Fri, 23 Aug 85       Volume 1 : Issue  31]

Dr. David Parnas has quite accurately pointed out some of the dangers inherent
in the software to be written for the Strategic Defense Initiative.  I must
take exception, however, to the following statement from the Boston Globe
story quoted in Volume 1, Issue 29, of this digest:

        "To imagine that Star Wars systems will work perfectly
         without testing is ridiculous.  A realistic test of the
         Strategic Defense Initiative would require a practice
         nuclear war.  Perfecting it would require a string of such wars."

There are currently many systems which cannot be fully tested.  One example
is the software used in our present defense early warning system.  Another
example, one with which I am personally familiar, is the Range Safety Command
Destruct system at Cape Canaveral Air Force Station.  This system provides
the commands necessary to destroy errant missiles which may threaten populated
areas; I wrote most of the software for the central computer in this system.
The system can never be fully tested in the sense implied above, for to do so
would involve the intentional destruction of a missile for testing purposes
only.  On the other hand, it must be reliable:  a false negative (failure to
destroy a missile which endangers a populated area) could cause the loss of
thousands of lives; a false positive (unintentional destruction of, say, a
Space Shuttle mission) is equally unthinkable.  There are many techniques
available to produce fault-tolerant, reliable software, just as there are for
hardware; the Range Safety system was designed by some of the best people at
NASA, the U. S. Air Force, and several contractors.  I do not claim that a 
failure of this system is "impossible", but the risk of a failure, in my
opinion, is acceptably low.

"But ANY risk is too great in Star Wars!"  

I knew someone would say that, and I can agree with this sentiment.  The only
alternative, then, is not to build it, because any system at all will involve
some risk (however small) of failure; and failure will, as Dr. Parnas has 
pointed out, lead to the Ultimate Disaster.  I believe that this is what Dr.
Parnas is hoping to accomplish:  persuading the authorities that the risk
is unacceptable.

It won't work.  Oh, perhaps it will in the short run; "Star Wars" may not 
be built now, or ever.  But sooner or later, some system will be given 
life-and-death authority over the entire planet, whether it is a space 
defense system, a launch-on-warning strategic defense system, or something 
else.  The readers of this digest are the present and future leaders in
the field of software engineering.  It is our responsibility to refine the
techniques now used and to develop new ones so that these systems WILL be
reliable.  I fear that some first-rate people may avoid working on such
systems because they are "impossible"; this will result in second-rate
people working on them, which is something we cannot afford.  This is NOT 
a slur at Dr. Parnas.  He has performed an invaluable service by bringing
the public's attention to the problem.  Now it is up to us to solve that
problem.

I apologize for the length of this message.  The above views are strictly
my own, and do not represent my employer or any government agency.

                                      Martin J. Moore
                                      Senior Software Analyst
                                      RCA Armament Test Project
                                      P. O. Box 1446
                                      Eglin AFB, Florida  32542
                             ARPAnet: MOOREMJ@EGLIN-VAX.ARPA

</PRE>
<HR><H3><A NAME="subj7.2">
Trip Report: Computing in Support of Battle Management
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.ARPA ">
horning@decwrl.ARPA 
</A>&gt;
</address>
<i>
21 Aug 1985 1243-PDT (Wednesday)
</i><PRE>

[This is a relatively long report, because I haven't been able to come
up with a simple characterization of an interesting and informative day.]

Background:

On August 13 I travelled to Marina del Rey to spend a day with the
U.S. Department of Defense Strategic Defense Initiative Organization
Panel on Computing in Support of Battle Management (DoD SDIO PCSBM).

SDI is the "Star Wars" antiballistic missile system; PCSBM is the panel
Dave Parnas resigned from.

I wasn't really sure what to expect. As I told Richard Lau when he
invited me to spend a day with them, I'd read what Parnas wrote, but
hadn't seen the other side.  He replied that the other side hadn't been
written yet. "Come on down and talk to us. The one thing that's certain
is that what we do will have an impact, whether for good or for ill."

Summary:

The good news is that the panel members are not crazies; they aren't
charlatans; they aren't fools. If a solution to SDI's Battle Management
Software problem can be purchased for five billion dollars (or even
ten), they'll probably find it; if not, they'll eventually recognize
that it can't.

The bad news is that they realize they don't have the expertise to
solve the problem themselves, or even to direct its solution. They
accept Dave Parnas's assessment that the software contemplated in the
"Fletcher Report" cannot be produced by present techniques, and that
AI, Automatic Programming, and Program Verification put together won't
generate a solution. Thus their invitations to people such as myself,
Bob Balzer, and Vic Vyssotsky to come discuss our views of the state
and prospects of software technology.

I think a fair summary of the panel's current position is that they are
not yet convinced that the problem cannot be modified to make it
soluble. ("Suppose we let software concerns drive the system
architecture? After all, it is one of the two key technologies.") They
are trying to decide what must be done to provide the information that
would be needed in the early 1990s to make a decision about deploying a
system in the late 1990s.

Assumptions:

Throughout the day's discussions, there were repeated disconnects
between their going-in assumptions and mine. In fairness, they tried to
understand the sources of the differences, to identify their
assumptions, and to get me to identify and justify mine.

* Big budgets: I've never come so close to a trillion-dollar ($10**12)
project before, even in the planning stage. ("The satellite launches
alone will cost upwards of $500 billion, so there's not much point in
scrimping elsewhere.")

- I was unprepared for the intensity of their belief that any technical
problem could be steamrollered with a budget that size.

- They seemed surprised that I believed that progress in software
research is now largely limited by the supply of first-rate people, and
that the short-term effect of injecting vastly more dollars would be to
slow things down by diverting researchers to administer them.

* Big software: They were surprised by my observation that for every
order of magnitude in software size (measured by almost any interesting
metric) a new set of problems seems to dominate.

- This implies that no collection of experiments with million-line
"prototypes" can ensure success in building a ten-million-line system.
I argued that the only prototype from which they would learn much would
be a full-scale, fully-functional one. Such a prototype would also
reveal surprising consequences of the specification.
(The FIFTEENTH LAW OF SYSTEMANTICS: A complex system that works is
invariably found to have evolved from a simple system that works.)

- Only Chuck Seitz and Bijoy Chatterjee seemed to fully appreciate why
software doesn't just "scale up" (doubtless because of their hardware
design experience). It is not a "product" that can be produced at some
rate, but the design of a family of computations; it is the
computations that can be easily scaled.

* Reliability: I had assumed that one of the reasons Battle Management
software would be more difficult than commercial software was its
more stringent reliability requirement. They assume that this is one of
the parameters that can be varied to make the problem easier.

Discussion:

The Panel is still in the process of drafting its report on Battle
Management Systems. Although they take the need to produce such a
system as a given, almost anything else is negotiable. (In particular,
they do not accept the "Fletcher Report" as anything more than a
springboard for discussion, and criticize current work for following it
too slavishly. The work at Rome Air Development Center--which produced
estimates like 24.61 megalines of code, 18.28 gigaflops per weapons
platform--was mentioned contemptuously, while the Army work at Huntsville
was considered beneath contempt.)

The following comments are included merely to indicate the range and
diversity of opinions expressed. They are certainly not official
positions of the panel, and--after being filtered though my
understanding and memory--may not even be what the speaker intended.
Many of the inconsistencies are real; the panel is working to identify
and resolve them.

- The problem may be easier than a banking system, because: each
autonomous unit can be almost stateless; a simple kernel can monitor
the system and reboot whenever a problem is detected; there are fewer
people in the loop; more hardware overcapacity can be included.

- If you lose a state it will take only a few moments to build a new
state. (Tracks that are more than 30 minutes old are not interesting.)

- Certain kinds of reliability aren't needed, because: a real battle
would last only a few minutes; the system would be used at most once;
with enough redundancy it's OK for individual weapons to fail; the
system doesn't have to actually work, just be a credible deterrent; the
system wouldn't control nuclear weapons--unless the Teller "pop up"
scheme is adopted; the lasers won't penetrate the atmosphere, so even
if the system runs amok, the worst it could do would be to intercept some
innocent launch or satellite.

- We could debug the software by putting it in orbit five or ten years
before the weapons are deployed, and observing it. We wouldn't even
have to deploy them until the system was sufficiently reliable. Yes,
but this would not test the important modes of the system.

- Dependence on communication can be minimized by distributing
authority: each platform can act on its own, and treat all
communication as hints.

- With a multi-level fault-tolerance scheme, each platform can monitor
the state of its neighbors, and reboot or download any that seem to be
malfunctioning.

- In fifteen years we can put 200 gigaflops in orbit in a teacup. Well,
make that a breadbox.

- Space qualification is difficult and slow. Don't count on
microprocessors of more than a few mips in orbit. Well, maybe we could
use fifty of them.

- How much can we speed up computations by adding processors? With
general-purpose processors, probably not much. How much should we rely
on special-purpose space-qualified processors?

- Processor cost is negligible. No, it isn't. Compared to software
costs or total system costs it is. No, it isn't, you are
underestimating the costs of space qualification.

- 14 MeV neutron flux cannot effectively be shielded against and
represents a fundamental limitation on the switching-speed, power
product. Maybe we should put all the computationally intensive
components under a mountain. But that increases the dependence on
communication.

- Maybe we could reduce failure rates by putting the software in
read-only memory. No, that makes software maintenance incredibly
difficult.

- Flaccidware. It's software now, but it can become hardware when
necessary.

- Is hardware less prone to failure if switched off? Maybe we could
have large parts of the system on standby until the system goes on
alert. Unfortunately, the dominant hardware failure modes continue even
with power off.

- The software structure must accommodate changes in virtually all
component technologies (weapons, sensors, targets, communication,
computer hardware) during and following deployment. But we don't have
much technology for managing rapid massive changes in large systems.

Relation to Critics:

Dave Parnas's criticisms have obviously been a matter of considerable
concern for the panel. Chuck Seitz and Dick Lau both said explicitly
that they wouldn't be satisfied making a recommendation that failed to
address the issues Dave and other critics have raised. Chuck also
distributed copies of "The Star Wars Computer System" by Greg Nelson
and David Redell, commending it to the attention of the panel as
"Finally, some well-written and intelligent criticism."

Richard Lipton had a somewhat different attitude: How can they say that
what we are going to propose is impossible, when even we don't know
yet what we're going to propose? And why don't software researchers
show more imagination? When a few billion dollars are dangled in front
of them, the physicists will promise to improve laser output by nine
decimal orders of magnitude; computer scientists won't even promise one
or two for software production.

The minutes of the August 12 meeting contain the following points:

- Critics represent an unpaid "red team" and serve a useful function in
identifying weak points in the program.

- Critiques should be acknowledged, and areas identified as to how we
can work to overcome these problem areas.

- Throughout our discussions, and in our report we should reflect the
fact that we have accepted a degree of uncertainty as an inherent part
of the strategic defense system.

- How to get the system that is desired? This basic problem goes back
to defining requirements--a difficult task when one is not quite sure
what one wants and what has to be done.

Prospects:

After all of this, what do I think of the prospects for SDI Battle
Management Software? I certainly would not be willing to take on
responsibility for producing it. On the other hand, I cannot say flatly
that no piece of software can be deployed in the 1990s to control a
ballistic missile defense system. It all depends on how much
functionality, coordination, and reliability are demanded of it.

Unfortunately, as with most other computer systems, the dimension in
Gwhich the major sacrifice will probably be made is reliability. The
reality of the situation is that reliability is less visible before
deployment than other system parameters and can be lost by default. It
is also probably the hardest to remedy post facto. Of course, with a
system intended to be used "at most once," there may be no one around
to care whether or not it functioned reliably.

Despite these misgivings, I am glad that this panel is taking seriously
its charter to develop the information on which a deployment decision
could responsibly be based.

Jim H.

</PRE>
<HR><H3><A NAME="subj7.3">
Forum on Risks to the Public in Computer Systems 
</A>
</H3>
<address>
John McCarthy 
&lt;<A HREF="mailto:JMC@SU-AI.ARPA">
JMC@SU-AI.ARPA
</A>&gt;
</address>
<i>
13 Aug 85  1521 PDT
</i><PRE>

[An earlier SU-bboard message that prompted the following sequence of 
replies seemed like total gibberish, so I have omitted it.  PGN]


                              [but not To: RISKS...]

I was taking [as?] my model Petr Beckmann's book "The Health Hazards of not
Going Nuclear" in which he contrasts the slight risks of nuclear energy with
the very large number of deaths resulting from conventional energy sources
from, e.g. mining and air pollution.  It seemed to me that your announcement
was similarly one sided in its consideration in risks of on-line systems and
ignoring the possibility of risks from their non-use.  I won't be specific
at present, but if you or anyone else wants to make the claim that there are
no such risks, I'm willing to place a substantial bet.

   [Clearly both inaction and non-use can be risky.  The first two items at
    the beginning of this issue (Vol 1 no 2) -- the lobstermen and the Union
    Carbide case -- involved inaction.  PGN]

</PRE>
<HR><H3><A NAME="subj7.4">
IJCAI as a forum   
</A>
</H3>
<address>
John McCarthy 
&lt;<A HREF="mailto:JMC@SU-AI.ARPA">
JMC@SU-AI.ARPA
</A>&gt;
</address>
<i>
14 Aug 85  1635 PDT
</i><PRE>

	Like Chris Stuart, I have also contemplated using IJCAI as a forum.
My issue concerns the computer scientists who have claimed, in one case "for
fundamental computer science reasons" that the computer programs required
for the Strategic Defense Initiative (Star Wars) are impossible to write and
verify without having a series of nuclear wars for practice.  Much of the
press (both Science magazine and the New York Times) have assumed (in my
opinion correctly) that these people are speaking, not merely as
individuals, but in the name of computer science itself.  The phrase "for
fundamental computer science reasons" was used by one of the computer
scientist opponents.

	In my opinion these people are claiming an authority they do not
possess.  There is no accepted body of computer science principles that
permits concluding that some particular program that is mathematically
possible cannot be written and debugged.  To put it more strongly, I don't
believe that there is even one published paper purporting to establish
such principles.  However, I am not familiar with the literature on
software engineering.

	I think they have allowed themselves to be tempted into
exaggerating their authority in order to support the anti-SDI cause,
which they support for other reasons.

	I have two opportunities to counter them.  First, I'm giving
a speech in connection with an award I'm receiving.  Since I didn't
have to submit a paper, I was given carte blanche.  Second, I have
been asked by the local arrangements people to hold a press conference.
I ask for advice on whether I should use either of these opportunities.
I can probably even arrange for some journalist to ask my opinion on
the Star Wars debugging issue, so I wouldn't have to raise the issue
myself.  Indeed since my position is increasingly public, I might
be asked anyway.

	To make things clear, I have no position on the feasibility
of SDI, although I hope it can be made to work.  Since even the
physical principles that will be proposed for the SDI system haven't
been determined, it isn't possible to determine what kind of programs
will be required and to assess how hard they will be to write
and verify.  Moreover, it may be possible to develop new techniques
involving both simulation and theorem proving relevant to verifying
such a program.  My sole present point is that no-one can claim
the authority of computer science for asserting that the task
is impossible or impractical.

	There is even potential relevance to AI, since some of the
opponents of SDI, and very likely some of the proponents, have suggested
that AI techniques might be used.

	I look forward to the advice of BBOARD contributors.

</PRE>
<HR><H3><A NAME="subj7.5">
Verifying SDI software
</A>
</H3>
<address>
Peter Karp 
&lt;<A HREF="mailto:KARP@SUMEX-AIM.ARPA">
KARP@SUMEX-AIM.ARPA
</A>&gt;
</address>
<i>
Thu 15 Aug 85 00:17:09-PDT
</i><PRE>

John McCarthy: I argue CPSR's approach is reasonable as follows:

1) I assume you admit that bugs in the SDI software would be very
   bad since this could quite conceivably leave our cities open
   Soviet attack.

2) You concede software verification theory does not permit proof
   of correctness of such complex programs.  I concede this same
   theory does not show such proofs are impossible.

3) The question to responsible computer professionals then becomes:
   From your experience in developing and debugging complex computer
   systems, how likely do you believe it is that currently possible
   efforts could produce error-free software, or even software whose
   reliability is acceptable given the risks in (1) ?

Clearly answering (3) requires subjective judgements, but computer
professionals are among the best people to ask to make such 
judgements given their expertise.  

I think it would be rather amusing if you told the press what you
told bboard: that you "hope they can get it to work".


</PRE>
<HR><H3><A NAME="subj7.6">
sdi 
</A>
</H3>
<address>
John McCarthy 
&lt;<A HREF="mailto:JMC@SU-AI.ARPA">
JMC@SU-AI.ARPA
</A>&gt;
</address>
<i>
16 Aug 85  2200 PDT
</i><PRE>

I thank those who advised me on whether to say something about the
SDI controversy in my lecture or at the press conference.  I don't
presently intend to say anything about it in my lecture.  Mainly
this is because thinking about what to say about a public issue
would interfere with thinking about AI.  I may say something or
distribute a statement at the press conference.

I am not sure I understand the views of those who claim the computer
part of SDI is infeasible.  Namely, do they hope it won't work?  If
so, why?  My reactionary mind thinks up hypotheses like the following.
It's really just partisanship.  They have been against U.S. policy
in many areas including defense, that they automatically oppose any
initiative and then look for arguments.

</PRE>
<HR><H3><A NAME="subj7.7">
Re:  [John McCarthy &lt;JMC@SU-AI.ARPA&gt;: IJCAI as a forum   ]
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:vax-populi!dparnas@nrl-css ">
vax-populi!dparnas@nrl-css 
</A>&gt;
</address>
<i>
Thu, 15 Aug 85 13:01:46 pdt
</i><PRE>

McCarthy is making a classic error of criticizing something that 
he has not read.  I have not argued that any program cannot be written 
and debugged.  I argue a much weaker and safer position, that we cannot
know that the program has been debugged.  There are "fundamental computer
science reasons" for that, they have to do with the size of the smallest
representation of the mathematical functions that describe the behaviour
of computer software and our inability to know that the specifications
are correct.  

Dave


Date: Thu, 15 Aug 85 13:14:22 pdt
From: vax-populi!dparnas@nrl-css (Dave Parnas)
To: neumann@SRI-CSL.ARPA
Subject: Copy of cover letter to Prof. John McCarthy

Dear Dr. M

	A friend of mine, whose principal weakness is reading the junk mail 
posting on bulletin boards sent me a copy of your posting with regard to 
SDI.

	It is in general a foolish error to criticize a paper that you have
not read on the basis of press reports of it.

	Nobody has, in fact, claimed that any given program cannot be
written and "debugged" (whatever that means).  The claim is much weaker,
that we cannot know with confidence that the program does meet its
specification and that the specification is the right one.  There is both
theoretical (in the form of arguments about the minimal representation of
non-continuous functions) and empirical evidence to support that claim.  The
fact that you do not read the literature on software engineering does not
give you the authority to say that there are no papers supporting such a
claim.

	As I would hate to see anyone, whether he be computer scientist or AI
specialist, argue on the basis of ignorance, I am enclosing ...


</PRE>
<HR><H3><A NAME="subj7.8">
Speaking Out On SDI
</A>
</H3>
<address>
Gary Martins 
&lt;<A HREF="mailto:GARY@SRI-CSLA.ARPA">
GARY@SRI-CSLA.ARPA
</A>&gt;
</address>
<i>
Thu 15 Aug 85 18:50:46-PDT
</i><PRE>
To: jmc@SU-AI.ARPA

Dear Dr. McC -

In response to your BB announcement:

1.  Given that IJCAI is by and large a forum for hucksters and crackpots of
various types, it is probably a poor choice of venue for the delivery of
thoughts which you'd like taken seriously by serious folks.

2. Ditto, for tying your pro-SDI arguments in with "AI"; it can only lower
the general credibility of what you have to say.

3.  You are certainly right that no-one can now prove that the creation of
effective SDI software is mathematically impossible, and that part of your
argument is beyond reproach, even if rather trivial.  However, you then
slip into the use of the word "impractical", which is a very different
thing, with entirely different epistemological status.  On this point,
you may well be entirely wrong -- it is an empirical matter, of course.


I take no personal stand on the desirability or otherwise of SDI, but
as a citizen I have a vested interest in seeing some discussions of
the subject that are not too heavily tainted by personal bias and
special pleading.


Gary R. Martins
Intelligent Software Inc.

 ------------------------------

       International Conference on Software Engineering
              28-30 August 1985, London UK
         Feasibility of Software for Strategic Defense
                    Panel Discussion
             30 August 1985, 1:30 - 3:00 PM

                       Panelists:       
        Frederick P. Brooks III, University of North Carolina
        David Parnas, University of Victoria
           Moderator: Manny Lehman, Imperial College

This panel will discuss the feasibility of building the software for the
Strategic Defense System ('Star Wars') so that that software could be
adequately trusted to satisfy all of the critical performance goals.  The
panel will focus strictly on the software engineering problems in building
strategic defense systems, considering such issues as the reliability of the
software and the manageability of the development.

    [This should be a very exciting discussion.  Fred has extensive hardware,
     software, and management experience from his IBM OS years.  David's
     8 position papers have been widely discussed -- and will appear in the
     September American Scientist.  We hope to be able to report on this
     panel later (or read about it in ARMS-D???).   Perhaps some of you
     will be there and contribute your impressions.  PGN]

</PRE>
<A NAME="subj8"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj8.1">

</A>
</H3>
<address>
Tom Parmenter 
&lt;<A HREF="mailto:parmenter@SCRC-STONY-BROOK.ARPA">
parmenter@SCRC-STONY-BROOK.ARPA
</A>&gt;
</address>
<i>
Mon, 15 Jul 85 11:05 EDT
</i><PRE>
From an article in Technology Review by Herbert Lin on the difficulty
(impossibility) of developing software for the Star Wars (Strategic
Defense Initiative) system:

  Are there alternatives to conventional software development?  Some defense
  planners think so.  Major Simon Worden of the SDI office has said that

    "A human programmer can't do this.  We're going to be developing new
     artificial intelligence systems to write the software.  Of course, 
     you have to debug any program.  That would have to be AI too."

</PRE>
<A NAME="subj9"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj9.1">

</A>
</H3>
<address>
Latitudinarian Lobster
&lt;<A HREF="mailto:uwmacc!myers@wisc-rsch.arpa ">
uwmacc!myers@wisc-rsch.arpa 
</A>&gt;
</address>
<i>
Wed, 14 Aug 85 18:08:57 cdt
</i><PRE>
To: risks@sri-csl.arpa 
Subject: CPSR-Madison paper for an issue of risks?

The following may be reproduced in any form, as long as the text and credits
remain unmodified.  It is a paper especially suited to those who don't already
know a lot about computing.  Please mail comments or corrections to:

Jeff Myers                              [Something was lost here...]
University of Wisconsin-Madison		reflect the views of any other
Madison Academic Computing Center	person or group at UW-Madison.
1210 West Dayton Street
Madison, WI  53706
ARPA: uwmacc!myers@wisc-rsch.ARPA
UUCP: ..!{harvard,ucbvax,allegra,heurikon,ihnp4,seismo}!uwvax!uwmacc!myers
BitNet: MYERS at MACCWISC

 -------------------------------------------------------------------------------

                   COMPUTER UNRELIABILITY AND NUCLEAR WAR

     Larry Travis, Ph.D., Professor of Computer Sciences, UW-Madison 
	      Daniel Stock, M.S., Computer Sciences, UW-Madison
	     Michael Scott, Ph.D., Computer Sciences, UW-Madison
	    Jeffrey D. Myers, M.S., Computer Sciences, UW-Madison
	      James Greuel, M.S., Computer Sciences, UW-Madison
James Goodman, Ph.D., Assistant Professor of Computer Sciences, UW-Madison
     Robin Cooper, Ph.D., Associate Professor of Linguistics, UW-Madison
	     Greg Brewster, M.S., Computer Sciences, UW-Madison

                               Madison Chapter
               Computer Professionals for Social Responsibility
                                  June 1984

           Originally prepared for a workshop at a symposium on the
                     Medical Consequences of Nuclear War
                         Madison, WI, 15 October 1983

  [The paper is much too long to include in this forum, but can be 
  obtained from Jeff Myers at the above net addresses, or FTPed from
  RISKS@SRI-CSL:&lt;RISKS&gt;MADISON.PAPER.  The section headings are as follows:

    1.  Computer Use in the Military Today, James Greuel, Greg Brewster
    2.  Causes of Unreliability, Daniel Stock, Michael Scott
    3.  Artificial Intelligence and the Military, Robin Cooper
    4.  Implications, Larry Travis, James Goodman

  ]

</PRE>
<A NAME="subj10"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A><H3><A NAME="subj10.1">

</A>
</H3>
<address>
Clifford Johnson 
&lt;<A HREF="mailto:GA.CJJ@Forsythe">
GA.CJJ@Forsythe
</A>&gt;
</address>
<i>
Wed, 21 Aug 85 17:46:55 PDT
</i><PRE>
Subject:  @=  Can a computer declare war?

****************** CAN A COMPUTER DECLARE WAR?

Below is the transcript of a court hearing in which it is was argued by the
Plaintiff that nuclear launch on warning capability (LOWC, pronounced
lou-see) unconstitutionally delegates Congress's mandated power to declare
war.

The Plaintiff is a Londoner and computer professional motivated to act by
the deployment of Cruise missiles in his hometown.  With the advice and
endorsement of Computer Professionals for Social Responsibility, on February
29, 1984, he filed a complaint in propria persona against Secretary of
Defense Caspar Weinberger seeking a declaration that peacetime LOWC is
unconstitutional.  The first count is presented in full below; a second
count alleges a violation of Article 2, Part 3 of the United Nations Charter
which binds the United States to settle peacetime disputes "in such a manner
that international peace and security, and justice, are not endangered":

1.  JURISDICTION:  The first count arises under the Constitution of the
United States at Article I, Section 8, Clause 11, which provides that "The
Congress shall have Power ... To declare War"; and at Article II, Section 2,
Clause 1, which provides that "The President shall be Commander in Chief" of
the Armed Forces.

2.  Herein, "launch-on-warning-capability" is defined to be any set of
procedures whereby the retaliatory launching of non-recoverable nuclear
missiles may occur both in response to an electronically generated warning
of attacking missiles and prior to the conclusively confirmed commencement
of actual hostilities with any State presumed responsible for said attack.

3.  The peacetime implementation of launch-on-warning-capability is now
presumed constitutional, and its execution by Defendant and Defendant's
appointed successors is openly threatened and certainly possible.

4.  Launch-on-warning-capability is now subject to a response time so short
as to preclude the intercession of competent judgment by the President or by
his agents.

5.  The essentially autonomous character of launch-on-warning-capability
gives rise to a substantial probability of accidental nuclear war due to
computer-related error.

6.  Said probability substantially surrenders both the power of Congress to
declare war and the ability of the President to command the Armed Forces,
and launch-on-warning-capability is therefore doubly repugnant to the
Constitution.

7.  The life and property of Plaintiff are gravely jeopardized by the threat
of implementation of launch-on-warning-capability.

WHEREFORE, Plaintiff prays this court declare peacetime
launch-on-warning-capability unconstitutional.

****************** THE HEARING IN THE COURT OF APPEALS FOLLOWS 

[in the original message, and is too lengthy to include here.  I presume you
will find it in ARMS-D -- see my interpolation into the note from Bob Carter
above.  Otherwise, you can FTP it from SRI-CSL:&lt;RISKS&gt;JOHNSON.HEARING.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/1.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.1.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/1.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-55</DOCNO>
<DOCOLDNO>IA012-000128-B043-498</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1/index.html 128.240.150.127 19970217001423 text/html 28762
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:12:51 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Index to Volume 1</TITLE>
<LINK REL="Next" HREF="/Risks/2/index.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Index to Volume 1</H1>
<H2> Saturday, 31 May 1986 </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------">
<DL>
<DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.1.html">Volume 1 Issue 1 (1 Aug 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.1.html#subj1">  ACM Council Resolution of 8 October 1984</A>
<LI><A HREF="/Risks/1.1.html#subj2">  An Agenda for the Future</A>
<LI><A HREF="/Risks/1.1.html#subj3">  Computer-Related Incidents Illustrating Risks to the Public </A>
<LI><A HREF="/Risks/1.1.html#subj4">  Strategic Computing Initiative</A>
<LI><A HREF="/Risks/1.1.html#subj5">  Strategic Defense Initiative; David Parnas and SDI</A>
<LI><A HREF="/Risks/1.1.html#subj6">  Herb Lin: Software for Ballistic Missile Defense, June 1985</A>
<LI><A HREF="/Risks/1.1.html#subj7">  Weapons and Hope by Freeman Dyson (minireview by Peter Denning)</A>
<LI><A HREF="/Risks/1.1.html#subj8">  Christiane Floyd et al.: The Responsible Use of Computers</A>
<LI><A HREF="/Risks/1.1.html#subj9">  Human safety (software safety)</A>
<LI><A HREF="/Risks/1.1.html#subj10">  Computers in critical environments, Rome, 23-25 October 1985</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.2.html">Volume 1 Issue 2 (28 Aug 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.2.html#subj1">  Introduction; three more risk items (Peter Neumann)</A>
<LI><A HREF="/Risks/1.2.html#subj2">  Mariner 1 Irony (Nicholas Spies)</A>
<LI><A HREF="/Risks/1.2.html#subj3">  RISKS Forum ... [Reaction] (Bob Carter)</A>
<LI><A HREF="/Risks/1.2.html#subj4">  RISKS Forum ... [An Air Traffic Control Problem] (Scott Rose)</A>
<LI><A HREF="/Risks/1.2.html#subj5">  Risks in AI Diagnostic Aids (Art Smith)</A>
<LI><A HREF="/Risks/1.2.html#subj6">  Warning! ... [A Trojan Horse Bites Man] (Don Malpass)</A>
<LI><A HREF="/Risks/1.2.html#subj7">  SDI (Martin Moore, Jim Horning, John McCarthy, Peter Karp, Dave Parnas,        Gary Martins, Tom Parmenter; panel at 8th ICSE in London)
</A>
<LI><A HREF="/Risks/1.2.html#subj8">  The Madison Paper on Computer Unreliability and Nuclear War (Jeff Myers)</A>
<LI><A HREF="/Risks/1.2.html#subj9">  Can a Computer Declare War? (Cliff Johnson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.3.html">Volume 1 Issue 3 (30 Aug 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.3.html#subj1">  Miscellaneous comments on V1#2 (Dave Curry)</A>
<LI><A HREF="/Risks/1.3.html#subj2">  Computer/hardship list (Jerome Rosenberg)</A>
<LI><A HREF="/Risks/1.3.html#subj3">  Medical KBES --  Some AI systems may need FDA approval</A>
<LI><A HREF="/Risks/1.3.html#subj4">  Health hazards of CRT use (Robin Cooper)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.4.html">Volume 1 Issue 4 (2 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.4.html#subj1">  The Case of the Broken Buoy (Matt Bishop)</A>
<LI><A HREF="/Risks/1.4.html#subj2">  Inaction; Buoys will be buoys; KAL 007; Malpractice (PGN)</A>
<LI><A HREF="/Risks/1.4.html#subj3">  Health Hazards of CRT Use (Brint Cooper, Robin Cooper, PGN)</A>
<LI><A HREF="/Risks/1.4.html#subj4">  Medical Software (Brint Cooper)</A>
<LI><A HREF="/Risks/1.4.html#subj5">  Rolm's Hawk-32 (Doug Bryan)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.5.html">Volume 1 Issue 5 (4 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.5.html#subj1">  The Strategic Defense Initiative (Joseph Weizenbaum)</A>
<LI><A HREF="/Risks/1.5.html#subj2">  1.5 million Ford engines need recall? (Hal Murray)</A>
<LI><A HREF="/Risks/1.5.html#subj3">  Risks in CAD, etc. (Eugene Miya)</A>
<LI><A HREF="/Risks/1.5.html#subj4">  crt &amp; non-crt risks (Mike McLaughlin)</A>
<LI><A HREF="/Risks/1.5.html#subj5">  Computerworld... on Union Carbide and NJ false arrests (Charlie Spitzer)</A>
<LI><A HREF="/Risks/1.5.html#subj6">  More on false arrests (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.6.html">Volume 1 Issue 6 (6 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.6.html#subj1">  Joseph Weizenbaum's comments (Dave Parnas)</A>
<LI><A HREF="/Risks/1.6.html#subj2">  Good Risks and Bad Risks (Dave Brandin, PGN)</A>
<LI><A HREF="/Risks/1.6.html#subj3">  Hot rodding you AT (Dan Bower)</A>
<LI><A HREF="/Risks/1.6.html#subj4">  Hazards of VDTs and CRTs (Al Friend)</A>
<LI><A HREF="/Risks/1.6.html#subj5">  crt &amp; non-crt risks (Brint Cooper)</A>
<LI><A HREF="/Risks/1.6.html#subj6">  The Case of the Broken Buoy (Herb Lin, Matt Bishop)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.7.html">Volume 1 Issue 7 (8 Seo 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.7.html#subj1">  The risks of not using some technology (John McCarthy)</A>
<LI><A HREF="/Risks/1.7.html#subj2">  More on SDI (Joseph Weizenbaum)</A>
<LI><A HREF="/Risks/1.7.html#subj3">  SDI reliability (Martin Moore)</A>
<LI><A HREF="/Risks/1.7.html#subj4">  Re: Hazards of VDTs and CRTs (Bernie Elspas)</A>
<LI><A HREF="/Risks/1.7.html#subj5">  Viruses, Trojan horses, and worms (Fred Hapgood, PGN)</A>
<LI><A HREF="/Risks/1.7.html#subj6">  Re: The Case of the Broken Buoy (Herb Lin, Matt Bishop) </A>
<LI><A HREF="/Risks/1.7.html#subj7">  Re: Hot rodding you AT (Keith F. Lynch)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.8.html">Volume 1 Issue 8 (8 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.8.html#subj1">  Risks of omission (Nancy Leveson, Nicholas Spies, Herb Lin, Dave Parnas)</A>
<LI><A HREF="/Risks/1.8.html#subj2">  Hot rodding you AT and the weather (John McCarthy)</A>
<LI><A HREF="/Risks/1.8.html#subj3">  Re:  Good Risks and Bad Risks (Brint Cooper)</A>
<LI><A HREF="/Risks/1.8.html#subj4">  SDI reliability (Herb Lin)</A>
<LI><A HREF="/Risks/1.8.html#subj5">  Viruses, Trojan horses, and worms (Lin and Neumann, 2 each -- his own?)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.9.html">Volume 1 Issue 9 (9 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.9.html#subj1">  McCarthy, Weizenbaum on SDI  (Douglas Schuler)</A>
<LI><A HREF="/Risks/1.9.html#subj2">  Why I'm against even a reliable SDI (Jeffrey Mogul)</A>
<LI><A HREF="/Risks/1.9.html#subj3">  Risk Assessment and Risk Management (Edward V. Berard)</A>
<LI><A HREF="/Risks/1.9.html#subj4">  Risks in displaying a file containing control characters (Keith F. Lynch)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.10.html">Volume 1 Issue 10 (12 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.10.html#subj1">  Weizenbaum, etc.; even if SDI worked.... (John Shore)</A>
<LI><A HREF="/Risks/1.10.html#subj2">  SDI (John McCarthy)</A>
<LI><A HREF="/Risks/1.10.html#subj3">  More on SDI reliability (Martin Moore)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.11.html">Volume 1 Issue 11 (13 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.11.html#subj1">  SDI and John McCarthy (Charlie Crummer)</A>
<LI><A HREF="/Risks/1.11.html#subj2">  SDI and Safeguard (John Mashey)</A>
<LI><A HREF="/Risks/1.11.html#subj3">  SDI and Robert Jastrow (Herb Lin)</A>
<LI><A HREF="/Risks/1.11.html#subj4">  Some financial disaster cases from Software Engineering Notes          (three contributions, totalling five reports)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.12.html">Volume 1 Issue 12 (13 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.12.html#subj1">  Wire-Transfer Risks; Risk of Non-application of Technology (Jerry Saltzer)</A>
<LI><A HREF="/Risks/1.12.html#subj2">  Date-Time stamps (and errors therein) (Ted M P Lee)</A>
<LI><A HREF="/Risks/1.12.html#subj3">  JMC's remarks (Joseph Weizenbaum)</A>
<LI><A HREF="/Risks/1.12.html#subj4">  Subjective Factors in Risk Assessment (Lynne C. Moore)</A>
<LI><A HREF="/Risks/1.12.html#subj5">  Moral vs. Technological Progress (Charlie Crummer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.13.html">Volume 1 Issue 13 (15 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.13.html#subj1">  Risks in RISKS (Peter G. Neumann)</A>
<LI><A HREF="/Risks/1.13.html#subj2">  Preserving rights to Email messages (Larry Hunter)</A>
<LI><A HREF="/Risks/1.13.html#subj3">  Risk Comparisons (T. Tussing)</A>
<LI><A HREF="/Risks/1.13.html#subj4">  Risks history/philosophy (Nicholas Spies)       [long but interesting]</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.14.html">Volume 1 Issue 14 (16 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.14.html#subj1">  Pitfalls of a Fail-Safe Mail Protocol? (Peter G. Neumann)</A>
<LI><A HREF="/Risks/1.14.html#subj2">  Some Ruminations on an Ideal Defense System (Bob Estell)</A>
<LI><A HREF="/Risks/1.14.html#subj3">  SDI, feasibility is irrelevant (Gopal)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.15.html">Volume 1 Issue 15 (20 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.15.html#subj1">  SDI Panel at 8th ICSE in London (David Weiss)</A>
<LI><A HREF="/Risks/1.15.html#subj2">  Risks to the Moderator (PGN)</A>
<LI><A HREF="/Risks/1.15.html#subj3">  Mailer Protocol Woes (Marty Moore)</A>
<LI><A HREF="/Risks/1.15.html#subj4">  Another Horror Story -- Sidereal Time Rollover (Marty Moore)</A>
<LI><A HREF="/Risks/1.15.html#subj5">  Article: Health Hazards of Computers (Ted Shapin)</A>
<LI><A HREF="/Risks/1.15.html#subj6">  Two More SDI Related Queries (douglas schuler)</A>
<LI><A HREF="/Risks/1.15.html#subj7">  CAL ID -- computerized fingerprint system (douglas schuler)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.16.html">Volume 1 Issue 16 (26 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.16.html#subj1">  Intellectual honesty and the SDI (Bill Anderson)</A>
<LI><A HREF="/Risks/1.16.html#subj2">  RISKy Stuff (Mike Padlipsky)</A>
<LI><A HREF="/Risks/1.16.html#subj3">  Mailer Protocol Woes (Rob Austein)</A>
<LI><A HREF="/Risks/1.16.html#subj4">  Risks in Synchronizing Network Clocks (Ann Westine for Jon Postel)</A>
<LI><A HREF="/Risks/1.16.html#subj5">  Re: Moral vs. Technological Progress (Joel Upchurch)</A>
<LI><A HREF="/Risks/1.16.html#subj6">  Risk Contingency Planning -- Computers in Mexico (Mike McLaughlin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.17.html">Volume 1 Issue 17 (27 Sep 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.17.html#subj1">  SDI debate announcement</A>
<LI><A HREF="/Risks/1.17.html#subj2">  Minor risk to the pocket book (Eugene Miya)</A>
<LI><A HREF="/Risks/1.17.html#subj3">  Social Impacts of Computing: Graduate Study at UC-Irvine (Rob Kling)</A>
<LI><A HREF="/Risks/1.17.html#subj4">  Friendly enemy test teams (John Mashey)</A>
<LI><A HREF="/Risks/1.17.html#subj5">  More protocol goofs (Dave Curry)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.18.html">Volume 1 Issue 18 (4 Oct 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.18.html#subj1">   Lack of a backup computer closes stock exchange (Marty Moore)</A>
<LI><A HREF="/Risks/1.18.html#subj2">   DPMA survey on computer crime offenses (J.A.N. Lee)</A>
<LI><A HREF="/Risks/1.18.html#subj3">   Ethics vs. morality (Marty Cohen)</A>
<LI><A HREF="/Risks/1.18.html#subj4">   The Mythical Man-Month of Risk (Stavros Macrakis)</A>
<LI><A HREF="/Risks/1.18.html#subj5">   Risk Assessment by real people (Mike McLaughlin)</A>
<LI><A HREF="/Risks/1.18.html#subj6">   CRTs again, solution to one eye-problem (Mike McLaughlin)</A>
<LI><A HREF="/Risks/1.18.html#subj7">   Failure of Mexican Networks (Dave Flory)</A>
<LI><A HREF="/Risks/1.18.html#subj8">   Technical Reports Lists (Laurence Leff)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.19.html">Volume 1 Issue 19 (8 Oct 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.19.html#subj1">  Emanations and interference in the civil sector (Peter Neumann,Jerry Saltzer)</A>
<LI><A HREF="/Risks/1.19.html#subj2">  Administrivia -- Escaped Mail and Delays (Mark S. Day)</A>
<LI><A HREF="/Risks/1.19.html#subj3">  Computer databases (Andy Mondore)</A>
<LI><A HREF="/Risks/1.19.html#subj4">  Re: Friendly test teams (John Mashey)</A>
<LI><A HREF="/Risks/1.19.html#subj5">  Re: CRTs again, solution to one eye-problem (Brint Cooper)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.20.html">Volume 1 Issue 20 (8 Oct 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.20.html#subj1">  Risks using robots in industry (Bill Keefe)</A>
<LI><A HREF="/Risks/1.20.html#subj2">  Re: Computer databases (Matt Bishop)</A>
<LI><A HREF="/Risks/1.20.html#subj3">  Registrar's databases; Database risks - census data (Hal Murray, 2 messages)</A>
<LI><A HREF="/Risks/1.20.html#subj4">  The winners of evolution... (William McKeeman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.21.html">Volume 1 Issue 21 (10 Oct 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.21.html#subj1">  Public Accountability (Jim Horning, Peter Neumann)</A>
<LI><A HREF="/Risks/1.21.html#subj2">  The Titanic Effect (JAN Lee)</A>
<LI><A HREF="/Risks/1.21.html#subj3">  Databases, Grades, etc. (Brian Borchers, Andy Mondore, Mark Day [twice],    Alan Wexelblat, Ross McKenrick, Randy Parker)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.22.html">Volume 1 Issue 22 (9 Nov 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.22.html#subj1">  Administratrivia (Friedrich von Henke)</A>
<LI><A HREF="/Risks/1.22.html#subj2">  Medical software incidents (Nancy Leveson)</A>
<LI><A HREF="/Risks/1.22.html#subj3">  European activities  (Udo Voges)</A>
<LI><A HREF="/Risks/1.22.html#subj4">  Robots are different (Jerry Saltzer)</A>
<LI><A HREF="/Risks/1.22.html#subj5">  Automobile computer control systems (Bennett Smith)</A>
<LI><A HREF="/Risks/1.22.html#subj6">  Police computers (Dave Dyer)</A>
<LI><A HREF="/Risks/1.22.html#subj7">  Electronic Surveillance (Geoffrey S. Goodfellow / Bill Keefe)</A>
<LI><A HREF="/Risks/1.22.html#subj8">  Network Mailer Woes (Lynne Moore)</A>
<LI><A HREF="/Risks/1.22.html#subj9">  Databases, grades, etc. (Karl Kluge, Andy Mondore, Mark Sienkiew)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.23.html">Volume 1 Issue 23 (19 Nov 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.23.html#subj1">  Expecting the unexpected (Peter G. Neumann)</A>
<LI><A HREF="/Risks/1.23.html#subj2">  Safety Group Activities in the U.S. (Nancy Leveson)</A>
<LI><A HREF="/Risks/1.23.html#subj3">  Automobile computer control systems susceptible to interference(Bennett Smith)</A>
<LI><A HREF="/Risks/1.23.html#subj4">  Irresponsible computer "game"; BBS Legislation (Ted Shapin)</A>
<LI><A HREF="/Risks/1.23.html#subj5">  SDI Debate at MIT (John L. Mills)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.24.html">Volume 1 Issue 24 (20 Nov 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.24.html#subj1">  Doing Something About Risks in Computer Systems (Brad Davis)</A>
<LI><A HREF="/Risks/1.24.html#subj2">  Space Program Software (Jerome Rosenberg)</A>
<LI><A HREF="/Risks/1.24.html#subj3">  Susceptibility to interference (John Brewer)</A>
<LI><A HREF="/Risks/1.24.html#subj4">  Expecting the unexpected  (Herb Lin)</A>
<LI><A HREF="/Risks/1.24.html#subj5">  Philip W. Anderson's "Case Against Star Wars" (Pete Kaiser)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.25.html">Volume 1 Issue 25 (1 Dec 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.25.html#subj1">  Some Thoughts on Unpredicted Long-Term Risks (Peter G. Neumann)</A>
<LI><A HREF="/Risks/1.25.html#subj2">  Computer snafu halts treasury (Peter G. Trei)</A>
<LI><A HREF="/Risks/1.25.html#subj3">  "Hacker" Game (Ken Brown; Keith F. Lynch; Werner Uhrig)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.26.html">Volume 1 Issue 26 (4 Dec 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.26.html#subj1">  Humility (Matt Bishop)</A>
<LI><A HREF="/Risks/1.26.html#subj2">  Reliable Computer Systems (Jim Horning)</A>
<LI><A HREF="/Risks/1.26.html#subj3">  Electromagnetic Interference (Peter G. Neumann)</A>
<LI><A HREF="/Risks/1.26.html#subj4">  Hackers (Thomas Cox)</A>
<LI><A HREF="/Risks/1.26.html#subj5">  "The Hacker Game": Is it simulating security of *REAL* machines? (Ted Shapin)</A>
<LI><A HREF="/Risks/1.26.html#subj6">  Unexpected load on telephone trunks (Ted Shapin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.27.html">Volume 1 Issue 27 (7 Dec 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.27.html#subj1">Contents: SPECIAL ISSUE on viruses and worms</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.28.html">Volume 1 Issue 28 (9 Dec 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.28.html#subj1">  Viruses and Worms (Mark S. Day, Aaron M. Ellison, Ted Lee, Dave Parnas)</A>
<LI><A HREF="/Risks/1.28.html#subj2">  Electromagnetic Interference (Chuq Von Rospach)</A>
<LI><A HREF="/Risks/1.28.html#subj3">  Crackers (Peter Reiher, Matt Bishop, Dave Dyer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.29.html">Volume 1 Issue 29 (12 Dec 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.29.html#subj1">  Computer-compared prescriptions (Dave Platt)</A>
<LI><A HREF="/Risks/1.29.html#subj2">  SDI: Danny Cohen and Eastport Group comments (Gary Chapman via Jim Horning)</A>
<LI><A HREF="/Risks/1.29.html#subj3">  Worms, etc. (Keith F. Lynch, Stavros Macrakis)</A>
<LI><A HREF="/Risks/1.29.html#subj4">  Passwords, etc. (King Ables, Dave Curry, Dan Bower)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.30.html">Volume 1 Issue 30 (16 Dec 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.30.html#subj1">  Request for Cases, Settled or Decided (George S. Cole)</A>
<LI><A HREF="/Risks/1.30.html#subj2">  Risks of job displacement from computerization (Fred Hapgood)</A>
<LI><A HREF="/Risks/1.30.html#subj3">  Risks re computer-compared prescriptions (Richard Lamson)</A>
<LI><A HREF="/Risks/1.30.html#subj4">  Legal bootlegs (a case against worms) (K. Richard Magill)</A>
<LI><A HREF="/Risks/1.30.html#subj5">  Passwords ()</A>
<LI><A HREF="/Risks/1.30.html#subj6">  Verifying source code vs. executable code (Martin J. Moore)</A>
<LI><A HREF="/Risks/1.30.html#subj7">  Seminar - SDI Debate (SU)   (Joan Feigenbaum)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.31.html">Volume 1 Issue 31 (19 Dec 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.31.html#subj1">  Enough on passwords? Pharmacy systems (Elizabeth Willey)</A>
<LI><A HREF="/Risks/1.31.html#subj2">  Risks re computer-compared prescriptions (Brint Cooper)</A>
<LI><A HREF="/Risks/1.31.html#subj3">  Oops (Marty Moore)</A>
<LI><A HREF="/Risks/1.31.html#subj4">  $32 Billion Overdraft Resulted From Snafu (Washington Post)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.32.html">Volume 1 Issue 32 (23 Dec 85)</A>
<DD><UL>
<LI><A HREF="/Risks/1.32.html#subj1">  Can Bank of New York Bank on Star Wars? (Jim Horning)</A>
<LI><A HREF="/Risks/1.32.html#subj2">  Cohen's AT&amp;T SDI Software Analogy (Richard A. Cowan)</A>
<LI><A HREF="/Risks/1.32.html#subj3">  Failure probabilities in decision chains (Will Martin)</A>
<LI><A HREF="/Risks/1.32.html#subj4">  Ten-year any-worseries (Dan Hoey)</A>
<LI><A HREF="/Risks/1.32.html#subj5">  Multiple digests as a result of crashed systems (Rob Austein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.33.html">Volume 1 Issue 33 (1 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.33.html#subj1">  Star Wars and Bank of NY (Brint Cooper, Chris Hibbert, Jim Horning)</A>
<LI><A HREF="/Risks/1.33.html#subj2">  Lipton and SDI (Herb Lin)</A>
<LI><A HREF="/Risks/1.33.html#subj3">  The robot sentry (Martin Minow)</A>
<LI><A HREF="/Risks/1.33.html#subj4">  Murphy is watching YOU (Rob Austein)</A>
<LI><A HREF="/Risks/1.33.html#subj5">  Re: Failure probabilities in decision chains (Stephen Wolff)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.34.html">Volume 1 Issue 34 (4 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.34.html#subj1">  C&amp;P Computer Problems Foul 44,000 D.C. Phones (Mike McLaughlin)</A>
<LI><A HREF="/Risks/1.34.html#subj2">  Putting the Man in the Loop; Testing SDI; Independent Battlestations    (Jim McGrath)
</A>
<LI><A HREF="/Risks/1.34.html#subj3">  Failure probablities in decision chains... independence (Edward Vielmetti)</A>
<LI><A HREF="/Risks/1.34.html#subj4">  Pharmacy prescription systems (Normand Lepine)</A>
<LI><A HREF="/Risks/1.34.html#subj5">  Masquerading (Paul W. Nelson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.35.html">Volume 1 Issue 35 (6 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.35.html#subj1">  SDI --    Meteors as substitutes for nuclear war (Jim Horning, Dave Parnas)
    Putting a Man in the Loop (Jim McGrath, Herb Lin, JM again)
    Testing SDI (Herb Lin, Jim McGrath, HL again)
    Independent Battlestations (Herb Lin, Jim McGrath, HL again)
    The Goal of SDI; Politicians (Jim McGrath)
</A>
<LI><A HREF="/Risks/1.35.html#subj2">  Pharmacy prescription systems (Rodney Hoffman)</A>
<LI><A HREF="/Risks/1.35.html#subj3">  How to steal people's passwords (Roy Smith)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.36.html">Volume 1 Issue 36 (7 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.36.html#subj1">  PLEASE READ Weapons and Hope by Freeman Dyson. (Peter Denning)</A>
<LI><A HREF="/Risks/1.36.html#subj2">  Wolves in the woods (Jim Horning, Dave Parnas)</A>
<LI><A HREF="/Risks/1.36.html#subj3">  "Certifiable reliability" and the purpose of SDI (Michael L. Scott)</A>
<LI><A HREF="/Risks/1.36.html#subj4">  SDI Testing (Jim McGrath, Jim Horning)</A>
<LI><A HREF="/Risks/1.36.html#subj5">  Dec. 85 IEEE TSE: Special Issue on Software Reliability--Part I</A>
<LI><A HREF="/Risks/1.36.html#subj6">  Masquerading (R. Michael Tague)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.37.html">Volume 1 Issue 37 (9 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.37.html#subj1">  IEEE TSE Special Issue on Reliability -- Part 1 (Nancy Leveson)</A>
<LI><A HREF="/Risks/1.37.html#subj2">  SDI Testing (Nancy Leveson, Dave Parnas)</A>
<LI><A HREF="/Risks/1.37.html#subj3">  Multiple redundancy (Henry Spencer)</A>
<LI><A HREF="/Risks/1.37.html#subj4">  On Freeman Dyson (Gary Chapman, Jon Jacky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.38.html">Volume 1 Issue 38 (9 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.38.html#subj1">  Ad-hominem SDI discussion (Mike McLaughlin [and Peter Neumann])</A>
<LI><A HREF="/Risks/1.38.html#subj2">  Men in the loop (Martin J. Moore)</A>
<LI><A HREF="/Risks/1.38.html#subj3">  Failure probabilities in decision chains (Jim Miller) [also in SOFT-ENG]</A>
<LI><A HREF="/Risks/1.38.html#subj4">  Testing SDI (Karl Kluge, Robert Goldman)</A>
<LI><A HREF="/Risks/1.38.html#subj5">  Summing Up on SDI (Jim McGrath)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.39.html">Volume 1 Issue 39 (13 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.39.html#subj1">  Real-time responsibility (Dave Wade)</A>
<LI><A HREF="/Risks/1.39.html#subj2">  Big Brother (Jim McGrath, Peter Neumann)</A>
<LI><A HREF="/Risks/1.39.html#subj3">  Men in the SDI loop (Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.40.html">Volume 1 Issue 40 (17 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.40.html#subj1">  Big Brother (Jim Ziobro, Keith Lynch)</A>
<LI><A HREF="/Risks/1.40.html#subj2">  Multiple redundancy (Henry Spencer)</A>
<LI><A HREF="/Risks/1.40.html#subj3">  COMPASS 86: System Integrity: Process Security and Safety (Al Friend)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.41.html">Volume 1 Issue 41 (19 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.41.html#subj1">  On a Clear Day You Can See Forever ... or Nothing At All (Peter G. Neumann)</A>
<LI><A HREF="/Risks/1.41.html#subj2">  Unreleased SDIO Computing Panel Report: Specialists Fault `Star Wars' Work</A>
<LI><A HREF="/Risks/1.41.html#subj3">  Man in the loop and magnetic bottles (Jon Jacky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.42.html">Volume 1 Issue 42 (28 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.42.html#subj1">  The Space Shuttle Challenger (Peter G. Neumann)</A>
<LI><A HREF="/Risks/1.42.html#subj2">  When you start an engine at 40 below, you could be injured...  (David Wade)</A>
<LI><A HREF="/Risks/1.42.html#subj3">  "Brazil" and Risks to the Public (Martin Minow)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.43.html">Volume 1 Issue 43 (29 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.43.html#subj1">  Reliability of Shuttle Destruct System (Martin J. Moore) (LONG MESSAGE)</A>
<LI><A HREF="/Risks/1.43.html#subj2">  Challenger lost (and note on self-destruct mechanism) (Earle S. Kyle, jr.)</A>
<LI><A HREF="/Risks/1.43.html#subj3">  Challenger ICING !!! (Werner Uhrig)</A>
<LI><A HREF="/Risks/1.43.html#subj4">  Big Brother, again (Col. G. L. Sicherman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.44.html">Volume 1 Issue 44 (29 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.44.html#subj1">  Shuttle SRB/MFT self-destruct mechanisms     (Dusty Bleher, Herb Lin, Martin Moore)
</A>
<LI><A HREF="/Risks/1.44.html#subj2">  Challenger speculation (Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/1.45.html">Volume 1 Issue 45 (31 Jan 86)</A>
<DD><UL>
<LI><A HREF="/Risks/1.45.html#subj1">  Risks from discussing Reliability of Shuttle Destruct System    (John Carpenter, Peter G. Neumann)
</A>
<LI><A HREF="/Risks/1.45.html#subj2">  Possible triggering of the self-destruct mechanism (Peter G. Neumann)</A>
<LI><A HREF="/Risks/1.45.html#subj3">  Challenger and Living with High-Risk Technologies (Dave Benson)</A>
<LI><A HREF="/Risks/1.45.html#subj4">  The Challenger [non]accident (Jeff Siegal)</A>
<LI><A HREF="/Risks/1.45.html#subj5">  Shuttle Explosion -- Plutonium on Galileo (Larry Shilkoff)</A>
<LI><A HREF="/Risks/1.45.html#subj6">  Reliability in redundant systems (Brad Davis)</A>
</UL></DL>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-56</DOCNO>
<DOCOLDNO>IA012-000128-B043-535</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3/index.html 128.240.150.127 19970217001453 text/html 59495
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:13:04 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Index to Volume 3</TITLE>
<LINK REL="Pref" HREF="/Risks/2/index.html">
<LINK REL="Next" HREF="/Risks/4/index.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/4/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Index to Volume 3</H1>
<H2> Sunday, 2 November 1986 </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------">
<DL>
<DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.1.html">Volume 3 Issue 1 (4 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.1.html#subj1">  Unshakeable Faith in Technology (Richard A. Cowan)</A>
<LI><A HREF="/Risks/3.1.html#subj2">  Unshakeable Faith in Technology: Shuttles &amp; Nuclear Power (Peter G. Neumann)</A>
<LI><A HREF="/Risks/3.1.html#subj3">  Basis for SDI Assumptions? (Doug Schuler)</A>
<LI><A HREF="/Risks/3.1.html#subj4">  Technical vs. Political in SDI (Herb Lin)</A>
<LI><A HREF="/Risks/3.1.html#subj5">  Computer Crime Laws (Peter G. Neumann)</A>
<LI><A HREF="/Risks/3.1.html#subj6">  Backups for micros (Evan Dresel)</A>
<LI><A HREF="/Risks/3.1.html#subj7">  The Clock Lies Again (PGN, Jagan Jagannathan)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.2.html">Volume 3 Issue 2 (5 Jun 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/3.2.html#subj1">  Are SDI Software predictions biased by old tactical software? (Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.3.html">Volume 3 Issue 3 (6 Jun 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/3.3.html#subj1">  Watch this Space (Eugene Miya)</A>
<LI><A HREF="/Risks/3.3.html#subj2">  Unshakeable Faith in Technology (Herb Lin)</A>
<LI><A HREF="/Risks/3.3.html#subj3">  SDI as a defense against terrorists?             (Bruce Wampler, Martin Moore, Bernie Gunther)
</A>
<LI><A HREF="/Risks/3.3.html#subj4">  Basis for SDI Assumptions? (Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.4.html">Volume 3 Issue 4 (9 Jun 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/3.4.html#subj1">  Re: Watch this Space (Mark Jackson, Eugene Miya)</A>
<LI><A HREF="/Risks/3.4.html#subj2">  Software developer's liability (Paul Schauble)</A>
<LI><A HREF="/Risks/3.4.html#subj3">  What an Algorithm!! (Brian Bishop)</A>
<LI><A HREF="/Risks/3.4.html#subj4">  Sgt. York's Latrine, and other stories (Mike McLaughlin, Ken Laws)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.5.html">Volume 3 Issue 5 (10 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.5.html#subj1">  A powerful metal detector and magnetic personalities with bank cards      (Matthew P. Wiener)
</A>
<LI><A HREF="/Risks/3.5.html#subj2">  Shuttle Launch Decisions (Don Wegeng)</A>
<LI><A HREF="/Risks/3.5.html#subj3">  Re: Estell's defense of SDI (Martin Purvis)</A>
<LI><A HREF="/Risks/3.5.html#subj4">  Sgt. York's Latrine, and other stories (Mike McLaughlin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.6.html">Volume 3 Issue 6 (12 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.6.html#subj1">  Risks from inappropriate scale of energy technologies (Michael J. Natkin)</A>
<LI><A HREF="/Risks/3.6.html#subj2">  Shuttle Software (David C. Smith)</A>
<LI><A HREF="/Risks/3.6.html#subj3">  An additional SDI problem: sensor technology (Eugene Miya)</A>
<LI><A HREF="/Risks/3.6.html#subj4">  Privacy in the electronic age (Dave Platt)</A>
<LI><A HREF="/Risks/3.6.html#subj5">  Sgt York software (Larry Campbell, Mark Vilain)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.7.html">Volume 3 Issue 7 (13 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.7.html#subj1">  Eastport Study Group report ("Science" article) (Pete Kaiser)</A>
<LI><A HREF="/Risks/3.7.html#subj2">  An additional SDI problem: sensor technology (Jon Jacky)</A>
<LI><A HREF="/Risks/3.7.html#subj3">  Shuttle software and CACM (James Tomayko [and Herb Lin])</A>
<LI><A HREF="/Risks/3.7.html#subj4">  Privacy laws (Bruce O'Neel)</A>
<LI><A HREF="/Risks/3.7.html#subj5">  A mini-editorial on running the RISKS Forum (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.8.html">Volume 3 Issue 8 (15 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.8.html#subj1">  Challenger, SDI, and management risks (Dick Dunn)</A>
<LI><A HREF="/Risks/3.8.html#subj2">  Re: Risks from inappropriate scale of energy technologies (Chuck Ferguson)</A>
<LI><A HREF="/Risks/3.8.html#subj3">  Distributed versus centralized computer systems (Peter G. Neumann)</A>
<LI><A HREF="/Risks/3.8.html#subj4">  Privacy legislation (Michael Wagner)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.9.html">Volume 3 Issue 9 (20 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.9.html#subj1">  Informing the Senate on SDI (Jim Horning)</A>
<LI><A HREF="/Risks/3.9.html#subj2">  A medical risk of computers (Karen R. Sollins)</A>
<LI><A HREF="/Risks/3.9.html#subj3">  Risks of VDTs (Alan Wexelblat)</A>
<LI><A HREF="/Risks/3.9.html#subj4">  Minor addition on Risks of Distributed Energy (Ted Lee)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.10.html">Volume 3 Issue 10 (20 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.10.html#subj1">  Re: Privacy Legislation &amp; Cellular Swiss Cheese (RISKS-3.8)(Geoff Goodfellow)</A>
<LI><A HREF="/Risks/3.10.html#subj2">  Re: Privacy Legislation (RISKS-3.6) [divulging] (Dan Franklin)</A>
<LI><A HREF="/Risks/3.10.html#subj3">  Re: Privacy Legislation (RISKS-3.6) [radar detectors] (Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.11.html">Volume 3 Issue 11 (23 Jun 86  [mislabelled RISKS-3.12 in masthead])</A>
<DD><UL>
<LI><A HREF="/Risks/3.11.html#subj1">  A medical risk of computers (overdose during radiation therapy) (Jon Jacky)</A>
<LI><A HREF="/Risks/3.11.html#subj2">  Secure computer systems (Herb Lin)</A>
<LI><A HREF="/Risks/3.11.html#subj3">  Radar Detectors (Re: Privacy legislation in <A HREF="/Risks/3.10.html">RISKS-3.10</A>) (Jeff Makey)</A>
<LI><A HREF="/Risks/3.11.html#subj4">  Telco Central office woes in Southfield, MI. (via Geoff Goodfellow)</A>
<LI><A HREF="/Risks/3.11.html#subj5">  Reducing the managerial risks in SDI (Bob Estell)</A>
<LI><A HREF="/Risks/3.11.html#subj6">  Economic Impact of SDI:  Transcript Info (Richard A. Cowan)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.12.html">Volume 3 Issue 12 (24 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.12.html#subj1">  License Plate Risks (Chuck Price)</A>
<LI><A HREF="/Risks/3.12.html#subj2">  SDI is for ICBMs, Not Terrorists (Mark Day)</A>
<LI><A HREF="/Risks/3.12.html#subj3">  Still another kind of clock problem (Rodney Hoffman)</A>
<LI><A HREF="/Risks/3.12.html#subj4">  Estimating Unreported Incidents (Ken Laws)</A>
<LI><A HREF="/Risks/3.12.html#subj5">  Estimating Unreported Incidents -- and the risks of using statistics (PGN)</A>
<LI><A HREF="/Risks/3.12.html#subj6">  Re: Privacy legislation (RISKS-3.8) and radio eavesdropping    (Jerry Mungle, Jeff Mogul, Jim Aspnes)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.13.html">Volume 3 Issue 13 (26 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.13.html#subj1">  The Risky Gap Between Two Design Cultures (Jack Goldberg)</A>
<LI><A HREF="/Risks/3.13.html#subj2">  Risks of nuclear power (Dan Franklin)</A>
<LI><A HREF="/Risks/3.13.html#subj3">  Research programs that pay for themselves (Rich Cowan)</A>
<LI><A HREF="/Risks/3.13.html#subj4">  Having an influence from "within the system" (Rich Cowan)</A>
<LI><A HREF="/Risks/3.13.html#subj5">  RISKS in running RISKS -- continued (PGN and an unhappy Mailer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.14.html">Volume 3 Issue 14 (27 Jun 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/3.14.html#subj1">  A Personal View on SDI (Harlan Mills)</A>
<LI><A HREF="/Risks/3.14.html#subj2">  Privacy legislation (<A HREF="/Risks/3.10.html">RISKS-3.10</A>) (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/3.14.html#subj3">  Risks in burning wood (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.14.html#subj4">  Mailer explosion (Sean Malloy)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.15.html">Volume 3 Issue 15 (29 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.15.html#subj1">  A Personal View on SDI from Harlan Mills (Herb Lin)</A>
<LI><A HREF="/Risks/3.15.html#subj2">  Having an influence from "within the system" (Herb Lin)</A>
<LI><A HREF="/Risks/3.15.html#subj3">  Re: Research programs that pay for themselves (Rich Cowan)</A>
<LI><A HREF="/Risks/3.15.html#subj4">  Text Scanners (Fred Hapgood)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.16.html">Volume 3 Issue 16 (30 Jun 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.16.html#subj1">  Chernobyl (a suprise to the Soviets) (Martin Minow)</A>
<LI><A HREF="/Risks/3.16.html#subj2">  Airwaves &amp; Security (2 Subjects) (Richard S. D'Ippolito via dhm)</A>
<LI><A HREF="/Risks/3.16.html#subj3">  Interesting Technical Questions (originally SDI) (Martin Moore)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.17.html">Volume 3 Issue 17 (3 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.17.html#subj1">  How Much Computer Literacy Is Enough? (JAN Lee)</A>
<LI><A HREF="/Risks/3.17.html#subj2">  Working within the system (Rich Cowan)</A>
<LI><A HREF="/Risks/3.17.html#subj3">  Re: [Airwaves &amp;] Security -- SDI (Herb Lin)</A>
<LI><A HREF="/Risks/3.17.html#subj4">  Complex issues, complex answers (Bob Estell)</A>
<LI><A HREF="/Risks/3.17.html#subj5">  Politics and Engineering Practice (Seifert)</A>
<LI><A HREF="/Risks/3.17.html#subj6">  Multiple copies of <A HREF="/Risks/3.16.html">RISKS-3.16</A> (Kenneth Sloan)</A>
<LI><A HREF="/Risks/3.17.html#subj7">  GTE Sprint billing problems (Chuck Weinstock/Lee Breisacher)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.18.html">Volume 3 Issue 18 (8 Jul 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/3.18.html#subj1">  Computer Crime in Scandinavia (Martin Minow)</A>
<LI><A HREF="/Risks/3.18.html#subj2">  Re: Risks from inappropriate scale of energy technologies (Henry Spencer)</A>
<LI><A HREF="/Risks/3.18.html#subj3">  Sensor technology and disinformation (Eugene Miya)</A>
<LI><A HREF="/Risks/3.18.html#subj4">  Educating to prevent RISKS (Steven Gutfreund)</A>
<LI><A HREF="/Risks/3.18.html#subj5">  Rash of 'Undeliverable mail' (Chuck Price)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.19.html">Volume 3 Issue 19 (10 Jul 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/3.19.html#subj1">  Computer Literacy (Rick Smith, Bob Estell, Col. G. L. Sicherman, PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.20.html">Volume 3 Issue 20 (15 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.20.html#subj1">  Risks of computer incompetence (Dave Benson)</A>
<LI><A HREF="/Risks/3.20.html#subj2">  RE: educating about RISKS (Don Lindsay)</A>
<LI><A HREF="/Risks/3.20.html#subj3">  Computer Literacy (<A HREF="/Risks/3.19.html">RISKS-3.19</A>) (Ron Morgan)    ... and Basic (Martin Minow, Andrew Klossner, PGN)
</A>
<LI><A HREF="/Risks/3.20.html#subj4">  Dial-up computing (Sterling Bjorndahl)</A>
<LI><A HREF="/Risks/3.20.html#subj5">  Research programs that pay for themselves (Clayton Cramer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.21.html">Volume 3 Issue 21 (16 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.21.html#subj1">  Responsibility (Willis Ware)</A>
<LI><A HREF="/Risks/3.21.html#subj2">  Programming languages and computer literacy (Bob Estell)</A>
<LI><A HREF="/Risks/3.21.html#subj3">  Teaching about risks, BASIC, NASA, etc. (Eugene Miya)</A>
<LI><A HREF="/Risks/3.21.html#subj4">  Programming Languages (Matthew Kruk)</A>
<LI><A HREF="/Risks/3.21.html#subj5">  BBoard Lingo (Trojan viruses,...) (Hank Burchard, via Peter G. Neumann)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.22.html">Volume 3 Issue 22 (19 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.22.html#subj1">  Nostalgia (Mike Williams)</A>
<LI><A HREF="/Risks/3.22.html#subj2">  Flames about BASIC (Jim Anderson)</A>
<LI><A HREF="/Risks/3.22.html#subj3">  More on risks of teaching "just" programming (Herb Lin)</A>
<LI><A HREF="/Risks/3.22.html#subj4">  Responsibility for Computer Actions (George S. Cole)</A>
<LI><A HREF="/Risks/3.22.html#subj5">  CDP and Certification (Andy Glew)</A>
<LI><A HREF="/Risks/3.22.html#subj6">  The undetected hang-up risk (more) (Ted Lee)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.23.html">Volume 3 Issue 23 (22 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.23.html#subj1">  Re: Comet and Electra (Jim Horning)</A>
<LI><A HREF="/Risks/3.23.html#subj2">  100,000 Late Phone Bills (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.23.html#subj3">  Types of "Programming" (Henry Schaffer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.24.html">Volume 3 Issue 24 (24 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.24.html#subj1">  Comet and Electra (Jerry Saltzer, Marv Zelkowitz, Don Chiasson, Bard Bloom)</A>
<LI><A HREF="/Risks/3.24.html#subj2">  No gasoline because the computer is down? (Jim Barnes)</A>
<LI><A HREF="/Risks/3.24.html#subj3">  HBO Hacker Captain Midnight Caught (via Geoff Goodfellow)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.25.html">Volume 3 Issue 25 (24 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.25.html#subj1">  Petroski on the Comet failures (Alan Wexelblat)</A>
<LI><A HREF="/Risks/3.25.html#subj2">  Re: Comet and Electra (Douglas Adams)</A>
<LI><A HREF="/Risks/3.25.html#subj3">  On the dangers of human error (Brian Randell via Lindsay Marshall)</A>
<LI><A HREF="/Risks/3.25.html#subj4">  Software Paranoia (Ken Laws)</A>
<LI><A HREF="/Risks/3.25.html#subj5">  Royal Wedding Risks (Lindsay Marshall)</A>
<LI><A HREF="/Risks/3.25.html#subj6">  How to Think Creatively (John Mackin)</A>
<LI><A HREF="/Risks/3.25.html#subj7">  Dangers of improperly protected equipment (Kevin Belles)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.26.html">Volume 3 Issue 26 (26 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.26.html#subj1">  DIVAD (Herb Lin)</A>
<LI><A HREF="/Risks/3.26.html#subj2">  Royal wedding risks -- common change modes (Don Chiasson)</A>
<LI><A HREF="/Risks/3.26.html#subj3">  Security and dialbacks (David I. Emery via Herb Lin)   [Long message]</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.27.html">Volume 3 Issue 27 (29 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.27.html#subj1">  Whoops!  Lost an Area Code! (Clayton Cramer)</A>
<LI><A HREF="/Risks/3.27.html#subj2">  Comet-Electra (<A HREF="/Risks/3.25.html">RISKS-3.25</A>) (Stephen Little)</A>
<LI><A HREF="/Risks/3.27.html#subj3">  Comparing computer security with human security (Bob Estell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.28.html">Volume 3 Issue 28 (31 Jul 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.28.html#subj1">  Laserprinter dangers (Mansfiel)</A>
<LI><A HREF="/Risks/3.28.html#subj2">  Errors in error-handlers (Mansfiel)</A>
<LI><A HREF="/Risks/3.28.html#subj3">  Military testing errors (Alan Wexelblat)</A>
<LI><A HREF="/Risks/3.28.html#subj4">  Re: Comet-Electra (<A HREF="/Risks/3.25.html">RISKS-3.25</A>) (Bill Fisher)</A>
<LI><A HREF="/Risks/3.28.html#subj5">  Computer and Human Security (Lindsay Marshall)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.29.html">Volume 3 Issue 29 (1 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.29.html#subj1">  Ozone hole undetected for years due to programming error (Bill McGarry)</A>
<LI><A HREF="/Risks/3.29.html#subj2">  Aircraft simulators and risks (Art Evans)</A>
<LI><A HREF="/Risks/3.29.html#subj3">  Military testing errors (Scott E. Preece)</A>
<LI><A HREF="/Risks/3.29.html#subj4">  Risks: computers in the electoral process (Kurt Hyde via Pete Kaiser)</A>
<LI><A HREF="/Risks/3.29.html#subj5">  Risks of CAD (Alan Wexelblat)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.30.html">Volume 3 Issue 30 (4 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.30.html#subj1">  Ozone hole undetected (Jeffrey Mogul)</A>
<LI><A HREF="/Risks/3.30.html#subj2">  Re: Risks of CAD (Henry Spencer)</A>
<LI><A HREF="/Risks/3.30.html#subj3">  Comment on Hartford Civic Roof Design (Richard S D'Ippolito)</A>
<LI><A HREF="/Risks/3.30.html#subj4">  Expert system to catch spies (Larry Van Sickle)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.31.html">Volume 3 Issue 31 (5 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.31.html#subj1">  Another cruise missile lands outside Eglin test range (Martin J. Moore)</A>
<LI><A HREF="/Risks/3.31.html#subj2">  Aircraft simulators and risks (Gary Wemmerus)</A>
<LI><A HREF="/Risks/3.31.html#subj3">  Re: Comment on Hartford Civic Roof Design (Brad Davis)</A>
<LI><A HREF="/Risks/3.31.html#subj4">  Expert system to catch spies (<A HREF="/Risks/3.30.html">RISKS-3.30</A>) (Chris McDonald)</A>
<LI><A HREF="/Risks/3.31.html#subj5">  Computer and Human Security (Henry Spencer)</A>
<LI><A HREF="/Risks/3.31.html#subj6">  Ozone Reference (Eugene Miya)</A>
<LI><A HREF="/Risks/3.31.html#subj7">  Financial risks (Robert Stroud)</A>
<LI><A HREF="/Risks/3.31.html#subj8">  Mail Load Light(e)ning? (SRI-CSL Mail Daemon)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.32.html">Volume 3 Issue 32 (6 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.32.html#subj1">  DC-10 Crash (Chuck Weinstock)</A>
<LI><A HREF="/Risks/3.32.html#subj2">  Earthquake Reporting (AP)</A>
<LI><A HREF="/Risks/3.32.html#subj3">  The Recent Near-Disaster for the Shuttle Columbia (Peter G. Neumann)</A>
<LI><A HREF="/Risks/3.32.html#subj4">  Traffic lights in Austin (Alan Wexelblat)</A>
<LI><A HREF="/Risks/3.32.html#subj5">  Re: Laserprinter dangers (Graeme Hirst)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.33.html">Volume 3 Issue 33 (7 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.33.html#subj1">  Air traffic computer failure (Hal Perkins)</A>
<LI><A HREF="/Risks/3.33.html#subj2">  Re: Laserprinter dangers (Sean Malloy)</A>
<LI><A HREF="/Risks/3.33.html#subj3">  Re: Expert system to catch spies (Rich Kulawiec)</A>
<LI><A HREF="/Risks/3.33.html#subj4">  Survey of Computer Professionals (Kurt Hyde)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.34.html">Volume 3 Issue 34 (9 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.34.html#subj1">  Non-Flying Airplanes and Flying Glass (Jim Horning)</A>
<LI><A HREF="/Risks/3.34.html#subj2">  Failure Recovery, Simulations, and Reality (Danny Cohen)</A>
<LI><A HREF="/Risks/3.34.html#subj3">  Ottawa Power Failure (Dan Craigen)</A>
<LI><A HREF="/Risks/3.34.html#subj4">  Liability for Software Problems (Peter G. Neumann)</A>
<LI><A HREF="/Risks/3.34.html#subj5">  Ozone hole (Hal Perkins)</A>
<LI><A HREF="/Risks/3.34.html#subj6">  Re: Survey of Trust in Election Computers (Chris Hibbert)</A>
<LI><A HREF="/Risks/3.34.html#subj7">  Nondelivery of <A HREF="/Risks/2.38.html">RISKS-2.38</A> (8 April 1986) and other mail     (Communications Satellite [and PGN])
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.35.html">Volume 3 Issue 35 (11 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.35.html#subj1">  Flying windows on the Hancock Building (Remy Malan)</A>
<LI><A HREF="/Risks/3.35.html#subj2">  Pilots and counter-intuitive maneuvers (Martin Minow)</A>
<LI><A HREF="/Risks/3.35.html#subj3">  Mail adrift (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.35.html#subj4">  Laserprinter dangers (Niall Mansfield)</A>
<LI><A HREF="/Risks/3.35.html#subj5">  A bit of humor and even philosophy (Willis Ware)</A>
<LI><A HREF="/Risks/3.35.html#subj6">  Official Report on Chernobyl disaster (Robert Stroud)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.36.html">Volume 3 Issue 36 (12 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.36.html#subj1">  Another Medical Risk? (Lee Breisacher)</A>
<LI><A HREF="/Risks/3.36.html#subj2">  RISKy Business in Surgery (Mark Jackson)</A>
<LI><A HREF="/Risks/3.36.html#subj3">  Reliance on word-processors discussed in the Israeli Supreme (Ady Wiernik)</A>
<LI><A HREF="/Risks/3.36.html#subj4">  Expert Systems - The New Cop on the Beat (Laws via Fred Ostapik)</A>
<LI><A HREF="/Risks/3.36.html#subj5">  Chernobyl (Art Evans, Dick Karpinski)</A>
<LI><A HREF="/Risks/3.36.html#subj6">  Air Traffic Control computer failure (Dan Melson)</A>
<LI><A HREF="/Risks/3.36.html#subj7">  Possible failures of BMD software (Herb Lin)</A>
<LI><A HREF="/Risks/3.36.html#subj8">  A note about stories "from memory" (Henry Mensch)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.37.html">Volume 3 Issue 37 (14 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.37.html#subj1">  Computer Viruses (Robert Stroud)</A>
<LI><A HREF="/Risks/3.37.html#subj2">  On knowing how hard a system is to make work (Bob Estell)</A>
<LI><A HREF="/Risks/3.37.html#subj3">  COMSAT and the Nondelivery of Mail (Rob Austein)</A>
<LI><A HREF="/Risks/3.37.html#subj4">  Exploding Office Chairs (Jonathan Bowen) </A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.38.html">Volume 3 Issue 38 (17 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.38.html#subj1">  Computer gives away California state funds (Rodney Hoffman)</A>
<LI><A HREF="/Risks/3.38.html#subj2">  High-Tech Sex Ring: Beware of Whose Database You Are In! (Peter G. Neumann)</A>
<LI><A HREF="/Risks/3.38.html#subj3">  Computer Viruses (Chris McDonald, Paul Garnet, Matt Bishop)</A>
<LI><A HREF="/Risks/3.38.html#subj4">  Computer Viruses and Air Traffic Control (Dan Melson)</A>
<LI><A HREF="/Risks/3.38.html#subj5">  Re: Traffic lights in Austin (Bill Davidsen)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.39.html">Volume 3 Issue 39 (19 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.39.html#subj1">  Nuclear false alarm (Robert Stroud)</A>
<LI><A HREF="/Risks/3.39.html#subj2">  Risk to beer production? (Robert Stroud)</A>
<LI><A HREF="/Risks/3.39.html#subj3">  Re: High Tech Sex (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/3.39.html#subj4">  QA on nuclear power plants and the shuttle (Roy Smith)</A>
<LI><A HREF="/Risks/3.39.html#subj5">  Hackers in BITNET (Sterling Bjorndas)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.40.html">Volume 3 Issue 40 (21 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.40.html#subj1">  QA on nuclear power plants and the shuttle (Eugene Miya, Ken Dymond)</A>
<LI><A HREF="/Risks/3.40.html#subj2">  CAD, Simulation, Armored Combat Earthmover, and Stinger (Mary C. Akers)</A>
<LI><A HREF="/Risks/3.40.html#subj3">  Risks Distribution List -- Private-Copy Subscribers PLEASE READ! (PGN)</A>
<LI><A HREF="/Risks/3.40.html#subj4">  Could computers launch a nuclear attack? (Jeff Myers)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.41.html">Volume 3 Issue 41 (23 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.41.html#subj1">  $1 million bogus bank deposit (Hal Perkins)</A>
<LI><A HREF="/Risks/3.41.html#subj2">  Cheating of automatic teller machines (Jacob Palme)</A>
<LI><A HREF="/Risks/3.41.html#subj3">  Simulation, Armored Combat Earthmover, and Stinger (Herb Lin)</A>
<LI><A HREF="/Risks/3.41.html#subj4">  Report from AAAI-86 (Alan Wexelblat)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.42.html">Volume 3 Issue 42 (25 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.42.html#subj1">  Re: $1 million bogus bank deposit (Barry Shein)</A>
<LI><A HREF="/Risks/3.42.html#subj2">  Sometimes things go right (Matt Bishop)</A>
<LI><A HREF="/Risks/3.42.html#subj3">  Re: Cheating of automatic teller machines (Dave Farber)</A>
<LI><A HREF="/Risks/3.42.html#subj4">  Keystroke Analysis for Authentication (rclex)</A>
<LI><A HREF="/Risks/3.42.html#subj5">  Computer Vote Counting In the News -- More (John Woods)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.43.html">Volume 3 Issue 43 (26 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.43.html#subj1">  Comment on PGN's comment on human error (Nancy Leveson)</A>
<LI><A HREF="/Risks/3.43.html#subj2">  Keystroke Analysis for Authentication (Scott E. Preece, Eugene Miya)</A>
<LI><A HREF="/Risks/3.43.html#subj3">  Risks of Mechanical Engineering [More on O-Rings] (Martin Harriman)</A>
<LI><A HREF="/Risks/3.43.html#subj4">  Re:  Words, words, words... (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.43.html#subj5">  Comments on paper desired (Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.44.html">Volume 3 Issue 44 (27 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.44.html#subj1">  F-16 Problems (George Moore via Bill Janssen)</A>
<LI><A HREF="/Risks/3.44.html#subj2">  Various clips from European Newspapers (Martin Minow)</A>
<LI><A HREF="/Risks/3.44.html#subj3">  Comment on Nancy Leveson's comment on... (Alan Wexelblat)</A>
<LI><A HREF="/Risks/3.44.html#subj4">  Words, words, words... (Herb Lin)</A>
<LI><A HREF="/Risks/3.44.html#subj5">  Software Safety (Paul Anderson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.45.html">Volume 3 Issue 45 (28 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.45.html#subj1">  Nonviolent Resistor Destroys Aries Launch (PGN)</A>
<LI><A HREF="/Risks/3.45.html#subj2">  Risks in the design of civil engineering projects (Annette Bauman)</A>
<LI><A HREF="/Risks/3.45.html#subj3">  ATMs (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/3.45.html#subj4">  Re: Typing Profiles (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/3.45.html#subj5">  Human errors prevail (Ken Dymond, Nancy Leveson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.46.html">Volume 3 Issue 46 (30 Aug 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.46.html#subj1">  Human error (Nancy Leveson, Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/3.46.html#subj2">  Re: F-16 Tales (Earl Boebert, Phil Ngai)</A>
<LI><A HREF="/Risks/3.46.html#subj3">  Correction to note about flight simulators (Martin Minow)</A>
<LI><A HREF="/Risks/3.46.html#subj4">  Supermarket grinds to a halt (David Sherman)</A>
<LI><A HREF="/Risks/3.46.html#subj5">  Video processing (Guy Schafer)</A>
<LI><A HREF="/Risks/3.46.html#subj6">  ATMs (Jacob Palme)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.47.html">Volume 3 Issue 47 (1 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.47.html#subj1">  Flight Simulators Have Faults (Dave Benson)</A>
<LI><A HREF="/Risks/3.47.html#subj2">  Re: QA on nuclear power plants, the shuttle, and beer (Henry Spencer)</A>
<LI><A HREF="/Risks/3.47.html#subj3">  Acts of God vs. Acts of Man (Nancy Leveson -- two messages)</A>
<LI><A HREF="/Risks/3.47.html#subj4">  Computer Literacy (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.47.html#subj5">  Another supermarket crash (Ted Lee)</A>
<LI><A HREF="/Risks/3.47.html#subj6">  A supermarket does not grind to a halt (Brint Cooper)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.48.html">Volume 3 Issue 48 (2 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.48.html#subj1">  Aeromexico Crash (UPI via PGN)</A>
<LI><A HREF="/Risks/3.48.html#subj2">  Air Force puts secrets up for sale (Peter G. Neumann) </A>
<LI><A HREF="/Risks/3.48.html#subj3">  Randi, Popoff, and Data Privacy Laws (Phil Karn via Geoff Goodfellow)</A>
<LI><A HREF="/Risks/3.48.html#subj4">  Flight Simulators Have Faults (Gary Whisenhunt)</A>
<LI><A HREF="/Risks/3.48.html#subj5">  On-Line with Taco Bell Telephone (John Mulhollen)</A>
<LI><A HREF="/Risks/3.48.html#subj6">  Titanic photo expedition (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/3.48.html#subj7">  New Zealand $1 million deposit (Dave Sherman)</A>
<LI><A HREF="/Risks/3.48.html#subj8">  Examination Processing Error (Joe Stoy)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.49.html">Volume 3 Issue 49 (4 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.49.html#subj1">  Human Error (Dave Parnas, Bill Anderson)</A>
<LI><A HREF="/Risks/3.49.html#subj2">  Machine errors - another point of view  (Bob Estell)</A>
<LI><A HREF="/Risks/3.49.html#subj3">  Flight simulators (Eugene Miya)</A>
<LI><A HREF="/Risks/3.49.html#subj4">  F-16 software (Henry Spencer)</A>
<LI><A HREF="/Risks/3.49.html#subj5">  Terminal (!) lockup (Ken Steiglitz)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.50.html">Volume 3 Issue 50 (7 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.50.html#subj1">  Enlightened Traffic Management (Alan Wexelblat)</A>
<LI><A HREF="/Risks/3.50.html#subj2">  Flight Simulator Simulators Have Faults (Dave Benson)</A>
<LI><A HREF="/Risks/3.50.html#subj3">  Re: Flight Simulators and Software Bugs (Bjorn Freeman-Benson)</A>
<LI><A HREF="/Risks/3.50.html#subj4">  Always Mount a Scratch Monkey (Art Evans)</A>
<LI><A HREF="/Risks/3.50.html#subj5">  Re: supermarket crashes (Jeffrey Mogul)</A>
<LI><A HREF="/Risks/3.50.html#subj6">  Machine errors - another point of view (Bob Estell)</A>
<LI><A HREF="/Risks/3.50.html#subj7">  Human Behv. &amp; FSM's (Robert DiCamillo)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.51.html">Volume 3 Issue 51 (7 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.51.html#subj1">  Computer almost created swing vote (Bjorn Freeman-Benson)</A>
<LI><A HREF="/Risks/3.51.html#subj2">  Computer Sabotage of Encyclopedia Brittania (Rosanna Lee)</A>
<LI><A HREF="/Risks/3.51.html#subj3">  F-16 software (Wayne Throop)</A>
<LI><A HREF="/Risks/3.51.html#subj4">  Arbiter failures and design failures (Martin Harriman)</A>
<LI><A HREF="/Risks/3.51.html#subj5">  Systems errors (hardware AND humans) (Bill Janssen)</A>
<LI><A HREF="/Risks/3.51.html#subj6">  Re: Terminal (!) lockup (Roy Smith)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.52.html">Volume 3 Issue 52 (8 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.52.html#subj1">  Re:  F-16 software (Nancy Leveson)</A>
<LI><A HREF="/Risks/3.52.html#subj2">  Upside-down F-16's and "Human error" (Jon Jacky)</A>
<LI><A HREF="/Risks/3.52.html#subj3">  F-16 software (Scott E. Preece)</A>
<LI><A HREF="/Risks/3.52.html#subj4">  Do More Faults Mean More Faults? (Ken Dymond)</A>
<LI><A HREF="/Risks/3.52.html#subj5">  Why components DON'T interact more often (Bob Estell)</A>
<LI><A HREF="/Risks/3.52.html#subj6">  Computer almost created swing vote (Scott E. Preece)</A>
<LI><A HREF="/Risks/3.52.html#subj7">  Computer Sabotage [MISSING LAST LINE FROM <A HREF="/Risks/3.51.html">RISKS-3.51</A>]</A>
<LI><A HREF="/Risks/3.52.html#subj8">  Computer Sabotage of Encyclopedia Brittanica (Scott E. Preece)</A>
<LI><A HREF="/Risks/3.52.html#subj9">  Captain Midnight &amp; military satellites (Werner Uhrig)</A>
<LI><A HREF="/Risks/3.52.html#subj10">  Re: always mount a scratch monkey (Alexander Dupuy) </A>
<LI><A HREF="/Risks/3.52.html#subj11">  Erroneous computer printout used in public debates (Chris Koenigsberg)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.53.html">Volume 3 Issue 53 (10 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.53.html#subj1">  Hardware/software interface and risks (Mike Brown)</A>
<LI><A HREF="/Risks/3.53.html#subj2">  More on Upside down F-16s (Mike Brown)</A>
<LI><A HREF="/Risks/3.53.html#subj3">  "Unreasonable behavior" and software (Gary Chapman)</A>
<LI><A HREF="/Risks/3.53.html#subj4">  Re: supermarket crashes (Scott Preece)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.54.html">Volume 3 Issue 54 (15 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.54.html#subj1">  Ada Inherently Secure? (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.54.html#subj2">  A million lines of code works the first time? (Ken Calvert)</A>
<LI><A HREF="/Risks/3.54.html#subj3">  Computers and Ethics (Mark S. Day)</A>
<LI><A HREF="/Risks/3.54.html#subj4">  New book: HUMAN RELIABILITY: With Human Factors (Elizabeth ?)</A>
<LI><A HREF="/Risks/3.54.html#subj5">  Answers to WWMCCS Intercomputer Network questions (Harold E. Russell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.55.html">Volume 3 Issue 55 (15 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.55.html#subj1">  Hardware/software interface and risks (Kevin Kenny)</A>
<LI><A HREF="/Risks/3.55.html#subj2">  F-16 (Holleran, Eugene Miya, Ihor Kinal, Doug Wade)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.56.html">Volume 3 Issue 56 (16 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.56.html#subj1">  Massive UNIX breakins at Stanford (Brian Reid)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.57.html">Volume 3 Issue 57 (16 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.57.html#subj1">  Computers and the Stock Market (again) (Robert Stroud)</A>
<LI><A HREF="/Risks/3.57.html#subj2">  The Old Saw about Computers and TMI (Ken Dymond)</A>
<LI><A HREF="/Risks/3.57.html#subj3">  Do More Faults Mean (Yet) More Faults? (Dave Benson)</A>
<LI><A HREF="/Risks/3.57.html#subj4">  A critical real-time application worked the first time (Dave Benson)</A>
<LI><A HREF="/Risks/3.57.html#subj5">  Autonomous weapons (Eugene Miya)</A>
<LI><A HREF="/Risks/3.57.html#subj6">  "Unreasonable behavior" and software (Eugene Miya on Gary Chapman)</A>
<LI><A HREF="/Risks/3.57.html#subj7">  Risks of maintaining computer timestamps revisited (John Coughlin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.58.html">Volume 3 Issue 58 (17 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.58.html#subj1">  Massive UNIX breakins (Dave Curry, Brian Reid)</A>
<LI><A HREF="/Risks/3.58.html#subj2">  "Atlanta's been down all afternoon" (Alan Wexelblat)</A>
<LI><A HREF="/Risks/3.58.html#subj3">  F-16 software (Herb Lin)</A>
<LI><A HREF="/Risks/3.58.html#subj4">  Viking Project (Eugene Miya)</A>
<LI><A HREF="/Risks/3.58.html#subj5">  Protection of personal information (David Chase)</A>
<LI><A HREF="/Risks/3.58.html#subj6">  Autonomous Weapons (Ken Laws)</A>
<LI><A HREF="/Risks/3.58.html#subj7">  Re: computers and petty fraud (Col. G. L. Sicherman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.59.html">Volume 3 Issue 59 (20 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.59.html#subj1">  Computers and Wall Street (Robert Stroud)</A>
<LI><A HREF="/Risks/3.59.html#subj2">  Report from the Computerized Voting Symposium (Kurt Hyde)</A>
<LI><A HREF="/Risks/3.59.html#subj3">  Computers, TMI, Chernobyl, and professional licensing (Martin Harriman)</A>
<LI><A HREF="/Risks/3.59.html#subj4">  Failsafe software (Martin Ewing)</A>
<LI><A HREF="/Risks/3.59.html#subj5">  Software vs. Mechanical Interlocks (Andy Freeman)</A>
<LI><A HREF="/Risks/3.59.html#subj6">  How Not to Protect Communications (Geoff Goodfellow)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.60.html">Volume 3 Issue 60 (20 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.60.html#subj1">  Sanity checks (Roy Smith)</A>
<LI><A HREF="/Risks/3.60.html#subj2">  Viking Flight Software working the `first' time? (Greg Earle)</A>
<LI><A HREF="/Risks/3.60.html#subj3">  A million lines of code works the first time?    (Anonymous, Dave Benson, Herb Lin)
</A>
<LI><A HREF="/Risks/3.60.html#subj4">  Re: Massive UNIX breakins at Stanford (Scott E. Preece)</A>
<LI><A HREF="/Risks/3.60.html#subj5">  Re: Protection of personal information (Andy Mondore, Herb Lin)</A>
<LI><A HREF="/Risks/3.60.html#subj6">  Announcement of Berkeley Conference on the SDI (Eric Roberts)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.61.html">Volume 3 Issue 61 (21 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.61.html#subj1">  Computers and Ethics (Robert Reed)</A>
<LI><A HREF="/Risks/3.61.html#subj2">  Autonomous weapons (Wayne Throop)</A>
<LI><A HREF="/Risks/3.61.html#subj3">  Simulation risk (Rob Horn)</A>
<LI><A HREF="/Risks/3.61.html#subj4">  Viking software (James Tomayko)</A>
<LI><A HREF="/Risks/3.61.html#subj5">  Risks of passwords on networks (Bruce)</A>
<LI><A HREF="/Risks/3.61.html#subj6">  More on digital jets; Sanity checks (Eugene Miya)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.62.html">Volume 3 Issue 62 (22 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.62.html#subj1">  Massive UNIX breakins at Stanford                 (Jerry Saltzer, Rob Austein, Andy Freeman, Scott Preece)
</A>
<LI><A HREF="/Risks/3.62.html#subj2">  F-16 Software (Henry Spencer)</A>
<LI><A HREF="/Risks/3.62.html#subj3">  1,000,000 lines of correct code? (Stephen Schaefer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.63.html">Volume 3 Issue 63 (24 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.63.html#subj1">  NOTROJ (a Trojan Horse) (James H. Coombs via Martin Minow)</A>
<LI><A HREF="/Risks/3.63.html#subj2">  Massive UNIX breakins at Stanford (Scott Preece [two more messages!])</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.64.html">Volume 3 Issue 64 (24 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.64.html#subj1">  Sane sanity checks /  risking public discussion (Jim Purtilo)</A>
<LI><A HREF="/Risks/3.64.html#subj2">  More (Maybe Too Much) On More Faults (Ken Dymond)</A>
<LI><A HREF="/Risks/3.64.html#subj3">  Re: Protection of personal information (Correction from David Chase)</A>
<LI><A HREF="/Risks/3.64.html#subj4">  Towards an effective definition of "autonomous" weapons      (Herb Lin, Clifford Johnson [twice each])
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.65.html">Volume 3 Issue 65 (24 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.65.html#subj1">  UNIX and network security again (Andy Freeman)</A>
<LI><A HREF="/Risks/3.65.html#subj2">  F-16 software (Wayne Throop)</A>
<LI><A HREF="/Risks/3.65.html#subj3">  NYT feature article on SDI software (Hal Perkins)</A>
<LI><A HREF="/Risks/3.65.html#subj4">  Autonomous widgets (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.65.html#subj5">  Robottle Management Software? (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.66.html">Volume 3 Issue 66 (25 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.66.html#subj1">  Follow-up on Stanford breakins: PLEASE LISTEN THIS TIME! (Brian Reid)</A>
<LI><A HREF="/Risks/3.66.html#subj2">  F-16 software [concluded?] (Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.67.html">Volume 3 Issue 67 (25 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.67.html#subj1">  Old GAO Report on Medical Device Software (Chuck Youman)</A>
<LI><A HREF="/Risks/3.67.html#subj2">  Re: Stanford breakin, <A HREF="/Risks/3.62.html">RISKS-3.62</A> DIGEST (Darrel VanBuer)</A>
<LI><A HREF="/Risks/3.67.html#subj3">  Re: Passwords and the Stanford break-in (<A HREF="/Risks/3.61.html">RISKS-3.61</A>) (Dave Sherman)</A>
<LI><A HREF="/Risks/3.67.html#subj4">  Re: role of simulation - combat simulation for sale (Jon Jacky)</A>
<LI><A HREF="/Risks/3.67.html#subj5">  MIT Symposium on economic impact of military spending (Richard Cowan)</A>
<LI><A HREF="/Risks/3.67.html#subj6">  "Friendly" missiles and computer error -- more on the Exocet (Rob MacLachlan)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.68.html">Volume 3 Issue 68 (26 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.68.html#subj1">  VDU risks -- Government changes its mind, perhaps (Stephen Page)</A>
<LI><A HREF="/Risks/3.68.html#subj2">  "Drive by wire" systems (Charles R. Fry)</A>
<LI><A HREF="/Risks/3.68.html#subj3">  Viking Landers worked the first time and met the specs (Dave Benson)</A>
<LI><A HREF="/Risks/3.68.html#subj4">  Unix breakins - secure networks (David C. Stewart)</A>
<LI><A HREF="/Risks/3.68.html#subj5">  Comment on the reaction to Brian's Breakin Tale (Dave Taylor)</A>
<LI><A HREF="/Risks/3.68.html#subj6">  Reliability, complexity, and confidence in SDI software (Bob Estell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.69.html">Volume 3 Issue 69 (28 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.69.html#subj1">  Confidence in software via fault expectations (Dave Benson)</A>
<LI><A HREF="/Risks/3.69.html#subj2">  More on Stanford's UNIX breakins (John Shore, Scott Preece)</A>
<LI><A HREF="/Risks/3.69.html#subj3">  F-16 simulator (Stev Knowles)</A>
<LI><A HREF="/Risks/3.69.html#subj4">  Deliberate overrides? (Herb Lin)</A>
<LI><A HREF="/Risks/3.69.html#subj5">  Viking Landers -- correction to <A HREF="/Risks/3.68.html">RISKS-3.68</A> (Courtenay Footman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.70.html">Volume 3 Issue 70 (29 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.70.html#subj1">  Deliberate overrides? (Scott E. Preece)</A>
<LI><A HREF="/Risks/3.70.html#subj2">  Multiple causes and where to place the "blame" (PGN)</A>
<LI><A HREF="/Risks/3.70.html#subj3">  The Art of "Science" and its Computers (PGN)</A>
<LI><A HREF="/Risks/3.70.html#subj4">  No-lock Brakes (Peter Ladkin)</A>
<LI><A HREF="/Risks/3.70.html#subj5">  Sanity in Automating Keyword Abstracting (Brint Cooper)</A>
<LI><A HREF="/Risks/3.70.html#subj6">  The Network Is Getting Old? (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.71.html">Volume 3 Issue 71 (30 Sep 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.71.html#subj1">  Deliberate overrides? (Herb Lin, Alan M. Marcum, Eugene Miya)</A>
<LI><A HREF="/Risks/3.71.html#subj2">  "Friendly" missiles and computer error - more on the Exocet (Robert Stroud)</A>
<LI><A HREF="/Risks/3.71.html#subj3">  Re: Reliability, complexity, and confidence in SDI (Michal Young)</A>
<LI><A HREF="/Risks/3.71.html#subj4">  My understanding of "path" and "bathtub curve" (Bob Estell)</A>
<LI><A HREF="/Risks/3.71.html#subj5">  More artificial than intelligent? (Autokeywords) (Bob Estell)</A>
<LI><A HREF="/Risks/3.71.html#subj6">  A Viking lander query (PGN)</A>
<LI><A HREF="/Risks/3.71.html#subj7">  Note on ARPANET congestion (Nancy Cassidy)  </A>
<LI><A HREF="/Risks/3.71.html#subj8">  Indeed, the network is getting old (Jonathan Young)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.72.html">Volume 3 Issue 72 (1 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.72.html#subj1">  Viking Lander (Nancy Leveson)</A>
<LI><A HREF="/Risks/3.72.html#subj2">  Deliberate override (George Adams)</A>
<LI><A HREF="/Risks/3.72.html#subj3">  Overriding overrides (Peter Ladkin)</A>
<LI><A HREF="/Risks/3.72.html#subj4">  A propos landing gear (Peter Ladkin)</A>
<LI><A HREF="/Risks/3.72.html#subj5">  Paths in Testing (Mark S. Day)</A>
<LI><A HREF="/Risks/3.72.html#subj6">  Confidence in software via fault expectations (Darrel VanBuer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.73.html">Volume 3 Issue 73 (2 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.73.html#subj1">  Lessons from Viking Lander software (Bob Estell)</A>
<LI><A HREF="/Risks/3.73.html#subj2">  Software wears out? (Rob Austein)</A>
<LI><A HREF="/Risks/3.73.html#subj3">  Wrongful eviction through computer error (Bill Janssen)</A>
<LI><A HREF="/Risks/3.73.html#subj4">  Deliberate override (Herb Lin, Ray Chen)</A>
<LI><A HREF="/Risks/3.73.html#subj5">  Re: Piper Arrow Gear Override (Douglas Adams)</A>
<LI><A HREF="/Risks/3.73.html#subj6">  Undesirable breakins and causes (Ian Davis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.74.html">Volume 3 Issue 74 (3 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.74.html#subj1">  Opinions vs. Facts in RISKS Reports (re Aviation Accidents) (Danny Cohen)</A>
<LI><A HREF="/Risks/3.74.html#subj2">  Mathematical checking of programs (quoting Tony Hoare) (Niall Mansfield)</A>
<LI><A HREF="/Risks/3.74.html#subj3">  Risks of maintaining computer timestamps revisited [<A HREF="/Risks/3.57.html">RISKS-3.57</A>] (Ian Davis)</A>
<LI><A HREF="/Risks/3.74.html#subj4">  Keyword indexing in automated catalogs (Betsy Hanes Perry)</A>
<LI><A HREF="/Risks/3.74.html#subj5">  Re: Viking Landers -- correction (Scott Preece)</A>
<LI><A HREF="/Risks/3.74.html#subj6">  Re: Confidence in software via fault expectations (Scott Preece)</A>
<LI><A HREF="/Risks/3.74.html#subj7">  Overrides and tradeoffs (Jerry Leichter)</A>
<LI><A HREF="/Risks/3.74.html#subj8">  Re: Deliberate overrides (Brint Cooper)</A>
<LI><A HREF="/Risks/3.74.html#subj9">  Re: idiot-proof cars (<A HREF="/Risks/3.68.html">risks-3.68</A>) (Col. G. L. Sicherman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.75.html">Volume 3 Issue 75 (4 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.75.html#subj1">  re: Estell on Viking (<A HREF="/Risks/3.73.html">RISKS-3.73</A>) (David Parnas, Dave Benson)</A>
<LI><A HREF="/Risks/3.75.html#subj2">  Software becomes obsolete, but does not wear out (Dave Benson)</A>
<LI><A HREF="/Risks/3.75.html#subj3">  The fallacy of independence (Dave Benson)</A>
<LI><A HREF="/Risks/3.75.html#subj4">  Re: Paths in Testing (<A HREF="/Risks/3.72.html">RISKS-3:72</A>) (Chuck Youman, Mark Day)</A>
<LI><A HREF="/Risks/3.75.html#subj5">  Mathematical checking of programs (quoting Tony Hoare) (Henry Spencer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.76.html">Volume 3 Issue 76 (5 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.76.html#subj1">  Obsolescence vs wearing out (<A HREF="/Risks/3.75.html">RISKS-3.75</A>) (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/3.76.html#subj2">  Cars, computers and unexpected interactions (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.76.html#subj3">  Re: Mathematical checking of programs (quoting Tony Hoare) (Matthew Wiener)</A>
<LI><A HREF="/Risks/3.76.html#subj4">  "Total correctness", "complete reliability" (<A HREF="/Risks/3.75.html">RISKS-3.75</A>) (Bard Bloom)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.77.html">Volume 3 Issue 77 (8 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.77.html#subj1">  Evaluating software risks (Brian Randell)</A>
<LI><A HREF="/Risks/3.77.html#subj2">  Misapplication of hardware reliability models (Nancy Leveson)</A>
<LI><A HREF="/Risks/3.77.html#subj3">  Deliberate overrides? (Mark Brader, Ephraim)</A>
<LI><A HREF="/Risks/3.77.html#subj4">  Trusting-infallible-machines Stonehenge anecdote (Mark Brader)</A>
<LI><A HREF="/Risks/3.77.html#subj5">  [More Aviation Hearsay?] (C Lewis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.78.html">Volume 3 Issue 78 (9 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.78.html#subj1">  On models, methods, and results (Bob Estell)</A>
<LI><A HREF="/Risks/3.78.html#subj2">  Fault tolerance vs. verification experiments (Nancy Leveson)</A>
<LI><A HREF="/Risks/3.78.html#subj3">  The second Tomahawk failure (PGNeumann)</A>
<LI><A HREF="/Risks/3.78.html#subj4">  Re: Overrides and tradeoffs (Eugene Miya, Herb Lin)</A>
<LI><A HREF="/Risks/3.78.html#subj5">  Software getting old (Ady Wiernik)</A>
<LI><A HREF="/Risks/3.78.html#subj6">  Rebuttal -- Software CAN Wear Out! (George Cole)</A>
<LI><A HREF="/Risks/3.78.html#subj7">  "Obsolescence" and "wearing out" as software terms (Dave Benson)</A>
<LI><A HREF="/Risks/3.78.html#subj8">  Obsolesence and maintenance - interesting non-software anecdote (Jon Jacky)</A>
<LI><A HREF="/Risks/3.78.html#subj9">  FAA - Plans to replace unused computers with new ones ( McCullough)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.79.html">Volume 3 Issue 79 (12 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.79.html#subj1">  China Air incident... the real story (Peter G. Trei)</A>
<LI><A HREF="/Risks/3.79.html#subj2">  Air-Traffic Control Spoof (Peter G. Neumann)</A>
<LI><A HREF="/Risks/3.79.html#subj3">  Aviation Accidents and Following Procedures (<A HREF="/Risks/3.77.html">RISKS-3.77</A>) (Matthew Waugh)</A>
<LI><A HREF="/Risks/3.79.html#subj4">  DC-9 crash again (Peter Ladkin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.80.html">Volume 3 Issue 80 (15 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.80.html#subj1">  US Navy reactors (Henry Spencer)</A>
<LI><A HREF="/Risks/3.80.html#subj2">  Data Protection Act Risks (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/3.80.html#subj3">  Is Bours(e)in on the Menu? (Martin Minow)</A>
<LI><A HREF="/Risks/3.80.html#subj4">  Re: Software Wears Out (anonymous)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.81.html">Volume 3 Issue 81 (19 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.81.html#subj1">  System effectiveness is NOT a constant! (anonymous)</A>
<LI><A HREF="/Risks/3.81.html#subj2">  Aircraft self-awareness (Scott Preece)</A>
<LI><A HREF="/Risks/3.81.html#subj3">  Re: US Navy reactors (Brint Cooper, Eugene Miya, Stephen C Woods)</A>
<LI><A HREF="/Risks/3.81.html#subj4">  Editorial on SDI (Michael L. Scott)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.82.html">Volume 3 Issue 82 (20 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.82.html#subj1">  NASDAQ computer crashes (Jerry Leichter, Vint Cerf)</A>
<LI><A HREF="/Risks/3.82.html#subj2">  Sensors on aircraft (Art Evans, Henry Spencer)</A>
<LI><A HREF="/Risks/3.82.html#subj3">  Loss of the USS Thresher (John Allred)</A>
<LI><A HREF="/Risks/3.82.html#subj4">  Re: US Navy reactors (Henry Spencer)</A>
<LI><A HREF="/Risks/3.82.html#subj5">  Risks from Expert Articles (Andy Freeman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.83.html">Volume 3 Issue 83 (21 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.83.html#subj1">  Risks from Expert Articles (David Parnas, Herb Lin, Andy Freeman)</A>
<LI><A HREF="/Risks/3.83.html#subj2">  Loss of Nuclear Submarine Scorpion (Donald W. Coley)</A>
<LI><A HREF="/Risks/3.83.html#subj3">  Staffing Nuclear Submarines (Martin Minow)</A>
<LI><A HREF="/Risks/3.83.html#subj4">  An SDI Debate from the Past (Ken Dymond)</A>
<LI><A HREF="/Risks/3.83.html#subj5">  System effectiveness is non-linear (Dave Benson)</A>
<LI><A HREF="/Risks/3.83.html#subj6">  Stealth vs Air Traffic Control (Schuster via Herb Lin)</A>
<LI><A HREF="/Risks/3.83.html#subj7">  Missing engines &amp; volcano alarms (Martin Ewing)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.84.html">Volume 3 Issue 84 (22 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.84.html#subj1">  Risks of using an automatic dialer (Bill Keefe)</A>
<LI><A HREF="/Risks/3.84.html#subj2">  Re: Missing engines &amp; volcano alarms (Eugene Miya)</A>
<LI><A HREF="/Risks/3.84.html#subj3">  False premise ==&gt; untrustworthy conclusions (Martin Harriman)</A>
<LI><A HREF="/Risks/3.84.html#subj4">  USN Automated Reactors (Dan C Duval)</A>
<LI><A HREF="/Risks/3.84.html#subj5">  Keep It Simple as applied to commercial nuclear power generation       (Martin Harriman)
</A>
<LI><A HREF="/Risks/3.84.html#subj6">  Works as Documented (Martin Minow)</A>
<LI><A HREF="/Risks/3.84.html#subj7">  Re:  Editorial on SDI (Michael L. Scott)</A>
<LI><A HREF="/Risks/3.84.html#subj8">  Risks from Expert Articles (Herb Lin)</A>
<LI><A HREF="/Risks/3.84.html#subj9">  Stealth vs. ATC / SDI Impossibility? / Missing Engines ? (Douglas Humphrey)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.85.html">Volume 3 Issue 85 (23 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.85.html#subj1">  On the Risk of Discussing SDI (Craig Milo Rogers)</A>
<LI><A HREF="/Risks/3.85.html#subj2">  SDI Impossibility (Douglas Humphrey)</A>
<LI><A HREF="/Risks/3.85.html#subj3">  Swedish Vulnerability Board Report on Complex System Vulnerabilities      (Chuck Youman)
</A>
<LI><A HREF="/Risks/3.85.html#subj4">  Re: Thresher (David Feldman)</A>
<LI><A HREF="/Risks/3.85.html#subj5">  Stealth and ATC (Dan Melson)</A>
<LI><A HREF="/Risks/3.85.html#subj6">  Inoperative components (Peter Ladkin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.86.html">Volume 3 Issue 86 (26 Oct 86 )</A>
<DD><UL>
<LI><A HREF="/Risks/3.86.html#subj1">  Addition to Census of Uncensored Sensors (PGN)</A>
<LI><A HREF="/Risks/3.86.html#subj2">  Military vs. civilian automatic control systems (Will Martin)</A>
<LI><A HREF="/Risks/3.86.html#subj3">  Re:  System effectiveness is non-linear (Scott E. Preece)</A>
<LI><A HREF="/Risks/3.86.html#subj4">  SDI assumptions (Daniel M. Frank)</A>
<LI><A HREF="/Risks/3.86.html#subj5">  SDI impossibility (David Chase)</A>
<LI><A HREF="/Risks/3.86.html#subj6">  Editorial on SDI (Henry Spencer plus quote from David Parnas)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.87.html">Volume 3 Issue 87 (26 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.87.html#subj1">  System Overload (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.87.html#subj2">  Information Overload (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.87.html#subj3">  SDI assumptions (Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.88.html">Volume 3 Issue 88 (27 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.88.html#subj1">  SDI, Missing engines, feeping creatureism in consumer products (Roy Smith)</A>
<LI><A HREF="/Risks/3.88.html#subj2">  More aircraft instrumentation (John Allred)</A>
<LI><A HREF="/Risks/3.88.html#subj3">  Re: Military vs. civilian automatic control systems (Eugene Miya)</A>
<LI><A HREF="/Risks/3.88.html#subj4">  Perfection (Douglas Humphrey)</A>
<LI><A HREF="/Risks/3.88.html#subj5">  Shipboard anecdotes (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.88.html#subj6">  RISKS UNDIGESTIFIER on UNIX (John Romine)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.89.html">Volume 3 Issue 89 (28 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.89.html#subj1">  Airplanes and risks (Alan Wexelblat)</A>
<LI><A HREF="/Risks/3.89.html#subj2">  TSE, Air Canada (Matthew Kruk)</A>
<LI><A HREF="/Risks/3.89.html#subj3">  Big Bang (Robert Stroud)</A>
<LI><A HREF="/Risks/3.89.html#subj4">  Physicists on SDI and engineering.. (Herb Lin)</A>
<LI><A HREF="/Risks/3.89.html#subj5">  ABM, SDI, and Freeman Dyson (Peter Denning)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.90.html">Volume 3 Issue 90 (30 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.90.html#subj1">  Anti Skid Brakes (Paul Schauble)</A>
<LI><A HREF="/Risks/3.90.html#subj2">  The Mother's Day Myth, and "Old Reliable" (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/3.90.html#subj3">  Collision avoidance systems (John Larson)</A>
<LI><A HREF="/Risks/3.90.html#subj4">  Crime and punishment (Peter Ladkin)</A>
<LI><A HREF="/Risks/3.90.html#subj5">  Air Canada (Matthew Kruk)</A>
<LI><A HREF="/Risks/3.90.html#subj6">  (Voting) Machine Politics (Mike McLaughlin)</A>
<LI><A HREF="/Risks/3.90.html#subj7">  Computer RISKS in "Ticker-Tape Parades" (PGN)</A>
<LI><A HREF="/Risks/3.90.html#subj8">  SDI vs. Social Security (Scott Guthery)</A>
<LI><A HREF="/Risks/3.90.html#subj9">  SDI Impossibility? (Scott Dorsey)</A>
<LI><A HREF="/Risks/3.90.html#subj10">  Feeping Creaturism (Charley Wingate)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/3.91.html">Volume 3 Issue 91 (30 Oct 86)</A>
<DD><UL>
<LI><A HREF="/Risks/3.91.html#subj1">  Evolution, Progress (Jim Horning)</A>
<LI><A HREF="/Risks/3.91.html#subj2">  System Overload (David Parnas)</A>
<LI><A HREF="/Risks/3.91.html#subj3">  "Perfect" systems from imperfect parts (Bob Estell)</A>
<LI><A HREF="/Risks/3.91.html#subj4">  The software that worked too well (Dave Benson)</A>
<LI><A HREF="/Risks/3.91.html#subj5">  Assessing system effectiveness (Dave Benson)</A>
<LI><A HREF="/Risks/3.91.html#subj6">  Risks of raining computer print-out (Alan Wexelblat, Martin Ewing, PGN)</A>
</UL></DL>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/4/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-57</DOCNO>
<DOCOLDNO>IA012-000128-B043-564</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.2.html 128.240.150.127 19970217001520 text/html 21153
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:13:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/2.01.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 2</H1>
<H2> Saturday, 1 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
More on Shuttle destruct systems 
</A>
<DD>
<A HREF="#subj1.1">
Martin J. Moore
</A><br>
<A HREF="#subj1.2">
 Sean Malloy
</A><br>
<A HREF="#subj1.3">
 Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The Challenger [non]accident 
</A>
<DD>
<A HREF="#subj2.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Redundancy 
</A>
<DD>
<A HREF="#subj3.1">
D. Cook
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Galileo Plutonium power 
</A>
<DD>
<A HREF="#subj4.1">
Martin Schoffstall
</A><br>
<A HREF="#subj4.2">
 James Tomayko
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  VDT's and birth defects in mice 
</A>
<DD>
<A HREF="#subj5.1">
Dan Hoey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  ORCON dissemination constraint on RISKS 1.43 
</A>
<DD>
<A HREF="#subj6.1">
Ted Lee
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
More on Shuttle destruct systems
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>

</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

This morning I talked to my successor at the Cape, who was in the Range Safety 
area during the launch.  I've got a few things to report and some questions to 
answer from previous issues.  I found out that the Range Safety Officer 
commanded the destruction of the SRBs approximately 20 sec after the main 
explosion, as they were careening wildly away from the site.  Both SRBs did
explode on command.  The mood at the Cape is described as "devastated", 
especially among those who went outside to watch live.  My successor also 
reported that Range Safety had been officially cleared as of yesterday,
with respect to any responsibility for the accident; but that they expected 
*much* closer scrutiny than before (which is, of course, perfectly fine.)
Interestingly, many of the media and a large percentage of the general public 
were not aware of the existence of the destruct system.

The latest theory I have heard contains a "leak" in one of the SRBs resulting 
in a 6000 C jet of flame cutting into the tank and igniting its fuel.

Now, individual responses:

&gt; From: John Carpenter
&gt; As I read the article [by Martin Moore in <A HREF="/Risks/1.43.html">RISKS-1.43</A>,] it occurred to me
&gt; that as we discuss the risks of the destruct system we could be creating
&gt; another risk by revealing the nature of it's operation...
&gt; If the destruct system is public information, I would like to know why, 
&gt; If it isn't, it certainly has no place on the net.

Your point is well taken, and I did have some misgivings about posting the 
original article; not because I was revealing anything I shouldn't, but 
because I have no wish to be drawn into a national media controversy.  Hence
the restrictions on dissemination of the article.  None of the information in 
the article was classified, and all of it was publicly available; and NASA is 
very good about providing access to any information that isn't classified.
As to *why* it is public information...I think Neumann's response in 1-45
sums this up pretty well.  Also, if it's not public, then the question that 
will be raised is "what are they hiding?"  

Incidentally, my successor told me that there is an article in this morning's
(1/31) Orlando Sentinel about the destruct system, at about the same level
of detail as my article in 1-43.  Would some Central Florida reader be kind 
enough to send me a summary or a copy of that article?

&gt; From: Jeff Siegal &lt;JBS%DEEP-THOUGHT@mit-eddie.MIT.EDU&gt;
&gt; Is there someone who knows enough about the security at NASA/KSC to be
&gt; able to estimate the difficulty that a malicious party would have in
&gt; getting getting physical access to the shuttle/SRB/MFT prior to the launch?  

I'm not a physical security expert, but I believe that it would be 
extraordinarily difficult to get physical access to the shuttle itself at
any time.  Regarding the possibility raised by Kyle of a rifle shot, NASA
maintains a "clear zone" 1.5 miles (I think) in radius around the shuttle when 
it is on the pad.  This includes the closing of a public beach while the 
shuttle is on the pad, invariably causing complaints from some local citizens.

&gt; From: b-davis@utah-cs.ARPA (Brad Davis)
&gt; It also brings up an important question.  If the hardware system is
&gt; redundant, what about the software system?  Is the same software running
&gt; on all of the redundant hardware systems or are there more than one 
&gt; software packages developed.  If there is only one software package then
&gt; if one system fails due to a software failure then the other systems'
&gt; software may fail since the same conditions may still be in effect.

Each member of a redundant set runs the same software (obviously, computers
with different functions run different software).  The danger you note is a 
real one; however, I believe the best solution is to make each piece of 
software as robust and fail-safe as possible.  Consider that if redundant 
computers were running different software, you could have a failure of 
computer A and switchover to computer B without being able to reliably predict 
what computer B was doing at that instant!  The whole idea of redundancy is
that if a tool breaks in my hand, I want to be able to slap another one of the
same kind of tool into my hand and not miss a beat.  What your point leads to
is to have additional tools for cases where the first one doesn't apply; this
is a good idea, but it actually falls under the heading of "robustness" rather 
than "redundancy."
                                       mjm

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Possible triggering of the self-destruct mechanism &amp; (non)accident
</A>
</H3>
<address>
Sean Malloy
&lt;<A HREF="mailto:malloy@nprdc.arpa ">
malloy@nprdc.arpa 
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 07:05:50 pst
</i><PRE>

  &gt;Date: 30 Jan 86 09:23:53 PST (Thu)
  &gt;From: Peter G. Neumann &lt;Neumann@SRI-CSL.ARPA&gt;
  &gt;Subject: Possible triggering of the self-destruct mechanism

[The physicist ... who speculated that the explosion in the solid-fuel
rocket booster set off the self-destruct mechanism ... suggested that it
could not have been a hydrogen leak because hydrogen burns clear and the
Shuttle explosion had an obvious orange glow] is a classic example of what
happens when people overspecialize themselves. Here we have a physicist
making inaccurate statements about a fact of chemistry. I would suggest that
this physicist watch the film of the Hindenberg disaster, and watch the
bright, opaque flames of hydrogen burning in an insufficient quantity of
oxygen for complete consumption. Only when hydrogen has a sufficient
quantity of oxygen to burn completely does it burn with a clear blue flame.

One of the problems that this brings up is the tendency of the average
person to regard any statement made by a scientist about a scientific
subject as being correct because "they've been trained in science, so they
know what they're talking about", whether they are making a statement within
their field or out of it. Particularly when a scientist says that something
is impossible or impractical. Too many scientists over history have delcared
something impossible or impractical that is commonplace today to reject some
line of research because of such pronouncements.

   &gt;Date: Thu 30 Jan 86 20:22:37-EST
   &gt;From: Jeff Siegal &lt;JBS%DEEP-THOUGHT@mit-eddie.MIT.EDU&gt;
   &gt;Subject: The Challenger [non]accident

   &gt;I have heard speculation that some fuel leaking (LHY or LOX) from the
   &gt;MFT and a unexpected flame could be seen (on slow-motion videotape)
   &gt;for some time prior to the explosion.  This seems consistent with
   &gt;rifle bullet impact/puncture, long before the actual explosion
   &gt;occured.

This is one of the possibilities that the NASA investigating board is
going to be looking at. However, the existence of the flames in the
turbulent area just aft of the external tank is also consistent with a
leak in the fuel pipes from the external tank to the orbiter. 

If it did occur from an external impact, then the leak would have to
have started after the shuttle had taken off, because the plume of
escaping LHY would have caused enough condensation to be visible on
the gantry monitors, a situation that would have halted the launch. I
don't know of any way that someone shooting at the shuttle could be
sure that the bullet would only damage the tank enough to fail at max
Q, rather than penetrate and start a leak immediately. Or, failing
that, to hit the external tank after launch, with the shuttle rolling
and pitching into its climb attitude.

	Sean Malloy
	(malloy@nprdc-arpa)

-------------------------------

Date:     Fri, 31 Jan 86 9:54:00 EST
From:     Brint Cooper &lt;abc@BRL.ARPA&gt;
To:       "Peter G. Neumann" &lt;Neumann@sri-csl.arpa&gt;
cc:       RISKS@sri-csl.arpa
Subject:  Re:  Possible triggering of the self-destruct mechanism

But the news has consistently been reporting that, after the explosion that
destroyed Challenger, the Air Force used the destruct mechanism to destroy
the boosters (?) because one had gone off course and threatened populated
areas.  If this is true, can we not assume that the destruct mechanism did
not cause the accident?  Is it not a 'one time only' capability?

Brint

   [As Martin Moore said in <A HREF="/Risks/1.43.html">RISKS-1.43</A>, there are FIVE destruct receivers:
    one on the ET and two on each of the SRBs.  I was talking about the one
    on the ET; the SRBs somehow survived until they were intentionally 
    destroyed.  PGN]

</PRE>
<HR><H3><A NAME="subj1.3">
 The Challenger [non]accident
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 10:41:51 EST
</i><PRE>
To: JBS@DEEP-THOUGHT.MIT.EDU
cc: LIN@MC.LCS.MIT.EDU, RISKS@SRI-CSL.ARPA

    From: Jeff Siegal &lt;JBS at DEEP-THOUGHT.MIT.EDU&gt;
    I have heard speculation that some fuel leaking (LHY or LOX) ...
    ... This seems consistent with rifle bullet impact/puncture, long 
    before the actual explosion occured.

Depends on what you mean by "long".  The licks of flame at the base of
the SRB occurred at most 2 sec before the main explosion.  It was
going at 2900 fps, so at best its altitude would have been 1 nautical
mile lower when the bullet hit, meaning 8 nm altitude.  Pretty far out
to imagine a rifle bullet hitting at that point.

    There has been no public mention of the possibility of terrorism.

Terrorists claim credit for events.  To my knowledge, no one has
claimed credit.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Redundancy
</A>
</H3>
<address>
&lt;<A HREF="mailto:dcook@SCRC-STONY-BROOK.ARPA">
dcook@SCRC-STONY-BROOK.ARPA
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 10:49 EST
</i><PRE>
To: risks@SRI-CSL.ARPA
cc: Spool@SCRC-STONY-BROOK.ARPA, dcook@SCRC-STONY-BROOK.ARPA

There is a point in the redundancy argument that has bothered me since I
interviewed at Stratus a year or so ago.  

Using the Stratus example, they run two copies of what they call a dipole.
One copy is "live" and one is shadowing the live one.  Each dipole is two
mirror image processors with a high-speed comparator in the middle.  When
the live module gets a miscompare, it lights a LED and hands control over
to the backup module.  The operating system is able to do whatever clean
up has to be done to brief module 2 so that computing is essentially
non-stop.  (Oh, one little "goodie" is that the module connectors are
designed so that *the customer* can pull out the lighted module and put
in a new one without shutting off the machine.)  Now the $64,000 question:
isn't the compare logic a single point of failure?  (Note that because
in this example you have a total of 4 CPU's, this isn't necessarily
a crash.)  But in the shuttle version, as I understood it, the systems
were only redundant and therefore a comparator or checker failure could,
it seems, knock the system out.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Galileo Plutonium power
</A>
</H3>
<address>
Martin Schoffstall 
&lt;<A HREF="mailto:schoff%rpics.csnet@CSNET-RELAY.ARPA">
schoff%rpics.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 09:56:32 EST
</i><PRE>

I'm not sure how much information is publicly available on the generating
systems of various satellites but I would like to point out something that
has been published that is somewhat analogous:  cardiac pacemakers.

As I remember it the plutonium powered ones were designed such that
the containment device could not be penetrated by:

	- .38 special at 15 feet.
	- cremation temperatures (natural gas)
	- aircraft impact.

Obviously I am being very coarse here and I don't have the details but
I'm sure others do but if the above is "close" I'll throw out some
number estimates that I'm sure others will correct:

	- .38 special at 15 feet, say 1000 feet/sec 300 foot-lbs???
	- natural gas burns at 2000 degrees?
	- say 9gs at impact?

The point is as follows:  If pacemakers are designed to handle stresses
such as that I would assume that the satellites are designed much better,
especially since the Soviets dumped a load on Canada (did they ever pay
damages for that?).

marty schoffstall

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Galileo Plutonium power
</A>
</H3>
<address>
&lt;<A HREF="mailto:James.Tomayko@a.sei.cmu.edu">
James.Tomayko@a.sei.cmu.edu
</A>&gt;
</address>
<i>
Friday, 31 January 1986 13:41:14 EST
</i><PRE>
Message-ID: &lt;1986.1.31.18.22.7.James.Tomayko@a.sei.cmu.edu&gt;

Re Larry Shilkoff's note on Galileo carrying plutonium:

Not only plutonium, but the spacecraft was to be deployed atop a
new version of the Centaur hydrogen/oxygen upperstage used on the
Atlas-Centaur and Titan III boosters. Therefore, aside from several 
hundred pounds of plutonium the Shuttle would be carrying several 
thousand pounds of highly volatile fuel &lt;inside&gt; the cargo bay, adding
considerable energy to any explosion. Worse yet, Galileo was to be the
&lt;first&gt; user of the new upperstage, which shares little with its predecessor
except the name. It has new tanks, engines, and instrumentation. In contrast
to previous unmanned missions, only &lt;one&gt; Galileo has been built. Considering
that the cost of building a second one would only have been 15% of the
cost of the first, NASA is taking a big chance by launching its only
Jupiter orbiter on an untested upperstage, in view of the multiple
failures of Shuttle-carried upperstages such as the IUS and various 
satellite kickstages. 

Sadly, the Galileo launch has already been delayed several years for 
various reasons (including one to switch it from the IUS to Centaur) and
is likely to be delayed again. If the Shuttle fleet is not declared
spaceworthy by May, the precession of Jupiter dictates a 13-month
launch delay. Some of the parts of the spacecraft are nearly six years old
now, and many have been in test for years on end. Even though the
mission is projected to be shorter than Voyager, the spacecraft itself may
actually "live" longer.

As a footnote specific to the risks question, a friend of mine who is a 
an astronaut trainer for NASA said to me several months ago that crews
training for Galileo and the Solar Polar launch also using Centaur were
wary because of critical questions relating to aborts. If the Shuttle
has to do a return to launch site abort or an abort to Africa before deploying
Galileo, what are the dangers of trying to land with a full load of 
hydrogen and radioactive isotopes? The possibility of explosions never
came up. Now it has to.

</PRE>
<HR><H3><A NAME="subj4.2">
VDT's and birth defects in mice
</A>
</H3>
<address>
Dan Hoey 
&lt;<A HREF="mailto:hoey@nrl-aic.ARPA">
hoey@nrl-aic.ARPA
</A>&gt;
</address>
<i>
31 Jan 1986 17:45:15 EST (Fri)
</i><PRE>
To: Risks@SRI-CSL.ARPA

Yesterday I heard a radio report that a Swedish study found that video
display terminals increased the incidence of birth defects in mice.
Does anyone have more information on this?

I have not previously heard of any controlled research in the area that
has identified a hazard.  I am interested in trying to find out what
the results of the study indicated, whether it is a new result, and how
credible it is.

Dan

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 ORCON dissemination constraint on RISKS 1.43
</A>
</H3>
<address>
&lt;<A HREF="mailto: TMPLee@DOCKMASTER.ARPA">
 TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 23:35 EST
</i><PRE>
To:  Neumann@SRI-CSL.ARPA

You realize, of course, that Martin Moore's fascinating and worthwhile
piece is accessible to *ANYONE* on the net who is allowed to use FTP by
their home site since SRI-CSL supports anonymous FTP logons and since
you have the RISKS back-issues in a public file.

                [... or indeed from any BBOARD receiving RISKS, 
                 not even necessarily on the ARPANET!  PGN]

Ted

(For readers not familiar with it, ORCON is a handling marking in some
circles that means "further distribution only with permission of the
originator, i.e., ORiginator CONtrolled." It is a non-trivial task to
get a computer system to implement that handling marking in a secure but
natural way, especially across a network.)

     [Yes, of course.  Less obscurely, someone can even ask to be put on 
      the RISKS list, which I presume would permit me to send them the back
      issue within the spirit of Martin's constraints.  I think what Martin
      may have been more concerned about was wholesale rebroadcastings.  
      So what we have is an experimental exercise in self-control, to see if
      our network community is mature enough to adhere to his constraints.
      I would be very interested in hearing of any postings contary to his
      caveat.  But you are very correct in suggesting that enforcing ORCON
      is a nasty problem that cannot be adequately addressed in most computer
      system environments today.  That is one reason why overclassification
      occurs.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-58</DOCNO>
<DOCOLDNO>IA012-000128-B044-14</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.3.html 128.240.150.127 19970217001537 text/html 12403
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:14:01 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 3</TITLE>
<LINK REL="Prev" HREF="/Risks/2.02.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.04.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 3</H1>
<H2> Saturday, 1 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The possible vs the impossible 
</A>
<DD>
<A HREF="#subj1.1">
Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  RISKS generalizations 
</A>
<DD>
<A HREF="#subj2.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Challenger speculation 
</A>
<DD>
<A HREF="#subj3.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Possible triggering of the self-destruct mechanism 
</A>
<DD>
<A HREF="#subj4.1">
Don Wegeng
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Redundancy in the Shuttle's Computers 
</A>
<DD>
<A HREF="#subj5.1">
Mark S. Day
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Galileo Plutonium power 
</A>
<DD>
<A HREF="#subj6.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Icing the Shuttle 
</A>
<DD>
<A HREF="#subj7.1">
Jim McGrath
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re:  The possible vs the impossible
</A>
</H3>
<address>
Dave Parnas
&lt;<A HREF="mailto:vax-populi!dparnas@nrl-css.arpa ">
vax-populi!dparnas@nrl-css.arpa 
</A>&gt;
</address>
<i>
Sat, 1 Feb 86 08:52:11 pst
</i><PRE>

In response to an off the cuff remark by an unnamed physicist, Sean Malloy
writes, "Too many scientists over history have declared something impossible
or impractical that is commonplace today to reject some line of research
because of such pronouncements."  It is equally true that, too many
scientists over history have declared to be possible or practical something
that was later found to be impossible or impractical to pursue some line of 
research or development because of such pronouncements."  There have been 
countless schemes to build perpetual motion machines, faster than light
transport, 600 user time-sharing systems, world champion chess programs,
unbreakable codes, impregnable forts, unsinkable ships, etc. etc.  

We cannot reject a negative prediction simply because earlier negative
predictions have been wrong just as we cannot reject a positive prediction
simply because earlier positive predictions have been wrong.  To have
credence any prediction must be supported by detailed argumentation.  If
nobody can produce a convincing refutation of that argumentation, it is
foolish not to act on the prediction.  I would not support any effort to build
faster than light rockets until someone shows me the flaw in Einstein's 
reasoning.  Any researchers who hope to execute the following algorithm,
"for I:=1 step 1 until 10,000 do `build rocket with n stages using DoD
funding' should begin with a serious study of relativity, not with an SDI
proposal to build a national totem pole center.

David L. Parnas

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
RISKS generalizations 
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
1 Feb 1986 1339-PST (Saturday)
</i><PRE>

Thanks for the digest of the digest. In following Risks from day to
day, it was easy to lose sight of the general principles illustrated by
all the specific cases and discussions. I guess that I would add to
your list just one more generalization, concerning our ability to predict
failures:

  If a system is complex, it is practically impossible to predict its
  sources of catastrophic failure. This is especially true in well-
  engineered systems, since good engineers make allowance for the
  problems that they foresee.

Jim H.
       [Jim, That is perhaps the most important of all.  Thanks.  Peter]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Challenger speculation
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!henry@ucbvax.berkeley.edu">
ihnp4!utzoo!henry@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
Sat, 1 Feb 86 05:11:33 PST
</i><PRE>

Herb Lin writes:

&gt; If you are into pure, unadulterated speculation, another possibility
&gt; is that a bullet was fired into an SRB while it was on the ground, and
&gt; lodged there.  When the fuel burned to that point, a jet leaked out,
&gt; and triggered an explosion.

Alas for this particular speculation, the SRB fuel burns outward from the
booster axis rather than upward along the booster.  Combustion starts from
a hole running the full length of the axis, and reaches the outer casing
only at the very end of the burn.  There may well be a few places near the
ends where casing is progressively uncovered -- I don't have drawings at
hand to check on this -- but this imposes much more severe constraints on
aim.  All in all, it seems implausible.  All the more so because the SRBs
continued on after the explosion, reasonably intact with no signs of any
marked side thrust or substantial extraneous exhaust jets.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,linus,decvax}!utzoo!henry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Possible triggering of the self-destruct mechanism
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
1 Feb 86 12:24:16 EST (Saturday)
</i><PRE>
To: risks@sri-csl.arpa
From: Don Wegeng &lt;Wegeng.Henr@Xerox.COM&gt;

I heard on CNN last night that one of the latest theories about the
cause of the shuttle accident is that flames from a leak in an SRB may
have set off the explosives which are part of the ET self-destruct
mechanism. Not knowing anything about explosives, this seems plausible
to me. 

On the other hand, PBS interviewed someone last night (the editor of an
aviation magazine, I believe) who said that a fuel leak in an SRB would
have probably caused it to immediately stray wildly from its previous
trajectory, but that the video of the launch seems to show both of them
continuing on in the same general direction after the explosion. I
believe that Range Safety did not destroy the SRBs until about 20
seconds after the explosion.

/Don

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Redundancy in the Shuttle's Computers
</A>
</H3>
<address>
Mark S. Day 
&lt;<A HREF="mailto:MDAY@XX.LCS.MIT.EDU">
MDAY@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat 1 Feb 86 12:58:03-EST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

A submission in RISKS-2.2 was concerned about a Stratus-like comparator
mechanism being a single point of failure in the Space Shuttle's operations.
However, the space shuttle's redundant set doesn't use a comparator
mechanism.  Instead, the actuators are controlled by a hydraulic
"force-fight" mechanism, with each computer sending independent commands on
independent buses.  If one computer of four fails, the other three can exert
enough force to overpower its (presumably bad) commands.  If this pressure
differential persists for long enough, the overpowered one is hydraulically
bypassed.

For more details, see "Case Study: The Space Shuttle Primary Computer System"
by Al Spector and Dave Gifford in CACM 27 #9 (September 1984).

--Mark

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Galileo Plutonium power
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat,  1 Feb 86 11:15:38 EST
</i><PRE>
To: schoff%rpics.csnet@CSNET-RELAY.ARPA
cc: LIN@MC.LCS.MIT.EDU, risks@SRI-CSL.ARPA

    From: Martin Schoffstall &lt;schoff%rpics.csnet at CSNET-RELAY.ARPA&gt;

    The point is as follows:  If pacemakers are designed to handle stresses
    such as that I would assume that the satellites are designed much better,
    especially since the Soviets dumped a load on Canada (did they ever pay
    damages for that?).

Bad assumption.  The physics of materials tells us that in general,
big things are weak and small things are strong -- relatively
speaking.  The influence that holds things together is an area effect
-- the tensile strength in materials.  The force that breaks things
apart depends on gravity, a volume effect.  As the object gets larger,
the gravity induced stress grows faster than the tensile stresses.
That's why it's harder to break a small clump of ice than a big one.

The Soviet ultimately paid about 1/5 the cleanup costs.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Icing the Shuttle
</A>
</H3>
<address>
"Jim McGrath" 
&lt;<A HREF="mailto:MCGRATH%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
MCGRATH%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat 1 Feb 86 19:16:42-EST
</i><PRE>
To: risks%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
cc: aviation%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU

   From: Werner Uhrig  &lt;CMP.WERNER@R20.UTEXAS.EDU&gt;
   From TV-news coverage, I have the impression as if there might not
   have been adequate attention paid to icing which is supposed to
   have occurred this morning on the launch-pad.

My understanding was that the shuttle launch was delayed for more than
an hour due to the icing.  Since they delayed the launch specifically
because of the weather, I strongly doubt that they would have delayed
it for too short a period (if they are going to be yelled at by the
media for being overly cautious, then they might as well delay for the
full required time).

Jim
      [This subject drifts somewhat from the computer-related risks. 
       However, because we have to train ourselves to think about
       vulnerabilities overall, I have included Jim's message.  
       Jim, note the various reports of icicles.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-59</DOCNO>
<DOCOLDNO>IA012-000128-B044-45</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.4.html 128.240.150.127 19970217001558 text/html 14341
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:14:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 4</TITLE>
<LINK REL="Prev" HREF="/Risks/2.03.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.05.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 4</H1>
<H2> Sunday, 2 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Solid propellants 
</A>
<DD>
<A HREF="#subj1.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Plutonium 
</A>
<DD>
<A HREF="#subj2.1">
Jim McGrath
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  SRB Self-Destruct Mechanisms 
</A>
<DD>
<A HREF="#subj3.1">
Clive Dawson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Details on the 1981 Quebec election -- a program bug 
</A>
<DD>
<A HREF="#subj4.1">
Jean-Francois Lamy
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Solid propellants
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Sun, 2 Feb 86 14:08:17 est
</i><PRE>

Odd topic for a computer centered forum - but worth discussing a bit.  The
computer hook relates to what could have been monitored, detected, and reac-
ted to in computer time; but not in human time.  I base this discussion on
long-ago experience in writing about solid propellant rockets, plus Sunday's
TV &amp; radio news.

1.  Solid propellants burn at a surface.  If they are designed to burn at one
end, they are called "cigarette burning."  If they are designed to burn 
through a hole in the middle, they are not.  The prepared hunk of propellant 
is called a "grain."  

2.  Cigarette burning produces roughly constant propelling force throughout 
the burn.  Chunks of loose propellant (cylinders, spheres, etc.) produce more
thrust at the beginning, less at the end, as the surface area of the grains is
reduced/consumed.

3.  The hole in the center of a grain can be tailored in shape to affect burn
characteristics just about any way the engineer wants.  In addition, "inhibi-
tors" can be put on the grain to further control its burn characteristics.

4.  In most boosters the grain fills the container, except for the hole in the
center, and a space near the nozzle.  An ignitor (actually, another small 
rocket) is usually at the end opposite the nozzle. 

5.  Remember, the grain burns at the surface.  A crack in the grain provides
another surface to burn.  If the grain separates from the casing, the 
exterior of the grain provides another burning surface.  If the grain is 
sectional, i.e. too large to build as one unit, the ends of the sections can
provide burning surfaces.  Naturally, it is the engineer's job to control and
prevent these undesirable burning surfaces, and to produce the thrust profile
required for the task at hand. 

(tutorial ends, speculation begins)

It is my understanding that "SRBs" were built in 6 sections, and assembled
on-site. Nose, 4 grain sections (not necessarily identical, the hole can be
tapered), and tail.  I also understand that the casing sections were "bolted"
together (probably a fairly complex bolting system); and were considered to 
be quite safe &amp; reliable.  The casings were recovered after a launch, refurb-
ished, reloaded, &amp; re-used.

Recently released film, computer-enhanced offline, after the accident, show
that the right hand SRB had a plume coming out the side, in a location that
appeared to me to be about where the joint between the 3rd and 4th grain/
casing sections would be - but, depending on the actual design, could have
been further aft, near the end of the grain, towards the nozzle.  If this 
was a casing/grain burn-through, the mildest result would be assymetric 
thrust.  *This should have been immediately detectable by the guidance system's
reaction in attempting to maintain the desired trajectory.*  If similar per-
terbations occurred in wind shears, etc., it might not be recognizable as
abnormal. 

Another result could be that the errant jet impinged on the main fuel tank,
heating, penetrating, and igniting the fuel load. (It might be able to ignite
it without penetrating the tank structure.)  *This should be quickly detec-
table by excursions in tank pressure.*  Reaction times, even of computers, 
might not be fast enough to make any difference in the outcome.

I believe that both of the above could have been detected with instrumentation
that was certainly on board.  Additional (or existing?) instrumentation could
detect temperature changes in SRB and fuel tank skins, torques on SRB mounts,
abnormal "seismic" vibrations within the SRB structure, abnormal "plumes",
etc.  

It is so easy to second-guess.  I am sure the engineers concerned are casti-
gating themselves for what they failed to forsee, for what they concluded was
trivial, for what now seems eminently clear to them.  I wish they would quit it.
The whole program is so full of checks and balances that only a Higher Power
could add more.  From "MTM's" description of the safety system, it seems a 
miracle that it was possible to destroy the SRBs under normal circumstances,
much less in the middle of disaster.  The astronauts participated in the design
and manufacturing process - they were ready to go.

We have lost seven of our best and brightest.  But perhaps we are seven closer
to whatever is out there in space, waiting for us to get on with it, get out
there, fulfill our dreams.
------------------------------------------------------------------------------
Peter: this is too long, but I had to write it, tell someone.  I went into 
space in the '50s, with Heinlein and Bonestell.  The Challenger Seven must 
not be regarded as sacrifices on the altar of science - they were just seven
of us who went a little closer to the edge of knowledge than the rest of us
dare.  The human/computer symbiosis will get us out there eventually, and
the Challenger Seven will have helped every one who follows them. - Mike

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Plutonium
</A>
</H3>
<address>
"Jim McGrath" 
&lt;<A HREF="mailto:MCGRATH%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
MCGRATH%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat 1 Feb 86 19:20:51-EST
</i><PRE>
To: risks%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU

First, I assume that everyone knows that no atomic explosion would
occur under any circumstances.  Nor any fallout.

That only leaves the actual radioactive fuel itself.  Plutonium's
danger, for a constant mass, depends upon the size of the particles.
The worse thing that can happen is for dust size particles to be
inhaled.  Large chunks would be a local danger, but one easily
handled.  Note that if the launch was from the Cape, then it would
eventually settle into the ocean.  This would aid considerably in
dispersing it to extremely low concentrations.  Finally, remember that
the Soviets lost a satellite powered by radioactives over Canada.
While the Canadians were not happy, and took clean up measures, the
real problem was getting the Soviets to pony up for the cleanup costs.

    From: James.Tomayko@a.sei.cmu.edu
    .... Therefore, aside from several hundred pounds of plutonium ...

Are you sure about your numbers?  Hundreds of pounds of pure
plutonium?  The cost would be outrageous.  Moreover, this implies a
total mass would be thousands of pounds, if not tons (since the
plutonium would be diluted to a lower concentration and sufficient
shielding for the electronics would have to be provided).  Maybe you
mean a fuel assembly massing hundreds of pounds?  If so, then the
actual mass of Plutonium would be a small fraction of the total mass.

Jim

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
SRB Self-Destruct Mechanisms
</A>
</H3>
<address>
Clive Dawson 
&lt;<A HREF="mailto:AI.CLIVE@MCC.ARPA">
AI.CLIVE@MCC.ARPA
</A>&gt;
</address>
<i>
Fri 31 Jan 86 13:29:44-CST
</i><PRE>
To: risks@SRI-CSL.ARPA

One aspect of the SRB self-destruct mechanism which has bothered me the
most is the fact that a single action will destroy BOTH SRB's (and perhaps
the external tank as well?).  It is clear that recovery of the intact
casings would have been invaluable in the NASA investigation.  News reports
tell us that one of the SRB's was headed on a dangerous course toward
popluated areas and had to be destroyed.  Fair enough.  But why destroy
the other one unless and until it was also proved necessary??

Thinking about this further reveals it may not be that simple.  First of
all, I can imagine scenarios in which both SRB's would need to be destroyed
as quickly as possible, especially in the early phases of the launch.  You
would certainly want to have a mechanism for doing this as exists now.
On the other hand, last Tuesday's events show that it would be very
valuable to be able to destroy them individually as well.  This would imply
modifying the hardware/software such that each SRB responded to two sets
of tones: a common set for both and an individual set.  Perhaps a simpler
scheme would be to simply have two different frequencies which could be
used simultaneously or separately.

Those of us discussing this were momentarily satsified until somebody
asked, "Yes, but how do you tell which SRB is which??!"  In this case, it
was reasonably easy to answer that question when they emerged from the 
fireball, but this might not always be the case.  Furthermore, it's not
clear that the task would be any easier when watching them on a radar
screen.  (What does the Range Safety Officer use?)  This difficulty
can presumably be overcome by electronic equipment on each SRB that would
tag its radar image in some fashion.

I'm wondering if this is a case of "good hindsight", or if there are
other considerations we didn't think of.

Clive

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Details on the 1981 Quebec election -- a program bug (RISKS-2.1)
</A>
</H3>
<address>
Jean-Francois Lamy 
&lt;<A HREF="mailto:lamy%utai%toronto.csnet@CSNET-RELAY.ARPA">
lamy%utai%toronto.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
02 Feb 86 09:40:43 EST (Sun)
</i><PRE>
Organization: CSRI AI, University of Toronto

&gt;   [FROM THE SUMMARY OF DISASTERS in RISKS-2.1:]
&gt;
&gt; - Quebec election prediction gave loser big win [1981] (SEN 10 2, p. 25-26)

Election monitoring software for two television networks was faulty: votes
were being attributed to the wrong candidates.  Names were being kept
in alphabetical order while votes were kept in decreasing order.
This is a language related bug: the contractor was IP Sharp and the
software was programmed in APL -- the informations ended up in distinct
vectors, with one being mistakenly kept sorted.

  Jean-Francois Lamy
  Department of Computer Science, University of Toronto,
  Departement d'informatique et de recherche operationnelle, U. de Montreal.

  CSNet:      lamy@toronto.csnet
  UUCP:       {utzoo,ihnp4,decwrl,uw-beaver}!utcsri!utai!lamy
  CDN:        lamy@iro.udem.cdn (lamy%iro.udem.cdn@ubc.csnet)

    [FOR THE RECORD, HERE WAS THE ORIGINAL PARAGRAPH from Software
     Engineering Notes, from a review by PGN of John Shore's "The
     Sachertorte Algorithm and Other Antidotes to Computer Anxiety", 
     vol 10 no 2, pp. 25-26, April 1985.]

  The chapter on Myths of Correctness brings us the tale of the 1981
  provincial election in Quebec, Canada.  One station's computer had been
  misprogrammed, and it announced that the overwhelming underdog Union
  Nationale had won 19 out of 49 races.  Their announcers somehow even managed
  to come up with erudite analyses explaining why this amazing upset had
  occurred.  It was not until twenty minutes after the other station had
  declared that the Parti Quebecois and the Liberal Party had totally
  dominated the election that the first station realized that there had been a
  colossal mistake somewhere!                       [PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-60</DOCNO>
<DOCOLDNO>IA012-000128-B044-64</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.5.html 128.240.150.127 19970217001612 text/html 16315
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:14:39 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 5</TITLE>
<LINK REL="Prev" HREF="/Risks/2.04.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.06.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 5</H1>
<H2> Monday, 3 Jan 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
SRBs and What the Computers Should Monitor 
</A>
<DD>
<A HREF="#subj1.1">
Sean Malloy
</A><br>
<A HREF="#subj1.2">
 Charley Wingate
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  SRB survival 
</A>
<DD>
<A HREF="#subj2.1">
Bill Keefe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Physical Security at the Cape 
</A>
<DD>
<A HREF="#subj3.1">
Tim Wicinski
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  A hard rain is gonna fall, 
</A>
<DD>
<A HREF="#subj4.1">
Marc Vilain
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Correction re Galileo plutonium 
</A>
<DD>
<A HREF="#subj5.1">
James Tomayko
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Quebec Election 
</A>
<DD>
<A HREF="#subj6.1">
Dan Craigen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  SCRIBE time-bomb goes off! 
</A>
<DD>
<A HREF="#subj7.1">
Peter G. Neumann
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Solid Propellants and What the Computers Should Monitor
</A>
</H3>
<address>
Sean Malloy
&lt;<A HREF="mailto:malloy@nprdc.arpa ">
malloy@nprdc.arpa 
</A>&gt;
</address>
<i>
Mon, 3 Feb 86 07:14:54 pst
</i><PRE>

 &gt;Date: Sun, 2 Feb 86 14:08:17 est
 &gt;From: mikemcl@nrl-csr (Mike McLaughlin)
 &gt;Subject:  SRBs and What the Computers Should Monitor 

 &gt;Another result could be that the errant jet impinged on the main fuel tank,
 &gt;heating, penetrating, and igniting the fuel load. (It might be able to ignite
 &gt;it without penetrating the tank structure.)  *This should be quickly detec-
 &gt;table by excursions in tank pressure.*  Reaction times, even of computers, 
 &gt;might not be fast enough to make any difference in the outcome.

&gt;I believe that both of the above could have been detected with instrumentation
 &gt;that was certainly on board.  Additional (or existing?) instrumentation could
 &gt;detect temperature changes in SRB and fuel tank skins, torques on SRB mounts,
 &gt;abnormal "seismic" vibrations within the SRB structure, abnormal "plumes",
 &gt;etc.  

One of the points that was brought up during the broadcasts the day of the
disaster was that the telemetry tapes were going to have to be analyzed to
determine if there was any indication as to what happened.  The temperature
data for the external tank was specifically mentioned as one of the
telemetry streams that was NOT fed to a display in either the launch control
area or Mission Control. The NASA spokesman explained that there was so much
information coming in that a decision had to be made to limit what the
launch control personnel had to pay attention to.

This brings up a much more subtle problem in risk evaluation -- what data is
considered relevant to the task at hand? A line has to be drawn between
significant and extraneous data, based on the processing capacity of the
system/personnel interpreting the data. NASA had decided that the ET
temperatures were not of immediate use to the launch control personnel, and
simply recorded the data.  In the previous 24 shuttle launches, they were
right; in this case, they were wrong. In the future, they probably will have
someone monitoring that data. What also has to be considered in the decision
is what can be done on the basis of a given stream of data. I don't know how
long the ET temperatures would have been elevated before the explosion, so I
don't know whether there would have been time to recognize the problem,
identify the source, and jettison the SRBs. If you can show that there won't
be enough time to react properly, then giving someone responsibility for
making the right decision in that situation is asking someone to volunteer
to have a nervous breakdown.

In retrospect, there should have been immediate scrutiny of the SRB
performance. Looking at the pictures of the exhaust trails after the
explosion, one of the SRBs is looping away from the blast apparently
undamaged, while the trail from the other proceeds straight for a
short distance, then peters out abruptly. Why would one survive
unscathed while the other one was badly damaged unless something
happened with or adjacent to the SRB? Hindsight is always 20/20.

	Sean Malloy
	(malloy@nprdc-arpa)

</PRE>
<HR><H3><A NAME="subj1.2">
  SRBs and What the Computers Should Monitor
</A>
</H3>
<address>
Charley Wingate 
&lt;<A HREF="mailto:mangoe@mimsy.umd.edu">
mangoe@mimsy.umd.edu
</A>&gt;
</address>
<i>
Mon, 3 Feb 86 14:00:39 EST
</i><PRE>
Organization: University of Maryland, Dept. of Computer Sci.

  &gt;  If this [new plume]
  &gt;was a casing/grain burn-through, the mildest result would be assymetric 
  &gt;thrust.  *This should have been immediately detectable by the guidance
  &gt;system's reaction in attempting to maintain the desired trajectory.*  If
  &gt;similar pert[u]rbations occurred in wind shears, etc., it might not be
  &gt;recognizable as abnormal. 

In fact, the shuttle was just passing out of an area where wind shear is
common.  If you look at the trail that was left, there appears to be a sharp
jog just before the plume enters the base of the fireball cloud, suggesting
either wind shear or perhaps the thrust from the extra hole.  It's also
possible that the thrust from the spurious plume would be too small to be
noticed (which I believe is in this case a matter of several percent).

  &gt;Another result could be that the errant jet impinged on the main fuel tank,
      [... see above message ...]

Judging from the film, this seems unlikely, although localized overheating
could have occured and caused a failure.

  &gt;Those of us discussing this were momentarily satsified until somebody
  &gt;asked, "Yes, but how do you tell which SRB is which??!"  ...

Actually, the shuttle is within visual range throughout the SRB boost phase,
if I remember correctly.  The two boosters could be distinguished by
painting a different roll pattern on each.

As far as risks are concerned, I think that the one point of all of this is
to illustrate the value of collecting data even if you can't immediately use
it to determine what to do.  There seems to be a consensus, for instance,
that temperature readings on the ET and the removed sensors on the SRBs were
useless under normal circumstances.  It was immediately apparent how
valuable they would be in illuminating the failure that did finally occur.
It will be interesting to see if NASA's philosophy changes as a result of
the accident.

Charles Wingate

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
SRB survival
</A>
</H3>
<address>
Bill Keefe
&lt;<A HREF="mailto:keefe%milrat.DEC@decwrl.DEC.COM  ">
keefe%milrat.DEC@decwrl.DEC.COM  
</A>&gt;
</address>
<i>
Monday,  3 Feb 1986 07:45:51-PST
</i><PRE>

That both SRB's survived, while the shuttle didn't, makes me wonder how the 
structural integrity of the SRB's differed from the shuttle in allowing
them to survive the explosion.

	- Bill Keefe

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Physical Security at the Cape
</A>
</H3>
<address>
Tim Wicinski 
&lt;<A HREF="mailto:wicinski@nrl-css.ARPA">
wicinski@nrl-css.ARPA
</A>&gt;
</address>
<i>
Mon, 3 Feb 86 07:41:52 est
</i><PRE>

I believe someone asked about the security out at the Cape, I have some good
first hand knowledge about it.  I have been to over a half dozen launches
and/or attempted launches at the Cape, and I worked there for a few months
as a Contractor during a few launches.  A few days before a launch the Air
Force closes off the beaches north of the Cape for a good distance (over 3
miles) as well as some of the beaches south of the Cape.  I believe they try
to keep visitors away from the launch site at a distance of about 4 miles,
which is is how far away you see the launch if you get a car pass from Nasa.
The press and VIP's sit only 2.3 miles from the launch pad, and they have a
hard time from the guards getting there (I once viewed the launch from
here).  Also, planes are allowed in a restricted air space around the Cape,
but you are still a good distance from the launch itself, and with Air Force
jets patrolling the area to make sure of this.

On launch days when I worked at the Cape, I usually had my car searched,
and a few times they put in spot check points to make sure no one was going
where they weren't supposed to.  At every launch the security I felt was
very good, but I guess there is always somewhere where there could be 
a place where someone could get in undetected, it is a big place. 

--tim           wicinski@nrl-css        {umcp-cs decvax}!nrl-css!wicinski

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
A hard rain is gonna fall.
</A>
</H3>
<address>
Marc Vilain 
&lt;<A HREF="mailto:MVILAIN@G.BBN.COM">
MVILAIN@G.BBN.COM
</A>&gt;
</address>
<i>
Mon 3 Feb 86 15:18:48-EST
</i><PRE>
To: risks@SRI-CSL.ARPA

   Larry Shilkoff observed in RISKS 1-45 that future shuttle missions have
(or maybe had) been planned to carry plutonium-powered spacecraft, the
Galileo probe in particular.  Had Challenger carried such a spacecraft,
Southern Florida would have been exposed to substantial plutonium fallout.

   This brings up a similar issue with the Strategic Defense Initiative.  In
a recent Forum article in New Scientist (16 January 1986), physicist Raymond
Harwell considered the after-effects of a *successful* interception of
Soviet ICBM boosters.  He looked at the levels of radioactive fallout that
would ensue from the return to Earth of disabled ICBMs and their warheads.
Quoting from his article:

  Some simple calculations indicate the likely consequences of SDI
  interceptions of Soviet ICBMs.  A Soviet first strike could involve the
  simultaneous launching of some 5000 nuclear warheads at targets in the US.
  If only 20 percent of these warheads, each containing 10 kg of plutonium
  239, are disintegrated (without a nuclear explosion) in the northern
  hemisphere, about 10^13 lethal doses (if inhaled or ingested) of
  alpha-emitting plutonium would be released -- about 5,000 doses per person
  in the northern hemisphere.  If that radioactive debris were distributed
  uniformly, there would be one lethal dose for every 25 square metres of the
  northern hemisphere.  Not all the radioactive material will have immediate
  effects on Earth but, however delayed the fallout of stratospheric plutonium
  might be, its long half-life (24,000 years) would ensure its eventual
  arrival at altitudes likely to be occupied by human beings, other animals
  and plants.

   Most of the technical discussion of the risks in deploying the SDI has
focussed on its failure modes.  Harrowell's analysis brings up another face
of the problem, namely that the success mode of the system may be so
narrowly defined as to ensure significant, if not unacceptable, risks --
whether the system succeeds or fails.

   The regrettable lesson, is that success of an engineering
application, if defined overly narrowly, may not be success at all.

   marc vilain.

PS: Full reference to the article: Raymond Harrowell, "Debris that
shatters the star wars myth", _New Scientist_, 16 January 1986, page 55.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Correction re Galileo plutonium
</A>
</H3>
<address>
&lt;<A HREF="mailto:James.Tomayko@a.sei.cmu.edu">
James.Tomayko@a.sei.cmu.edu
</A>&gt;
</address>
<i>
Monday, 3 February 1986 11:40:09 EST
</i><PRE>

Re my post dated 31 January:

&gt;...aside from several hundred pounds of plutonium.....(onboard Galileo)

Make that 24 pounds---sorry for the mistatement.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Quebec Election
</A>
</H3>
<address>
Dan Craigen  
&lt;<A HREF="mailto:CMP.CRAIGEN@R20.UTEXAS.EDU">
CMP.CRAIGEN@R20.UTEXAS.EDU
</A>&gt;
</address>
<i>
Mon 3 Feb 86 14:43:55-CST
</i><PRE>
To: risks@SRI-CSL.ARPA

Naturally I was somewhat interested in Lamy's comments on the Quebec
election (1981) and I.P. Sharp's role.  I was only marginally aware of the
details involved and thought I should check the facts. 
                                                   [Dan is at IPSharp.  PGN]
Lamy is essentially accurate in his comments. His message does,
however, seem to indicate that there was an error in the APL language
interpreter. Such was not the case -- it was a programming error.
A case could possibly be made that the programming styles that have developed
around the APL notation led to the resulting situation. (But there
are always penalties that arise from using any notation...)

dan

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
SCRIBE time-bomb goes off!
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Mon 3 Feb 86 02:05:07-PST
</i><PRE>
To: RISKS@SRI-CSL

At the same time over the past weekend, SCRIBE stopped working on several
(but not all) SRI computer systems.  There was some sort of accidental
latent time-bomb in the UNILOGIC software (other than the expected annual
crypto-lock time-bomb that goes off annually to prevent people from merrily
copying SCRIBE and using it indefinitely or without paying their dues).
This is a fine example of software that has always worked suddenly no longer
working.

Peter

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-61</DOCNO>
<DOCOLDNO>IA012-000128-B044-81</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.6.html 128.240.150.127 19970217001624 text/html 17651
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:14:53 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 6</TITLE>
<LINK REL="Prev" HREF="/Risks/2.05.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.07.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 6</H1>
<H2> Tuesday, 4 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Shuttle computers 
</A>
<DD>
<A HREF="#subj1.1">
Marc Vilain
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  SRBs and Challenger 
</A>
<DD>
<A HREF="#subj2.1">
Mike Iglesias
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Galileo, Plutonium, Centaur, physical security [4 messages] 
</A>
<DD>
<A HREF="#subj3.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  RISKS-2.5 &amp; "Some simple calculations" 
</A>
<DD>
<A HREF="#subj4.1">
Bob Ayers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A hard rain is gonna fall. 
</A>
<DD>
<A HREF="#subj5.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  By the slip of a finger ... 
</A>
<DD>
<A HREF="#subj6.1">
Ted Lee
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Shuttle computers
</A>
</H3>
<address>
Marc Vilain 
&lt;<A HREF="mailto:MVILAIN@G.BBN.COM">
MVILAIN@G.BBN.COM
</A>&gt;
</address>
<i>
Tue 4 Feb 86 12:34:09-EST
</i><PRE>
To: risks@SRI-CSL.ARPA

The following is excerpted from this Sunday's New York Times.  It may
be somewhat old news to some, but does a good job of summarizing much of
the evidence and arguments surrounding the Challenger's computers.

           SHUTTLE EXPERTS DOUBT COMPUTERS COULD DETECT FIRE
                           By David E. Sanger

   The computers and sensors that guided the flight of the space shuttle
Challenger appear not to have been programmed to detect flames burning
throught the sides of a solid-fuel booster rocket, experts familiar with the
shuttle system said yesterday.

   Their comments came as evidence accumulated that the right-side booster
began to fail as much as 10 seconds before the explosion that destroyed the
craft, as reported yesterday in the New York Times.

   Even if the sensors had picked up the first signs of fire, safety
measures built into the system to protect the astronauts would have
prevented the shedding of the giant external fuel tank that exploded soon
after, NASA officials and the computers' designers said.

                            Only From Pilot

   That command could have come only from the pilot, and officials said they
doubted even that could have saved the crew.
   ...
   Experts who have studied the shuttle's computer system say it was not
programmed to separate the orbiter automatically from its fuel supply in
part because of the fears that faulty sensor readings could cause the
computers to abort a mission unnecessarily, risking the lives of the crew.

                      Preparation for Emergencies

   Still the possibility that there were signs of trouble as long as 10
seconds before the explosion raised some questions yesterday about the
enormously complex equipment that guides the shuttle.
   ...
   "The possibility that a booster might burn through could well have
been a failure mode that was never considered," said Alfred Spector, a
Carnegie-Mellon professor who two years ago conducted a study of the
computer system guiding the shuttle.

   NASA officials said little publicly in response to the report that
data sent from the shuttle showed a sudden drop in the power of the
right booster rocket about 10 seconds before the spacecraft exploded.

   But computer experts said the computer's response to such a power drop
may have been executed flawlessly.  The program, they said, was primarily
designed to correct for the effects of an uneven rocket thrust by swiveling
engine nozzles to the side, keeping the shuttle on course.  Sources close to
the situation say that the ground data show that the nozzles had in fact
swiveled to one side.

   In the absence of other danger signals, however, the computer would not
have searched for the cause of the power loss.  And the initial signals
apparently indicated only a 4 percent decrease in thrust, a figure that the
computer, or the cabin crew and officials at the Johnson Space Center in
Houston, may have judged did not indicate a serious problem.
   ...
   [End of excerpt]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
SRBs and Challenger
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 03 Feb 86 21:06:59 -0800
From: Mike Iglesias &lt;iglesias@UCI.EDU&gt;

According to this morning's LA Times:

 - Early shuttle flights had sensors on the SRBs to monitor performance,
   but they were removed to save weight when it was felt that the SRBs
   were performing well.  The sensors monitored pressure, temperature
   and vibration in the SRBs.

 - Two Rockwell officials familiar with the NASA inquiry said that NASA
   data shows that the 3 main engines experienced a power loss just
   before the explosion.  The power loss was noted between one-tenth and
   one-one hundreth of a second before the explosion.  The SRB that
   probably caused the explosion suffered a 3% loss of power (about
   100,000 pounds of thrust) seconds before.

 - NASA noted that even if there were sensors on the SRBs, little can 
   be done to save the crew if there is a problem during the first 2
   minutes during the flight.  They might be able to jettison the SRBs,
   but it would be difficult to stay clear of them and the external
   tank.  And another NASA spokesman said later that the crews don't
   train for that maneuver, and that NASA documents state that such
   an escape is possible only after the SRBs have completed firing.
   The shuttle would have a near-impossible task of ditching in the
   ocean if it was able to steer clear of the SRBs and the ET.

 - Other Rockwell sources said that telemetry shows that the external
   tank experienced an increase in pressure in both the oxygen and
   hydrogen tanks, and that pressure relief valves in both tanks 
   popped to decrease some of the pressure.

Could the crew have survived had they known about the problem?  Who knows?
Maybe, if they had known about the SRB problem in time, if they had been 
able to get away from the SRBs and the ET, and been able to ditch successfully
in the ocean.  That's a lot of ifs...

I wonder if NASA is going to think twice about removing sensors after this...

Mike Iglesias
University of California, Irvine

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Galileo, Plutonium, Centaur, physical security [4 messages combined]
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!henry@seismo.CSS.GOV">
ihnp4!utzoo!henry@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Tue, 4 Feb 86 22:26:32 EST
</i><PRE>

[Re Marty Schoffstall, on plutonium batteries for pacemakers and satellites:]

Note that the Soviet satellites use reactors, not isotope capsules, as
their power sources.  The two are quite different, especially in this
context.  It's not practical to encapsulate a reactor the way the isotope
capsules are armored against possible accidents.

[Re Larry Shilkoff, on Galileo:]

The capsules used to hold plutonium 238 (note that this is not the
fissionable isotope used in reactors and bombs) for deep-space power
sources are designed to withstand uncontrolled re-entry, and I think
to withstand launch accidents as well.  Quite likely they would have
survived intact.  There have been a few re-entries of satellites carrying
such capsules, and one went into the Pacific with the lunar module of
Apollo 13.  No dire results.

[Re James Tomayko, on Centaur aboard shuttle:]

Apart from the volatility, this is nothing new:  major solid-fuel motors
routinely ride in the cargo bay.  Those things are dangerous too.  People
doing some of the amateur-satellite work have estimated that the paperwork
needed to clear a satellite for a ride in the shuttle cargo bay roughly
triples if it is carrying any substantial rocket motor, solid or liquid.

&gt; Worse yet, Galileo was to be the
&gt; &lt;first&gt; user of the new upperstage, which shares little with its predecessor
&gt; except the name. It has new tanks, engines, and instrumentation...

Not quite true:  the Ulysses solar-polar mission, using the same upper
stage, was to launch about a week before Galileo.  Still awfully tight.

&gt; [in an abort] what are the dangers of trying to land with a full load of 
&gt; hydrogen and radioactive isotopes? ...

Actually, although the liquid hydrogen is what everyone points at, the
liquid oxygen is probably the greater danger.  "Stages to Saturn", the NASA
history of the Saturn boosters, commented that liquid hydrogen hazards were
found to be comparable to those of highly-volatile gasoline (not trivial,
mind you!), while it was liquid oxygen that really needed extraordinary
handling precautions.

[Re: Jeff Siegal on NASA/KSC physical security:]

It's not conspicuous, but it's there.  Practically nothing is said about
it in public.  I was down at the Cape for the 41C launch, on the National
Space Institute tour.  We got (I think) a slightly closer look at things
than the ordinary KSC tours, but when we went past the actual active pad
a day or two before launch we were cautioned that (a) the bus could slow
down but it must not stop, and (b) all windows, including the driver's
little vent window, must stay 100% shut.  With a strong indication that
we were being watched and our NASA guide would be in deep guano if either
rule was violated even momentarily.  We went past some press folks setting
up cameras, and our guide commented "if you're wondering why they're allowed
out of their bus and you aren't, it's because they've been searched and you
haven't".  The pad area proper also has an impressive concentration of
things like concertina wire (think of it as industrial-strength barbed wire)
around its perimeter.  It's difficult for a non-professional to evaluate
the quality of the precautions, but they did seem to be taking it seriously.

I have since heard a rumor that there were some awkward and hushed-up
incidents quite early in the Shuttle program that caused considerable
tightening of the original fairly loose security.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,linus,decvax}!utzoo!henry

      [We may be approaching the point of no return on some of the second-
       and third-order discussion.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: RISKS-2.5 &amp; "Some simple calculations"
</A>
</H3>
<address>
&lt;<A HREF="mailto:Ayers.PA@Xerox.COM">
Ayers.PA@Xerox.COM
</A>&gt;
</address>
<i>
4 Feb 86 09:05:41 PST (Tuesday)
</i><PRE>
To: RISKS@SRI-CSL.ARPA
cc: Ayers.PA@Xerox.COM

If we're going to talk about SDI and WWIII rather than computers,
please, let us at least use responsible analysis. Vilain quotes

  Some simple calculations indicate the likely consequences of SDI
  interceptions of Soviet ICBMs.  A Soviet first strike could involve the
  simultaneous launching of some 5000 nuclear warheads at targets in the US.
  If only 20 percent of these warheads, each containing 10 kg of plutonium
  239, are disintegrated (without a nuclear explosion) in the northern
  hemisphere, about 10^13 lethal doses (if inhaled or ingested) of
  alpha-emitting plutonium would be released -- about 5,000 doses per person
  in the northern hemisphere.  If that radioactive debris were distributed
  uniformly, there would be one lethal dose for every 25 square metres of the
  northern hemisphere.  Not all the radioactive material will have immediate
  effects on Earth but, however delayed the fallout of stratospheric plutonium
  might be, its long half-life (24,000 years) would ensure its eventual 
  arrival at altitudes likely to be occupied by human beings, other animals
  and plants.

This arithmetic [of?] "simple calculations" is irrelevant.  The "if"s are
totally bogus.

Every year, the US spreads about one fatal-dose per person of Arsenic
Trioxide onto food-plants via crop-dusters. And how many fatal doses of
salt does Connecticut spread on the roads every winter?

If you believe the quote, everyone in the northern hemisphere is already
dead (more than one fatal dose per person) from the atmospheric bomb
tests of the '50s and 60's.

Bob

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 A hard rain is gonna fall.
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue,  4 Feb 86 23:37:23 EST
</i><PRE>
To: MVILAIN@BBNG.ARPA
cc: ARMS-DISCUSSION@MC.LCS.MIT.EDU, LIN@MC.LCS.MIT.EDU,
    risks@SRI-CSL.ARPA

    From: Marc Vilain &lt;MVILAIN at G.BBN.COM&gt;

       This brings up a similar issue with the Strategic Defense Initiative.  

      If that radioactive debris were distributed uniformly, there would be 
      one lethal dose for every 25 square metres of the northern hemisphere.

Bad assumption.  Most of boost-phase intercept occurs over the Soviet Union. 

       The regrettable lesson, is that success of an engineering
    application, if defined overly narrowly, may not be success at all.

This general point is well-taken, despite my comments above.  As they
say, "The operation was a success but the patient died."

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 By the slip of a finger ... [A lesser risk]
</A>
</H3>
<address>
&lt;<A HREF="mailto: TMPLee@DOCKMASTER.ARPA">
 TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 4 Feb 86 23:33 EST
</i><PRE>
To:  risks@SRI-CSL.ARPA

I thought the following incident fits into RISKS.  Recently one of our
people moved from our Philadelphia corporate headquarters site
(thousands of employees) to our new Atlanta Development Center (only
dozen or so on board at the time.)  He sent the appropriate change of
address notifications into the publishers of his professional journals.
("change my address, P.O.  Box xyz, Blue Bell, Pa., to P.O.  Box qrs,
Norcross, Ga.", or words close to that.)  Shortly thereafter our poor
office secretary and part-time mail clerk down there was inundated with
mountains of journals from one of those publishers.  We don't know
exactly what happened, but apparently the software used to maintain the
circulation list was instructed, and dutifully did so, to "change all
addresses that match" (which, I guess, would be used to move a
household) rather than "change this particular subscriber record":
every single journal by that publisher addressed to our corporate
headquarters (modulo spelling variations, I presume) had by a handful of
keystrokes been redirected elsewhere.  The publisher involved shall
remain nameless (not ACM, that would make too nice a story) but it was
one dealing with the computer field.  The problem appears to have been
fixed, naturally the fix taking the usual "six weeks", whereas the
original error, naturally, happened in a couple of days.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-62</DOCNO>
<DOCOLDNO>IA012-000128-B044-108</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.7.html 128.240.150.127 19970217001637 text/html 18839
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:15:05 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 7</TITLE>
<LINK REL="Prev" HREF="/Risks/2.06.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.08.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 7</H1>
<H2> Thursday, 6 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The lesson of Challenger 
</A>
<DD>
<A HREF="#subj1.1">
Barry Shein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Mistaken Arrest due to computer error 
</A>
<DD>
<A HREF="#subj2.1">
Steve Rabin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Denial of [Religious] Service 
</A>
<DD>
<A HREF="#subj3.1">
Chris Guthrie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Earthquake Monitoring Systems 
</A>
<DD>
<A HREF="#subj4.1">
Gary T. Leavens
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Mice &amp; CRT Radiation 
</A>
<DD>
<A HREF="#subj5.1">
Ted Shapin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  SRBs, What the Computers Should Monitor, and Expert Systems? 
</A>
<DD>
<A HREF="#subj6.1">
Jim Giles
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Redundancy in the Shuttle's Computers 
</A>
<DD>
<A HREF="#subj7.1">
K. Richard Magill
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Nuclear Cargo in the Shuttle 
</A>
<DD>
<A HREF="#subj8.1">
Larry Shilkoff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Software Protection Symposium 
</A>
<DD>
<A HREF="#subj9.1">
Barbara Zayas
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The lesson of Challenger
</A>
</H3>
<address>
Barry Shein 
&lt;<A HREF="mailto:bzs%bostonu.csnet@CSNET-RELAY.ARPA">
bzs%bostonu.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Tue, 4 Feb 86 22:39:47 EST
</i><PRE>

Although this is a very sad event, it would be sadder if we would refuse to
learn from it.

Seven people were killed in this disaster, and billions of dollars of
equipment, but the rest of us will survive. The lesson is the limit of faith
we should put into our technology. I believe we should continue, that in
many ways we have been too cautious and should heed the pioneering spirit we
all feel, even if the pioneers put themselves at risk. Individuals should be
allowed to risk something to gain something, they should be encouraged,
applauded and honored for their sacrifices, if need be.

It is quite another thing to think that such systems can be relied upon
to end the current nuclear nightmare, that in these technologies we
will find strengths that we cannot find in ourselves at a bargaining
table. In this case, we risk far too much.

The technology will fail, we should expect that and have the courage
to take chances where there is something to learn. Only a fool or a
madman would risk an entire civilization's fate on a gadget.

Let's continue into space, with all due speed. But let's also stop thinking
that nations (people!) will settle their differences with gadgets.  The
philosopher's stone for human relations just doesn't exist.

	-Barry Shein, Boston University

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Mistaken Arrest due to computer error
</A>
</H3>
<address>
Steve Rabin
&lt;<A HREF="mailto:stever%vlsi.caltech.edu@nrl-css ">
stever%vlsi.caltech.edu@nrl-css 
</A>&gt;
</address>
<i>
Sun, 26 Jan 86 02:25:03 PST
</i><PRE>

Thursday night I was mistakenly arrested by a Pasadena police patrol due to
a computer error.  I spent two hours in a smelly holding cell while my
friends collected bail.  $130.50 Cash.  Exact change please.

When I appeared in court Friday morning with proof that the ticket had in
fact been paid in February of 1984, the case against me was dismissed.

In conversation with the court clerk and with the police officers who
processed me I learned that mistakes like this are not uncommon, and that
the safest thing for me to due is to keep the 1984 receipt on my person
at all times.  One friendly officer said "In processing these (warrant
dismissals), the paperwork goes through so many hands that if anyone
drops the ball there is no way to tell what happened."

It appears I have a good case against the City &amp; County of LA ("failure to
properly document computer system"), and the City of Pasadena ("improper
stop and use of excessive force by arresting officer").  The excessive force
claim arises because the officer physically prevented my departure after I
had identified myself and before the information about the bogus warrant
came over the radio.  He is not supposed to do this.  There may be an
additional case against Pasadena if in fact the statute on the original
offense (jay walking in 1981) had expired.

Do any of you high powered legal types have any insights on my case?  Do any
of you folks know good, reasonably priced lawyers in the LA area with whom
you have had personal experience?  Have their been any problems with Chas. &amp;
Angelique Johnson, attys?  I am also looking for a good patent lawyer, so if
you know/are one please write me.

My interest in this news group (until now) has been focused on copyright &amp;
software marketing issues.  I am a grad student in Computer Science at
Caltech.  Hobbies include science fiction, the tunes of Garcia/Hunter, and
long distance running.  I would like to do triathalons too but my swimming
is weak.  Pleased to meet you all.

("I won't do it again!  Honest!")
(I thank you for your patience)    stever@{cit-vax.arpa,csvax.caltech.edu}

        [For those of you who have not read RISKS back to 4 September 1985,
         RISKS-1.5 contains several related items, another in <A HREF="/Risks/1.20.html">RISKS-1.20</A>.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Denial of [Religious] Service
</A>
</H3>
<address>
Chris Guthrie
&lt;<A HREF="mailto:chris%ic%BERKELEY.EDU@nrl-css ">
chris%ic%BERKELEY.EDU@nrl-css 
</A>&gt;
</address>
<i>
Tue, 31 Dec 85 20:55:34 PST
</i><PRE>

    [This is an old item, but had not previously been reported here.
     The denial-of-service problem is very widespread, and presents much
     greater risks than most of us realize.  PGN]

Reprinted from the Sacramento Bee:

              ANGRY CALLER TITHES UP FALWELL'S LINE

    A self-employed computer whiz in Atlanta is under orders from a
telephone company to stop making harassing computerized calls to the
Rev. Jerry Falwell's toll-free tithing line.
    Officials of Southern Bell said they would yank Edward Johnson's
service if he didn't unhook his phone from a computer that automatically
dials Falwell's "Old Time Gospel Hour" every 30 seconds, tying up the
line and annoying the operators.
    Falwell aides said they would take legal action against him.
    Johnson's computer has been making the calls to the Lynchburg, Va.,
line day and night since April.  Officials estimated that the computer
has made 500,000 calls to Falwell's line.
    Johnson, 46, a computer analyst who said he wants to bog down Falwell's
fund-raising operations and hurt the organization's morale, maintained that
he is not impressed by the threats.  He said he is considering moving his
computer to a friend's telephone to continue the campaign.
    Falwell aides said they would take legal action against Johnson, who
started his crusade against Falwell after his mother "almost gave the
family farm away" to the television evangelist.
    Mark DeMoss, a Falwell assistant, said Falwell has lost a dollar for
every call Johnson's computer has made.
    "We do plan legal action," DeMoss said.  "Naturally toll-free calls
in that quantity would constitute a pretty significant expense for us."
    Johnson's crusade stopped Friday at 11 a.m. when a Southern Bell
security agent, acting on a complaint from Falwell's organization, called
Johnson and ordered him to unhook his computer from his phone or lose
his telephone service.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Earthquake Monitoring Systems
</A>
</H3>
<address>
Gary T. Leavens 
&lt;<A HREF="mailto:GTL@XX.LCS.MIT.EDU">
GTL@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu 6 Feb 86 12:38:18-EST
</i><PRE>
To: risks@SRI-CSL.ARPA

	I recently read an article in CACM about two earthquake monitoring
networks in California.  Presumably they are designed to withstand a major
earthquake so they can perform their data collection functions, etc.  Does
anyone know if they really are designed to function during a major earthquake?
If so, what design considerations were used?

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Mice &amp; CRT Radiation
</A>
</H3>
<address>
Ted Shapin 
&lt;<A HREF="mailto:BEC.SHAPIN@USC-ECL.ARPA">
BEC.SHAPIN@USC-ECL.ARPA
</A>&gt;
</address>
<i>
Wed 5 Feb 86 12:10:43-PST
</i><PRE>
To: hoey@NRL-AIC.ARPA
cc: risks@SRI-CSL.ARPA
Phone: (714)961-3393; Mail:Beckman Instruments, Inc.
Mail-addr: 2500 Harbor Blvd., X-11, Fullerton CA 92634

John Ott, the pioneer in time lapse photography, published a paperback book
"Health and Light" about 10 years ago.  In it he mentioned his observations
on the negative effects on the health of mice exposed to a color CRT, even
when the screen was covered with black cardboard.
I don't recall any more than that.

Ted.
        [For those of you who were not reading RISKS back in September,
         RISKS-1.6 had a lengthy piece by Al Friend on the CRT subject,
         plus some other comments in RISKS-1.5.  However, Dan Hoey's
         query in RISKS-2.2 asked about a recent Swedish study.  
         Apparently no one had seen it.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
SRBs, What the Computers Should Monitor, and Expert Systems?
</A>
</H3>
<address>
Jim Giles
&lt;<A HREF="mailto:jlg%a@LANL.ARPA ">
jlg%a@LANL.ARPA 
</A>&gt;
</address>
<i>
Thu, 6 Feb 86 18:20:33 mst
</i><PRE>
Organization: Los Alamos National Laboratory

In RISKS-2.5, Sean Malloy writes:
 &gt;One of the points that was brought up during the broadcasts the day of the
 &gt;disaster was that the telemetry tapes were going to have to be analyzed to
 &gt;determine if there was any indication as to what happened.  The temperature
 &gt;data for the external tank was specifically mentioned as one of the
 &gt;telemetry streams that was NOT fed to a display in either the launch control
 &gt;area or Mission Control. The NASA spokesman explained that there was so much
 &gt;information coming in that a decision had to be made to limit what the
 &gt;launch control personnel had to pay attention to.

Has Expert System Technology been thought of as a fix for this
problem?  It would seem that a really fast computer (or several) could
monitor all those inputs which aren't under the direction of human
flight controllers and could be set to pop up warnings for any
conditions that are unacceptably peculiar.  The human flight controllers
would still have the final word on what to do, the computer would just
be there to watch those things that the staff normally can't.  Are
expert systems yet advanced enough to make this worthwhile?  If so,
are any being used?

In the Challenger case, there was a 4% loss of thrust in the SRB about
15 seconds before the explosion.  If this had been correlated with a
temperature rise in the ET or some other anomaly that indicated possible
SRB burnthru, there might possible have been warning of the problem.
An expert system might have been able to correlate several minor
readings that together formed a pattern of SRB failure.  A succinct
display of the information together with the machine's conclusion
could have been given to one of the controllers.

Of course, it is possible that the telemetry tapes contain no information
that would have helped - even if it were monitored.  Abort before the
SRBs stop firing is (I'm told) a risky thing anyway, so advance warning
may not have been of much value.

J. Giles
Los Alamos

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Redundancy in the Shuttle's Computers
</A>
</H3>
<address>
&lt;<A HREF="mailto:decwrl!decvax!cwruecmp!rexago1!rich@ucbvax.berkeley.edu ">
decwrl!decvax!cwruecmp!rexago1!rich@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Mon, 3 Feb 86 18:39:32 est
</i><PRE>
Organization: Roadway Express, Akron, OH

&gt;From: Mark S. Day &lt;MDAY@XX.LCS.MIT.EDU&gt;
&gt;Subject: Redundancy in the Shuttle's Computers 
&gt;To: RISKS@SRI-CSL.ARPA

&gt;A submission in RISKS-2.2 was concerned about a Stratus-like comparator
&gt;mechanism being a single point of failure in the Space Shuttle's operations.
&gt;However, the space shuttle's redundant set doesn't use a comparator
&gt;mechanism.  Instead, the actuators are controlled by a hydraulic
&gt;"force-fight" mechanism, with each computer sending independent commands on
&gt;independent buses.  If one computer of four fails, the other three can exert
&gt;enough force to overpower its (presumably bad) commands.  If this pressure
&gt;differential persists for long enough, the overpowered one is hydraulically
&gt;bypassed.

How is a *single* hydraulic comparator any different than a digital
"force-fight" mechanism?

K. Richard Magill
(don't know my address from arpa, maybe rexago1!rich%Case@csnet-relay
 or rexago1!rich@case.csnet)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Nuclear Cargo in the Shuttle
</A>
</H3>
<address>
&lt;<A HREF="mailto:LShilkoff.ES@Xerox.COM">
LShilkoff.ES@Xerox.COM
</A>&gt;
</address>
<i>
Thu, 6 Feb 86 14:46 PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

An article in the L.A. Times of Feb. 6, 1986 discusses the dangers of
carrying nuclear cargo in the shuttle. The article states:

The Energy Department contends that the protective shell around the
plutonium would withstand explosive pressures up to 2,200 psi, and that
the shuttle explosion appears to be less than 2,200 psi.  According to a
NASA-produced safety analysis report on the Galileo and Ulysses projects,
... a blast caused by activating the spacecraft's "command
destruct" mechanisms' explosive devices attached to the large external tank
and suspected of being detonated by Challenger's leaking solid rocket
booster would produce a burst of pressure ranging from 740 to 7,800 psi. If
a shuttle fails to get off the pad and topples over, even greater explosive
pressure could be generated...possibly as high as from 2,000 to 19,600 psi.

      [By the way, this morning's SF Chron indicates the destruct charges
       for the external tank were found intact.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Software Protection Symposium
</A>
</H3>
<address>
&lt;<A HREF="mailto:Barbara.Zayas%a.sei.cmu.edu@nrl-css">
Barbara.Zayas%a.sei.cmu.edu@nrl-css
</A>&gt;
</address>
<i>
Friday, 17 January 1986 13:41:46 EST
</i><PRE>

Software Protection Symposium
To Be Held in Pittsburgh 4-5 April 1986

PITTSBURGH -- "The Future of Software Protection", a two-day symposium
scheduled for 4-5 April 1986, will bring prominent legal scholars and others
together to discuss one of the most crucial and controversial legal issues
of the day.  The symposium is jointly sponsored by the Software Engineering
Institute and the University of Pittsburgh Law Review.  The program will
focus on intellectual property law and whether it can evolve to provide
adequate protection for software.

Topics to be discussed during the one and a half days include patent
protection for algorithms, simultaneous copyright/trade secret protection,
scope of fair use in copyright cases, ownership rights in computer generated
works, and sui generis protection for software without legislation.
Discussion on the second day will center on the Department of Defense's
software procurement policy.

The registration fee of $100 includes the University of Pittsburgh Law
Review issue in which articles by the major speakers will be published.  
For further information, please contact Carol Biesecker, [412] 268-7786.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-63</DOCNO>
<DOCOLDNO>IA012-000128-B044-128</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.8.html 128.240.150.127 19970217001649 text/html 15768
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:15:18 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 8</TITLE>
<LINK REL="Prev" HREF="/Risks/2.07.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.09.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 8</H1>
<H2> Friday, 7 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Expert systems and shuttles 
</A>
<DD>
<A HREF="#subj1.1">
Michael Brown
</A><br>
<A HREF="#subj1.2">
 Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Plutonium 
</A>
<DD>
<A HREF="#subj2.1">
Martin J. Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Earthquake Monitoring Systems 
</A>
<DD>
<A HREF="#subj3.1">
Mike Raugh via Matt Bishop
</A><br>
<A HREF="#subj3.2">
 Hal Murray
</A><br>
<A HREF="#subj3.3">
     Eugene Miya
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Expert systems and shuttles
</A>
</H3>
<address>
&lt;<A HREF="mailto:mlbrown@nswc-wo.ARPA">
mlbrown@nswc-wo.ARPA
</A>&gt;
</address>
<i>
Fri, 7 Feb 86 09:17:13 est
</i><PRE>

In Risks 2.7, J. Giles speculates:
&gt;Has expert system technology been thought of as a fix for this problem?
&gt;...  a really fast computer ... could monitor all those inputs which aren't
&gt;under the direction of human flight controllers...
&gt;Are expert systems yet advanced enough to make this worthwhile?

Unfortunately, expert systems developed to handle such an occurrence would
have to be based on a foreknowledge of the relationship of the various 
anomalies that occurred in the shuttle disaster.  I seriously doubt that
most competent systems safety engineers could have predicted the occurrence
even with a full knowledge of the anomalies that occurred.  Development of
such an expert system would likely have to be based on that type of 
knowledge.  However, expert systems aside, I am amazed that the NASA systems
safety people would permit a multiple section rocket motor to be manufactured
at one location and assembled at another.  Misfortune has shown us in the past
that these composite structure solid rockets have some very unique and 
undesirable properties.  It will be interesting to see exactly where the 
failure occurred in the shuttle's SRB if in fact it did fail.  If the failure
occurred at some location other than the suspect joint, chalk another one
up to experience.

			Michael Brown

</PRE>
<HR><H3><A NAME="subj1.2">
Expert systems to detect shuttle failure
</A>
</H3>
<address>
Dave Platt 
&lt;<A HREF="mailto:Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA">
Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Fri, 07 Feb 86 10:11 PST
</i><PRE>
References: Jim Giles' comments in Risks 2.7

Well, it's certainly possible to set up some sort of expert system that
would monitor incoming telemetry and issue warnings in case of
possibly-dangerous combinations of unusual conditions.  However,
I can see a couple of difficulties involved here:

1- There are some conflicts re the amount of data that you want to
   feed into the expert-system tool.  Certainly, the more data that
   is available (from many different classes of sensors), the smaller
   the chance that the tool won't have the information needed to
   detect the problem.  [For example, Challenger was equipped with
   far fewer sensors on the SRB than was Columbia during its tryoug
   flights].

   But... as you increase the number of individual sensors, and the
   amount of data (# of different classes of data, especially), you
   necessarily increase the number of rules in the system, and the
   amount of crunchpower necessary to step through the rules and
   determine whether any conclusions need to be brought to the
   attention of the controllers.  It doesn't do you much good to
   receive a warning saying "Engine failure is probable, based on
   conditions xxx and yyy" if you don't get the warning in time to
   do anything about it.

   In my [very limited] experience, very few if any existing expert
   systems are capable of handling large amounts of real-time data;
   the ones that I've seen tend to be somewhat sluggish.  I don't
   doubt that it would be possible to build special-purpose hardware
   that would support such a system... but I don't believe it has been
   done yet.

2- As I understand them, expert systems are designed to reproduce (or
   mimic) the sort of what-if and maybe-then decision sequences that
   an expert would go through when analyzing a particular sort of
   problem.  They work by encoding (in explicit form) the steps and
   conclusion that an expert would use.  A large part of the work
   involved in developing an expert system is sitting down with the
   expert(s), and assisting them in encoding their (often implicit and
   unspoken) rules into rigorous form.

   All well and good... BUT... the expert system's "expertise" is
   entirely limited by the completeness of the rules that are used to
   construct it.  One cannot assume that an expert system will be able
   to detect or diagnose a situation that has never been encountered
   before... it may do so, if the rules were complete enough and if the
   situation is similar to one that has occurred before, but you don't
   want to bet your life on it!

   Only the simplest expert systems can ever be considered to be
   "complete".  When solving a complex, real-world problem (such as
   "Is the shuttle's current behavior normal?"), the best that you
   can expect is that some useful fraction of all possible situations
   will be analyzed in a meaningful fashion.  Expert systems tend to
   grow and evolve as they are used... just as a human expert's
   capabilities do... and both humans and expert systems will tend to
   misdiagnose situations that fall outside of their current knowledge
   base.

3- Even if an expert system reacts quickly and accurately enough to give
   a meaningful warning ("SRBs leaking, ET overheating, explosion
   imminent"), you're still faced with: [A] Human reaction time (controller
   and pilot);  [B] taking the necessary immediate action (split the
   SRBs from the ET and/or split the orbiter away from the ET);  and
   [C] surviving (getting far enough away from the ET before it goes
   *BLOOIE*, and then completing a very difficult dead-stick turnaround
   and landing, or a tough water ditching).  In the case of the Challenger
   explosion, it looks as if all three of these factors were dead-set
   against the crew... there was very little time to react, no way
   to get away, and a water ditching would probably have killed many
   of the crew.

I imagine that you could certainly build an expert system that would
be capable of reading the shuttle's telemetry, and warning of most
conditions THAT THE DESIGNERS OF THE SYSTEM HAD TAKEN INTO ACCOUNT!
The real problem lie, of course, in detecting conditions that no one
had expected would occur... if the system has no rules that would lead
to a conclusion such as "The SRB segment ring seals are leaking",
then the system will never report such a condition.  At best, some other
warning will be reported ("Asymmetric thrust from SRBs exceeding
2%");  at worst, no warning will be received, or the system will issue
warnings unnecessarily ("Heavy engine vibration").

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Plutonium
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

I don't think the worries about plutonium should be dismissed out of hand.
It is my understanding that the lethality of plutonium is due to its extreme
toxicity, as opposed to its radioactivity.  Comments from a knowledgeable
chemist are eagerly solicited.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Earthquake Monitoring Systems
</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:mab@riacs.ARPA">
mab@riacs.ARPA
</A>&gt;
</address>
<i>
7 Feb 1986 1502-PST (Friday)
</i><PRE>

I took the liberty of forwarding Gary Leaven's question on earthquake
monitoring systems (ie, are they designed to function during a major
earthquake?) to Mike Raugh, the author of the CACM article which
prompted the question.  Here's his reply:

             ---------------------------------

Matt,
	The question you forwarded to me is a good one: Are the
seismic instruments used in Calnet and the Southern California Array
built to withstand the shaking of a major earthquake?  The answer is
Yes and No, but it doesn't matter!  Even if a local subset of
instruments (or the telemetry system serving that subset) is
knocked out by a major quake, more distant instruments will pick up
signals from the quake that will be adequate for locating, timing and
calculating the earthquake "mechanism", i.e. direction of first motion,
plane of rupture, magnitude.  The purpose of the two arrays is to 
monitor earthquake activity throughout California, so you can see that
the entire combined two arrays will almost certainly not be totally 
incapacited by a major quake, hence they will continue to monitor 
activity (even distant activity) successfully.
	That being said, it should also be mentioned that seismologists
are very interested in the fine-grained signals that are obtainable
only at close range to a major earthquake (seismic waves that have
traveled teleseismic distance through the earth lose much of the higher
frequency energy).  Such close-in data from large earthquakes can only
be obtained from special "strong motion" instruments: this type of
instrument furnished the data for Archuleta's study of the Imperial
Valley quake discussed in my paper.  Strong motion instruments are much
more difficult to make, for all the obvious reasons, and are
expensive compared to the ones that comprise the two arrays mentioned
above.
	The problem of designing sophisticated modern microcomputer
based instruments that have sufficient sensitivity and dynamic range
and are robust in the presence of violent shaking is a big one.
Especially when you consider that such instruments must have local
storage and power supplies to back up data collection in the event of 
telemetry break-downs.   I can think of two groups at the USGS in Menlo 
Park that are working on systems of this kind.  The first is lead by Roger
Borchardt (his GEOS project was mentioned in my article).  Another is
being conducted by Larry Baker, Joe Fletcher, and Paul Spudich, who are
developing a down-hole three-dimensional mesh of instruments for
observation of the detailed progression of faulting expected to occur
in the officially USGS-predicted earthquake at Parkfield.  In other
words, new designs for such instruments are on the frontier of research
and development at the USGS.  Very likely other work of similar import
is taking place elsewhere.
	I hope this answers your question.
		Mike

</PRE>
<HR><H3><A NAME="subj3.2">
Earthquake Monitoring Systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:Murray.pa@Xerox.COM">
Murray.pa@Xerox.COM
</A>&gt;
</address>
<i>
Fri, 7 Feb 86 03:13:43 PST
</i><PRE>
To: RISKS FORUM (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;

Neither of these stories involves mainline computer risks, but they might
contribute some insight. 

I got this story from a friend doing earthquake research for the USGS. I
think it was '71 when a bigish quake near LA collapsed a VA hospital and a
half constructed bridge. That generated a lot of interest in the way
buildings (and bridges) react to quakes. Nobody really knew how much stress
is present on various structural parts of a building. In response, many
strain recording gizmos were installed in many large buildings.

Time passed, and everybody went back to their normal work. After several
years, another bigish quake came along, and somebody remembered all
those installed instruments. So they went out to collected them. Most of
them had died. I don't remember any numbers, but I was left with the
feeling that everybody was discouraged that they didn't get much
interesting data.

Another friend worked on LASA (Large Area Seismic Array?). It was one of the
early seismic arrays with hundreds of sensors scattered over eastern
Montana. I think it was primarily part of the bomb test detection program.
With that many sensors and that much wire and electronics to collect all the
data, a few sensors were always off the air. They discovered that they got
better data if they didn't tell the fixit crew that a test was coming.

</PRE>
<HR><H3><A NAME="subj3.3">
Re: RISKS-2.7: Earthquake monitoring systems
</A>
</H3>
<address>
Eugene Miya
&lt;<A HREF="mailto:eugene@AMES-NAS.ARPA ">
eugene@AMES-NAS.ARPA 
</A>&gt;
</address>
<i>
7 Feb 1986 0849-PST (Friday)
</i><PRE>

... I can tell you that earthquake instrumentation really need not survive 
a local earthquake.  Local measurement is very unreliable because of
environmental factors: soil type, underlying geologic structures, and so
forth &lt;the force in Mexico City's earthquake is a good example because it's
so far away from epicenter&gt;.  Meters over such areas go off the scale as a
matter of practice.  It's the more distant meters which can separate the
different waves which are important for triangulating location, magnitude,
etc.

--eugene miya,   NASA Ames Research Center,   eugene@ames-nas
  {decwrl,hao,ihnp4,hplabs}!ames!aurora!eugene

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-64</DOCNO>
<DOCOLDNO>IA012-000128-B044-145</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.9.html 128.240.150.127 19970217001700 text/html 9476
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:15:30 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 9</TITLE>
<LINK REL="Prev" HREF="/Risks/2.08.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.10.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 9</H1>
<H2> Sunday, 9 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computerized train wreck?  ... Computer-induced stock-market swings.    
</A>
<DD>
<A HREF="#subj1.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Selectively Displaying Data -- Boeing 767 EFIS 
</A>
<DD>
<A HREF="#subj2.1">
Alan M. Marcum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Cape Range Safety Display Systems 
</A>
<DD>
<A HREF="#subj3.1">
Lynne C Moore
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computerized train wreck?  ... Computer-induced stock-market swings.
</A>
</H3>
<address>
Martin Minow, DECtalk Engineering ML3-1/U47 223-9922
&lt;<A HREF="mailto:minow%serf.DEC@decwrl.DEC.COM  ">
minow%serf.DEC@decwrl.DEC.COM  
</A>&gt;
</address>
<i>
09-Feb-1986 2048
</i><PRE>

On the news recently, it was noted that the recent Canadian train wreck
[8 Feb 1986] "shouldn't have happened as the system was computer
controlled."

     [Bill Dewan, spokesman for the Canadian National Railroad, was 
      quoted in the SF Chron, 9 Feb 1986: "The [freight] train should not
      have left the double-track section, and whether its failure to stop
      was due to signal failure or human failure is what is under
      investigation."  Death toll initially estimated 30 to 50.  Eastbound
      transcontinental passenger train with up to 120 people aboard, 
      head-on with westbound freight on single-track section, 75 yards
      after freight left double-track section.  PGN]

                                ------

In today's Boston Globe (Sunday, Feb. 9, 1986), an article by Rick Gladstone, 
Associated Press discussed problems caused by "the growing effect of
computerized buying and selling programs that influence stock prices without
regard to economic fundamentals that historically have shaped the market."

These programs monitor stock prices and future prices for the same stock,
selling the stock and buying futures when the stock price exceeds the
futures price and buying stocks and selling futures when the stock price
falls below the futures price.  "The investors, therefore, profit no matter
what."  ... The recent big swings of the Dow Jones average "are partly
attributed by some Wall Street analysts" to these programs, "because they are 
activated at the same time and greatly increase the number of shares traded."

... Many analysts "agree that at least part of the Dow Jones industrial 
average's record 39.10-point plunge Jan. 8 was linked to a mass of
sell-program orders activated by the computers."

Martin Minow         minow%rex.dec@decwrl.arpa

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Selectively Displaying Data -- Boeing 767 EFIS
</A>
</H3>
<address>
Alan M. Marcum, Sun Consulting
&lt;<A HREF="mailto:sun!nescorna!marcum@ucbvax.berkeley.edu ">
sun!nescorna!marcum@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Fri, 7 Feb 86 16:17:06 PST
</i><PRE>
To: ucbvax!risks

In Risks V2.7, Jim Giles raises a question regarding selective display of
telemetry, with a computer helping control what is displayed.  This is
currently being done in the "Electronic Flight Instrument System" (EFIS)
being used on, for example, the Boeing 767.  The EFIS can be configured to
display various data on command by the flight crew, and to display "flags"
if certain things go outside the normal range.  This is by no means using
what we might consider full-blown expert systems technology.

For those unfamiliar with the 767 cockpit, or an EFIS in general, there are
various CRTs under computer control.  Usually, the tubes immediately in
front of the pilot and the co-pilot display the flight attitude (an enhanced
"artificial horizon"), often with airspeed, altitude, heading, and trends.
Additional tubes display route and various engine parameters.  These
additional tubes are those used for displaying abnormal information.

A couple of EFIS configurations are available for some of the larger general
aviation aircraft (for example, Beech's new Starship turboprop will be
delivered with and EFIS).  It is interesting in light of this digest to note
that in all EFIS configurations I've seen, there are ALWAYS conventional
(i.e. mechanical) backups for the critical instruments portrayed by the EFIS.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Cape Range Safety Display Systems
</A>
</H3>
<address>
"LYNNE C MOORE" 
&lt;<A HREF="mailto:moorel@eglin-vax">
moorel@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

Clive Dawson (in Risks 2.4) asked what kind of data display the Range Safety 
officer at Cape Canaveral uses to determine when to destroy missiles.

Data is collected from a wide variety of sources throughout the Eastern Test 
Range, including a number of radar and telemetry sites and optical trackers. 
The latter are especially important in the first few seconds of launch, when 
radars cannot be used due to multi-path problems associated with the large 
metal gantries. This data is collected by the Central real-time computers 
(redundant Cyber 740's), which determines the best and next-best estimates of 
present position and instantaneous impact point for the missile body. This is 
displayed by the Range Safety Display System (RSDS) computers along with plots 
of destruct lines, which indicate the limit of endangerment of a populated 
area if the missile's thrust were to terminate at that moment. These destruct 
limits are considerably broader on the Shuttle than they are for an unmanned 
missile. In addition, the RSO's maintain a voice link with the Shuttle Flight 
Dynamics Officer (in Houston), and they will not destroy the Shuttle as long 
as the crew is in control, even if the destruct line is violated.

The RSO's also have real-time telemetry displays and video plus a voice link 
to an observer as close to the launch pad as safety permits to assist at the 
initial moments of flight when the data is at its worst. 

This system provides the best chance for crew survival within the limits of 
range safety, assuming there is enough time in a danger situation for crew
response (which there wasn't in the Challenger explosion).

At the time that my husband, Martin Moore, was working on the destruct
software at the Cape, I was working on a radar data switching system which
is physically located in the same room as the RSDS system. I was also one of
the near-real-time analysts for the Central computer, involved in reducing
post-mission trajectory and orbital data. In the course of my duties, I
learned a lot about the RSDS system and the other data collection/display
systems at Cape Canaveral AFS (which is not quite the same thing as Kennedy
Space Center -- KSC is NASA, CCAFS is the Air Force).

Lynne C. Moore (moorel@eglin-vax.arpa)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-65</DOCNO>
<DOCOLDNO>IA012-000128-B044-164</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.10.html 128.240.150.127 19970217001714 text/html 11846
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:15:41 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 10</TITLE>
<LINK REL="Prev" HREF="/Risks/2.09.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.11.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 10</H1>
<H2> Wednesday, 12 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computerized aircraft collision avoidance 
</A>
<DD>
<A HREF="#subj1.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computerized Feedback and the Stock Market 
</A>
<DD>
<A HREF="#subj2.1">
Eric Nickell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Analyst Changes City Treasurer's Computer Code 
</A>
<DD>
<A HREF="#subj3.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Plutonium on the Space Shuttle 
</A>
<DD>
<A HREF="#subj4.1">
Tom Slone
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Request to RISKS Readers from COMPASS 86 (COMPuter ASSurance) 
</A>
<DD>
<A HREF="#subj5.1">
Al Friend
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computerized aircraft collision avoidance
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Wed 12 Feb 86 10:46:35-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

As noted on various previous occasions, it is always nice to report
computer-related successes in avoiding risks, but they seem to get scant
notice.  Perhaps some of you can keep your eyes open.

I had a phone report last night of a TV news item in Washington DC, relating
to a computerized aircraft collision-avoidance system that succeeded in
preventing what otherwise would have been a midair collision yesterday.  Can
anyone provide details?

Peter

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computerized Feedback and the Stock Market
</A>
</H3>
<address>
&lt;<A HREF="mailto:Nickell.pasa@Xerox.COM">
Nickell.pasa@Xerox.COM
</A>&gt;
</address>
<i>
Mon, 10 Feb 86 08:31:17 PST
</i><PRE>
To: RISKS FORUM (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;

Martin Minow's note about the effect that computerized stock traders can
have on the market brings up an interesting general situation.

Any self-correcting system which has a delay in the feedback loop (as
opposed to something like a spring, where the feedback is instantaneous)
can fail to correct itself if it is pushed too hard during a single
feedback period.  Further, if the forces acting on the system are
themselves made a function of the system, there is the possibility of
increasingly amplified oscillation until the system breaks down at some
point.

The stock market is a case in point.  Stock prices drift according to
the buying and selling of the stock.  But in the case Martin Minow
cites, I am guessing that the computers were able to deluge the system
with sell orders before the price could adjust itself.

The delay in price adjustment was not a problem until we had computers
capable of swamping it with orders.  Thus we may be introducing
computers into environments where slowness provides some degree of
stability to a process.  Speed itself has its dangers.

Eric Nickell	Nickell.pasa@Xerox.xcom

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Analyst Changes City Treasurer's Computer Code
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Mon, 10 Feb 86 10:14:01 est
</i><PRE>
Cc: mikemcl@nrl-csr

D.C. FINANCE ANALYST LOCKED OUT OF OFFICE, GIVEN NEW DUTIES
Deputy Mayor's Employe Changed Computer
by Peter Perl, Washington Post Staff Writer
&lt;excerpted from the Washington Post, Sunday, 9 February 1986&gt;
&lt;indicates a comment&gt;, (indicates a bridge or clarification)

A controversial D.C. government financial analyst who publicly accused his 
bosses of wrongdoing and recently changed a city treasurer's secret com-
puter code to deny them access to files has been locked out of his office 
and assigned other duties... 

... was removed from his job (7 Feb) because he changed the password to the 
treasurer's office computer and refused to tell his superiors the code.  

Frost confirmed yesterday that he had altered the computer code, saying he did
so to prevent documents from being destroyed or altered, which he said has 
happened before.  He charged that his transfer was a retaliation... for 
criticisms of District financial managers. ...

(Deputy Mayor) Hill, who is under investigation by a federal grand jury ... 
called Frost "a nerd and an imbecile."... "He was insubordinate and he had 
no right to change the master code," Hill said... 

Frost... manages &lt;managed?&gt; a $300 million cash investment portfolio, drew the
ire of his superiors last year with his charges of incompetence and possible 
fraud in the cash management system."

... Frost's testimony put his superiors in hot water after disclosure that 
they had used the computer system to backdate a key memorandum. ... 

Frost said he decided to change the secret manager's computer code because
he believed that another employe used to code to obtain a copy of (Frost's
letter accusing superiors of incompetence or corruption) written in the 
treasurer's computer system - and leak it to the Washington Times.

Williams realized (6 Mar) he could not get access to the manager's computer
account and asked Frost ... Frost acknowledged that he had, but refused to
restore the original code or tell Williams the new one... 

"(Frost) will be given a key to his new office," Hill said. "... He has a 
phone, a desk.  He can continue to work.  But he is not in there where the
computer is."

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Plutonium on the Space Shuttle
</A>
</H3>
<address>
415)486-5954]
&lt;<A HREF="mailto:michael%ucbiris@BERKELEY.EDU (Tom Slone [">
michael%ucbiris@BERKELEY.EDU (Tom Slone [
</A>&gt;
</address>
<i>
Tue, 11 Feb 86 09:49:49 pst
</i><PRE>

Recent Freedom Of Information Act (FOIA) information has revealed that NASA
officials considered the possibility of a Space Shuttle exploding to be so
remote that the dangers of carrying tens of pounds of Plutonium aboard was
not given much thought.  Plans are apparently still in the works to launch
these Plutonium driven space probes starting in May of this year.  The
manufacturer of these probes has claimed that the Plutonium element would
have survived the Challenger explosion as material of similar strength was
recovered from the debris.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Request to RISKS Readers from COMPASS 86 (COMPuter ASSurance)
</A>
</H3>
<address>
Al Friend
&lt;<A HREF="mailto:friend@nrl-csr ">
friend@nrl-csr 
</A>&gt;
</address>
<i>
Tue, 11 Feb 86 10:41:50 est
</i><PRE>

                            WE NEED YOUR HELP
                            -----------------

TO:    The readers of the RISKS FORUM
FROM:  Program Committee COMPASS 86

1.  We need an estimate of attendees and authors at a conference we are 
    planning.  Also, we need input in terms of ideas and events for it.

2.  The conference is COMPASS 86, which stands for COMPuter ASSurance.














    This conference is all about the things we are discussing in this forum. 
    The security and safety of processes rather than data banks, or 
    communication links.  We have in mind not only weapons and defense type 
    systems, but medical systems, tranportation systems, and the multitude of 
    computer controlled systems that touch our everyday lives.

    Dave Parnas will be the keynote speaker. 

    There will be a series of panel discussions, which will address everything
    from SDI to the application of AI.

    Papers will be reviewed by computer and software scientists working in the 
    areas of safety and security from the University of California, SRI,
    and the Naval Research Laboratory.

    The idea is to encourage new ideas, new applications of neglected ideas 
    and promote useful interactions.

3.  The conference specifics are:

    DATE:  7-11 July 1986
    PLACE:  The George Washington University, Wash., DC
    HONORARY CHAIRMAN (prospective):  Ruth Davis, former Assistant to 
                                      Deputy Undersecretary of Defense
                                      for Research and Advanced Technology
    GENERAL CHAIRMAN (prospective):   H.O. LUBBES, Space and Naval Warfare 
                                      Systems Command (lubbes@nrl-csr)
    SPONSOR:                          IEEE Washington Section

4.  It would help us if the readers of this forum could give us some feedback 
    on the number of people likely to attend and the number of people likely
    to submit papers.  Also, we would like to incorporate any special events
    that people would like to see into it.  The important dates are:

        March 31 --- Abstracts Due
        April 30 --- Authors Notified
        May 30   --- Camera Ready Manuscripts Due
        
    The call for papers is in the February issue of IEEE Computer.  Also, a 
    version of it ran a little while back in this forum.

          [I won't comment on the risks of running the first conference of
           its kind!  Good luck.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-66</DOCNO>
<DOCOLDNO>IA012-000128-B044-182</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.11.html 128.240.150.127 19970217001735 text/html 12299
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:16:04 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 11</TITLE>
<LINK REL="Prev" HREF="/Risks/2.10.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.12.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 11</H1>
<H2> Sunday, 16 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
SF Federal Reserve Bank 2 Billion Dollar Goof 
</A>
<DD>
<A HREF="#subj1.1">
SF Chron via Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Washington D.C. Analyst's Password Game 
</A>
<DD>
<A HREF="#subj2.1">
AP via Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Boeing 767 EFIS -- compare Airbus A320 
</A>
<DD>
<A HREF="#subj3.1">
Rob Warnock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Networks Pose New Threats to Data Security                                
</A>
<DD>
<A HREF="#subj4.1">
InfoWorld-86/2/10 via Werner Uhrig
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
SF Federal Reserve Bank 2 Billion Dollar Goof
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Sun 16 Feb 86 20:04:54-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

The SF Chronicle (7 Feb 86) had an article on what was "perhaps the biggest
banking blunder ever" (despite the Bank of New York just having had a $32
billion screw-up, reported in <A HREF="/Risks/1.31.html">RISKS-1.31</A>).  On 21 January 1986, the Fed was
testing its computers and accidentally transferred $2B to 19 financial
institutions.  A weekend test session had been constructed using 1000 actual
transactions from the previous Friday.  The test program and data were
accidentally left around, and thus the transactions were repeated on Monday
morning.  As opposed to the $32B case, all of the money was recovered, and
no actual losses were incurred.  A spokesman "stressed, however, that $2
billion represents only 2 percent of the funds handled by the Fed each day."
(... peanuts ... chicken-feed ...?)  In the future, testing will be done with
make-believe transactions and fictitious account numbers.  Six employees
deemed responsible were suspended without pay for three days.
  
   [Thanks to W. Randolph Franklin &lt;wrf@degas.berkeley.edu&gt; for reminding 
    me of that one.  I had meant to include it earlier.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Washington D.C. Analyst's Password Game [more on <A HREF="/Risks/2.10.html">RISKS-2.10</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
15 Feb 1986 05:39-PST
</i><PRE>
From: the tty of Geoffrey S. Goodfellow &lt;Geoff@SRI-CSL.ARPA&gt;
To: risks@SRI-CSL.ARPA
	
a010  2248  14 Feb 86
PM-Password, Bjt,0580
Disgruntled Computer Analyst Asks D.C. Children To Solve Money Mystery
By DIANE DUSTON
Associated Press Writer
    WASHINGTON (AP) - A disgruntled former District of Columbia employee
who hid the code word to computerized city accounts is inviting
children to try to find the password by playing a game he is placing
in a newspaper.
    Alvin C. Frost, an accountant for the city, said Friday he would
have clues published in The Washington Post this Sunday to a code
word he used to hide accounts in the city's computer system.
    The game is the latest twist in an ongoing dispute between the
district and Frost, who hid the accounts because of what he says are
mismanagement and improprieties in the city's finance office. He has
not accused officials of criminal wrongdoing.
    Frost, who worked for the city's office of financial management 3 1/2
years, resigned Friday.
    The accountant is asking children 12 years old and under to guess
the password based on the clues and win a tour of the monuments,
White House, Capitol, and Supreme Court and lunch in a downtown restaurant.
    ''Kids like to be involved in what is going on in the news,'' Frost said.
''Maybe this little game will get people involved in what's going on.''
    Though city officials say computer experts helped them crack the
code and regain access to the hidden accounts, Frost said he doesn't
think they know the password he used.
    ''Right now, they don't know. They don't know what's in the
computer,'' said Frost, who says he designed the computer program
used to manage the city's cash.
    Frost said there may be a ''tapeworm,'' or malfunction, in the
city's computer that could consume files if the word is not discovered.
    ''I planted the seed (to such a malfunction). Whether it actually
exists, they'll have to find out,'' said Frost.
    He was stripped of all his responsibilities after he devised the new
code word and refused to tell his superiors.
    He said he was resigning effective March 15, ''for historical and
literary reasons,'' a reference, he said, to the Ides of March, when
Julius Caesar was assassinated by a group of trusted friends.
    ''I've done my job,'' said Frost. ''Now it is time for the people to
get involved.''
    Frost gave reporters a chance to figure out the password by offering
these clues:
    -It has seven characters.
    -It has two syllables.
    -It's a real word.
    -All the characters are letters.
    -The word is not in the Declaration of Independence.
    -But the first syllable is used four times in the Declaration.
    -And, it is what the Declaration really means.
    At the news conference, a reporter guessed ''freedom,'' but Frost
wouldn't confirm it as the password.
    Officials did not return phone calls seeking comment Friday after
Frost announced he would resign.
    He said that last October he was questioned by the FBI and IRS about
operations in the office. He said the IRS was ''looking to trace the
trail of possible payoffs,'' but he would give no further details.
    Frost changed the password to some computer accounts after someone
entered the system and made copies of a letter he had written to
Mayor Marion Barry Jr. with his complaints.
    He was stripped of his responsibilities, though not fired, when he
refused to tell his superiors the code word.
    
AP-NY-02-15-86 0147EST

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Boeing 767 EFIS -- compare Airbus A320
</A>
</H3>
<address>
Rob Warnock
&lt;<A HREF="mailto:sun!redwood.uucp!rpw3@ucbvax.berkeley.edu ">
sun!redwood.uucp!rpw3@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Fri, 14 Feb 86 02:53:46 PST
</i><PRE>

Alan Marcum &lt;marcum@sun.uucp&gt; writes:
+---------------
| ...currently being done in the "Electronic Flight Instrument System" (EFIS)
| being used on, for example, the Boeing 767.  The EFIS can be configured to
| display various data on command by the flight crew, and to display "flags"...
|                        ... It is interesting in light of this digest to note
| that in all EFIS configurations I've seen, there are ALWAYS conventional
| (i.e. mechanical) backups for the critical instruments portrayed by the EFIS.
+---------------

Well... see pages 14-17 of the special supplement on Keyboards &amp; Switches
in Electronic News, Monday, February 10. These four pages have a special
on the new style cockpit showing up on recent planes, and has a very nice
color picture of the A320 cockpit. The Airbus A320 has no conventional yoke
to fly the plane with -- each pilot has only a small "side stick", much like
the shuttle pilots. Quote: "The side sticks are used to apply the input order
such as azimuth and climb angle while the on-board computers take complete
responsibility for applying the correct amount of power and for leveling off
the aircraft at the desired altitude. An A320 aircraft cannot be commanded
to go into an overspeed, overload, or stall condition..."

I commend the entire article to the readership of this list, since it has
other little goodies in it, like: "When operation is normal, the flight
deck is a dark and restful place. When an event happens that needs a pilot's
attention, lights go on, displays change color. Formerly, when this happened,
pilots had to make decision, throw switches. They had to really take charge.
Now, although there are noticeably fewer switches for the pilot to get involved
with, the switching still goes on behind the scenes, as systems and circuits
test themselves and make decisions that call for no human intervention...
And the over-riding benefit is the avoidance of human error."

I'm sure the decrease in display density helps an awful lot. But what happens
when a pilot is trying to analyze a critical display and it changes on him/her
because the system thought a new display was more important? Maybe the system
was right. We'll see...

Oh yes, they saved enough money on switches and instruments to go from
doubly-redundant to triply-redundant computers. That's nice... ;-}

p.s. Not knocking it, you know, just noting that pure fly-by-wire is
already here, including ordering the plane "to navigate to a selected
airport and make an unassisted landing."


Rob Warnock
Systems Architecture Consultant

UUCP:	{{ihnp4,hplabs,dual}!fortune,sun,ism780c}!redwood!rpw3
DDD:	(415)572-2607
USPS:	627 26th Ave, San Mateo, CA  94403

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Networks Pose New Threats to Data Security  [InfoWorld-86/2/10]
</A>
</H3>
<address>
Werner Uhrig  
&lt;<A HREF="mailto:CMP.WERNER@R20.UTEXAS.EDU">
CMP.WERNER@R20.UTEXAS.EDU
</A>&gt;
</address>
<i>
Thu 13 Feb 86 04:32:42-CST
</i><PRE>
To: risks@R20.UTEXAS.EDU

  "As local area networks become more commonplace in the corporate computing
  environment, the possibility of prying eyes gaining access to your data is
  significantly increased.  And the spy is likely to be someone who knows you
  well."

[ nothing earth-shaking or new, just interesting to see what issues the
"popular press" pulled into the spotlight. ]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-67</DOCNO>
<DOCOLDNO>IA012-000128-B044-203</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.12.html 128.240.150.127 19970217001752 text/html 13297
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:16:16 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 12</TITLE>
<LINK REL="Prev" HREF="/Risks/2.11.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.13.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 12</H1>
<H2> Tuesday, 18 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks in automobile microprocessors -- Mercedes 500SE 
</A>
<DD>
<A HREF="#subj1.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Train safeguards defeated 
</A>
<DD>
<A HREF="#subj2.1">
Chuck Weinstock
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Security Safeguards for Air Force Computer Systems 
</A>
<DD>
<A HREF="#subj3.1">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  How can Alvin Frost fight City Hall? 
</A>
<DD>
<A HREF="#subj4.1">
Jim DeLaHunt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  More Plutonium/Shuttle 
</A>
<DD>
<A HREF="#subj5.1">
Martin J. Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Computerized Voting -- talk by Eva Waskell 
</A>
<DD>
<A HREF="#subj6.1">
Wednesday eve
</A><br>
<A HREF="#subj6.2">
 19 February
</A><br>
<A HREF="#subj6.3">
 MIT
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks in automobile microprocessors -- Mercedes 500SE
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Tue 18 Feb 86 20:28:05-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

We have had the El Dorado brake microprocessor recall, the Mark VII
computerized air suspension recall, and the on-going CB interference problem
in automotive microprocessors.  For the record, let me add the current
manslaughter trial of John C. (Sandy) Walker, who was driving when his 1982
Mercedes 500SE went into an uncontrollable skid.  He escaped, but his
passenger was killed in the resulting flames.  An "accident reconstruction
specialist", Paul O'Shea (also a consulting engineer for Mercedes and NASA,
and winner of three championship races), testified that the state-of-the-art
anti-skid braking system malfunctioned.  When working properly, it is
designed to slow the vehicle gracefully, and "will leave no skid marks, no
matter how hard you step on the brakes."  The longest skid marks from the
accident on 9 June 1984 on the Silverado Trail in the Napa Valley were
measured at 368 feet!  One line of investigation is that mechanical defects
might have caused a fire in the engine compartment, resulting in the
malfunction of the brake computer.  O'Shea noted that the emission-control
system had been fitted with rubber hoses where metal hoses should have been,
and which were placed too close to a heat-producing exhaust header. 
    [SF Chronicle 5 Feb 86]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Train safeguards defeated
</A>
</H3>
<address>
&lt;<A HREF="mailto:Chuck.Weinstock@a.sei.cmu.edu">
Chuck.Weinstock@a.sei.cmu.edu
</A>&gt;
</address>
<i>
Tuesday, 18 February 1986 15:49:12 EST
</i><PRE>

You will recall the recent head-on collision between a Via passenger train
and a freight in Canada [Risks-2.9].  A recent series of relevant messages
on the railroad discussion list follows.  For background, note that the
Burlington Northern Railroad has had a significant number of "cornfield
meets" (railroad slang for train collisions) in the past few years.  Many
were later blamed on alcohol and drugs being used by the crew.  (It has
gotten so bad that when the BN notified the community that it would
transport no steam locomotives over it's most reasonable route to Vancouver
for the Expo there, many railfans breathed a sigh of relief...they wouldn't
want to trust something as precious as a steam locomotive to a railroad with
a history of collisions.)

Chuck
- - - - Begin forwarded message - - - - [...]
From: FarleighSE &lt;sef@drutx.uucp.arpa&gt;
Subject: Re: VIA rail train collides head-on with freight.
Date: 13 Feb 86 23:16:16 GMT
To: railroad@rochester.arpa

&gt;Engines have "dead-man" controls.  I know that the E- and F-unit diesels
&gt;had foot pedals that the engineer had to keep depressed continuously.
&gt;If the engineer let up on the pedal, emergency brakes would be applied.
&gt;I'm not sure the pedal system is in use today, but some variation is.
&gt;On GO Transit in your neck of the woods, for example, the engineer has
&gt;to be in contact with some part of the controls regularly (the throttle
&gt;or brake lever, for example).  If he/she hasn't touched the controls
&gt;for 30 seconds, an alarm buzzes in the cab, telling him/her to touch the
&gt;controls at least briefly to confirm that he/she is still alive.  If
&gt;no contact is made, on go the brakes!
&gt;
&gt;Carl Blesch

Burlington Northern removed their Deadman controls a number of years ago.
It seems that the Engineers were overriding the system (putting a brick on
the pedal?).  So the management of BN (means Better'n Nothin') decided to
remove the Deadmans throttle altogether.  About two years ago one of the
many BN wrecks could have been avoided if the Deadman's throttle was
installed and used.  It seems that instead of BN's management addressing the
problem of their many times stoned crew defeating the saftey device they
opted to remove the safety device.

Scott E. Farleigh
AT&amp;TIS

- - - - End forwarded message - - - -

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Security Safeguards for Air Force Computer Systems
</A>
</H3>
<address>
Dave Platt 
&lt;<A HREF="mailto:Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA">
Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Tue, 18 Feb 86 12:31 PST
</i><PRE>

From the Los Angeles Times, 2/17/86:

"WASHINGTON (UPI) - The Air Force has failed to properly safeguard 77% of
its computer systems, allowing the possible breach of classified data on
space boosters, 'Star Wars' technology and major weapons systems, Pentagon
auditors and officials say.
   The security vulnerability also extends to sensitive data on the MX and
Midgetman missiles and B-1 and F-16 aircraft, they say.
   An Air Force official, responding to queries about the disclosure,
said that he was '95% confident' that no 'actual compromises' of classified
information on computers had actually occurred.
   The Air Force Audit Agency, which inspected eight bases, sharply
criticized officers at each facility for failure to inspect safeguards,
such as lead boxes designed to limit electromagnetic signals emitted
by the equipment..."

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
How can Alvin Frost fight City Hall?
</A>
</H3>
<address>
Jim DeLaHunt 
&lt;<A HREF="mailto:JDLH@SU-SUSHI.ARPA">
JDLH@SU-SUSHI.ARPA
</A>&gt;
</address>
<i>
Mon 17 Feb 86 18:22:01-PST
</i><PRE>
To: risks@SRI-CSL.ARPA

I am intrigued by the apparent success of analyst Alvin Frost's attempt to 
keep the city of Washington, DC out of their own computer.  With one 7-
character password (and apparently physical access to the machine) he seems
to be able to keep certain files out of the reach of his superiors.  Does 
anybody know:
	* What machine, OS, etc. this is?
	* Whether his superiors have in fact cracked his protection?
	* What sort of data protection systems are immune to a legitimate 
	  systems manager logging on as root (or OPERATOR or whatever)?
	* What is actually going on here?

Send responses to me; I will be glad to summarise to the net.
	--Jim DeLaHunt, Stanford University 	JDLH @ SU-Sushi.ARPA

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
More Plutonium/Shuttle
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

The 2/17/86 issue of Aviation Week contains an article entitled "Officials 
Disagree on Data Assessing Shuttle Reliability."  The main topic of the 
article is the danger of plutonium contamination from nuclear shuttle 
payloads in case of an accident (I seem to have heard about this somewhere 
before :-).  I recommend the article to the RISKS readership.  One quote from
Robert K. Weatherwax, author of a study titled "Review of Shuttle/Centaur 
Failure Probability Estimates for Space Nuclear Mission Applications" 
[December 1983] seems to answer the questions we were throwing around:

   We concluded that many, if not most, solid rocket motor failures would
   result in some release of plutonium, or at least a high likelihood of 
   that.  We recommended more safety analyses be done to evaluate the 
   likelihood of booster failures in conjunction with this nuclear risk.
   A nuclear payload cannot explode, but it can be broken up, vaporzied or 
   fragmented.  You would have prompt fatalities on the ground and substantial
   contamination in eastern Florida [if a catastrophic launch failure 
   occurred.]  In a worst possible case, you could double the entire worldwide
   burden of plutonium in the atmosphere.

Weatherwax is head of Sierra Energy and Risk Assessment, located in 
Sacramento.  Sierra was contracted by the Air Force to perform the study.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 [BERLIN: Computerized Voting]
</A>
</H3>
<address>
"Steven A. Swernofsky" 
&lt;<A HREF="mailto:SASW@MC.LCS.MIT.EDU">
SASW@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 18 Feb 86 23:06:33 EST
</i><PRE>
To: RISKS@MC.LCS.MIT.EDU

...
Date: Tue 18 Feb 86 13:51:03-EST
From: Steve Berlin &lt;BERLIN@XX.LCS.MIT.EDU&gt;
Subject: Computerized Voting
To: bboard@XX.LCS.MIT.EDU

                   Wednesday, February 19, 1986, 7:30

                             Ms. Eva Waskell

          Independent Investigative Reporter and Science Writer

      ``Computerized Voting: No Standards and a Lot of Questions''

Ms. Waskell will address problems involved with computerized voting
programs.  She will relate the status of litigation in several jurisdictions
and will suggest safeguards in the voting system.

Ms. Waskell's research provided a basis for several New York Times articles
exposing problems with the most popular computerized balloting system in use.


CPSR/Boston meets on the third Wednesday of each month, at 545 Technology
Square, in the lounge on the 8th floor.  545 Tech Square is located at
the corner of Main and Vassar Streets in Cambridge, near the Kendall
Square stop on the red line.  Meetings are free and open to the public,
and free parking is available.

For more information, contact CPSR/Boston at P.O. Box 962, Cambridge, MA,
02142, or call Steve Berlin at 617-253-6018.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-68</DOCNO>
<DOCOLDNO>IA012-000128-B044-227</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.13.html 128.240.150.127 19970217001805 text/html 14114
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:16:35 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 13</TITLE>
<LINK REL="Prev" HREF="/Risks/2.12.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.14.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 13</H1>
<H2> Thursday, 20 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Dec. 8 cruise missile failure caused by procedural problems 
</A>
<DD>
<A HREF="#subj1.1">
Martin J. Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computerized voting 
</A>
<DD>
<A HREF="#subj2.1">
Matt Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Non-science quotations on Plutonium 
</A>
<DD>
<A HREF="#subj3.1">
Bob Ayers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Software Piracy 
</A>
<DD>
<A HREF="#subj4.1">
D.Reuben
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Air Force Security Safeguards 
</A>
<DD>
<A HREF="#subj5.1">
Stephen Wolff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Shuttle Safety 
</A>
<DD>
<A HREF="#subj6.1">
NYTimes News Summary
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Dec. 8 cruise missile failure caused by procedural problems
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

Last December 8, a Tomahawk cruise missile was launched from a submarine in 
the Gulf of Mexico.  It was intended to fly around southern Alabama and the 
Florida panhandle and then crash onto the Eglin AFB reservation; however,
about 9 minutes into the flight the missile made a sudden right turn and
crashed outside the reservation near the small town of Freeport (the 
residents of Freeport were less than amused.)  No explanation for the failure
was given until an article in the 2/20 issue of the "Playground Daily News"
[Fort Walton Beach, Florida].  The article says in part:

   Human error caused a malfunction that led to the errant flight and 
   subsequent grounding near Freeport of an unarmed cruise missile on
   a test flight two months ago...Newly released information shows that a
   "procedural problem" involving the missile's computer guidance system
   caused the malfunction [according to a Navy spokesman]...He said the
   middle portion of a launch-fly-recovery program guidng the sophisticated
   missile was erased when the launch crew loaded the information into the
   missile's memory banks too quickly.  As a result, the missile went from
   the launch mode straight to the recovery mode "without going through the
   most important part of the mission"..."That's what caused it to make the
   unscheduled turn," he said.  "It was not the missile's fault.  It did
   exactly what it was supposed to do."..."It was not a mistake.  In reviewing
   the procedures we can see how it happened.  Since then, new directions and
   new procedures have been instituted."

Old saying:     If all else fails, follow the instructions.
New corollary:  If you follow the instructions, you can't make a mistake.
                (or, "I was only following orders, Your Honor.")

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computerized voting
</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:mab@riacs.ARPA">
mab@riacs.ARPA
</A>&gt;
</address>
<i>
19 Feb 1986 0804-PST (Wednesday)
</i><PRE>

   Unfortunately, I'm not in Massachusetts, so I won't be going to Ms.
Waskell's lecture on computerized voting.  But ever since I heard about
the electronic tally board in some legislative house (I think the U.S.
House of Representatives), I've been interested in the safeguards.
The method used involved the legislators pushing one of two buttons at
their desk (one for "yea", the other for "nay").  Well, it seems that
some legislators pushed buttons for colleagues who were absent and who
did not know how they were "voting"!

   Now, this story may be apocryphal (since I don't remember the
source, you might as well take it with a grain of salt) but it does
bring up a point I've not heard addressed.  If you use an electronic
"ballot puncher" (as opposed to manually punching the cards then
counting them electronically) how can you ensure the ballot is punched
correctly?

   So, my questions to this group:  Anybody know if all electronic
voting schemes used at election time require manually punched ballots?
If not, what tests are the electronic "ballot punchers" subjected to 
in order to test their reliability?  (I gather there can be no precautions
against someone voting for someone else other than careful checks at
the precinct, by the precinct workers.  Opposing comments welcome!)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Non-science quotations on Plutonium (Risks 2.12)
</A>
</H3>
<address>
Ayers.PA@Xerox.COM 
&lt;<A HREF="mailto:Bob Ayers">
Bob Ayers
</A>&gt;
</address>
<i>
19 Feb 86 11:00:20 PST (Wednesday)
</i><PRE>
To: RISKS@SRI-CSL.ARPA

From Risks 2.12:
    "In a worst possible case, you could double the entire worldwide
     burden of plutonium in the atmosphere."
        Robert K. Weatherwax, head of Sierra Energy and Risk Assessment
	 
I find this quotation silly and non-science. Here are two meanings for
his sentence:

  1. The accident could double the instantaneous weight of Pu in 
     the atmosphere.
       
       So what? Weatherwax supplies no figure for the current atmosphereic
       Pu burden, and no figure for that burden's harm or risk.
       Anyone know what the current level of Pu is? If its one femtogram, or
       even one milligram, who cares what "doubling" it does?
       
  2. The accident could double the amount of Pu that has been added to
     the atmosphere by man.
       
       That's probably what Weatherwax wants you to read into his sentence.
       And its clearly silly, because when an above-ground Pu atom bomb goes
       off, MOST of the 10-20 kilogram critical mass of Pu goes into the
       atmosphere. Considering the number of above-ground bombs tested, this
       would mean that the "accident" involved at least a tonne of Pu!

Look at the loaded words: "double" "entire" "worldwide".  Would his sentence
have changed meaning if he had simply left out the words "entire worldwide"?
No, but it wouldn't have sounded like a drum-roll was being played in the
background.  This isn't science, guys, this is politics -- or silliness.

           [If we horse around a little, we might get to Whinny the Pu.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Software Piracy
</A>
</H3>
<address>
 D.Reuben  
&lt;<A HREF="mailto:S.D-REUBEN@KLA.WESLYN">
S.D-REUBEN@KLA.WESLYN
</A>&gt;
</address>
<i>
Thu 20 Feb 86 16:34:11-EST
</i><PRE>
To:  Risks@SRI-CSL.Arpa

   In Risks-2.11, I noticed that it was suggested that one way that software
manufacturers combated software piracy was by providing various "extras"
with their software packages which supposedly enhance the value of the
product. To an extent, this is true, and I will grant that those who are
really interested in a said game (business software is another matter) will
purchase it rather than copy it because of the extras and the value that
they provide during the playing of the game. However, I submit that the vast
majority of computer users are only casually interested in a certain "new
game", and because of this will not be too deterred by the lack of colorful
maps or cute little clues which are provided with the game. These can easily
be described or listed in a small and easily written text file, and
distributed all over the US and Canada with the actual "cracked" game that
is being pirated. Thus, these objects included with the software are only a
deterrent for the interested player, who probably buys most of his software
anyhow. Software companies do not loose money due to these people, rather,
it is the software trader who seeks to get new software at a regular rate
(which with a modem is exceptionally easy to do) who is the main threat to
software company profits, and large cloth maps and parchment instructions
thrown in to the software package are of little interest to some one who can
easily get the complete instructions and contents of the "extras" all typed
up in a neat little text file. This also goes for games like "Captain
Goodnight", which sought to deter piracy by having a set of codes, which if
not used properly in various sections of the game, would cause the program
disk to reboot (Apple version). However, it was just as easy to type up the
chart that the software manufacturer provided and include it with the
program on the same disk. Versions have even been circulated where the
section of the program that asks for your 'ID code' is taken out, and the
game proceeded as if the user had typed in the right code.

   One further thing - Another notable software manufacturer which is reputed
for their software protection policy is Beagle Brothers, who provide valuable
utilities and some games for the Apple which are unprotected and at a
much more modest cost then most of its competition.

D.Reuben                      Reuben@Weslyn.Bitnet (or Reuben@Weslyn.Arpa)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Air Force Security Safeguards (<A HREF="/Risks/2.12.html">RISKS-2.12</A>)
</A>
</H3>
<address>
    Stephen Wolff 
&lt;<A HREF="mailto:steve@BRL.ARPA">
steve@BRL.ARPA
</A>&gt;
</address>
<i>
Wed, 19 Feb 86 4:10:21 EST
</i><PRE>

&gt;   Subject: Security Safeguards for Air Force Computer Systems
&gt;   "WASHINGTON (UPI) - . . . .
&gt;   
&gt;      The Air Force Audit Agency, which inspected eight bases, sharply
&gt;   criticized officers at each facility for failure to inspect safeguards,
&gt;   such as lead boxes designed to limit electromagnetic signals emitted
&gt;   by the equipment..."

Bet the spells to ward off evil spirits weren't current, either.

                     [If you think that Steve's remark is off the 
                      mark for the RISKS Forum, you could be wrong.  
                      But no spirited follow-ups, please.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Shuttle Safety
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Thu 20 Feb 86 16:51:02-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

EXCERPTED FROM THE BBOARDS: 
c.1986 N.Y. Times News Service: news summary for Thursday, February 20, 1986
    
    Washington - NASA's technical experts reviewed the shuttles' booster
rocket sealing problems last August without considering the impact of
cold weather on the seals or giving much attention to the possibility
that launchings should be delayed while the seals were strengthened,
according to a key participant in the top-level review and recently
released documents. The participant, William H. Hamby, deputy director
of shuttle program integration, described in an interview a history of
rising concern over the rocket seals.
    
    New York - Shuttle safety margins were cut to adhere to an
accelerating launching schedule, according to space agency documents
made public by the chairman of a House panel. The chairman, Rep. Edward
J. Markey, D-Mass., said the actions, coupled with the explosion of the
Challenger, raised basic questions about the safety of the shuttle
design and precautions by the space agency.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-69</DOCNO>
<DOCOLDNO>IA012-000128-B044-247</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.14.html 128.240.150.127 19970217001820 text/html 10051
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:16:46 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 14</TITLE>
<LINK REL="Prev" HREF="/Risks/2.13.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.15.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 14</H1>
<H2> Monday, 24 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Automotive Problems Intensify 
</A>
<DD>
<A HREF="#subj1.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A hard rain is gonna fall (around March 23) 
</A>
<DD>
<A HREF="#subj2.1">
Martin J. Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Misdirected modems 
</A>
<DD>
<A HREF="#subj3.1">
Alan Silverstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Witch hunts, or Where does the buck stop? 
</A>
<DD>
<A HREF="#subj4.1">
M.L. Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Spells and Spirits 
</A>
<DD>
<A HREF="#subj5.1">
Steve Berlin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Automotive Problems Intensify
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Mon 24 Feb 86 11:20:54-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

The National Highway Trafic Safety Administration has expanded its
investigation into the sudden acceleration of automobiles to include
vehicles made by six manufacturers.  The expanded inquiry involves 1.4
milion mid-size and full-size cars made by Ford Motor Co (1984-85
model years), 100,000 Audit model 5000 cars (1984-85), 350,000 280Z and
380Z Nissan cars (1980-85), 400,000 Alliance and Encore cars made for
American Motors-Renault (1983-85), and 140,000 Toyota Cressida luxury
cars (1981-84).  [See today's NY Times, SF Chron, etc.]  

We have reported here previously on effects of radio-frequency interference
on automobile microprocessors (e.g., RISK-1.23 and 24).  This sounds like
lots more of the same.  Is the same chip-set involved, or is this a new
kind of common-mode fault across different chip manufacturers?

Peter

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
A hard rain is gonna fall (around March 23) 
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

According to "Das Bild", a West German newspaper, a Soviet spy satellite has
lost its steering capability and will impact between March 21 and March 25.
Cosmos 1714, launched December 28, is presumably powered by an atomic power
plant.  The Soviets have not (as far as I know) commented on this yet.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
misdirected modems
</A>
</H3>
<address>

&lt;<A HREF="mailto:hp-sdd!hpfcla!ajs@nosc.ARPA">
hp-sdd!hpfcla!ajs@nosc.ARPA
</A>&gt;
</address>
<i>
Mon, 24 Feb 86 11:12:54 pst
</i><PRE>

Twice recently, computers at our company (Hewlett-Packard) have been the
embarrassing causes of telephonic annoyance.  Phone numbers entered
incorrectly in uucp L.sys files, due to typos or misunderstandings, have
led to systems repeatedly calling private telephones in Fort Collins.
The recipients of such calls, understandably annoyed, have had to
backtrack through Mountain Bell to discover the cause.

I bet this happens a lot more than anyone realizes or admits.

Alan Silverstein, Hewlett-Packard Fort Collins Systems Division, Colorado
{ihnp4 | hplabs}!hpfcla!ajs, 303-226-3800 x3053, N 40 31'31" W 105 00'43"

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Witch hunts, or Where does the buck stop?
</A>
</H3>
<address>
&lt;<A HREF="mailto:mlbrown@nswc-wo.ARPA">
mlbrown@nswc-wo.ARPA
</A>&gt;
</address>
<i>
Fri, 21 Feb 86 08:38:21 est
</i><PRE>

I note with interest that we have yet to hear from anyone who performed
system safety analyses on the solid rocket booster system.  Where are
the system safety engineers who analyzed this design?

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Spells and Spirits
</A>
</H3>
<address>
Steve Berlin 
&lt;<A HREF="mailto:BERLIN@XX.LCS.MIT.EDU">
BERLIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Fri 21 Feb 86 11:31:55-EST
</i><PRE>
To: risks@SRI-CSL.ARPA

The comment about spells and spirits in the RISKS 2.13 reminded me of a set
of papers from Princeton that readers of this forum might be interested in.

First, the references:

  "The Persistent Paradox of Psychic Phenomena: An Engineering Perspective"
	Robert G. Jahn, Proceedings of the IEEE, Vol 70, No. 2, Feb. 1982

  "Princeton Engineering Anomalies Research"
	R.G. Jahn, B.J. Dunne, and R.D. Nelson, technical note PEAR 84002

  "An REG Experiment with Large Data Base Capability, III: Operator
	Related Anamolies"
	R.D. Nelson, B.J. Dunne, R.G. Jahn, technical note PEAR 84003

All three papers describe experiments in which humans attempt to influence
the distribution of random events using 'psychic' means. According to the
authors, the results indicate that there ARE deviations that range in
likelihood from 10^-4 to 10^-7.  I will not attempt to summarize any
further, interested readers should contact the authors directly at:

	Princeton Engineering Anomalies Research
	School of Engineering/ Applied Science
	Princeton University
	Princeton, NJ  08544

I would like to type in the abstracts, however, the latter two papers
explicitly "withhold the right to reprint or quotation".

The abstract for the IEEE paper follows:

Although a variety of so-called psychic phenomena have attracted man's
attention throughout recorded history, organized scholarly effort to
comprehed such effects is just one century old, and systematic academic
research roughly half that age.  Over recent years, a sizeable spectrum of
evidence has been brought forth from reputable laboratories in several
disciplines to suggest that at times himan consciousness can acquire
information inaccessible by any known physical mechanism (ESP), and can
influence the behavior of physical systems or processes (PK), but even the
most rigorous and sophisticated of these studies display a characteristic
dilemma: The experimental results are rarely replicable in the strict
scientific sense, but the anomalous yields are well beyond chance
expectations and a number of common features thread through the broad range
of reported effects.  Various attempts at theoretical modeling have so far
shown little functional value in explicating experimental results, but have
served to stimulate fundamental re-examination of the role of consciousness
in the determination of physical reality.  Further careful study of this
formidable field seems justified, but only within the context of very well
conceived and technically impeccable experiments of large data-base
capability, with disciplined attention to the pertinent aesthetic factors,
and with more constructive involvement of the critical community.

Disclaimer:  I don't currently hold an opinion on the validity of the 
experiments described in these papers.  I do, however, agree that there
are phenomena which 'modern science' has no satisfactory explanation.

						-- Steve

    [I don't expect that RISKS will go lurching off in this direction.
     But, nevertheless, there is certainly a wide collection of issues
     related to risks to the public in the use of computer systems.
     An intriguing bit of science fiction along that line is the old novel
     by Ingo Swann, Star Fires.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-70</DOCNO>
<DOCOLDNO>IA012-000128-B044-271</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.15.html 128.240.150.127 19970217001836 text/html 13591
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:17:04 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 15</TITLE>
<LINK REL="Prev" HREF="/Risks/2.14.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.16.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 15</H1>
<H2> Tuesday, 25 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Software Safety Survey 
</A>
<DD>
<A HREF="#subj1.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Titanic Effect 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  F-18 spin accident 
</A>
<DD>
<A HREF="#subj3.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Space shuttle problems 
</A>
<DD>
<A HREF="#subj4.1">
Brad Davis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Misdirected modems 
</A>
<DD>
<A HREF="#subj5.1">
Matt Bishop
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Software Safety Survey
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@ICSD.UCI.EDU">
nancy@ICSD.UCI.EDU
</A>&gt;
</address>
<i>
22 Feb 86 12:20:49 PST (Sat)
</i><PRE>

I have been interested in safety for the past five years and have just
completed a long-term project to write a survey of software safety.  It
includes sections on whether there is a problem (probably not of doubt to
those who already read RISKS), why there is a problem, the implications for
software engineering research, the relationship of software safety to
software reliability and security research, a definition of software safety,
a brief survey of relevant aspects of system safety, and a description of
software safety techniques and research issues (requirements analysis,
verification and validation of safety, assessment, software design, and
human factors).  Although good software engineering techniques will
undoubtedly add to the safety of software, this is not a software
engineering survey -- emphasis is on needed additions and changes to current
software engineering techniques and research and on new procedures which
have special relevance to safety.  It is also a technical rather than a
political document (although a few ethical and political issues are
mentioned in the conclusions).

The paper is currently in the form of a technical report although it has
been submitted to Computing Surveys (chosen primarily because of the size of
the document -- about 60 pages).  I will be glad to send out a reasonable
number of copies in exchange for any comments which might help me to improve
it.  Comments on what you like and think is correct or helpful would be nice
along with the complaints.  If you would like a copy, send your regular mail
address (not e-mail) to me:  nancy@uci.edu (after March 4 my e-mail address
is changing to nancy@ics.uci.edu).

Nancy Leveson
ICS Dept.
University of California, Irvine

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Titanic Effect
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@ICSD.UCI.EDU">
nancy@ICSD.UCI.EDU
</A>&gt;
</address>
<i>
22 Feb 86 12:21:30 PST (Sat)
</i><PRE>

In Peter Neumann's latest SEN column, he mentions the Titanic Effect without
an explanation of why it occurs.  
     [Actually, JAN Lee introduced it unattributably in <A HREF="/Risks/1.21.html">RISKS-1.21</A>:
           The severity with which a system fails is directly proportional
           to the intensity of the designer's belief that it cannot.   PGN]

I would like to suggest a hypothesis.  The Titanic effect is essentially the
statement that the worst accidents often occur in systems which are thought
to be completely safe.  The Titanic was thought to be so safe that normal
safety procedures, such as having an adequate number of lifeboats, were
neglected with the result that many more lives were lost than might have
been necessary.

The lesson is an important one because it goes back to the problems of using
quantitative assessment techniques.  Quantitative risk assessment can
provide insight and understanding and allow comparison of alternatives.
Probabilistic approaches have merit in that the necessity to calculate very
low probability numbers forces on the analyst a discipline that requires
studying the system in great detail.  But there is also the danger of
placing implicit belief in the accuracy of a calculated number.  That is, it
is easy to place too much emphasis on the models and forget the many
assumptions which are implied.  The models can also never capture all the
factors, such as quality of life, that are important in a problem.  (see
Morgan -- Probing the Question of Technology-Induced Risk, IEEE Spectrum,
Nov. 1981).

Getting back to the Titanic, certain assumptions were made in the analysis
that did not hold in practice.  For example, the ship was built to stay
afloat if four or less of the sixteen water-tight compartments (spaces below
the waterline) were flooded.  Previously, there had never been an incident
where more than four compartments of a ship were damaged so this assumption
was considered reasonable.  Unfortunately, the iceberg ruptured five spaces.
It can be argued that the assumptions were the best possible given the state
of knowledge at that time.  The mistake was in placing too much faith in the
assumptions and the models and not taking measures in case they were
incorrect (like the added cost of putting on-board an adequate number of
lifeboats).  The Titanic is not an isolated example.  Safety devices (such
as sensors in solid-rocket boosters or software safety analysis and design
procedures) cost -- usually in terms of dollars and performance.  There are
often attempts to get around them by using models which show that the
hazards are so negligible that the cost is unjustified.  On the other hand,
too much safety can make the system unusable or unprofitable which is not
the answer either.

The Titanic provides an important lesson for us involved in building
safety-critical computer systems.  Our current models for software
reliability make a large number of assumptions which may be unrealistic or
just not hold for particular systems.  This is true also, to a lesser
extent, with the hardware reliability models.  Much effort is frequently
diverted to proving theoretically that a system meets a stipulated level of
risk when the effort could much more profitably be applied to eliminating,
minimizing, and controlling hazards.  I have seen a great deal of effort
spent on trying to prove that a system which contains software has two or
three more "9's" after the decimal point in the reliability models when the
effort and resources might have been more effective if applied to using
sophisticated software engineering and software safety techniques.

Nancy Leveson
ICS Dept.
University of California, Irvine

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
F-18 spin accident
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!henry@seismo.CSS.GOV">
ihnp4!utzoo!henry@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Tue, 25 Feb 86 02:44:45 EST
</i><PRE>

Recent reading of a book on the F-18 turned up a couple of details on the
spin accident that might be of interest; I don't think these were part of
the original reports.

(For those who haven't heard about this before...  The US Navy's F-18
fighter	is heavily computerized, including "fly by wire" controls in which
the computers always mediate between the pilot's controls and the aircraft.
One thing the software does is to limit control-surface movements to within
safe ranges, so the pilot cannot accidentally break the aircraft in combat
maneuvering.  The 12th prototype was lost when it got into a peculiar type
of spin and the software did not give the pilot enough control authority
for recovery.  The pilot ejected safely.  After investigation, the software
was modified.)

Detail number one has something to say about the problems of exhaustive
testing:  even after the problem was known to exist, it took 110 attempts
to duplicate the spin!

Detail number two is that the spin was *not* unrecoverable.  The spin-test
F-18 was equipped with an anti-spin chute just in case, but the pilot who
first duplicated the spin discovered that he could recover without the chute
by setting the outer-side engine to flight idle and the inner-side engine to
full afterburner.  The original pilot could have done this, had he thought
of it.  This might strengthen the case for giving flight-control software
more authority, so that such unorthodox substitutes for ineffective or damaged
controls could be employed automatically.

Reference:  Bill Gunston, "F/A-18 Hornet", Ian Allan 1985, p. 43.  Gunston
does comment that apart from this one strange spin mode, the F-18 is probably
the most spin-proof fighter in existence.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,linus,decvax}!utzoo!henry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Space shuttle problems (a comment on risks in general)
</A>
</H3>
<address>
Brad Davis
&lt;<A HREF="mailto:b-davis@utah-cs.arpa ">
b-davis@utah-cs.arpa 
</A>&gt;
</address>
<i>
Mon, 24 Feb 86 19:53:39 MST
</i><PRE>

If the current speculation about the shuttle is true (that seals on the
solid fuel rockets failed because of the cold and that the Thiokol 
engineers asked for a delay because of their worries) then we should
look more at the humans in any decision chain.  Most of the major
failures that I can recall were due to humans overriding the expert
system (whether it was a electronic, mechanical, or human expert
system) or just messing things up in the first place (like the UPL
power generator that was connected to the power grid backwards, made
a real big electric motor for a short time).

Brad Davis	{ihnp4, decvax, seismo}!utah-cs!b-davis	
		b-davis@utah-cs.ARPA
One drunk driver can ruin your whole day.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Misdirected modems
</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:mab@riacs.ARPA">
mab@riacs.ARPA
</A>&gt;
</address>
<i>
24 Feb 1986 2221-PST (Monday)
</i><PRE>

Reminds me of something I read at 7 SOSP.  Someone got the bright idea
of collecting computer horror stories (an excellent idea, by the way!)
and one of them involved one computer calling another.  The connection
suddenly quit working after about a year.  The system people got
curious and hooked an audio device to the telephone line.  They then
told the computer to contact its counterpart.  They heard the computer
dial, the phone at the other end go off hook, and the computer send its
whistling tones indicating it had something to say.  From the other end
came the words, "Martha, it's that nut with the whistle again."
Problem solved.

Matt

     [Thanks for the anonymous plug.  It was I who anthologized the 
      anecdotes for 7 SOSP, and they all appeared in ACM Software
      Engineering Notes Vol 5 no 1 (January 1980) -- as noted at the 
      very bottom of my disaster list in RISKS-2.1!  PGN

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-71</DOCNO>
<DOCOLDNO>IA012-000128-B044-287</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.16.html 128.240.150.127 19970217001847 text/html 10894
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:17:17 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 16</TITLE>
<LINK REL="Prev" HREF="/Risks/2.15.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.17.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 16</H1>
<H2> Tuesday, 25 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Volunteers to study security of computerized voting booths? 
</A>
<DD>
<A HREF="#subj1.1">
Kurt Hyde
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Our Economy Is Based On Electricity 
</A>
<DD>
<A HREF="#subj2.1">
Jared M. Spool
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Misdirected modems 
</A>
<DD>
<A HREF="#subj3.1">
Jared M. Spool
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The Titanic Effect 
</A>
<DD>
<A HREF="#subj4.1">
Earl Boebert
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
volunteers to study security of computerized voting booths?
</A>
</H3>
<address>
Kurt Hyde DTN 264-7759 MKO1-2/E02
&lt;<A HREF="mailto:hyde%topcat.DEC@decwrl.DEC.COM  ">
hyde%topcat.DEC@decwrl.DEC.COM  
</A>&gt;
</address>
<i>
Tuesday, 25 Feb 1986 04:45:16-PST
</i><PRE>

How secure are computerized voting booths?

I teach Systems Analysis at a local college here in Nashua, NH.  For the
last two years, my students and I have been studying the impact of
computerization on voting security.  The recent charges of fraud in Mexican
and Phillipine elections increase the importance of such studies as
computers are now being implemented into three areas of voting --
maintaining voter registration lists, tallying of votes, and directly
computerized voting.

Last year's class discovered that an OEM was manufacturing a computerized
voting booth.  Further research has revealed that the company's strategy for
ensuring security is secrecy of operation.  Secrecy of operation increases
the difficultly in penetration, but it also has a negative side effect of
making it difficult (if not impossible) to detect tampering.

There are many documented cases of accidental miscalculation in computerized
vote tallying equipment.  The reasons why such errors were discovered is
because reconstruction and recount was possible.  Investigators
reconstructed by gathering the machine-readable ballots.  They were then
able to recount by machine or by hand.  Such reconstruction is impossible
with the current state of the art in computerized voting booths because no
physical ballots are created.  Recounts in such cases are wholly dependent
upon the software to have stored each vote in its proper storage location at
the time of voting.

As far as I can tell, no computerized voting booth has ever been subjected
to product testing by hackers.  I discussed this with the chief engineer at
the first company to make computerized voting booths.  He agreed with me in
a phone conversation that such testing would be nice and that he was open to
the idea.  However, the only way to get something done in this area is for
concerned citizens to try it.  There are now at least three companies either
making or planning to make computerized voting booths and, according to the
FEC, they all intend to rely on secrecy of operation for security.  Oddly,
none of the companies have named their flagship products "The Titanic".

Do you think these people have developed perfect, unbreakable codes?  Some
associates of mine and I think not.  In fact, we have begun to formulate
some testing strategies.  I've done a lot of work myself, but I now need
some expertise in the areas of cryptography, decompiling programs, and
MS-DOS on IBM PC.

Perhaps we can avoid having a Marcos-Aquino style problem here in America.

                                  Kurt

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Our Economy Is Based On Electricity
</A>
</H3>
<address>
Jared M. Spool 
&lt;<A HREF="mailto:Spool@SCRC-STONY-BROOK.ARPA">
Spool@SCRC-STONY-BROOK.ARPA
</A>&gt;
</address>
<i>
Tue, 25 Feb 86 11:47 EST
</i><PRE>
To: risks@SRI-CSL.ARPA

Last week, on payday, I was informed from our efficient payroll department
that my bank account would not be credited with my automatic deposit of my
paycheck for a couple of days.  The reason that was given was a "Power
Blackout In The LA area".  (Our payroll is handled out of our LA office,
while R&amp;D is on the east coast.  I don't know the reason for this
polarization.  I think it has to do with opposites repelling or something.)

A lot of our economy is based on things that use electricity.  While battery
backups are not uncommon in computer systems, what percentage can withstand
a 24 hour blackout?  How about 48 hours?

If NY were hit with a 48 hour blackout, what would happen to the NYSE?

I realize that there are lots of social things that happen during blackouts
(like rioting and baby booms), but these things tend to be localized to the
area of the outage.  But, as I stated above, I need a cross country
connection to get paid.  How much of our economy would be downed because of
something like this?

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Misdirected modems
</A>
</H3>
<address>
Jared M. Spool 
&lt;<A HREF="mailto:Spool@SCRC-STONY-BROOK.ARPA">
Spool@SCRC-STONY-BROOK.ARPA
</A>&gt;
</address>
<i>
Tue, 25 Feb 86 11:31 EST
</i><PRE>
To: RISKS FORUM &lt;RISKS@SRI-CSL.ARPA&gt;

    From: Alan Silverstein &lt;hp-sdd!hpfcla!ajs@nosc.ARPA&gt;
    Date: Mon, 24 Feb 86 11:12:54 pst
    Subject: misdirected modems

    Twice recently, computers at our company (Hewlett-Packard) have been the
    embarrassing causes of telephonic annoyance.  Phone numbers entered
    incorrectly in uucp L.sys files, due to typos or misunderstandings, have
    led to systems repeatedly calling private telephones in Fort Collins.

    [...]

    I bet this happens a lot more than anyone realizes or admits.

I'll admit it.  Four jobs ago, I worked at (what was then a startup) as
one of two developers on a electronic mail package using regular phone
lines as the network.  We used to test the product, over night, by
having the five test machines try to send and receive 100-200 messages
(per machine) over the five phone lines.  (We did this in batches of 20
messages.)  The tests were set to start anywhere from 11:00 p.m. to 3:00
a.m. and could go 2-3 hours in length depending on how we set them up.
Different machines would have different starting and length times.

The product worked, such that if the phone was busy or didn't answer,
(the modem couldn't detect the difference,)  it would try again after a
certain delay (approx 15-20 minutes) until it failed 10 times.  The test
was set up that each batch would generate only one phone call.

One morning, after running such a test, I noticed that, on one of the
machines, all of the batches set to go to a second machine didn't make
it, while all of the batches for the other three machines did.  On
further investigation, I determined that the phone number for the second
machine was incorrectly typed into the sending machines database.  It
turned out to be a residence, and an apology was made.  We double
checked our test sets before starting them, after that.

In conclusion, it is very easy, with today's technology to do such a
thing.  Modem technology has even progressed that the modems themselves
redial the numbers until a connection is made, with no regard to the
fact that there will never be a machine on the other end.

We have always had wrong numbers.  However, when a human dials a wrong
number, there is (almost) immediate confirmation that the number is wrong,
and a second or third or tenth retry is not attempted to the same number.

Maybe what we need is a touch tone code (or something) that one can
enter into a modem that says "The number you have is wrong, go away."  

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 The Titanic Effect
</A>
</H3>
<address>
&lt;<A HREF="mailto: Boebert@HI-MULTICS.ARPA">
 Boebert@HI-MULTICS.ARPA
</A>&gt;
</address>
<i>
Tue, 25 Feb 86 18:21 CST
</i><PRE>
cc: risks@SRI-CSL.ARPA

This rule is, I believe, actually an instance of the 28th Axiom of
Systemantics:  "When A Fail-Safe System Fails, It Fails by Failing to Fail
Safe." All 32 Axioms, the Four Basic Postulates, and Corollaries can be
found in the delightful _Systemantics_ by John Gall (Quadrangle/NYT Books,
1977, ISBN 0-8129-0674-8), which deserves to be better known.

Earl

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-72</DOCNO>
<DOCOLDNO>IA012-000128-B044-311</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.17.html 128.240.150.127 19970217001904 text/html 16207
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:17:29 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 17</TITLE>
<LINK REL="Prev" HREF="/Risks/2.16.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.18.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 17</H1>
<H2> Friday, 28 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Replacing humans with computers? 
</A>
<DD>
<A HREF="#subj1.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Eastern Airlines stock 
</A>
<DD>
<A HREF="#subj2.1">
Steve Strassmann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computerized stock trading and feedback systems 
</A>
<DD>
<A HREF="#subj3.1">
Kremen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computer Voting Booths 
</A>
<DD>
<A HREF="#subj4.1">
Larry Polnicky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Reliance on security 
</A>
<DD>
<A HREF="#subj5.1">
Jong
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  AI risks 
</A>
<DD>
<A HREF="#subj6.1">
Nicholas Spies
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Data Encryption Standard 
</A>
<DD>
<A HREF="#subj7.1">
Dave Platt
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Replacing humans with computers?
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@ICSD.UCI.EDU">
nancy@ICSD.UCI.EDU
</A>&gt;
</address>
<i>
25 Feb 86 22:06:36 PST (Tue)
</i><PRE>

I have recently seen several risks contributions which assumed that humans
are the cause of most system accidents and that if the human was somehow
replaced by a computer and not allowed to override the computer (i.e. to
mess things up), everything would be fine.  The issue is too complicated to
cover adequately here.  But before rushing off to replace human controllers
with computers, at the least consider the following:

  ** Most accidents involve multiple failures of different components
     of the system.  It is rarely possible to pinpoint one particular
     failure as the sole cause.  (e.g. Three Mile Island involved at
     least four or five different types of mechanical failures.  Who
     got the blame?)
  ** There are often powerful and compelling reasons for wanting the
     blame placed on the human.  For example, Babcock and Wilcox can
     be sued for billions if there is something wrong with the design
     of their nuclear power plants -- how much can you collect from
     some poor operator?
  ** The human is often called in to save the day after chaos has
     already begun and then expected to come up with a miracle.  If he
     does not save the day, then the blame is often placed on him/her
     instead of the initiating mechanical failures.
  ** Most accidents result from unanticipated events and conditions.  
     Thus it is doubtful that computers will be able to cope with emergencies
     as well as humans do.  Expert systems do not help in coping with
     unanticipated events or conditions.
  ** There are many examples of accidents which were averted by a human
     overruling an errant computer.  If the operator had not intervened at
     the Crystal River Nuclear Power Plant, for example, a catastrophe might
     have occurred because of the computer error.  The hype about "expert 
     systems" and "artificial intelligence" may be very dangerous.  
     There are reports that commercial pilots are becoming so complacent 
     about automatic flight control systems that they are averse to 
     intervene when failures do occur and are not reacting fast enough 
     (because of the assumption that the computer must be right).

The problem is just not that simple that the answer "replace the human
with a computer" will solve it.   Nancy

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Eastern Airlines stock
</A>
</H3>
<address>
Steve Strassmann 
&lt;<A HREF="mailto:straz@MEDIA-LAB.MIT.EDU">
straz@MEDIA-LAB.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 27 Feb 86 02:38:17 EST
</i><PRE>

As an owner of Eastern Airlines stock (fell from $11 to $5 right after
I bought it), I'm particularly upset by this.  I don't know the
details; I hope someone with more knowledge can fill them in.

According to my stock broker (Disclaimer: I don't have any hard
documentation, and I'm not a Wall. St. expert), one of the major blows
to the already troubled company was a bogus earnings report issued on
a Dow Jones computer (something like 20 cents instead of $1.50). The
mistake was corrected within the hour, but in that hour, portfolio
managers had dumped Eastern stock, and the price fell $3, and never
recovered. I think this happened around early September.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computerized stock trading and feedback systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 26 Feb 86 07:57:40 PST (Wed)
From: kremen@aero

There seems to be some misunderstanding about computerized stock trading.

First, "programmed buys" and "programmed sells" really have nothing to do
with computers. All "programmed" transactions could be done by hand but
typically they are extremely complex, so a computer is needed.  Programmed
trading only occurs when special intermarket conditions are present. Program
trading consists of arbitrageurs who use the spread between the value of
stocks on the New York Stock Exchange (NYSE) and the Chicago Board of
Options Exchange (CBOE) in Chicago. Occasionally other markets are used.

Intermarket arbitrage adds to market volatility but not in a negative sense.
The infamous "Triple Witching Hour", a time four times a year of extremely
volatile trading, is a direct result of this intermarket arbitrage.

Eric Nickell in his note compare the market to a feedback system that
oscillates - something like a forcing function with resonance. Well not
at all true. The market cannot get really swamped because something
will "break-down first". In the case of the NYSE - the "market makers"
will have an "order imbalance" preventing further trading.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Computer Voting Booths
</A>
</H3>
<address>
 Larry Polnicky 
&lt;<A HREF="mailto:Polnicky@HIS-PHOENIX-MULTICS.ARPA">
Polnicky@HIS-PHOENIX-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 26 Feb 86 10:43 MST
</i><PRE>
To:  RISKS@SRI-CSL.ARPA

In RISKS Vol 2, Issue 16, Kurt Hyde write:

&gt; There are many documented cases of accidental miscalculation in computerized
&gt; vote tallying equipment.  The reasons why such errors were discovered is
&gt; because reconstruction and recount was possible.  Investigators
&gt; reconstructed by gathering the machine-readable ballots.  They were then
&gt; able to recount by machine or by hand.  Such reconstruction is impossible
&gt; with the current state of the art in computerized voting booths because no
&gt; physical ballots are created.  Recounts in such cases are wholly dependent
&gt; upon the software to have stored each vote in its proper storage location at
&gt; the time of voting.

While the risks would not be entirely removed, and regardless if any fraud
or error is suspected, there could be a standard practice initiated whereby
a sample from each election is validated by follow-up phone call or
physical notification.  Privacy could be somewhat maintained by automating
this process, e.g., immediately after the polls close, the computer randomly
selects some small sample and sends a letter saying, "Citizens Jones,
according to our computer voting system, you voted thusly:...."  The
citizen then returns the card validating or invalidating his voting record.
A box could be checked for him to indicate that he would rather not
acknowledge via mail or not at all; the percentage of such respondents
would probably be low.  Also, since some people may goof or maliciously
be inconsistent, the final validation would not have to be unanimous;
some standard percentage of validation would pass as I believe it does
today in a recount.  If delegating the follow-up procedure to a computer
is the start of a new computer risk, then it could be done manually,
but I believe this kind of check-back mechanism would significantly
reduce the risks involved in computer voting to the point that it
could gain approval.

Larry Polnicky, Honeywell Information Systems, McLean, Virginia.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Reliance on security
</A>
</H3>
<address>
&lt;<A HREF="mailto: Jong@HIS-BILLERICA-MULTICS.ARPA">
 Jong@HIS-BILLERICA-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 26 Feb 86 12:19 EST
</i><PRE>
To:  risks@SRI-CSL.ARPA

Kurt Hyde's reference to the Phillipine elections and the security of
computerized vote-counting systems reminds me that the issue of computer
security is artificially narrow.  If I am a criminal, and you confront me
with an unbreakable computer security system, I will simply direct my
attention elsewhere.  Attacking strong points went out with World War I (or,
to maintain the underworld analogy, with Machine Gun Kelly).

The most elaborately password-protected system is easily cracked if the
passwords are transmitted over telephone lines, or if people leave their
passwords lying about on scraps of paper.  That may fall outside the venue
of computer science, but not outside the venue of reality.  In the case of
the Phillipine elections, it didn't matter how well the vote-counting
computers were programmed; there were soldiers at the polling places
threatening to shoot voters.  Ballot boxes were opened to reveal twenty
thousand ballots marked in the same handwriting for Mr.  Marcos.  The
computer operators were being told what numbers to enter.

I guess there's not much you can do about risks outside your direct control.
My point is not to get too focussed in our concerns.

    [As noted many times in RISKS, any single weak link may represent a
     vulnerability.  In systems designed not to have single weak links,
     there are weak combinations.  Thus we must be concerned with ALL of
     the weak links.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
AI risks
</A>
</H3>
<address>
&lt;<A HREF="mailto:Nicholas.Spies@GANDALF.CS.CMU.EDU">
Nicholas.Spies@GANDALF.CS.CMU.EDU
</A>&gt;
</address>
<i>
26 Feb 1986 23:19-EST
</i><PRE>
To: risks@sri-csl

Today I attended an IEEE videoconference on "Applications of Artificial
Intelligence" with Drs. Tom Mitchell (CMU/Rutgers), Alex Pentland (SRI),
Peter Szolovits (MIT) and Harry Tennant (Texas Instruments). Aside from some
overdriven graphics such that it interfered with the audio, it was an
excellent intro to AI (for those concerned with the medium AND and the
message).

I asked the question, asked here and elsewhere by others, about the
potential legal responsibility of authors of AI software, the most obvious
example being medical diagnosis.  The answer from the panel was that most AI
work now has been done under very controlled conditions, responsibility has
never been tested in a court case, and that (possibly) the law applying to
publishers of reference books might apply also to AI systems (that is,
willful deceit would be punishable but typos and other innocent mistakes
would not make a publisher accountable). But according to one of the panel
members some AI researchers ARE in fact taking out insurance against
possible suits but (paraphrase) "the insurance companies look upon this
problem as something of a lark and the insurance emiums are low now"
although the same panel member said that (paraphrase) "this may become a
very important problem in the future".

I originally phrased the question to ask whether the implicit threat of
possible suits against artificial intelligence applications might have a
chilling effect on research and development of interesting applications
(that is, those involving human life and property), but as it was not asked
it was not answered.

My own (legally uninformed) feeling is that AI by its very nature spreads
around the concept of "volition" such that the present legal system might
have a difficult task in assigning responsibility in a damage suit (and
these doubtless will come down the pike someday).

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Data Encryption Standard
</A>
</H3>
<address>
Dave Platt 
&lt;<A HREF="mailto:Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA">
Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Thu, 27 Feb 86 17:31 PST
</i><PRE>

There's an interesting article in the 2/24 issue of InformationWEEK
concerning the DES.  Apparently, DES was up for voting to become an
international encryption standard sanctified by ISO.  The NSA (National
Security Agency) was lobbying very strongly within ANSI (the United States'
representative within ISO) to have DES disapproved...  the apparent reason
being that wide standardization of DES, and its routine use, would make it
substantially more difficult for NSA to monitor overseas voice and data
communications.  IBM pushed very strongly within ANSI for a "yes" vote
within ISO (DES is already an ANSI standard, and its details have been
readily available to anyone for the past five years or more).  In the end,
IBM won and NSA lost; ANSI abstained from voting, which had the same net
effect as a "yes" vote.

Have any studies been done concerning the risks of having, or not having
a secure data-encryption scheme to guard the integrity of one's data?

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-73</DOCNO>
<DOCOLDNO>IA012-000128-B044-337</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.18.html 128.240.150.127 19970217001919 text/html 20300
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:17:46 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 18</TITLE>
<LINK REL="Prev" HREF="/Risks/2.17.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.19.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 18</H1>
<H2> Friday, 28 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Titanic and What did I overlook? 
</A>
<DD>
<A HREF="#subj1.1">
Hal Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Titanic Effect 
</A>
<DD>
<A HREF="#subj2.1">
Jong
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computers placing telephone calls 
</A>
<DD>
<A HREF="#subj3.1">
Art Evans
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Misdirected modems 
</A>
<DD>
<A HREF="#subj4.1">
Sam Kendall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Modems and phone numbers 
</A>
<DD>
<A HREF="#subj5.1">
David Barto
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Misdirecting my modem 
</A>
<DD>
<A HREF="#subj6.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Power-outages, &amp; other failures of central DP systems 
</A>
<DD>
<A HREF="#subj7.1">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Computer voting booths 
</A>
<DD>
<A HREF="#subj8.1">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Data Encryption Standard 
</A>
<DD>
<A HREF="#subj9.1">
Chris McDonald
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Titanic and What did I overlook?
</A>
</H3>
<address>
&lt;<A HREF="mailto:Murray.pa@Xerox.COM">
Murray.pa@Xerox.COM
</A>&gt;
</address>
<i>
Wed, 26 Feb 86 00:24:08 PST
</i><PRE>
To: RISKS FORUM (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;

There is also the reverse of the Titanic problem. Sometimes trying to
protect against a particular mode of failure that you are very worried
about actually makes the overall reliability worse. I'm thinking of the
cases where the whole system gets so much more complicated because
"fixing" something pushes it over the edge of well understood
technology.

The aspect of calculating failure probabilities that has always bothered
me is that I can't see any way to take into account the things I have
totally overlooked, the areas that I haven't even dreamed about. You
know, the sort of problem where, after you hear the story, you sigh, and
feel sorry of the people involved rather than thinking that they would
have noticed the problem if they had been a bit more diligent when
testing. Is there any theory in this area?

I've helped track down several very obscure bugs in hardware and/or
microcode. Each time we finally located a problem, I've been amazed at
how easy it was to make it happen. That is after we knew where to poke
and had set up the right test programs. Two examples come to mind.

Ten years ago, I worked on a PDP-10. At one point, the machine was acting a
bit funny. It would run Tenex for days. However, our only big hairy LISP
program sometimes got the wrong answer and the bootstrap loader sometimes
zeroed itself while it cleared memory. One day, the boot loader trouble got
reasonably solid. We wrote a small program to mimic what the it was doing,
catch the trap, reconstruct the test sequence, and try again. It didn't
fail. We included the previous 6 instructions from the loader into our test
sequence. They were doing something totally uninteresting. It failed solidly
- every few milliseconds for an hour while we poked around with a scope. We
finally found a textbook example of a runt pulse. It was happening just when
the end test should decide to stop. (The real problem was a sick power
supply.)

Several years ago, I was doing a lot of Ethernet tire-kicking. The early
Dandelions were coming out of the factory. Everybody was looking for
trouble rather then introducing new problems into their code. Things
felt pretty solid. One evening, I was testing some transceivers. Nothing
interesting was happening, so I connected in another spool of coax.
Poof. Lots of packets started falling through the cracks. Simple tests
worked 100%, but more complicated tests would miss 50% of the packets.
It was a simple timing problem. If a packet started arriving while the
microcode was preloading the transmit FIFO, the microcode/hardware
discarded the input packet as it disabled the transmitter while
switching modes to go inspect the input packet. By inserting the extra
coax, I had increased the delays enough to drop a packet right into the
window.

PS: I second Earl Boebert's recommendation for John Gall's Systemantics.
If only I could remember all his lessons that seem so simple and
obvious while reading about them....
                                      [Maybe you could be COAXed.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Titanic Effect
</A>
</H3>
<address>
&lt;<A HREF="mailto: Jong@HIS-BILLERICA-MULTICS.ARPA">
 Jong@HIS-BILLERICA-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 26 Feb 86 12:24 EST
</i><PRE>
To:  risks@SRI-CSL.ARPA

I suppose if I had said to the designer of the Titanic:  "Yes, the worse
maritime accident on record involved the breaching of four watertight
compartments, SO LET'S PLAN ON SURVIVING FIVE," the designer would have
specified smaller compartments, so that the Titanic would have had eighteen,
not sixteen, compartments.  And the iceberg would have ruptured six
compartments... 

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computers placing telephone calls
</A>
</H3>
<address>
"Art Evans" 
&lt;<A HREF="mailto:Evans@TL-20B.ARPA">
Evans@TL-20B.ARPA
</A>&gt;
</address>
<i>
Wed 26 Feb 86 14:18:23-EST
</i><PRE>
To: Risks@SRI-CSL.ARPA

Some years ago the ARPANet Network Control Center (NCC) at BBN was
tasked to check periodically that each dialup line to each TIPs was in
fact functional.  Absent such a check, a TIP port could be
non-operational for a long time before anyone would notice.

To make the check, a computer at NCC was connected to an outward WATS
line and programmed to call every TIP line around the country
periodically, every week or so, to be sure it could properly connect to
a modem.  For a busy signal or other failure to handshake with a modem,
the program would retry a few times and then alert a human being about a
possible problem.  Then a person at the TIP site would be asked to check
the line there.

All this was OK, and it worked just fine.  Once, however, by some
accident, the computer was connected to an ordinary phone line rather
than to the outward WATS line.  The first indication BBN had about this
disaster occured when the phone bill came, in a cardboard box, with some
three inches thickness of call itemization slips for all those calls.  I
don't remember the total, but I do remember that it attracted a *lot* of
attention at very high management levels.  There was much discussion
about whether the improper phone connection was BBN's error or the phone
company's; I think a compromise was eventually worked out.

A nice check was immediately added to the whole system.  The outward
WATS line had the property that it could be used to call anywhere in the
48 contiguous states except Massachusetts (which is where BBN is).
Thereafter, each night the program placed the first call to a
Massachusetts modem.  If that call worked, the run immediately aborted
and a human was notified that some line other than the proper WATS line
was in use.

A lot of problems are easy to solve, once you know what the problem is.

Art Evans

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Misdirected modems
</A>
</H3>
<address>
&lt;<A HREF="mailto:delftcc!sam@nyu.arpa">
delftcc!sam@nyu.arpa
</A>&gt;
</address>
<i>
Fri, 28 Feb 86 08:09:37 est
</i><PRE>

Modems and calling software should treat as special the case that the
phone on the receiving end goes off hook, but no carrier is detected.
This means either that (1) a person has picked up the phone, or (2)
there is some incompatibility between the calling and answering modems,
or (3) there is a bad connection.  (3) should also be detectable to a
modem (is this true?), so we eliminate it from the special case.  In the
special case the calling software should retry the number a very few
times, then call for human intervention.

Unfortunately, the ultra-standard Hayes Smartmodem 1200 cannot
distinguish between various NO CARRIER conditions at all, much less
distinguish (3) from (1) and (2).  Better (smarter) modems are needed
before the calling software can deal with this special case, and stop
its modems from accidentally torturing people.

----
Sam Kendall			     allegra \
Delft Consulting Corp.		seismo!cmcl2  ! delftcc!sam
+1 212 243-8700			       ihnp4 /
ARPA: delftcc!sam@nyu.ARPA

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Modems and phone numbers
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 27 Feb 86 13:27:46 PST (Thu)
From: David Barto &lt;celerity!shipit!barto@sdcsvax.ucsd.edu&gt;

While setting up a link to a new system, I entered the phone number
incorrectly.  I failed to connect when the machine attempted to do the
call.  Being very suspect of myself (on the first call), I dialed the
number the machine was attempting to call.  A person answered, and I
attempted to determine the phone number she was at.  This number was
not the same number I was dialing.  I then called the operator (good
old AT&amp;T), and asked what was going on.  The operator dialed the same
number, got the same person on the line, and verified the number was
different.

We worked on the crossed lines problem for 2 days.

The final solution was not crossed lines, but the fact that multiple
numbers connected to ONE phone.

Sadly, neither the operator, nor the person answering the phone, had
any idea that multiple phone numbers went to the same physical unit.

How many phones sit on your desk.  How many phone numbers will it
ring to.  Are you really sure?
-- 
David Barto, Celerity Computing, San Diego Ca, (619) 271-9940
decvax-\    bang-\			ARPA: celerity!barto@sdcsvax.ARPA
ucbvax--&gt;-sdcsvax-&gt;!celerity!barto
ihnp4--/   akgua-/

	"Moderation in all things, including moderation"

   [Including net addresses?  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Misdirecting my modem
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Wed, 26 Feb 86 20:36:07 est
</i><PRE>

Once upon a time, early in the days of my computer-life, I worked late.  I
told my Z-120 to tell my Hayes to call a number.  It did, and I heard the
ring, and then the answer.  No whistle-hiss-CONNECT, but a quavery young 
female voice saying, "Hello?... "  I sent three pluses and an ATH to the 
Hayes, read the (wrong) number off the screen, and dialed it on my voice
phone.  I wanted to render immediate and abject apologies.  The phone 
rang and rang.  I redialed, in case I had incorrectly dialed the wrong 
wrong number.  It rang and rang.  I quit.  There was no way to un-scare
that young woman.  I have been much more careful since then - but still 
ring a wrong number now and then.  If it is during the day I voice-phone to
apologize.  If it is in the wee hours, I just say a prayer for that person's
serenity, and mine, and go on.  

It seems common courtesy to check all supposed "computer phones" by voice, 
by day, prior to using them in an auto-dial mode.  The computer doesn't lie
awake at night wondering what wierdo is ringing the phone and hanging up.

	- Mike McLaughlin

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Power-outages, &amp; other failures of central DP systems
</A>
</H3>
<address>
Dave Platt 
&lt;<A HREF="mailto:Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA">
Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 26 Feb 86 12:11 PST
</i><PRE>

In my experience, battery backup for computer systems is usually of
extremely limited capacity (an hour or two) when you're talking about
a large computer center with lots of power-hungry disks and so forth.
Frequently, the amount of battery storage capacity is enough to permit
the system operators to shut down their machines in a graceful fashion,
and requeue any work-in-progress for processing when the AC mains come
back up.  Sites that absolutely require uninterruptable power generally
have backup diesel generators... they're much smaller per kilowatt
than batteries would be, and can run for days at a time as long as you
keep feeding them fuel.

I'm not sure what would happen to the NYSE if there were a two-day
blackout in New York.  There was an extensive blackout (six hours or
so???) back in the 60's, I seem to recall... but it was shorter than
the one that you're speaking of, and the NYSE is probably much more
dependent on computers than it was twenty years ago.  I imagine that
they'd probably have to shut down.

I read a book recently that might be of some interest to Risks readers,
as it addresses the problems of centralized data transmission and storage
to some extent.  The book is "Night of Power", by Spider Robinson;  it's
fictional, borderline SF [by my standards... open to dissent], and
revolves around the seizure of Manhattan Island (and the East Coast's
major satellite uplink) during a social revolution in the 1990's.  The
point was made that the seizure of the uplink could easily have resulted
in a major collapse of the world's interlinked financial systems, if
the data flowing through the link were to be cut off or corrupted.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Computer voting booths
</A>
</H3>
<address>
Dave Platt 
&lt;<A HREF="mailto:Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA">
Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Fri, 28 Feb 86 12:10 PST
</i><PRE>

GAAK! Maybe I'm misunderstanding [Larry Polnicky], or the systems actually
used in the computerized voting booths... but I had always believed that the
voting systems in this country [paper, computer-based, or whatever] were
designed to GUARANTEE A SECRET BALLOT! I've NEVER heard of a public-voting
system that was designed to permit anyone to identify a particular vote, or
set of votes, with a particular voter.  There is a longstanding tradition in
this country of guaranteeing that an individual can vote his or her
conscience, without being identified afterwards as "the person who voted for
Smidget for Congress".

There have been plenty of examples in the past of the problems that can
occur when a person's votes are not kept secret.  Both in this country,
and in numerous countries overseas, people who have voted the "wrong
way" (usually against a clique in power) have been pressured, fired from
their jobs, beaten, tortured, or killed.  I would strongly resist any
computerized (or paper) voting system that would make any votor's voting
record identifiable to *anyone* without that votor's explicit approval.

Note here that I'm not talking about voting systems such as Congress
uses, in which the public has an explicit right to know who voted for &amp;
against what.  In systems such as this, it's fine to have records kept,
and some sort of accuracy/accountability audit... but by their very
nature, these systems are generally much smaller than state-wide or
national voting systems, and are thus less likely to be subject to
large-scale fraud.


    [Even in paper ballot systems, there is usually a serial number which
     provides a back-link from the voter to the ballot.  Otherwise fraud is
     far too easy, with mystery ballots appearing out of nowhere.  But
     recall the earlier Phillipine election in which a local power failure
     downed the central ballot-counting computer, which upon reboot
     immediately finished the ballot counting.  Somebody has to be trusted
     somewhere.  There is a choice as to whom the trust must be given.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Data Encryption Standard
</A>
</H3>
<address>
Chris McDonald 
&lt;<A HREF="mailto:cmcdonal@wsmr06.arpa">
cmcdonal@wsmr06.arpa
</A>&gt;
</address>
<i>
Fri, 28 Feb 86 12:47:35 MST
</i><PRE>
To: RISKS FORUM &lt;RISKS@SRI-CSL.ARPA&gt;

In response to the DES item, the National Security Agency and other US
intelligence services have conducted numerous signal intercept exercises
throughout the US.  The results of such exercises are for good reasons
classified under national security directives.  Readers Digest, however, which
obviously has good connections, has published several articles during the last
5 years describing the threat from foreign intelligence services as well as
from industrial espionage.  IEEE Spectrum publication had an excellent article,
"Thwarting the Information Thieves," in its Jul 85 edition.

Presently under Fed Standard 1027 DES devices are export controlled items.
This would means that US firms who build such encryption hardware must obtain
an export license before any foreign sale.  Since NSA is the author of the
Standard, their position would seem to be consistent.  IBM of course does sell
and build DES devices, and its personnel developed the algorithm upon which DES
is based.  Therefore, their position would seem to be consistent.

Chris McDonald
White Sands Missile Range

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-74</DOCNO>
<DOCOLDNO>IA012-000128-B044-354</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.19.html 128.240.150.127 19970217001939 text/html 12252
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:18:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 19</TITLE>
<LINK REL="Prev" HREF="/Risks/2.18.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.20.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 19</H1>
<H2> Sunday, 2 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A word from Isaac Asimov about Robots 
</A>
<DD>
<A HREF="#subj1.1">
Bryan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  AI risks 
</A>
<DD>
<A HREF="#subj2.1">
John Shore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Replacing Humans with Computers 
</A>
<DD>
<A HREF="#subj3.1">
David desJardins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  On-line Slot Machines 
</A>
<DD>
<A HREF="#subj4.1">
Jeff Makey
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A word from Isaac Asimov about Robots.
</A>
</H3>
<address>

&lt;<A HREF="mailto:crash!bryan@nosc.ARPA">
crash!bryan@nosc.ARPA
</A>&gt;
</address>
<i>
Sat, 1 Mar 86 13:45:11 PST
</i><PRE>

I went on vacation last week, irrelevant I know except for the following.
 
I flew on American Airlines, which had for the amusement of its passengers
an in flight magazine called "American Way"  issue dated February 18, 1986.
It contained an article written by Isaac Asimov which I have reproduced
here.  The clever pictures by Kent Robbins also in the article were omitted
for obvious technical reasons.
 
 
                                 Robots! Beware!
                                       by
                                  Isaac Asimov
 
  reprinted from American Way, February 18, 1986.
 
   I invented the Three Laws of Robotics in 1942, and these laws, which are
built into the robots of my science-fiction stories, prevent them from harming
human beings, force them to follow orders,a nd make them protect themselves,
in that order of importance.
 
   Of course, the robots in which I imagined these laws to exist are complex
fictional robots, far more advanced than anything in real life (as yet).
In contrast, the robots in industrial assembly lines right now are just com-
puterized arms, capable of doing simple tasks over and over.
 
   But they are capable of doing harm, and, as the inventor of the laws, I
always feel guilty.
 
   Two workman in Japan were killed by robots, and in July, 1984, there was
the first fatality in the United States.  When the first American was killed
by robots, there were 13,000 robots in in industrial use in the United States.
One such accident with 13,000 robots in existence doesn't seem like a bad
ratio, but it is estimated that by 1990 the number of industrial robots will
reach 100,000.  Will the rate of robot-caused fatalities also increase eight-
fold?
 
   One may argue that accidents occur in connection with almost every 
mechanical device, however simple and small.  Yet robots are different.
Because they seem more intelligent than other machines, a fatal accident seems
more likely to be the result of there malevolence.  There is the feeling that
intelligent machines should be more careful and avoid hurting a human being.
In short, even if I hadn't invented the Three Laws of Robotics, people would
take it for granted that they ought to exist.
 
   People therefore would resent robots more than they would resent other
devices that do harm; a robot should know better.
 
   If we're living in a society that is going to be more and more robotized,
then a public that resents and fears robots is likely to cripple what we think
of as progress.
 
   Yet the serious accidents that have taken place so far in connection with
robots have been the result. at least in part, of human carelessness.
 
   Perhaps in place of the first law we need a substitute that puts the onus
on human beings.  The first law --"A robot may not injure a human being, or
through inaction, allow a human being to come to harm"-- cannot be built into
the simple robots of today, so maybe it should be replaced with "A human being
must not approach a robot in operation or one that may suddenly become
operable."
 
   In other words, the human being must stay away.  In order to reinforce that,
the robot must be surrounded by a barrier, ideally one with a gate that when
opened to allow human beings access will cut off all power to the robot.
 
   Unfortunately, a barrier is sometimes insufficient.  If it can be climbed
or crawled under, there is nothing to prevent someone from doing that rather
than taking the trouble to open the gate. (Why? It's hard to explain, but we
see human beings risking their lives every day in order to save 15 seconds of
time.)
 
   As a result the barrier must not simply consist of railings or a low fence.
It should consist of an elaborate fence that only can be penetrated by way of
a gate.
 
   Furthermore, people who work with robots (of the kind we have now) must be
thoroughly indoctrinated with the understanding that a robot that is not in
operation may have inactivity as part of its cycle and that if the power is
not off, the robot may suddenly move into operation as another part of its
cycle begins.
 
   There might be emergencies when human beings must approach robots in oper-
ation.  If so, it is unsafe to suppose that they can count on a robot cont-
inuing a motion indefinitely no matter how often it repeats the motion.
It is possible that the robot's programming calls for repeated motions of a
particular sort, but eventually, a set of different motions will start as
another part of the cycle begins.
 
   To help understand this, there should be clear markings on the floor and
other work areas representing the extreme range of all robot movements in
all directions.
 
   Since no matter what one does, experienced workers begin to be over-
confident of their own abilities and contemptuous of the robot's ability
to do harm, indoctrination should be repeated periodically, and any viola-
tion of safety rules invariably should be followed with disciplinary action.
 
   Eventually, of course, when robots have grown sufficiently complex, the
three laws may be built into them, and then take over the responsibility for
human safety, and we can relax.
 
                              ====================
 
Isaac Asimov report's that the word "robot" is of Slavic origin and was
first used in a play, "R. U. R." written by a Czech playwright, Karl Capek,
in 1921.  The initials stand for Rossum's Universal Robots.  In Czech the
word refers to "involuntary servitude."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: AI risks
</A>
</H3>
<address>
&lt;<A HREF="mailto:epiwrl!shore@seismo.CSS.GOV">
epiwrl!shore@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Sat, 1 Mar 86 07:32:52 EST
</i><PRE>

Expert systems are inherently untrustworthy.  

If you claim or imply otherwise, 
and if the system subsequently causes harm, 
and if those harmed sue you, 
you get what you deserve. 

John Shore

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Replacing Humans with Computers
</A>
</H3>
<address>
David desJardins
&lt;<A HREF="mailto:desj@brahms.berkeley.edu ">
desj@brahms.berkeley.edu 
</A>&gt;
</address>
<i>
Fri, 28 Feb 86 20:47:58 pst
</i><PRE>
Organization: University of California, Berkeley

Nancy Leveson &lt;nancy@ICSD.UCI.EDU&gt; writes:
&gt;I have recently seen several risks contributions which assumed that humans
&gt;are the cause of most system accidents and that if the human was somehow
&gt;replaced by a computer and not allowed to override the computer (i.e. to
&gt;mess things up), everything would be fine.

   I really don't think anyone is proposing this.  What people are proposing
is the use of computers to monitor data and alert humans to potentially
dangerous situations.  My understanding is that even minor failures at
nuclear power plants activate hundreds of alarms and warning indicators.
Clearly what is needed is an expert system to analyze the mass of incoming
data and summarize the situation to the human staff.  It can also react,
more quickly than humans can, but presumably it would be designed to seek
human approval before taking any drastic action.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
On-line Slot Machines
</A>
</H3>
<address>
Jeff Makey 
&lt;<A HREF="mailto:Makey@LOGICON.ARPA">
Makey@LOGICON.ARPA
</A>&gt;
</address>
<i>
28 Feb 86 15:53 PST
</i><PRE>

The following article, reproduced here in its entirety, appeared in the
25 February 1986 edition of the San Diego Tribune.

               Can Nevada handle new slot gimmick?

        LAS VEGAS (AP) - A slot machine promotion promising
      payoffs of $10 million to $15 million has been given the
      green light by the Nevada Gaming Commission, but not
      without some misgivings.

        Commission Chairman Paul Bible said he had
      reservations about slot cheats who might rig the
      machines for phony payoffs.  The progressive slot
      machine network, known as Megabucks, would be available
      in numerous hotels throughout Nevada and would be linked
      by a computer system to build up the huge jackpots.

        Ray Pike, an attorney for Megabucks manufacturer
      International Gaming Technology, said the company has
      made every effort to make the machine cheat-proof.

It sounds like they are using some sort of computer network to link a
bunch of slot machines together.  Without knowing more than the above
about the system it's hard to tell if they have vulnerabilities that
other financial networks (like ATMs) don't have.  Cheating a slot
machine is not the same (in most people's minds, I suspect) as stealing
from a bank, so -- with $10+ million at stake -- I'll bet (pun intended)
that someone will try to break the system soon.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-75</DOCNO>
<DOCOLDNO>IA012-000128-B044-379</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.20.html 128.240.150.127 19970217001955 text/html 15038
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:18:21 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 20</TITLE>
<LINK REL="Prev" HREF="/Risks/2.19.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.21.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 20</H1>
<H2> Sunday, 2 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks in Encryption 
</A>
<DD>
<A HREF="#subj1.1">
Jerry Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  NSA and encryption algorithms 
</A>
<DD>
<A HREF="#subj2.1">
Curtis Jackson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Low-Tech Computerized Voting 
</A>
<DD>
<A HREF="#subj3.1">
Harry S. Delugach
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risks in ballot-counting systems 
</A>
<DD>
<A HREF="#subj4.1">
Larry Campbell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Misdirected modems 
</A>
<DD>
<A HREF="#subj5.1">
Richard H. Lathrop
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Risks in Encryption
</A>
</H3>
<address>
&lt;<A HREF="mailto:Saltzer@Athena.MIT.EDU">
Saltzer@Athena.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 28 Feb 86 19:01:21 est
</i><PRE>

Dave Platt asks:

"Have any studies been done concerning the risks of having, or not having
a secure data-encryption scheme to guard the integrity of one's data?"

Studies I am not aware of, but my own informal observations suggest
that one of the biggest risks in using good quality encryption is that
when you come to use the data you may discover that

     a)  you have misplaced the key
     b)  it was encrypted with a different key than you thought
     c)  a few bits have been damaged in storage
     d)  something else went wrong

and the data is unusable garbage.  All these problems can be avoided,
of course, but only if very careful system design is applied to key
management and verification that the encryption was done right.  The
way to think of the problem is as follows: before you delete the
original cleartext you would like a very credible proof of the
theorem that "this stuff will be decipherable six months from now
when I want it."  After thinking about it you may decide to simply
copy the cleartext to a floppy disk and lock it in your desk.  At
least then you have some intuition about the list of threats you are
up against.

						Jerry

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
NSA and encryption algorithms
</A>
</H3>
<address>
&lt;<A HREF="mailto:ulysses!burl!rcj@ucbvax.berkeley.edu">
ulysses!burl!rcj@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
Sat, 1 Mar 86 14:56:43 est
</i><PRE>

&gt;international encryption standard sanctified by ISO.  The NSA (National
&gt;Security Agency) was lobbying very strongly within ANSI (the United States'
&gt;representative within ISO) to have DES disapproved...  the apparent reason
&gt;being that wide standardization of DES, and its routine use, would make it
&gt;substantially more difficult for NSA to monitor overseas voice and data
&gt;communications.  IBM pushed very strongly within ANSI for a "yes" vote

This is not the first time NSA has tried to stomp an encryption standard
for these reasons.  A few years back several business organizations (mostly
major banks and other financials) got together and came up with an
algorithm involving encrytion keys that were HUGE prime numbers (like
50-100 digits) to use in protecting sensitive financial data transmissions.
NSA stepped in and put tremendous pressure on them not to use this algorithm
-- seems it would take all their Crays about 3-4 days to break any given
transmission.  The pressure worked, the idea was dropped.

The MAD Programmer -- 919-228-3313 (Cornet 291)
alias: Curtis Jackson	...![ ihnp4 ulysses cbosgd mgnetp ]!burl!rcj
			...![ ihnp4 cbosgd akgua masscomp ]!clyde!rcj

P.S.:  I really don't remember where or when I read this, so correct me
(publicly, if I am wrong enough) if you can and don't ask me for more details
'cause that's all I remember.  Thanks!

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Low-Tech Computerized Voting
</A>
</H3>
<address>
"Harry S. Delugach" 
&lt;<A HREF="mailto:hsd%virginia.csnet@CSNET-RELAY.ARPA">
hsd%virginia.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Fri, 28 Feb 86 10:29:10 est
</i><PRE>

Our local elections are tabulated by computer. The balloting itself uses 
that ancient (but tangible) 80-column punch card placed in a holder with 
candidates' names, The voter uses a little punch next to the name. After 
voting, the card is placed in a sealed counter, under the eyes of a polling
official. Each ballot comprises a single card -- if you make a mistake, the 
election official tears up the card and gives you a new one.  This method is 
a long way from the technologist's state-of-the-art, but it fosters public 
confidence in the vote count, because each ballot exists as a piece of paper. 

My father has been a polling judge for many years. His precinct (in another
state) uses mechanical voting machines. To ensure an accurate count, one
person reads the total off the machine while a second person watches to 
double-check. A third person writes them in ink on a paper tally sheet, while
a fourth person double-checks. After the tallies are made, the *entire
machine* is sealed and sent downtown for checking. It would involve
the complicity of lots of pairs of people in many locations to make ballot-
stuffing work, and not just (perhaps) one or two dishonest programmers.
Not high-tech, but still reliable.

As the Philippine election suggests, the public's highest priority is its
trust in poll workers and the honesty of the count. The speed of the count 
is not as important.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Risks in ballot-counting systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:hplabs!topaz!harvard!wjh12!maynard!campbell@ucbvax.berkeley.edu">
hplabs!topaz!harvard!wjh12!maynard!campbell@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
Sun, 2 Mar 86 23:10:08 est
</i><PRE>
To: RISKS@SRI-CSL

&gt; [Even in paper ballot systems, there is usually a serial number which
&gt;  provides a back-link from the voter to the ballot.  Otherwise fraud is
&gt;  far too easy, with mystery ballots appearing out of nowhere.  But
&gt;  recall the earlier Phillipine election in which a local power failure
&gt;  downed the central ballot-counting computer, which upon reboot
&gt;  immediately finished the ballot counting.  Somebody has to be trusted
&gt;  somewhere.  There is a choice as to whom the trust must be given.  PGN]

I've never seen a voting machine, so I can't comment on them.  But I have
been active in Massachusetts state and local politics for a few years and
have always voted on paper ballots.  I've *never* seen any sort of serial
number and would be shocked to see such a thing.

When I vote, the following steps are involved:

    1.	I go to the first table and tell the person there my name
	and address.  She crosses my name off the voting list.

    2.	The person at the next table hands me a ballot.  There is
	no serial number on the ballot, and no notation is made
	on the voting list other than to cross off my name.

    3.	I mark my ballot and go to the other side of the room (away from
	the voting list table).

    4.	A person there, at the ballot box, takes my (folded) ballot and
	inserts it into the ballot box slot.  While I watch, the crank
	is turned to suck the ballot into the (locked) box.

There are a number of techniques used to prevent fraud.

    1.	Each political party designates one or more observers to oversee
	both the polling place and the counting of ballots.  Of course
	the observers are biased, but in opposite directions that hopefully
	cancel out.

    2.	The ballot boxes used here have a slot into which the ballot is
	inserted and a crank that's turned to suck it in.  I don't know,
	but the crank could also stamp the precinct number on the ballot.
	If fraud is suspected, you'd look for precincts turning in more
	ballots than they had registered voters.

    3.	The voting procedure is open to challenge at any time.  Voter lists
	are public information and are scrutinized before the election by
	political workers (I know, I have done this for a campaign).
	Anyone can go up to the polling place and challenge a vote ("I think
	Joe Shmoe is a pseudonym and I challenge his ballot").  When Joe
	Shmoe votes, his ballot is set aside as a challenged ballot and
	is verified separately.  Of course, in this case his ballot is
	marked (I presume by being placed in a sealed envelope with his
	name on it) but if he is verified as a legitimate voter then
	his ballot can be mixed in with the other ballots anonymously.
	(Just like an absentee ballot.)

	Of course, once the ballot is cast it's anonymous and can't be
	challenged in particular.  When I worked as an observer at the
	polls we were encouraged to challenge any voter or name that
	looked the least little bit fishy (of course, the unspoken rule
	was you'd only challenge voters wearing a button for the opposition).
	It doesn't hurt to challenge a ballot that turns out later to be
	valid (other than annoying the precinct workers) but if you fail
	to challenge a truly invalid ballot, it's pretty difficult to do
	anything about it after the fact.

Sorry about the length, but the gist of this is that, around here anyway,
once you investigate you find that there are enough checks and balances
to make fraud (not impossible but) unlikely, and also to guarantee secrecy.

If voting operates substantially differently in other parts of the country
I'd be interested in hearing about it.
--
Larry Campbell                                 The Boston Software Works, Inc.
ARPA: maynard.UUCP:campbell@harvard.ARPA       120 Fulton Street
UUCP: {harvard,cbosgd}!wjh12!maynard!campbell  Boston MA 02109

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Misdirected modems
</A>
</H3>
<address>
Richard H. Lathrop 
&lt;<A HREF="mailto:RICKL@OZ.AI.MIT.EDU">
RICKL@OZ.AI.MIT.EDU
</A>&gt;
</address>
<i>
Sun, 2 Mar 86 07:58 EST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

    RISKS-LIST: RISKS-FORUM Digest,  Monday, 24 Feb 1986  Volume 2 : Issue 14

    From: &lt;hp-sdd!hpfcla!ajs@nosc.ARPA&gt;
    Date: Mon, 24 Feb 86 11:12:54 pst

    Twice recently, computers at our company (Hewlett-Packard) have been the
    embarrassing causes of telephonic annoyance.  Phone numbers entered
    incorrectly in uucp L.sys files, due to typos or misunderstandings, have
    led to systems repeatedly calling private telephones in Fort Collins.
    The recipients of such calls, understandably annoyed, have had to
    backtrack through Mountain Bell to discover the cause.

    I bet this happens a lot more than anyone realizes or admits.

Yes, I suspect this does.  I am reminded of a time several years ago
when I was in Oregon working on a tide-monitoring system for NOAA (Natl.
Oceanic &amp; Atmospheric Admin.).  They were interested in accurate
measurements of tidal depth for navigation charts, storm surge &amp; tsunami
monitoring, etc., and we developed a remote station for them which would
measure the water depth to the nearest 1/100 inch every 6 minutes and
store the data in internal memory.  There were several of these
scattered along the coasts and Great Lakes, and every couple of days a
master controller would call them all up (at midnight, to take advantage
of lower phone rates &amp; line activities) &amp; drain their data.

At the time I was writing the Assembler telecommunication subsystem and
a partner was writing the Fortran user-interface and control system.
Since we only had one development machine, I was on a night schedule &amp;
he was on days.  Predictably (by 20-20 hindsight), while testing one
midnight the call was answered, not by our remote, but by a very sleepy
&amp; puzzled Michigan housewife (2:00 am there).  I suddenly found myself
on the line trying to explain that I was not a prankster, but that my
computer had dialed her up from Oregon and warbled at her, by mistake.

Of course, a typo had been made in the data file that specified the
phone numbers.  One thing to note about this incident is the separation
between the specification function (done on the daytime schedule) and
the test function (nights).  While it is always possible to err, this
separation precluded the possibility that we could cross-check each
other.

			-=*=- Rick Lathrop

rickl%oz@mit-ai

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-76</DOCNO>
<DOCOLDNO>IA012-000128-B044-401</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.21.html 128.240.150.127 19970217002008 text/html 10316
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:18:39 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 21</TITLE>
<LINK REL="Prev" HREF="/Risks/2.20.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.22.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 21</H1>
<H2> Monday, 3 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The risks of (not) using Robots 
</A>
<DD>
<A HREF="#subj1.1">
Hal Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computerized Voting Booths 
</A>
<DD>
<A HREF="#subj2.1">
Larry Polnicky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  No-carrier detection by misdirected modems 
</A>
<DD>
<A HREF="#subj3.1">
Dave Platt
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The risks of (not) using Robots
</A>
</H3>
<address>
&lt;<A HREF="mailto:Murray.pa@Xerox.COM">
Murray.pa@Xerox.COM
</A>&gt;
</address>
<i>
Mon, 3 Mar 86 18:56:03 PST
</i><PRE>
To: RISKS FORUM (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;

Workers are very good at bypassing systems designed to protect them.
Ducking under the fence to jump in front of the robot is just the tip of
the iceberg. Ask anyone who has worked around big machinery.

The standard interlock for a hand fed press is a pair of big buttons,
located at waist level, one on each side. You have to press both to
start the cycle. The operator is expected to use one hand on each
button, and hence can't have any fingers in the danger zone. Tape, feet,
hips, boards, ... The list is endless. (That description may be out of
date. OHSA has issued reams of rules over the past 10 years.)

If you have never seen the sort of press I'm thinking of, imagine a
machine that's 8-10 feet square at the base, 15 ft tall, and very
sturdy. It's got a lot of steel. There isn't any plastic in sight. There
is a motor that pumps up a big flywheel. Push the button(s), and a
clutch engages and the a crankshaft to turn the rotary motion of the
flywheel into an up-down motion driving a set of dies. Each ker-whump,
it spits out a piece of bent metal with holes in the right places. Small
ones make beer can openers and that size parts. Bigger ones make fenders
and washing machines from flat sheets of steel. This sort of machine is
the bread and butter of factorys. A row of them is a very impressive
sight and sound. They don't slow down at all if you leave your fingers
in the way.

The more robots we use, the more people will get injured or killed by
robots. The critical thing to notice is that most robots are being used
in places that were very dangerous for humans, and hence are probably
saving lives. (I think painting cars is the prime example.)

Anybody know where to get good numbers?

We need to consider the RISKS of not using robots/computers/you-name-it
as well as the RISKS of using them. Sure, we need to look for ways to
make things safer, but we shouldn't dismiss an idea because it isn't
100% safe. In fact, if we don't use robots enough, we are costing lives.
(Wait 'till that one hits the courts.)

To complicate things, people (and courts) get very irrational when
considering emotional issues like robots taking over jobs.

     [OK.  Remember, someone loses either way.  The question is this: which 
      loss is socially least reprehensible?  Optimization depends strongly 
      on your viewpoint.  A mining company has a view very different from
      that of the miner, which in turn differs from that of the ecologist.
      (Don't get caught in a robot of mine without an ore, or you'll
      have to pretend you are Ingot Berg-man.  Sorry.  That one smelt
      bad, but I have been trying for too long to remain unemotional
      about the risks of a robot taking over the RISKS Forum.)  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Computerized Voting Booths
</A>
</H3>
<address>
&lt;<A HREF="mailto: Polnicky%PCO@CISL-SERVICE-MULTICS.ARPA">
 Polnicky%PCO@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Mon, 3 Mar 86 07:30 MST
</i><PRE>
To:  RISKS@SRI-CSL.ARPA

       [This is Larry's response to Dave Platt's response in <A HREF="/Risks/2.18.html">RISKS-2.18</A>
       to Larry Polnicky's statement in <A HREF="/Risks/2.17.html">RISKS-2.17</A>..

  &gt; Date:  Friday, 28 February 1986 15:10 est
  &gt; From:  Dave Platt &lt;Dave-Platt at HIS-LA-CP6&gt;
  &gt; Subject:  Computer voting booths              [FULL TEXT IN <A HREF="/Risks/2.18.html">RISKS-2.18</A>]
  &gt; To:  Larry Polnicky &lt;Polnicky at HIS-PHOENIX-MULTICS&gt;
  &gt;
  &gt; GAAK!  Maybe I'm misunderstanding you, or the systems actually used in
  &gt; the computerized voting booths... but I had always believed that the
  &gt; voting systems in this country [paper, computer-based, or whatever] were
  &gt; designed to GUARANTEE A SECRET BALLOT!  I've NEVER heard of a
  &gt; public-voting system that was designed to permit anyone to identify a
  &gt; particular vote, or set of votes, with a particular voter.  ...

I understand the concerns for privacy.  Perhaps the sample that is checked-back
could give prior permission.  I'm sure there would be some who would give
up that right to privacy for the sake of helping to ensure a more reliable
election.  I would.  Indeed, many of us do when we discuss politics around
the office and reveal for whom we voted.  Last election, I voted by
absentee ballot, which associates my name with my vote, though granted not on
the ballot itself, but on the envelope in which it is mailed.  Computerization
has its costs; computer risk reduction will also cost something.

Larry Polnicky, Honeywell Information Systems, McLean, Virginia.

     [Once again, we tend to make naive assumptions that ignore the presence
      of back-pointers, audit trails, system programmers, maintenance folks,
      etc.  But then, we love to oversimplify.  The name of the game is to
      anticipate all reasonable risks, and then to make sure your design
      covers many of the unreasonable ones as well -- just in case.  Audit
      trails (for example) can be of great help (albeit after the fact),
      but they too can be bypassed, spoofed, or misused.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
No-carrier detection by misdirected modems
</A>
</H3>
<address>
&lt;<A HREF="mailto:Dave Platt <Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA> ">
Dave Platt &lt;Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA&gt; 
</A>&gt;
</address>
<i>
Mon, 03 Mar 86 11:01 PST
</i><PRE>

Some modems (such as the Racal-Vadic VS212P, of which I own one) do have a
voice-detection feature.  The VS212P can be optioned to determine that there
is something on the line which is neither (a) a carrier, (b) a busy signal,
or (c) a ringing signal; it submits the string "Voice!" through the RS232
port, waits ten seconds, and hangs up.

There are two slight problems with this, though... the modem is NOT
Hayes-compatible (although I understand that later models are), and the
voice-detection feature is not 100% reliable... it's possible for the modem
to fail to detect voice, or to report voice detection when it should be
reporting busy.  For that reason, the modem's standard option setting
disables voice detection.

I wonder what the results would be if all autodialing modems (&amp; their
software) did consider voice-detection [or anything other than carrier or
busy] to be a "trouble" condition that requires human intervention before
calling that number again.  My experience has been that a substantial number
of calls that "should" go through normally don't, for one reason or
another... congestion in a private phone network (the network switch
recording says "All circuits are busy, please stand by"), failed
long-distance trunk, destination system is down and is not answering the
phone for the moment, noise on the line that prevents carrier detection /
scrambler latch (not uncommon on long-distance calls using the 212
protocol), and so forth.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-77</DOCNO>
<DOCOLDNO>IA012-000128-B044-433</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.22.html 128.240.150.127 19970217002022 text/html 11659
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:18:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 22</TITLE>
<LINK REL="Prev" HREF="/Risks/2.21.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.23.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 22</H1>
<H2> Wednesday, 5 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Voting receipt 
</A>
<DD>
<A HREF="#subj1.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Voting booths 
</A>
<DD>
<A HREF="#subj2.1">
Jim McGrath
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computerized Voting 
</A>
<DD>
<A HREF="#subj3.1">
Tom Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Replacing humans with computers 
</A>
<DD>
<A HREF="#subj4.1">
Alan M. Marcum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Electricity's power 
</A>
<DD>
<A HREF="#subj5.1">
Marianne Mueller
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Voting receipt
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Tue, 4 Mar 86 09:47:20 est
</i><PRE>

Pardon my paranoia, but I would rather not agree, in advance, or afterwards,
to have my vote audited for whatever good purpose.  Absentee ballots are a
problem that I don't worry about too much today... but I might tomorrow.

Besides privacy/secrecy/retribution concerns, I might just forget... or lie... 
about how I voted.  I don't want to be asked to have my vote audited.  The 
fact that I accept or reject the request tells Big Brother something about
how I voted.  

Therefore, I suggest that the magic voting machine *offer* me a voting
"receipt" as soon as I complete my manipulation of its levers or buttons.
The "receipt" would contain the date, time, machine number, serial number of
the vote, and name the candidates and issues for or against whom/which I
voted.  It would NOT list my name.  The precinct voting records would show
only that I voted, in such a fashion as to prohibit tracking of my name to
my receipt number.

If I rejected the receipt, it would fall into a locked hopper, openable only 
upon completion of the voting period.  

If I accepted the receipt, I could check it immediately for accuracy, and ask
for a corrective procedure.  If it was OK, I could save it for a possible
recount; or trash it/burn it/shred and eat with milk &amp; prunes, whatever.  

Machine-retained receipts could be sampled against the retained electronic 
record by voting authorities.  

In the event of a recount, I could return my receipt to the voting organiza-
tion directly, or through a third party/blind drop/cutout or whatever.  

My receipt should probably also carry a checksum or other method of making it
difficult to tamper with the receipts.  

This proposal is neither fool- nor dictator-proof.  It does provide a method
for personal vote checking, a recount method, and preserves personal 
anonymity.  

	- Mike McLaughlin

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Voting booths
</A>
</H3>
<address>
"Jim McGrath" 
&lt;<A HREF="mailto:MCGRATH%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
MCGRATH%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue 4 Mar 86 22:44:16-EST
</i><PRE>
To: Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA
cc: risks@SRI-CSL.ARPA
Reply-to: mcgrath%mit-oz@mit-mc.arpa

    From: Dave Platt &lt;Dave-Platt%LADC@CISL-SERVICE-MULTICS.ARPA&gt;
    ....  There is a longstanding tradition in this country of
    guaranteeing that an individual can vote his or her conscience,
    without being identified afterwards as "the person who voted for
    Smidget for Congress".

Actually, the "longstanding tradition" is less than a century old (quite
short when you consider our history as spreading back hundreds of years into
colonial times).  Until a wave of reform around the turn of the century, it
was quite usual for the state not to provide any ballots at all.  Instead,
individual voters or local officials would provide the necessary paper.  As
time went on, it became common practive for the political parties to provide
the ballots used in the election.  Since ticket splitting was difficult, and
these ballots were quite distinctive, voting was hardly secret (I recall
that in the El Salvador Presidential election a few years ago the ballots
were of a different color, and the box was clear, making voting an open act).

All this information from my reading a few years back of the 3 election
volumes of the California State Code.

Jim

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computerized Voting
</A>
</H3>
<address>
Tom Benson
&lt;<A HREF="mailto:<T3B%PSUVM.BITNET@WISCVM.WISC.EDU>  ">
&lt;T3B%PSUVM.BITNET@WISCVM.WISC.EDU&gt;  
</A>&gt;
</address>
<i>
Tue, 4 Mar 86 16:27 EST
</i><PRE>
To:  RISKS@SRI-CSL.ARPA

Larry Polnicky and others have recently been discussing the risks of
computerized voting.  Surely the first principle ought to be the protection
of secret balloting rather than the promotion of the possible convenience of
computerized vote-counting.  There is a (perhaps slightly cumbersome)
solution to the problem of checking accuracy.  Suppose an electronic voting
booth, with a screen and some sort of simple keyboard.  In effect, a
menu-driven ballot on the screen.  The voter fills in his or her choices and
has a chance to go back and correct errors.  At that point, the voter pushes
a button to confirm the ballot, and a printer prints card ballot, which it
retains behind a transparent screen (it can be read but not altered).  Voter
scans the printed card and is asked whether it is accurate.  At this point,
if it is not, a REVISE or CANCEL button is pushed and the process starts
over with nothing having been recorded (the card is shredded).  When the
screen and card match the voter's intentions, a second CONFIRM button is
pushed and the card is ejected, while the vote is electronically forwarded.
The voter takes the card out of the booth and drops it in a ballot box.

This system would permit absolute secrecy for the individual voter, who
could not be traced to the card or the electronic vote.  But the cards would
be in a ballot box, where they could be counted by hand.  After the election, 
a representative random sample of precinct boxes would be counted by hand,
and matched to the electronic tally, just to audit accuracy.  And in the
case of a re-count, the entire election result could be counted by hand.

   Tom Benson, Department of Speech Communication,
   The Pennsylvania State University, 227 Sparks Building
   University Park, PA 16802           phone 814-238-5277

     {akgua,allegra,ihnp4,cbosgd}!psuvax1!psuvm.bitnet!t3b   (UUCP)
     t3b%psuvm.bitnet@wiscvm.arpa (ARPA)
     T3B@PSUVM    (BITNET)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Replacing humans with computers
</A>
</H3>
<address>
Alan M. Marcum, Consulting
&lt;<A HREF="mailto:sun!nescorna!marcum@ucbvax.berkeley.edu ">
sun!nescorna!marcum@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Mon, 3 Mar 86 19:57:58 PST
</i><PRE>
To: ucbvax!risks

In Risks-2.17, Nancy Leveson comments that

	There are reports that commercial pilots are becoming so
	complacent about automatic flight control systems that they are
	averse to intervene when failures do occur and are not reacting
	fast enough (because of the assumption that the computer must
	be right).

While that may be true, one of the things I learned very early during
flight training (I have a private pilot's license with an instrument
rating) is to constantly cross-check indications or directives from an
autopilot, navigation system, or flight control system.  If I have any
reason to suspect the autopilot or the navigation instruments (whether
it be a fault, or a low vacuum indication for vacuum-driven flight
instruments), I take corrective action.  It's my life up there, and
those of my passengers.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Electricity's power
</A>
</H3>
<address>
Marianne Mueller 
&lt;<A HREF="mailto:MASHA@WASHINGTON.ARPA">
MASHA@WASHINGTON.ARPA
</A>&gt;
</address>
<i>
Tue 4 Mar 86 20:45:07-PST
</i><PRE>
To: risks@SRI-CSL.ARPA

Monday saw the complete silencing of the cs lab at the Univ of Washington.
"A 13,000-volt feeder cable broke down from 1 a.m. till 4 a.m. but some
buildings on the east side of campus were without power till late in the
morning." (UW Daily, campus rag.)

Although the U's electric system is separate from the city's, "The blackout
in (60 surrounding blocks) occurred when the surge from the University
shutdown `jumped' the City Light circuit breakers that would normally
prevent the spread of a blackout.  Three major City Light circuits were
overloaded," the Daily notes.

So no one could do anything on Monday, the terminals were mercifully blank,
the halls deserted.  The hospital, however, ran on emergency power for three
hours, and they got plenty worried about it.  Our computers died since 3
hours without air conditioning was more than they could take.

Just for the record.

Marianne

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-78</DOCNO>
<DOCOLDNO>IA012-000128-B044-451</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.23.html 128.240.150.127 19970217002046 text/html 13090
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:19:15 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 23</TITLE>
<LINK REL="Prev" HREF="/Risks/2.22.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.24.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 23</H1>
<H2> Thursday, 6 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computerized voting 
</A>
<DD>
<A HREF="#subj1.1">
Jeff Mogul
</A><br>
<A HREF="#subj1.2">
 Larry Polnicky
</A><br>
<A HREF="#subj1.3">
 Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  ATM Ripoff 
</A>
<DD>
<A HREF="#subj2.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Internet importance/robustness 
</A>
<DD>
<A HREF="#subj3.1">
Tom Perrine
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computerized voting
</A>
</H3>
<address>
Jeff Mogul 
&lt;<A HREF="mailto:mogul@su-shasta.arpa">
mogul@su-shasta.arpa
</A>&gt;
</address>
<i>
5 Mar 1986 2307-PST (Wednesday)
</i><PRE>

    From: &lt;T3B%PSUVM.BITNET@WISCVM.WISC.EDU&gt;  (Tom Benson)
    Subject: Computerized Voting

    After the election, a representative random sample of precinct boxes
    would be counted by hand, and matched to the electronic tally, just to
    audit accuracy.

I'm afraid of the seeming reasonableness of this "solution".  If we are
using the audits to look for fraud in ballot-counting, then "who chooses the
`representative random sample'" becomes the interesting question; votes,
unlike decaying nuclei, are not uniformly distributed.  People who tend to
vote for candidate X might live in certain precincts (i.e., black people);
might vote at certain times of day (9-to-5 working people); might vote by
absentee ballot (older people).  If I had the ability to "cook" a voting
machine, I might just as easily have the opportunity to cook the "random
audit selector".

If we are using the audits to detect failures, rather than fraud, then we
must still check every machine and for all times of day, for the same
reason: to avoid disenfranchising a segment of the electorate, whether
inadvertently or intentionally.  Every vote counts: recall the senatorial
race in NH decided by 1 or 2 votes a few years ago, or (closer to where I
now live) the East Palo Alto incorporation election, decided by 13 votes and
still being challenged in the courts.

Another thing: mikemcl@nrl-csr (Mike McLaughlin) suggests
    The "receipt" would contain the date, time, machine number, serial
    number of the vote, and name the candidates and issues for or
    against whom/which I voted.  It would NOT list my name.

No, but the poll watcher who saw you vote and wrote down the machine
number and time of day next to your name wouldn't have much trouble
matching the receipt, if you ever returned it.

I'm not saying that non-computerized systems are immune to error;
but be careful that a technology that appears value-neutral (such
as "representative random sampling") isn't ignoring political reality
or creative dishonesty.

</PRE>
<HR><H3><A NAME="subj1.2">
 Computerized voting
</A>
</H3>
<address>
&lt;<A HREF="mailto: Polnicky%PCO@CISL-SERVICE-MULTICS.ARPA">
 Polnicky%PCO@CISL-SERVICE-MULTICS.ARPA
</A>&gt;
</address>
<i>
Thu, 6 Mar 86 08:11 MST
</i><PRE>
To:  RISKS@SRI-CSL.ARPA

I find the various suggestions to back up computerized voting with
physical ballotting as taking steps in the wrong direction.  Certainly
we can reduce risks by backing up computer/automated systems with human
beings, where feasible, but to keep around a bunch of punched cards in
order to ensure the integrity of electronic voting seems to me to be the
wrong approach.

Larry Polnicky, Honeywell Information Systems, McLean, Virginia.

</PRE>
<HR><H3><A NAME="subj1.3">
Computerized voting
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Thu 6 Mar 86 17:33:34-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

This is not a VOTIVE message; I have broken my vow to remain silent while
watching the schemes for voting integrity get wilder and less controllable.
DEVOTED as I am, I can no longer keep silent.  My main point here is that as
more complex mechanisms are added to control or audit the integrity of the
voting process, the more vulnerabilities are likely to be introduced, and
the less controllable the whole process is likely to be.  Nancy Leveson
makes a similar point in her survey paper on software safety: as complexity
is added to control safety, the more things get out of hand.  I am prompted
to drag out my old Albert Einstein quote -- for our newer readers:
  
  Everything should be made as simple as possible, but not simpler.

There is intrinsic complexity in the voting process.  A voting scheme with
no controls is easy to misuse.  A voting scheme with many controls can also
be misused, but in different ways -- perhaps requiring greater subtlety.
Furthermore, such a computerized system must be used and administered by
ordinary mortals; however, elaborate procedures tend to break down or be
vulnerable.  Furthermore, remember that many of the programs controlling
elections are written by just a few software houses.  The potential for
Trojan-horsing around is enormous.  A gifted system programmer can pull off
all sorts of things.  We have already seen cases of data changed on the fly
in computer-counted ballots, even with consistency checks and audit trails
(which themselves can be fudged).  One can dream up all sorts of checks and
balances -- formal verification of the algorithms, crypto seals on the
stored code for integrity, encryption schemes to detect added ballots, and
so on, but there are always points of vulnerability.

So, in the discussions here, please let us try to be realistic!

Peter

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
ATM Ripoff
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@purdue-ecn.ARPA ">
davy@purdue-ecn.ARPA 
</A>&gt;
</address>
<i>
Thu, 6 Mar 86 08:59:55 EST
</i><PRE>

   WASHINGTON (UPI) - A computer glitch enabled a man to get away with
$140,000 in $10- and $20-bills in a weekend run on 16 automatic teller
machines in the nation's capital and its Virginia suburbs, the Secret
Service said Wednesday.
   Michael Caputo, 31, of Fairfax Station, Va., admitted in federal
court Tuesday to using a stolen VISA credit card to make more than 400
withdrawals from the money machines last October.
   The withdrawals represent the largest fraud committed agains VISA
with an automatic teller machine, officials said.
   "Why didn't someone else in line notice it?" asked John Magaw, a
Secret Service agent.  "It's very bizarre.  All of a sudden this guy
realized how good he had it.  His pockets just weren't big enough.
The machines just weren't programmed to stop."
   Caputo was photographed by monitors at the 16 mechanized tellers
receiving $300 during each transaction - at times smiling while other
times holding bags of money.
   "Normally, you can't take more than $200 at a time, and (most
machines) will not allow you on nights and weekends to go beyond a
certain limit," Magaw said.  "Somehow, the safeguards broke down to
allow for that to happen."
   Magaw said that Caputo apparently used the VISA card at two banking
institutions.  He said that the two computers did not "blend together,"
and allowed him to take large amounts of money without being detected.
   "It's like having a Chevrolet and a Buick and putting a carburetor
from one on the other," Magaw explained.  "You may get it to work, but
it just doesn't quite go together.  There's glitches that have to be
worked out."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Internet importance/robustness
</A>
</H3>
<address>
Tom Perrine 
&lt;<A HREF="mailto:tom@LOGICON.ARPA">
tom@LOGICON.ARPA
</A>&gt;
</address>
<i>
6 Mar 86 16:50 PST
</i><PRE>

The following message, which was in the tcp-ip list from SRI-NIC was in
discussions of Internet (ARPA/MIL) Mailbridge performance.  I think it is
interesting from a RISKS point of view.  How much does the computer
science, aerospace, etc industry/research depend on the Internet?? What are
the consequences of a long-term failure of ARPAnet? How suceptable is the
ARPANET to terrorism/natural disaster/etc. ?
------BEGIN INCLUDED PORTIONS ------
  &gt;Date:  3 Mar 1986 17:03:11 EST
  &gt;From: Edward A. Cain &lt;cain@EDN-UNIX.ARPA&gt;
  &gt;Subject: Re: Mail Bridge Performance
  &gt;To: gross@mitre.ARPA (Phill Gross)
  &gt;
  &gt;Phill,
  &gt;
  &gt;Thanks for the summary of mailbridge traffic. I think it does partially
  &gt;explain why performance is so awful at times thru the mailbridges. The
  &gt;correlation with school schedules is interesting, too, and probably a better
  &gt;guess than any I've heard recently.
  &gt;
  &gt;There is one other important consideration. Performance on the ARPANET alone
  &gt;has been terrible at times. For example, ICMP ECHO and ECHO REPLY round-trip
  &gt;measurements between east and west coast hosts were averaging 18 seconds on 
  &gt;Feb 3-4, with tails of the delay distribution out to 37 seconds, as measured
  &gt;from DCEC (via arpanet) and at BRL (via milnet). Delays were very high
  &gt;again during the Feb 12-14 time period. Even worse, on Feb 20th, one hour
  &gt;in the afternoon the roundtrip delay from DCEC to the arpanet interface of
  &gt;the ISI mailbridge was 30-40 seconds, and from DCEC to the arpanet
  &gt;interface of the SRI mailbridge the delays were 45-47 seconds during the
  &gt;same hour, with 90% packet loss!!! 
  &gt;
  &gt;Usually, this kind of behavior on the arpanet is coincident with the outage
  &gt;of key lines or nodes in the arpanet. On Feb 20th for example, line 76
  &gt;(utah to lbl2) and line 76 (sri2 to collins) were both down most of the
  &gt;day because of flooded cableheads.!!! The loss of a key component in the
  &gt;arpanet seems to create serious congestion when the traffic goes up. And
  &gt;congestion is noticed quickly by the mailbridges, which are among the
  &gt;busiest arpanet hosts in terms of both packets sent and connection blocks
  &gt;used (in the IMP).
  &gt;
[REST OF MESSAGE TRUNCATED]
  &gt;Ed Cain


The recent message about flooded cableheads and the potential vulnerability
of the internet to loss of critical components made me wonder:

  How many IMPs are there on the ARPA side?                  [Hundreds]

  How many on the MILNET side?                               [Hundreds]

  Where are they? I would assume that at least the MILNET IMPs are
  in secure areas.          [Not necessarily, but they are under the 
                             control of DCA and BBN.  That helps.  PGN]

Tom Perrine

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-79</DOCNO>
<DOCOLDNO>IA012-000128-B044-468</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.24.html 128.240.150.127 19970217002058 text/html 10818
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:19:27 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 24</TITLE>
<LINK REL="Prev" HREF="/Risks/2.23.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.25.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 24</H1>
<H2> Saturday, 8 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computerized ballot stuffing 
</A>
<DD>
<A HREF="#subj1.1">
Andy Kegel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Progress report on computerized voting 
</A>
<DD>
<A HREF="#subj2.1">
Kurt Hyde
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Wild Modems 
</A>
<DD>
<A HREF="#subj3.1">
Bjorn Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Misdirected modems 
</A>
<DD>
<A HREF="#subj4.1">
Phil Ngai
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Power outages 
</A>
<DD>
<A HREF="#subj5.1">
Phil Ngai
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Earthquake problems with Nuclear Reactors 
</A>
<DD>
<A HREF="#subj6.1">
Lindsay F. Marshall
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computerized ballot stuffing
</A>
</H3>
<address>
ihnp4!ihuxn!agk@ucbvax.berkeley.edu 
&lt;<A HREF="mailto:Andy Kegel">
Andy Kegel
</A>&gt;
</address>
<i>
Fri, 7 Mar 86 08:23:30 PST
</i><PRE>

In our area (extreme suburban Chicago, aka "the boonies"), we use a
computer-counted paper-ballot voting mechanism.  I am fairly sure I recall
serial numbers on the ballots.  However, I recognize that human memory is
weak and subject to interpretation and assumptions.  There is an election
coming up this month, and I will be particularly careful to observe and
understand the relevant facets of the process.

Remember, in Chicago, the rule is "Vote Early, Vote Often."

This message does not represent the position of my employer, or
any individuals or organizations other than myself.

	-andy kegel      

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Progress report on computerized voting
</A>
</H3>
<address>
Kurt Hyde DTN 264-7759 MKO1-2/E02
&lt;<A HREF="mailto:hyde%topcat.DEC@decwrl.DEC.COM  ">
hyde%topcat.DEC@decwrl.DEC.COM  
</A>&gt;
</address>
<i>
Friday,  7 Mar 1986 05:57:00-PST
</i><PRE>

A sincere thank you to all the people who have responded to my request
for assistance in computerized voting standards.

I called New Hampshire's Secretary of State and he will be meeting
with me and some other people regarding security standards. I will 
be proposing something like the following:


  Computerized voting booths should print a paper ballot for each voter
  to view and check for accuracy.  The hardcopy ballot must be visible
  to the voter by appearing under a covered (transparent) window.  The 
  dimensions of the window must allow for at least 10 votes to be viewed
  at one time.  The printer must then feed each ballot into a ballot box
  which is guarded from access outside access while the voting machine
  is in use.  The audible signal which confirms that the voter is completed
  may occur after the hardcopy of the ballot is no longer in view.

  In order to protect the anonymity of the voter casting each ballot, 
  each ballot must be on a separate piece of paper when deposited in
  the ballot box.  It may be be cut after printing or be sheet-fed into
  the printer.

  This additional functionality allows for a recount.  The current 
  machines do not have the capability of recounting the ballots.  They
  only have the capability to recalculate from subtotals.  

  Because of recount capability, it will be possible to resolve election
  disputes at the place of the voting.  This means it will not be 
  necessary to contact the FEC and National Bureau of Standards in
  order to perform an audit on the machine's computer programs.
  The procedure for the FEC and NBS to audit the machine's computer 
  programs has not been established and is likely to be extremely
  complex as certainly procedures must be established to be certain
  that the computer programs haven't been tampered with in order to 
  return them back to their proper state.

My students at Rivier College will still be investigating further into
the proper security controls.  One of them is considering a way to let
the voter see his/her ballot and abort that ballot.  The printer would
then print an appropriate message such as "CANCELLED" on the bottom.

Once again, let me thank all those who are participating.  Your assistance
is very valuable and appreciated.  Let us not let the United States
suffer from a similar disaster as the Phillipines.

                                      Kurt

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Wild Modems
</A>
</H3>
<address>
Bjorn Benson
&lt;<A HREF="mailto:sun!fluke!uw-beaver!entropy!dataio!bjorn@ucbvax.berkeley.edu ">
sun!fluke!uw-beaver!entropy!dataio!bjorn@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Wed, 5 Mar 86 16:50:59 pst
</i><PRE>
Newsgroups: mod.risks
Organization: Data I/O Corp., Redmond WA

All this talk in RISKS about modems calling humans rather than computers
reminded me of an article I read about telecomputing in Europe: it seems
that laws in Europe require modems to have equipment attached to explain
what is going on in four languages, should the computer happen to dial
a wrong number.

						Bjorn N Benson

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Misdirected modems
</A>
</H3>
<address>
Phil Ngai
&lt;<A HREF="mailto:amdcad!phil@decwrl.DEC.COM ">
amdcad!phil@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
Sat, 8 Mar 86 00:34:30 pst
</i><PRE>

This is an often repeated wives tale by people who ought to know better.
With ordinary dialup modems of the 103/212 class, it is the *answering*
modem which initiates a tone. The originating modem (the one that dialed)
remains silent until it hears the carrier of the answering modem.

Thus, if a computer dialed a wrong number, the person receiving
the call would hear nothing, not a "funny whistle".

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
power outages
</A>
</H3>
<address>
Phil Ngai
&lt;<A HREF="mailto:amdcad!phil@decwrl.DEC.COM ">
amdcad!phil@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
Sat, 8 Mar 86 00:46:23 pst
</i><PRE>

I am familiar with AMD's data center. It is relatively small by comparison
to some sites, having only four IBM 3081s and one 3090, but it does have
battery backup and a huge dual turbo charged diesel generator. The diesel
has a thousand gallon fuel tank, which will last it 24 hours. We have
arrangements to get refills within that 24 hour period, so our data center
could presumably survive an indefinite outage and you could continue to
order chips from us even during a blackout!

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Earthquake problems with Nuclear Reactors.
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk">
ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk
</A>&gt;
</address>
<i>
Fri, 7 Mar 86 10:20:51 gmt
</i><PRE>

This is not really computer related, but seems interesting all the same....

A recent article in The Guardian highlighted some investigations into the
safety of British nuclear reactors in the face of the kind of mild earthquakes
that we have here. In particular it mentioned the Calder Hall reactor which
is nearly 25 years old and is built quite near to the area of Britain that
has the most earth tremors. This installation has a reactor vessel weighing
2000 tons suspended 18ft above the ground which is now so radioactive that
it would be impossible to examine or modify. The investigation showed that
the original safety calculations "had been done on the back of an envelope"
and that the reactor bolts might shear with an earthquake of 0.5 (units?).
There was an earthquake of that intensity last year, but it is impossible to
find out if anything was damaged because of the intensity of the radiation 
not forgetting the 5ft of concrete and steel surrounding the chamber.......

So if you hear that Newcastle vanished, you'll know why!

           [and we'll be back to carrying coals ...  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-80</DOCNO>
<DOCOLDNO>IA012-000128-B045-7</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.25.html 128.240.150.127 19970217002119 text/html 13920
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:19:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 25</TITLE>
<LINK REL="Prev" HREF="/Risks/2.24.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.26.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 25</H1>
<H2> Monday, 10 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Balloting 
</A>
<DD>
<A HREF="#subj1.1">
Barbara E. Rice
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Canceling ballots 
</A>
<DD>
<A HREF="#subj2.1">
Jim McGrath
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Bank robbery 
</A>
<DD>
<A HREF="#subj3.1">
Curtis Jackson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Earthquake problems with Nuclear Reactors 
</A>
<DD>
<A HREF="#subj4.1">
throopw
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Modems DON'T WORK AS SUPPOSED 
</A>
<DD>
<A HREF="#subj5.1">
Brent Chapman
</A><br>
<A HREF="#subj5.2">
 Martin J. Moore
</A><br>
<A HREF="#subj5.3">
 Phil Ngai
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Balloting
</A>
</H3>
<address>
Barbara E. Rice
&lt;<A HREF="mailto:rice@nrl-csr ">
rice@nrl-csr 
</A>&gt;
</address>
<i>
Mon, 10 Mar 86 12:43:50 est
</i><PRE>

     There has been much discussion on the net as to the secrecy of
ballots. No one has mentioned yet the situation I find myself in
regularly  with the absentee ballot system. My name is printed on the
outside of the envelope and I assume checked off when it arrives at its
destination to insure that I don't vote 2 or more times.  What is to
prevent someone from just taking a peek and seeing who I voted for.  In
fact I have never heard what the method is to insure that my name and
who I vote for are not put together.  There is a simple way to check
this out to see if my vote is secret but I do not have the courage to
try it.  All I would need to do is vote a straight communist ticket.  If
my security clearence is revoked in the next six months it would be safe
to assume my vote is not secret.  Anyone know of a non-career
threatening way to check this out?
Barb R.
  
</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Canceling ballots
</A>
</H3>
<address>
"Jim McGrath" 
&lt;<A HREF="mailto:MCGRATH%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
MCGRATH%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Mon 10 Mar 86 22:12:18-EST
</i><PRE>
To: risks@SRI-CSL.ARPA
cc: MCGRATH%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU, hyde%topcat@DECWRL.DEC.COM
Reply-to: mcgrath%mit-oz@mit-mc.arpa

  Subject: Progress report on computerized voting
    From: hyde%topcat.DEC@decwrl.DEC.COM  (Kurt Hyde DTN 264-7759 MKO1-2/E02)
    My students at Rivier College will still be investigating further
    into the proper security controls.  One of them is considering a
    way to let the voter see his/her ballot and abort that ballot.
    The printer would then print an appropriate message such as
    "CANCELED" on the bottom.

I can see a lot of potential problems with canceling already printed
ballots.  In particular, any technology that takes a ballot which
would, by default, be valid and then modifies it to be invalid could
be used to invalidate valid ballots after the polls have been closed.
Moreover, if the technology fit in a voting booth, then it is probably
portable enough so that such modifications could be done on site (i.e.
without physically removing the ballots to an unauthorized location).

I would thus suggest that you use some sort of display (CRT, LED, or
just light bulbs next to the appropriate names) for voter
confirmation.  Failing that, you should print out the ballot as
before, but on white (say) paper.  If the voter confirms the ballot,
then the white copy is stamped CANCELED, a duplicate is printed on
red (say) paper, and both are deposited in separate boxes.  While both
copies would be kept, only the red copy would be treated as
authoritative.

You can still forge red ballots (you can forge any paper ballots).
But you cannot turn a red ballot into a white one by using a CANCEL
stamp or somesuch.  Only gross mutilation or removal of the ballot
from an authorized area could cancel the valid ballot - both harder to
do (at least undetected).


Jim

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
bank robbery
</A>
</H3>
<address>
&lt;<A HREF="mailto:ulysses!burl!rcj@ucbvax.berkeley.edu">
ulysses!burl!rcj@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
Sat, 8 Mar 86 20:45:11 est
</i><PRE>
Organization: AT&amp;T Technologies @ Burlington, NC

I read an excellent book a few years ago simply entitled "Computer Crime".
                                       [PRESUMABLY BY DONN PARKER?  PGN]
I highly recommend it to the readers of mod.risks.  Here are a couple
of example horror stories from the book (from memory, sorry):

  a) A guy gets a bank loan, when he gets his payment book he sends in the
  *last* payment slip from the book with his first payment.  The bank's
  computer sends him a cheerful letter congratulating him on settling his
  debt in a timely manner.

  b) A guy opens an account at a major NYC bank with several thousand dollars.
  After he gets his personalized checks, he goes to a shady printer friend
  and has the guy print up identical checks but with a bogus magnetic number
  on the bottom.  He then goes on a $1,000,000 check-writing spree.  Every
  time on large purchases they call his bank and electronically verify that
  he can cover the check.  Every time the sorting machine at the bank sees
  the leading ?3?-digit code of a West Coast bank, and automatically mails
  the check there.  The West Coast bank's sorter kicks the check out to
  manual sorting because it has a bogus account number.  The human sorter
  takes one look at the check and sees the name of the NYC bank and blithely
  mails it back...  They finally got onto him when one of the checks had
  been through so many sorter and mailer machines it was nearly in shreds,
  and the human sorter on the West Coast got curious enough to look at the
  magnetic ink number.

  c) Guy opens an account in a Washington, D.C. bank.  He rips off several
  pads of blank deposit slips from the lobby of said bank, takes them to
  a location (?maybe he worked at the place?) that has a magnetic ink
  typewriter.  He laboriously types his own account number on the bottom
  of all the slips, then places the pads back in the lobby of the bank.
  A month later he withdraws $100,000 and disappears.

The MAD Programmer -- 919-228-3313 (Cornet 291)
alias: Curtis Jackson	...![ ihnp4 ulysses cbosgd mgnetp ]!burl!rcj
			...![ ihnp4 cbosgd akgua masscomp ]!clyde!rcj
       [OLD STUFF, BUT WHY NOT?  WE HAVEN'T HAD THEM HERE BEFORE.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Earthquake problems with Nuclear Reactors
</A>
</H3>
<address>

&lt;<A HREF="mailto:mcnc!rti-sel!dg_rtp!throopw@seismo.CSS.GOV">
mcnc!rti-sel!dg_rtp!throopw@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Mon, 10 Mar 86 17:33:22 est
</i><PRE>
Apparently-To: mcnc!seismo!risks%sri-csl

&gt; From: "Lindsay F. Marshall" &lt;ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk&gt;
&gt; Subject: Earthquake problems with Nuclear Reactors.
&gt; [...]
&gt; So if you hear that Newcastle vanished, you'll know why!
&gt;            [and we'll be back to carrying coals ...  PGN]

Ok, ok, cute, I laughed, I liked it.  But nuclear paranoia being what it
is, and with no smiley, this seems to me to be blatantly inaccurate, and
worthy of clarification.  As far as I know, nothing short of refining
the fuel and making a bomb out of it can cause a power reactor to
explode with a large yield.  Or perhaps the two of you know of some
other way that a power reactor can cause a city to "vanish" (implying a
sudden, physical removal of the city from existence or perception)?

        [Whatever happened to Sverdlovsk -- or was that biological?  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
103/212 modems DON'T WORK AS SUPPOSED (10% of the time?)
</A>
</H3>
<address>
Brent Chapman
&lt;<A HREF="mailto:chapman%miro@BERKELEY.EDU ">
chapman%miro@BERKELEY.EDU 
</A>&gt;
</address>
<i>
Sun, 9 Mar 86 02:00:47 PST
</i><PRE>
Organization: University of California, Berkeley

In article &lt;8603081745.AA20185@ucbvax.berkeley.edu&gt; Phil Ngai writes:
  &gt;RISKS-LIST: RISKS-FORUM Digest,  Saturday, 8 Mar 1986  Volume 2 : Issue 24
  &gt;
  &gt;Date: Sat, 8 Mar 86 00:34:30 pst
  &gt;From: amdcad!phil@decwrl.DEC.COM (Phil Ngai)
  &gt;To: risks@sri-csl.ARPA
  &gt;Subject: Re: Misdirected modems
  &gt;
  &gt;This is an often repeated wives tale by people who ought to know better.
  &gt;With ordinary dialup modems of the 103/212 class, it is the *answering*
  &gt;modem which initiates a tone. The originating modem (the one that dialed)
  &gt;remains silent until it hears the carrier of the answering modem.
  &gt;
  &gt;Thus, if a computer dialed a wrong number, the person receiving
  &gt;the call would hear nothing, not a "funny whistle".

Sorry, maybe that's how it's SUPPOSED to work, but it just doesn't happen
that way.  I work with several 103/212 class modems, and every one of them,
at least 10% of the time, "responds" to a "carrier" before there actually is
one.  There appear to be no fixed, recognizable reasons for this.  They will
respond to rings, busy signals, or someone picking up the line.  All of
these modems are recent models, purchased within the last year, so I don't
think it's a problem of out-of-date technology.

Brent Chapman
chapman@miro.berkeley.edu
ucbvax!miro!chapman

</PRE>
<HR><H3><A NAME="subj5.2">
Re: misdirected modems
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

&gt; From: amdcad!phil@decwrl.DEC.COM (Phil Ngai)
&gt; This is an often repeated wives tale by people who ought to know better.
&gt; With ordinary dialup modems of the 103/212 class, it is the *answering*
&gt; modem which initiates a tone. The originating modem (the one that dialed)
&gt; remains silent until it hears the carrier of the answering modem.
&gt; Thus, if a computer dialed a wrong number, the person receiving
&gt; the call would hear nothing, not a "funny whistle".

True, the answering modem normally initiates a tone first.  However, some
103/212-class modems (e.g., the Hayes Smartmodem 1200 which I use at the office
and the similar Prometheus P1200A which I use at home) will start a tone after
a few seconds regardless of whether the answering modem starts one.  I have
the speaker on during the dialing and connection process, and both modems
always start a tone whenever a call fails to go through or gets a wrong number
(one or the other happens about 10% of the time.)  Anyone who is skeptical of
this is welcome to drop by my office and I'll be happy to demonstrate it. 
In fact, I whistled at some poor soul on a wrong number while dialing in for
this terminal session! 
                                marty moore (mooremj@eglin-vax.arpa)

</PRE>
<HR><H3><A NAME="subj5.3">
Re: misdirected modems 
</A>
</H3>
<address>
Phil Ngai
&lt;<A HREF="mailto:amdcad!phil@decwrl.DEC.COM ">
amdcad!phil@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
Mon, 10 Mar 86 17:42:34 pst
</i><PRE>

I have a Hayes and I just tried it and it does not
whistle at me.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-81</DOCNO>
<DOCOLDNO>IA012-000128-B045-30</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.26.html 128.240.150.127 19970217002131 text/html 9195
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:20:00 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 26</TITLE>
<LINK REL="Prev" HREF="/Risks/2.25.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.27.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 26</H1>
<H2> Friday, 14 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Integrity of the Electoral Process 
</A>
<DD>
<A HREF="#subj1.1">
Mark Jackson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Ballot Secrecy 
</A>
<DD>
<A HREF="#subj2.1">
Lindsay F. Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Nuclear waste-land 
</A>
<DD>
<A HREF="#subj3.1">
Jerry Mungle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Nuclear disasters 
</A>
<DD>
<A HREF="#subj4.1">
Lindsay F. Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  103/212 modems 
</A>
<DD>
<A HREF="#subj5.1">
Ephraim
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Integrity of the Electoral Process
</A>
</H3>
<address>
&lt;<A HREF="mailto:MJackson.Wbst@Xerox.COM">
MJackson.Wbst@Xerox.COM
</A>&gt;
</address>
<i>
12 Mar 86 11:39:29 EST (Wednesday)
</i><PRE>
To: RISKS@SRI-CSL.ARPA

It seems to me that the discussion has strayed from the mark.  No balloting
procedure is completely unbreakable.  Current systems appear to be
reasonably secure, but this is primarily due to effective vigilance (e.g.
poll watchers from each party).  When enough of the "system" falls under the
effective control of a single organization then fraud becomes possible,
hence inevitable (e.g. Chicago under the Machine).

The "risk" involved in computerization of the ballot collection and counting
process is the centralization of much of the process under the control of a
single organization (hardware and software system).  The challenge is to
assure that the resulting system is sufficiently distributed and subject to
routine checks so that the potential for fraud is not increased.

Apropos of this, it is not clear to me that the proposal for printing
individual ballot hardcopies addresses what would otherwise be an
*increased* risk.  For example, with lever-type voting machines is some
record kept beyond the candidate tallies read out when the polls close?

Mark
      [Apparently no individual record is kept -- only the running totals. 
       Fraud-prevention is largely dependent on the poll watchers.  But it
       may be relatively easy to vote twice in a large and noisy room if your
       machine is facing away from the poll watchers back-to-back with
       another machine facing the other way -- unless the system is set up
       so that it has to be rearmed manually each time the exit-lever
       automatic vote recorder is triggered.

       There are always some vulnerabilities, as I noted in <A HREF="/Risks/2.23.html">RISKS-2.23</A>,
       including bribed officials.  The recent election in the Philippines
       give us another datapoint.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Ballot Secrecy
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk">
ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk
</A>&gt;
</address>
<i>
Wed, 12 Mar 86 11:28:38 gmt
</i><PRE>

One of my regular grouses to Clerks at election time is that the Ballot
is not actual secret. They always say "oh yes it is", but when you point out
that each voting slip is stamped with a serial number (when you get the
paper) which is recorded in such a way that it can be traced back to you,
they then say "Oh, but that's in case there is any Ballot Rigging so that
we can backtrack to find multiple votes etc.". The ballot in UK elections
is most definitely not "secret" in the sense that most people assume, though
there is no evidence that anyone is checking out how you voted (yet).

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Nuclear waste-land
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
11 Mar 1986 06:26:43 PST
</i><PRE>
From: Jerry Mungle &lt;JMUNGLE@USC-ISIF.ARPA&gt;
To: RISKS FORUM (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;

Re: Nuclear power plant accidents...

  The explosion in the USSR was due to storage of nuclear waste, not a 
power plant accident.  However, seems I recall there are some low probability
(aren`t they all) accidents which can send a breeder reactor into a low yield
explosion (probably *very* dirty, too).

  Two tangental comments - I live near TVA's Browns Ferry reactors.  ALL of the
operators failed NRC license tests(!) so BF has been shut down till 80% can
pass.  Is there a license for reactor control software, and if not, perhaps
TVA might be a good place to test (worst case operator actions and all that)?

  Second, there is a siren to alert the population to a BF accident with a
leak.  Nearby is a state prison with an occasional leak.  People have
suggested a siren to warn of escapes, but the chance for confusion is high.
Anyone know of a good way to spread an alarm when you have multiple risks??

  (ps. smiley face to the TVA test suggestion....)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Nuclear disasters
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk">
ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk
</A>&gt;
</address>
<i>
Wed, 12 Mar 86 11:24:01 gmt
</i><PRE>

The last line was a joke - the problem with 2000ton reactor vessels dropping
18ft is not explosion but one of contamination. The radiation leakage would
be huge and most of the South of Scotland and North of England would be
affected. If it actually happened Newcastle might just as well have
vanished......

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
103/212 modems [Will the messages never cease?]
</A>
</H3>
<address>
&lt;<A HREF="mailto:ucdavis!lll-crg!seismo!harvard!encore!vaxine!wanginst!wang!ephraim@ucbvax.berkeley.edu ">
ucdavis!lll-crg!seismo!harvard!encore!vaxine!wanginst!wang!ephraim@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Tue, 11 Mar 86 18:27:52 est
</i><PRE>

In <A HREF="/Risks/2.24.html">RISKS-2.24</A>, Phil Ngai writes:
&gt; This is an often repeated wives tale by people who ought to know better...

As it happens, I can testify that Phil's statement is not correct, or at
least not universally so.  On Sunday 3/9, I called the modem line of a friend
using my Applemodem 1200.  His modem was not ready, so he answered the call
manually and said "hello" to get my attention.  He tells me that my modem
*did* produce carrier when he picked up the phone.

Sorry, Phil.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-82</DOCNO>
<DOCOLDNO>IA012-000128-B045-56</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.27.html 128.240.150.127 19970217002152 text/html 17270
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:20:18 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 27</TITLE>
<LINK REL="Prev" HREF="/Risks/2.26.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.28.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 27</H1>
<H2> Saturday, 15 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Overload of a different sort [Air traffic stoppage] 
</A>
<DD>
<A HREF="#subj1.1">
Ted Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Cordless Phones Cry Wolf! 
</A>
<DD>
<A HREF="#subj2.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  The Mob Breaks into the Information Age 
</A>
<DD>
<A HREF="#subj3.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  [Non]computerized train wreck 
</A>
<DD>
<A HREF="#subj4.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Ballot Integrity; Specialization in Decision-Making 
</A>
<DD>
<A HREF="#subj5.1">
Tom Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Network Security, Integrity, and "Importance" 
</A>
<DD>
<A HREF="#subj6.1">
Kurt F. Sauer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Modems 
</A>
<DD>
<A HREF="#subj7.1">
James R. McGowan
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Overload of a different sort [Air traffic stoppage]
</A>
</H3>
<address>
&lt;<A HREF="mailto: TMPLee@DOCKMASTER.ARPA">
 TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 14 Mar 86 12:26 EST
</i><PRE>
To:  Risks@SRI-CSL.ARPA

This may or may not involve a computer, but I think it did.  Those of
you travelling in the Southeast yesterday were made well aware that the
Atlanta airport was thrown into a complete chaos by the thunderstorms in
the area, and this rippled throughout the air transport system.  To make
a long story short, I managed to get out of Augusta on a plane that was
five hours late, which was okay since that had me leaving Augusta only
two hours after I was supposed two, and my connecting flight was also
two hours late.  The computer part is this.  After we boarded in Atlanta
the pilot announced he had called for his air traffic control clearance
and was told that flow control into Minneapolis was in effect and there
would be an indefinite delay.  Those of you who have had nothing to do
with air traffic control may not realize that in the late 60's or early
70's a change was made in the way the over-all air traffic was
controlled:  instead of stacking planes up over destinations when
traffic got crowded, a national system was instituted to monitor and
control the general flow, not allowing a plane to depart until there was
a clear slot for it to land in.  This is all coordinated between the
terminal air traffic control computers and a central computer in
Washington.  Anyway, we sat for about another half hour and the pilot
called again.  Same answer.  He and/or the Delta operations people used
a little common sense:  the weather in Minneapolis was just fine and
they could understand no reason why the airport should be congested --
they called Washington and after someone checked around received the
answer "there shouldn't be any flow control into Minnapolis; someone got
their wires crossed." We left in five minutes, having been on the ground
for nearly an hour by either a computer error or human error only
possible because the computers were installed to manage a humanly
unmanageable task -- almost certainly the error was caused by the
overload generated to handle the disrupted schedules throughout the
system.

Ted

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Cordless Phones Cry Wolf!
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Sat 15 Mar 86 12:00:04-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

The SF Chronicle 15 March 1986 has a news story about cordless phones making
``ghost'' phone calls to the emergency number 911 (and presumably to other
numbers as well).  The cordless phones, which send out and respond to radio
frequencies, behave strangely when their batteries start to run down.  In
addition, other household appliances can spur cordless phones to start
diaing spontaneously.  Michael Moos (president of the National Emergency
Number Association) was quoted: ``Frequencies given off by other appliances
-- micorwave ovens, blenders and even fluorescent lights -- interfere with
the cordless phones and make them start dialing.''  On an average day, at
least 12 of the 2000 calls received by Santa Clara County's 911 system are
such ghost calls.  [Cf. heart pacemaker interference, Sputnik triggering 
garage door openers, automotive CB interference, etc., in past RISKS.]  PGN

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
The Mob Breaks into the Information Age
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Fri, 14 Mar 86 15:17:48 est
</i><PRE>

INFOSYSTEMS, Vol 33, No. 3, March 86 carries subject article, beginning
on page 40.  Also several other computer security items.  Ought to help
sell a few password systems, at least. - Mike McLaughlin

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
[Non]computerized train wreck
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!dciem!msb@seismo.CSS.GOV">
ihnp4!utzoo!dciem!msb@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Fri, 14 Mar 86 08:45:38 EST
</i><PRE>

The wreck of a VIA Rail Canada train and Canadian National freight
train on February 8 was mentioned in this forum.
      [See Martin Minow, RISKS-2.9; Chuck Weinstock, <A HREF="/Risks/2.12.html">RISKS-2.12</A>]
I think it's worth pointing out that the accident has been attributed
to human error, specifically by the CN engine crew, both of whom were
among the 23 killed.  (Not 30+ as feared originally.)  They drove past
a stop signal which both men should have seen.

Not only was this NOT a case of computer malfunction, but indeed, a more
fully computerized system (with cab signalling and automatic train stopping)
would probably have prevented the accident.

Mark Brader

     [A fine example of the risks having to include people, not just
      computers, and of a more pervasive role of the computer than meets
      the eye -- indeed a more human-oriented computer system might have 
      helped!  Thus, even though it appears NOT to be a computer problem, 
      we discover that the computer could have done better!  But, of course,
      don't blame the computer system.  Blame the people who specified, 
      designed, and implemented it -- not JUST the train operator(s).  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Ballot Integrity; Specialization in Decision-Making
</A>
</H3>
<address>
Tom Benson 238-5277
&lt;<A HREF="mailto:      <T3B%PSUVM.BITNET@WISCVM.WISC.EDU> ">
      &lt;T3B%PSUVM.BITNET@WISCVM.WISC.EDU&gt; 
</A>&gt;
</address>
<i>
Fri, 14 Mar 86 10:54 EST
</i><PRE>
To:  RISKS@SRI-CSL.ARPA

I don't want to extend this discussion of ballot integrity, but my
understanding is that in Pennsylvania there is a registration number
on the ballot when it is given to the voter, but the voter tears it
off and retains it, so the ballot when in the ballot box is not
traceable to the voter.

I'm curious about the tone of some of the discussion on this issue.
Granted we shouldn't assume the absolute integrity of non-computerized
voting without careful scrutiny.  But some of the contributions seem, if
I am not mistaken, to justify computerized balloting on the grounds of
a broad (and unarguable) assumption that "any balloting process can be
subverted."  Sure.  But the object is to insure insofar as possible that
it won't be, and that means, primarily, protecting (1) secrecy, and
(2) accuracy.

Does anyone have an opinion on the question of how the local situation,
in this case RISKS, may influence the general consideration of the issue?
That is, RISKS is devoted to an interest in computers, not voting. Does
that, explicitly or implicitly, influence the question of what ought to
be relevant to the decision process?  I'm not complaining, nor am I
criticizing previous comments by correspondents or the editor.  What I am
trying to do is draw attention, as a communication scholar, to another
potential RISK: the use of electronic mail and digests with clear agendas
may inhibit the generalism needed to address substantive problems. Does
anyone have instances of this in their experience? (Note: I understand that
the problem is not limited to computers; committee work in general suffers
from this problem).

Tom Benson T3B AT PSUVM (BITNET)

     [Hmm.  For some reason I am rarely accused of undergeneralizing.
      I keep mumbling that to deal with RISKS, we must do so holistically,
      and that the computer is only a small part of what must concern us --
      even though it is the primary justification for the existence of this
      forum.  Any weak link can be devastating.  RISKS indeed tends more 
      toward breadth than depth, toward ALL RISKS than just computer risks.
      Indeed a few other people have commented that we have strayed off into
      the subjects of THEIR on-line forums!  I don't really think there is 
      too much danger that we are too narrow.  But discussion is welcome if
      relevant to RISKS.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Network Security, Integrity, and "Importance"
</A>
</H3>
<address>
    "Kurt F. Sauer" 
&lt;<A HREF="mailto:ks%a.cs.okstate.edu@CSNET-RELAY.ARPA">
ks%a.cs.okstate.edu@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Fri, 14 Mar 86 18:46:51 CST
</i><PRE>

Tom's Perrine's question about the Interface Message Processors' (IMP)
security [<A HREF="/Risks/2.23.html">RISKS-2.23</A>] is a really well-founded one.  As I see it (and I
haven't spent much time thinking about it, really), we can design a
network's security procedures based on some information and management
judgements.

Try answering some of these questions about the network you manage or
administer:

            o How critical is the general network operation?

This can be based on many things, not the least of which include the value
of the tokens passed on the network and the desirability or necessity of
proper message reception.

            o How confidential are the messages?  Are patterns,
              themselves, classified?

Traditional cryptology can be applied to "entire messages" (or whatever the
DIRNSA will let you get away with), but would releasable routings disclose
critical paths?  Would they "give away" operational information which should
be protected?

            o  Can message speed be increased for vital information
               whose delivery is paramount?  I'm not sure that this is as
               much a security problem as it is a basic applied-computer-
               science question.  Some feel that packet precedence systems
               are unnecessary; some feel otherwise.

The Defense Data Network (DDN), which is comprised of the ARPAnet and the
MILNET, serves a mighty diverse consumer market.  Universities, research
facilities, commercial institutions, and government operations all share the
facilities of the network.

Currently, some classified (i.e. sensitive) operations make use of the DDN.
Systems like the COINS-CINCPAC project now use the DDN as a transport
medium; loss of the medium would have at least some impact on CINCPAC's
intelligence operations.  For such setups, the basic network security is
ensured through fail-secure cryptographic setups which are only able to
prepend one specific message header to an already encrypted packet.  (One
thus gets around the red-black interface problem with packet addressing.)
And physical security is ensured by using guards, locked doors, and the like
at the point of security interface, and at all secured locations.

But this doesn't address the Internet physical or electronic security in
general.  I believe that the Defense Data Network Program Plan has a
scheduled dis-integration of the DDN parts very soon.  Obviously we have
already traversed the ARPA/MIL separation, but more is soon to come.  With
the introduction of Internet Private Line Interfaces (IPLIs) (and, based on
various community needs, estimates for numbers of IPLIs are nearly 1000--and
probably higher), the network can divide itself such that hosts will not
talk to non-community-of-interest hosts.  The "big plan" includes folding
MINET, MILNET, SACDIN (!), and IDHS (!!) into one network:  the DDN.  The
current ARPAnet will remain an R&amp;D network, essentially isolated completely
from the DDN.

I haven't been watching the network events (due to my absence) for about a
year now, so I don't know how far along we are in this plan.  But if it's
implemented (we're all waiting for BLACKER, so budgetary holdbacks may well
intervene), then "vital network nodes" would be physically secured, with the
ability to fold ARPAnet into DDN in the event of a crisis where additional
redundancy is required to limit network failures due to attacks on the
system.

Perhaps someone who really knows a lot about these things could comment on
the physical security side of the DDN house.  For those of you who are
interested, I have some citations to references which I would be happy to
share with persons on the ARPANET or MILNET; I will respond only to e-mail
requests.
		Kurt F. Sauer
		Tulsa, Oklahoma

Internet:	ks@a.cs.okstate.EDU       UUCP:		ks@svo.UUCP

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Modems                 [still... enough already?]
</A>
</H3>
<address>
James R. McGowan
&lt;<A HREF="mailto:jrm@Ford-wdl1.ARPA ">
jrm@Ford-wdl1.ARPA 
</A>&gt;
</address>
<i>
Fri, 14 Mar 86 16:48:27 PST
</i><PRE>
To: RISKS@sri-csl.arpa

In re the modem controversy:  the originating modem contains circuitry
to detect answering tones (in the range of 2000-2400 Hz.) It should
remain silent until it does detect the answering carrier (at least 
if the modem claims to be Hayes standard.) However, other sounds on the 
telephone line (noise, human voice, even just picking up the phone)
can sometimes excite th detection circuitry and software, resulting
in the originating modem turning on its tone generator.  Sorry, but
Phil does know what he's talking about.
				Jim McGowan
				(jrm@ford-wdl1)

    [Let's BLOW the WHISTLE on this one.  There's no modem operandi.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-83</DOCNO>
<DOCOLDNO>IA012-000128-B045-82</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.28.html 128.240.150.127 19970217002209 text/html 15363
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:20:35 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 28</TITLE>
<LINK REL="Prev" HREF="/Risks/2.27.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.29.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 28</H1>
<H2> Monday, 17 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of commission vs. risks of omission 
</A>
<DD>
<A HREF="#subj1.1">
Dave Parnas and Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The TIME is RIPE -- a clock problem 
</A>
<DD>
<A HREF="#subj2.1">
Peter Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Mailer Gone Mad? 
</A>
<DD>
<A HREF="#subj3.1">
Landrum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Money Talks 
</A>
<DD>
<A HREF="#subj4.1">
Matthew Kruk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Another discourteous modem 
</A>
<DD>
<A HREF="#subj5.1">
Glenn Hyatt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Will the modem discussions ever hang up? 
</A>
<DD>
<A HREF="#subj6.1">
Rob Austein
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of commission vs. risks of omission
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Sat, 15 Mar 86 17:30:09 pst
</i><PRE>

Dave Parnas in a private note to me has raised a set of concerns involving
the actions and inactions of a particular system.  Those concerns seem very
important to RISKS, and so I quote him here (with his permission).

  "What about the difference between risks of commission and risks of
  omission?  Whenever we speak of a risk it is shorthand for the risk of some
  specific danger.  I consider a risk to be one one of commission if the
  danger is that the system will perform some action from a finite set of
  "bad" things.  A risk is one of omission if the danger is that the system
  does not perform the task that it was built to perform.  I think risks of
  commission are less difficult to deal with than risks of omission for two
  reasons: (1) for risks of commission one can do specific "backward" analysis
  to look for ways that that danger could occur, (2) for risks of commission
  one can include checks and hardware to prevent the danger.  Risks of
  omission are often insurmountable because confidence that they will not
  occur requires a proof of "correctness" or at least a proof of certain
  aspects of correctness.  Do the readers of the forum agree with this
  distinction and evaluation?  Can they site save examples of successful
  software with a severe risk of the omission type?"  [Dave Parnas]

There are several comments that I would like to make, and then I'll turn this
open to the Forum.

The finite set of "bad" things may be incomplete.  An example in the
security community is the multilevel security property -- NO FLOW of
information downward to a lower level of security or laterally to another
compartment at the same security level.  This is the property upon which
various security kernels are based.  However, it represents only a portion
of the "bad things" that must be prevented.  Furthermore, proving the NO
FLOW property for a few dozen kernel functions is not enough if the entire
machine language is accessible via assembly language!

Yes, the former may seem easier to deal with -- at least superficially.
However, the errors of commission are insidious in that it is very hard to
GUARANTEE their absence.  In many cases the set of properties ("bad things")
is already stated negatively ("X MAY NOT HAPPEN", as in the case of the NO
FLOW property), and applies only abstractly.  Even even if you can
demonstrate that a particular interface (e.g.,a security kernel) satisfies
the desired set of properties (that is, the design satisfies the properties
and the code and hardware together are consistent with the design), the set
of properties may incomplete.  Thus, "correctness" arguments are relevant in
the errors of commission as well -- down to and including the hardware.

Dave reminds us of Martin Moore's example of the range safety shuttle
destruct system.  

  "Here there are risks of both kinds.  There is a risk that the system may
  destroy a shuttle that performs properly.  There is also a risk that it may
  not destroy a shot that should be destroyed because it is about to crash in
  Miami's heavily populated area.  Martin described how many measures could be
  taken to make the commission risk less likely.  Physical control of data
  paths was one of those measures.  However, it is much harder to see how we
  can make sure that the destruct system will perform.  We would need some
  correctness arguments or extensive testing to have faith that it would
  perform when it should."  [Dave Parnas]

The risks of omission are also insidious in that the model of what must be
done may be incomplete.  While the distinction between errors of commission
and omission is valuable, I suspect that there are essentially equivalent
problems with each, but this is probably of little help in practice.  Both
types of risks must be considered.  Furthermore, in some cases, a given
problem may involve both types of errors.

Peter

   [Perhaps a survey of the disaster list (e.g., RISKS-2.1) might be in
    order, but I want to get this issue out without further delay.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
The TIME is RIPE -- a clock problem 
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Fri 7 Dec 84 09:46:27-PST                        [WRONG!]
</i><PRE>
To: RISKS@SRI-CSL.ARPA                                 [NOT THE REAL TIME!  
                                           MORE LIKE Mon 14 Mar 7:50AM PST] 

Somehow the time-of-date clock on my system got reset to 7 Dec 1984 last
night around 10:40 PM PST, while I was logged in.  I was apparently the only
user on the system at the time, but I was doing nothing unusual.  Could it
have been a dropped bit (despite parity) (I haven't had the patience to do
the calculation of the time difference)? or a time-dependent software
glitch?  At any rate, it is something I had never seen before, and it seems
quite relevant to RISKS.  

The side-effects of such a clock burp could be very painful.  (1) A
delete-by-date of older-dated versions of a file results in deletion of the
newest versions actually created.  (2) All of the messages in my mailboxes
were marked as UNSEEN.  In a mailbox with hundreds of messages, that is a
nuisance.  (3) In clock-dependent asynchronous systems, all hell could break
loose.  (Recall the first shuttle launch delay.)  (4) All sorts of other
things might stop working.  (I wonder if anyone ever runs a system in the
virtual past in order to keep the SCRIBE time-bomb from going off, to avoid
paying UNILOGIC for another year!) PGN]

      [I waited to send this issue out until the clock had been corrected,
       in order to minimize further side-effects, notably confusion.]   
Peter

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Mailer Gone Mad?  
</A>
</H3>
<address>
&lt;<A HREF="mailto:Landrum @ DDN1.ARPA">
Landrum @ DDN1.ARPA
</A>&gt;
</address>
<i>
14 Mar 86 14:12 EST
</i><PRE>
To: neumann @ sri-csl.arpa

Comment: Found this in my mailbox.  Something appears to have gone awry!!

Taylor Landrum
         Forwarded message:  
         -----------------------------------------------------
  Date:  Thu 6 Mar 86 22:27:50-PST
  From: RISKS @ SRI-CSL.ARPA
  Subject:  <A HREF="/Risks/2.23.html">RISKS-2.23</A>
  Sender:  NEUMANN@SRI-CSL.ARPA
  cc:
  Text: LTC Elderd,

  I just got another issue of Bar Code News in the mail, and it had an
  insert on something called "ID EXPO", which is sponsored by Bar Code News,
  and is billed as "the conference and exposition of automatic identification
  and keyless data entry".  It will be held at the civic auditorium/Brooks
  Hall in San Francisco, 19-21 May.

  ...
                                      - Jim Jack
 
  -------------END OF FORWARDED MESSAGE(S)-------------

     [I omit the rest of the message, and hope that Jim Jack does not mind
     my including this here.  I hope you see that someone's mailer has 
     committed A MONSTROUS SCREW-UP.  The header information is precisely
     that of <A HREF="/Risks/2.23.html">RISKS-2.23</A>, and Landrum@DDN1 was on the list to receive that
     issue.  But it is clear that the message received was truncated after
     some of the header stuff (notice the TO: field is missing!) and the
     text of another message concatenated.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Money Talks
</A>
</H3>
<address>
&lt;<A HREF="mailto:Matthew_Kruk%UBC.MAILNET@MIT-MULTICS.ARPA">
Matthew_Kruk%UBC.MAILNET@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Sun, 16 Mar 86 15:43:34 PST
</i><PRE>

The following article appeared in the Vancouver Sun (Vancouver,
B.C.), Saturday, March 15th:

            New bills will prove that money can talk

  OTTAWA - It costs six cents to make, wears out in about a year,
  and is an oddball in the U.S., where today it's only worth $1.43.

  Someday it will even be able to talk - in both offical languages.

  It's the new Canadian $2 bill, announced today by the Bank of
  Canada, which has redesigned the deuce - and its $5 pal - for
  introduction later this year.
  ...
  The new bills will also have a feature to assist the
  visually-impaired distinguish denominations.

  Don Bennett, a spokeman for the Bank of Canada, said the new bills
  will have a code printed into them which, when inserted into an
  electronic device, will activate a synthesized "voice" which will
  speak the denomination.

  Bennett said the bank is continuing development work on the
  device, but field tests, which included Vancouver, were recently
  completed.

  Bennett said it will be the end of the decade before the devices
  are in wide-spread use although some may be available by 1987. The
  target cost is below $50.
  ...

My curiousity is how "fool-proof" are these codes (I have not seen
what the codes look like but I suspect something similar to that
imprinted on personal checks) and devices. Does anyone know of
something similar? Will money not only "talk" but "lie" too?

    [I am reminded of the BART and METRO fare cards.  Although the remaining
     fare is encrypted, the magnetic stripe is trivial to copy.  Since the
     encoded signature of the $2 bill will be identical for all $2 bills, in
     principle it should be easy to copy -- perhaps onto an OLD $1 that has 
     no such markings, although that is not such a great loss.  What about
     higher denominations?  (Holograms embedded in the bill to prevent 
     forgeries (as in credit cards) would not help the blind much.)  If you
     were blind, would you have any confidence in a machine that tells you
     that the bill you have just been given by a well-known shyster is a 
     perfectly good $1000 bill?  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Another discourteous modem
</A>
</H3>
<address>
    Glenn Hyatt 
&lt;<A HREF="mailto:hyatt@dewey.udel.EDU">
hyatt@dewey.udel.EDU
</A>&gt;
</address>
<i>
Sat, 15 Mar 86 17:03:51 EST
</i><PRE>

The other day, someone finally reached me who had been trying
for several days.  I have a second phone line into my house
that I use only for data -- no telephone attached -- and it
seems she had gotten that phone number instead of the one I
always use for voice.  Usually I am either using the data line
or the modem is turned off, so she kept getting a busy signal
or no answer.  Once, though, someone -- my modem, left on for
once -- answered.  It beeped, so she left a message, taking it
for an answering machine.  Took me for the sort who never
returns phone calls.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Will the modem discussions ever hang up?
</A>
</H3>
<address>
Rob Austein 
&lt;<A HREF="mailto:SRA@XX.LCS.MIT.EDU">
SRA@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 15 Mar 1986  19:19 EST
</i><PRE>

Peter,

I suggest that if you are as tired of modem stuff as you sound, you
just redirect anybody who wants to talk further to TELECOM@XX.  Lag
time to the various parts of the net is bad enough that you will still
be getting this crud for weeks if you don't put a lid on it.

--Rob
         [I'm not tired of the topic itself, but I think our readers may grow
          a little weary of the seemingly endless variations on the theme. 
          However, I think I may turn up my REJECT RATIO a little more.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-84</DOCNO>
<DOCOLDNO>IA012-000128-B045-110</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.29.html 128.240.150.127 19970217002222 text/html 15812
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:20:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 29</TITLE>
<LINK REL="Prev" HREF="/Risks/2.28.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.30.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 29</H1>
<H2> Monday, 17 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Commission vs. Omission 
</A>
<DD>
<A HREF="#subj1.1">
Martin J. Moore plus an example from Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A Stitch in Time 
</A>
<DD>
<A HREF="#subj2.1">
Jagan Jagannathan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Clockenspiel 
</A>
<DD>
<A HREF="#subj3.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Cordless phones 
</A>
<DD>
<A HREF="#subj4.1">
Chris Koenigsberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Money talks 
</A>
<DD>
<A HREF="#subj5.1">
Dirk Grunwald
</A><br>
<A HREF="#subj5.2">
 date correction from Matthew Kruk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  [Non]computerized train wreck 
</A>
<DD>
<A HREF="#subj6.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  On-line Safety Database 
</A>
<DD>
<A HREF="#subj7.1">
Ken Dymond
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Commission vs. Omission
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

Dave Parnas's points regarding the shuttle destruct system are well taken.
The policy, stated informally, was that "it better work if we need it --
but it absolutely better NOT 'work' when we DON'T need it" which generated the
extreme emphasis on preventing what Dave calls "risks of commission."  I feel
that the risk of commission on the destruct system is extremely small, while 
the risk of omission is somewhat higher, although still small.  During 
validation testing and in every pre-launch checkout, we performed "exhaustive" 
checks -- "exhaustive" meaning that we tried every combination of 
  [(2 central computers) * (6 remote sites) * (2 computers per site) 
      * (2 transmitters per site) * (2 comm paths to each site) 
      * (2 possible commands in various sequences)].  
Yeah, this takes a *LONG* time (with practice, we got it down 
to several hours if everything went smooth.)  On one occasion during 
validation testing, we did find a software error which only manifested on a
particular (central computer/comm path/remote computer/unusual command
sequence) combination.  Exhaustive tests *are* necessary.

I have often wondered why the emphasis was to prevent errors of commission
over errors of omission (not to say that we wanted either kind, but errors
of commission were definitely considered to be worse!).  An erroneous
destruct would cost the lives of the flight crew, loss of the Orbiter, and
possibly damage on the ground if it occurred early in the flight (e.g.,
windows blown out, etc.)  An erroneous non-destruct, in the worst case (if
the ET were to detonate near the crowded spectator area on the NASA
causeway), could cause the loss of TENS OF THOUSANDS of lives.  Certainly
this is worse than an erroneous destruct.  I believe there may be a
subconscious feeling that an erroneous destruct means the difference between
a success and a disaster, while an erroneous non-destruct means the
difference between a disaster and a worse disaster.  Subjectively, that
difference is not as great as the first, although objectively it may be much
greater.
                                     Martin Moore

&lt;The usual disclaimers.  I'm too tired to type in the whole silly thing.&gt;

        [By the way, Dave Parnas suggested the following example to
         illustrate his message in <A HREF="/Risks/2.28.html">RISKS-2.28</A>:]

         "Consider elevators.  Consider how much easier it is to prevent the
         floor indicator from saying "13" than to assure that the floor
         indicator will always give the actual floor that the elevator is
         on.  The risk of indicating "13" can be gotten acceptably low by
         eliminating "13" from the set of indicator lights.  The risk of
         indicating an incorrect floor or not indicating the current floor
         is much harder to eliminate."  [Dave Parnas]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
A Stitch in Time
</A>
</H3>
<address>
&lt;<A HREF="mailto:JAGAN@SRI-CSL.ARPA ">
JAGAN@SRI-CSL.ARPA 
</A>&gt;
</address>
<i>
Mon 17 Mar 86 11:43:53-PST
</i><PRE>
To: Neumann@SRI-CSL.ARPA

   [As it now turns out, the reboot occurred just moments BEFORE I logged
    in Sunday night.  Here are some further details.  PGN]

This is the probable sequence of events that led us back in time on CSLA:
1. A power glitch (late night SUNDAY) caused the F4 to hard boot.
2. During a hard boot, the TIME is retrieved from eleven independent sources
   (which are assumed to be correct!)
3. One of these sources had the incorrect time of some warm day in 1972
   causing the average to be wrongly computed resulting in Dec 6th/1985.

Suggestion:
1. Change the statistical measure from MEAN to something less sensitive to
   one or two abnormal times; for example the average of the 5th, 6th, and 7th
   largest times.  

       [IT IS ABSOLUTELY INCREDIBLE THAT UNSAFE ALGORITHMS continue to
        be used.  This problem is as old as the hills.  Statisticians
        routinely throw out the absurd values before computing the
        mean.  Dorothy Denning pointed out the pun in their terminology
        (applicable to Byzantine agreement algorithms, where you don't
        trust anyone): the OUT-LIERS are really the OUT-LIARS.  

        EVEN WORSE, Jagan points out that if the clock had been accidentally
        set INTO THE FUTURE, things could also get very sticky.  We also
        have a problem of nonunique clock readings during the hour at 2AM when
        Daylight Savings Time ends.  A good time to be asleep.  PGN]

[Here is some more background.]

  Date: Mon 17 Mar 86 12:37:37-PST
  From: Mark Lottor &lt;MKL@SRI-NIC.ARPA&gt;
  Subject: [Louis A. Mamakos &lt;louie@trantor.UMD.EDU&gt;: time]
  To: Jagan@SRI-CSL.ARPA

  This was just to verify that the problem was on the
  remote system and not some local problem...
                ---------------

  Date: Mon, 17 Mar 86 15:31:14 EST
  From: Louis A. Mamakos &lt;louie@trantor.UMD.EDU&gt;
  To: MKL@sri-nic.ARPA
  In-Reply-To: Mark Lottor's message of Mon 17 Mar 86 11:34:41-PST
  Subject: time

  Yes, I can verify that it was indeed the clock (actually the host the clock
  was on) that was screwed up.  It it unfortunate that there is no way to get
  the current year out of the WWVB clock.  There was work being done in the
  computer room, which reset our LSI-11/73 host, which subsequently got
  confused.  Sorry about the problem.

  Louis A. Mamakos  WA3YMH    Internet: louie@TRANTOR.UMD.EDU
  University of Maryland, Computer Science Center - Systems Programming

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Clockenspiel
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@decwrl.DEC.COM ">
horning@decwrl.DEC.COM 
</A>&gt;
</address>
<i>
17 Mar 1986 1436-PST (Monday)
</i><PRE>

Your errant clock reminds me of something that happened at Stanford in
the mid-sixties. I was apparently one of the first users of the 360/67
to run a job that started on one day and finished on the next. When the
statement for my account arrived in the mail, I had quite a job
convincing my wife that the huge figure (to a graduate student couple)
was nothing to worry about: It was a CREDIT resulting from a job that
was charged for minus 23 hours and 58 minutes!

The Xerox Alto operating system had a compiled-in reasonableness check
on the date and time. When it started up, if the local clock wasn't
"reasonable," it sent a request over the Ethernet and put "Date and
Time Unknown" in the banner. Well, you guessed it: The day came when
the (correct) time from the time server was no longer "reasonable," and
therefore couldn't be corrected by appeal to the time server....

Jim H.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
RISKS re: Cordless phones
</A>
</H3>
<address>
&lt;<A HREF="mailto:Chris.Koenigsberg@G.CS.CMU.EDU">
Chris.Koenigsberg@G.CS.CMU.EDU
</A>&gt;
</address>
<i>
17 Mar 1986 11:48-EST
</i><PRE>

My roommate has a cordless phone and it goes on the blink every few weeks.
All the phones in the house stop working. When you pick any one up, all you
get is a very loud static sound and you can't dial out. I have learned that
I can fix this problem by sneaking in his room and unplugging the cradle for
his cordless phone. A visitor in the house was very frightened one night
when she was left alone and though someone had cut the phone lines or
something. It was the cordless phone on the blink again.

Chris Koenigsberg
ckk@g.cs.cmu.edu , or ckk%andrew@pt.cs.cmu.edu
{harvard,seismo,topaz,ucbvax}!g.cs.cmu.edu!ckk
(412)268-8526 office, (412)362-6422 home
Center for Design of Educational Computing
Carnegie-Mellon U.
Pgh, Pa. 15213

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
re: money talks
</A>
</H3>
<address>
Dirk Grunwald
&lt;<A HREF="mailto:grunwald@b.CS.UIUC.EDU ">
grunwald@b.CS.UIUC.EDU 
</A>&gt;
</address>
<i>
Mon, 17 Mar 86 16:44:15 CST
</i><PRE>

I read the 'money talks' article with great amusement. One of the risks to
society which is worth talking about is the risk of using inappropriate, or
downright silly, technology.

Talking money would appear to be such a waste of resources. Certainly some
other method of denomination descrimination could be devised for the
visually impared. Rasied lettering, coinage instead of paper money, different
sized paper money, different paper stock. But talking money?

dirk grunwald
university of illinois

</PRE>
<HR><H3><A NAME="subj5.2">
Money Talks
</A>
</H3>
<address>
&lt;<A HREF="mailto:Matthew_Kruk%UBC.MAILNET@MIT-MULTICS.ARPA">
Matthew_Kruk%UBC.MAILNET@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Mon, 17 Mar 86 09:07:32 PST
</i><PRE>

Correction to my previous message: The date of the article should be
March 14th (Friday).

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
[Non]computerized train wreck
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!lsuc!msb@seismo.CSS.GOV">
ihnp4!utzoo!lsuc!msb@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Mon, 17 Mar 86 19:04:03 EST
</i><PRE>

Me:
&gt; Not only was this NOT a case of computer malfunction, but indeed, a more
&gt; fully computerized system (with cab signalling and automatic train stopping)
&gt; would probably have prevented the accident.

PGN:
&gt; [... Thus, even though it appears NOT to be a computer problem, 
&gt; we discover that the computer could have done better!  But, of course,
&gt; don't blame the computer system.  Blame the people who specified, 
&gt; designed, and implemented it -- not JUST the train operator(s).  PGN]

You sound more critical than I meant to be.  The cost of equipping all major
railways with cab signalling and the like would be considerable, to say the
least.  While such installations certainly do exist, especially on busy
high-speed lines, the "centralized traffic control" in use on the route in
question is probably much more common.  Are you calling on all railways to
upgrade their signaling systems long before they are life-expired, every
time something somewhat better comes along?

Mark Brader  (ihnp4!utzoo!lsuc!msb and ...!dciem!msb are both me.)

   [One would hope that new improvements do not always require everything
    to be thrown out.  Long ago we discovered the advantages of software
    solutions over hardware solutions.  But when human lives are at stake,
    safer systems may be worth the price of upgrading equipment.  I think
    that the incredible escalation of law-suit awards and of rates for 
    malpractice and liability insurance may provide some new incentives.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
On-line Safety Database
</A>
</H3>
<address>
"DYMOND, KEN" 
&lt;<A HREF="mailto:dymond@nbs-vms.ARPA">
dymond@nbs-vms.ARPA
</A>&gt;
</address>
<i>
17 Mar 86 15:14:00 EST
</i><PRE>
To: "risks" &lt;risks@sri-csl.ARPA&gt;

Our Library Bulletin (and as a frequent user I'd have to say that the NBS 
has one of the best technical libraries going) for February contained a 
notice that Pergamon Infoline (evidently a supplier of such services) is
offering a new online database service, SAFETY: "SAFETY, produced by
Cambridge Scientific Abstracts, provides broad interdisciplinary
coverage of safety, including industrial, transportation, environmental,
and medical safety.  This database indexes journals, books, reports,
patents, and proceedings published in 1981 or later."  If someone on
the list uses this database, please let us know how well it covers
computer and software safety.

Ken Dymond
National Bureau of Standards

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-85</DOCNO>
<DOCOLDNO>IA012-000128-B045-130</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.30.html 128.240.150.127 19970217002234 text/html 13754
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:21:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 30</TITLE>
<LINK REL="Prev" HREF="/Risks/2.29.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.31.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 30</H1>
<H2> Tuesday, 18 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Classes of Errors 
</A>
<DD>
<A HREF="#subj1.1">
Scott Rose
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Range Safety System 
</A>
<DD>
<A HREF="#subj2.1">
David desJardins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Commission vs omission 
</A>
<DD>
<A HREF="#subj3.1">
Geoffrey A. Landis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Stupid Clock Software 
</A>
<DD>
<A HREF="#subj4.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Control characters in headers from eglin-vax 
</A>
<DD>
<A HREF="#subj5.1">
Martin J. Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Money Talks 
</A>
<DD>
<A HREF="#subj6.1">
Prasanna G. Mulgaonkar
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Classes of Errors
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 17 Mar 86 20:28:30 PST (Mon)
From: Scott Rose  {206} 543-4226 &lt;rose@uw-bluechip.arpa&gt;

The dichotomy between errors of commission and of omission is reminiscent of
the tension between negative and positive control in launch-on-warning
systems.  Clearly, negative control is a snap if one is willing to
compromise positive control: there is perfectly reliable negative control
whenever the system is shut off.  That is, errors of omission are not
possible if one is willing to accept errors of commission in this case.
Obviously, there is a continuum of possibilities between this extreme and
the extreme of just launching without any reliable detection whatsoever;
this is the only region of interest.  The point illustrated is that the two
classes of error are not likely to be independently controllable; there is a
built-in tension between them.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Range Safety System
</A>
</H3>
<address>
David desJardins
&lt;<A HREF="mailto:desj@brahms.berkeley.edu ">
desj@brahms.berkeley.edu 
</A>&gt;
</address>
<i>
Mon, 17 Mar 86 21:52:11 pst
</i><PRE>
Organization: University of California, Berkeley

   I haven't seen anybody mention that there does seem to have been an
"error of commission" in the operation of the range safety system after
the Challenger explosion (specifically, the destruction of the SRBs).
Of course this is a human rather than a computer error, but the result
is the same; the system as a whole functioned less than optimally.

   I understand that even NASA now admits that the SRBs were not in fact
endangering anything at the time that they were destroyed.  But I do
understand how there must be an almost irresistible temptation for the
range safety officer to do the "safe" thing (in this case, destroy the
boosters).  Perhaps this is the inevitable result of having humans making
these decisions (error on the side of safety).

   I'm not sure that anything can really be done about this, except to
provide extensive training and an adequate supply of information on which
to base the actual decisions.  Do the range safety officers have access
to real-time flight-path projections and similar information that would
allow them to make intelligent decisions?

   -- David desJardins

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     commission vs omission
</A>
</H3>
<address>
&lt;<A HREF="mailto: ST401385%BROWNVM.BITNET@WISCVM.WISC.EDU">
 ST401385%BROWNVM.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
Tue, 18 Mar 86 11:06:01 EST
</i><PRE>

     Martin J Moore queries why the shuttle destruct system should be
tested more extensively against errors of commission (error causes
destruct system to activate) than against errors of omission (error
causes destruct system to be unable to activate).  The reason is that
for the errors of omission, the rest of the system serves as an
additional link, ie., for an error of commission to cause disaster,
ONLY the destruct system has to fail.  For an error of omission to cause
disaster, the destruct system has to fail SIMULTANEOUSLY with the vehicle
failing.   Thus, the most probable event is for an error of omission to
gail "safe": the vehicle wouldn't have blown up if somebody wanted it to,
but nobody wanted it to, so it didn't matter.
                   --Geoffrey A. Landis, Brown University
                     Reply to: ST401385%BROWNVM.BITNET@WISCVM.ARPA

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Stupid Clock Software
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@ee.purdue.edu ">
davy@ee.purdue.edu 
</A>&gt;
</address>
<i>
Tue, 18 Mar 86 08:39:44 EST
</i><PRE>

Here at Purdue's Engineeering Computer Network, we've had "synchronized"
time on all our machines for some time.  For a long time, all the machines
ran "datesync", a program which checked a central machine every N minutes
(usually 15 or 30) and set the local machine's date and time according to
what it got from the central host.  There were some minor sanity checks, but
nothing fancy.  We never had too much trouble, since if the central machine
came up with the wrong date you could get it reset before the other machines
came and got their time information.

A couple of years ago, we plugged a Heathkit (Al)Most Accurate Clock (WWV)
into the central machine.  It used to be set off "George's Watch".  This
made stuff somewhat better -- when the central machine came up, it got the
time from WWV instead of "datesync"ing to another machine.  The WWV software
was used periodically (every 15 minutes, I think) to adjust the central
machine clock.  Except for the time when the someone unplugged the WWV clock
and then a few days later it's battery backup freaked out, we have NEVER had
a serious problem with the "datesync" scheme (20 machines or so).

Well, with 4.3BSD UNIX you get this neat toy called the "time daemon".  It
handles network clock synchronization off a master machine by doing various
clock adjustments (rather than hard-setting the clock, it actually diddles
the clock speed).  It has all these neato sanity checks and SUPPOSEDLY it
won't let a preposterous time come in.  In fact, you even see this stuff on
the console once in awhile that says "PREPOSTEROUS TIME ....".  Sounds neat,
right?

Well, last month all the machines on the network decided that it was 4:00pm,
January 4, 1985.  Somehow this slipped right by all the sanity checks, and
the master time daemon stuffed it into one machine.  Then it PROPAGATED it
to all the other machines.  Having horribly wrong time can be fairly
catastrophic on a UNIX system -- the "cron" utility starts up all sorts of
programs based on the time of day and day of the week.  Including things
like "find all files older than X and delete them".  We were less than
amused...  Another brain-damaged feature of the time daemon -- if you set
the date on ONE machine, it BROADCASTS that information through the time
daemons to ALL the machines.  You better PRAY you never mistype the date!

The thing that really bugs me about this stuff is that it's so simple to make
it more bullet-proof (not fool-proof, necessarily).  For example, just plain
IGNORE any date which changes your date by more than X unless you are
explicitly told TAKE THIS DATE REGARDLESS.

Well, this letter is already twice as long as I intended, so I'll shut up
now...  things like this are an interesting subject though -- I wonder how
much other software in computerdom just blindly assumes that some
"authority" is correct.

--Dave Curry
Purdue University

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Control characters in headers from eglin-vax
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks-request" &lt;risks-request@sri-csl&gt;

In addition to its other bugs (e.g., null timestamps), our mailer puts a
control character at the beginning of each user's personal name.  This arises
from keeping the personal name as a counted string but displaying it as
ordinary text; the control character is the count byte.  Recently I have
received messages (ranging from polite to nasty) from several RISKS readers
telling me that my control character causes their terminals to reset, go into
graphics mode, or do other unpleasant things.  I can't do anything about it;
we're waiting for a fix from the vendor, and we're stuck until we get it.
Since you edit my headers to get the date right, would you mind flushing the
control character also?
                                     mjm

      [I took it out of the FROM field.  But this problem reminds me that
       many of our readers may not have never heard of the old problem of
       squirreling away control characters and escape sequences in messages
       which when read can wreak havoc with an unsuspecting mail reader,
       especially one with an intelligent terminal having redefinable keys.
       If that problem has not been fixed on YOUR system, dear reader, YOU
       may be running at great risk.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Money Talks
</A>
</H3>
<address>
Prasanna G. Mulgaonkar 
&lt;<A HREF="mailto:PRASANNA@SRI-AI.ARPA">
PRASANNA@SRI-AI.ARPA
</A>&gt;
</address>
<i>
Tue 18 Mar 86 09:05:17-PST
</i><PRE>
To: risks@SRI-CSL.ARPA

One of the origin of risks in any system is exemplified by the discussion of
the Canadian effort at "vocalizing" the value of a currency note. I do not
have any information in addition to what has been posted in the RISKS digest
(so feel free to correct me if I am wrong), but there seems to be nothing in
the original posting [RISKS 2-28] to indicate that the aim of the device is
to dectect/reduce forgeries. Yet, the first argument offered against it is
the ability to fool it.

My interpretation of the device is one to help a blind person "read" the
currency note SOMETHING THAT HE CANNOT NOW DO--- not to tell him if the
currency note is valid or a forgery! Risks of such a system come from the
public putting more faith or expecting more from a system than its stated
goal.

As a side issue, there is no reason to think that fooling such a device
would be any different than fooling change machines that are commonly found
around here, which detect at least the difference between 1$ and 5$ bills.
There is no reason why such a machine could not be connected to a voice
synthesizer to speak out the amount. Addition of speech capability in itself
does not increase the risks/unreliability/foolability(?)  of any system.

	      --Prasanna

           [Just don't trust it with anything larger than what you are
            willing to be cheated out of.  You may have noticed that you
            don't see change machines for $100 bills.  There are good
            reasons.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-86</DOCNO>
<DOCOLDNO>IA012-000128-B045-161</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.31.html 128.240.150.127 19970217002247 text/html 20744
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:21:15 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 31</TITLE>
<LINK REL="Prev" HREF="/Risks/2.30.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.32.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 31</H1>
<H2> Wednesday, 19 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Still more on shuttle destruct systems 
</A>
<DD>
<A HREF="#subj1.1">
Martin J. Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Clock Synchronization 
</A>
<DD>
<A HREF="#subj2.1">
Andy Mondore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Timestamp integrity at system startup 
</A>
<DD>
<A HREF="#subj3.1">
John Coughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Danny Cohen on SDI 
</A>
<DD>
<A HREF="#subj4.1">
Charlie Crummer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Two more mailer problems 
</A>
<DD>
<A HREF="#subj5.1">
Sidney Markowitz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Marking money for the blind 
</A>
<DD>
<A HREF="#subj6.1">
Atrocity Joelll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Why would anyone want to computerize voting? 
</A>
<DD>
<A HREF="#subj7.1">
Larry Campbell
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Still more on shuttle destruct systems
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

&gt;From: desj@brahms.berkeley.edu (David desJardins)
&gt;[T]he destruction of the SRBs...is a human rather than a computer error.

It was certainly a human action but I do not agree that it was an error.
That we now -- long after the fact -- would like to retrieve the boosters
is unfortunate; but had they not been destroyed they would either have
ended up in the drink anyway (possibly much further away from the Cape and in
much deeper water, making the recovery even more difficult than it is) or they
would have endangered a land area.

&gt; NASA admits that the SRBs were not in fact endangering anything at the time
&gt; that they were destroyed...there must be an almost irresistible temptation 
&gt; for the range safety officer to do the "safe" thing. 

First, the destruct decision does not come from NASA; it comes from the Air 
Force.  Second, there is no "temptation" involved; the range safety officer
MUST DO the safe thing based on the information available in real time.  He 
did so.  For more on the information available to the RSO, see below.

&gt; Perhaps this is the inevitable result of having humans making
&gt; these decisions (error on the side of safety).

Would you prefer error on the side of non-safety?  Or are you advocating the
use of computers to make the actual destruct decision?  If the latter, you
will have a hard time getting anyone to fly the vehicle!  Also, in the 
Challenger case, a computer would have made the same decision to destroy the 
SRBs.  While I was at the Cape, there was some investigation into the 
possibility of automating the destruct decision; it was decided that even if 
it were safe and reliable, it could only be used on unmanned launches.  Since
the number of unmanned launches would decrease dramatically in the coming 
years, an automatic destruct decision system would not be cost-effective.

&gt; I'm not sure that anything can really be done about this, except to
&gt; provide extensive training and an adequate supply of information on which
&gt; to base the actual decisions.  Do the range safety officers have access
&gt; to real-time flight-path projections and similar information that would
&gt; allow them to make intelligent decisions?

The RSO's do receive *extensive* training.  Being an RSO is a full-time job, 
not an extra duty; the RSO's are either Air Force officers or high-grade
civil servants (incidentally, I was once encouraged by some of the RSO's to 
apply for an opening in their number.  I am REALLY glad I decided not to!).
Their training includes realistic launch simulations in which various 
things go wrong.  The problems include not only wild trajectories but 
equipment and people problems; during the simulations, one of the RSOs is in 
charge of setting up the problems.  They perform this duty on a rotating basis 
and it is quite competitive.  In addition to the real-time training, there is
"office" training in which they study the effects of various missiles, 
possible debris footprints, etc.

Regarding flight projections:  tracking data are gathered from a variety of 
sources, including radars, inertial guidance telemetry, and optical trackers 
(mainly used very early in flight when radars are ineffective due to 
multipath.)  The tracking data is fed to the Central Computer (redundant Cyber 
740s) where through various filtering and checking the two "best" sources are
chosen, and used to determine the vehicle's position and velocity, and to 
compute from them the Instantaneous Impact Point (IIP), which is the point at 
which the vehicle would impact if thrust were to terminate at that instant.
The RSO has a lot of information displayed on his consoles: the primary and 
alternate position, velocity, and IIP, real-time telemetry from the vehicle
(e.g., engine chamber pressures), live video coverage, and others.  The RSO
uses this information (plus comm links to the Flight Director in Houston on a 
manned launch) to make his decisions.  The present position itself is not 
critical; it is the IIP that determines when an area is endangered.  The RSO 
has displays of the nearby land masses, with "destruct lines" drawn some 
distance out to sea; if an IIP crosses a destruct line, the land area is 
endangered and the missile should be destroyed.  Also, if a vehicle is 
obviously wild (such as an orphaned SRB) it should be destroyed while still in 
a safe area *before* it can endanger the land mass!  This is why the RSO's 
decision was not an error.  As I understand it, although the SRB had not yet 
crossed the destruct line, it had curved back toward the coast and would have 
crossed the line in a few seconds.  

From my observations, I evolved my own rough rules-of-thumb for destroying a 
missile.  These are purely my personal observations, they're not official,
and they're pretty general, so please don't nitpick at them.
----
IF (missile is unmanned) THEN
   IF (IIP crosses destruct line) OR (missile is obviously out of control)
   OR (missile is out of communications for a length of time sufficient
   to endanger any area from its last known position) OR (pad disaster occurs
   -- e.g., vehicle falls over after ignition) THEN
      Destroy the missile.
ELSE IF (missile is manned) THEN
   IF ((IIP crosses destruct line) AND (Houston reports the flight crew is
   *not* in control of the vehicle)) OR (pad disaster occurs) THEN
      Destroy the missile.
END IF
----
SRBs flying by themselves are certainly unmanned and obviously out of control.

Sorry about the length of this message, but I'm getting a little tired of 
hearing people second-guess the RSO's decision.  The RSO in question is one of 
the most intelligent and capable individuals I have ever known; he made the 
correct decision based on the real-time information, and that's what he is 
supposed to do.  One SRB was heading toward the coast, and even though it
had not yet crossed the destruct line, the risk to the population was 
significant (and increasing).  He unquestionably made the right decision based 
on the information at the time.
                                           
                                     Martin Moore
                          
Disclaimer:  I disclaim everything.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Clock Synchronization
</A>
</H3>
<address>
&lt;<A HREF="mailto:Andy_Mondore%RPI-MTS.Mailnet@MIT-MULTICS.ARPA">
Andy_Mondore%RPI-MTS.Mailnet@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 19 Mar 86 09:38:18 EST
</i><PRE>

The recent discussion of computer clocks showing the wrong time
has reminded me of a related problem -- clock synchronization on
computers.  For example, I will sometimes receive a message from
someone on another host on campus where the "time received" on
my host will be earlier than the "time sent" on his machine!
Granted, clock synchronization  with electronic mail isn't really
that critical, but I can think of a lot of other applications where
having clocks out of sync with each other would be totally
unacceptable.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Timestamp integrity at system startup
</A>
</H3>
<address>
      John Coughlin 
&lt;<A HREF="mailto:John_Coughlin%CARLETON.BITNET@WISCVM.WISC.EDU">
John_Coughlin%CARLETON.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
19 Mar 86 10:56:56 EST
</i><PRE>
ReSent-To: RISKS@SRI-CSL.ARPA

   The  CP-6  operating  system  has  an interesting integrity check for
timestamp setting.  On a warm or cold boot the operator is asked for the
date and  time.  This is compared  with the timestamp on  the last error
log entry.  If  the 'new' timestamp is earlier than  the error log entry
or is more  than nine hours later then a  timewarp error is reported and
confirmation is  requested.  If the operator chooses  to reject the time
he entered he can make a correction.

   There are two  problems with this system.  First, if  a new system is
being built there  are no error log files.  I  think the base time stamp
(1978-01-01  00:00) is  used in  this case.   Second, it is possible for
there  to  have  been  no  error  recorded  in a nine hour period.  This
actually happened to us a couple of times, so we now write a dummy error
log entry every  four hours.  I am thinking of  stepping this up to once
per hour in case the system is down at exactly 00:00 or 04:00 or ...

   This  system  has  its  drawbacks,  but  helps to reduce the risks of
setting an unreasonable timestamp at system startup.
                                                          /jc

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Danny Cohen on SDI
</A>
</H3>
<address>
&lt;<A HREF="mailto:crummer@aero">
crummer@aero
</A>&gt;
</address>
<i>
07 Mar 86 20:23:58 PST (Fri)
</i><PRE>
[EXCERPTED FROM Soft-Eng Digest Wed, 19 Mar 86 Volume 2 : Issue 9]  

                    [SINCE MY GUESS IS THAT MOST OF YOU ARE NOT READING 
                     SOFT-ENG@XX.LCS.MIT.EDU, IT SEEMED WORTH INCLUDING 
                     THIS HERE.  PGN]

The following is a "summary" of a talk given by Danny Cohen of ISI.  Dr. Cohen
is chair of the SDI Organization (SDIO) and a member of the "Eastport Group", a
panel on computing in support of battle management:

     The Eastport Group panel was appointed to devise an appropriate
  computational/communication response to the SDI battle management computing
  problem and make recommendations for a research and technology development
  program to implement the response.
      
     The panel concluded that computing resources and battle management 
  software for a strategic defense system are within the capabilities of the 
  hardware and software technologies that could be developed within the next
  several years.

     However, the anticipated complexity of the battle management software
  and the necessity to test, simulate, modify, and evolve the system make
  battle management and command, control, and communication (BM/C3) the
  paramount strategic defense problem.

     Software technology is developing against inflexible limits in the 
  complexity and reliability that can be achieved.  The tradeoffs necessary
  to make the software task tractable are in the system architecture.  The
  "applique approach" of designing the system first and then writing the 
  software to control it is the wrong approach is the wrong approach for SDI.
  System architecture and battle management must be developed together.  This
  was suggested in an earlier report on SDI known as teh Fletcher Report.

     One promising class of system architectures for a strategic defense system
  are those that are less dependent on tight coordination that what is implied
  by the Fletcher Report.  The advantages of this type of architecture include
  robustness, simplicity, and the ability to infer the performance of full-
  scale deployment by evaluating the performance of small parts of the system.

     The panel prefers an unconventional architecture that simplifies the soft-
  ware development and testing tasks over reliance on radical software develop-
  ment approaches and the risk that reliable software could not be developed
  by the "applique approach" at any cost.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Two more mailer problems
</A>
</H3>
<address>
"Sidney Markowitz" 
&lt;<A HREF="mailto:SIDNEY%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Wed 19 Mar 86 16:34:28-EST
</i><PRE>
To: risks@SRI-CSL.ARPA

1) I did not personally see this, but I was told that Symbolics briefly
introduced a new feature in their mail program with the current release of
the operating system. It was a new header line that a sender could use to
include graphics as part of the mail message.  This was implemented by
having the header line include a lisp expression that would be evaluated
(executed) when the receiving mailer loaded the message for display.
Somebody pointed out the other possible ways in which an arbitrary piece of
executed code in a mail message could be used, and that feature was dropped
very quickly.

2) This is not quite on the same level as the above problem, or the old
control character in the message trick, but the following message appeared
in my mailbox some 5 or 6 times over the course of a couple of days. It's
relevant to RISKS as yet another real life example of "nothing can go
wrong... go wrong... go wrong..."

The message was sent to a net distribution list:

[begin edited forwarded message:]

To: info-gnu@PREP.AI.MIT.EDU, info-gnu-emacs@PREP.AI.MIT.EDU
Subject: Duplicate messages

1) Apologies from the chief gnu list maintainer.

2) For a variety of reasons, this happens intermittenly on prep, an
MIT AI Lab machine the lists are hosted on.  For a variety of reasons,
there is little that the GNU staff can do about it, at this time.

3) Thanx for your patience.

[End of edited forwarded message]

Sidney Markowitz &lt;sidney%oz@mit-mc.arpa&gt;

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
bounced mail - i bet that this is for y'all?   [THANKS]
</A>
</H3>
<address>
Andrew Scott Beals 
&lt;<A HREF="mailto:bandy@lll-crg.ARPA">
bandy@lll-crg.ARPA
</A>&gt;
</address>
<i>
Wed, 19 Mar 86 14:46:25 pst
</i><PRE>

From ucdavis!uucp Tue Mar 18 22:41:20 1986
Date: Tue, 18 Mar 86 22:17:29 pst

Mail failed.  Letter returned to sender.
&gt;From seismo!harvard!think!mit-eddie!genrad!panda!talcott!maynard!campbell
  Tue Mar 18 21:30:28 1986 remote from lll-crg
             [...AS USUAL, I DELETED THE ROUTING, ALTHOUGH IT WAS EXCITING...]
Date: Tue, 18 Mar 86 17:36:01 EST
To: ucdavis!ucbvax!sri-csl.arpa!  
Subject: Why would anyone want to computerize voting?  

Why would anyone want to computerize voting?  Doing so only increases the
risk of fraud, by reducing the number of people involved in the process.
("The best deterrent to crime -- witnesses.")  Elections don't happen often
enough that saving money can count for much -- in fact, I believe around
here ballot counters are unpaid volunteers.  Rapidity of the count?  Who
cares whether the results are known in two hours or two days?

Sounds like yet another scheme (remember "computer literacy"?) to enrich
computer companies at the public's expense.

      [There are of course lots of reasons for automating.  But PLEASE,
       let's not get a flurry of messages answering that one here.  This
       is just another fine example of a more complicated solution
       introducing new vulnerabilities and different risks.  PGN]

Larry Campbell                                 The Boston Software Works, Inc.
ARPA: maynard.UUCP:campbell@harvard.ARPA       120 Fulton Street
UUCP: {harvard,cbosgd}!wjh12!maynard!campbell  Boston MA 02109

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Marking money for the blind
</A>
</H3>
<address>
Atrocity Joelll
&lt;<A HREF="mailto: Joelll%UMass.BITNET@WISCVM.WISC.EDU  ">
 Joelll%UMass.BITNET@WISCVM.WISC.EDU  
</A>&gt;
</address>
<i>
Wed, 19 Mar 86  18:02:22 EST
</i><PRE>
To:  risks@SRI-CSL.arpa

On the subject of the bill-denomination-determining in Canada, there is a
method that I noticed is in use in Israel when I was there recently: on
every denomination of shekel notes there is a unique raised pattern of lines
for the use of the sight-impaired and to aid in annoying counterfeiters.
For example, on the five-shekel note there are three dots formed of these
lines, each about 4 mm in diameter, and on the 500 shekel note there is an
oval shape made of the raised lines about 12 mm long and 4 mm wide.

The biggest benefits of this system, in addition to making counterfeiting
harder, are that is is cheap, there is no computer 'denomination reader' to
have vandalized, and that the blind persons who use this service wouldn't
have to go out and find one of these silly machines...

Atrocity Joelll
JOELLL%Umass.Bitnet@wiscvm.wisc.edu

      [One must carefully examine the code of raised symbols to see how
       easily a lower denomination can be changed into a higher 
       denomination.  In Braille, for example, it is easy to change a
       TWO into a ONE (assuming the fingers do not detect a rough
       flattened spot) and a ONE into a TWO (by raising an extra spot).  
       By the way, there are situations in which one might wish to make
       a higher denomination appear as a lower denomination... fooling
       a blind customs official with Altered Braille?  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-87</DOCNO>
<DOCOLDNO>IA012-000128-B045-190</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.32.html 128.240.150.127 19970217002303 text/html 17054
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:21:28 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 32</TITLE>
<LINK REL="Prev" HREF="/Risks/2.31.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.33.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 32</H1>
<H2> Thursday, 20 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Om/Comm-ission, and analysis of risks 
</A>
<DD>
<A HREF="#subj1.1">
Niall Mansfield
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  RSO's and IIP's 
</A>
<DD>
<A HREF="#subj2.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Complex systems ru(i|n)ning our cities 
</A>
<DD>
<A HREF="#subj3.1">
Mike Mc Namara
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Two more mailer problems 
</A>
<DD>
<A HREF="#subj4.1">
Bernard S. Greenberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Banknotes for the visually handicapped 
</A>
<DD>
<A HREF="#subj5.1">
Nigel Roberts
</A><br>
<A HREF="#subj5.2">
 Barbara E. Rice
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Psychological and sociological consequences 
</A>
<DD>
<A HREF="#subj6.1">
Harald Baerenreiter
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
       Om/Comm-ission, and analysis of risks
</A>
</H3>
<address>
          Niall Mansfield 
&lt;<A HREF="mailto:MANSFIELD%DHDEMBL5.BITNET@WISCVM.WISC.EDU">
MANSFIELD%DHDEMBL5.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
Thu, 20 Mar 86 12:30:42 n
</i><PRE>

It is often difficult to decide whether an action carried out really is a
fault of omission or commission. As is so often said, many program failures
are due to not considering a possible set of circumstances, which when it
occurs causes the program to act improperly. In such cases, the damage is
certainly an act of commission, but the real failure is the omission to
predict the failure. I think that any attempt to distinguish formally
between om/comm-ission is likely to lead to sophistic arguments distracting
attention from the real cause of the problem.

Another unproductive approach seems to be suggested by something PGN said in
<A HREF="/Risks/2.27.html">RISKS-2.27</A>:

  &gt; A fine example of the risks having to include people, not just
  &gt; computers, and of a more pervasive role of the computer than meets
  &gt; the eye -- indeed a more human-oriented computer system might have
  &gt; helped!  Thus, even though it appears NOT to be a computer problem,
  &gt; we discover that the computer could have done better!

There are very few cases where a system which has failed could NOT have done
better, so saying it doesn't advance our understanding. It seems that
because RISKS is about computer risks, then we will do our best to find a
computer cause for every failure. (Remember the immediate speculation after
the Shuttle disaster about how a computer could be shown to be responsible).

Surely RISKS should concentrate on failures that occur because of computer
involvement but which would not have occurred with a human-only system,
because systems are always going to fail. As Murray.pa@xerox pointed out in
<A HREF="/Risks/2.21.html">RISKS-2.21</A>, there are risks involved in not using computers, where such use
can lead to saving lives: if a system is doing superb work 99% of the time,
it is fruitless to pick on the 1% failure, and jump on the bandwagon saying
"Ohhhhhh, the computer's run amok, isn't it terrible". We must keep risks
and benefits in perspective. As PGN finished off:

  &gt; But, of course, don't blame the computer system.
  &gt; Blame the people who specified, designed, and
  &gt; implemented it -- not JUST the train operator(s).

This is the heart of the matter - we are looking at the risks (presumably)
so that we humans, the makers of systems, can avoid the same mistakes, not
just for the malicious pleasure of beating the drum about somebody else's
shortcoming.

(So maybe I don't disagree with PGN after all).

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
RSO's and IIP's
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@ee.purdue.edu ">
davy@ee.purdue.edu 
</A>&gt;
</address>
<i>
Thu, 20 Mar 86 07:44:56 EST
</i><PRE>
Cc: risks@sri-csl.arpa

One thing keeps nagging at me after reading your explanation of RSOs and
IIPs.  I suspect it's more from my lack of knowledge about trajectories and
launching things and such than anything else.  Anyway, here goes...

You said several times that if the IIP ever crosses the "safety lines" then
the missile should be destroyed.  What I'm confused about is this:  does
this mean that under "normal" circumstances the IIP never crosses these
lines, or do you mean the missile should be destroyed only if something is
"wrong"?  It seems to me (again I know very little about launching things
and such) that if the IIP can never go "that way" then you are limited in
the directions you can send a rocket (come to think of it I guess I've never
heard of a launch going "back" over the U.S. to get somewhere...).

Also, where does the consideration of the IIP stop?  Something sticks in the
back of my mind that the shuttle flies over land masses (isn't there
someplace in Rota, Spain where they can abort?).  If it does, does this mean
the IIP itself never touches the land masses, or does the IIP become less
important after the missile reaches a certain speed/altitude/trajectory?

Thanks,
--Dave Curry

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Complex systems ru(i|n)ning our cities
</A>
</H3>
<address>
Mike Mc Namara at ESL Sunnyvale Ca
&lt;<A HREF="mailto:lll-lcc!tflop!mac@lll-crg.ARPA ">
lll-lcc!tflop!mac@lll-crg.ARPA 
</A>&gt;
</address>
<i>
Wed, 19 Mar 86 19:07:42 pst
</i><PRE>

	In pursuit of new directions for the RISKS forum, and in response to
a recent article in the New Yorker Magazine, I bring up the subject of the
risks inherent in the complex systems in which we live.  We've probably all
heard talk about how few hours New York City could survive without power/
water/subway/ etc, but perhaps it is worth discussing in this forum.

	The article in the NYM is written from the perspective of a resident
of a self-sufficient rent controlled apartment in the Village, who feeling
quite smug about his castle, suddenly notices all the holes in the wall.
There is the hole letting in electricity, the one for natural gas; there are
lines for taking out the sewage, and lines bringing in fresh water.

	This writer wonders where these lines lead.  He then takes us along
in his search to James Bay in Canada, where New York gets some of its
electricity from hydroelectric plants.  He takes us to Arizona, where some
of the uranium for the Indian Point reactors is mined.  He takes us to
Brazil, where Con Ed gets the low quality diesel oil to burn to make
electricity.

	Similarily, he takes us upstate to the many reservoirs which supply
New York with its world famous water.  He follows the gas mains to Louisiana.

	And so on.  

	I offer to the risk readers the question, How intelligently are we
managing the risks assumed by the creation of our complex cities?  We build
systems so that millions of people can live in areas that are really
deserts.  What risks exists because of the creation of a L. A.  that relies
on 500 mile aqueducts to supply life-critical water?  Who is in charge of
insuring adequate safe guards?  Budget conscious, 2 year term politicians,
or life time members of water boards?  The ramifications of any single
failure of a utility system can probably be maintained via such a board that
takes the long view and has the capitol to implement long term strategies.

	But what about the interdependencies of utilities?  What would a
water shortage do to a nuclear power plant, that perhaps required cooling
water that simply wasn't available?  What would a collapse of the telephone
system do to a natural gas distribution system that used remote pressure
regulators that were controlled via telephone links?

	What organizations exist to worry about such things, so I rest assured 
that there is no problem, and get some sleep at night?  

	What inter-system crashes are the readers aware of, that they might
share with this list?

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Two more mailer problems
</A>
</H3>
<address>
Bernard S. Greenberg 
&lt;<A HREF="mailto:BSG@SCRC-STONY-BROOK.ARPA">
BSG@SCRC-STONY-BROOK.ARPA
</A>&gt;
</address>
<i>
Thu, 20 Mar 86 11:15 EST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

    Date: Wed 19 Mar 86 17:54:33-PST
    From: RISKS FORUM    (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;

    Date: Wed 19 Mar 86 16:34:28-EST
    From: "Sidney Markowitz" &lt;SIDNEY%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU&gt;
    Subject: Two more mailer problems
    To: risks@SRI-CSL.ARPA

    1) I did not personally see this, but I was told that Symbolics briefly
    introduced a new feature in their mail program with the current release of
    the operating system. It was a new header line that a sender could use to
    include graphics as part of the mail message.  This was implemented by
    having the header line include a lisp expression that would be evaluated
    (executed) when the receiving mailer loaded the message for display.
    Somebody pointed out the other possible ways in which an arbitrary piece of
    executed code in a mail message could be used, and that feature was dropped
    very quickly.

This is utterly and wholly false.  No one here would be so naive.

Bernard S. Greenberg, Symbolics, Inc., Cambridge, Mass.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Banknotes for the visually handicapped (<A HREF="/Risks/2.31.html">RISKS-2.31</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:roberts%forty2.DEC@decwrl.DEC.COM">
roberts%forty2.DEC@decwrl.DEC.COM
</A>&gt;
</address>
<i>
Thursday, 20 Mar 1986 01:59:05-PST
</i><PRE>

The Netherlands uses a similar system of raised impressions.  High
denominations are distinguished by different symbols (e.g.  the H.Fl 50 note
has a raised triangle, while lower notes such as the 10 and 25 have dots).
I'm afraid I don't know what the new H.Fl 1000 notes have --- I don't see
them very often :-). Britain, on the other hand simply uses different sizes
of paper for different denominations, as does West Germany.

Nigel Roberts, Reading, England
       [Different sizes of paper don't help the visually handicapped
        discriminate copy-machine products from originals....  PGN]

</PRE>
<HR><H3><A NAME="subj5.2">
Banknotes for the visually handicapped 
</A>
</H3>
<address>
Barbara E. Rice
&lt;<A HREF="mailto:rice@nrl-csr ">
rice@nrl-csr 
</A>&gt;
</address>
<i>
Thu, 20 Mar 86 10:51:27 est
</i><PRE>

     With all the talk about fooling the visually impaired by altering
raised marks on bills or the magnetic ink, has anyone considered how small a
population they are dealing with?  My uncorected vision went beyond legally
blind twenty years ago and has continued to go down hill since then.
Without my glasses I can not see the eyechart much less any letters on it 
(with my glasses I can just scrape by a driver's eye exam).  So I conducted a
test here with my glasses off I was able to distinguish between a five and a
one dollar bill at 6 feet (much further than arm's length).

   So the population that could be fooled by such means I would say is
relativlysmall, too small to it be worth anyones time and effort to steal
from them.  It would also be risky. Most people remember where it is that
they get money from and where they have bought things. Anything larger than
a $20 I definitely know where I got it. The error would be picked up by any
sighted person dealing with the blind person not just an expert in
conterfeit detection thus the altered bill would be rapidly discovered.  So
a person using this scheme would have to be constantly on the move and not
collecting very much for his efforts.  For most large puchases people use
creditcards or cashiers check.  Purse snatching or mugging would yield a
better risk and effort vs profit ratio.

     The point I hope I made is that thinking of methods to get around
marking intended to help the blind is an interesting mental excercise but
none of the methods thought up is a reason for not putting aids to the blind
on currency.  (really a blind customs agent? How many are there and how
would you guarentee you got him? With my luck he would call in sick that
morning and then I would really be in trouble.)  A better reason for not
using such aids is the small number of people who would benefit by it, but
then you should consider the number of would be conterfeiters it might
frustrate into trying other means of getting rich quick.  That would be a
good systems trade off problem.

   [Come on, now.  You think the example of the blind customs agent was
    serious?  I was trying to give you an example where reducing the value
    consituted a risk.  The problem is one of vulnerabilities.   Pacemakers 
    and automobile microprocessors are fine.  But there are some very 
    serious risks that must not remain unconsidered.  Of course there are
    advantages to currency interpreters.  But are they designed so poorly
    that they accept blank pieces of paper with funny symbols embossed on 
    them?  Do they introduce new risks that never existed before?  PGN]
    
</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Psychological and sociological consequences 
</A>
</H3>
<address>
&lt;<A HREF="mailto: ERA01%DHAFEU11.BITNET@WISCVM.WISC.EDU">
 ERA01%DHAFEU11.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
Thu, 20 Mar 86 11:27:54 cet
</i><PRE>
ReSent-To: RISKS@SRI-CSL.ARPA

We are preparing a study about the psychological and sociological consequences 
if young people have intensive contacts with (home-) computers.  So, we are 
looking for empirical studies (in wide spread) dealing with that subject.

Especially we are searching for articles about
  - different methodological approaches (e.g. analytical, ethnological,
    qualitative and quantitative aspects ...)
  - empirical designs and ideas
  - results.
If you have any information (or know anyone who has) please help us.

Contact HARALD BAERENREITER, Fernuniversitaet, Arbeitsbereich Allgemeine
Soziologie, Postfach 940, D-5800 Hagen, F.R.G., or NETMAIL to FROM: field.
Thank you for being so helpful.    Harald.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-88</DOCNO>
<DOCOLDNO>IA012-000128-B045-215</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.33.html 128.240.150.127 19970217002314 text/html 14932
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:21:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 33</TITLE>
<LINK REL="Prev" HREF="/Risks/2.32.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.34.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 33</H1>
<H2> Sunday, 23 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
RSO's and IIP's - Martin Moore's response 
</A>
<DD>
<A HREF="#subj1.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Omissions/commissions and missile destructs 
</A>
<DD>
<A HREF="#subj2.1">
Chris McDonald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Blind and Paper Money 
</A>
<DD>
<A HREF="#subj3.1">
sdo
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Two Cases of Computer Burglary 
</A>
<DD>
<A HREF="#subj4.1">
NY Times
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
RSO's and IIP's - Martin Moore's response
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@ee.purdue.edu ">
davy@ee.purdue.edu 
</A>&gt;
</address>
<i>
Fri, 21 Mar 86 08:00:21 EST
</i><PRE>

This is Martin Moore's response to my questions about RSO's and IIP's
which appeared in <A HREF="/Risks/2.32.html">RISKS-2.32</A>.  It is forwarded with his permission.  Dave

------- Forwarded Message

Good question...I guess I forget that not all of the audience is familiar with 
space launch details and orbital mechanics.  I'll try to explain the IIP's 
relation to the world and how it is used...

Simply stated, the IIP of an object is the intersection of its ballistic 
trajectory (or "orbit") with the surface of the Earth.  An object is in a 
ballistic trajectory when it is not accelerating under its own power; its 
acceleration is due only to gravitational effects (in short, it's falling.)
The trajectory can be determined almost entirely from the object's position 
(mostly altitude) and velocity vector relative to the Earth (there are minor 
effects due to aerodynmaics and various anomalies but these can be ignored for 
this type of calculation -- they take a great deal of computation to yield a 
relatively small correction.)  An object which is resting on the Earth's 
surface is located at its IIP.  An object in free orbit does not have an IIP; 
its orbit does not intersect the Earth's surface.  For an object falling 
through the atmosphere (which is what our missile would do if its thrust 
terminated) the IIP becomes interesting.

Since the IIP is the end result of an object's ballistic trajectory, the IIP 
does not change when the object is not accelerating; conversely, while the 
missile is accelerating, the IIP moves downrange *FAST*.  (Consider that the 
Challenger explosion occurred 8 miles or so downrange, but most of the pieces 
impacted 20-40 miles downrange.)  So on a normal missile launch the IIP starts 
on the launch pad; as the missile launches the IIP moves downrange very fast
until it eventually moves off the planet (if an orbital launch) or to the 
target area (for a weapons test) or something is wrong.  On a shuttle launch, 
the IIP has moved off the planet by MECO (about +520 seconds); the shuttle's 
engines cut off even though it has not yet achieved orbit -- it "coasts" on up 
to orbit based on the velocity vector it has achieved through powered flight.

Now, to answer your question, missiles launched at the Cape NEVER fly over 
land intentionally except at the very first seconds (unavoidable) or during a 
shuttle landing (when the Orbiter is flying by itself and the dangerous parts 
have been dropped.)  This is why the launch facility at Vandenberg was built; 
shuttles cannot be launched into polar orbits from the Cape because there is 
land both due north and due south.  On *any* launch, violation of the destruct 
lines means something is wrong (they are drawn with the missile's nominal 
trajectory in mind) and the population is endangered.  Missiles can be 
obviously bad *without* crossing the destruct line; if a second stage, say, 
fails to ignite, the IIP stops halfway downrange and the missile falls into 
the drink.  It is generally wise to blow it up in this case as if it falls 
intact the fuel is not very good for the environment.  Unmanned missiles are 
pretty easy: something goes wrong, you blow it up.  Obviously, this has to 
modified with the Shuttle; if it's performing an abort you don't blow it up 
(the tanks and solids are already gone; the Orbiter is no threat.)  If it goes 
awry and curves back over land *but* the crew is still in control (which is at 
least theoretically possible) you let it go as long as they are in control -- 
they may be able to recover for a landing or at least get it back over the 
ocean, drop the tank (you don't want to blow it over land -- would shatter 
every window in Brevard County), and try to ditch and have at least a chance
of surviving. 

Whew.  I hope this has answered your question.  Feel free to follow up if it 
hasn't or if you have other questions.

					/mjm
- ------

------- End of Forwarded Message

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Omissions/commissions and missile destructs
</A>
</H3>
<address>
Chris McDonald  SD 
&lt;<A HREF="mailto:cmcdonal@wsmr06.arpa">
cmcdonal@wsmr06.arpa
</A>&gt;
</address>
<i>
Fri, 21 Mar 86 13:09:06 MST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Regarding Dave Curry's musings about his never having heard about a "missile
going back over the US", in fact missiles go over the US on a daily basis at
White Sands Missile Range.  As a 4,000 square mile DoD test facility the
Range has been an inland range for missile and rocket firings for over 40
years.  This fact has some bearing on the discussion of
omissions/commissions in flight safety computers because major cities
surround the Range resulting in legitimate safety concerns.  During the last
40 years not every flight has range boundaries and in one well-publicized
incident a rocket landed in a Juarez, Mexico cemetery.  While redundancy in
flights safety computers has so far precluded an accident or incident
attributable to a computer, there was one incident in which a missile was
destroyed by computer because of a breakdown in trajectory tracking data
transmissions.  The computer was programmed to automatically destroy the
missile if it did not have tracking data from a specified number of radars.
The rationale behind this was that, if one lost radar track given the manner
in which the test was structured, the missile was well off course and should
be destroyed.  Even though there was redundancy in radars, a situation
occurred in which radar problems precluded the flight safety computer from
receiving the anticipated tracking data.  Launch occurred and from all
personnel accounts appeared to be nominal.  But in fact the computer was not
receiving the tracking data immediately after launch to predict what another
contributor referred to as IIP or Instantaneous Impact [that] destroyed the
missile.  All readers can well understand that the project manager for the
missile system involved was extremely upset over the destruction of his test
item.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Blind and Paper Money
</A>
</H3>
<address>
&lt;<A HREF="mailto:celerity!sdo@sdcsvax.ucsd.edu">
celerity!sdo@sdcsvax.ucsd.edu
</A>&gt;
</address>
<i>
Sat, 22 Mar 86 14:35:40 pst
</i><PRE>
Apparently-To: risks@sri-csl.ARPA

One solution I have heard proposed to the problem of the blind being unable
to read the denomination of paper currency is to cut off the corners of the
bills.
	The $1   bill would have 4 corners cut off.
	The $5   bill would have 3 corners cut off.
	The $10  bill would have 2 corners cut off.
	The $20  bill would have 1 corners cut off.
	The $100 bill would have 0 corners cut off.

Forgery would be limited since cutting of a corner of a bill would
decrease its value.

	This is much simpler and less costly than "talking money".

             [This may seem unrelated to Computer RISKS.  However, in
              some cases -- believe it or not -- the best solution may
              not involve technology.  However, this solution still begs
              fraud by copy machine.  It is easy to cut corners off of a
              copy...  But, let's blow the whistle on this topic for now.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
It would take someone really sophisticated, with a Ph.D in math or CS.
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
22 Mar 1986 12:50-PST
</i><PRE>
From: the tty of Geoffrey S. Goodfellow &lt;Geoff@SRI-CSL.ARPA&gt; [...]
Cc: Neumann@SRI-CSL.ARPA

This story made the front page of the Palo Alto TimesTribune:
	
a775 21-Mar-86  12:32  ny  BCBURGLARY
Two Cases of Computer Burglary
(WashPage)   c.1986 N.Y. Times News Service
    
    WASHINGTON - Jennifer Kuiper was working late at her computer terminal
in the office of Rep. Ed Zschau of California on March 7 when she heard
a beep that told her someone had entered the computer system from an
outside telephone line.
    Twenty minutes later, her computer screen went blank. When service was
restored, copies of more than 200 letters sent to constituents and
iformation on mailing addresses had disappeared.
    Four days later, staff workers for Rep. John McCain of Arizona told
the police they had discovered that someone outside their office had
reached into McCain's computer and destroyed hundreds of letters and
mailing addresses over the lunch hour.
    Why the computers were entered from the outside, and by whom, is now
the subject of a criminal investigation by the Capitol police and the
United States attorney for the District of Columbia. They say the have
ruled out the possibility of staff error in destruction of the records
and have some leads. But they refuse to discuss possible motives.
    Both Zschau and McCain are Republicans, neither yet a House leader but
both increasingly visible on Capitol Hill. Both are seeking Senate
seats in the November elections.
    These were apparently the first computer break-ins on Capitol Hill,
where computers are increasingly being used, especially for recordkeeping 
and answering mail.
    ''This is definitely a concern,'' said Inspector Robert R. Howe of the
Capitol police. ''We're looking into better controls to prevent it from
ever happening in the future.''
    Zschau, who taught computer courses at Stanford Business School, and
founded and for 13 years was president of System Industries, a computer
software company, said the illegal entering of his office computer was
''tantamount to someone breaking into my office, taking my files and
burning them.''
    ''I am very concerned,'' he added, ''and the police would be more
concerned if this were a physical break-in.
    ''Because people don't see the files overturned or a pile of ashes
outside the door, it doesn't seem as bad,'' he continued. ''But it is
equally as devastating. We rely on computers a lot for correspondence,
writing articles and keeping a record of the history of the letters and
responses sent to our constituents.
    ''Every office on Capitol Hill can be broken into in this way and the
files deleted. It can bring the work that a member of Congress does to
a complete halt.''
    After both break-ins, the copies of most of the lost records were
regained from duplicate files. ''We were lucky,'' said James M.
LeMunyon, administrative aide to Zschau. ''We had back-up computer
tapes that restored all but 30 of the 200 letters. My greatest concern
was that they might have destroyed our lists of constituents' names.''
    Stephen A. Armstrong, vice president of Micro Research, the company
that provides computers and related equipment to more than 150 members
of Congress, including both Zschau and McCain, said that whoever broke
into the computers ''would have to have a password and two security
codes to get in.''
    In a congressional office that has computers, the system operates
independently of systems in other offices, and each staff member has a
personal password to gain access to computer files.
    For someone to enter the system by telephone from outside the office,
a special switch in the office must be on.
    ''It is possible to break into a system if all physical and software
security measures are ignored,'' Armstrong said.
    ''But it would take someone really sophisticated, with a Ph.D. in math
or computer science.''
    
nyt-03-21-86 1532est

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-89</DOCNO>
<DOCOLDNO>IA012-000128-B045-242</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.34.html 128.240.150.127 19970217002325 text/html 8170
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:21:56 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 34</TITLE>
<LINK REL="Prev" HREF="/Risks/2.33.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.35.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 34</H1>
<H2> Thursday, 27 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
RSO's and IIP's - Martin Moore's response 
</A>
<DD>
<A HREF="#subj1.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Range Safety: a final word 
</A>
<DD>
<A HREF="#subj2.1">
Martin Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Someone really sophisticated, with a Ph.D... 
</A>
<DD>
<A HREF="#subj3.1">
Nigel Roberts
</A><br>
<A HREF="#subj3.2">
 Keith F. Lynch
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: RSO's and IIP's - Martin Moore's response
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!henry@seismo.CSS.GOV">
ihnp4!utzoo!henry@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Wed, 26 Mar 86 20:45:04 EST
</i><PRE>

&gt; Now, to answer your question, missiles launched at the Cape NEVER fly over 
&gt; land intentionally except at the very first seconds (unavoidable) or during a
&gt; shuttle landing...  This is why the launch facility at Vandenberg was built; 
&gt; shuttles cannot be launched into polar orbits from the Cape because there is 
&gt; land both due north and due south...

As an example of how bureaucratic priorities can sometimes override known
safety considerations, it is worth noting that the Office of Mismanagement
and Bean-counting did suggest saving the cost of the Vandenberg shuttle
facility by launching north from KSC.  This idea was a non-starter for about
five different reasons, range safety not least.  It's amazing that it was
ever suggested, but it was -- quite seriously.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,linus,decvax}!utzoo!henry

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Range Safety: a final word
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

Apparently I confused a few people judging by the mail I've gotten...what I 
said about missiles launched at the Cape not flying over land applies ONLY TO 
MISSILES IN THE LAUNCH PHASE.  Obviously, satellites in orbit pass over a 
large part of the Earth's surface.  And as another contributor pointed out,
some test ranges routinely fly missiles over land; I was talking only about 
the Cape, which does not.

I think this discussion is reaching the point of diminishing returns from the 
RISKS viewpoint.  I will continue to answer detailed questions by personal 
mail, but let's move them out of RISKS.

					/mjm                [PGN concurs.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Someone really sophisticated, with a Ph.D...
</A>
</H3>
<address>
&lt;<A HREF="mailto:roberts%forty2.DEC@decwrl.DEC.COM">
roberts%forty2.DEC@decwrl.DEC.COM
</A>&gt;
</address>
<i>
Monday, 24 Mar 1986 05:26:49-PST
</i><PRE>

  ----------reply to mail dated 24-MAR-1986 06:19 [<A HREF="/Risks/2.33.html">RISKS-2.33</A>]-----------

  &gt;     ''It is possible to break into a system if all physical and software
  &gt; security measures are ignored,'' Armstrong said.
  &gt;     ''But it would take someone really sophisticated, with a Ph.D. in math
  &gt; or computer science.''

Since when does a Ph.D in math, or even one in Computer Science, teach you
how to be a hacker (either kind)?

Most of the "Computer Burglars" I have come across were entirely self-taught.

Nigel.
       [I presume that is why Geoff titled it the way he did.  It is guys
        such as Armstrong who are headstrong -- except that their heads are
        in the sand.  They really believe it takes sophistication.  Readers
        of RISKS supposedly know better, although I have tried to be fairly 
        gentle in exposing gross security flaws in existing systems.  PGN]

</PRE>
<HR><H3><A NAME="subj3.2">
Someone really sophisticated, with a Ph.D...
</A>
</H3>
<address>
"Keith F. Lynch" 
&lt;<A HREF="mailto:KFL@AI.AI.MIT.EDU">
KFL@AI.AI.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 24 Mar 86 22:06:43 EST
</i><PRE>
To: Geoff@SRI-CSL.ARPA
cc: RISKS@SRI-CSL.ARPA

  There was a story on the front page of the Washington Post on February
20th headlined "Maryland Computer Whiz Kid Faces Seven Theft Charges" and
subsubtitled "Credit Card Numbers Shared Electronically".  It described a 15
year old who got credit card numbers off a pirate CBBS and ordered computer
equipment over the phone to be sent to a vacant house.  Other than this, the
"whiz kid" did nothing at all remotely exceptional.
  It looks to me like the wave of computer hysteria still hasn't passed.
One of our Senators here in Virginia is introducing a bill to allow
unlimited government snooping into personal computer files on the grounds
that there might be data on child molestation (!) on the floppies.  Seems to
be an equally good case could be made on those grounds for warrantless
searches of personal papers, and any other violations of the Bill of Rights
I can think of.
  Computer security is the responsibility of system managers.  There is a
growing trend toward making microcomputers, often with no security systems
at all, available over phone lines.  Unknown phone numbers are NOT good
security.  Lots of kids dial numbers randomly searching for modem carriers.
  And there can be NO excuse for not having important data backed up.
To make frequent backups should be the first thing anyone learns about
computers.  And being able to easily and frequently save state is one
of the most important things any program should do.
								...Keith

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-90</DOCNO>
<DOCOLDNO>IA012-000123-B018-79</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.35.html 128.240.150.127 19970217002337 text/html 5653
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:22:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 35</TITLE>
<LINK REL="Prev" HREF="/Risks/2.34.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.36.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 35</H1>
<H2> Sunday, 30 Mar 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
San Jose Library 
</A>
<DD>
<A HREF="#subj1.1">
Matthew P. Wiener
</A><br>
<A HREF="#subj1.2">
 Ken Laws
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Inter-system crashes 
</A>
<DD>
<A HREF="#subj2.1">
Rich A. Hammond
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
San Jose Library
</A>
</H3>
<address>
Matthew P. Wiener
&lt;<A HREF="mailto:weemba@brahms.berkeley.edu ">
weemba@brahms.berkeley.edu 
</A>&gt;
</address>
<i>
Fri, 28 Mar 86 00:14:06 pst
</i><PRE>
To: RISKS@sri-csl.arpa

From an article in the 27 March 1986 San Francisco Chronicle:
                    ------------------------------
  An employee of the San Jose public library "destroyed 16 days of records
  and garbled two weeks of circulation files."  A supervisor had "neglected
  to create a backup file".  267,000 books are involved.

  They expect 95.5 percent will be returned on time.  That leaves 12000.
  4000 are routinely returned late.  The other 8000 are considered lost
  at a replacement cost of $10 each, or $80,000.  About $18,000 in overdue
  fines will be lost.

  The system was two months old.  Training was still incomplete.  Several
  employees will be disciplined.

  The blunder might cost three new positions for next year, expected to be
  refilled after cut out by Proposition 13 budget cuts.
                    ------------------------------
I have one remark on the above.

Not only does poor computer usage cause risks to everybody else, I think we
should be concerned about workers who are forced to use unfamiliar systems
and then are held responsible for the damage they did.  Somehow it does not
seem fair, but I believe this is becoming far too common.

</PRE>
<HR><H3><A NAME="subj1.2">
San Jose Library
</A>
</H3>
<address>
Ken Laws 
&lt;<A HREF="mailto:Laws@SRI-AI.ARPA">
Laws@SRI-AI.ARPA
</A>&gt;
</address>
<i>
Thu 27 Mar 86 12:36:52-PST
</i><PRE>
To: Risks@SRI-CSL.ARPA

... at the main library and 17 branches. ...

That's $2,000,000 worth of books unaccounted for.  The library usually gets
95% back without sending out reminders, but with the publicity -- who knows?
They really can't afford to replace even $100,000 worth, even if they knew
what to replace.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Inter-system crashes
</A>
</H3>
<address>
Rich A. Hammond at lafite.UUCP
&lt;<A HREF="mailto:hammond%lafite@mouton.ARPA ">
hammond%lafite@mouton.ARPA 
</A>&gt;
</address>
<i>
Thu, 27 Mar 86 08:32:18 est
</i><PRE>

I worked in a hotel once when they were adding a new wing.  The main water
and electricity systems had to be turned off to connect the new wing.
Management decided to do both at the same time so there would only be one
interruption in service.  The problem:  Turning off the electric power
caused the emergency generator to come on, but the generator was cooled by
water which came from the main and ran into the drain, i.e., no
recirculation.  Of course there was no water, the generator engine managed
to warp its head pretty badly before we shut it off.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-91</DOCNO>
<DOCOLDNO>IA012-000123-B018-99</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.36.html 128.240.150.127 19970217002420 text/html 14450
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:22:28 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 36</TITLE>
<LINK REL="Prev" HREF="/Risks/2.35.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.37.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 36</H1>
<H2> Tuesday, 1 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Errant Clocks 
</A>
<DD>
<A HREF="#subj1.1">
Barry Shein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer Illiteracy 
</A>
<DD>
<A HREF="#subj2.1">
Matthew P. Wiener
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  San Jose Library 
</A>
<DD>
<A HREF="#subj3.1">
Dick Karpinski
</A><br>
<A HREF="#subj3.2">
 Holleran
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Psychological and sociological consequences 
</A>
<DD>
<A HREF="#subj4.1">
Dave Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  More inter-system crashes 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  COMPASS 86:  A Progress Report 
</A>
<DD>
<A HREF="#subj6.1">
Al Friend
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Errant Clocks
</A>
</H3>
<address>
Barry Shein 
&lt;<A HREF="mailto:bzs%bostonu.csnet@CSNET-RELAY.ARPA">
bzs%bostonu.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Sun, 30 Mar 86 21:25:09 EST
</i><PRE>

A reasonable double check before setting the time is to have the
program check the last time the file system on disk was stamped with
(I assume almost all O/S's stamp the time on the disk.)  Certainly on
a re-start time should not have moved backwards, for example, and some
motions forward should be viewed with suspicion (more than say, a few
hours.) This at least can be used to set a lower and upper bounds
before the system screams on the console. UNIX uses this, I am sure
other systems either do or could easily. Of course, this just shifts
us to a different authority, and we know that the crash that started
this cycle just might have damaged the file system, well, I guess that
is left as an exercise for the designer, but at least you get to trust
yourself.
	-Barry Shein, Boston University

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer Illiteracy
</A>
</H3>
<address>
Matthew P. Wiener
&lt;<A HREF="mailto:weemba@brahms.berkeley.edu ">
weemba@brahms.berkeley.edu 
</A>&gt;
</address>
<i>
Tue, 1 Apr 86 05:59:33 pst
</i><PRE>

I'd like to relate a phenomena that happened when I computerized my grading
system some years back.  It used to be I did everything involving grades by
hand, and one summer I finally wrote the software to do it all on by machine.
From my point of view this was wonderful.  I thought it was useful from the
students' point of view: I now passed out individualized summaries of what
my records had, giving them a chance to correct any mistakes I made.  But
one subtle hitch occurred.

Traditionally, I let the students come in at certain appointed hours after
the grades have been computed but before they have been submitted to correct
any last minute errors.  I also take the time to explain their grades and how
they were computed.  It doesn't always make them happy; I cannot be budged
when it comes to my judgement calls.  This last chance office hour can be
quite unpleasant at times--so many students take their grades seriously to
the most ridiculous degrees, and make all sorts of irrational/emotional
appeals to get the better grade.

When I switched over, the following happened.  I was teaching calculus for
non-technical students for the third year in a row, so I was expecting the
same student reactions at grade time--especially from the pre-meds.  Instead,
as soon as a student began his/her complaint, and I said, "OK, let's check
the records here," I'd show them the computer printout and he/she would then
acquiesce immediately.  "Oh, so that is why I only got a B+."  They were, of
course, the exact same numbers that I could have written down by hand on the
specially lined paper provided by the department.

At the time I was elated at this easy solution to the pesky student problem
that I had just found.  But looking back, I find this reaction disturbing,
with possibilities that the new computer illiteracy is actually dangerous
to its victims.

Since then, the only students I've had who aren't put off by the computer
printouts are the ones with actual computer experience and/or actual human
intelligence, which usually occurs in the more advanced math classes.

     [We took this one, but let's go slow on starting a sequence of anecdotes
     on people trusting computers absurdly.  There are enough cases to fill
     up the RISKS Forum forever.  The message is clear, however.  There is a
     lot of ignorance in the general populace.  But do we really know better?

     Perhaps we should pervert the negative Turing Test hypothesis to
     "You can always tell a computer, but you can't tell it much."  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
San Jose Library
</A>
</H3>
<address>
Dick Karpinski
&lt;<A HREF="mailto:ucsfcca.UCSF!dick@ucsf-cgl.ARPA ">
ucsfcca.UCSF!dick@ucsf-cgl.ARPA 
</A>&gt;
</address>
<i>
Mon, 31 Mar 86 03:50:38 PST
</i><PRE>

Considering the amount of loss, perhaps some expert tinkering (a la NSA)
could actually recover the info.  I know we got data off _physically_
crashed hard disks through Data Recovery in LA a couple of years back.

Considering the forum here, perhaps I should mention the crashes we had.
It was Fourth of July when they told me the PDP-11/70 would not boot. 
When I asked, they said one of our three 300MB drives blew a fuse so they
had switched the pack to the center drive normally used for backups.  Not
only did the live data get trashed, but all three generations of our backup
packs had been crashed between the time the backup was done and the time
the pack was replaced with the next in cycle.  Three weeks worth or so,
switching packs in mid day and backing up at 4am.  It took thousands of
dollars and two weeks to get our data back.  We gained new respect for
inter-media backups and for fixed media disks.

Dick

</PRE>
<HR><H3><A NAME="subj3.2">
 San Jose Library
</A>
</H3>
<address>
&lt;<A HREF="mailto: Holleran@DOCKMASTER.ARPA">
 Holleran@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 1 Apr 86 09:32 EST
</i><PRE>
To:  RISKS@SRI-CSL.ARPA

If the public realized that the audit trail for returned books, records,
tapes, et cetera was missing then more of the returned books, records,
tapes, et cetera would not be returned.  Most people return items on
time or not unreasonably late only because there is an audit trail.
Without the audit trail, there is no incentive for timeliness.  A
possible solution might be to lie and say to the newspaper that the
audit trail had been recovered.  As a follow-up, the library could then
offer a penalty free time for the return of all materials.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Psychological and sociological consequences
</A>
</H3>
<address>
Dave Benson 
&lt;<A HREF="mailto:benson%wsu.csnet@CSNET-RELAY.ARPA">
benson%wsu.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Mon, 31 Mar 86 21:28:13 pst
</i><PRE>

	(An inquiry from)
	HARALD BAERENREITER, Fernuniversitaet, Arbeitsbereich Allgemeine
	Soziologie, Postfach 940, D-5800 Hagen, F.R.G.

Regarding the inquiry from Baerenreiter:	The light reading

	Stephen Levy
	Hackers: Heroes of the Computer Revolution
	Doubleday &amp; Co., 1984
	(paperback: Dell Publ Co.)

should suggest some of the psychological and sociological risks associated
with certain forms of computer use.

Please do note that I specifically disclaim any suggestion that computer
use CAUSES these psychological or sociological effects.  It may well be that
certain psychological states induce the forms of computer use mentioned in
Levy's book.	Whatever the case, the book is certainly enjoyable reading.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
More inter-system crashes
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!henry@seismo.CSS.GOV">
ihnp4!utzoo!henry@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Tue, 1 Apr 86 22:16:18 EST
</i><PRE>

Rich Hammond writes, in part:

&gt; ...The problem:  Turning off the electric power
&gt; caused the emergency generator to come on, but the generator was cooled by
&gt; water which came from the [shut off] main...

Apparently there were quite a number of vaguely analogous situations in
the Eastern Seaboard blackout of 1965.  Samples:

One hospital had an excellent emergency generator that cut in promptly, but
it was in the basement.  The hospital was in a low-lying area, and the
basement was kept dry by constant pumping.  You guessed it:  the pumps were
not on the emergency power bus, and the emergency power died as soon as
the rising seepage reached the generator.

Another organization (hospital?) discovered the hard way that its diesel
emergency generator had an AC-powered electric starter.

Most modern power plants need housekeeping power to function, and in
particular to start up.  With the whole grid down, a chicken-and-egg
situation developed very quickly.  The New York area got startup power
from a little power plant on Long Island, whose alert operator had
violated standing orders and simply opened all the circuits -- including
the power-grid tie-line -- when his meters went wild as the grid collapsed.
Boston got startup power from MIT; the MIT EE Dept. generators had been shut
down for the day, but apparently the MIT people managed to put together
enough car batteries (!) to bootstrap themselves.

Practically the only people whose emergency preparations really did work
flawlessly were the professional paranoids:  the military and the phone
company.  Even the air traffic control centers were dead; it was just as
well that it was a clear night with considerable moonlight.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
COMPASS 86:  A Progress Report
</A>
</H3>
<address>
Al Friend
&lt;<A HREF="mailto:friend@nrl-csr ">
friend@nrl-csr 
</A>&gt;
</address>
<i>
Tue, 1 Apr 86 11:21:56 est
</i><PRE>

(From: Albert W. Friend, SPAWAR, Washington, DC)

  The preparations for COMPASS 86 in Washington, 7-11 July are going
quite well.  Many people have expressed considerable interest in the
keynote address by Dave Parnas:

                 When Can We Trust Software Systems?

  We have received a number of abstracts and papers.  
  We should have an excellent attendance, based on the statements of
those who say that they plan to come.
  In reviewing the papers that have come in, we would like to see
more papers in the areas of:

                          Measuring,
                          Assessing,
                          Specifying, and
                          Eliminating

risks due to defects in software, computer hardware design, process
security, etc.   We would be particularly interested in more papers
from the academic community, especially ones with a strong basis in 
the theoretical infrastructure of software engineering, mathematics, 
etc.  Also, papers relating to the psychology of programmers, and the 
possible limitations placed on practical software, would be extremely
interesting.  We have not even one paper in this area so far.
  If you have any bright ideas, COMPASS is the place to try them out.
  Any abstract received by Monday, 21 April will be reviewed by the
program committee.  They should either be sent by U.S. Mail to:

    COMPASS,   P.O.Box 3815,   Gaithersburg, MD 20815

or sent to me over the net at   friend at nrl-csr

                        Albert W. Friend, Program Chairman, COMPASS 86

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-92</DOCNO>
<DOCOLDNO>IA012-000123-B018-118</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.37.html 128.240.150.127 19970217002433 text/html 11863
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:23:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 37</TITLE>
<LINK REL="Prev" HREF="/Risks/2.36.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.38.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 37</H1>
<H2> Sunday, 6 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Request for information about military battle software 
</A>
<DD>
<A HREF="#subj1.1">
Dave Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Programming productivity 
</A>
<DD>
<A HREF="#subj2.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Space Shuttle Software 
</A>
<DD>
<A HREF="#subj3.1">
via PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Open-and-Shut Case Against Reagan's Command Plane 
</A>
<DD>
<A HREF="#subj4.1">
Geoffrey S. Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Computer Illiteracy 
</A>
<DD>
<A HREF="#subj5.1">
Matt Bishop
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Request for information about military battle software
</A>
</H3>
<address>
Dave Benson 
&lt;<A HREF="mailto:benson%wsu.csnet@CSNET-RELAY.ARPA">
benson%wsu.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Sat, 5 Apr 86 17:06:18 pst
</i><PRE>

	The following is an excerpt from a report of the talk by David
Parnas, Lansdowne Professor of Computer Science at the University of
Victoria and consultant to the Naval Research Laboratories in Washington
DC.  The talk was a list of reasons for why the envisaged SDI BMD software
can never be trusted to work.  The full report appeared recently on the
arms-d bulletin board.  To me, the most telling point reported is contained
in the following exerpt from the report of the talk:

   -------------------------------------------------------------------------
   The other members of the SDI advisory panel that David Parnas was on
   and other public figures have said "Why are you so pessimistic?  You don't
   have any hard figures to back up your claims."  Parnas agreed that he
   didn't have any until he thought of the only one that he needed: ZERO.
   ZERO is the number of real systems that were trustworthy at first use.
   ZERO is the number of real systems that met unknown requirements at
   first use.  ZERO is the number of prototyped systems that worked at first
   use.  ZERO is the number of simulated systems that worked at first use.
   ZERO!
   ----------------------------------------------------------------------------

To set the context, Professor Parnas is discussing military battle
software in the above, or so the report leads me to believe.


Question:  Can anyone offer evidence of military battle software which
belies any of Professor Parnas' claims as reported above?  Does anyone
know about software which belies any of Professor Parnas' claims, even
if they cannot, for security or other reasons, provide evidence?

I would greatly appreciate learning of such.  
   E-mail address: benson.wsu@csnet-relay
   Postal service address: Professor David B. Benson, Computer Science
     Department, Washington State University, Pullman WA 99164-1210, USA

Thank you very much for whatever information you can provide.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Programming productivity
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!henry@seismo.CSS.GOV">
ihnp4!utzoo!henry@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Fri, 4 Apr 86 07:52:30 EST
</i><PRE>

In the course of catching up with a backlog of reading, the October 1985
issue of SEN (the ACM SIGSOFT newsletter) came to the top of the pile.
Among its contents is an informal report by Jim Horning on his visit with
a committee assessing the solvability of the SDI software problem.  What
I found most interesting was his report of a comment by one of the folks,
Lipton I think, to the effect of "The physicists, given a few billion
dollars, are quite willing to commit themselves to improvements of several
orders of magnitude in laser efficiency.  The computer science community
is unwilling to suggest even one or two orders of magnitude improvement
in the software-production problem."  Granted that the comparison is not
really entirely fair, this still got me thinking.

I went and re-read Terry Winograd's old "Reactive Engine" paper.  He comments,
roughly:  "If, by decree of God or ARPA, we were only allowed to run one user
at a time on the PDP-10, just think of all the effort that would be invested
in making that one user's time productive."  Despite the enormous increases
in computing power available to individual users since then, that has not
happened:  much of that extra power is simply being thrown away.  Most of
the millions of personal computers out there spend most of their *active*
time (when a user is actually seated in front of them using them) idling.
Even the LISP machines are a pale shadow of the sort of thing that Winograd's
observation calls to mind.

The other thing that came to mind was the genesis of the "Chief Programmer
Team" in the "super-programmer" experiment at IBM.  The key fact about the
C.P.T. approach is that it was *not*, in its original form, a team at all:
it was a support system for a single programmer.  Consider the elaborate
support setup that surrounds, say, a top trial lawyer:  assistants, clerks,
information-retrieval specialists, etc., all there to make sure that the
central figure can spend his time using his unique abilities, rather than
squandering endless hours on chores that don't require such skill.

How many programmers, even ones working on life-critical software like
airliner flight control or fiercely difficult problems like ballistic-missile
defence, have the kinds of electronic and human support that these thoughts
suggest are possible?

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Space Shuttle Software
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Sun 6 Apr 86 11:54:20-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

In another post mortem on the Challenger explosion, the 6 Apr 86 SF Sunday
Examiner &amp; Chronicle ran a Chicago Tribune story on the presidential
commission finding "a tangle of bureaucratic underbrush":
 
  "Astronauts told the commission in a public hearing last week that poor
   organization of shuttle operations led to such chronic problems as
   crucial mission software arriving just before shuttle launches and the
   constant cannibalization of orbiters for spare parts."

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Open-and-Shut Case Against Reagan's Command Plane
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
4 Apr 1986 11:47-PST
</i><PRE>
From: the tty of Geoffrey S. Goodfellow &lt;Geoff@SRI-CSL.ARPA&gt;
To: Risks@SRI-CSL.ARPA
	
    SAN BERNARDINO, Calif. (AP) - When President Reagan comes to
California for vacation, thousands of homeowners lose their automatic
garage door openers to the interests of national security, a
businessman says.
    Larry Murdock, owner of Genie Garage Doors in San Bernardino, says
he's certain that high-powered radio transmissions from the
president's airborne command post jam the signals of the
remote-control switches that open and close garage doors.
    Murdock said Thursday he'd had 800 or 900 calls since Reagan arrived
Sunday for a vacation at his Santa Barbara ranch. The E-4B plane is
parked about 10 miles south of here at March Air Force Base.
    Press officers for the Air Force and Secret Service would neither
confirm nor deny knowledge of garage-door problems.
    ''We are concerned the president is in a safe and secure
environment, and that plane is just that,'' Secret Service spokesman
Bill Corbett told the San Bernardino Sun.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Computer Illiteracy 
</A>
</H3>
<address>
Matt Bishop 
&lt;<A HREF="mailto:mab@riacs.ARPA">
mab@riacs.ARPA
</A>&gt;
</address>
<i>
2 Apr 1986 0804-PST (Wednesday)
</i><PRE>

(This follows Matthew Weiner's message in Risks Vol. 2, No. 36)

This underscores a problem a lot of people have with computers -- they tend
to regard them as "infallible."  I always try to plant some seeds of doubt
when I talk to people like that -- when I opened my bank account, the person
at the bank did a quick electronic check to see if I was in trouble
financially (she didn't call it a credit check when I asked.)  While the box
buzzed, I asked where it got its information, and she said she didn't know
but was certain "the computer" was always accurate.  She was quite surprised
when I laughed and explained that that is not necessarily true.  We talked
about it, and her comment was, "Great -- now I'll always wonder if the
computer's right whenever I do this check."

Maybe someday people who use computers (as opposed to those who program
them) will learn not to trust them completely.

Matt Bishop

    [By then there wouldn't be any computer jobs left.  AI programs will do
     everything, including being the users, and we can all go down to the 
     seashore.  But we probably wouldn't be able to go in the water.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-93</DOCNO>
<DOCOLDNO>IA012-000123-B018-142</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.38.html 128.240.150.127 19970217002446 text/html 14693
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:23:14 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 38</TITLE>
<LINK REL="Prev" HREF="/Risks/2.37.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.39.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 38</H1>
<H2> Wednesday, 9 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The UK Driving Vehicle Licensing Centre 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer crime wave 
</A>
<DD>
<A HREF="#subj2.1">
Chris Hibbert
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Programming productivity 
</A>
<DD>
<A HREF="#subj3.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Request for information about military battle software 
</A>
<DD>
<A HREF="#subj4.1">
Scott E. Preece
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Aviation Week Technical Survey:  AI &amp; Aviation 
</A>
<DD>
<A HREF="#subj5.1">
Werner Uhrig
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The UK Driving Vehicle Licensing Centre
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:brian%cheviot.newcastle.ac.uk@cs.ucl.ac.uk">
brian%cheviot.newcastle.ac.uk@cs.ucl.ac.uk
</A>&gt;
</address>
<i>
Tue, 8 Apr 86 12:03:45 gmt
</i><PRE>

Several newspapers and magazines here have carried stories about
the alleged activities of hackers regarding the Driving Vehicle Licensing
Centre - a very large computer system that has received much bad
publicity in the press and in parliament over the years because
of cost over-runs and delays.
Here is a sample, from  the April 1986 glossy journal "Business":

  "Computer hackers have been running a brisk racket "cleaning up" the
  driving licences of wealthy business men. For a charge of [pounds] 100
  a point endorsements have been erased from the files of the British
  Government's Licensing Centre at Swansea and its supposedly impenetrable
  computer ordered to issue new licences. Drivers who accumulate 12 penalty
  points within 3 years are liable to ban or disqualifications. Reckless
  driving, for instance, attracts 10 points; failing to stop after an accident
  5.9 points; drunken driving 10 points (plus a 12 months disqualification).
  Drivers' records at Swansea are held on the Department of Transport's
  3081 Model G mainframe, whose manufacturers, of course, are not responsible
  for its customers security procedures. About a year ago, an access code
  number appeared on at least four "bulletin boards" - informal computer
  games and information exchange facilities set up and used by home computer
  enthusiasts (not in this instance mischevious schoolboys).
  "I am not suggesting the number on the board was that of the DVLC", says a
  source, "but it gave you access to a database with levels of password 
  protection. It was obviously a secure system and was related to DVLC
  because the name headed the file. The access was not very privileged
  but knowing the procedures allowed priority in the system and enabled you
  to eliminate endorsements and order new licences to be issued."
  Amendments to the DVLC mainframe were automatically carried through to
  the back-up records kept on magnetic disc storage."
 
Such stories have inspired denials from the DVLC - for example in Datalink:

  "The Driving and Vehicle Licensing Centre in Swansea has denied press
  reports that computer hackers have broken into its database and wiped
  traffic offenses off driver records.
  The DVLC, which employs 1500 staff in a computer centre running a variety of 
  kit including two IBM 3083s, is adamant that its system is secure from 
  outside interference. "We have no dial-in facility, there's no electronic
  access at all from off-site," a spokesman said.  

Some 160 programmers work at the DVLC, and the spokesman admitted that
officials are "looking at internal arrangements" to see whether files have
been amended in return for payment."

My cynical view is that from most other sources such a denial would be
immediately accepted, and indeed it may well be true. However the thought that
such record tampering just might be going on, and so allowing banned drivers
back onto the roads, is a worrying one.

Cheers, Brian Randell - Computing Laboratory, University of Newcastle upon Tyne

  ARPA  : brian%cheviot.newcastle@ucl-cs.arpa
  UUCP  : &lt;UK&gt;!ukc!cheviot!brian
  JANET : brian@uk.ac.newcastle.cheviot

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
computer crime wave
</A>
</H3>
<address>
&lt;<A HREF="mailto:Hibbert.pa@Xerox.COM">
Hibbert.pa@Xerox.COM
</A>&gt;
</address>
<i>
Wed, 2 Apr 86 10:53:29 PST
</i><PRE>
To: RISKS FORUM (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;

There was an article in the March 31, 1986 edition of the Washington
Post's National Weekly Edition titled "The Computer Crime 'Wave': It's
more politician's bark than our byte".

After an initial few paragraphs in which the writer reminded us that
"national commissions that are set up to study and report on This Trend
or That Issue always end up concluding that the trend/issue in question
is a bigger national problem than anybody ever imagined", the article
reported on the "First Annual Statistical report" from the National
Center on Computer Crime.  

"Over a two year period, the national center surveyed 130 prosecutor's
offices in 38 states and asked how many computer crimes each office had
encountered. ...  The national center's survey of prosecutors came up with a
grand total of 75 reported 'computer crimes.'  Even that minuscule number,
it must be noted includes some infractions that can only be classified
'computer crime' if you stretch the language considerably.  One reported
case involves ... a county prosecutor ...  who got a friend in the motor
vehicle department to delete two speeding tickets from his driving record.
This is labeled 'computer crime' because the record was on a computer tape...

In short, this first national census says that 'computer crime,' by any
stretch of the definition, is a statistically minute phenomenon.  The antics
of a few hackers have garnered grossly disproportionate attention from the
media and the law-enforcement community.  So-called 'computer crime' is
novel and exciting, so it's hardly surprising that even a few cases would
attract considerable notice.

But Legislators around the country are acting as if there really is a
'computer crime' problem.  The center's study shows that 22 states
passed new 'computer crime' legislation in the past two years. ..."

Chris

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Programming productivity
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sun, 6 Apr 1986  23:45 EST
</i><PRE>

    From: ihnp4!utzoo!henry at seismo.CSS.GOV

    I went and re-read Terry Winograd's old "Reactive Engine" paper.  He
    comments, roughly: "If, by decree of God or ARPA, we were only allowed
    to run one user at a time on the PDP-10, just think of all the effort
    that would be invested in making that one user's time productive."
    Despite the enormous increases in computing power available to
    individual users since then, that has not happened: much of that extra
    power is simply being thrown away.

True enough.  But why do you think that large amounts of effort
invested would necessarily improve productivity?  Despite long
practice, for example, people can hold only a few ideas simultaneously
in short term memory.  There are mnemonic aids available, but they
don't enable someone to do hundreds of times better.

I use this analogy because there is some evidence that limitations
on short-term memory account for a variety of cognitive limitations,
among which may be programming.  Ultimately, it may the limitations of
the human mind that prevent us from forever expanding our achievements.

    How many programmers, even ones working on life-critical software like
    airliner flight control or fiercely difficult problems like
    ballistic-missile defence, have the kinds of electronic and human
    support that these thoughts suggest are possible?

That's easy.  Not many.  Indeed, military software procurement is by
all accounts an utter mess.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Request for information about military battle software
</A>
</H3>
<address>
Scott E. Preece
&lt;<A HREF="mailto:preece%ccvaxa@gswd-vms ">
preece%ccvaxa@gswd-vms 
</A>&gt;
</address>
<i>
Mon, 7 Apr 86 09:43:05 cst
</i><PRE>

&gt; [Parnas, quoted by Dave Benson]

&gt; The other members of the SDI advisory panel that David Parnas was on
&gt; and other public figures have said "Why are you so pessimistic?  You
&gt; don't have any hard figures to back up your claims."  Parnas agreed
&gt; that he didn't have any until he thought of the only one that he
&gt; needed: ZERO.  ZERO is the number of real systems that were trustworthy
&gt; at first use.  ZERO is the number of real systems that met unknown
&gt; requirements at first use.  ZERO is the number of prototyped systems
&gt; that worked at first use.  ZERO is the number of simulated systems that
&gt; worked at first use.  ZERO!
----------
There are two essential, undefined terms in this statement: "first use"
and "worked".  The shuttle Enterprise, for instance, worked the first
time they dropped it from its carrier 747.  Was that its "first use", or
do you count the many hours of simulation preceding that first flight?
I wasn't there and have no idea whether there were bugs that showed up,
but they clearly didn't keep the test from succeeding.  Is that
"working"?

The trouble with a debate like this is that it tends to force people
more and more into idiotic dichotoomized positions.  SDI software would
obviously be a huge challenge to produce and validate.  I have no hope
it would work perfectly the first time used; I have no reason to believe
it wouldn't work partially the first time it was used.  The question of
how perfectly it has to work is the central one.  All the reports I've
seen on both sides, including Parnas's essays, are hand waving.  The
task is too ill defined to be making statements about whether it can be
done.  The debate is silly.  If you build the thing, you don't trust
your security to it until you have been damned well convinced that it
works; I am unwilling to accept the statement that "You can never be
convinced that it works," when daily we all trust our lives dozens of
times to things that we have been convinced work.  There are plenty of
good and, I think sufficient, arguments for not building SDI without
claiming that it can't be done.

-- 
scott preece
gould/csd - urbana
ihnp4!uiucdcs!ccvaxa!preece

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Aviation Week Technical Survey:  AI &amp; Aviation
</A>
</H3>
<address>
Werner Uhrig  
&lt;<A HREF="mailto:CMP.WERNER@R20.UTEXAS.EDU">
CMP.WERNER@R20.UTEXAS.EDU
</A>&gt;
</address>
<i>
Tue 8 Apr 86 11:06:41-CST
</i><PRE>
To: aviation@R20.UTEXAS.EDU, risks@R20.UTEXAS.EDU
Message-ID: &lt;12197222935.31.CMP.WERNER@R20.UTEXAS.EDU&gt;

[ I am sure, readers of AVIATION and RISKS are interested also;
  for somewhat different reasons, of course ....		---Werner ]

                ---------------

Date: Wed 26 Mar 86 09:08:28-PST
From: Oscar Firschein &lt;FIRSCHEIN@SRI-IU.ARPA&gt;
Subject: Aviation Week Technical Survey


AILIST readers might be interested in the following:

Aviation Week and Space Technology, Feb. 17, 1986 has a technical
survey of artificial intelligence, mostly applied to military
applications.  Included are the DARPA-supported programs in Pilot's
Associate and the Autonomous Land Vehicle (ALV) and the VLSI lisp
machine being built by Texas Instruments.

Company profiles include McDonnell Aircraft's work in the Pilot's
Associate and avionics maintenance expert system; Boeing's AI Center;
MITRE's work in natural language understanding; Grumman's decision
support systems; Hughes AI center; and Westinghouse avionics
troubleshooting expert system.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-94</DOCNO>
<DOCOLDNO>IA012-000123-B018-162</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.39.html 128.240.150.127 19970217002459 text/html 14129
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:23:27 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 39</TITLE>
<LINK REL="Prev" HREF="/Risks/2.38.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.40.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 39</H1>
<H2> Friday, 11 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
$36 million accounting mistake 
</A>
<DD>
<A HREF="#subj1.1">
Graeme Hirst
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Admissability of computer files as evidence? 
</A>
<DD>
<A HREF="#subj2.1">
Kathryn Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Rapid advance" of SDI software 
</A>
<DD>
<A HREF="#subj3.1">
Walt Thode
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Blame-the-computer syndrome 
</A>
<DD>
<A HREF="#subj4.1">
JAN Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Hackensack Phone Snafu 
</A>
<DD>
<A HREF="#subj5.1">
Dirk Grunwald
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
$36 million accounting mistake
</A>
</H3>
<address>
Graeme Hirst 
&lt;<A HREF="mailto:gh%utai%toronto.csnet@CSNET-RELAY.ARPA">
gh%utai%toronto.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Thu, 10 Apr 86 12:10:32 est
</i><PRE>

[From the [Toronto] Globe and Mail, 10 April 1986]

BLUNDER BY ALBERTA COMPUTER LEADS TO $36 MILLION MISTAKE

A botched computer operation jeopardized the [Canadian province of] Alberta
Government's ability to keep track of vehicle licence revenue, causing
$36 million too much to be reported in a bank balance, the province's
Auditor-General reported yesterday.

  The Solicitor-General Department's new motor vehicles computer system was
designed with little help from department accounting staff, an omission which
``undoubtedly'' led to many of its weaknesses, said Auditor-General Donald
Salmon.

  The division's bank balance was shown at $48 million on March 31, 1985, when
it was actually $12 million.

  In addition, the vehicles division lost track of accounts which could not
be immediately processed, and unearned revenues were misstated by $2 million in
March of 1985.

  ``These and other ancillary problems were caused largely by insufficent
direction and control by senior financial management,'' the report said.

  The Auditor-General picked up similar problems in 1981-82 in a massive new
computer system developed to keep track of about $2 billion a year in natural
gas royalties.

  Oil revenues were miscalculated in a confused federal-provincial transfer of
information involving three different price categories under the old regulated
pricing system.

  The governments later agreed to forget it rather than try to sort out the
mess.

  ``The province didn't lose money,'' Mr Salmon said.  ``You could probably say
the producers lost some . . . but we did not quantify.''

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Admissability of computer files as evidence?
</A>
</H3>
<address>
Kathryn Smith
&lt;<A HREF="mailto:kathy%gsg.UUCP@harvard.HARVARD.EDU ">
kathy%gsg.UUCP@harvard.HARVARD.EDU 
</A>&gt;
</address>
<i>
Thu, 10 Apr 86 12:02:39 est
</i><PRE>

    This arises out of a discussion in mod.legal over the meaning of UNIX
as a trademark, and how it (the name) might/might not pass into the public
domain by becoming a generic descriptive term for a type of operating system
rather than refering to a specific product of AT&amp;T.  One of the postings 
which I quote below raised the broader question of the use of postings to
a computer network as evidence.  

	In a recent posting (Message-ID: &lt;8604011618.AA15083@bu-cs.ARPA&gt;),
Barry Shein said the following:

	"What immediately occurs to me is that if I were an ATT lawyer I
	would squirrel away the note imploring people not to attribute
	UNIX as a (whatever) of (whomever.) It could prove very useful
	to open an argument that any appearance of it coming into
	common use was in fact a conspiracy on the part of the technological
	community."

   I have no idea of the likelihood of the "conspiracy" defense working to
hold onto AT&amp;T's trademark, however the part about holding onto the note
got me to thinking.  Does anyone out there know if any precedents have been
set for the admissability/inadmissability of computer files as evidence in
court?  

    I, for one, find the thought that some court of law might, in ignorance,
accept computer files as evidence frightening.  Certainly on UNIX if you can
get access to a privileged account, whether legally or illegally, you can 
change anything on the system, including editing i-node entries to alter 
creation dates, etc., with no way I can think of of proving that alterations
were made unless the hacker does something extra-ordinarily stupid.  I suspect
that the same is true of most other systems.  No matter how good system 
security is, given sufficient knowledge of how it works, it is breakable.  

    Coupled with the unfortunate tendency of the layman to accept whatever
comes out of a computer as gospel, this provides some very strong reasons for 
not trusting computer files as evidence, but considering the growing number of 
transactions being performed by/on computers, there are, or soon will be, a 
great number of areas where the computer's audit trail may be the only evidence
of a transaction.  Have any precedents been set already, and if not, what do 
people think the solution is?

					Kathryn Smith
					(...decvax!gsg!kathy)
					General Systems Group
					Salem, NH

   [This is a very valid question.  The crypto community has all sorts of
    techniques for crypto sealing for integrity and crypto authentication.
    Reasonable techniques exist to give some better assurance, but there
    are always going to be some internal vulnerabilities.  However, since
    most legal and administrative people do not yet recognize the ease with
    which on-line evidence -- including audit trails -- can be altered, and
    for other reasons as well, these techniques are not yet in widespread
    use.  PGN]
  
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Rapid advance" of SDI software 
</A>
</H3>
<address>
&lt;<A HREF="mailto:thode@nprdc.arpa">
thode@nprdc.arpa
</A>&gt;
</address>
<i>
9 April 1986 0807-PST (Wednesday)
</i><PRE>

In an article in the Sunday San Diego Union, Gregory Fossedal (Copley
News Service) discusses the "rapid advance of SDI."  He indicates that
progress is good enough that a "decision to deploy a Star Wars defense ...
could be made before Ronald Reagan leaves office."  He describes some
progress made in lasers and other hardware areas.  He then goes on to
discuss progress by software engineers, and says that "concepts in
computer software ... have leaped ahead."  He indicates that critical
arguments "...that 'a single error' could cripple the whole shield apply
only to outmoded types of unwieldy, highly centralized software.  Thanks
to new software ideas, Star Wars defenses need not be run by a grand
central brain."

--Walt Thode (thode@nprdc)

   [Announcements of great BREAKTHROUGHS often coincide with great BREAKDOWNS 
    -- in communication and common sense.  This one is being hyped like a 
    great BREAKFAST cereal -- distributed Wheaties are better than old
    Wheaties, the breakfast of chumpions.  Don't put all your eggs in one
    basket -- just use thousands of baskets instead, and train the hens to 
    BREAKDANCE in space.  But don't forget to distribute the roosters as well.
    Walt, thanks for the enlightenment.  

    I note that in principle there are indeed some software engineering 
    advances, but nothing that GUARANTEES that distributed systems are sound
    -- especially in their operating environments.  The tradeoffs are very
    complex, and thus this is not a simple discussion.  Many problems of
    centralized systems reappear in other guises in distributed systems, and 
    wonderful new problems arise.  Perhaps some day we will have a
    dispassionate, technically motivated analysis -- although many of the
    arguments are nontechnical.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Blame-the-computer syndrome
</A>
</H3>
<address>
     
&lt;<A HREF="mailto:JANLEE%VTCS1.BITNET@WISCVM.WISC.EDU">
JANLEE%VTCS1.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
Wed,  9-APR-1986 09:37 EST
</i><PRE>

One of my colleagues, a visiting prof. from the UK, bought a new Ford Escort
in mid-February and at the same time purchased the "Extended Warranty"
package.  Following a trip to Florida for Spring break, the vehicle broke
down outside Daytona (that may suggest this is a put-up job!!)  on Saturday
afternoon March 29th (also Easter Weekend).  Calling the 800 number he was
referred to a specific repair shop.  On arriving there the owner called the
800 number to confirm the warranty and was told that there was no record of
a warranty "in the computer" and that any additional enquiries would have to
wait until Monday.  They stayed in a hotel over the weekend (at a high rate
since they had no reservations and limited means of transportation) and on
Monday were again informed that there was no record of their warranty.  It
took most of the rest of that day to have the dealer from whom they
purchased the car to confirm that ARTh a warrenty did exist and to have the
repair shop agree to START the repairs.  It turns out that the dealer
doesn't send in the warranties until the end of each month, and the backlog
doesn't allow the warrantor to get them in the computer for perhaps another
month.  This is probably based on the probability that a new car won't need
repairs in the first two months and in any case the owner would probably be
close to home still!  Here is a typical case of having a computer in the
system and thus being able to "hide" behind it.  By the way, check you own
extended warranty to see if it covers the cost of hotel accomodations!

Also, I am still researching the Melbourne Bridge Failure for you -- I have
got the sequence of events and a precis of the findings of the Royal
Commission which blamed the failure on a computer program, but I am waiting
for a copy of the actual report before I send you more.  The sequence of
events is well documented in the London Times but I am not sure I want ot
trust their reporting on this about the program use until I see the report.

JAN

PS. Did you see the Hackers Report in CACM this month?   [Yup.  Arrived today.]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Hackensack Phone Snafu 
</A>
</H3>
<address>
Dirk Grunwald
&lt;<A HREF="mailto:grunwald@b.CS.UIUC.EDU ">
grunwald@b.CS.UIUC.EDU 
</A>&gt;
</address>
<i>
Thu, 10 Apr 86 16:04:50 CST
</i><PRE>

According to a NYT article reprinted in the Daily Illini, a local student
newspaper, the phone system in Hackensack N.J. experienced a problem with
billing long-distance phone calls from pay-phones. I quote:

	Technology in an electronic switching center here failed
	New Jersey Bell, and for nearly two months perhaps half
	the international calls placed from 400 pay phones around
	town went through without charge, according to Ted Spencer,
	a spokesman for the company.
	  ``Apparently a problem developed in a computer program - in
	the software,'' Spencer said. ``We don't have a record of the
	calls that got through. They bypassed the billing system.''

Does anyone have anymore in-depth information concerning this? Several
people who used the loop-hole were arrested and charge with theft of
services.

Dirk Grunwald, Univ. of Illinois

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-95</DOCNO>
<DOCOLDNO>IA012-000123-B018-192</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.40.html 128.240.150.127 19970217002513 text/html 17672
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:23:41 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 40</TITLE>
<LINK REL="Prev" HREF="/Risks/2.39.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.41.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.39.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.41.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 40</H1>
<H2> Saturday, 12 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
GREAT BREAKTHROUGHS [Red Herrings swimming upstream?] 
</A>
<DD>
<A HREF="#subj1.1">
Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Military battle software ["first use", "works"]    
</A>
<DD>
<A HREF="#subj2.1">
James M Galvin
</A><br>
<A HREF="#subj2.2">
 Herb Lin
</A><br>
<A HREF="#subj2.3">
 Scott E. Preece
</A><br>
<A HREF="#subj2.4">
 Dave Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  First use - Enterprise 
</A>
<DD>
<A HREF="#subj3.1">
Lindsay F. Marshall
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
GREAT BREAKTHROUGHS [Red Herrings swimming upstream?]
</A>
</H3>
<address>
Peter Neumann
&lt;<A HREF="mailto:Neumann@SRI-CSL ">
Neumann@SRI-CSL 
</A>&gt;
</address>
<i>
Fri, 11 Apr 86 07:34:38 pst
</i><PRE>
To: RISKS

In this issue of RISKS, we include a commentary on the article by Fossedal,
contributed to me privately by Dave Parnas, reproduced with his permission.

   &gt;In an article in the Sunday San Diego Union, Gregory Fossedal (Copley
   &gt;News Service) discusses the "rapid advance of SDI."....  He then goes on to
   &gt;discuss progress by software engineers, and says that "concepts in
   &gt;computer software ... have leaped ahead."  He indicates that critical
   &gt;arguments "...that 'a single error' could cripple the whole shield apply
   &gt;only to outmoded types of unwieldy, highly centralized software.  Thanks
   &gt;to new software ideas, Star Wars defenses need not be run by a grand
   &gt;central brain."

Message from Dave Parnas follows:

        One of the more amazing aspects of this report is that no plan 
   ever called for the defenses to be run by a "grand central brain".  If
   you read the unclassified volume of the Fletcher report, you will find
   a proposal for a highly decentralized distributed system.  The Fletcher
   panel worried about the survivability of the system and proposed a  
   system in which each battle station could function on its own if others
   were destroyed.  They even rejected a military-like hierarchical 
   command structure for the computers so that there would be no "Achilles
   Heel" in the system.  Nothing that I have read ever proposed a centralized
   system.
   
        When the SDIO Panel on Computing in Support of Battle Management
   (PCSBM) announced that people were assuming a highly centralized system 
   as per the Fletcher report they were using a classic political technique,
   the "red herring".  The Fletcher panel was not anywhere near as stupid
   as they implied.  I have not seen the contractor designs but I cannot
   believe that they were as stupid as was suggested either.  

        Some of the newspaper reports on the PCSBM red herring suggest that 
   there is a proposal to build a network in which the battle stations remain
   autonomous by having no communication.  That is simply not the case.  Every
   report that I have seen calls for extensive communication between those
   stations.  Weapon Stations that were denied the use of data obtained by
   other satellites would be severely handicapped and more easily defeated.
   
        Fossedal's reference to "a single error" is part of another red
   herring in which SDIO supporters claim that the critics want perfection.
   The only reference to "error free software" came from SDI supporters,
   none of the critics have assumed that perfection was needed.  You only
   have to get rid of the errors that matter.  Some claim this as a new
   discovery as well.

        When Fossedal reports such great progress, it is progress from a 
   position that was never held by any responsible computer system designer.

[End of message from Dave Parnas]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Military battle software 
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Thu, 10 Apr 86 15:52:59 -0500
From: James M Galvin &lt;galvin@dewey.udel.EDU&gt;

&gt; From:   preece%ccvaxa@gswd-vms (Scott E. Preece)
&gt; Date:   Mon, 07 Apr 86 09:43:05 -0600.
&gt; 
&gt; There are two essential, undefined terms in this statement: "first use"
&gt; and "worked". ...

What about your essential, undefined phrase "convinced that it works"?
In the context of your argument I assume you are being facetious, but it
is not clear.  I will agree with you if what you are saying is that
"convinced that it works" is really just a "small probability of failure".
True, I trust my life to my car every day, but who's to say that someday
the steering column won't fail.

The next question is how small a probability is desired and how is it
achieved?  Isn't that an essential component of Parnas' argument?

Jim

</PRE>
<HR><H3><A NAME="subj2.2">
Information about military battle software 
</A>
</H3>
<address>
Scott E. Preece
&lt;<A HREF="mailto:preece%mycroft@gswd-vms ">
preece%mycroft@gswd-vms 
</A>&gt;
</address>
<i>
11 Apr 1986 08:58-CST
</i><PRE>
To: galvin%dewey.udel@gswd-vms
Cc: RISKS@sri-csl.arpa

 &gt; The next question is how small a probability is desired and how is it
 &gt; achieved?  Isn't that an essential component of Parnas' argument?

Yes, I think that's the essential question.  I think Parnas is saying that
you can never prove adequately that the probability is sufficiently small,
so you might as well not work on the question.

I wear my seatbelt BECAUSE there is always a probability that my steering
will fail or the wetware guiding some other vehicle will fail.  I know there
is also a small probability of the seatbelt failing, too, but there the risk
is low enough for me to accept.  If I could have airbags in a car I could
afford, I would.

I don't know if it is possible to build software systems capable of dealing
with the problems inherent in SDI.  I don't know what level of testing and
verification would be necessary to convince me that the software (and the
hardware) worked.  I think Parnas is saying that it IS impossible to do and
that NO proof could be sufficient.  I think that's wrong headed.

There are perfectly good arguments against going ahead with SDI --
destabilization is sufficient in itself, cost and the false sense of
security are also strong arguments.  Short range submarine-based missiles,
cruise missiles, and emplaced weapons are further arguments.

I think the Parnas arguments are tangential and misleading.  He creates a
situation where every time someone says "But look at system X; it worked
fine when it became operational" it becomes an argument for the pro-SDI side.  
Somebody (Asimov? Clarke?) has said "Whenever a very senior scientist says
something is impossible, the odds are he's wrong."  That's the way I react
automatically to Parnas's arguments.  I think a lot of other people do, too.

scott preece   [gould/csd - urbana]
   uucp: ihnp4!uiucdcs!ccvaxa!preece       

</PRE>
<HR><H3><A NAME="subj2.3">
 Preece's msg, first-time software, and SDI
</A>
</H3>
<address>
Dave Benson 
&lt;<A HREF="mailto:benson%wsu.csnet@CSNET-RELAY.ARPA">
benson%wsu.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Wed, 9 Apr 86 23:56:33 pst
</i><PRE>
 
To keep the thread of the discussion, I quote liberally from Preece's
msg to RISKS and comment on certain sections:

 |Date: Mon, 7 Apr 86 09:43:05 cst
 |From: preece%ccvaxa@gswd-vms (Scott E. Preece)
 |Subject: Request for information about military battle software
 |&gt; [Parnas, quoted by Dave Benson]

Correction.  This is from a report of a talk by Parnas.  I believe it
correctly represents Parnas' views, but may not be a quotation. I did not
have the opportunity to listen to the talk.  Pullman is 300 airmiles from
Seattle. The full report appeared on the ARMS-D bboard.

 |&gt; The other members of the SDI advisory panel that David Parnas was on
 |&gt; and other public figures have said "Why are you so pessimistic?  You
 |&gt; don't have any hard figures to back up your claims."  Parnas agreed
 |&gt; that he didn't have any until he thought of the only one that he
 |&gt; needed: ZERO...
 |
 |There are two essential, undefined terms in this statement: "first use"
 |and "worked".  The shuttle Enterprise, for instance, worked the first
 |time they dropped it from its carrier 747.  Was that its "first use", or
 |do you count the many hours of simulation preceding that first flight?
 |I wasn't there and have no idea whether there were bugs that showed up,
 |but they clearly didn't keep the test from succeeding.  Is that "working"?

My interpretation:  The simulation preceeding the first flight is not the
"first use" I had in mind.  The first operational use of real-time control
software is.  So your example is a good illustration of the working of
first-use real-time control software with humans (pilots and ground
personnel) in attendence.  In the minimum sense that the Enterprise was
piloted to a landing, the test was indeed a success.  (It may have been a
success in many other ways as well-- not the issue here.)  So, the software
clearly worked.  Furthermore, at least the test pilots trusted it to work,
so it is an example of a real system which was trustworthy at first use.

I appreciate having this example drawn to my attention.  Over and over again
I am impressed with NASA sponsored software, and this is another example of
how well NASA software contractors have done their work.  Any reader who
has helped build NASA software should take pride in some of the finest
real-time control software ever engineered.

However, my call was for military battle software.  Landing the shuttle
Enterprise does not qualify on these grounds. (It might not qualify on other
grounds in that the purpose of the space shuttle is not to drop from the
back of a 747 and land sucessfully.  This was only a partial operational
test of the flight software.  The first full operational test was attempting
to put the shuttle in orbit.  If I recall correctly, there was a
synchronization fault in the sofware... 	I don't want to quibble.)

If some of you have other NASA real-time control software stories to
contribute, especially if you are willing to make a judgement about how well
it worked the first time, I would greatly appreciate reading your
contributions.  Please send them directly to me, unless you think the
stories have relevance to the purposes of the RISKS bboard.  Thank you.  But
what I am primarily looking for is military battle software experiences.

 |The trouble with a debate like this is that it tends to force people
 |more and more into idiotic dichotoomized positions.  SDI software would
 |obviously be a huge challenge to produce and validate.  I have no hope
 |it would work perfectly the first time used; I have no reason to believe
 |it wouldn't work partially the first time it was used.  The question of
 |how perfectly it has to work is the central one.

I agree with the last sentence cited.  In existing military battle
equipment, when employed in realistic manuvers or in actual battle, there is
a mission to be accomplished.  If the mission is accomplished in the FIRST
ATTEMPT, then this negates Parnas' claim.  If the mission is not
accomplished, his hypothesis stands.  We see that Parnas' statement
satisfies one of the criteria for a scientific hypothesis:  It is rendered
false by one experiment.

One could imagine situations in which the mission is partially accomplished.
With the distructiveness of modern weaponry (and I'm not even including
nuclear devices in this thought), it is usually possible for a disinterested
judge to easily place such partial accomplishment in the Yea or Nay column.
(However, no such cases have yet come to my attention, beyond Herb Lin's
discussion of the Aegis test is his Scientific American article, December
1985 issue.  This test is an obvious failure for the software.  There were
particular requirements which the software failed to meet.)

So I think it perfectly reasonable to attempt to collect data about actual
military software, irrespective of SDI.  Parnas has stated a strong,
refutable claim.  If you will, a testable hypothesis about the software
engineering of military battle software.  The only sort of experiment I can
do is to ask whether any of you, whether any of your friends, peers,
associates, know of any actual experience to the contrary.  It only takes
one such (reliable, honest) piece of such information to refute Parnas'
claim.					I'm still waiting.

I remain of the opinion that actual engineering experience teaches some
important facts about the artifactual world in which we live.  Our
engineering successes, our engineering failures, eventually provide an
understanding of what works and what does not.  The successes and failures
place the limits on our ability to understand, in an engineering sense, the
real world.  Put a bit more strongly than I really mean (but it will take a
long essay to explain:  See Petroski's book "To Engineer is Human"),

    Engineering is the design of artifacts, using the accumulation of 
    knowledge about artifacts gained through experience with similar artifacts.

 |The task is too ill defined to be making statements about whether it can be
 |done.   [The task being SDI battle software, dbb]

I beg to differ with this statement.  Pick a mission, any mission for SDI
other that the trivial one that SDI does absolutely nothing at all.  This
becomes the requirement for the battle software.  So far there is no
evidence that the SDI battle software would complete your mission on first
operational use.  There is only evidence that this battle software, like all
battle software, would fail in the first operational use.

Therefore data, facts, about the first operational use of military battle
software are relevant to the question of whether any nontrivial mission for
SDI is possible in actual engineering practice.  This data does make a
difference in attempting to understand whether SDI battle software would or
would not work the first time.

Thank you this opportunity to expostulate.

I remain, still waiting for data to refute Parnas' claims,	Dave Benson

PS. Please send refuting data to benson%wsu@csnet-relay
Mail to: Professor David B. Benson, Computer Science Department,
Washington State University, Pullman, WA 99164-1210.

</PRE>
<HR><H3><A NAME="subj2.4">
First use - Enterprise 
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk">
ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk
</A>&gt;
</address>
<i>
Thu, 10 Apr 86 08:53:05 gmt
</i><PRE>
                             [Two messages are collapsed into one, omitting
                             my intervening request for clarification.  PGN]

I must admit that regarding the first shuttle flight, I had heard that
there was a serious computer failure immediately after the vehicle had
been released.

This story comes from Jack Garman, via Tom Anderson. On the first glide test
of the shuttle from the back of a 747 the first two messages on ground
telemetry were : "Explosive Bolts Fired", "Computer No.3 Failed"

	Lindsay

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.39.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.41.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-96</DOCNO>
<DOCOLDNO>IA012-000123-B018-212</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.41.html 128.240.150.127 19970217002523 text/html 11389
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:23:54 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 41</TITLE>
<LINK REL="Prev" HREF="/Risks/2.40.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.42.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 41</H1>
<H2> Sunday, 13 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer Naivete 
</A>
<DD>
<A HREF="#subj1.1">
Lindsay F. Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Admissability of computer files as evidence 
</A>
<DD>
<A HREF="#subj2.1">
Scott E. Preece
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Programming productivity 
</A>
<DD>
<A HREF="#subj3.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The San Jose Public Library [and responsibilities] 
</A>
<DD>
<A HREF="#subj4.1">
Sriram Vajapeyam
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer Naivete
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk">
ncx%cheviot.newcastle.ac.uk@cs.ucl.ac.uk
</A>&gt;
</address>
<i>
Fri, 11 Apr 86 11:32:53 gmt
</i><PRE>

  A LITTLE OFF KEY          [from the Guardian Computer Page April 10]

	A member of our Moles in Schools project reports that an
  adviser was called to a school where they were having trouble with
  their new disc drive.  He arrived to find a C15 cassette tape wedged
  firmly in the slot.
	Then a headmaster reported that his school had "broken their
  BASIC".  They had got a syntax error message.
	Best of all was the school where staff took exception to the
  QWERTY arrangement and rearranged the keys to read ABCD etc.  To their
  consternation the character on the key which had been hit did not then
  correspond to what appeared on the screen.  The adviser was greeted,
  on arrival, by an eight-year- old boy saying: "Thank goodness you've
  come.  They don't know what they are doing.  I told them they had to
  change the switches underneath as well but they wouldn't take any
  notice of me."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Admissability of computer files as evidence?
</A>
</H3>
<address>
Scott E. Preece
&lt;<A HREF="mailto:preece%ccvaxa@gswd-vms ">
preece%ccvaxa@gswd-vms 
</A>&gt;
</address>
<i>
Fri, 11 Apr 86 09:56:01 cst
</i><PRE>

&gt; From: kathy%gsg.UUCP@harvard.HARVARD.EDU (Kathryn Smith)
&gt; I, for one, find the thought that some court of law might, in
&gt; ignorance, accept computer files as evidence frightening...

I would think that a computer file would be acceptable evidence under the
same conditions that a paper document would be acceptable evidence -- when
there was a believable evidentiary chain establishing its provenance.  Thus
a computer file bearing a particular date would mean just as little as a
piece of paper with the same date, unless it could be established that that
particular piece of paper was in a known place, under neutral or believable
control, since that date.  If I take my dump tape from this afternoon to a
neutral agent and leave it there, I would expect a court at some time in the
future to accept that everything on it at that future time was on it today.
I would not expect the court to believe an arbitrary date BEFORE today on
the tape any more than I would expect the court to believe the date on a
paper letter from my files.

scott preece [gould/csd - urbana]
   ihnp4!uiucdcs!ccvaxa!preece

         [Lay people -- and even some of our colleagues -- tend to TRUST
          computers and ignore the people risks involved!  But a tape can
          easily be forged -- unless some nontrivial authenticator (crypto
          seal?) is used.  And even that can be forged with a little effort.
          Similarly, on-line files can often be changed without leaving any
          audit trail record of the change.  Furthermore, detecting Trojan
          horses and viruses in the computer world is generally nontrivial.
          On the other hand, in the paper world the piece of paper without
          provenance is more likely to be suspect.  Occasionally there may
          even be some evidence of tampering.  The burden comes down to good
          audit trails and protocols for handling both computer data and
          paper, as well as anticipation of what might someday be subject to
          tampering -- possibly everything -- and treatment accordingly.
          But once again, there are no guarantees and many pitfalls.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Programming productivity
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!henry@seismo.CSS.GOV">
ihnp4!utzoo!henry@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Fri, 11 Apr 86 10:38:46 EST
</i><PRE>

Herb Lin writes:

&gt;                 ... But why do you think that large amounts of effort
&gt; invested would necessarily improve productivity? ...

Remember "chunking".  Cognitive limitations can often be bypassed by
moving things to a higher level.  Few people would ever write (say) C code
if doing so required understanding the details of the compiler.  One major
thrust of the sort of support systems, both human and automated, that I
was alluding to, is removing the need to attend to unnecessary detail.

We have already come a long way in this direction:  much of the fundamental
knowledge base of a programmer of thirty years ago is obsolete.  Not just
because the machines have changed, but because modern programming is done
at a much higher level, where the low-level details are no longer visible.

Of course, the low-level details have not vanished; they have merely been
taken over by the support systems.  Which means that one must worry about
whether the support systems understand the details properly.  Although
programmer productivity is much increased if one can work entirely in
a high-level language and not have to care about the details of the
underlying machine, one's compiler had better be fairly well debugged or
this strategy will not work.

Even if one stipulates that ultimate limitations exist, it seems to me
that there remains good reason for believing that we are nowhere near
them yet, and that investments in better support systems are worthwhile
now and will remain worthwhile for the foreseeable future.

				Henry Spencer @ U of Toronto Zoology
				{allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The San Jose Public Library
</A>
</H3>
<address>
Sriram Vajapeyam
&lt;<A HREF="mailto:g-vajape@gumby.wisc.edu ">
g-vajape@gumby.wisc.edu 
</A>&gt;
</address>
<i>
Fri, 11 Apr 86 22:27:49 cst
</i><PRE>

&gt;&gt;From an article in the 27 March 1986 San Francisco Chronicle:
&gt;                    ------------------------------
&gt;  An employee of the San Jose public library "destroyed 16 days of records
&gt;  and garbled two weeks of circulation files."  A supervisor had "neglected
&gt;  to create a backup file".  [...]
&gt;  Training was still incomplete.  Several employees will be disciplined.
   ^^^^^^^^ ^^^ ^^^^^ ^^^^^^^^^^           ^^^^^^^^^ ^^^^ ^^ ^^^^^^^^^^^
&gt;                    ------------------------------
&gt;Not only does poor computer usage cause risks to everybody else, I think we
&gt;should be concerned about workers who are forced to use unfamiliar systems
&gt;and then are held responsible for the damage they did.  Somehow it does not
							 ^^^^^^^ ^^ ^^^^ ^^^
&gt;seem fair, but I believe this is becoming far too common.
 ^^^^ ^^^^
&gt;------------------------------

	Penalising the employees DOES seem unfair in the above case, and I 
feel they are sure to win if they go to a court of law seeking remedy. (They
didn't have enough training; the system was very young; we don't know if the 
system was fully reliable; etc etc.)  I have a few points about which others 
might want to express their opinions :

	* Mistakes made while using computers result in much more loss than 
those made, say, when working with official documents on paper.

             [This is influenced by the shorter time scale, the (misplaced)
              willingness to trust computers, and by the laziness/complacency 
              of computer users in not spotting mistakes.  But I'm not sure
              that your point is generally true.  PGN]

	* It seems easy for a person not very comfortable with computers to 
make mistakes that can't be corrected. (It doesn't seem fair to expect 
*everyone* to be comfortable with computers.)

	* How reliable is it to use computers in cases such as above (e.g.,
banks, libraries, etc), when they will be handled by people who might be
more prone to making mistakes?  SDI, even though having been brought into
existence and being maintained and used by professionals, is not supposed to
be reliable. Human error is always a frightening possibility even there!

	...Sriram V.     		g-vajape@gumby.wisc.edu

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-97</DOCNO>
<DOCOLDNO>IA012-000123-B018-241</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.42.html 128.240.150.127 19970217002547 text/html 23585
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:24:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 42</TITLE>
<LINK REL="Prev" HREF="/Risks/2.41.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.43.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 42</H1>
<H2> Monday, 14 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Robot safety 
</A>
<DD>
<A HREF="#subj1.1">
Ron Cain via Bill Park
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Use of computer files as evidence 
</A>
<DD>
<A HREF="#subj2.1">
Rob Horn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Review of *Softwar* 
</A>
<DD>
<A HREF="#subj3.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computerized Voting -- No Standards and a Lot of Questions     
</A>
<DD>
<A HREF="#subj4.1">
Summary of Eva Waskell's talk by Ron Newman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
[Ron Cain &lt;CAIN@SRI-AI.ARPA&gt;: robot safety]
</A>
</H3>
<address>
Bill Park 
&lt;<A HREF="mailto:PARK@SRI-AI.ARPA">
PARK@SRI-AI.ARPA
</A>&gt;
</address>
<i>
Mon 14 Apr 86 13:22:55-PST
</i><PRE>
To: Neumann@SRI-AI.ARPA

   Mail-From: CAIN created at 14-Apr-86 09:19:46
   Date: Mon 14 Apr 86 09:19:46-PST
   From: Ron Cain &lt;CAIN@SRI-AI.ARPA&gt;
   Subject: robot safety
   To: IA.STAFF: ;
   
   	For those who hadn't heard, I thought I'd mention two close calls
   we had out in the welding lab a week or so ago.  It is worth keeping them
   in mind the next time you stand near a robot.
   	In the first incident, a 68000 board in our system failed and
   caused the processor to jump to (of all places) a robot move routine.
   We were all standing around the emergency stop button looking at a
   terminal, and Jeff and Talia got to the button within a few milliseconds of
   hearing the crunching noise which marked the premature demise of a small
   jack belonging to the lab.  With our sensor mounted on the end-effector as
   it was, it could have been alot worse if we had been further from a kill
   button.
   	The second incident was even more sobering.  Some drive motor
   cards in the Cincinati-Milacon box failed and joints 5 and 6 began
   jerking around randomly.  Again, the kill button was nearby, and a
   potentially disastrous situation (at least for the sensor) was avoided.
   It could have been any other joint -- including the base or the shoulder.
   And someone could have been standing next to it.  We do all the time.
   	The point is just this: it can and does happen.
   	Watch yerselves around robots.
      								... ron

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Use of computer files as evidence (<A HREF="/Risks/2.39.html">RISKS-2.39</A>)
</A>
</H3>
<address>
Rob Horn
&lt;<A HREF="mailto:decvax!wanginst!infinet!rhorn@ucbvax.berkeley.edu ">
decvax!wanginst!infinet!rhorn@ucbvax.berkeley.edu 
</A>&gt;
</address>
<i>
Mon, 14 Apr 86 13:28:33 est
</i><PRE>

The use of computerized data as evidence has been treated carefully in
the environmental field (a litigious arena which includes acid rain,
toxic wastes, etc.).  The basic rule is:
   Computer-based data is NOT evidence unless ALL parties involved
   agree to treat it as evidence.
Yet, almost all of the data acquisition and processing is performed by
computers.  The route around this that is used by the legal process is
a dual PAPER or (only recently) MICROFILM evidence trail.  Using this
trail the following must be shown:
  1).  All instrumentation calibrations are traceable to NBS standards, with
	logs that are properly documented and signed by humans,
        in non-erasable ink on paper.  (Also on numbered sheets in bound
        notebooks only, with countersigned dates and occasion Q/A checks).
  2).  The computer processing includes the processing of routine calibration
        so that the computer is part of the calibration loop.
  3).  All reports are provided in both computerized and hardcopy form.  The
        hardcopy version is certified and signed by a Q/C person.
  4).  All equipment logs and records are duly signed and archived.

In fact, the computer records are generally trusted and used, but all
significant evidence is verified against the paper trail.  This does not
prevent tampering, but it does introduce several levels of human
verification and record keeping on top of the computer.  The legal system
is comfortable with its ability to deal with human error and dishonesty, so
they switch to the human trail when in doubt.

These rules posed quite a problem in automating some of the data acquisition
processes, because the people involved would NOT SIGN reports that they could
not verify.  (They had significant personal liability).  Most of the reports
had to be generated on the spot (so that the signer could verify that the
equipment was behaving correctly), and include a hardcopy printout that
showed all of the equations and intermediate computations used (so that
the signer could double check whenever the numbers looked unusual or the
value looked like it might have legal significance).  Then from these
individual data items computerized reports could be generated, but again
the signers of those reports insisted on hardcopy for intermediate
terms and double checked all the suspicious or signficant numbers.

Did mistakes get through? Probably.  But the error levels were low and
bad reports had a decent chance of being corrected.  Disputed reports could
be re-created by hand from "raw" data if necessary.  The "raw" data being
computerized instrumentation reports that were paper logged and signed.

Was the computerization complete?  Definitely not.  The people involved
refused to sign reports from a program where they were unable to perform
independent validation on a spot check basis, nor where they could not
find a totally hardcopy re-creation path.

My experience in this is now four years old, but this area changes
slowly and the rules are probably still the same.  The people involved
are very unwilling to abandon their independent audit path.  They were
only willing to trust computers for the general case, not the oddball
or legally significant items.  For things like averages, etc. they were
willing to trust computers after verifying 5% (selected at random) by hand.
				Rob  Horn
	UUCP:	...{decvax, seismo!harvard}!wanginst!infinet!rhorn
	Snail:	Infinet,  40 High St., North Andover, MA

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Review of *Softwar*
</A>
</H3>
<address>
Gary Chapman 
&lt;<A HREF="mailto:PARC-CSLI!chapman@su-glacier.arpa">
PARC-CSLI!chapman@su-glacier.arpa
</A>&gt;
</address>
<i>
Fri, 11 Apr 86 09:19:00 pst
</i><PRE>
To: glacier!RISKS@SRI-CSL.ARPA

  I thought participants of Risks might be interested in a recently released
  book called *Softwar*, by Thierry Breton and Denis Beneich, two French
  computer professionals.  The book is a computer science thriller, so for all
  of you out there who have longed for computer scientist heroes and heroines
  who resemble Indiana Jones or Mata Hari, this book is for you.  (*Softwar is
  published by Holt, Rinehart Winston, and is available only in hardcover right
  now, at $15.95.)

  The two principal characters in the book are computer scientists, one male
  and one female, one American and one Russian, who happen to have been lovers,
  too, of course.  The American is Assistant Professor of Computer Science at
  MIT Brendan Barnes, who is an expert on software reliability and debugging.
  The Russian, who was a grad student at MIT, is Yulya Voronkov, a beautiful
  Soviet computer scientist who is one of the department heads at the main
  Soviet computing center in Krasnoyarsk in Siberia.

  Barnes writes a piece for *Computers and Society* that talks about the
  potential of using software as a weapon in the ideological war with the
  Soviets.  This piece naturally attracts the attention of the CIA, and Barnes
  is gently (and without much resistance) coaxed into becoming a member of a
  team of military officers, CIA agents and technical experts who plan to use
  software bugs to plague the Soviet effort to computerize their economy.  They
  call these "softbombs," in a "softwar" with the Soviets.  As one character
  puts it in one of the many extemporaneous speeches about the role of
  computers in national security:

  ...any sector of society can be destabilized, even completely
  paralyzed--industry and defense, civil and military communications, logistics
  and transport, public administration, the entire economy--simply by a couple
  of keystrokes on a computer terminal, anywhere in the world.  We do
  definitely see this as the electronic battleground of the future, and we
  definitely see ourselves of being in the process of seizing the high ground
  for ourselves before the other side can get there.

  Barnes and his colleagues start by sabotaging a piece of software bought by
  the Soviets from the French.  It runs on a newly purchased "Craig 1" that the
  Soviets bought from the United States.  The software is programmed to spit
  out garbage when the U.S. Naval Weather Station in the Virgin Islands reports
  a barometric pressure of 1230 millibars.  Then it is programmed to restore
  all the data in perfect shape when the Weather Station reports that same
  figure again.  Of course, the Naval Weather Station is instructed not to
  report that figure unless specifically told to do so, so the "softbomb" is
  detonated at the choosing of the CIA.  They pick a detonation time about an
  hour before the "Craig 1" is to be demonstrated to a visiting delegation of
  the Soviet Academy of Sciences.

  But, aha!  There is a clever programmer at the console of the "Craig 1" who
  is bound and determined to find out why the machine went crazy at such an
  embarrassing time.  He eventually discovers the programming trick, and is on
  to how this is the product of deliberate tampering by someone outside the
  Soviet Union.  The KGB zeroes in on Professor Barnes, and he nearly catches a
  hand grenade in a Paris bar.

  From there on out, it's a battle of wits between the American computer
  scientist and his Soviet counterparts, and of course gradually that becomes
  the gorgeous and brilliant Yulya, his former grad student and former lover.

  The book is a fun read most of the time, especially for those intrigued by
  MIT trivia, Soviet trivia and computer trivia.  There are a few too many
  spots where some character gives a speech about the importance of computers
  to some such thing or other (Barnes gives a long speech to his wife about why
  he's mixed up with the CIA and catching hand grenades in Paris and having an
  affair with a beautiful Carribbean journalist, and it turns out that he's a
  radical democrat who wants computers used to increase the democratic process
  in the West).  But on the whole, it's a fairly conventional thriller spiced

  up for computer professionals with lots of jargon and speculation, and of
  course, dashing, sexy and adventurous computer scientists.

  -- Gary Chapman

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"Computerized Voting -- No Standards and a Lot of Questions"
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
To: risks@sri-csl
Date: Mon, 14 Apr 86 21:50:29 -0500
From: Ron Newman &lt;newman@ATHENA.MIT.EDU&gt;

The following is a slightly edited version of an article I wrote for the
April, 1985 issue of the Computer Professionals for Social Responsibility
Boston Chapter newsletter.

~~~~~~~~~~~~~~~
Our guest at CPSR/Boston's March 19 meeting was Eva Waskell, an independent
science writer, former computer programmer, and current stringer for The
Economist.  She spoke with considerable alarm about the rapid and
unregulated spread of computerized vote-counting systems in American
elections.

Waskell became interested in computerized vote-counting when Severo Ornstein
of CPSR National suggested that she look into several lawsuits pending against
Computer Election Systems (CES) of California.  CES is the leading vendor of
such software; it estimates that approximately 25% of the U.S. popular vote is
cast on its equipment.  Losing candidates in three states have sued the
company, claiming that its system produced inaccurate or fraudulent results.
While investigating, Waskell was appalled to find out that only one person
outside of CES, a consultant for one of the plaintiffs, had ever examined the
code.  Waskell's investigation resulted in several New York Times
articles last summer.

To use a computerized ballot system, a voter inserts a punch card into a book
containing the names of each candidate for office.  The voter casts a vote by
pushing a stylus through a hole in the book next to the name of the candidate.
thus punching out the appropriate hole in the punch card.   When the polls
close, punch cards from all the precincts are trucked to a central location
and tabulated on a mainframe, using software provided by CES or a competitor.

The first such system was developed by IBM in 1964, for use in Los Angeles
elections.  In 1969, there were accusations of fraud in LA's elections.
Fearing unfavorable publicity, IBM got out of the election business.  Four of
IBM's employees left IBM to form CES.

Waskell pointed out four problems with this type of system:

1) A single central computer, in a single location, is counting all the votes.
This takes control away from precinct poll workers, who formerly counted the
votes and could recognize deviations from traditional voting patterns in their
precincts.  It also makes rigging the election much easier:  instead of having
to buy off many individual precinct workers, who are known to the community,
one need bribe only a single computer operator, who is known by almost none of
the voters.

2) Election officials must now be much more than clerical workers -- they must
have technical skills.  Frequently, new people are hired from the outside to
learn and operate the computer equipment.  Officials often do not know what
the new people are doing.  In one state, workers rubber-stamped computer
printouts without examining them.  A Minnesota election official commented:
"It's kind of like black magic -- we really don't know what's going on."

3) There are no standards for election software, so anyone can write a
vote-counting program.  Vendors often talk state legislators into writing
enabling legislation which is vague and favors their company.  When a state
Board of Elections certifies a computer system, the board often fails to
consult any computer experts, and when it does consult experts, it may ignore
their advice.  The state of Pennsylvania certified a computerized election
system despite strong objections from two CMU professors.  (One of the
CMU professors, Michael Shamos, wrote a report called "The Votomatic
Election System: An Evaluation" in November 1980.)

4) Vendors consider their software to be proprietary.  As a result, in the last
20 years, almost nobody has examined any of the software.  Compare this to
accounting software, which is subjected to audit by third parties.  It is hard
to have confidence that software is performing accurately when you cannot look
at the code.


Waskell said that states and municipalities have ignored four clear warnings
against adopting these systems.  In 1970, a Los Angeles blue-ribbon committee
recommended that all vote-counting software be independently audited.  Similar
recommendations have been issued by the National Bureau of Standards (1975),
CMU computer science professor Michael Shamos (1980), and the independent
auditing firm of Coopers &amp; Lybrand (1982).  Nevertheless, none of the programs
has been audited.

According to Waskell, vote-counting programs are typically 4,000-5,000 lines
of COBOL "spaghetti code."  Earlier this year, an Indiana consulting firm
analyzed CES's program on behalf of one of the losing candidates who is suing
CES.  They found numerous problems, including the following:

  The translation between the Hollerith punch card code and characters was
  nonstandard.  The 1971 NCR system which the software ran on did not use
  standard EBCDIC.

  The contents of memory were continually being redefined.  Numerous variables
  and fields were overlaid in memory.

  The same memory locations were re-used for the vote counts of different 
  races.

  There was a total lack of structure.  The program contained no PERFORM UNTIL
  (DO-loop) statements but had numerous undocumented GOTOs.

  COBOL's ALTER verb was used, producing self-modifying code.

  A call was made to an undocumented, unknown subroutine.

  The program interacted heavily with the operator, who can operate the console
  switches to examine and modify any part of the memory or program after each
  set of data is tallied.

  The program made it easy for the operator to turn off error logging and audit
  trails, without leaving any trace.

  There was heavy use of control cards in the data deck to redefine data 
  fields, raising the possibility that a "knowledgable" voter could punch a
  control card and drop it into the ballot envelope to change the program's
  processing of election results.

  CES sends undocumented "updates" to election personnel before each election.

  The program used a time card to set the time and required that the computer's
  clock be disabled.  This makes it impossible to determine how long the
  program runs or to accurately determine when logs or printouts are produced.

  The program did not correctly count "crossover votes," in which, for example,
  a voter punches a vote for a straight Democratic ticket and punches votes for
  several individual Republicans.  Before an election in West Virginia,
  newspaper publicity specifically said that such votes were allowed, yet the
  program failed to count them.

  The program failed to keep a count of invalid ballots.


A report to the Illinois Board of Elections in September, 1985, revealed that
of the voting systems that the state tested before elections, 28% contained
errors.  Although those errors were corrected, such a high error rate suggests
that many errors are never detected or corrected.  Waskell said that other
states' election officials are unaware of the Illinois findings.  It disturbed
her that Illinois failed to keep a record of the errors it found, but simply
sent them back to the vendors for correction.

Suits against CES have been filed in Indiana, West Virginia, and Florida, but
judges have dismissed several of the cases for lack of evidence, saying that
computer experts' testimony is mere "speculation" and "suspicion."  It is hard
to successfully prosecute such a case when the computer system itself is
designed to ensure that no evidence exists.

In the Indiana case, the plaintiff charged that a CES representative was in
the counting room on election night, turned off the program's logging, and
added two extra control cards after the last votes were counted.  In the West
Virginia case, a CES representative allegedly connected a modem to the
computer and was down on his hands and knees around the compter on election
night, claiming that "a screw was loose."   In addition, the West Virginia
candidate alleged that the county clerk's husband manipulated the computer's
switches during the count.  Evidence in this case is difficult to obtain
because the county clerk destroyed all the ballots 61 days after the election
and returned the program deck to the vendor.

According to Waskell, a company called Cronus recently purchased both CES and
two of its competitors, Thornber and Governmental Data.  Together, these three
companies market 60-80% of the voting systems in use.  Cronus is financially
tied to the Tyler Corp., whose chief executive officer is Fred Meyer, the
Republican Chairman of Dallas County, Texas.  Meyer announced his candidacy
for Mayor of Dallas one month after the city bought a CES voting system.

Ms. Waskell closed her presentation with a series of recommendations.  The
Federal Government, using election powers outlined in the constitution, should
mandate that all vendors conform to NBS standards.  State election laws should
be changed to show a greater understanding of the technologies.  Local
election officials must ensure that audit trails are always turned on and that
they are continuous and unbroken.  Also, local officials should count a random
5% sample of the vote by a different method, thoroughly test computer systems
before adopting them, and be accountable and responsible for their use.

People interested in more information about this subject may want to
read New York Times articles by David Burnham, published on  7/29/85, 7/30/85,
8/4/85, 8/21/85, 9/24/85, and 12/18/85, and a letter to the editor, 8/6/85.
Ms. Waskell was the source for much of the information in these
articles.   If you write to me (newman@mit-athena), I can tell you how
to reach Ms. Waskell--I'm uncertain whether she wants her address &amp; phone
number posted on the net.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-98</DOCNO>
<DOCOLDNO>IA012-000123-B018-264</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.43.html 128.240.150.127 19970217002602 text/html 12806
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:24:32 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 43</TITLE>
<LINK REL="Prev" HREF="/Risks/2.42.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.44.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 43</H1>
<H2> Thursday, 17 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Review of *Softwar* 
</A>
<DD>
<A HREF="#subj1.1">
Marvin Schaefer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  GREAT BREAKTHROUGHS 
</A>
<DD>
<A HREF="#subj2.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Star Wars software advance 
</A>
<DD>
<A HREF="#subj3.1">
AP
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Smart bombs in Libya 
</A>
<DD>
<A HREF="#subj4.1">
Washington Post
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Pacific Bell Bills 
</A>
<DD>
<A HREF="#subj5.1">
SF Chronicle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  BU joins the InterNet... 
</A>
<DD>
<A HREF="#subj6.1">
Barry Shein
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Review of *Softwar*
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
15 Apr 1986 09:37-EST
</i><PRE>
From: Marvin Schaefer &lt;Schaefer@USC-ISI&gt;
To: RISKS@SRI-CSL.ARPA

        I have read &lt;&lt;Softwar&gt;&gt; only in the French version, and it is
interesting to see from Gary Chapman's review that several differences 
appear to have been worked into the details of the plot to make it more 
suitable for American [re]viewing audiences.
        Of particular note is the agency with which the American hero
is associated -- a Langley, Va. organization called NSA (the National
*Software* Agency) has been chartered with two primary missions:
software debugging and -- software bugging!  With only modest
chauvinism the authors point out that the French-derived programming
language Ada has been chosen as the primary tool for achieving the
software debugging mission since it makes it so much easier to locate
programming errors.  [There are lots of justified paeans to French
superiority in software engineering.]  Interestingly, the book's NSA
does not seem to have any interest in the use of methodological system
development techniques in which the intention is to produce correct
code in the first place.  One is forced to wonder how they intend to
produce correctly working softbombs to start with.  Perhaps the
two directorates do not talk with each other.
        The first softbomb is discovered by the soviet computing
scientist by analysing a trace of program execution.  He correctly
finds that the softbomb code executes less frequently than the other
instruction sequences in the massive meteorological program, and is
thus able to identify its trigger.
        Not so the more elaborate examples of hardware subversion that
follow in the book's development.
        The amount of blind trust that is placed in hardware
correctness over that of the software is a realistic assessment of
the fairly commonly misplaced faith that one sees today.  The
attribution to the 'NSA' of the view that using the new high-tech Ada
will lead to lower costs and higher reliability  (because of cheaper
debugging) is an opinion one frequently hears in government.
        The book, albeit oversimplified, was fun to read.  I found the
social implications of the book to be far more interesting than the
description of sophisticated computer virus attacks that was mentioned
in the Scientific American review a couple of years ago.
                            Marv Schaefer

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 GREAT BREAKTHROUGHS         [Red Herrings swimming upstream?]
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 16 Apr 86 18:07:03 EST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

       From Dave Parnas:

       The Fletcher panel...  They even rejected a military-like hierarchical
       command structure for the computers so that there would be no "Achilles
       Heel" in the system.

And then the Eastport panel went ahead to propose just that!!
       
               Fossedal's reference to "a single error" is part of another red
       herring in which SDIO supporters claim that the critics want perfection.
       The only reference to "error free software" came from SDI supporters,
       none of the critics have assumed that perfection was needed.  

The person who said this was Fletcher himself!

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Star Wars software advance
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Thu 17 Apr 86 17:36:15-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

  Defense Secretary Caspar Weinberger disclosed new scientific advances
yesterday that he said provide ``solid reasons'' that a Star Wars
anti-missile defense system can be made to work...
  Scitech [Princeton NJ, not to be confused with Sytek, of Sunnyvale CA]
developed a means for identifying ``rocket plume signatures''...  LTV
[Dallas] then modified that system to create a special computer program, or
algorithym [sic], that can be loaded in the sensors aboard a missile
interceptor.
  The sensors lock on the plume of fire from an enemy rocket, but the new
program makes the necessary corrections to ensure that the intercepting
missile hits the enemy rocket and not the plume.
  This advance is important because it suggests that enemy missiles can be
attacked during their earliest, or boost, stages of flight and are gliding
on a trajectory toward earth...  [Associated Press, 17 April 86]

                                [It all reduces to a SMOP 
                                (Small Matter of Programming)!  
                                (See the Hacker's Dictionary.)]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Smart bombs in Libya
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Thu 17 Apr 86 17:34:28-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

The U.S. Military now believes that damage to the French Embassy and a
residential neighborhood in Tripoli during Monday night's raid on Libya was
caused by a Air Force ``smart bomb'' that went astray either because it was
dropped by a damaged F-111 jet or because its guiding laser beam was blocked
by clouds, Defense Department officials said yesterday...

[The] second explanation is also consistent with the likely trajectory of
the bomb, however.  The 2000-pound GBU10 bombs ae designed to home in on a
beam of light which the ``Pave Tack'' system on the plane's underbelly
focuses on the target.  After the bomb was dropped, the F-111 probably
swerved and climbed to evade anti-aircraft fire, while the laser designator
on the undercarriage automatically swiveled to keep the target illuminated.
As the plane moved, however, the laser beam may have been broken by smoke or
clouds that were drifting over Tripoli Monday night, causing the bomb to
fall unguided into the residential neighborhood.  (Washington Post, 17 April
86)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Pacific Bell Bills
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Thu 17 Apr 86 17:36:47-PST
</i><PRE>
To: RISKS@SRI-CSL.ARPA

The San Francisco Chronicle of 3 April 86 had this story that I meant to
include earlier.

  More than a million California telephone customers will be getting an
  unpleasant surprise in their April bills because of an equipment
  malfunction...  Because of the goof, these customers were not billed for
  millions of medium- and long-distance calls since November, said company
  spokesman Roger Orr.  The calls not billed in January and February will show
  up on the April bill, Orr said.  The California Public Utilities Commission
  will not allow the phone company to charge for calls missed by the billing
  equipment in November and December.  Switching machines logged each call but
  did not put some of them on customers' bills...  [No estimate given of how
  much revenue was lost.]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
BU joins the InterNet...
</A>
</H3>
<address>
Barry Shein
&lt;<A HREF="mailto:bzs@bu-cs ">
bzs@bu-cs 
</A>&gt;
</address>
<i>
Thu, 17 Apr 86 13:27:24 EST
</i><PRE>

I may as well tell this anecdote before others do...

Boston University this past week submitted their host table for inclusion in
the NIC table. Unfortunately, there were a few entries in the table that
should never had made it. The most interesting was a one character nickname
("A") for host BU-CS (local convenience.)

Apparently a bug in the 4.2bsd program htable program which converts from
standard NIC format to the format UNIX uses proceeded to fill your disk when
it hit this entry. I suspect from the notes that some hosts must pick up the
table automatically in the wee hours and do the conversion with a command
script so they came in the next morning with a disk full of the string
"BUCSA". I was assured by one site that he no longer needs any mnemonics to
remember our name. I have no way of knowing numbers, but apparently some
number of machines went down or were crippled.

In addition, there was an entry for a machine type "3B2", htable broke on
that also although not so dramatically, because the string started with a
digit. It seems the next night or so htables were breaking again because
someone managed to put a lower case letter into the table.  (I have heard
this only second hand.)

I then fixed our host table to avoid the troubles and ran it through htable
myself just to be sure and it promptly deleted the first entry in my table.
Apparently it had to have at least one blank line before the first entry,
again, without warning.

This is after almost three years of the program being in production at
probably thousands of sites. Don't trust any program over 30 (lines of code)?

	-Barry Shein, Boston University

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-99</DOCNO>
<DOCOLDNO>IA012-000123-B018-285</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.44.html 128.240.150.127 19970217002629 text/html 14851
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:24:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 44</TITLE>
<LINK REL="Prev" HREF="/Risks/2.43.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.45.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 44</H1>
<H2> Monday, 21 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Why Simulation Is A Good Thing... 
</A>
<DD>
<A HREF="#subj1.1">
Lynne C. Moore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Hacking &amp; forgery laws 
</A>
<DD>
<A HREF="#subj2.1">
Robert Stroud
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Strategic Systems Reliability Testing 
</A>
<DD>
<A HREF="#subj3.1">
Dan Ball
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  SDI 
</A>
<DD>
<A HREF="#subj4.1">
Larry Campbell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Cost of phone billing error 
</A>
<DD>
<A HREF="#subj5.1">
Dave Redell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Normal Accidents and battle software 
</A>
<DD>
<A HREF="#subj6.1">
Dave Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Psychological risks, part II 
</A>
<DD>
<A HREF="#subj7.1">
Dave Benson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Why Simulation Is A Good Thing...
</A>
</H3>
<address>
&lt;<A HREF="mailto:<moorel@eglin-vax> Lynne C. Moore">
&lt;moorel@eglin-vax&gt; Lynne C. Moore
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

We are currently engaged in developing a system of remote video tracker
pedestals for tracking missile tests, and have recently chosen to implement an
interim hardware solution to allow time for a rational software development
cycle (rather than 25K+ lines in less than 6 months with 2 programmers). One
of the proposed advantages of the software solution is the ability to run a
real-time simulation for operator training, and there have been some questions
from our top management about why the software developers insist that this is
exceptionally important. 

Yesterday, an operator attempted to manually track a live missile for the
first time. He tracked it for about 1/2 second, and then commented, "Gosh,
that thing moves a lot faster than I thought." Too bad none of the managers
were there... 

		Lynne C. Moore &lt;moorel@eglin-vax.arpa&gt;

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Hacking &amp; forgery laws
</A>
</H3>
<address>
Robert Stroud 
&lt;<A HREF="mailto:robert%cheviot.newcastle.ac.uk@cs.ucl.ac.uk">
robert%cheviot.newcastle.ac.uk@cs.ucl.ac.uk
</A>&gt;
</address>
<i>
Fri, 18 Apr 86 10:18:28 gmt
</i><PRE>

This was printed in The Times yesterday April 16th. I am particularly
intrigued by the prosecution under the forgery laws. I don't see how
you can forge something like a telephone number - surely to be protected
by a forgery law, an identification should be personal in some sense.
Numeric codes are completely impersonal.

  ===========================================================================
  Prestel blunder 'helped hacker'. (c) Times Newspapers Limited, 1986

  A top-level blunder allowed a computer journalist to penetrate British
  Telecom's Prestel information system, a court was told yesterday. A secret 
  identification code allowing access to secret files was left unprotected 
  within the computer system it was said. Mr Robert Schifreen, aged 22, used 
  it to get the confidential identity numbers and passwords of every Prestel 
  customer, Southwark Crown Court was told.

  Mr Schifreen, who subscribed to Prestel under the codename "Bug Hunter",
  later wrote an article on how easily he had cracked the system. But Mr 
  Schifreen, who works for a computer magazine, denied he did so for personal
  gain, and accused Prestel of "negligence".
 
  Mr Austin Issard-Davies, for the prosecution, said a random experiment first
  gave him the telephone numbers of Prestel's private computers. The telephone
  numbers were not published to normal subscribers, and only a few people had
  access. But Mr Schifreen was said to have broken into the Prestel development
  test computer. It was alleged that he typed an experimental line of numbers,
  all twos, when the computer asked for a 10-digit identification. It worked,
  and the computer then asked for a four-digit password. He typed 1234 which
  turned out to be a test account and gave him access. But Mr Schifreen's
  attempts to get information out failed because he did not have the
  confidential identity code and password of the system manager. Nine months
  later, he came across the code and password "lying around" in one of the
  private Prestel computers.

  When questioned by police, Mr Schifreen allegedly admitted making
  unauthorised access into the system from his home computer, but claimed he
  had made Prestel more secure by doing so. Mr Issard-Davies said: "It is a
  bit like a burglar claiming all the credit for improved house security
  because the householder has put locks on all the windows." He added it was
  "twentieth century" forgery because Mr Schifreen allegedly used someone
  else's computer identification, like signing someone's name without consent.
  [omitted material]

  The charges have been brought under section one of the Forgery and 
  Counterfeiting Act, 1981. The test case trial is the first contested case
  to go to court. The hearing continues today.
  ============================================================================

Robert Stroud,
Computing Laboratory,
University of Newcastle upon Tyne.

ARPA robert%cheviot@ucl-cs.ARPA
UUCP ...!ukc!cheviot!robert

       [I reported on a breakin to British Telecom's Prestel Information 
        Service in the ACM Software Engineering Notes vol 10 no 1 (January
        1985).  A 19-yr-old young man had penetrated the unencrypted password
        file.  To demonstrate the vulnerability, he let a London Daily Mail
        reporter watch (reported in the LDM on 2 Nov 84) while he read
        Prince Philip's mailbox and then altered a financial market database.
        Things seem not to have improved much.   PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Strategic Systems Reliability Testing
</A>
</H3>
<address>
Dan Ball
&lt;<A HREF="mailto:ball@mitre.ARPA ">
ball@mitre.ARPA 
</A>&gt;
</address>
<i>
Fri, 18 Apr 86 14:45:03 est
</i><PRE>

It has been about twenty years since I've worked with strategic systems
(Polaris), but I can no longer resist putting in my two cents in the SDI
debate.

The issues concerning whether SDI can be made to work perfectly or even
well enough the first time since it can't be tested in a realistic environment
and there will be no second chance would appear to apply equally to both the
US and Soviet Offensive Systems.

During my four years with the Polaris Test Program, I know of no test involving
more than a single live missile.  Although these tests were for the most part
very successful, there was never an attempt to test the ripple fire capability
with real missiles on a single submarine, let alone a coordinated launch
involving all submarines as well as all land based ICBMs.

In addition to the readiness/reliability considerations of our strategic
nuclear forces, I would suspect that the command and control problems
would be formidable.  We seem to have considerable difficulty sending a
single urgent message (e.g. USS Liberty, USS Pueblo, USAF EC-121, etc.) ,
let alone a coordinated attack involving hundreds or thousands of platforms.

I'm relatively certain that the numbers of warheads actually reaching the
target following the initiation of an attack would be far less than the 
numbers in the inventories.

Finally, the briefing from SDI office that I heard didn't promise perfection. 
Unlike some of the political supporters who promise that it will be safe for
children to play outside during a nuclear exchange, the SDI technical types
were talking about the impact it would have on the numbers and required
modifications to the Soviet ICBMs that would be required for them to
maintain the same confidence of assured first strike destruction of the US.

(I promise that this will be my first and last comment concerning SDI as I
think there's far too much uninformed speculation and political opinion on
this subject in risk-forum already.  I'll even volunteer to be edited out as
I would like to see more contributions that could help those of us whose job
is trying to assure that computer reliability and safety requirements are met.)

Dan Ball

                      [Don't bet on there being no provoking replies.  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
SDI
</A>
</H3>
<address>
&lt;<A HREF="mailto:decvax!bellcore!genrad!panda!talcott!maynard!campbell@ucbvax.berkeley.edu">
decvax!bellcore!genrad!panda!talcott!maynard!campbell@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
Fri, 18 Apr 86 07:19:30 EST
</i><PRE>

The discussion in the last few issues of RISKS has demonstrated that Reagan's 
Strategic Defense Initiative HAS ALREADY SUCCEEDED.  It has done exactly
what Reagan wanted, which is to convert an essentially political question,
in which every American is qualifed and in fact obligated to participate,
into a technical debate, in which only the technical clergy are allowed.

Larry Campbell                                 The Boston Software Works, Inc.
ARPA: maynard.UUCP:campbell@harvard.ARPA       120 Fulton Street
UUCP: {harvard,cbosgd}!wjh12!maynard!campbell  Boston MA 02109

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Cost of phone billing error
</A>
</H3>
<address>
David Redell
&lt;<A HREF="mailto:redell@src.DEC.COM ">
redell@src.DEC.COM 
</A>&gt;
</address>
<i>
Fri, 18 Apr 86 09:50:03 pst
</i><PRE>

  More than a million California telephone customers will be getting an
  unpleasant surprise in their April bills because of an equipment
  malfunction...[No estimate given of how much revenue was lost.]

The estimate I saw was $25-30 million.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Normal Accidents and battle software
</A>
</H3>
<address>
Dave Benson 
&lt;<A HREF="mailto:benson%wsu.csnet@CSNET-RELAY.ARPA">
benson%wsu.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Sun, 20 Apr 86 21:51:10 pst
</i><PRE>

According to

	Charles Perrow
	Normal Accidents: Living with High-Risk Technologies
	Basic Books, New York, 1984

we should expect to see large-scale accidents such as the loss of the
space shuttle Challenger.  Perrow's thesis, I take it, is that the
complexity of current technology makes accidents a 'normal' aspect
of the products of these technologies.

We may view space shuttles launches, nuclear reactors, power grids,
transportation systems, and much real-time control software as lacking
homeostatis, "give", forgiveness.  Perhaps some of these technologies
will forever remain "brittle".

Questions: Does anybody have a good way to characterize this brittleness?
To what extent is existing battle software "brittle"?

Thank you for your suggestions/comments			dbb

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Psychological risks, part II
</A>
</H3>
<address>
Dave Benson 
&lt;<A HREF="mailto:benson%wsu.csnet@CSNET-RELAY.ARPA">
benson%wsu.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Sun, 20 Apr 86 21:59:17 pst
</i><PRE>

I have just finished reading

	Neil Frude
	The Intimate Machine
	New American Library, New York, 1983

which comments on animism and anthropomorphism in the past and present,
and speculates on the continuence of these tendencies into the future
with human-like qualities in computers.

I did not find the argument persuasive, but then I bang at this terminal
quite a bit, and certainly do not anthropomorphize it in the slightest.

Perhaps some of you have &lt;modern&gt; stories about people who view computers
as having human-like qualities, confusing their perceptions of humans
and computers.  If so, please send such direct to me unless you think
them generally enlightening RISKS.	Thanks,	dbb

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-100</DOCNO>
<DOCOLDNO>IA012-000123-B018-315</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.45.html 128.240.150.127 19970217002704 text/html 22318
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:25:28 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 45</TITLE>
<LINK REL="Prev" HREF="/Risks/2.44.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.46.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.44.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.46.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 45</H1>
<H2> Monday, 28 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
HBO gets Hacked:: We Interrupt This Program ... for a Viewer Protest.    
</A>
<DD>
<A HREF="#subj1.1">
Geoff Goodfellow
</A><br>
<A HREF="#subj1.2">
 Frank J. Wancho
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Ball's contribution on Polaris and SDI 
</A>
<DD>
<A HREF="#subj2.1">
from Dave Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  SDI Reliability Testing  - Offensive deterrent vs SDI 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  What are the limits to simulation? 
</A>
<DD>
<A HREF="#subj4.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Reference on admissibility of computer records 
</A>
<DD>
<A HREF="#subj5.1">
Bill Cox
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Phone billing error at Pacific Bell, etc. 
</A>
<DD>
<A HREF="#subj6.1">
John Coughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Cracked Libya Defense 
</A>
<DD>
<A HREF="#subj7.1">
Udo Voges
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Challenger article 
</A>
<DD>
<A HREF="#subj8.1">
Ron Minnich
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
HBO gets Hacked:: We Interrupt This Program ... for a Viewer Protest.
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
27 Apr 1986 15:51-PDT
</i><PRE>
From: the tty of Geoffrey S. Goodfellow &lt;Geoff@SRI-CSL.ARPA&gt;
To: videotech@SEISMO.CSS.GOV, telecom@XX.LCS.MIT.EDU
Cc: neumann@SRI-CSL.ARPA, shadow@AIM.RUTGERS.EDU

    NEW YORK (AP) - A video hacker calling himself ''Captain Midnight''
startled cable television viewers from Maine to the Plains early
Sunday when he interrupted a movie on Home Box Office with a printed
message protesting HBO's scrambling of its satellite-to-earth TV
signals.
    ''It's a criminal, willful interference of a government-licensed
satellite broadcast,'' fumed David Pritchard, an HBO vice president,
who said the cable system had received sabotage threats in recent
months.
    Pritchard said HBO planned to report the incident to the Federal
Communications Commission.
    ''It's kind of like terrorism of the airwaves,'' said Greg Mahany,
who was watching in Middletown, Ohio, when the message interrupted
''The Falcon and The Snowman.''
    The message, printed in white letters on a color-bar test pattern
background, read: ''Goodevening HBO from Captain Midnight. $12.95 a
month? No way! (Showtime-Movie Channel Beware.)''
    Mahany said that at first the picture flipped back and forth between
the message and the movie, making it seem like ''HBO was trying to
get its signal back. ... It looked like a fight for control of the
microwave beam.''
    The message appeared at 12:30 a.m., Eastern time, and remained on
the air about five minutes. It was seen in the eastern two-thirds of
the nation, which accounts for more than half of HBO's 14.6 million
subscribing households.
    Pritchard said the hacker, apparently with the use of a satellite
dish and a powerful transmitter, effectively replaced HBO's signal
with his own.
    For some reason - possibly because Captain Midnight's signal was
better-timed or more powerful - HBO's satellite received the hacker's
signal instead of HBO's and beamed it down to HBO's earth relay
stations.
    Sunday's intrusion was immediately noticed at HBO's communications
center in Hauppauge, N.Y., but it was not clear whether the hacker
ended his own message or was forced off by HBO.
    Pritchard said HBO would have no comment on that. ''We have
implemented some technical remedies, and we're pursuing others,'' he
said. ''This represents a clear danger to every satellite user.''
    Pritchard said action like Sunday morning's had been threatened in
letters to HBO and in magazines read by dish owners.
    ''We'd been threatened for the last four or five months with
something like this if we didn't reconsider our plan to scramble,''
he said. ''They said they'd do something. They didn't say what.''
    The HBO cable signal is scrambled to prevent reception in homes
wired for cable television but not equipped with an HBO converter.
Until earlier this year, satellite dish owners were able to intercept
the unscrambled signal HBO bounces off satellites to the earth
stations that relay the signal via cable.
    In January, however, HBO began scrambling all its satellite-to-earth
signals. HBO told dish owners who had been watching for free they
would have to buy a descrambler for $395 and pay $12.95 a month.
    Another leading pay cable service, Showtime, announced plans for a
similar system.
    Pritchard said about 6,000 dish owners put down the cash for the
decoder and signed up for HBO or its sister service, Cinemax. But the
proposal has been unpopular with others.
    ''They say things like, 'The airwaves are free,' and 'They (HBO) are
using government satellites that our taxes pay for,''' Pritchard
said.
    Pritchard said HBO's programs are its property, and it leases space
from privately owned satellites.

</PRE>
<HR><H3><A NAME="subj1.2">
HBO gets Hacked:: We Interrupt This Program ... for a Viewer Protest.
</A>
</H3>
<address>
"Frank J. Wancho" 
&lt;<A HREF="mailto:WANCHO@SIMTEL20.ARPA">
WANCHO@SIMTEL20.ARPA
</A>&gt;
</address>
<i>
Sun, 27 Apr 1986  22:39 MDT
</i><PRE>

    Until earlier this year, satellite dish owners were able to
    intercept the unscrambled signal HBO bounces off satellites to the
    earth stations that relay the signal via cable.

It is interesting to note that while protective "alledgedly" and similar
words are freely sprinkled in newsprint, the writer of the above chose
"intercept" over "receive".  The word "intercept" implies "theft", a
criminal act.  That "intercept" was unmodified and not a quote implies the
allegation was accepted as fact proven in court.  Is this indeed the case,
or simply the viewpoint held by the programming services?  If the latter,
then it was inappropriate and perhaps biased to use "intercept".

Just asking...

--Frank

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Ball's contribution on Polaris and SDI (from Dave Parnas)
</A>
</H3>
<address>
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Tue, 22 Apr 86 07:37:13 pst
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Dave Parnas is now on his way to Australia for almost two months, so
please don't expect him to reply.  But on his way out, he sent me this
(which I include with his permission):

  	As I read the first part of Ball's contribution, I was sure he 
  was agreeing with me, but no, as I read on I saw that he was on the 
  SDIO side.  His arguments are simple and they are the arguments that
  the other defenders of the program make.
  
  (1) The weapon systems that we have now have not been adequately tested and
  probably won't prove reliable so we can build another one with those
  properties.  It's "business as usual".
  
  (2) Its quite alright to allow the President, the Coalition for Star Wars,
  and High Frontiers to tell the public and congress that they are "making
  nuclear weapons impotent and obsolete" , "ending the fear of nuclear
  weapons" and trying to end the "immoral" policy of deterrence, while using
  those funds to do something quite different.  Misrepresentation is "business
  as usual".
  
  His message reconfirms my assertion that there is no doubt about the
  technical facts.  We cannot build a system that does what the president
  asked us to do and what the supporting public wants.  Almost nobody 
  working on it believes we can.  Its not a question of perfection.  It is a
  question of effectiveness and reliability.  The reliability of such a system
  will always be in question; its effectiveness will always be unknown.  We
  will always know that there are effective countermeasures.  It will not lead
  to increased security.  It will lead to "business as usual".
  
  Dave

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
SDI Reliability Testing  - Offensive deterrent vs SDI
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@uw-june.arpa ">
jon@uw-june.arpa 
</A>&gt;
</address>
<i>
Mon, 28 Apr 86 00:13:10 PDT
</i><PRE>

&gt; (Dan Ball writes)
&gt; The issues concerning whether SDI can be made to work perfectly or even
&gt; well enough the first time since it can't be tested in a realistic 
&gt; environment and there would be no second chance would appear to apply
&gt; equally well to both the US and Soviet offensive systems.
&gt;
&gt; During my four years with the Polaris Test Program, I know of no test 
&gt; involving more than a single live missile ... I'm relatively certain that
&gt; the numbers of warheads actually reaching the target following the 
&gt; initiation of an attack would be far less than the numbers in the 
&gt; inventories. ... In addition ... I would expect that the command and 
&gt; control problems would be formidable.

This point is well taken.  Still, I think there are two important differences
in degree, if not in principle:

1.  To have the desired deterrent effect, at least given today's very large
arsenals, it is not necessary that most weapons work especially well.  
It is only necessary to create the impression that something pretty awful 
would happen if we attempted to use some of them.

2.  The coupling between each weapon and other systems appears to be weak.
In particular, it is my understanding that once a missile is fired, it is
entirely self-guided, and does not depend on the correct functioning of any
other systems.  This is in contrast with your typical SDI scheme, which 
depicts a ground based laser bouncing its beam off two aiming mirrors on 
opposite sides of the planet, with various observation and battle-management
satellites hovering nearby.  Without this being an explicit design goal, the 
present offensive system seems to have achieved the desirable quality of
having a "system behavior which can be inferred from its components" in 
the Eastport panel's words.

My point is that testing a missile defense system is a much tougher job
than testing the offensive system it is supposed to defeat, if an equivalent
level of confidence is desired.

Note that this is true only if the offensive missile system is for deterrence.
If it is supposed to carry out a first strike, or any other highly-coordinated
activity - "counterforce," "countervailing response" or whatever you call it
-- the difficulty of obtaining confidence in the offensive system becomes 
much greater.   There is a huge literature of analysis and simulation 
devoted to highly coordinated offensive attacks.  I have no idea whether
policy makers regard these at all seriously, but I think it is 
important for technical people to point out that very little of this
has been tested in realistic conditions and it is anybody's guess what would
happen if anyone actually tried to carry out such plans.

&gt; The briefing from SDI office that I heard didn't promise perfection ...
&gt; I think there's far too much uninformed speculation and political opinion
&gt; on this subject in risks-forum already ...

People hear various things from people associated with SDI.  As far as I know,
there is still no official statement of what SDI's performance requirements 
are.  Until there is, discussion is necessarily limited to speculation and
generalities.  What is required, of course, is some quantitative requirement 
such as, "The defense must stop at least 90% of an attack by 1000 ICBM's," or
"The defense must preserve at least 50% of our land-based missile silos." 
Then, we could discuss what tests, if any, could make us confident that the 
requirements would be met in a real attack.  Discussion of whether the 
requirements were consistent with earlier promises to render missiles 
impotent, etc., do include political opinion and could be forbidden by the 
editor.

-Jonathan Jacky
University of Washington

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
What are the limits to simulation?
</A>
</H3>
<address>
Eugene Miya
&lt;<A HREF="mailto:eugene@AMES-NAS.ARPA ">
eugene@AMES-NAS.ARPA 
</A>&gt;
</address>
<i>
23 Apr 1986 1518-PST (Wednesday)
</i><PRE>

&gt; Subject: Why Simulation Is A Good Thing...
&gt; From: Lynne C. Moore
&gt;	Description of a tracking system.

The Subject field described is certainly well intended, but I really wonder
what simulation's various limits are.  Simulation is really only an extension
of human intellect, not the way things behave in Nature.  While I do not
take issue that some simulation is a good thing, I wonder where this ends?
What are limits: first social, next might be performance related.  I think
there has been an penchant towards things like simulation and non-destructive
testing, etc. of late, but we have recently seen with the Challenger
incident, that our best laid plans run into problems.  I wonder if we have
not taken these techniques, too far?  Perhaps we have to keep extra margins
for error and destructive testing (however expensive) in tact.  Consider:

Would YOU step into a plane which has only been simulated and never
test flown?

Consider that chemistry classes uses dangerous chemicals, should we
or should we not replace such chemicals with computers and `simulate'
reactions?  An educational point.

Would you trust YOUR life to a system like MYCIN?  Suppose I infected you
with a disease like Anthrax, and said, identify it.  [Note the US Army did
and does infect volunteers with various fatal diseases to test vaccines and
treatments.]

I've had people say, after seeing the first computer graphics planetary
flybys: "Hey that's really neat! Why send expensive spacecraft up there when
you can generate simulations like this?"

Do computer scientists sometimes have difficulty in distinguishing "reality?"

While it is true that computers can and will do somethings better than humans, 
I wonder where and how we will describe that limits.  What about dissent?

I think the people with the greatest humility (and perspective)
in simulation are the physicists who do weather prediction and analysis.
[Note early simulations took 27 hours to run a 24 hour forecast.]
Nothing like running a weather code, then looking out the window.

--eugene miya

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Reference on admissibility of computer records
</A>
</H3>
<address>
Bill Cox
&lt;<A HREF="mailto:bill@crys.wisc.edu ">
bill@crys.wisc.edu 
</A>&gt;
</address>
<i>
Wed, 23 Apr 86 00:50:40 CST
</i><PRE>

This is a copy of an article submitted to mod.legal on usenet.

Subject: Re: Admissabilty of computer files as evidence
Newsgroups: mod.legal
To: info-law@sri-csl.arpa
Summary: article in ACM TOOIS on admissibility of computer-generated records
References: &lt;8604171858.AA03202@taurus&gt;
 
There is an article in ACM TOCS that has some relevance to the subject.
 
        Roger King and Carolyn Stanley, "Ensuring the Court Admissibility of
        Computer-Generated Records", ACM Transactions on Office Information
        Systems, Vol 3, Number 4, pp398-412.

The focus is on issues related to accounting records, e.g., "What does Smith
owe my company", but also discusses issues in conspiracy cases where
"computer-generated records to prove essential elements of [the government's]
case."
 
There are relevant legal citations, and references to the Federal Rules
of Evidence and their current application to computer-generated records.
 
I think this article is in the "must-read" category for anyone interested
in both law and computers.  I am a novice in the law [I've paid many dollars
to attorneys, and a little of the knowledge rubbed off], but I must say
that this article seems well-researched and quite thorough.
 

	William Cox
	Computer Sciences Department
	University of Wisconsin, Madison WI
	bill@wisc.crys.edu
	...{ihnp4,seismo,allegra}!uwvax!bill

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Phone billing error at Pacific Bell, etc.
</A>
</H3>
<address>
      John Coughlin 
&lt;<A HREF="mailto:John_Coughlin%CARLETON.BITNET@WISCVM.WISC.EDU">
John_Coughlin%CARLETON.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
23 Apr 86 00:11:19 EST
</i><PRE>

&gt; More than a million California telephone customers will be getting an
&gt; unpleasant surprise in their April bills because of an equipment
&gt; malfunction...No estimate given of how much revenue was lost.|

According  to  Computer  Chronicles  on  PBS  tonight the "reprogramming
error" cost  Pacific Bell $51 million.  In  a related story, students in
Arkansas  obtained  a  confidential  telephone  number from Southwestern
Bell's  computer system  which enabled  them to  place thousands of free
long distance calls.  Also, a long lineup at a particular pay phone in a
Sears store in  Hackensack tipped off police to the  fact that one could
use  it to  place international  calls free  of charge.   Apparently 400
phones were affected by this software bug.
                                                                 /jc

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Challenger article
</A>
</H3>
<address>
&lt;<A HREF="mailto:    Rminnich@dewey.udel.EDU">
    Rminnich@dewey.udel.EDU
</A>&gt;
</address>
<i>
Fri, 25 Apr 86 12:03:25 EST
</i><PRE>

   The following article appeared in the Phila. Inquirer of 4/24.
   Since the Challenger was discussed on Risks by people in the 
know, I wondered if we could hear some more opinions. The writer 
is William V. Shannon, with the Boston Globe.
   I am excerpting; it is a long article.

      "... It is now clear that there was no explosion ..."
   
      "... The astronauts ... were probably making frantic efforts
   to bring their craft under control as it hurtled downward. If the 
   craft had been equipped, as it should have been, with parachutes and 
   seat-ejection fail-safe systems they could have saved themselves. "
      "They died because of NASA's false economies and incompetence. "
      "... Dr. William Doering, professor of chemistry at Harvard, pointed 
   out that ... was not an explosion at all. 'It is best described 
   as a fast fire ... If the fuel tank had exploded ... it would be 
   producing something much bigger ... They have stopped showing the 
   space module [sic] but I am confident that it is intact also or 
   was until it hit the water. '"
      "... Terry J. Armentrout, director of the NTSB investigation, 
   told reporters that '... the shuttle Challenger, including the crew 
   compartment, apparently survived the blast mostly intact'".
      Continues Shannon, 
      " ... the astronauts died from the force of the impact as the 
   craft hit the water ... There is no reason to believe that the crew died 
   because of sudden decompression ..."

   He goes on to hint that the down-link was lost as part of a
cover-up rather than due to the fast fire. 
   OK. I do not know if the Moderator wants to see replies 
or comments about this on RISKS; if not, please send me 
any thoughts you might have. I will send them on to the paper. 
Maybe this guy is absolutely right, but I have my own thoughts on that.
   ron minnich
   
</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.44.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.46.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-101</DOCNO>
<DOCOLDNO>IA012-000123-B018-346</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.46.html 128.240.150.127 19970217002718 text/html 16815
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:25:46 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 46</TITLE>
<LINK REL="Prev" HREF="/Risks/2.45.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.47.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.45.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.47.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 46</H1>
<H2> Tuesday, 29 Apr 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Martin J. Moore 
</A>
<DD>
<A HREF="#subj1.1">
on Challenger article
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  TV "piracy" 
</A>
<DD>
<A HREF="#subj2.1">
Nicholas Spies
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  HBO -- Hacked Briefly Overnight 
</A>
<DD>
<A HREF="#subj3.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The dangers of assuming too much -- on TMI-2 
</A>
<DD>
<A HREF="#subj4.1">
J. Paul Holbrook
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A POST Script on Nuclear Power 
</A>
<DD>
<A HREF="#subj5.1">
Peter G. Neumann
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Challenger article
</A>
</H3>
<address>

&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

&gt; From:     Rminnich@dewey.udel.EDU
&gt;   [excerpts from article Phila. Inquirer of 4/24.]

&gt;      "... It is now clear that there was no explosion ..."
   
Rubbish.  There was certainly an explosion; what do they think scattered
debris for miles and threw some so high it took an hour to impact?  That
it was not an all-consuming explosion as was originally thought, is now
obvious.  But I still wouldn't want to be anywhere around an explosion
like the one we saw.

&gt;      "... The astronauts ... were probably making frantic efforts
&gt;   to bring their craft under control as it hurtled downward. If the 
&gt;   craft had been equipped, as it should have been, with parachutes and 
&gt;   seat-ejection fail-safe systems they could have saved themselves. "

According to figures I have seen in the news media (AP stories, I think;
the newspapers are in the trashpile now) at the moment of downlink loss
the cabin pressure was 800 psi and the acceleration was 16g.  These were
extrapolated to be 2000 psi and 100g a few seconds later.  These are 
obviously unsurvivable in themselves, not to mention that the cabin windows
would not have survived the overpressure, resulting in explosive 
decompression, which is not exactly healthy either.

Of course, *if* anyone survived the initial blast and remained conscious, 
I'm sure they would have made frantic efforts to bring the craft under 
control (who wouldn't?).  On the subject of parachutes, I think that any
external parachute system would certainly have been burned away or ripped
away by the initial blast.  As for ejection seats, these may or may not
be useful; I believe there are severe technical problems (I'll have to pass
on the details -- maybe an expert on the subject will speak up.)  

&gt;      "They died because of NASA's false economies and incompetence. "

The commission hasn't even made its report yet, but this reporter obviously
has all the facts and has completed the inquest.  It's true that NASA looks
less than pure based on what the media have reported, but this verges on
deliberate slander (can you slander a government agency? sorry, I digress.)
(Also, let's please *not* start the "whose fault was it" flamage here; those
of you who read SPACE are probably more than sick of it by now, as I am.)

&gt;      "... Dr. William Doering, professor of chemistry at Harvard, pointed 
&gt;   out that ... was not an explosion at all. 'It is best described 
&gt;   as a fast fire ... If the fuel tank had exploded ... it would be 
&gt;   producing something much bigger ... They have stopped showing the 
&gt;   space module [sic] but I am confident that it is intact also or 
&gt;   was until it hit the water. '"

I haven't the chemistry knowledge to dispute this on technical grounds;
however, my point about debris scattering still holds.  Also, why did he 
wait until the crew module was found?  Why didn't he say after seeing the 
pictures, "That's not an explosion, it's just a fast fire."  Also, what is 
"intact"? "More or less in one piece" or "completely sound"?  Apparently at 
least the former was true.  But the 100g acceleration would pretty well rule 
out the latter.

&gt;      "... Terry J. Armentrout, director of the NTSB investigation, 
&gt;   told reporters that '... the shuttle Challenger, including the crew 
&gt;   compartment, apparently survived the blast mostly intact'".

Aw, c'mon!  The crew module stayed in one piece, but it was completely
separated from the rest of the Orbiter, which was wrecked (it's no surprise
that the crew module could maintain its integrity even if no other part
of the Orbiter did; it's the strongest part of the Orbiter.)
If the rest of the Orbiter survived "mostly intact" where did the bits of
Orbiter wreckage shown by the media (e.g., wing and stabilizer pieces, 
tiles, etc.) come from?

&gt;      Continues Shannon, 
&gt;      " ... the astronauts died from the force of the impact as the 
&gt;   craft hit the water ... There is no reason to believe that the crew died 
&gt;   because of sudden decompression ..."

Well, they probably died from 100g acceleration before they had a chance to
die from decompression; if not, decompression probably would have done it.
Maybe we'll never know for sure, but I believe the crew died within seconds of
the blast. 

&gt;   He goes on to hint that the down-link was lost as part of a
&gt;cover-up rather than due to the fast fire. 

This is so unbelievable that I don't even know what to say.  I don't suppose
he offers the least bit of proof?  (Speaking from personal experience,
which includes over 100 space launches including the first 8 shuttles,
I would say that there is *no* way such a coverup could be maintained for 
long, given the large number of people involved in the launch process.)

As always, I express herein only my own personal opinions, and not the
official position of my employer or any government agency. 

				Martin J. Moore
				mooremj@eglin-vax.arpa

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
TV "piracy"
</A>
</H3>
<address>
&lt;<A HREF="mailto:Nicholas.Spies@GANDALF.CS.CMU.EDU">
Nicholas.Spies@GANDALF.CS.CMU.EDU
</A>&gt;
</address>
<i>
28 Apr 1986 19:48-EST
</i><PRE>
To: risks@sri-csl

The recent "Captain Midnight" episode was, in my book, a completely
justified display of civil disobedience. I live in Pittsburgh, which has a
(pathetic) cable company to which I subscribe, so I am not an aggrieved dish
owner, but I sympathize with them. Why? Because cable program providers MUST
factor in ONLY wired-in subscribers when signing contracts to buy
programming (or else they are idiots) so the fringe viewers with discs (most
often far from any cable company) have little or nothing to do with their
financial situations. HBO's decision to scramble its signal to force people
who cost HBO, or cable systems, ABSOLUTELY NOTHING to "hook up" is
ridiculous; at least disc owners should be given a hefty credit for their
investment before having to buy a descrambler and pay monthly rates. Not
being a lawyer, it also seems that scambling makes a mockery of the 1934
Communications Act, which prevents encoded transmissions over public
channels.

This sort of problem may prevent another medium -- videodiscs -- from
fulfilling their promise of providing vast aounts of cheap information.
Consider: a 12" videodisc can store up to 108,000 frames of information.
What information? In the case of NASA, lots of planetary images. In the case
of the National Gallery of Art, 1645 art works and a couple of movies. But
what if a videodisc publisher wanted to provide a comprehensive collection
of ALL major works of western art, 65 TIMES the number of art works provides
on the NGA disc. As it stands, this would be impossible because each
provider of art images would want a royalty for each disk (to pay costs,
perhaps 1 cent per work per copy. But this would mean a $10,800 royalty PER
DISC for all suppliers, which would make the disc completely unsalable,
making a comprehensive history of art expert system all but impossible to
develop because the costs could not be amortized. (If you think this is
outlandish, consider that the Metropolitan Museum in New York wanted to
charge the US Marine Corps $50 for the LOAN of a photograph of an artifact
that the Marines wanted to include in their Bicentennial exhibit in
Washington DC in 1976. The Marines, to their credit, declined to pay.)

Some new paradigm will have to be worked out before mega-media will be
acceptable both to information providers and consumers.

Nick

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
HBO -- Hacked Briefly Overnight
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Mon, 28 Apr 86 21:51:15 edt
</i><PRE>

Overpowering a transmitter is essentially trivial.  If HBO was scrambling
its uplink, Captain Midnight's missive must have been similarly scrambled.
Perhaps HBO's scramble algorithm is also trivial.  Of course, if the uplink
is in the clear, Captain Midnight merely needed brute force.  Anyone know
how or where the signal is scrambled?  Or whether an HBO receiver set to
unscramble will pass an in-the-clear signal?  I realize that facts may set
limits to the discussion.  Regrettable.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The dangers of assuming too much
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
29 Apr 86 14:32:33 PDT (Tuesday)
</i><PRE>
From: Holbrook.OsbuSouth@Xerox.COM
To: Risks@SRI-CSL.Arpa, Methodology^.PA@Xerox.COM

[From "Three Mile Island: Thirty Minutes to Meltdown" by Daniel Ford;
Viking Press 1982.]

(The discussion preceeding this quote talks about how the temperature of the
fuel rod at Three Mile Island-2 increased from the normal 600 degrees to
over 4000 degrees during the 1979 accident, partially destroying the fuel
rods.  It also notes that instruments to measure core temperatures were not
standard equipment in reactors.)

  "Purely by chance, there were some thermocouples -- temperature-measuring
  devices -- present in the TMI-2 reactor when the accident occured.  Located
  about 12 inches above the top of the core, these thermocouples ... were
  installed as part of an experimental study of core performance, and were a
  temporary instrumentation feature of the plant, connected to the
  control-room computer for measuring temperatures during normal operation.
  Accordingly, if a control-room operator requested temperature data from the
  computer, he would receive useful information only when the temperature was
  within the normal 600 degree range.  When the temperature got above 700
  degrees, the computer, instead of reporting it, would simply print out a
  string of question marks -- "???????."  Although the thermocouples could
  actually measure much higher temperatures, the computer was not programmed
  to pass these higher temperature readings on to the operators ... there was
  an urgent need for timely, reliable data about the temperature in the core
  in the critical period between 6am and 7am on March 28; what was available
  from the computer was mostly question marks."
  
Paul

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
A POST Script on Nuclear Power
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Tue 29 Apr 86 22:42:21-PDT
</i><PRE>

While we are on nuclear power plants, please let me know if anyone gets some
solid facts that involve the computer-control system in the Chernobyl
nuclear accident in the Soviet Union over the weekend ("partial meltdown",
"graphite explosion", or whatever it was).

By the way, today's Washington Post gave a chronology of some of the more
interesting previous nuclear-power accidents, which I summarize here:

  Dec 2 1952 Chalk River, Canada.  Million gals radioactive water built up.  
      6 mos to clean up.  Human error.
  Nov 1955 EBR-1 experimental breeder, Idaho Falls.  Mishapen rods, human err.
  Oct 7-10 1957 Windscale Pile #1.  English coast of Irish Sea.  Largest
      known release of radioactive gases (20,000 curies of iodine).  Fire.
      .5 M gals milk destroyed.  Plant permanently shut down.
  Winter 1957-58 Kyshtym USSR.  400 mi contaminated?  Cities removed from maps.
  May 23 1958 Chalk River again.  Defective rod overheated during removal.
      Another long clean-up.
  Jul 24 1959 Santa Susana CA, 12 of 43 fuel elements melted.  Contained.
  Jan 3 1961 SL-1 Idaho Falls (military, experimental).  Fuel rods mistakenly
      removed.  3 killed.
  Oct 5 1966 Enrico Fermi, Michigan.  Malfunction melted part of core.
      Contained.  Plant closed in 1972.
  Jun 5 1970 Dresden II, Morris Illinois.  Meter gave false signal.  Iodine
      at 100x permissible.  Contained.
  Nov 19 1971 Monticello Minn.  50,000 gals radioactive waste spilled into
      Mississippi River, some into St Paul water supply.
  Mar 22 1975 Brown's Ferry, Decatur Alabama.  Insulation caught fire,
      disabled safety equipment.  $150 M cleanup.
  Mar 28 1979 Three Mile Island II.  NRC said, "within an hour of 
      catastrophic meltdown".  4 equipment malfunctions plus human errors
      plus inadequate control monitors.
  Feb 11 1981 Sequoyah I, Tennessee.  8 workers contaminated, 110,000 gals
      radioactive coolant leaked.
  Jan 25 1982 Ginna plant, Rochester NY.  Steam-generator tube ruptured.
  Feb 22 &amp; 25 1983 Salem I NJ.  Auto shutdown system failed twice.  Manual OK.
  Apr 19 1984 Sequoyah I again.  Contained.
  Jun 9 1985 Davis-Besse, Oak Harbor, Ohio. 16 pieces of equipment failed,
      at least one wrong button pushed.  Auxiliary pumps saved the day.
   
PGN (just off the plane from DC)

PS.  I hope you don't conclude that I am interested ONLY in catastrophes.  I
really have been professionally involved for many years in trying to develop
better computer systems.  But that does not mean that I have to trust them...

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.45.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.47.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-102</DOCNO>
<DOCOLDNO>IA012-000123-B018-368</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.47.html 128.240.150.127 19970217002729 text/html 11746
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:25:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 47</TITLE>
<LINK REL="Prev" HREF="/Risks/2.46.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.48.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.46.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.48.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 47</H1>
<H2> Thursday, 1 May 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
HBO hacking 
</A>
<DD>
<A HREF="#subj1.1">
Phil R. Karn
</A><br>
<A HREF="#subj1.2">
 Dan Franklin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  What are the limits to simulation? 
</A>
<DD>
<A HREF="#subj2.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Strategic Systems Reliability Testing 
</A>
<DD>
<A HREF="#subj3.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Correction on Challenger Discussion 
</A>
<DD>
<A HREF="#subj4.1">
Jeff Siegal
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
HBO hacking
</A>
</H3>
<address>
Phil R. Karn
&lt;<A HREF="mailto:karn@mouton.bellcore.com ">
karn@mouton.bellcore.com 
</A>&gt;
</address>
<i>
Wed, 30 Apr 86 17:58:40 edt
</i><PRE>

Satellite transponders used by the cable TV industry to relay programs are
"bent pipes", that is, they simply repeat whatever they hear.  The M/A-Com
scrambler equipment is all on the ground. However, the descramblers will
switch to "pass through" mode if a nonscrambled signal is received.
Therefore, when Captain Midnite sent his unencoded signal, the descramblers
simply passed the signal straight through to the various cable systems.

The transmitter power available on a satellite is very limited (5-10 watts).
Even with a very large receiver dish, the raw carrier-to-noise ratio is far
too low for acceptable picture quality if a linear modulation scheme (such
as VSB AM, used for ordinary TV broadcasting) were used.  Therefore,
satellite TV transmissions are instead sent as wideband FM in a 40 MHz
bandwidth.  Since the baseband video signal is only 5 MHz wide, this results
in a fairly large "FM improvement ratio" and a pronounced "capture" effect.
Full receiver capture occurs at about a 10 dB S/N ratio, and this figure is
essentially the same whether the "noise" is in fact thermal noise or another
uplink signal.  So for the purposes of fully overriding another uplink your
signal must be about 10 dB stronger (10 times the power).

The latest transponders are much more sensitive than those on the earliest
C-band domestic satellites launched 12 years ago.  Most of the 6 Ghz High
Power Amplifiers (HPAs) in use at uplink stations are therefore capable of
several kilowatts of RF output, but are actually operated at only several
hundred watts.  So Captain Midnite could have easily captured the HBO uplink
if he had access to a "standard" uplink station (capable of several
kilowatts into a 10 meter dish) or equivalent.  

I happened to turn on HBO in my Dayton, Ohio hotel room at about 1AM, half
an hour after the incident occurred, and noticed lots of "sparklies" (FM
noise) in the picture. At the time I grumbled something about having to pay
$90/night for a hotel that couldn't even keep their dish pointed at the
satellite, but I now suspect that the pirate was still on the air but that
HBO had responded by cranking up the wick on their own transmitter.  Because
they were unable to run 10 dB above the pirate's power level, they were
unable to fully recapture the transponder, hence the sparklies.  (Can anyone
else confirm seeing this, proving that my hotel wasn't in fact at fault?)

Even though each transponder has a bandwidth of 40 MHz, it is separated by
only 20 MHz from its neighbors. Alternating RF polarization is used to
reduce "crosstalk" below the FM capture level. Polarization "diversity"
isn't perfect, though, so it is possible in such a "power war" that the
adjacent transponders could be interfered with, requiring *their* uplinks
to compensate, which would in turn require *their* neighbors to do the same,
and so on.  So Captain Midnite could cause quite a bit of trouble for
all the users of the satellite, not just HBO.

Captain Midnite could have been anywhere within the Continental US, Southern
Canada, Northern Mexico, the Gulf of Mexico, etc.  In the worst case, it
could be practically impossible to locate him.  If he is caught, it will be
either because he shoots off his mouth, arouses suspicion among his
neighbors (or fellow workers, if a commercial uplink station), or transmits
something (distinctive character generator fonts, etc) that gives him away.
Only the NSA spooksats would be capable of locating him from his
transmissions alone, and I suspect even they would require much on-air time
to pinpoint the location accurately enough to begin an aerial search.

Phil Karn

</PRE>
<HR><H3><A NAME="subj1.2">
 HBO hacking
</A>
</H3>
<address>
    Dan Franklin 
&lt;<A HREF="mailto:dan@bbn-prophet.arpa">
dan@bbn-prophet.arpa
</A>&gt;
</address>
<i>
Wed, 30 Apr 86 18:11:02 EDT
</i><PRE>

Re the interception of HBO's uplink by "Captain Midnight": I understand
that the video scrambling is indeed pretty simple, consisting of reversing
black and white on some "randomly-chosen" scan lines.  It's easy to build
a box that will undo this scrambling.  The sound is much harder; it uses
DES.  In the accounts I read, Captain Midnight just put up a still video
picture with no sound, which would make sense assuming that the uplink is
encoded; he could easily encode his video but not his sound.

Nicholas Spies seems to feel that the scrambling was purely an act of
malice against individuals with dishes.  Not so; according to a recent
issue of Forbes, when HBO started scrambling, a number of CABLE TV
OPERATORS they'd never heard of signed up for the decoders!  If cable TV
operators can charge their customers for HBO, why should they get it for free?

I had some other comments about what the FCC Communications Act really
says and what "public" means, but this is getting awfully far from Risks...
"Telecom" and "poli-sci" are no doubt more appropriate.

	Dan Franklin (dan@bbn.com) 

     [Thanks for the restraint.  However, the relevance of the HBO case to
      RISKS is clear.  Various risks exist -- but have been customarily
      ignored: easy free reception and spoofing without scrambling, 
      video spoofing and denial of service even with scrambling.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 What are the limits to simulation?
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu,  1 May 86 10:43:02 EDT
</i><PRE>
To: eugene@AMES-NAS.ARPA
cc: RISKS@SRI-CSL.ARPA, LIN@MC.LCS.MIT.EDU

    From: eugene at AMES-NAS.ARPA (Eugene Miya)

    I really wonder what simulation's various limits are.

I believe it was Eddington that said "The Universe is not only
stranger than we imagine, but it is stranger than we can imagine."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Strategic Systems Reliability Testing
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu,  1 May 86 10:41:18 EDT
</i><PRE>
To: ball@MITRE.ARPA
cc: RISKS@SRI-CSL.ARPA, LIN@MC.LCS.MIT.EDU, ARMS-D@MC.LCS.MIT.EDU

    From: ball at mitre.ARPA (Dan Ball)

    I'm relatively certain that the numbers of warheads actually reaching
    the target following the initiation of an attack would be far less
    than the numbers in the inventories.

Probably true, if what you mean by target is a hardened silo.  But if
you aim at the center of a city, and you miss by a mile, that's still
"reaching the target" too.  And THAT is what the SDI is supposed to
protect us against.

    Finally, the briefing from SDI office that I heard didn't promise
    perfection.  Unlike some of the political supporters who promise that
    it will be safe for children to play outside during a nuclear
    exchange, the SDI technical types were talking about the impact it
    would have on the numbers and required modifications to the Soviet
    ICBMs that would be required for them to maintain the same confidence
    of assured first strike destruction of the US.

None of the technical supporters believe in near-perfect defense.  But
the political supporters do, and they are lying to the public.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Correction on Challenger Discussion (<A HREF="/Risks/2.46.html">RISKS-2.46</A>)
</A>
</H3>
<address>
Jeff Siegal 
&lt;<A HREF="mailto:JBS%DEEP-THOUGHT@EDDIE.MIT.EDU">
JBS%DEEP-THOUGHT@EDDIE.MIT.EDU
</A>&gt;
</address>
<i>
Thu 1 May 86 18:15:43-EDT
</i><PRE>
To: RISKS%SRI-CSL@EDDIE.MIT.EDU

    &gt;     "... Dr. William Doering, professor of chemistry at Harvard, pointed 
    &gt;   out that ... was not an explosion at all. 'It is best described 
    &gt;   as a fast fire ... If the fuel tank had exploded ... it would be 
    &gt;   producing something much bigger ... "

    [...]  Also, why did he 
    wait until the crew module was found?  Why didn't he say after seeing the 
    pictures, "That's not an explosion, it's just a fast fire."

It is stated in the original column that Dr. Doering's observation
_was_ made when he watched the videotape, not months later, as Mr.
Moore claims.

Jeff Siegal

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.46.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.48.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-103</DOCNO>
<DOCOLDNO>IA012-000123-B019-33</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.48.html 128.240.150.127 19970217002746 text/html 15907
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:26:14 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 48</TITLE>
<LINK REL="Prev" HREF="/Risks/2.47.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.49.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.47.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.49.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 48</H1>
<H2> Saturday, 3 May 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Failure to Backup Data 
</A>
<DD>
<A HREF="#subj1.1">
James H. Coombs
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer detracting from effective communication? 
</A>
<DD>
<A HREF="#subj2.1">
Bruce A. Sesnovich
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Words, words, words... 
</A>
<DD>
<A HREF="#subj3.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Copyright Laws 
</A>
<DD>
<A HREF="#subj4.1">
Matthew Kruk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Correction on Challenger 
</A>
<DD>
<A HREF="#subj5.1">
Martin J. Moore
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
     Failure to Backup Data
</A>
</H3>
<address>
          James H. Coombs  
&lt;<A HREF="mailto:JAZBO%BROWNVM.BITNET@WISCVM.WISC.EDU">
JAZBO%BROWNVM.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
Fri, 2 May 1986 20:22 EDT
</i><PRE>
To:  &lt;RISKS@SRI-CSL.ARPA&gt;

Experienced computer users are aware that they must backup their data
regularly to ensure that the inevitable hardware/software failures and
operator errors do not cost them months of work and considerable stress.  In
most mainframe environments, users are supported by well-designed backup
systems--including off site storage of tapes.  With the first wave of
microcomputers, people found that facilities for backing up their work were
inadequate: they consume too much time and are hard to organize.
Consequently, few microcomputer users can recover all of their work up to the
previous 24 hours.  The majority of users would lose years of work if the site
were destroyed or seriously damaged.  In fact, most people consider themselves
"lucky" if they can recover even a small portion of their work.  [I should add
that I know of one heavily-used VAX that gets backed up quarterly at best.]

Unfortunately, we are in the process of introducing more and more
professionals to computers.  We tell them that their work will be faster, more
efficient, and possibly even better.  From a recent survey of my department
(English), I would estimate that about 90% of "them" believe us.  So, we are
about to equip these people with workstations and will teach them to develop
their books on these machines.  Unfortunately, no one has mentioned backup at
all so far, in spite of the fact that these machines are rumored to eat files
and directories.  Even if we assume that professors will be admonished to
backup their files regularly, we cannot be so naive as to assume that they
will if it takes more than a few minutes.  Since a complete backup of a 10
megabyte hard disk on an IBM XT can take a half-hour, I am sure that backing
up a 40 megabyte hard disk on a workstation will require more time (and
diskettes) than the majority of our scholars will invest.  Now, one of these
people is going to lose a book, or most of a book.  And s/he is not going to be
happy.  In fact, I think we can be sure that new users will not ever want to
see a computer again, and colleagues may be scared off as well.  In addition,
someone is going to be held accountable.

Here is a brief tally of the risks:

1) loss of work by the professor

2) loss of interest in computing by the professor and some colleagues

3) loss of confidence in departmental consultant (me)

4) loss of confidence in project team heading the project

There may be others, and (1) may actually be much more severe than a loss of
work.  A delay of a couple of months in developing a manuscript could cost a
young professor tenure, for example (assuming that given the seasonal nature
of academia, a two month delay in submission could cause a six month delay in
acceptance or could make one's work obsolete because of another publication).

I would like to hear from others who have faced these problems.  Horror
stories, preventive strategies, references to theoretical articles--all would
be useful.  I suppose that there may be legal considerations as well?

--Jim Coombs, Brown University
              JAZBO@BROWNVM
Acknowledge-To:  &lt;JAZBO@BROWNVM&gt;

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer detracting from effective communication?
</A>
</H3>
<address>
&lt;<A HREF="mailto:rti-sel!dg_rtp!rtp41!dg_rama!bruces%mcnc.csnet@CSNET-RELAY.ARPA">
rti-sel!dg_rtp!rtp41!dg_rama!bruces%mcnc.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Fri, 2 May 86 20:13:18 edt
</i><PRE>

ARE WORD-PROCESSING AND ELECTRONIC MAIL HELPING TO PROLIFERATE BAD WRITING?

Before word processors and electronic mail existed, important letters or
documents were usually handwritten and hand-corrected, often in several
drafts, before being typed and mailed.  The typing of the letter represented
a finalizing and codifying process which encouraged well thought-out
communication. Care needed to be taken, since a single error could
necessitate re-typing the entire letter or document.

There is a hidden risk in the new media, in that they have enabled us to bypass
the correction and finalizing phases of letter writing, often resulting in 
quick and efficient dissemination of poorly planned, sloppy and confusing prose.

In technical communications, where complex and potentially important ideas are
exchanged, clearness of expression is obligatory.  I could cite, nevertheless,
many examples (some from recent RISKS, which I will not include to avoid
unfairly embarrassing the authors) where bad writing has rendered sentences
unintelligible and thoughts and ideas obscure.

We tend to be very quick to correct each other on points of technical accuracy,
but very slow to correct, or even recognize, inaccuracy of expression in our
own or others' writing.

While I do not advocate abandoning the ASCII keyboard for quill and parchment,
I do encourage readers of RISKS to take the time to proof and revise any of
their writing meant to convey important technical information.

Re-read your work, and have others examine it for clarity, absence of jargon,
and general comprehensibility before you send or submit it to anyone.  Remember
that word processors and email facilities are only tools, and that the burden
of effective communication still rests upon those who use them.

Bruce A. Sesnovich         mcnc!rti-sel!dg_rtp!sesnovich
Data General Corp.         suntoo!dg_rtp!sesnovich@sun.com
Westboro, MA               "The rest is silence, musically speaking"

      [This message gets a HEARTY ENDORSEMENT from the RISKS COORDINATOR.
       I am horrified at some of the messages that I get.  I do reject 
       some solely on the grounds of general incoherence.  (I stated
       initially that I would not tamper with messages, but occasionally
       I do fix a horrible "mispelling".  Being an inveterate punster,
       I am attuned to ambiguities; however, I notice that most people
       do not notice them (the ambiguities, not the people).

       Bruce's message is relevant to RISKS.  Just as ambiguities in program
       specifications can cause serious risks, so can ambiguities in
       discussions.  Much of the lay understanding of systems and computers
       -- particularly for something like Star Wars -- is based on
       sloppy reasoning, misrepresentation, misunderstanding, and so on.  
       If we can't take some care in writing what we think we meant to say,
       then it may not be worth writing -- or reading.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Words, words, words... 
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Sat, 3 May 86 13:06:29 edt
</i><PRE>

Many words have appeared here and in the press on topics such as SDI, 
Chernobyl, and other matters.  At least in this forum, we should be careful
of what we say, and what we think others mean when they say something.  To 
quote my favorite source, The American Heritage Dictionary of the English
Language:  

deceit - Misrepresentation; deception.  A strategem; trick; wile.  

deceitful - Given to cheating or deceiving.  Misleading, deceptive.  

deceive - To delude; mislead. _Archaic:_ To catch by guile; ensnare. 
	Synonyms: deceive, betray, mislead, beguile, delude, dupe, hoodwink,
	bamaboozle, outwit, double-cross.  These verbs mean to victimize 
	persons, for the most part by underhand means.  

error - An act, assertion, or belief that unintentionally deviates from what 
is correct, right, or true.  The condition of having incorrect or false 
knowledge.  A mistake.  The difference between a computed or measured value 
and a correct value.  
	Synonyms: error, mistake, oversight.  These nouns refer to what is 
	not in accordance with truth, accuracy, right, or propriety.  Error
	is clearly preferable to indicate belief in untruth or departure from 
	what is morally or ethically right or proper.  Mistake often implies 
	misunderstanding, misinterpretation, and resultant poor judgement... 
	Oversight refers to an omission or a faulty act that results from... 
	lack of attention.  

lie - A false statement or piece of information deliberately presented as 
being true; a falsehood.  Anything meant to deceive or give a wrong 
impression.  To present false information with the intent of deceiving. To 
convey a false impression.  To put in a specific condition through deceit. 

mislead - To lead or guide in the wrong direction.  To lead into error or 
wrongdoing in action or thought; influence badly; deceive.  
	See synonyms at deceive.  Misleading, deceptive, delusive.  Mis-
	leading is the most nonspecific... it makes no clear implication 
	regarding intent.  Deceptive applies... to surface appearance, and 
	may imply deliberate misrepresentation.  Delusive stresses calcu-
	lated misrepresentation or sham.  

mistake - An error or fault.  A misconception or misunderstanding.  To under-
	stand wrongly; misinterpret.  To recognize or identify incorrectly. 
	Wrong or incorrect in opinion, understanding, or perception.  Based 
	on error; wrong... 
	See synonyms at _error_.  

I have condensed the definitions and discussions somewhat.  The point is that
a person who believes something, however erroneously, and espouses and publi-
cly supports that belief, is *not* lying.  These are complex times.  There
are many matters about which reasonable persons, even reasonable scientists, 
may differ.  There is no point in saying that a person lied when that person
was doing the best work possible based on the knowledge and belief available
at the time.  It significantly interferes with rational discussion - it 
not only interferes with cooperative searches for the truth, it nearly 
eliminates any chance that the truth, when found, will be accepted.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Copyright Laws
</A>
</H3>
<address>
&lt;<A HREF="mailto:Matthew_Kruk%UBC.MAILNET@MIT-MULTICS.ARPA">
Matthew_Kruk%UBC.MAILNET@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Fri, 2 May 86 09:24:24 PDT
</i><PRE>
ReSent-To: neumann@SRI-CSL.ARPA [and thence to RISKS]

From the Thursday May 1st issue of the Vancouver Sun (Vancouver,
British Columbia):

              Copyright laws apply to software: court

  Waterloo,Ont. - Canada's 50-year-old copyright laws, created to
  protect artistic works such as music and literature, also cover
  computer programs, the Federal Court of Canada has ruled in a
  decision believed to set an international precedent.

  Although the verdict can be appealed, it is thought to be the
  first case anywhere in which legal dispute over rights to software
  has gone to trial. Similar cases in Britain, Australia and the
  U.S. have concluded with pre-trial injunctions against software
  pirates.

  In a decision this week, Justice Barbara Reed ruled in favour of
  Apple Computer Inc.

  Apple lawyer Alfred Schorr said the company cited the copyright
  law in suing "a very large number of defendants" involved in
  assembling and selling computers that were virtually identical to
  the Apple II.

  A central issue was whether programs encoded electronically on
  silicon chips are simply pieces of hardware or in fact represent
  intellectual property that should be viewed as "literary works",
  Schorr said.

  The defendants are prohibited from assembling and offering for
  sale computers or component parts that infringe on the two basic
  operating programs used in the Apple II.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Correction on Challenger
</A>
</H3>
<address>

&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
0  0 00:00:00 CDT
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

   &gt; [From Jeff Siegal]
   &gt; It is stated in the original column that Dr. Doering's observation
   &gt; _was_ made when he watched the videotape, not months later, as Mr.
   &gt; Moore claims.

I did not see the original article and the time element was not clear
from the excerpt.  Thank you for clarifying this.  I withdraw the comment
in question.
				/mjm

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.47.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.49.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-104</DOCNO>
<DOCOLDNO>IA012-000123-B019-54</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.49.html 128.240.150.127 19970217002803 text/html 23389
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:26:27 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 49</TITLE>
<LINK REL="Prev" HREF="/Risks/2.48.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.50.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 49</H1>
<H2> Tuesday, 6 May 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Perrow on reactor containment vessels 
</A>
<DD>
<A HREF="#subj1.1">
Richard Guy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Captain Midnight 
</A>
<DD>
<A HREF="#subj2.1">
Scott Dorsey
</A><br>
<A HREF="#subj2.2">
 MRB
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  NSA planning new data encryption scheme - they'll keep the keys 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Espionage 
</A>
<DD>
<A HREF="#subj4.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  The Star Wars Swindle 
</A>
<DD>
<A HREF="#subj5.1">
Dave Weiss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Backups 
</A>
<DD>
<A HREF="#subj6.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Interpreting Satellite Pictures 
</A>
<DD>
<A HREF="#subj7.1">
Lindsay F. Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Word-processing damages expression 
</A>
<DD>
<A HREF="#subj8.1">
Niall Mansfield
</A><br>
<A HREF="#subj8.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Proofreading vs. computer-based spelling checks 
</A>
<DD>
<A HREF="#subj9.1">
Dave Platt
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
       Perrow on reactor containment vessels
</A>
</H3>
<address>
          Richard Guy 
&lt;<A HREF="mailto:guy@LOCUS.UCLA.EDU">
guy@LOCUS.UCLA.EDU
</A>&gt;
</address>
<i>
Wed, 7 May 86 17:27:54 PDT
</i><PRE>

I found the following paragraph to be particularly prophetic: (p.40-1)

"We can be glad that we have containment buildings.  These are concrete
shells that cover the reactor vessel and other key pieces of equipment, and
are maintained at negative pressures--that is, at a lower air pressure than
the atmosphere outside of them--so that if a leak occurs, clean air will
flow in rather than radioactive air flowing out.  The Soviet Union, which
did not begin a large nuclear generating program until about 1970, is far
less concerned about the chance of large accidents, so they did not build
containment structures for their early reactors, nor do they yet require
emergency core cooling systems.  Had the accident at Three Mile Island
taken place in one of the plants near Moscow, it would have exposed the
operators to potentially lethal doses, and irradiated a large population."

How is negative pressure maintained?  By pumping the contents of the
containment building outside?  Into a tank somewhere?  It seems to me that
a leak in the reactor vessel would be releasing very hot gases at very high
pressure into the containment building, and even though the building is much
larger than the vessel, the pressure differential could be eliminated very
soon.  To answer my initial question, it seems that the only safe place to
pump the (possibly contaminated) building contents is into tanks inside
the containment building.  Does anyone know if this is how its done?

Richard Guy			Excerpt from: Normal Accidents, by Perrow
UCLA Computer Science					1984, Basic Books

    [The Soviets are putting the blame on human error.  But that may
     be the case only because they are not very computerized.  However,
     as in TMI, one can put some blame on the absence of computers! 
     In nuclear power, you seem to run the risk of losing either way!]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Captain Midnight
</A>
</H3>
<address>
Scott Dorsey 
&lt;<A HREF="mailto:gatech!gitpyr!kludge@seismo.CSS.GOV">
gatech!gitpyr!kludge@seismo.CSS.GOV
</A>&gt;
</address>
<i>
Sat, 3 May 86 18:30:55 edt
</i><PRE>

   Assuming that Captain Midnight was not an employee of HBO, the trouble
required to override a satellite signal is still pretty complex.  A
significant amount of power is required, probably from some travelling wave
tube or klystron.  High-power microwave stuff is often sold government
surplus at pretty low prices, and a kilowatt or so would certainly do the
job.  Modulation of equipment designed for pulse and similar radar
applications would not be simple, though, and from the look of the bad
signal that the Captain put out, that may well have been the method used.
Large dish antennae are pretty common, and mesh antennae can be put up and
taken down in an hours time, and constructed of wood and chicken wire.

    In addition, it is possible that the signal originated from somewhere
inside HBO.  Several examples exist of the wire feed from a radio station's
studio to their transmitter being cut and replaced with casette players,
etc.  In addition, if the studio/transmitter feed is a 2.6 GHz micro link,
it is pretty trivial to intercept and jam....  It is possible that
off-the-shelf Gunnplexers, and similar low-cost low-power transmission
equipment could be used.

    Of course, there is always the possibility that a disgruntled HBO
employee had a little bit of fun...

&gt;From the Land of Ted Turner 

Scott Dorsey       " If value corrupts
kaptain_kludge         then absolute value corrupts absolutely"

ICS Programming Lab, Rich 110, Georgia Tech, Box 36681, Atlanta, Georgia 30332
...!{akgua,allegra,amd,hplabs,ihnp4,seismo,ut-ngp}!gatech!gitpyr!kludge

</PRE>
<HR><H3><A NAME="subj2.2">
Capt. Midnight &amp; HBO
</A>
</H3>
<address>
&lt;<A HREF="mailto:sdcsvax!sdcrdcf!burdvax!psuvax1!psuvm.bitnet!mrb@psuecl.BITNET@ucbvax.berkeley.edu">
sdcsvax!sdcrdcf!burdvax!psuvax1!psuvm.bitnet!mrb@psuecl.BITNET@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
3 May 86 03:54:44 GMT
</i><PRE>
Via: arpa-videotech@seismo.CSS.GOV 
Via: Ole Jorgen Jacobsen &lt;OLE@SRI-NIC.ARPA&gt;

Well, it takes a little more than just a home TVRO outfit to break in on HBO.
Capt. Midnight had two possible places of entry: 1.) on the microwave path(s)
between HBOs origination point and their uplink transmitter (which I think is
on Long Island, but not sure)......or, 2.) by double illuminating their
satellite transponder which is actually carrying the program.  Double
illuminating is a fancy way of saying "broadcasting over top of them".

During a double illumination, when both signals are about the same power
level as received by the satellite, they just mix together.  I suppose if
one was much more powerful than the other, it would "capture" the channel;
it is F.M., after all.  However, what most likely happened is that the
HBO uplink staff was monitoring their return signal from the satellite.  For
C-band satellites like Galaxy, Westar, Satcom, etc., you send the signal up
at 6 GHz. and the satellite rebroadcasts it back down at 4 GHz.  Uplinks
routinely send &amp; receive simultaneously in order to monitor their signals.
In any event, they probably saw that somebody was uplinking on their
transponder.....this is not a totally unknown phenomenon; in fact, it
happened on a PBS show not too long ago (Sherlock Holmes, I think).
There are lots of video uplinks out there...some operated by Western Union,
RCA, etc....others by PBS stations in Hartford, Denver, Miami, Columbia S.C.,
etc. or the PBS Master Origination Terminal near Washington, D.C.......still
others by the bigger commercial stations for newsgathering, etc. (Metromedia,
INN, etc.).  Every once in a while, somebody in operations slips up and
starts transmitting on an occupied channel.  Well, standard procedure says
that you turn off your uplink signal to the satellite, which leaves just the
"bad guy".  Then it should be easy to identify who(m) it is.

This is most likely what happened when viewers saw a scrambled mess, and then
just the Capn's message.  Of course, he didn't stay on much longer after
that.  However, every uplink is a known quantity licensed by the FCC...I don't
know of any backyard ones (yet) due to the fairly high-power amplifier and
specialized microwave gear required.  So we can limit the possible suspects
down to the people who were working that night, or had access to the sites.
The type of character generator (electronic typewriter) used to produce the
message graphics limits it further...only a few uplinks probably have this
kind of character generator.  Also, many uplinks put an identification code
in the vertical interval (the black bar that rolls through the picture when
the vertical hold is messed up)...for example, PBS uses a binary number pulse
to identify their uplinks.  If the guy wasn't smart enough to disable or
delete the VITs, well...methinks they got him (not likely though).  Also,
all color bars are not alike when carefully examined, in terms of bar widths,
etc. and I'm sure those few seconds of signal are being pretty thoroughly
torn apart.

This of course presupposes that he did it on the uplink to the satellite,
not on the microwave path.  A good question that remains is: Was his signal
correctly scrambled so that all the descramblers would let it through (HBOs
video scrambling is not particularly sophisticated, unlike their digital
audio encoding...he didn't transmit any audio program)?  Or do descramblers
let "normal" signals through O.K. .... I don't think so.

Let's see some discussion on this! (Sorry the above was so lengthy.)
Personally speaking, it was a neat stunt but he better have covered his tracks
pretty well.

MRB@PSUECL
     
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
NSA planning new data encryption scheme - they'll keep the keys
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@uw-june.arpa ">
jon@uw-june.arpa 
</A>&gt;
</address>
<i>
Sun, 4 May 86 22:20:58 PDT
</i><PRE>

The following excerpts are from a New York Times story "Computer code shift
expected - eavesdropping fear indicated," by David E. Sanger, April 15,
1986, pps 29 and 32.  The story described plans by the National Security
Agency (NSA) to replace the current Data Encryption Standard (DES) with a
new system of its own design.  The story said that the system would be
phased in beginning January, 1988.  Speaking of DES, the story said,

"While the government helped design (DES), it has no special advantage in
determining a particular key being used. ... Security experts say there have
been no known successful efforts to defeat (DES). ...  But NSA officials have
said that they do not want to entrust a rising volume of sensitive data to a
coding system whose major elements have been widely published for some time.

Details of the new system are still unclear.  But ... unlike the Data
Encryption Standard, the new algorithms will not be publicly available.
Instead, they will be buried in computer chips manufactured to NSA
specifications, and encapsulated so that any effort to read the code with
sophisticated equipment would destroy the chip.

... By some accounts, under the new system the NSA would distribute the
keys --  probably limiting them to companies in the United States. ..."

The story explained that NSA wanted the system to be adopted by industry as
well as the Federal government, and if institutions like the Federal Reserve
system adopted it, banks and other private institutions would be encouraged
to follow suit.

I know little about data security and encryption, but these points seem
interesting:

  1. NSA appears concerned that DES may become compromised in the near
  future.

  2. NSA apparently believes that greater security can be assured by
  keeping the encryption algorithm secret.  Could this not lead to a
  false sense of security by preventing independent researchers from
  pointing out weaknesses that NSA is unaware of or unwilling to divulge?
  Is it reasonable to assert that hardware can be built so that no test
  equipment can probe it?

  3.  What about keeping the keys under NSA control?  At the very least,
  it could create logistical difficulties; at worst, it seems to permit
  NSA to snoop at will.

-Jonathan Jacky University of Washington

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Espionage
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Mon, 5 May 86 08:45:37 edt
</i><PRE>
Cc: neumann@sri-csl.ARPA

U.S. Naval Institute Proceedings, May, 1986 (Naval Review issue) has an 
excellent article by Bamford on the Walker case.  Also has a summary of
Navy espionage cases since 1981.
-	About 20 Navy/Marines charged in last five years.
- 	Not one was "recruited" - all approached the bad guys.
- 	All did it for money. 
- 	Although no case involved "computers" a number were "computer-like", 
	i.e. crypto &amp; telecommunications. 
Heartily recommend all compusec types read, and think. 
	- Mike McLaughlin

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
The Star Wars Swindle
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Sun 4 May 86 21:10:34-PDT
</i><PRE>

Dave Weiss passed along the following quote from Harper's, May 86, from an
article by Fred Reed entitled "The Star Wars Swindle":

  "The comprehensive vagueness of Star Wars is, insanely, allowing a
  technical question - Will it work? - to be answered by an ideological
  show of hands."

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Backups
</A>
</H3>
<address>
    Will Martin 
&lt;<A HREF="mailto:wmartin@BRL.ARPA">
wmartin@BRL.ARPA
</A>&gt;
</address>
<i>
Wed, 7 May 86 11:14:34 EDT
</i><PRE>

The issue of backup procedures, difficulties, and methodologies has been
discussed amongst those of us at this Activity and at other parts of the
Army Materiel Command for some time now, mainly in the context of our
acquiring and proliferating small workplace-automation computers which are
located in the users' offices (as opposed to being in traditional computer
centers), and where the systems administration tasks (which would include
backup) are performed by functional specialists who are (usually) not
computer experts or in computer-related job classifications. Though we have
discussed it, there really has been no good and elegant solution to the
problem(s). Most of these machines are backed up on cartridge tapes, with a
daily incremental and weekly full user-filesystem schedule (and monthly for
the entire system). When you then get into the issue of PC's, where you do
not have an assigned system administrator, the whole thing really breaks
down. If you have the luxury of having all your PC's on some network and can
run some sort of background task at odd hours, which backs up data to some
other storage system from each PC, that is great. (We don't have this, and I
don't know of anyone who does.)

One other thing I think we need more of, considering how the existence of
fresh backups cannot be relied upon, is more and better tools to get around
failures. Tools that will let a user get to the data on his hard disk even
after it has nominally been "deleted", or special hardware that will let
someone read data off a disk that has been damaged or trashed by some glitch
or another -- we all know that the bits are still there on the medium; it is
just the paths to get to them that are damaged and garbaged by failures. I
believe that there are firms who do this on a contract basis now; we
probably need to implement this expertise in devices and programs that are
usable by less-skilled people. Of course, the existence of such tools will
create security holes, also -- something that can dig down into the guts of
a disk this way would also bypass copy-protection or use-restriction, and
make the illicit recovery of data thought to be erased possible. I think we
will have to accept such risks to gain the capability to recover
irreplaceable data or work.

Will Martin
USArmy Materiel Command Automated Logistics Mgmt Systems Activity

UUCP/USENET: seismo!brl-smoke!wmartin  or  ARPA/MILNET: wmartin@almsa-1.ARPA

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Interpreting Satellite Pictures
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:lindsay%cheviot.newcastle.ac.uk@Cs.Ucl.AC.UK">
lindsay%cheviot.newcastle.ac.uk@Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Wed, 7 May 86 10:12:02 gmt
</i><PRE>

Sir - "We have never had to interpret this kind of satellite picture
before...... we may have got it wrong" (U.S. Government scientist, in the
Guardian Letters, Sat. 3rd May 1986)

(Could this be relevant to SDI?)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
       Word-processing damages expression
</A>
</H3>
<address>
          Niall Mansfield 
&lt;<A HREF="mailto:MANSFIELD%DHDEMBL5.BITNET@WISCVM.WISC.EDU">
MANSFIELD%DHDEMBL5.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
Tue, 06 May 86 13:14:59
</i><PRE>

In <A HREF="/Risks/2.48.html">RISKS-2.48</A>, Bruce A. Sesnovich asked whether word processing and
electronic mail are helping to proliferate bad writing.  Surely, YES! The
following is a list of the more interesting spellings noticed on the net,
excluding what I thought were obviously typos.

   [I have used the words on Bruce's list to write a nonsense paragraph:

    I beleive Britian is definately not compatable reguarding cleen
    explainations.  I was woundering if it is truely nessesary to let lose a
    concious warrantee which is to periferal too guarentee a miscellaney of
    usefull ideas.  The kernal idea is a distructive facination for
    publically loosing ones bargins.  (No Deniall)?  

    By the way, I added the hyphen in the SUBJECT: line, to remove one of
    its several ambiguities...  PGN]

</PRE>
<HR><H3><A NAME="subj8.2">
Re: Word-processing damages expression
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Wed 7 May 86 10:33:54-PDT
</i><PRE>
To: RISKS@SRI-CSL
Cc: MANSFIELD%DHDEMBL5.BITNET@WISCVM.WISC.EDU

One way of judging RISKS contributions is by how sloppy the spelling is.
One might assume that a miserable speller would be a sloppy thinker.
However, there is grave danger therein -- as some of our most intuitive and
forward-thinking (right-brained) folks are miserable spellers.  As someone
who has always been a good speller, a good grammarian, and so on, I resist
an instinctive suspicion of miserable spellers, mantaining the patience to
dig beneath the surface to seek worthwhile ideas lurking.  But please try
harder to make my task easier -- by writing more coherently and spelling
halfway decently.

Peter

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Proofreading vs. computer-based spelling checks
</A>
</H3>
<address>
Dave Platt 
&lt;<A HREF="mailto:Dave-Platt%LADC@HI-MULTICS.ARPA">
Dave-Platt%LADC@HI-MULTICS.ARPA
</A>&gt;
</address>
<i>
Tue, 06 May 86 13:10 PST
</i><PRE>

There has been some discussion in the SF-Lovers digest of late about this
basic subject... people have been submitting mention of their "favorite
typos".  Several people have noted that some recent books have been coming
out with some glaring errors:  words that are correctly spelled, but are
entirely wrong for the context in which they appear.  Frequently, these
words are either (a) similar in sound to the word that "should have" been
there, or (b) can be generated from the correct word via a simple
permutation of letters, addition or deletion of a letter, etc.

It appears that some publishers are accepting manuscripts in machine-
readable form (disk or download), running them through a spelling checker,
and then printing them without actually having them proofread by a
reasonably literate reviewer.  I don't know the details... perhaps they have
completely eliminated the author's galley copies, or perhaps some authors
just aren't taking the time to proofread the galleys (or having someone
other than themselves do the proofread to catch errors of this sort).

I seem to recall a passage in "Imperial Earth", by Arthur C. Clarke,
concerning the pitfalls of cybernetic voice-to-type memowriters about 150
years in the future.  He wrote that everybody who uses (will use?) such
systems was careful to proofread the output of the voice-recognition
modules, as some "hilarious" malaprops had occurred during the early years
of these systems' availability.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.48.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.50.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-105</DOCNO>
<DOCOLDNO>IA012-000123-B019-89</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.50.html 128.240.150.127 19970217002823 text/html 18845
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:26:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 50</TITLE>
<LINK REL="Prev" HREF="/Risks/2.49.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.51.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 50</H1>
<H2> Thursday, 8 May 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Refocus the discussion, please! 
</A>
<DD>
<A HREF="#subj1.1">
Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  [Response.] Also, Delta rocket shutdown 
</A>
<DD>
<A HREF="#subj2.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Large systems failures &amp; Computer assisted writing 
</A>
<DD>
<A HREF="#subj3.1">
Ady Wiernik
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  DESisting 
</A>
<DD>
<A HREF="#subj4.1">
dm
</A><br>
<A HREF="#subj4.2">
 William Brown II
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Failure to Backup Data 
</A>
<DD>
<A HREF="#subj5.1">
Greg Brewster
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Refocus the discussion, please!
</A>
</H3>
<address>

&lt;<A HREF="mailto:estell@nwc-143b">
estell@nwc-143b
</A>&gt;
</address>
<i>
8 May 86 12:44:00 PST
</i><PRE>
To: "risks" &lt;risks@sri-csl.arpa&gt;

I want to discourage RISKS contributors from discussing at length how Capt. 
Midnight jammed the HBO signal - UNLESS there is reason to suspect that 
(mis)use of computers was a contributing factor.  Similarly, I want to dis-
courage the continued discussion of the Challenger disaster, unless there 
is reason to suspect that computer error - or human error of omission 
because of reliance on computers - contributed materially to the failure.

Up to a point, these discussions are relevant; they demonstrate that we can
not trust our lives naively to fully automated systems.  SDI, BART, FAA,
NYSE, etc. must be aware of that.  As computer professionals, we have the
duty of admitting our own humanity, and the frailty of our creations.
Otherwise, the sophisticated technology can fool the public too easily.

Instead, I would encourage RISKS contributors to pursue topics like data
encryption, which appeared recently [RISKS 2.49]; and to wrestle with the
question raised by Dave Weiss in that same issue, viz. CAN Star Wars ever
be made to work?  Kept in technical focus, this question could lead to
research and application of genuine benefit.

It is very easy for us, the readers and contributors, to rely on the moder-
ator to filter our contributions.  But I think it unfair to put him in the
position of sorting lots of interesting items of questionable relevance.
To the extent that these topics (including the ones that interst me) should
be pursued, perhaps that should occur in another electronic forum.  Comment?

Bob 

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Refocus the discussion, please?  Also, Delta rocket shutdown.
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Thu 8 May 86 20:02:32-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Bob, Thanks.  Contributor self-discipine is greatly appreciated.  However,
when in doubt about a contribution, I have a bias toward the holistic view
-- we are using computers to control physical environments, and relying on
ordinary mortals to do it.  RISKS exists because of the computers and
communications.  But we must not forget the global nature of the problems.

Captain Midnight reminds us again of a type of communication vulnerability
that is vastly more widespread than many of our readers suspect.  The
Challenger disaster (28 Jan) is only the tip of an iceberg, although RISKS
has not had much on it lately -- or on the Titan 34D (18 Apr) or the Delta
rocket (3 May).  (We hope that the Atlas-Centaur fares better on 22 May, in
which case it might get dubbed the At-Last-Centaur!  Fortunately, it is
NASA's most reliable, with 43 successful launches dating back to September
1977.)

The type of issue that I raised after the Challenger disaster regarding the
possibility of accidental or malicious triggering of self-destruct
mechanisms in general recurs in a slightly different form in the Titan 34D
failure, in which the rocket's main engine mysteriously shut itself down 71
seconds into the flight -- with no evidence of why! (Left without guidance
at 1400 mph, it had to be destroyed.)  The flight appeared normal up to that
time, including the jettisoning of the first set of solid rockets just after
one minute out.  Bill Russell, the Delta manager, was quoted thus: "It's a
very sharp shutdown, almost as though it were a commanded shutdown."  Could
this have been an accidentally generated internal shutdown signal (software
bug or comm interference)?  (There was no evidence of a transmitted
shutdown, so it is was very unlikely that it was maliciously generated.)
Before you answer, recall the local CB interference problem on automobile
microprocessors, the microwave side-effects on pacemakers and other devices,
RF interference on computer buses (an older problem), the alleged Sheffield
communication interference problem, etc...

Peter

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Large systems failures &amp; Computer assisted writing.
</A>
</H3>
<address>
Ady Wiernik
&lt;<A HREF="mailto:wiernik@nyu-acf8.arpa ">
wiernik@nyu-acf8.arpa 
</A>&gt;
</address>
<i>
Thu, 8 May 86 16:36:07 edt
</i><PRE>

I hope that I'm not contributing to much to the (growing) link between the
risks forum and net.sf-lovers; However, please let me add my two-cent worth
of comments:

1. In his article, Dave Benson &lt;benson%wsu.csnet@CSNET-RELAY.ARPA&gt;
   asked:

&gt; From: Dave Benson &lt;benson%wsu.csnet@CSNET-RELAY.ARPA&gt;
&gt; Subject: Normal Accidents and battle software
&gt;
&gt; &gt;According to
&gt; &gt;
&gt; &gt;	Charles Perrow
&gt; &gt;	Normal Accidents: Living with High-Risk Technologies
&gt; &gt;	Basic Books, New York, 1984
&gt; &gt;
&gt; &gt;we should expect to see large-scale accidents such as the loss of the
&gt; &gt;space shuttle Challenger.  Perrow's thesis, I take it, is that the
&gt; &gt;complexity of current technology makes accidents a 'normal' aspect
&gt; &gt;of the products of these technologies.
&gt; &gt;
&gt; &gt;We may view space shuttles launches, nuclear reactors, power grids,
&gt; &gt;transportation systems, and much real-time control software as lacking
&gt; &gt;homeostatis, "give", forgiveness.  Perhaps some of these technologies
&gt; &gt;will forever remain "brittle".
&gt; &gt;
&gt; &gt;Questions: Does anybody have a good way to characterize this brittleness?
&gt; &gt;To what extent is existing battle software "brittle"?

The question was beautifully answered in a science-fiction book named "Dome"
(I don't remember the Author's name).  In this book, a large fast-breeding
reactor was built in Pittsburgh, and on the day before the ceremonial
opening, it had a meltdown-like accident as result of malfunction in the
control computers caused by human errors. The story contained many other
things, but the interesting point (at least to readers of this forum) is
that in the story a young mathematician had predicted before the reactor
accident that such an accident would happen, (within a predicted time from
the start of operations), based on calculations related to the complexity of
the nuclear power-plant and to the laws of probability theory.  His opinion
was suppressed by the power-company officials (he used to work there).

The "brittleness" is related to the amount of interdependencies between the
various subsystems of the power-plant and the chance of failure of each sub
subsystems. This argument is similar to the argument made in this forum
about the operation of SDI.

2.  In another article, Dave Platt &lt;Dave-Platt%LADC@HI-MULTICS.ARPA&gt;
    (why are there so many Dave's on this forum? Is HAL9000
    responsible? :-) states:

&gt; Date: Tue, 06 May 86 13:10 PST
&gt; From: Dave Platt &lt;Dave-Platt%LADC@HI-MULTICS.ARPA&gt;
&gt; To: Risks@SRI-CSL.ARPA
&gt; Subject: Proofreading vs. computer-based spelling checks
&gt; 
&gt;        [Edited out - related to typos in current SF literature]
&gt; 
&gt; I seem to recall a passage in "Imperial Earth", by Arthur C. Clarke,
&gt; concerning the pitfalls of cybernetic voice-to-type memowriters about 150
&gt; years in the future.  He wrote that everybody who uses (will use?) such
&gt; systems was careful to proofread the output of the voice-recognition
&gt; modules, as some "hilarious" malaprops had occurred during the early years
&gt; of these systems' availability.

A similar gadget is used in the second book of Issac Asimov's Foundation
trilogy (Foundation and Empire). In this book, the differentiation between
words with similar pronunciation was done using the accenting of the word,
and even then the machine has to be corrected sometimes.

							Ady Wiernik.
In two weeks: ady@taurus.BITNET or: ady%taurus.BITNET%wiscvm.ARPA

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 DESisting
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 08 May 86 14:07:35 EDT (Thu)
From: dm@BBN-VAX.ARPA

There was an article in Science about this several months ago (perhaps it
was just in the proposal stage then, and now is fact, or maybe it was a slow
news day at the Times...).

Since the volume of data transmitted using DES is so large, and the
information protected by it is so valuable (e.g., HBO audio tracks...,
Department of Agriculture Hog reports, electronic funds transfers between
Federal Reserve Banks...), NSA now feels that it is worthwhile for someone
to spend, e.g., $10 billion to build a DES-breaker, because the potential
payoff will be so great.  For that reason, they intend to decertify DES by 
1990.

To replace DES, NSA will offer their own little encryption boxes, with
secret encryption algorithms, and possibly protected so that snooping will
destroy the evidence of the encryption algorithm.  They will offer several
different kinds of encryption boxes, using several different algorithms, so
that there won't be so much reliance on a single algorithm.

What about keys?  Well, in decreasing order of security (says NSA,
disingenuously), you can buy them from NSA, I think you can buy instructions
on how to make up your own keys from NSA, or you can make up your own.
Buying them from NSA is more secure because NSA knows the pitfalls of the
algorithms, knows the general pitfalls of key generation, etc.  Of course,
if you buy the keys from NSA, maybe NSA keeps a copy of the keys, and maybe
they'll use their copy to keep tabs on what you're encrypting...

</PRE>
<HR><H3><A NAME="subj4.2">
DESisting (<A HREF="/Risks/2.49.html">RISKS-2.49</A>)
</A>
</H3>
<address>
Wm Brown III 
&lt;<A HREF="mailto:Brown@GODZILLA.SCH.Symbolics.COM">
Brown@GODZILLA.SCH.Symbolics.COM
</A>&gt;
</address>
<i>
Thu, 8 May 86 13:35 PDT
</i><PRE>
To: RISKS FORUM &lt;RISKS@SRI-CSL.ARPA&gt;

    RISKS-LIST: RISKS-FORUM Digest,  Tuesday, 6 May 1986  Volume 2 : Issue 49
    From: jon@uw-june.arpa (Jon Jacky)
    Subject: NSA planning new data encryption scheme - they'll keep the keys

My own knowledge of cryptology is limited and mostly theoretical, however there
are some additional bits of information available in public domain literature
which lead me to draw slightly different conclusions from this news item.

    The following excerpts are from a New York Times story "Computer code shift
    expected - eavesdropping fear indicated," by David E. Sanger, April 15,
    1986, pps 29 and 32.  The story described plans by the National Security
    Agency (NSA) to replace the current Data Encryption Standard (DES) with a
    new system of its own design.  

    Details of the new system are still unclear.  But ... unlike the Data
    Encryption Standard, the new algorithms will not be publicly available.
    Instead, they will be buried in computer chips manufactured to NSA
    specifications, and encapsulated so that any effort to read the code with
    sophisticated equipment would destroy the chip.

It is a long-standing ground rule of the crypto biz that the adversary
will sooner or later obtain the basic algorithm used in any cypher system.
Traditionally, security is **always** based only on the knowledge of keys, 
not on keeping the theory of operation secret.  

A system which depends upon the secrecy of its algorithm is effectively a
single-key code.  Eventually it will be compromised and the other side
will be able to read all those tapes of encrypted messages which they have
been saving.  Unless everything ever sent over the system has gone stale by
that time, this is generally an unacceptably large loss.  Not the way to 
design a system for long-term use.

By the time such a system is in general use, there will be many thousands of
devices in circulation and hundreds of people who know how it works.  Sooner
or later, the guys in black hats will get hold of one or the other and pry the
top off to find out what's inside.  It may be possible to make the packages 
tamper-resistant, but tamper-PROOF is a big order (ask the makers of Tylenol).

    ... By some accounts, under the new system the NSA would distribute the
    keys --  probably limiting them to companies in the United States. ..."

Many recent systems use keys consisting of very large numbers chosen from a
set which is too large to try exhaustively (100 digit primes, cubes, etc.).
This category includes most of the "Public Key" cryptosystems (in which the
encryption and decryption keys are different.)  It seems very possible that 
NSA intends to create a subset (still very large) of some such class and then 
distribute devices with these individual keys built into them.  Disassembling
such a chip would compromise only one possible key from a large universe, and
few if any humans can remember many such keys, eliminating that source of risk.

One of the fringe benefits (from NSA's viewpoint) is that they would know the
entire universe of assigned keys.  An outsider would have to try all of the
theoretical possibilities, however NSA could exhaustively try every one of
a few millions relatively quickly.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re:  Failure to Backup Data
</A>
</H3>
<address>
Greg Brewster
&lt;<A HREF="mailto:brewster@nacho.wisc.edu ">
brewster@nacho.wisc.edu 
</A>&gt;
</address>
<i>
Thu, 8 May 86 11:25:28 CDT
</i><PRE>

I must agree that the importance of regular backup of data on 
microcomputers is very much underemphasized to many nontechnical 
users.  However, in cases where individuals are solely responsible for 
particular data files (as in the example of a scholar using a 
microcomputer to write a book), I don't believe that incremental backups 
are prohibitively difficult.

As Jim Coombs correctly states in <A HREF="/Risks/2.48.html">RISKS-2.48</A>
&gt; Since a complete backup of a 10
&gt; megabyte hard disk on an IBM XT can take a half-hour, I am sure that backing
&gt; up a 40 megabyte hard disk on a workstation will require more time (and
&gt; diskettes) than the majority of our scholars will invest.  

However, there is absolutely no need for any single scholar to be concerned
with a complete epoch dump of a 40 megabyte hard disk.  The data files for
most books will fit on one or two floppy disks.  I believe that, if the
dangers of data loss were emphasized enough, any writer would be happy to 
copy each day ONLY the files s/he changed on that day.  If the microcomputer
has a reliable clock and files are marked with modification times, then any 
experienced programmer could write a simple command file to back up all 
the files changed during the time the current user has been logged in
automatically.

This is a case where the risk of data loss can be decomposed into a
risk of loss of particular data for each system user.  I believe a 
reasonable approach then is to require each user to deal with his/her
'individual risk' as s/he wishes.  However, the magnitude of this risk 
of data loss must be emphasized to inexperienced users. 


Greg Brewster				brewster@nacho.wisc.edu  (ARPA)
University of Wisconsin - Madison	..ihnp4!uwvax!brewster	 (UUCP)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.49.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.51.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-106</DOCNO>
<DOCOLDNO>IA012-000123-B019-120</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.51.html 128.240.150.127 19970217002847 text/html 14012
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:27:13 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 51</TITLE>
<LINK REL="Prev" HREF="/Risks/2.50.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.52.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 51</H1>
<H2> Sunday, 11 May 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Reliability limits 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  NSA assigning encryption keys 
</A>
<DD>
<A HREF="#subj2.1">
Jay Elinsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  HBO pirate 
</A>
<DD>
<A HREF="#subj3.1">
Lauren Weinstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Failure to Backup Data, by James H. Coombs 
</A>
<DD>
<A HREF="#subj4.1">
Roy Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Admissibility of legal evidence from computers 
</A>
<DD>
<A HREF="#subj5.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Electronic document media 
</A>
<DD>
<A HREF="#subj6.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Word processing and bad writing 
</A>
<DD>
<A HREF="#subj7.1">
many messages received
</A><br>
<A HREF="#subj7.2">
 none included
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Reliability limits
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:brian%cheviot.newcastle.ac.uk@Cs.Ucl.AC.UK">
brian%cheviot.newcastle.ac.uk@Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Fri, 9 May 86 10:28:52 gmt
</i><PRE>

    I have for a number of years held, and expounded, the opinion that:
"If one automates a complex manual system, which is being carried out 
reasonably competently, then the very best that one can hope to achieve
is fewer but BIGGER errors".

    To give a couple of low-key illustrations: an automated payroll system can 
normally be expected to get virtually all of its calculations exactly correct -
but have you ever heard of a manual payroll system producing a paycheck
for $999,999.99 or for $0.00? When a newspaper goes over to computerized 
type-setting one normally sees a considerable drop in the number of typos, but 
the sudden appearance of occasional major errors - e.g. instructions to the 
formatter in capitals in the middle of a paragraph, whole sections in 
completely the wrong font, etc.

    The thinking behind my statement is that, compared to computer-based
systems, humans usually have a great ability to recognise an unusual
situation, and to use their general knowledge of the world in assessing its
correctness, and its possible consequences.

    I now no longer have any idea whether the statement is one that I have
plagiarized from someone else, and often find that people find it illuminating
as well as believable, and that it is a good way of injecting a note of caution
into the more naive and over-optimistic discussions that often take place
concerning possible new computer-based systems.

    I would be most interested to see how the RISKS forum reacts to it -
always assuming that something along this lines has not already been the
subject of a debate which took place before I became a subscriber.

Brian Randell - Computing Laboratory, University of Newcastle upon Tyne

  ARPA  : brian%cheviot.newcastle@ucl-cs.arpa
  UUCP  : &lt;UK&gt;!ukc!cheviot!brian

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
NSA assigning encryption keys
</A>
</H3>
<address>
&lt;<A HREF="mailto:ELINSKY@IBM.COM">
ELINSKY@IBM.COM
</A>&gt;
</address>
<i>
9 May 86 10:55:02 EDT
</i><PRE>

In light of all the recent spy cases, if the NSA keeps records of the keys
it has assigned to users, there's the risk that someone with access to them
might sell them "for the right price".  The keys would be worth so much that
a would-be intruder could offer an irresistibly high price to the right
individual, and still come out ahead.
                                       Jay Elinsky, IBM T.J. Watson Research

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
HBO pirate
</A>
</H3>
<address>
Lauren Weinstein
&lt;<A HREF="mailto:vortex!lauren@rand-unix.ARPA ">
vortex!lauren@rand-unix.ARPA 
</A>&gt;
</address>
<i>
Thu, 8-May-86 11:00:05 PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Let me preface this by mentioning that my consulting includes work with 
the company that uplinks WTBS to the bird, and that I have some
experience in the details of satellite uplink technology.

Just briefly:

The odds are very high that the HBO pirate was at a commercial uplink
facility.  A variety of technical considerations (which I won't go into
here) make it very unlikely that a terrestrial microwave path was involved.
The signal quality put out by the pirate was actually quite good.  He had to
run 10db more power than the HBO uplink to capture, which is a fair amount
of juice.  This was probably made possible by the fact that most uplink
operators have tended to run much less power than they have at hand on site
since new transponders are very sensitive.  I think you can bet HBO is
running full power on their uplinks now! The character gen used by the
pirate was clearly of a standard commercial type that would be located at
virtually any site with uplink facilities.  Also, it should be noted that
when the pirate's "in the clear" signal captured the scrambled HBO uplink
signal, the far-end decoders noted the loss of scrambling and switched back
into "normal" video passthru mode with scrambling off.  It would be trivial
for the pirate to disable any ID on the colorbars by throwing one switch.
In fact, many uplinks never use such IDs at all.

Actions being taken to catch the pirate have supposedly included checking
the logs of many licensed uplink facilities to find out who was on duty at
the suspect time.  In fact, there are already rumors that the pirate has
been caught and fired by his company, but this has not been confirmed.  If
he (or she) is still unknown, however, the most likely way they'll be caught
is if someone starts bragging.

--Lauren--

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Failure to Backup Data, by James H. Coombs
</A>
</H3>
<address>
Roy Smith
&lt;<A HREF="mailto:allegra!phri!roy@seismo.CSS.GOV ">
allegra!phri!roy@seismo.CSS.GOV 
</A>&gt;
</address>
<i>
Thu, 8 May 86 17:26:01 edt
</i><PRE>

	One thing not mentioned in James's article is what happens when you
get a new system which has different backup media than the last one?  In
our case, that meant switching from 800 to 1600 bpi tape a couple of years
ago.  We no longer have a drive that can read our old 800 bpi tapes, so
we've got all these wonderful archive tapes that we can't do much with.

	Of course, there are media-copy services.  They may not be cheap,
but for the occasional needed file from antiquity, just about anybody can
do a raw tape to tape copy for you.  But what do you do when your backup
media is a 5-1/4" floppy in wombat-DOS verson 6.4 format?  Where are you
going to get that transfered onto something you can read?

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Admissibility of legal evidence from computers
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Sat, 10 May 86 13:24:17 edt
</i><PRE>

In one of my previous incarnations the taxpayers paid me to think small.
Specifically, to implement microform (microfilm, microfiche, COM) where-
ever it was cost effective.  Among other things, we converted about two 
million personnel records from paper to microfiche.  Did lots of good things
besides saving money.  But, there were certain practical problems... 

Personnel records are frequently placed into evidence at court proceedings.
With 2,000,000 or so records, each representing a real live (or formerly 
live) person, several dozen records were in court at any given time.  Not 
to speak of class action suits.  

We had researched laws, federal regs, etc.; gotten legal opinions, whatever. 
There was no question in *anyone's* mind that the records were legal, that 
the microfiche WAS the record, and that it WAS admissable in any federal 
court, and in most other courts.  

Trouble was, it wasn't readable.  Plaintiffs and lawyers do not come equipped
with 24X eyesight.  Judges and jurors don't either.  Ever try to annotate a
microfiche?  Underline a telling phrase - highlight a key date?  

We had to set up a fairly expensive system JUST TO HANDLE COURT CASES.  We 
had to go back to paper (copies for all concerned) in every court case.
Worse yet, we had to prove the heredity, ancestry, and legitimacy of the 
paper copies. 

Now, a word to those keeping records on magnetic media, or optical disk, or
holographic crystals... Better have a printer handy!


---------------------------------------------------------------------------

Date: Sat, 10 May 86 14:09:56 edt
From: mikemcl@nrl-csr (Mike McLaughlin)
To: risks@sri-csl.ARPA
Subject: Electronic document media

Risks 2.48 contains several items related to electronic document creation and
transmission.  James Coombs worries about loss of data and loss of tenure due
to authors being unaware of some of the discipline necessary for preserving 
electronic drafts.  Bruce Sesnovich and "PGN" are concerned with the poor 
quality of submissions to Risks, while I mutter about distinctions between
mistakes and lies.  

I agree entirely with Coombs, but take some exception to Sesnovich and PGN. 

1.  Editors and proofreaders are not the same - or should not be.  The
editor reads an author's draft, and assists the author to clarify it, or to
achieve some desired end (i.e., making it fit the available space).  The
proofreader checks the edited draft, ensures that it matches some
appropriate style guide, and ensures that the "galley" faithfully reflects
whatever the author and the editor have agreed upon.  Actually, the old
cycle used to be Author -&gt; Editor -&gt; Printer/Typist -&gt; Proofreader -&gt;
Pressman/Copier.  There were a lot of checks, and a lot of delays.  The end
product was quality work... as long as timeliness did not matter.

2.  Micros, word-processors, e-mail, bulletin boards and electronic forums 
have abridged the process.  Unless PGN or Captain Midnight interpose themselves
in the process, the readers of Risks will see exactly what I say, regardless
of what I mean.  Right out of my head and into the keyboard.  The reader gets
my half of an extemporaneous conversation.  That is both the charm and the 
risk of e-mail and e-forums.  

3.  I still have the choice of composing off-line, getting peer review, cor-
recting my work, up-loading it, then proofing the up-load (best done by some-
one else), and finally transmitting it to PGN.  I choose not to do so (but
might choose _to_ do so on some other topic or some other day).   

In short, I assess the competing demands of spontaneity and perfection, and 
then act accordingly.  My desktop micro, e-mail, and PGN have given me that
option.  When I started writing, there was no choice.  

Bruce, if the computer has done anything harmful to communication, that harm
lies in the penchant for excessive iteration of repetitious revisions that
squeeze all the juice out of some *person's* thought or opinion until it has
no more intellectual appeal than a spare-parts listing. 
	- Mike McLaughlin &lt;mikemcl@nrl-csr&gt;

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.50.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.52.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-107</DOCNO>
<DOCOLDNO>IA012-000123-B019-139</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.52.html 128.240.150.127 19970217002859 text/html 11771
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:27:29 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 52</TITLE>
<LINK REL="Prev" HREF="/Risks/2.51.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.53.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 52</H1>
<H2> Wednesday, 14 May 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Launch failures 
</A>
<DD>
<A HREF="#subj1.1">
Phil R. Karn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Brittleness of large systems 
</A>
<DD>
<A HREF="#subj2.1">
Dave Benson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  HBO 
</A>
<DD>
<A HREF="#subj3.1">
Scott Dorsey
</A><br>
<A HREF="#subj3.2">
 Dave Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Word processing -- reroute [reroot?] the discussion 
</A>
<DD>
<A HREF="#subj4.1">
Chuq Von Rospach
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Launch failures
</A>
</H3>
<address>
Phil R. Karn
&lt;<A HREF="mailto:karn@petrus.bellcore.com ">
karn@petrus.bellcore.com 
</A>&gt;
</address>
<i>
Mon, 12 May 86 03:46:15 edt
</i><PRE>
ReSent-To: RISKS@SRI-CSL.ARPA

There are a couple of minor errors in your mod.risks article. Delta, not
Atlas-Centaur, had the streak of 43 successful launches since 1977,
and it was Delta-178, not the Titan 34D, whose main engine shut down 71
seconds into flight.
            [Blame AP for that one, not me.  Never trust what you read in 
             the papers (or anywhere else, apparently)!  THANKS.  PGN]

I would heavily discount the possibility of a range safety signal
causing the failure of Delta-178. There are only two commands available
to the range safety officer, ARM and FIRE. The latter causes an engine
shutdown alright, but immediately follows it by the detonation of the
destruct explosives. The fact that the range safety system worked perfectly
20 seconds after the shutdown indicates that an unauthorized signal is
unlikely to have been the cause of the shutdown.  Besides, the media
has been reporting that the investigation has revealed strong evidence
from telemetry of a short circuit in the engine control circuit.

Phil
        [Ah, yes, but (a) a short circuit could easily trigger the
         shutdown command, and (b) strong evidence could also be wrong.

         Well, just for the record, I might as well mention here the misfire
         on 25 April (not reported until 9 May) of the Nike Orion, which had
         flown successfully 120 consecutive times -- and that was its first
         failure.  The burned-out Nike first stage failed to separate 
         before the second stage Orion ignited.  Murphy strikes again,
         but in spades over recent months.  PGN] 

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
brittleness of large systems
</A>
</H3>
<address>
Dave Benson 
&lt;<A HREF="mailto:benson%wsu.csnet@CSNET-RELAY.ARPA">
benson%wsu.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>

</i><PRE>

Profoundly, utterly and completely disagree that probability theory can be
used to characterize the brittleness of large systems.  Using probability
theory and mathematical statistics to assess the likelyhood of failure
requires experience, enough experience to know the frequency of failure of
parts, the frequency of failure of the interaction of parts, etc.

The one big attempt to do this was the Rasmussen report, WASH-(I don't
remember the number think it was 1400), which attempted to use fault-tree
analysis to predict the failure frequency of large nuclear reactors such as
the Three Mile Island set.  The actual accident which occured at TMI was not
even considered in the Rasmussen report, thus assigned probabilty zero.  By
twisting the "causes" of the accident at TMI, one might find a probability
attached to this accident in the Rasmusen report.  Those attempting this
have come up with the TMI accident as have an     "incredible"    probability,
i.e., about one chance per billion reactor years.

Nancy Leveson at UC-Irvine is preparing a long survey [mentioned earlier in
RISKS] of work on safety related issues in software.  She was so kind as to
send me a pre-publication version of the report.  I highly recommend the
finished report to the RISKS readership.  It is good.  But as Prof.
Leveson's survey makes clear, there are no new, good ideas for
characterizing brittleness.

She does survey the use of fault-tree analysis for producing reliable
software.  This technique will certainly help improve the current state of
the art in real-time software design.  But the Rasmussen report--TMI
accident demonstrates that the real world is not (and, I believe, cannot) be
completely characterized by such techniques.

Let me remind you that according to Fox, "Software and its Development" the
Enroute Air Traffic Control System (a large but not very large real-time
C**3-tye system) has to date, only executed about .001 to .003 of all
possible paths throught the code.

So, we have not the data to use probability and statistics.  Therefore, the
brittleness of large real-time software (C**3*I military systems, SDI, major
transaction processing software, etc.) needs something else.  Here is a
thought about that "something else":
  The traditional means of studying the most important aspect of our world,
  people and their societies, has been the humanities.  Language, culture,
  history, writings, anthropology, classics, literature...  and do not forget
  theology, perhaps the subtlest of all.  Recently (that is in the last
  hundred years) these have been supplemented by psychology and the social
  sciences.  This has become possible only AFTER a very long tradition in the
  humanities.

My suggestion is to study software, large software, with the intellectual
tools of the humanists.  I would very much like to hear and read what
theologians have to say about software.    Comments?

       [By the way, the AP story of 12 May on Washington State's Hanford
        nuclear reservation says that in the mid- to late 1940s, thousands
        of residents may have received doses of radioactive iodine-131 at
        levels hundreds of times greater than levels considered safe today.
        Reactors and plutonioum factories "spewed the gas out at levels that
        today would qualify as a major nuclear accident, thousands of times
        greater than levels recorded at TMI."  The standards have since been
        changed, but at the time it was apparently considered routine.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
HBO (<A HREF="/Risks/2.49.html">RISKS-2.49</A>)
</A>
</H3>
<address>
Scott Dorsey 
&lt;<A HREF="mailto:kludge%gitpyr%gatech.csnet@CSNET-RELAY.ARPA">
kludge%gitpyr%gatech.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Sat, 10 May 86 11:36:55 edt
</i><PRE>

   I am told by a friend that the HBO studio-transmitter link is a landline.
Alhough this cannot be easily overridden with a mobile transmitter, cases
exist (like that at the Virginia Tech campus radio station) where the
landline was cut along its path and replaced with an originating source (in
this case, perhaps a VTR, in the Va Tech case, a casette player).

</PRE>
<HR><H3><A NAME="subj3.2">
HBO (<A HREF="/Risks/2.49.html">RISKS-2.49</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ihnp4!utzoo!lsuc!dave@ucbvax.berkeley.edu">
ihnp4!utzoo!lsuc!dave@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
Mon, 12 May 86 17:20:53 PDT
</i><PRE>

  To: utzoo!ihnp4!ucbvax!SRI-CSL.ARPA!RISKS
  Subject: Re: <A HREF="/Risks/2.49.html">RISKS-2.49</A>

  &gt;				Or do descramblers
  &gt;let "normal" signals through O.K. .... I don't think so.

Someone else mentioned on RISKS that they do. I would think they'd have to.
Our cable company periodically runs "free Pay-TV weekends" in the hope that
viewers will like what they see on Pay-TV and sign up after the free period
is over.  And paying customers certainly don't have to disconnect their
descramblers at such times.

Dave Sherman, Toronto
{ ihnp4!utzoo  pesnta  utcs  hcr  decvax!utcsri  } !lsuc!dave

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Word processing -- reroute [reroot?] the discussion
</A>
</H3>
<address>
Chuq Von Rospach
&lt;<A HREF="mailto:chuq%plaid@SUN.COM ">
chuq%plaid@SUN.COM 
</A>&gt;
</address>
<i>
Mon, 12 May 86 22:44:04 PDT
</i><PRE>
ReSent-To: RISKS@SRI-CSL.ARPA

Word processing and bad english are well within the domain of the group
mod.mag -- you may want to toss a pointer there, and if there is 
interest I might put a mailing list on my machine to tie it all up 
for the Arpaland.

As someone who publishes a magazine electronically, gets most of its
submissions electronically, and is generally an electronic network 
junkie (gotta get my compuserve fix...), they are right.  It isn't the
medium in itself, though, but its tendency to let you toss things off
without thinking first (such as this message).

chuq     [I should also put in a pointer to COMPUTERS&amp;SOCIETY as a 
         source of discussion on such topics, for example, a piece 
         by "Bruce_A._Hamilton.OsbuSouth"@Xerox.COM entitled
         ARE ONLINE SYSTEMS HELPING TO PROLIFERATE BAD CODING?  Note:
         I continue to reject a slew of responses on this topic as too
         marginally related to RISKS.  Thanks anyway.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.51.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.53.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-108</DOCNO>
<DOCOLDNO>IA012-000123-B019-160</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.53.html 128.240.150.127 19970217002910 text/html 12884
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:27:40 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 53</TITLE>
<LINK REL="Prev" HREF="/Risks/2.52.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.54.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 53</H1>
<H2> Friday, 16 May 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A late report on the Sheffield 
</A>
<DD>
<A HREF="#subj1.1">
AP [from Martin Minow]
</A><br>
<A HREF="#subj1.2">
 LATimes [Dave Platt]
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  News items [Lobsters; Eavesdropping] 
</A>
<DD>
<A HREF="#subj2.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  More Phone Bill Bugs... 
</A>
<DD>
<A HREF="#subj3.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Backup problems 
</A>
<DD>
<A HREF="#subj4.1">
Davidsen
</A><br>
<A HREF="#subj4.2">
 Roy Smith
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A late report on the Sheffield -- RFI
</A>
</H3>
<address>
Martin Minow, DECtalk Engineering ML3-1/U47 223-9922
&lt;<A HREF="mailto:minow%pauper.DEC@decwrl.DEC.COM  ">
minow%pauper.DEC@decwrl.DEC.COM  
</A>&gt;
</address>
<i>
16-May-1986 1241
</i><PRE>

  [PGN's SUMMARY LIST OF HORROR STORIES CONTAINS THIS ON THE SHEFFIELD:
  "Exocet missile not on expected-missile list, detected as friend" (SEN 8 3)
   [see Sheffield sinking, reported in New Scientist 97, p. 353, 2/10/83]; 
   Officially denied by British Minister of Defence Peter Blaker
   [New Scientist, vol 97, page 502, 24 Feb 83].  Rather, sinking abetted by
   defensive equipment being turned off to reduce communication interference?]

From the Boston Globe, May 16, 1986:

		Phone call jammed antimissile defenses

LONDON -- Electronic antimissile defenses on the British frigate Sheffield,
sunk in the 1982 Falklands conflict, were jammed during an Argentine attack
by a telephone call from the captain to naval headquarters, the Defense
Ministry said yesterday.  Twenty crewmen were killed when the Sheffield was
sunk May 4, 1982, by a French-made Exocet missile fired by an Argentine
plane.  A Defense Ministry spokesman, confirming a report in [the] London
Daily Mirror, said Commodore James Salt, the Sheffield's captain, was making
"an urgent operational call" to naval headquarters near London when the
missile hit.  "The electronic countermeasures equipment was affected by the
transmission.  Steps have been taken to avoid a repetition," the spokesman
said.  Commodore Salt now has a shore job as chief of staff to the fleet
commander-in-chief. (AP)

</PRE>
<HR><H3><A NAME="subj1.2">
 A late report on the Sheffield -- RFI
</A>
</H3>
<address>
&lt;<A HREF="mailto:<Dave-Platt%LADC@HI-MULTICS.ARPA> ">
&lt;Dave-Platt%LADC@HI-MULTICS.ARPA&gt; 
</A>&gt;
</address>
<i>
Fri, 16 May 86 17:13 PDT
</i><PRE>

[beginning of message duplicated the above] From Today's LA TIMES: [...]  

  The telephone system's transmitter was on the same frequency as the homing
  radar of the French-built Exocet missile fired at the Sheffield, and the
  transmission prevented the Sheffield's electronic countermeasures equipment
  from detecting the missile's radar and taking evasive action.

The article implies that this situation might have been avoided had the
Sheffield been equipped with an uplink into the British satellite
communication system; the article gives no details but I'd guess that such
an uplink would have used a transmitter which was (a) less powerful, (b)
more directional, or (c) on a completely different wavelength.

Does anyone have additional information about the equipment in question?
      [Dave Platt]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
News items [Lobsters; Eavesdropping]
</A>
</H3>
<address>
Alan Wexelblat 
&lt;<A HREF="mailto:wex@mcc.arpa">
wex@mcc.arpa
</A>&gt;
</address>
<i>
Thu, 15 May 86 14:11:13 CDT
</i><PRE>

Here are a couple of items from today's paper that may be of interest to
RISKS readers:

(The following item was discussed in RISKS when the story first broke.)

AWARD REVERSED IN WEATHER DEATH CASE

Boston(AP) - A federal appeals court Tuesday overturned a $1.25 million
award to the families of three lobstermen who died in a hurricane the
National Weather Service had failed to predict because of an unrepaired
buoy.

The 1st Circuit Court of Appeals said the weather service is protected from
awards like that made by U.S. District Judge Joseph Tauro because weather
forecasting is a discretionary function.  [...] Tauro found the government
liable in the [fishermen's] deaths because of its failure to repair a
weather buoy used to forecast conditions.

In the appellate court ruling, Judge Bailey Aldrich wrote, "The government
did not create the weather, it merely failed in the (lower) court's opinion
to render adequate performance.    "This was a discretionary undertaking."

Michael Latti, attorney for the families, said he would ask the U.S.
Supreme Court to review the Appeals Court decision.

He said the 1st Circuit Court found the government did not have to exercise
"ordinary reasonable care" when it undertakes a discretionary function such
as issuing weather forecasts.


HOUSE PANEL OKS LIMITS ON HIGH-TECH EAVESDROPPING
By Mary Thornton, Washington Post Service

After more than two years of study, a House subcommittee Wednesday
unanimously approved a bill that would make it illegal to eavesdrop on
electronic communications, including cellular telephone conversations,
electronic fund transfers, and computer messages and data transmissions.

The bill would also extend to such communications Fourth Amendment
protection against unreasonable search and seizure.

A report by the congressional Office of Technology Assessment last October
[...]included a survey of federal agencies, including six that said they
planned to intercept or monitor electronic mail as part of their
investigative work.

The bill would require a court-approved search warrant for law enforcement
agencies to obtain a computer message within six months of its generation
and a subpoena after that. [...]

Also, under the legislation law enforcement agencies would have to meet the
strict standards of the federal wiretap statute to eavesdrop on cellular
telephone conversations.

The bill contains several provisions to make it easier for federal law
enforcement agencies to obtain court-approved wiretaps.  It would expand
the categories of crimes for which a wiretap may be approved as well as the
number of officials in the Justice Department who can approve such a
request.

The bill also would make it a misdemeanor to use a satellite dish to
intercept subscription television signals, but only if the information is
then used commercially.


The bill is currently being called "The Electronic Communications Privacy
Act of 1986".  No HR number was given in the article.

--Alan Wexelblat
ARPA: WEX@MCC.ARPA
UUCP: {ihnp4, seismo, harvard, gatech, pyramid}!ut-sally!im4u!milano!wex

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
More Phone Bill Bugs...
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@ee.purdue.edu ">
davy@ee.purdue.edu 
</A>&gt;
</address>
<i>
Thu, 15 May 86 16:14:31 EST
</i><PRE>

To add to the ever-increasing list of screwed up phone billing software,
this is from the May 12 issue of Communications Week (selected excerpts):

    "GTE Sprint Communications failed to bill customers for millions
    of dollars worth of calls made between Feb. 21 and April 26 of
    this year, Communications Week has learned."

    ".... cost Sprint between $10 million and $20 million."
    
    "The errors were made through 10 of Sprint's 58 switches...."

    "Regular calls.... went undetected in those 10 switches...."

    ".... $1 billion in revenues a year, $20 million represents about
    2 percent of the company's annual revenue."

    "The errors apparently happened because programmers made billing
    software changes in some, but not all, of Sprint's switches.  The
    omissions have since been corrected."

Sometimes one wonders if we'll ever learn...  I wonder what happens now
to the poor slob who approved those software changes ("ooops.")...

--Dave Curry, Purdue University    [davy@ee.purdue.edu]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
backup problems
</A>
</H3>
<address>
&lt;<A HREF="mailto:davidsen%kbsvax.tcpip@ge-crd.arpa">
davidsen%kbsvax.tcpip@ge-crd.arpa
</A>&gt;
</address>
<i>
14 May 86 11:50 EST
</i><PRE>
To: risks@csl.sri.com

Getting people to do backup can be done by management (or whatever passes
for it in educational institutions). The trick is to convince people at
the gut level that there will be consequences if they don't backup.

One method might be to quietly pick people at random, and if their files
are not backed up, pull hardcopy of the work and revoke the user's rights
to use the computer. A really hardnosed management might just randomly
trash a disk now and then (after warning people that this would be done)
and letting the resulting cries of pain get the job done. There will
*ALWAYS* be those who are too stupid or stubborn to respond to any
education. You might as well either (a) get rid of them, or (b) if they
are really valuable in other ways, assign someone to back up their work.

At one (unnamed) site, management was encouraged to read their electronic
mail regularly by having top management send meeting notices and requests
for data to the middle management. Just one phone call from an irate top
manager asking why a meeting was missed usually did the trick. The middle
management started passing the concept on, and now Email is used instead
of paper for most messages.

</PRE>
<HR><H3><A NAME="subj4.2">
More on backup procedures (amusing ad)
</A>
</H3>
<address>
Roy Smith
&lt;<A HREF="mailto:allegra!phri!roy@seismo.CSS.GOV ">
allegra!phri!roy@seismo.CSS.GOV 
</A>&gt;
</address>
<i>
Thu, 15 May 86 21:10:48 edt
</i><PRE>
Organization: Public Health Research Institute, NYC, NY

	There have been several items in RISKS-DIGEST recently about the
dangers of not doing backups.  I've already made my contribution, but an
interesting ad from 3-M caught my eye.  As the ad says, "when it comes to
doing computer backup, any excuse will do" [i.e. for not doing it -- RHS].
See the June Sci. Am., page 21 for the rest.

	BTW, I have no connection with 3-M.  I just liked the ad.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-109</DOCNO>
<DOCOLDNO>IA012-000123-B019-177</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.54.html 128.240.150.127 19970217002922 text/html 12939
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:27:51 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 54</TITLE>
<LINK REL="Prev" HREF="/Risks/2.53.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.55.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 54</H1>
<H2> Sunday, 25 May 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Meteorites 
</A>
<DD>
<A HREF="#subj1.1">
Larry West
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Meteorites, Chernobyl, Technology, and RISKS 
</A>
<DD>
<A HREF="#subj2.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  London Stock Exchange Computer System Crash 
</A>
<DD>
<A HREF="#subj3.1">
Lindsay F. Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Backup 
</A>
<DD>
<A HREF="#subj4.1">
Fred Hapgood
</A><br>
<A HREF="#subj4.2">
 Bruce O'Neel
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Meteorites
</A>
</H3>
<address>
Larry West
&lt;<A HREF="mailto:west@nprdc.arpa ">
west@nprdc.arpa 
</A>&gt;
</address>
<i>
21 May 1986 2309-PDT (Wednesday)
</i><PRE>

An article on page 11 of the Wed 21 May New York Times raises an issue I
haven't quite seen raised here before.  It's only partly related to
automation, but that relation is a threatening one.

The article is titled ``Consequences Weighed of Meteorite Explosion'' and
reports on the semi-annual meeting of the American Geophysical Union in
Baltimore.  The article is by Walter Sullivan and is too well-written to
condense satisfactorily, but I'll try:

:::::

  Meteoric explosions on the scale of the 1908 event in Siberia (12 Megatons)
  are expected about once per century, and somewhat smaller (but still in the
  range of nuclear explosions) events should happen more frequently.
  
  Although the US, USSR and Europe could ``probably'' detect that the
  explosion was non-nuclear, and thus avoid an inappropriate reaction, this
  would be less true in, say, the Middle (Near) East or India &amp; Pakistan.
  ``Also, [specialists] said, the response of highly automated systems, such
  as the proposed Strategic Defense Initiative, could not be predicted.''
  
  Even without a military response, the after-effects could be devastating:
  filling the atmosphere with sun-blocking particles and curbing food
  production.  Currently, there is roughly a 70-day supply of food on hand in
  the world [which surprises me -- LW] but a very large meteor could reduce
  sunlight for two years.
  
  Further, the most energetic explosions will come from those meteors
  travelling the fastest (and sometimes coming from outside the solar system),
  and thus the most difficult to predict.
  
  ``The discussion took place at a session on natural hazards ...  Presiding
  was Dr. Joseph V. Smith of the University of Chicago, who has been calling
  for an Internation Decade for Hazard Reduction that would begin in 1990.
  That effort would be aimed at reducing loss of life, particularly from
  catastrophes that are on a very large scale but sufficiently rare to have
  been largely ignored.  The plan was first suggested in 1984 by Dr. Frank
  Press, now president of the National Academy of Sciences.''

  ``Dr. Smith .... also urged the initiation of an International Decade on
  Stockpiling for Survival, including development of new techniques for
  effective, economical storage of ... foods''

  Various methods of dealing with a meteor were mentioned, including nuking it
  and firmly pushing it aside.  The main problem is being prepared and being
  able to reach the meteor in time.

:::::

Hope this hasn't gone too far afield from the focus of this mailing list... 

Larry West				USA+619-452-6771
Institute for Cognitive Science		non-business hrs: 452-2256
UC San Diego (mailcode C-015)
La Jolla, CA  92093  USA
ARPA:	&lt;west@nprdc.ARPA&gt;	or	&lt;west@ucsd.ARPA&gt;
DOMAIN:	&lt;west@nprdc.mil&gt;	or	&lt;west@csl.ucsd.edu&gt;

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Meteorites, Davis-Besse, Chernobyl, Technology, and RISKS
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Sun 25 May 86 11:27:51-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Larry West wonders whether his Meteorite contribution has strayed too far
afield for RISKS.  I think not.  One of the biggest risks of using computers
in critical environments is that we tend to trust them blindly -- even if
the models on which the systems are based are incomplete.  In connection
with an article on the 46 US Senators who are seeking to cut back the SDI
budget, Senator William Proxmire is quoted in the Washington Post of Friday
23 May 1986:

           "Challenger and Chernobyl have stripped some 
            of the mystique away from technology."

Some of the blind trust naively placed in technology may lessen for a while
after such incidents as the Challenger (together with the other recent NASA
difficulties) and Chernobyl.  But it always seems to return fairly rapidly,
and the lessons are quickly forgotten -- by those who use, depend upon,
operate, administer, and regulate the technology.  Anticipating the events
that might follow the appearance of such a giant meteorite is vital [to
avoid administering last Meteor-Rites?].  (This possibility recalls the old
case of BMEWS at Thule "recognizing" the moon as an incoming missile.)

As another example of blind trust, the WashPost of Sat 24 May had an article
reassessing the Davis-Besse Nuclear Power Plant emergency shutdown last
June.  "[E]xperts say, Davis-Besse came as close to a meltdown as any U.S.
nuclear plant since the Three Mile Island accident of 1979.  Faced with a
loss of water to cool the reactor and the improbable breakdown of FOURTEEN
separate components, operators performed a rescue mission noted both for
skill and human foible:  They pushed wrong buttons, leaped down steep
stairs, wended their way through a maze of locked chambers and finally saved
the day last June 9 by muscling free the valves and plugging fuses into a
small, manually operated pump not designed for emergency use."  [Emphasis on
FOURTEEN is PGN's.]  The article goes on to describe prior power-company
foot dragging and bureaucratic wrangling, despite the lack of a backup pump
having been identified as an intolerable risk long beforehand.

The WashPost of Thursday, 22 May 1986 shed a little more light on what
happened at Chernobyl.  (In case you could not guess, I was in DC for the
week.)  Could an experiment have gone awry?  Human error and/or system error?

  The Soviet Union was conducting experiments to check systems at
  Chernobyl's fourth nuclear reactor when a sudden surge of power touched off
  the explosion last month, a Soviet official said ... Soviet officials have
  said that the explosion happened when heat output of the reactor suddenly
  went from 6 or 7 percent to 50 percent of the plant's capacity in 10 
  seconds.  The power had been reduced for a prolonged period in preparation
  for a routine shutdown...  "We planned to hold some experiments, research
  work, when the reactor was on this level," Sidorenko [deputy chairman of
  the State Committee for Nuclear Safety] said today [21 May].  "The
  accident took place at the stage of experimental research work."

Peter G. Neumann

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
London Stock Exchange Computer System Crash
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:lindsay%cheviot.newcastle.ac.uk@Cs.Ucl.AC.UK">
lindsay%cheviot.newcastle.ac.uk@Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Fri, 23 May 86 09:40:23 gmt
</i><PRE>

The other day I saw a headline that said the London Stock Exchange had
been disrupted by a system crash. There were no more details. Does anybody
know anything more??

Lindsay F. Marshall, Computing Lab., U of Newcastle upon Tyne, Tyne &amp; Wear, UK
  ARPA  : lindsay%cheviot.newcastle.ac.uk@ucl-cs.arpa
  JANET : lindsay@uk.ac.newcastle.cheviot
  UUCP  : &lt;UK&gt;!ukc!cheviot!lindsay

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Backup
</A>
</H3>
<address>
"Fred Hapgood" 
&lt;<A HREF="mailto:SIDNEY.G.HAPGOOD%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY.G.HAPGOOD%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat 17 May 86 08:32:13-EDT
</i><PRE>
To: risks%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU

	What is needed here is a service that will automatically come
into your computer at 4 a.m., or whenever, look around inside your hard
disk, make a record of the bytes that have changed since the previous
night's checkup, and download those to some off-site storage device.
Such a system would have the double advantage of being totally automatic
and of storing backups off-site, safe from the effects of user stupidity,
which is a much better reason for off-site backups than fire or burglary.
People worried about security can have the system encrypt everything
before the service is allowed in. 

   [The Get-Rite Backup Company provides an off-the-shelf program that you
    might want to try.  Unfortunately, they were the lowest bidder, and
    took a lot of shortcuts -- the most important of which is that nothing
    is ever actually saved.  Of course this never bothers you unless you need
    to retrieve something.  Unfortunately, the program was sabotaged by
    Get-Rite's competitor, Trojan-Horses-for-Stud (to whom "backup" has an
    entirely different meaning).  They lived up to their name, and managed
    to install a Trojan Horse that, upon first request by you to retrieve a
    file, simply deletes ALL of your on-line files and then disappears into 
    the woodwork.  I hear that they will also take large bribes if you want to
    wipe out other users' files on demand.  PGN]

</PRE>
<HR><H3><A NAME="subj4.2">
     Backup
</A>
</H3>
<address>
        Bruce O'Neel  
&lt;<A HREF="mailto:ZWBEO%VPFVM.BITNET@WISCVM.WISC.EDU">
ZWBEO%VPFVM.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
Sat, 17 May 86 12:51 EDT
</i><PRE>
To: Risks &lt;RISKS@SRI-CSL.ARPA&gt;

Re: Management monitoring of backups.

I have a feeling that in educational institutions where the choice is given
between hiring someone to do backups for people and "forcing" people to do
the backups themselves, hiring someone (undergrad student) will get the nod.

Just a small thought.

bruce (zwbeo@vpfvm.bitnet)

         [A THIRD choice usually wins: Do nothing at all until after
          you get wiped out.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-110</DOCNO>
<DOCOLDNO>IA012-000123-B019-206</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.55.html 128.240.150.127 19970217002945 text/html 19300
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:28:10 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 55</TITLE>
<LINK REL="Prev" HREF="/Risks/2.54.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.56.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 55</H1>
<H2> Wednesday, 28 May 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Culling through RISKS headers; SDI 
</A>
<DD>
<A HREF="#subj1.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Blind Faith in Technology, and Caspar Weinberger 
</A>
<DD>
<A HREF="#subj2.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks of doing software quality assurance too diligently       
</A>
<DD>
<A HREF="#subj3.1">
PGN from Chris Shaw and the Torrance Daily Breeze
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Collegiate jungle 
</A>
<DD>
<A HREF="#subj4.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Decease and Desist -- Death by Computer 
</A>
<DD>
<A HREF="#subj5.1">
Deborah L. Estrin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  The Death of the Gossamer Time Traveler 
</A>
<DD>
<A HREF="#subj6.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Computer Ethics 
</A>
<DD>
<A HREF="#subj7.1">
Bruce A. Sesnovich
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
SDI; Culling through RISKS headers [Message entirely edited]
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.DEC.COM ">
horning@src.DEC.COM 
</A>&gt;
</address>
<i>
Tue, 27 May 86 11:51:06 pdt
</i><PRE>
  
    [[Jim and several others called my attention to an article in the
      NYTimes of 27 May 86, page 9.  I have excerpted from the article, as
      follows.  PGN ]


          "Feasible Computer Control For Missile Shield Doubted"
              by Charles Mohr (Special to the New York Times)

  "An expert [Jim Horning] in computer programs who was asked to advise on
  research into defense against long-range nuclear missiles says he is
  skeptical that a reliable computer system to control such a defense can
  ever be devised."

The article quotes from a letter from Jim Horning to Douglas Waller (on the
staff of Senator William Proxmire):

  "To date no system of this complexity has performed as expected (or
  hoped) in its first full-scale operational test; no one has advanced
  any reason to expect that an S.D.I. would either.  A huge system that
  is intended to be used at most once, and cannot be realistically tested
  in advance of use, simply cannot be trusted."

The article also quotes a statement signed by 36 of the 61 experts who
attended a workshop on computing March 16-19 at Pacific Grove CA:

  "The effective defense from nuclear annihilation of the lives, homes and
  property of the American people, as embodied by the Strategic Defense
  Initiative (Star Wars), requires highly reliable computer systems of
  unprecedented complexity.  As experts in reliable computing, we strongly
  believe that a system meeting these requirements is technologically
  infeasible."

The article notes Dave Parnas' role in the ongoing discussions, and also

  "Lieut. Gen. James A. Abrahamson, the director of the missile defense
  organization, has said that computer programming was probably the most
  difficult technical problem faced by his group.  But he stresses an
  optimistic view that it can be solved and argues that Mr. Parnas has 
  applied "unrealistically high criteria"."

  Mr. Horning, who like Mr. Parnas has written computer programs for
  weapons systems, is supportive of Mr. Parnas, observing that "there has
  been a movement toward Parnas' position" among those knowledgeable about
  technology.

The article also quotes from Jim Horning's "trip report" to participate in a
meeting of the Strategic Defense Initiative Organization (see RISKS-1.2, 28
August 85).   END of PGN excerpting.]   

     [Wow, it is 9 months to the day since RISKS-1.2, and we've had 99
      issues (not counting the "pilot issue", RISKS-1.1, on 1 Aug 85).  
      I hope we are not overwhelming you, but I also hope we can keep 
      up the generally good quality of contributions.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Blind Faith in Technology, and Caspar Weinberger
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sun, 25 May 1986  17:45 EDT
</i><PRE>

On the blind faith in technology, it is interesting to note that, when
initial reports came in after the bombing of Libya that U.S. bombers had 
hit the French Embassy, Weinberger said, 

        "That's impossible.  They weren't ordered to do that."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Risks of doing software quality assurance too diligently
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Wed 28 May 86 21:02:44-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

From the Torrance Daily Breeze, 19 May 1986, page 1, courtesy of Chris Shaw:

              Death threats dog fired whistleblower
                (by James Hart, Aerospace writer)

  Finding a new job after getting fired can be hard enough, but Edward F.
  Wilson never expected the death threats.  Wilson, a computer software
  engineer fired narly a year ago from a small Hawthorne-based aerospace
  company, says he's paying the price for speaking out against government
  contracting abuses.  The threats -- anonymous, of course -- have come over
  the telephone twice in recent weeks at his Long Beach home...
  "Whistleblowing, I'm afraid, is not very popular," he said with a sigh.

  He said that soon after being asked ... to draw up software quality-assurance
  programs required by the government, he realized that Amex Systems officials
  were doing it strictly for show.  "They said to me on several occasions that
  they had no intention of implementing them," he said.  

The article goes on to document Wilson's memo to his employer, his being
fired for "being a troublemaker", his filing a wrongful discharge suit, the
ensuing criminal investigation currently underway on unnamed government
programs, various denials, etc.  Dina Rasor, director of the Project on
Military Procurement, a self-styled watchdog agency in Washington D.C. spoke
about the situation:

  "I've heard of whistleblowers being blackballed from the industry and of
  government whistleblowers put in 'do-nothing' jobs, but in five years of
  working with these people I've never had anyone receive a death threat.
  ...  What I've found is so unusual about Ed Wilson is that he made his
  complaints known to the company well before he was fired.  He hasn't
  brought all this up later as sour grapes."

  Wilson said he remains optimistic he will eventually find a job, but
  admits his "faith in the system is diminishing."  "I did what I thought
  was in the best interests of the country," he said.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Collegiate jungle
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Tue, 27 May 86 08:42:00 edt
</i><PRE>

Darwinian selection will solve the backup problem on campus.  Them that 
backs up will survive, them that don't, won't.

Permission is granted to delete "campus" and insert any other sphere of 
computer-supported activity presently known or yet to be discovered.

	Mike McLaughlin &lt;mikemcl@nrl-csr.arpa&gt;

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Decease and Desist -- Death by Computer
</A>
</H3>
<address>
Deborah L. Estrin
&lt;<A HREF="mailto:estrin%usc-cseb@usc-cse.usc.edu ">
estrin%usc-cseb@usc-cse.usc.edu 
</A>&gt;
</address>
<i>
Mon, 26 May 86 18:43:45 pdt
</i><PRE>
ReSent-To: RISKS@SRI-CSL.ARPA

An editorial appeared in yesterday's (Saturday's) LA Times.  It is written
by Forman Brown, on the subject of computer error.

Following are a few exerpts:  

  "I first became aware of my death last May when my checks began to bounce.
  Never having experienced bouncing checks before, and knowing that I had
  quite a respectable balance at the bank, I was both shocked and angry.  When
  I examined the returned checks and found, stamped over my signature on each
  of them, in red ink, "Deceased", I was mystified. Then, when one of the
  recipients of my checks, a utility company, demanded that I appear in
  person, cash in hand, plus $10 for their trouble--their trouble--I was
  shocked, angry and mystified. I wondered just how they expected us deceased
  to acquiesce."

Well, to paraphrase, Brown went to the bank, the series of tellers could not
believe such a thing had happened and said it was probably the computer's
fault and sent him home to write new checks and explanations--including one
to a friend who thought he was dead due to the "deceased" notice on the
bounced check.

Then the next month he found that his social security payment was not
credited to his account. On investigation he found that whatever troubled
the computers "had spread to those of the Social Security system as well."
This went on for a couple of months despite visits to Social Security.  Then
finally the bank agreed to credit the amount to his account until Social
Security started payment again--which they did several months later.

Brown thought the story was over until his physician contacted him recently
to say that Medicare had refused to accept his bill for services rendered
becuase the date of the service was six months later than the date of the
patient's decease...

He concludes by saying that if he were 20, all this might merely be
irritating, but since he is 85 the prospect of death is too near to be
treated lightly.
  
</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
The Death of the Gossamer Time Traveler
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Wed 28 May 86 22:08:47-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Dr. Paul MacCready has had some marvelous successes, including the first and
only human-powered flight across the English Channel in 1979 on his Gossamer
Condor.  His Time Traveler, a short-winged model of the prehistoric
Quetzalcoatlus northropi from 65 million years ago, had made something like
43 consecutive safe flights and starred in a film, "On the Wing",
replicating the original appearance and flying style of QN.  Weighing in at
44 pounds, it includes battery-operated motors, a computerized autopilot,
and ground-based radio controls.  Unfortunately, the bird chose the day of
its first public appearance, 17 May 86 at Andrews Air Force Base, to have
its head break off.  Computer archaeologists of the future will of course
try to ascertain whether the accident was due to human error in overtaxing
the creature, or to a computer program bug in the safety controls that might
have otherwise have prevented flight instability, or some other cause.  We
hope that the head crash can be repaired.  The construction cost, variously
reported as $500,000 and $700,000, was funded by the National Air and Space
Museum and the Johnson Wax Company.  [Maybe this was inspired by its more
modern precursor, the "one-SEATER WAX-WING".]

Your roving [raving or raven'?] reporter, PGN

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Computer Ethics
</A>
</H3>
<address>
&lt;<A HREF="mailto:rti-sel!dg_rtp!rtp41!dg_rama!bruces%mcnc.csnet@CSNET-RELAY.ARPA">
rti-sel!dg_rtp!rtp41!dg_rama!bruces%mcnc.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Tue, 27 May 86 13:36:39 edt
</i><PRE>

The following is a copy of a review I wrote for a recent newsletter of the
Boston chapter of Computer Professionals for Social Responsibility (CPSR).
Readers of RISKS may be interested, as well.

METAPHILOSOPHY is a British journal published three times yearly which is
dedicated to considerations about particular schools, fields, and methods of
philosophy.  The October 1985 issue, Computers &amp; Ethics (Volume No. 16, Issue
No. 4), is recommended reading [...].

This issue's articles attempt to define and delimit the scope of Computer
Ethics, and examine several emerging and current concerns within the field.

One current concern is responsibility for computer-based errors.  In his
article on the subject, John W. Snapper asks:  "...whether it is advisable to
...write the law so that a machine is held legally liable for harm." The author
invokes Aristotle's "Nichomachean Ethics" (!) in an analysis of how computers
make decisions, and what is meant by "decision" in this context.

On the same subject, William Bechtel goes one step further, considering the
possibility that computers could one day bear not only legal, but moral
responsibility for decision-making:  "When we have computer systems that ...can
be embedded in an environment and adapt their responses to that environment,
then it would seem that we have captured all those features of human beings
that we take into account when we hold them responsible."

Deborah G. Johnson discusses another concern:  ownership of computer programs.
In "Should Computer Programs Be Owned?," Ms. Johnson criticizes utilitarian
arguments for ownership, as well as arguments based upon Locke's labor theory
of property. The proper limits to extant legal protections, including
copyrights, patents, and trade secrecy laws, are called into question.

Other emerging concerns include the need to educate the public on the dangers
and abuses of computers, and the role of computers in education.  To this end,
Philip A. Pecorino and Walter Maner present a proposal for a college level
course in Computer Ethics, and Marvin J. Croy addresses the ethics of
computer-assisted instruction.

Dan Lloyd, in his provocative but highly speculative article, "Frankenstein's
Children," envisions a world where cognitive simulation AI succeeds in
producing machine consciousness, resulting in a possible ethical clash of the
rights of artificial minds with human values.

The introductory article, James H. Moor's "What is Computer Ethics," is an
ambitious attempt to define Computer Ethics, and to explain its importance.
According to Moor, the development and proliferation of computers can rightly
be termed "revolutionary":  "The revolutionary feature of computers is their
logical malleability.  Logical malleability assures the enormous application of
computer technology." Moor goes on to assert that the Computer Revolution, like
the Industrial Revolution, will transform "many of our human activities and
social institutions," and will "leave us with policy and conceptual vacuums
about how to use computer technology."

An important danger inherent in computers is what Moor calls "the invisibility
factor." In his own words:  "One may be quite knowledgeable about the inputs
and outputs of a computer and only dimly aware of the internal processing."
These hidden internal operations can be intentionally employed for unethical
purposes; what Moor calls "Invisible abuse,"  or can contain "Invisible
programming values":  value judgments of the programmer that reside, insidious
and unseen, in the program.

Finally, in the appendix, "Artificial Intelligence, Biology, and Intentional
States," editor Terrell Ward Bynum argues against the concept that "intentional
states" (i.e. belief, desire, expectation) are causally dependent upon
biochemistry, and thus cannot exist within a machine.

If you're at all like me, you probably find reading philosophy can be "tough
going," and METAPHILOSOPHY is no exception.  References to unfamiliar works,
and the use of unfamiliar terms occasionally necessitated my reading
passages several times before extracting any meaning from them.  The topics,
however, are quite relevant and their treatment is, for the most part,
lively and interesting.  With its well-written introductory article, diverse
survey of current concerns, and fairly extensive bibliography, this issue of
METAPHILOSOPHY is an excellent first source for those new to the field of
Computer Ethics.

[METAPHILOSOPHY, c/o Expediters of the Printed Word Ltd., 515 Madison Avenue,
Suite 1217, New York, NY  10022]

Bruce A. Sesnovich         mcnc!rti-sel!dg_rtp!sesnovich
Data General Corp.         rti-sel!dg_rtp!sesnovich%mcnc@csnet-relay.arpa
Westboro, MA               "Problems worthy of attack
                            prove their worth by hitting back"

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-111</DOCNO>
<DOCOLDNO>IA012-000123-B019-225</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.02.html 128.240.150.127 19970217003003 text/html 21153
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:28:26 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 2: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/2.01.html">
<LINK REL="Up" HREF="/Risks/index.2.html">
<LINK REL="Next" HREF="/Risks/2.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/2.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 2: Issue 2</H1>
<H2> Saturday, 1 Feb 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
More on Shuttle destruct systems 
</A>
<DD>
<A HREF="#subj1.1">
Martin J. Moore
</A><br>
<A HREF="#subj1.2">
 Sean Malloy
</A><br>
<A HREF="#subj1.3">
 Brint Cooper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The Challenger [non]accident 
</A>
<DD>
<A HREF="#subj2.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Redundancy 
</A>
<DD>
<A HREF="#subj3.1">
D. Cook
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Galileo Plutonium power 
</A>
<DD>
<A HREF="#subj4.1">
Martin Schoffstall
</A><br>
<A HREF="#subj4.2">
 James Tomayko
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  VDT's and birth defects in mice 
</A>
<DD>
<A HREF="#subj5.1">
Dan Hoey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  ORCON dissemination constraint on RISKS 1.43 
</A>
<DD>
<A HREF="#subj6.1">
Ted Lee
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
More on Shuttle destruct systems
</A>
</H3>
<address>
"MARTIN J. MOORE" 
&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>

</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

This morning I talked to my successor at the Cape, who was in the Range Safety 
area during the launch.  I've got a few things to report and some questions to 
answer from previous issues.  I found out that the Range Safety Officer 
commanded the destruction of the SRBs approximately 20 sec after the main 
explosion, as they were careening wildly away from the site.  Both SRBs did
explode on command.  The mood at the Cape is described as "devastated", 
especially among those who went outside to watch live.  My successor also 
reported that Range Safety had been officially cleared as of yesterday,
with respect to any responsibility for the accident; but that they expected 
*much* closer scrutiny than before (which is, of course, perfectly fine.)
Interestingly, many of the media and a large percentage of the general public 
were not aware of the existence of the destruct system.

The latest theory I have heard contains a "leak" in one of the SRBs resulting 
in a 6000 C jet of flame cutting into the tank and igniting its fuel.

Now, individual responses:

&gt; From: John Carpenter
&gt; As I read the article [by Martin Moore in <A HREF="/Risks/1.43.html">RISKS-1.43</A>,] it occurred to me
&gt; that as we discuss the risks of the destruct system we could be creating
&gt; another risk by revealing the nature of it's operation...
&gt; If the destruct system is public information, I would like to know why, 
&gt; If it isn't, it certainly has no place on the net.

Your point is well taken, and I did have some misgivings about posting the 
original article; not because I was revealing anything I shouldn't, but 
because I have no wish to be drawn into a national media controversy.  Hence
the restrictions on dissemination of the article.  None of the information in 
the article was classified, and all of it was publicly available; and NASA is 
very good about providing access to any information that isn't classified.
As to *why* it is public information...I think Neumann's response in 1-45
sums this up pretty well.  Also, if it's not public, then the question that 
will be raised is "what are they hiding?"  

Incidentally, my successor told me that there is an article in this morning's
(1/31) Orlando Sentinel about the destruct system, at about the same level
of detail as my article in 1-43.  Would some Central Florida reader be kind 
enough to send me a summary or a copy of that article?

&gt; From: Jeff Siegal &lt;JBS%DEEP-THOUGHT@mit-eddie.MIT.EDU&gt;
&gt; Is there someone who knows enough about the security at NASA/KSC to be
&gt; able to estimate the difficulty that a malicious party would have in
&gt; getting getting physical access to the shuttle/SRB/MFT prior to the launch?  

I'm not a physical security expert, but I believe that it would be 
extraordinarily difficult to get physical access to the shuttle itself at
any time.  Regarding the possibility raised by Kyle of a rifle shot, NASA
maintains a "clear zone" 1.5 miles (I think) in radius around the shuttle when 
it is on the pad.  This includes the closing of a public beach while the 
shuttle is on the pad, invariably causing complaints from some local citizens.

&gt; From: b-davis@utah-cs.ARPA (Brad Davis)
&gt; It also brings up an important question.  If the hardware system is
&gt; redundant, what about the software system?  Is the same software running
&gt; on all of the redundant hardware systems or are there more than one 
&gt; software packages developed.  If there is only one software package then
&gt; if one system fails due to a software failure then the other systems'
&gt; software may fail since the same conditions may still be in effect.

Each member of a redundant set runs the same software (obviously, computers
with different functions run different software).  The danger you note is a 
real one; however, I believe the best solution is to make each piece of 
software as robust and fail-safe as possible.  Consider that if redundant 
computers were running different software, you could have a failure of 
computer A and switchover to computer B without being able to reliably predict 
what computer B was doing at that instant!  The whole idea of redundancy is
that if a tool breaks in my hand, I want to be able to slap another one of the
same kind of tool into my hand and not miss a beat.  What your point leads to
is to have additional tools for cases where the first one doesn't apply; this
is a good idea, but it actually falls under the heading of "robustness" rather 
than "redundancy."
                                       mjm

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Possible triggering of the self-destruct mechanism &amp; (non)accident
</A>
</H3>
<address>
Sean Malloy
&lt;<A HREF="mailto:malloy@nprdc.arpa ">
malloy@nprdc.arpa 
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 07:05:50 pst
</i><PRE>

  &gt;Date: 30 Jan 86 09:23:53 PST (Thu)
  &gt;From: Peter G. Neumann &lt;Neumann@SRI-CSL.ARPA&gt;
  &gt;Subject: Possible triggering of the self-destruct mechanism

[The physicist ... who speculated that the explosion in the solid-fuel
rocket booster set off the self-destruct mechanism ... suggested that it
could not have been a hydrogen leak because hydrogen burns clear and the
Shuttle explosion had an obvious orange glow] is a classic example of what
happens when people overspecialize themselves. Here we have a physicist
making inaccurate statements about a fact of chemistry. I would suggest that
this physicist watch the film of the Hindenberg disaster, and watch the
bright, opaque flames of hydrogen burning in an insufficient quantity of
oxygen for complete consumption. Only when hydrogen has a sufficient
quantity of oxygen to burn completely does it burn with a clear blue flame.

One of the problems that this brings up is the tendency of the average
person to regard any statement made by a scientist about a scientific
subject as being correct because "they've been trained in science, so they
know what they're talking about", whether they are making a statement within
their field or out of it. Particularly when a scientist says that something
is impossible or impractical. Too many scientists over history have delcared
something impossible or impractical that is commonplace today to reject some
line of research because of such pronouncements.

   &gt;Date: Thu 30 Jan 86 20:22:37-EST
   &gt;From: Jeff Siegal &lt;JBS%DEEP-THOUGHT@mit-eddie.MIT.EDU&gt;
   &gt;Subject: The Challenger [non]accident

   &gt;I have heard speculation that some fuel leaking (LHY or LOX) from the
   &gt;MFT and a unexpected flame could be seen (on slow-motion videotape)
   &gt;for some time prior to the explosion.  This seems consistent with
   &gt;rifle bullet impact/puncture, long before the actual explosion
   &gt;occured.

This is one of the possibilities that the NASA investigating board is
going to be looking at. However, the existence of the flames in the
turbulent area just aft of the external tank is also consistent with a
leak in the fuel pipes from the external tank to the orbiter. 

If it did occur from an external impact, then the leak would have to
have started after the shuttle had taken off, because the plume of
escaping LHY would have caused enough condensation to be visible on
the gantry monitors, a situation that would have halted the launch. I
don't know of any way that someone shooting at the shuttle could be
sure that the bullet would only damage the tank enough to fail at max
Q, rather than penetrate and start a leak immediately. Or, failing
that, to hit the external tank after launch, with the shuttle rolling
and pitching into its climb attitude.

	Sean Malloy
	(malloy@nprdc-arpa)

-------------------------------

Date:     Fri, 31 Jan 86 9:54:00 EST
From:     Brint Cooper &lt;abc@BRL.ARPA&gt;
To:       "Peter G. Neumann" &lt;Neumann@sri-csl.arpa&gt;
cc:       RISKS@sri-csl.arpa
Subject:  Re:  Possible triggering of the self-destruct mechanism

But the news has consistently been reporting that, after the explosion that
destroyed Challenger, the Air Force used the destruct mechanism to destroy
the boosters (?) because one had gone off course and threatened populated
areas.  If this is true, can we not assume that the destruct mechanism did
not cause the accident?  Is it not a 'one time only' capability?

Brint

   [As Martin Moore said in <A HREF="/Risks/1.43.html">RISKS-1.43</A>, there are FIVE destruct receivers:
    one on the ET and two on each of the SRBs.  I was talking about the one
    on the ET; the SRBs somehow survived until they were intentionally 
    destroyed.  PGN]

</PRE>
<HR><H3><A NAME="subj1.3">
 The Challenger [non]accident
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@MC.LCS.MIT.EDU">
LIN@MC.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 10:41:51 EST
</i><PRE>
To: JBS@DEEP-THOUGHT.MIT.EDU
cc: LIN@MC.LCS.MIT.EDU, RISKS@SRI-CSL.ARPA

    From: Jeff Siegal &lt;JBS at DEEP-THOUGHT.MIT.EDU&gt;
    I have heard speculation that some fuel leaking (LHY or LOX) ...
    ... This seems consistent with rifle bullet impact/puncture, long 
    before the actual explosion occured.

Depends on what you mean by "long".  The licks of flame at the base of
the SRB occurred at most 2 sec before the main explosion.  It was
going at 2900 fps, so at best its altitude would have been 1 nautical
mile lower when the bullet hit, meaning 8 nm altitude.  Pretty far out
to imagine a rifle bullet hitting at that point.

    There has been no public mention of the possibility of terrorism.

Terrorists claim credit for events.  To my knowledge, no one has
claimed credit.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Redundancy
</A>
</H3>
<address>
&lt;<A HREF="mailto:dcook@SCRC-STONY-BROOK.ARPA">
dcook@SCRC-STONY-BROOK.ARPA
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 10:49 EST
</i><PRE>
To: risks@SRI-CSL.ARPA
cc: Spool@SCRC-STONY-BROOK.ARPA, dcook@SCRC-STONY-BROOK.ARPA

There is a point in the redundancy argument that has bothered me since I
interviewed at Stratus a year or so ago.  

Using the Stratus example, they run two copies of what they call a dipole.
One copy is "live" and one is shadowing the live one.  Each dipole is two
mirror image processors with a high-speed comparator in the middle.  When
the live module gets a miscompare, it lights a LED and hands control over
to the backup module.  The operating system is able to do whatever clean
up has to be done to brief module 2 so that computing is essentially
non-stop.  (Oh, one little "goodie" is that the module connectors are
designed so that *the customer* can pull out the lighted module and put
in a new one without shutting off the machine.)  Now the $64,000 question:
isn't the compare logic a single point of failure?  (Note that because
in this example you have a total of 4 CPU's, this isn't necessarily
a crash.)  But in the shuttle version, as I understood it, the systems
were only redundant and therefore a comparator or checker failure could,
it seems, knock the system out.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Galileo Plutonium power
</A>
</H3>
<address>
Martin Schoffstall 
&lt;<A HREF="mailto:schoff%rpics.csnet@CSNET-RELAY.ARPA">
schoff%rpics.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 09:56:32 EST
</i><PRE>

I'm not sure how much information is publicly available on the generating
systems of various satellites but I would like to point out something that
has been published that is somewhat analogous:  cardiac pacemakers.

As I remember it the plutonium powered ones were designed such that
the containment device could not be penetrated by:

	- .38 special at 15 feet.
	- cremation temperatures (natural gas)
	- aircraft impact.

Obviously I am being very coarse here and I don't have the details but
I'm sure others do but if the above is "close" I'll throw out some
number estimates that I'm sure others will correct:

	- .38 special at 15 feet, say 1000 feet/sec 300 foot-lbs???
	- natural gas burns at 2000 degrees?
	- say 9gs at impact?

The point is as follows:  If pacemakers are designed to handle stresses
such as that I would assume that the satellites are designed much better,
especially since the Soviets dumped a load on Canada (did they ever pay
damages for that?).

marty schoffstall

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Galileo Plutonium power
</A>
</H3>
<address>
&lt;<A HREF="mailto:James.Tomayko@a.sei.cmu.edu">
James.Tomayko@a.sei.cmu.edu
</A>&gt;
</address>
<i>
Friday, 31 January 1986 13:41:14 EST
</i><PRE>
Message-ID: &lt;1986.1.31.18.22.7.James.Tomayko@a.sei.cmu.edu&gt;

Re Larry Shilkoff's note on Galileo carrying plutonium:

Not only plutonium, but the spacecraft was to be deployed atop a
new version of the Centaur hydrogen/oxygen upperstage used on the
Atlas-Centaur and Titan III boosters. Therefore, aside from several 
hundred pounds of plutonium the Shuttle would be carrying several 
thousand pounds of highly volatile fuel &lt;inside&gt; the cargo bay, adding
considerable energy to any explosion. Worse yet, Galileo was to be the
&lt;first&gt; user of the new upperstage, which shares little with its predecessor
except the name. It has new tanks, engines, and instrumentation. In contrast
to previous unmanned missions, only &lt;one&gt; Galileo has been built. Considering
that the cost of building a second one would only have been 15% of the
cost of the first, NASA is taking a big chance by launching its only
Jupiter orbiter on an untested upperstage, in view of the multiple
failures of Shuttle-carried upperstages such as the IUS and various 
satellite kickstages. 

Sadly, the Galileo launch has already been delayed several years for 
various reasons (including one to switch it from the IUS to Centaur) and
is likely to be delayed again. If the Shuttle fleet is not declared
spaceworthy by May, the precession of Jupiter dictates a 13-month
launch delay. Some of the parts of the spacecraft are nearly six years old
now, and many have been in test for years on end. Even though the
mission is projected to be shorter than Voyager, the spacecraft itself may
actually "live" longer.

As a footnote specific to the risks question, a friend of mine who is a 
an astronaut trainer for NASA said to me several months ago that crews
training for Galileo and the Solar Polar launch also using Centaur were
wary because of critical questions relating to aborts. If the Shuttle
has to do a return to launch site abort or an abort to Africa before deploying
Galileo, what are the dangers of trying to land with a full load of 
hydrogen and radioactive isotopes? The possibility of explosions never
came up. Now it has to.

</PRE>
<HR><H3><A NAME="subj4.2">
VDT's and birth defects in mice
</A>
</H3>
<address>
Dan Hoey 
&lt;<A HREF="mailto:hoey@nrl-aic.ARPA">
hoey@nrl-aic.ARPA
</A>&gt;
</address>
<i>
31 Jan 1986 17:45:15 EST (Fri)
</i><PRE>
To: Risks@SRI-CSL.ARPA

Yesterday I heard a radio report that a Swedish study found that video
display terminals increased the incidence of birth defects in mice.
Does anyone have more information on this?

I have not previously heard of any controlled research in the area that
has identified a hazard.  I am interested in trying to find out what
the results of the study indicated, whether it is a new result, and how
credible it is.

Dan

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 ORCON dissemination constraint on RISKS 1.43
</A>
</H3>
<address>
&lt;<A HREF="mailto: TMPLee@DOCKMASTER.ARPA">
 TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 31 Jan 86 23:35 EST
</i><PRE>
To:  Neumann@SRI-CSL.ARPA

You realize, of course, that Martin Moore's fascinating and worthwhile
piece is accessible to *ANYONE* on the net who is allowed to use FTP by
their home site since SRI-CSL supports anonymous FTP logons and since
you have the RISKS back-issues in a public file.

                [... or indeed from any BBOARD receiving RISKS, 
                 not even necessarily on the ARPANET!  PGN]

Ted

(For readers not familiar with it, ORCON is a handling marking in some
circles that means "further distribution only with permission of the
originator, i.e., ORiginator CONtrolled." It is a non-trivial task to
get a computer system to implement that handling marking in a secure but
natural way, especially across a network.)

     [Yes, of course.  Less obscurely, someone can even ask to be put on 
      the RISKS list, which I presume would permit me to send them the back
      issue within the spirit of Martin's constraints.  I think what Martin
      may have been more concerned about was wholesale rebroadcastings.  
      So what we have is an experimental exercise in self-control, to see if
      our network community is mature enough to adhere to his constraints.
      I would be very interested in hearing of any postings contary to his
      caveat.  But you are very correct in suggesting that enforcing ORCON
      is a nasty problem that cannot be adequately addressed in most computer
      system environments today.  That is one reason why overclassification
      occurs.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/2.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.2.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/2.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-112</DOCNO>
<DOCOLDNO>IA012-000123-B019-239</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/1.46.html 128.240.150.127 19970217003011 text/html 379
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:28:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML>
<HEAD>
<TITLE>Risks Digest</TITLE>
</HEAD>
<BODY>
<H1>Bad request</H1>
"/RISKS/1.46.html" is not a valid issue of Risks.
<HR>
<ADDRESS>
<A HREF="http://catless.ncl.ac.uk/Lindsay.html">Lindsay.Marshall@newcastle.ac.uk</A>
</ADDRESS>
</BODY>
</HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-113</DOCNO>
<DOCOLDNO>IA012-000123-B019-253</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/2.57.html 128.240.150.127 19970217003019 text/html 379
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:28:53 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML>
<HEAD>
<TITLE>Risks Digest</TITLE>
</HEAD>
<BODY>
<H1>Bad request</H1>
"/RISKS/2.57.html" is not a valid issue of Risks.
<HR>
<ADDRESS>
<A HREF="http://catless.ncl.ac.uk/Lindsay.html">Lindsay.Marshall@newcastle.ac.uk</A>
</ADDRESS>
</BODY>
</HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-114</DOCNO>
<DOCOLDNO>IA012-000123-B019-280</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/4/index.html 128.240.150.127 19970217003047 text/html 80033
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:29:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Index to Volume 4</TITLE>
<LINK REL="Pref" HREF="/Risks/3/index.html">
<LINK REL="Next" HREF="/Risks/5/index.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Index to Volume 4</H1>
<H2> Saturday, 6 June 1987 </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------">
<DL>
<DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.1.html">Volume 4 Issue 1 (2 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.1.html#subj1">  Latest version of the computer-related trouble list (Peter G. Neumann)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.2.html">Volume 4 Issue 2 (2 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.2.html#subj1">  Insurgent Squirrel Joins No-Ways Arc (Ross McKenrick)</A>
<LI><A HREF="/Risks/4.2.html#subj2">  Collision avoidance systems - FAA vs. Honeywell (Charlie Hurd)</A>
<LI><A HREF="/Risks/4.2.html#subj3">  The Military and Automatic Humans (Ronald J Wanttaja)</A>
<LI><A HREF="/Risks/4.2.html#subj4">  Assessing system effectiveness (Scott E. Preece)</A>
<LI><A HREF="/Risks/4.2.html#subj5">  Computers in elections (Kurt Hyde)</A>
<LI><A HREF="/Risks/4.2.html#subj6">  17th FAULT-TOLERANT COMPUTING SYMPOSIUM (Flaviu Cristian)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.3.html">Volume 4 Issue 3 (3 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.3.html#subj1">  The Big Bang at the London Stock Exchange (Jonathan Bowen)</A>
<LI><A HREF="/Risks/4.3.html#subj2">  UK computer security audit (Robert Stroud)</A>
<LI><A HREF="/Risks/4.3.html#subj3">  Austin's computer-controlled traffic lights (Alan Wexelblat)</A>
<LI><A HREF="/Risks/4.3.html#subj4">  Computers and Medical Charts (Elliott S. Frank)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.4.html">Volume 4 Issue 4 (4 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.4.html#subj1">  Flawed Radars in Air Traffic Control (PGN/UPI)</A>
<LI><A HREF="/Risks/4.4.html#subj2">  The Future of English (risks of technocrats, risks of word processors)        (Martin Minow)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.5.html">Volume 4 Issue 5 (5 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.5.html#subj1">  Computer causes chaos in Brazilian Election (Jonathan Bowen)</A>
<LI><A HREF="/Risks/4.5.html#subj2">  Risks of FAA Philosophy ? (Robert DiCamillo)</A>
<LI><A HREF="/Risks/4.5.html#subj3">  Computers and Medical Charts (Christopher C. Stacy)</A>
<LI><A HREF="/Risks/4.5.html#subj4">  Re: Insurgent Squirrel Joins No-Ways Arc (rsk)</A>
<LI><A HREF="/Risks/4.5.html#subj5">  Micros in Car engines (Peter Stokes)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.6.html">Volume 4 Issue 6 (6 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.6.html#subj1">  Computerized Reagan swamps Hospital with calls     (David Whiteman via Werner Uhrig)
</A>
<LI><A HREF="/Risks/4.6.html#subj2">  Aftermath of the Big Bang (Robert Stroud)</A>
<LI><A HREF="/Risks/4.6.html#subj3">  Fault tolerant computer manufacturer RISKS (Robert Stroud)</A>
<LI><A HREF="/Risks/4.6.html#subj4">  Re: Micros in Car engines (Don Wegeng)</A>
<LI><A HREF="/Risks/4.6.html#subj5">  Re:airplanes and risks, Risks 3.89 (Udo Voges)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.7.html">Volume 4 Issue 7 (7 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.7.html#subj1">  Risks of RISKS (PGN)</A>
<LI><A HREF="/Risks/4.7.html#subj2">  Details on the British Air Traffic Control computer outage (from Herb Hecht)</A>
<LI><A HREF="/Risks/4.7.html#subj3">  Re: UK computer security audit (Robert Stroud)</A>
<LI><A HREF="/Risks/4.7.html#subj4">  USS Liberty (Matthew P Wiener)</A>
<LI><A HREF="/Risks/4.7.html#subj5">  Grassroots sneak attack on NSA (Matthew P Wiener)</A>
<LI><A HREF="/Risks/4.7.html#subj6">  A variation of the Stanford breakin method (Arno Diehl)</A>
<LI><A HREF="/Risks/4.7.html#subj7">  Re: Subject: Computers and Medical Charts (Roy Smith)</A>
<LI><A HREF="/Risks/4.7.html#subj8">  DDN Net breakdown (?) on 6 Nov 86? (Will Martin)</A>
<LI><A HREF="/Risks/4.7.html#subj9">  Re: Linguistic decay (Matthew P Wiener)</A>
<LI><A HREF="/Risks/4.7.html#subj10">  Mechanical Aids to Writing (Earl Boebert)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.8.html">Volume 4 Issue 8 (9 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.8.html#subj1">  Brazilian laws require proof of voting. People NEED those cards.       (Scot E. Wilcoxon)
</A>
<LI><A HREF="/Risks/4.8.html#subj2">  Grassroots sneak attack on NSA (Herb Lin, Matthew P Wiener)</A>
<LI><A HREF="/Risks/4.8.html#subj3">  Ethernet Security Risks (Phil Ngai)</A>
<LI><A HREF="/Risks/4.8.html#subj4">  Perfection (Herb Lin)</A>
<LI><A HREF="/Risks/4.8.html#subj5">  Information replacing knowledge (Daniel G. Rabe)</A>
<LI><A HREF="/Risks/4.8.html#subj6">  Word Processors / The Future of English (Stephen Page)</A>
<LI><A HREF="/Risks/4.8.html#subj7">  Copyrights; passwords; medical information (Matthew P Wiener)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.9.html">Volume 4 Issue 9 (10 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.9.html#subj1">  Risk of aging (Lee F. Breisacher)</A>
<LI><A HREF="/Risks/4.9.html#subj2">  Re: UK computer security audit (Henry Spencer)</A>
<LI><A HREF="/Risks/4.9.html#subj3">  Lost files (Norman Yusol)</A>
<LI><A HREF="/Risks/4.9.html#subj4">  Canard!! [Looping Mailers] (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/4.9.html#subj5">  Friend-foe identification (Henry Spencer)</A>
<LI><A HREF="/Risks/4.9.html#subj6">  Micros in Car Engines (Jed Sutherland)</A>
<LI><A HREF="/Risks/4.9.html#subj7">  Information replacing knowledge (Bard Bloom, Herb Lin, Jerry Saltzer)</A>
<LI><A HREF="/Risks/4.9.html#subj8">  Spelling becoming obsolete? (Ted Lee)</A>
<LI><A HREF="/Risks/4.9.html#subj9">  They almost got me! [A motor-vehicle database saga] (Mark Hittinger)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.10.html">Volume 4 Issue 10 (12 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.10.html#subj1">  Extreme computer risks in British business (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/4.10.html#subj2">  Alabama election snafu caused by programmer (PGN)</A>
<LI><A HREF="/Risks/4.10.html#subj3">  Looping mailer strikes again (Brian Reid, Nancy Leveson)</A>
<LI><A HREF="/Risks/4.10.html#subj4">  Lost files on Bitnet (Niall Mansfield)</A>
<LI><A HREF="/Risks/4.10.html#subj5">  VOA car testing (Bill Janssen)</A>
<LI><A HREF="/Risks/4.10.html#subj6">  Re: Aftermath of the Big Bang (apology) (Robert Stroud)</A>
<LI><A HREF="/Risks/4.10.html#subj7">  Re: The Future of English (T. H. Crowley [both of them])</A>
<LI><A HREF="/Risks/4.10.html#subj8">  Word-processors Not a Risk (Ralph Johnson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.11.html">Volume 4 Issue 11 (14 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.11.html#subj1">  Computers don't kill people, people kill people (Howard Israel)</A>
<LI><A HREF="/Risks/4.11.html#subj2">  Open microphone in the sky (Bob Parnass)</A>
<LI><A HREF="/Risks/4.11.html#subj3">  Computerized Voting in Texas (Jerry Leichter)</A>
<LI><A HREF="/Risks/4.11.html#subj4">  Problems with HNN (Alan Wexelblat)</A>
<LI><A HREF="/Risks/4.11.html#subj5">  Post-hacker-era computer crime (Talk by Sandy Sherizen)</A>
<LI><A HREF="/Risks/4.11.html#subj6">  Re: They almost got me! [A motor-vehicle database saga] (Doug Hardie)</A>
<LI><A HREF="/Risks/4.11.html#subj7">  Re: information replacing knowledge (G.L. Sicherman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.12.html">Volume 4 Issue 12 (16 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.12.html#subj1">  Air Traffic Control radar problems </A>
<LI><A HREF="/Risks/4.12.html#subj2">  Stuck Microphone and Near-Collision of 727s </A>
<LI><A HREF="/Risks/4.12.html#subj3">  Gwinnett County Voting (Scott Dorsey)</A>
<LI><A HREF="/Risks/4.12.html#subj4">  Micros in cars (Paul Kalapathy)</A>
<LI><A HREF="/Risks/4.12.html#subj5">  DMV computer networks (Bob Campbell)</A>
<LI><A HREF="/Risks/4.12.html#subj6">  Serious security bug in 3.4 (Dave Martindale)</A>
<LI><A HREF="/Risks/4.12.html#subj7">  "Maj. Doug Hardie" and his story (Bruce Schuck)</A>
<LI><A HREF="/Risks/4.12.html#subj8">  Necessity of language skills (Daniel G. Rabe)</A>
<LI><A HREF="/Risks/4.12.html#subj9">  Call for Papers -- Safety and Reliability Society Symposium (Nancy Leveson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.13.html">Volume 4 Issue 13 (18 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.13.html#subj1">  Framing of life-and-death situations (Jim Horning)</A>
<LI><A HREF="/Risks/4.13.html#subj2">  On placing the blame (Peter J. Denning)</A>
<LI><A HREF="/Risks/4.13.html#subj3">  Computer picks wife (Matthew Kruk)</A>
<LI><A HREF="/Risks/4.13.html#subj4">  Re: Micros in cars (Brint Cooper)</A>
<LI><A HREF="/Risks/4.13.html#subj5">  Re: They almost got me! (Will Martin)</A>
<LI><A HREF="/Risks/4.13.html#subj6">  Re:  A variation of the Stanford breakin method (Joe Pistritto)</A>
<LI><A HREF="/Risks/4.13.html#subj7">  Microfiched income-tax records stolen (John Coughlin)</A>
<LI><A HREF="/Risks/4.13.html#subj8">  Re: Copyrights (Andrew Klossner)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.14.html">Volume 4 Issue 14 (19 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.14.html#subj1">  Re: On placing the blame (Matt Bishop)</A>
<LI><A HREF="/Risks/4.14.html#subj2">  At last, a way to reduce [net]news traffic                  (Jerry Aguirre via Matthew P Wiener)
</A>
<LI><A HREF="/Risks/4.14.html#subj3">  Safety-Critical Software in the UK (Appendix B of ACARD report)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.15.html">Volume 4 Issue 15 (20 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.15.html#subj1">  IBM VM/SP SP Cracked (Jack Shaw)</A>
<LI><A HREF="/Risks/4.15.html#subj2">  On placing the blame AND Safety-Critical UK Software (Bjorn Freeman-Benson)</A>
<LI><A HREF="/Risks/4.15.html#subj3">  On placing the blame (Scot Wilcoxon)</A>
<LI><A HREF="/Risks/4.15.html#subj4">  Safety-Critical Software in the UK (Scott E. Preece)</A>
<LI><A HREF="/Risks/4.15.html#subj5">  Computer-based stock trading (from Discover)</A>
<LI><A HREF="/Risks/4.15.html#subj6">  FAA's Role in Developing a Mid-Air Collision-Avoidance System (Chuck Youman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.16.html">Volume 4 Issue 16 (22 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.16.html#subj1">  Banking machine almost ruins love life of Vancouver couple (Mark Brader)</A>
<LI><A HREF="/Risks/4.16.html#subj2">  2+2= ? (Risks of self-testing, especially with nonexistent tests) (Lindsay)</A>
<LI><A HREF="/Risks/4.16.html#subj3">  Re: Computer-based stock trading (Roger Mann)</A>
<LI><A HREF="/Risks/4.16.html#subj4">  Re: appendix to ACARD report (Nancy Leveson)</A>
<LI><A HREF="/Risks/4.16.html#subj5">  Some further thoughts on the UK software-certification proposals (Dave Platt)</A>
<LI><A HREF="/Risks/4.16.html#subj6">  Dependable Computing and the ACM Communications (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.17.html">Volume 4 Issue 17 (24 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.17.html#subj1">  Computer Risks and the Audi 5000    (Howard Israel with excerpts from Brint Cooper, Charlie Hurd, Clive Dawson)
</A>
<LI><A HREF="/Risks/4.17.html#subj2">  Risks of changing Air Traffic Control software? (Greg Earle)</A>
<LI><A HREF="/Risks/4.17.html#subj3">  Re: the UK Software-Verification Proposal (Bard Bloom)</A>
<LI><A HREF="/Risks/4.17.html#subj4">  Program Trading (Howard Israel, Eric Nickell, dmc)</A>
<LI><A HREF="/Risks/4.17.html#subj5">  Decision Making (Clive Dawson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.18.html">Volume 4 Issue 18 (26 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.18.html#subj1">  RISKS, computer-relevance, where-to-place-the-blame, etc. (PGN)</A>
<LI><A HREF="/Risks/4.18.html#subj2">  Verification and the UK proposal (Jim Horning)</A>
<LI><A HREF="/Risks/4.18.html#subj3">  When the going gets tough, the tough use the phone... (Jerry Leichter)</A>
<LI><A HREF="/Risks/4.18.html#subj4">  Re: 60 minutes reporting on the Audi 5000 (Eugene Miya)</A>
<LI><A HREF="/Risks/4.18.html#subj5">  Minireviews of Challenger article and computerized-roulette book     (Martin Minow)
</A>
<LI><A HREF="/Risks/4.18.html#subj6">  More on the UK Software-Verification Proposal (Bill Janssen)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.19.html">Volume 4 Issue 19 (26 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.19.html#subj1">  Very Brief Comments on the Current Issues (Kim Collins)</A>
<LI><A HREF="/Risks/4.19.html#subj2">  The Audi discussion is relevant (Hal Murray)</A>
<LI><A HREF="/Risks/4.19.html#subj3">  Audi 5000 (Roy Smith)</A>
<LI><A HREF="/Risks/4.19.html#subj4">  Laser-printer health risks; also, how to get ACARD report (Jonathan Bowen)</A>
<LI><A HREF="/Risks/4.19.html#subj5">  Data point on error rate in large systems (Hal Murray)</A>
<LI><A HREF="/Risks/4.19.html#subj6">  Re: Program Trading (Roger Mann)</A>
<LI><A HREF="/Risks/4.19.html#subj7">  Technical merits of SDI (from Richard Scribner)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.20.html">Volume 4 Issue 20 (30 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.20.html#subj1">  Smart metals (Steven H. Gutfreund)</A>
<LI><A HREF="/Risks/4.20.html#subj2">  Risks of having -- or not having -- records of telephone calls</A>
<LI><A HREF="/Risks/4.20.html#subj3">  Audi and 60 Minutes (Mark S. Brader)</A>
<LI><A HREF="/Risks/4.20.html#subj4">  Audi 5000/Micros in cars and the Mazda RX7 (Peter Stokes)</A>
<LI><A HREF="/Risks/4.20.html#subj5">  Automated trading (Scott Dorsey)</A>
<LI><A HREF="/Risks/4.20.html#subj6">  "Borrowed" Canadian tax records; Security of medical records (Mark S. Brader)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.21.html">Volume 4 Issue 21 (30 Nov 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.21.html#subj1">  Risks of Computer Modeling and Related Subjects (Mike Williams--LONG MESSAGE)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.22.html">Volume 4 Issue 22 (2 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.22.html#subj1">  More Air Traffic Control Near-Collisions (PGN)</A>
<LI><A HREF="/Risks/4.22.html#subj2">  Re: satellite interference (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/4.22.html#subj3">  "Welcome to the .......... system": An invitation? (Bruce N. Baker)</A>
<LI><A HREF="/Risks/4.22.html#subj4">  Replicability; econometrics (Charles Hedrick)</A>
<LI><A HREF="/Risks/4.22.html#subj5">  Re: Risks of computer modeling (John Gilmore)</A>
<LI><A HREF="/Risks/4.22.html#subj6">  Computerized weather models (Amos Shapir)</A>
<LI><A HREF="/Risks/4.22.html#subj7">  Active control of skyscrapers (Warwick Bolam)</A>
<LI><A HREF="/Risks/4.22.html#subj8">  Privacy in the office (Paul Czarnecki)</A>
<LI><A HREF="/Risks/4.22.html#subj9">  Kremlin is purging dimwitted scientists (Matthew P Wiener; also in ARMS-D)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.23.html">Volume 4 Issue 23 (3 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.23.html#subj1">  The persistence of memory  [and customs officials] (Richard V. Clayton)</A>
<LI><A HREF="/Risks/4.23.html#subj2">  America's Cup - floppies held to ransom (Computing Australia via Derek)</A>
<LI><A HREF="/Risks/4.23.html#subj3">  Some thoughts regarding recent postings: blame and causality (Eugene Miya)</A>
<LI><A HREF="/Risks/4.23.html#subj4">  Microcomputer controlled cars (not Audi) (Miriam Nadel)</A>
<LI><A HREF="/Risks/4.23.html#subj5">  Re: Welcome to the system (Ronda Henning)</A>
<LI><A HREF="/Risks/4.23.html#subj6">  Re: Automated trading (Scott Dorsey)</A>
<LI><A HREF="/Risks/4.23.html#subj7">  Active control of skyscrapers (Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.24.html">Volume 4 Issue 24 (5 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.24.html#subj1">  Criminal Encryption &amp; Long Term effects (Baxter) </A>
<LI><A HREF="/Risks/4.24.html#subj2">  Criminals and encryption (Phil Karn)</A>
<LI><A HREF="/Risks/4.24.html#subj3">  Re: ATC Near-Collisions (Rony Shapiro)</A>
<LI><A HREF="/Risks/4.24.html#subj4">  High Availability Systems (PGN)</A>
<LI><A HREF="/Risks/4.24.html#subj5">  Plug-compatible modules (PGN)</A>
<LI><A HREF="/Risks/4.24.html#subj6">  "Satellite interference" (Lauren Weinstein)</A>
<LI><A HREF="/Risks/4.24.html#subj7">  Re: Privacy in the office (Brint Cooper)</A>
<LI><A HREF="/Risks/4.24.html#subj8">  ACARD Report (Samuel B. Bassett)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.25.html">Volume 4 Issue 25 (7 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.25.html#subj1">  Child electrocuted (Anonymous, Brad Davis, Paul Nelson) [READ ALL 3!]</A>
<LI><A HREF="/Risks/4.25.html#subj2">  On models, publications, and credibility (Bob Estell)</A>
<LI><A HREF="/Risks/4.25.html#subj3">  Encryption and criminals (Perry Metzger, Fred Hapgood)</A>
<LI><A HREF="/Risks/4.25.html#subj4">  Mode-C altitude transponders (Dan Nelson)</A>
<LI><A HREF="/Risks/4.25.html#subj5">  ATM Limits (Richard Outerbridge)</A>
<LI><A HREF="/Risks/4.25.html#subj6">  Taking the 5th (Jerry Leichter)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.26.html">Volume 4 Issue 26 (10 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.26.html#subj1">  Computer Error Endangers Hardware (Nancy I. Garman)</A>
<LI><A HREF="/Risks/4.26.html#subj2">  "One of the Worst Days Ever for Muni Metro, BART" (PGN)</A>
<LI><A HREF="/Risks/4.26.html#subj3">  Korean Air Lines Flight 007 (Steve Jong)</A>
<LI><A HREF="/Risks/4.26.html#subj4">  Plug Compatible Modules; Criminal Encryption (David Fetrow)</A>
<LI><A HREF="/Risks/4.26.html#subj5">  More on skyscraper control (Mike Ekberg)</A>
<LI><A HREF="/Risks/4.26.html#subj6">  Satellite interference (James D. Carlson)</A>
<LI><A HREF="/Risks/4.26.html#subj7">  (Il)legal Encryption (Richard Outerbridge)</A>
<LI><A HREF="/Risks/4.26.html#subj8">  Software article in _Computer Design_ (Walt Thode)</A>
<LI><A HREF="/Risks/4.26.html#subj9">  Heavy metal and light algorithms (PGN)</A>
<LI><A HREF="/Risks/4.26.html#subj10">  Suit against Lotus dropped (Bill Sommerfeld)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.27.html">Volume 4 Issue 27 (11 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.27.html#subj1">  Computerised Discrimination (Brian Randell)</A>
<LI><A HREF="/Risks/4.27.html#subj2">  Belgian Paper transcends computer breakdown (Martin Minow)</A>
<LI><A HREF="/Risks/4.27.html#subj3">  Re: Plug-compatible modules (Keith F. Lynch)</A>
<LI><A HREF="/Risks/4.27.html#subj4">  Re: Criminal Encryption (Keith F. Lynch, Ira D. Baxter, Dave Platt)</A>
<LI><A HREF="/Risks/4.27.html#subj5">  Re: More on skyscraper control (Brint Cooper)</A>
<LI><A HREF="/Risks/4.27.html#subj6">  The Second Labor of Hercules (Dave Benson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.28.html">Volume 4 Issue 28 (12 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.28.html#subj1">  Mount a scratch giraffe, too?  Make that several. (Jim Horning)</A>
<LI><A HREF="/Risks/4.28.html#subj2">  Elf debuts as parking attendant (Kevin B. Kenny)</A>
<LI><A HREF="/Risks/4.28.html#subj3">  Plug-compatible plugs (Chris Koenigsberg, Henry Schaffer)</A>
<LI><A HREF="/Risks/4.28.html#subj4">  An Amusing Article on the Taxonomy of "Bugs" (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/4.28.html#subj5">  Satellite interference (Lauren Weinstein)</A>
<LI><A HREF="/Risks/4.28.html#subj6">  Fast-food computers (Scott Guthery)</A>
<LI><A HREF="/Risks/4.28.html#subj7">  Re: More on skyscraper control (Chuck Kennedy)</A>
<LI><A HREF="/Risks/4.28.html#subj8">  Re: Risks of Computer Modeling (Craig Paxton)</A>
<LI><A HREF="/Risks/4.28.html#subj9">  Re: Computerized Discrimination (Randall Davis)</A>
<LI><A HREF="/Risks/4.28.html#subj10">  Computers and Educational Decrepitude (Geof Cooper)</A>
<LI><A HREF="/Risks/4.28.html#subj11">  Symposium -- Directions and Implications of Advanced Computing (Jon Jacky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.29.html">Volume 4 Issue 29 (14 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.29.html#subj1">  America's Cup: Left-over Digital Filter (Bruce Wampler)</A>
<LI><A HREF="/Risks/4.29.html#subj2">  Some additions to the "bug" taxonomy (Dick King)</A>
<LI><A HREF="/Risks/4.29.html#subj3">  Re: uninterruptible power (Ted Lee)</A>
<LI><A HREF="/Risks/4.29.html#subj4">  Trade-offs between BMD architecture and software tractability (Herb Lin)</A>
<LI><A HREF="/Risks/4.29.html#subj5">  Re: Criminal encryption (Garry Wiegand)</A>
<LI><A HREF="/Risks/4.29.html#subj6">  Computerised Discrimination (Scott Preece)</A>
<LI><A HREF="/Risks/4.29.html#subj7">  More on Incompatible Plug-Compatible Monitors (Al Stangenberger)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.30.html">Volume 4 Issue 30 (16 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.30.html#subj1">  Arpanet outage (Andrew Malis)</A>
<LI><A HREF="/Risks/4.30.html#subj2">  Dynamic Signature Verification (Robert Stroud [and Brian Randell])</A>
<LI><A HREF="/Risks/4.30.html#subj3">  Wobbly skyscrapers and passive vs. active controls (Niall Mansfield)</A>
<LI><A HREF="/Risks/4.30.html#subj4">  Re: The Audi 5000 problems (Matt Smiley)</A>
<LI><A HREF="/Risks/4.30.html#subj5">  Modifying bank cards (Rodney Hoffman)</A>
<LI><A HREF="/Risks/4.30.html#subj6">  Credit card mag strips (Ted Marshall)</A>
<LI><A HREF="/Risks/4.30.html#subj7">  Fast-Food Computing (Edward Vielmetti)</A>
<LI><A HREF="/Risks/4.30.html#subj8">  "bugs" (Doug McIlroy, Jonathan Clark, Bob Estell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.31.html">Volume 4 Issue 31 (17 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.31.html#subj1">  Don't sit too close!  ("And Now, Exploding Computers") (Jerry Leichter)</A>
<LI><A HREF="/Risks/4.31.html#subj2">  Car-stress syndrome (Robert D. Houk)</A>
<LI><A HREF="/Risks/4.31.html#subj3">  Korean Air Lines Flight 007 (Niall Mansfield)</A>
<LI><A HREF="/Risks/4.31.html#subj4">  Heisenbugs (Rob Austein [an example], Doug Landauer)</A>
<LI><A HREF="/Risks/4.31.html#subj5">  Criminal Encryption (Bill Gunshannon [counterexample?])</A>
<LI><A HREF="/Risks/4.31.html#subj6">  Taking the "con" out of econometrics... correction and a plea (Mike Williams)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.32.html">Volume 4 Issue 32 (18 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.32.html#subj1">  EXTRA! British Telecom payphone Phonecard broken?</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.33.html">Volume 4 Issue 33 (21 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.33.html#subj1">  Help British Telecom save a WORM. (Scot E. Wilcoxon)</A>
<LI><A HREF="/Risks/4.33.html#subj2">  Security of magnetic-stripe cards (Brian Reid)</A>
<LI><A HREF="/Risks/4.33.html#subj3">  Korean Air Lines Flight 007 (Dick King)</A>
<LI><A HREF="/Risks/4.33.html#subj4">  Car-stress syndrome (Dick King)</A>
<LI><A HREF="/Risks/4.33.html#subj5">  Bugs called cockroaches [A True Fable For Our Times] (anonymous)</A>
<LI><A HREF="/Risks/4.33.html#subj6">  Re: More on car computers (not Audi) (Miriam Nadel)</A>
<LI><A HREF="/Risks/4.33.html#subj7">  Runaway Audi 5000 (John O. Rutemiller)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.34.html">Volume 4 Issue 34 (23 Dec 86)</A>
<DD><UL>
<LI><A HREF="/Risks/4.34.html#subj1">  Debit cards that don't (Edward M. Embick, PGN)</A>
<LI><A HREF="/Risks/4.34.html#subj2">  Re: security of magnetic-stripe cards (Henry Spencer)</A>
<LI><A HREF="/Risks/4.34.html#subj3">  Plug-compatible plugs (Henry Spencer)</A>
<LI><A HREF="/Risks/4.34.html#subj4">  Runaway Audi 5000 (Mark Brader)</A>
<LI><A HREF="/Risks/4.34.html#subj5">  Ozone layer (Mark Brader)</A>
<LI><A HREF="/Risks/4.34.html#subj6">  Another heisenbug (Zhahai Stewart)</A>
<LI><A HREF="/Risks/4.34.html#subj7">  More "bugs" (Tom Parmenter via Richard Lamson)</A>
<LI><A HREF="/Risks/4.34.html#subj8">  Computer Malpractice (Dave Platt)</A>
<LI><A HREF="/Risks/4.34.html#subj9">  Financial Servomechanisms (Brian Randell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.35.html">Volume 4 Issue 35 (3 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.35.html#subj1">  Computer Gets Stage Fright (Chuck Youman)</A>
<LI><A HREF="/Risks/4.35.html#subj2">  Still More on PhoneCards (PGN)</A>
<LI><A HREF="/Risks/4.35.html#subj3">  Miscarriages Up in Women Exposed In Computer-Chip Process (Martin Minow)</A>
<LI><A HREF="/Risks/4.35.html#subj4">  Across the Atlantic with Cast Iron (Earl Boebert)</A>
<LI><A HREF="/Risks/4.35.html#subj5">  Heisenbugs -- Two more examples (Maj. Doug Hardie)</A>
<LI><A HREF="/Risks/4.35.html#subj6">  Risks Involved in Campus Network-building (Rich Kulawiec)</A>
<LI><A HREF="/Risks/4.35.html#subj7">  Update on Swedish Vulnerability Board Report (Martin Minow)</A>
<LI><A HREF="/Risks/4.35.html#subj8">  DES cracked? (Dave Platt)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.36.html">Volume 4 Issue 36 (6 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.36.html#subj1">  A Heisenbug Example from the SIFT Computer (Jack Goldberg)</A>
<LI><A HREF="/Risks/4.36.html#subj2">  More Heisen-debugs (Don Lindsay)</A>
<LI><A HREF="/Risks/4.36.html#subj3">  The Conrail train wreck (PGN)</A>
<LI><A HREF="/Risks/4.36.html#subj4">  Software glitches in high-tech defense systems (from Michael Melliar-Smith)</A>
<LI><A HREF="/Risks/4.36.html#subj5">  Computer program zeroes out fifth grader; Computerized gift-wrap (Ed Reid)</A>
<LI><A HREF="/Risks/4.36.html#subj6">  Videocypher, DES (Jerry Leichter)</A>
<LI><A HREF="/Risks/4.36.html#subj7">  More on the possible DES crack (David Platt)</A>
<LI><A HREF="/Risks/4.36.html#subj8">  Campus LANs (James D. Carlson, Don Wegeng, Henry Spencer)</A>
<LI><A HREF="/Risks/4.36.html#subj9">  Engineering Ethics (Chuck Youman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.37.html">Volume 4 Issue 37 (7 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.37.html#subj1">  Re: vulnerability of campus LANs (Ted Lee, David Fetrow)</A>
<LI><A HREF="/Risks/4.37.html#subj2">  Re: DES cracked? (Henry Spencer)</A>
<LI><A HREF="/Risks/4.37.html#subj3">  Cellular risks (from Geoff Goodfellow via PGN)</A>
<LI><A HREF="/Risks/4.37.html#subj4">  "Letters From a Deadman" (Rodney Hoffman)</A>
<LI><A HREF="/Risks/4.37.html#subj5">  Stock Market Volatility (Randall Davis)</A>
<LI><A HREF="/Risks/4.37.html#subj6">  Engineering ethics (Dick Karpinski)</A>
<LI><A HREF="/Risks/4.37.html#subj7">  Computerized Discrimination (Ken Laws)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.38.html">Volume 4 Issue 38 (8 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.38.html#subj1">  As the year turns ... (Jeffrey Mogul)</A>
<LI><A HREF="/Risks/4.38.html#subj2">  Automobile micros (Hal Murray)</A>
<LI><A HREF="/Risks/4.38.html#subj3">  Chemicals in semiconductor manufacturing (Michael Scott)</A>
<LI><A HREF="/Risks/4.38.html#subj4">  Cellular -- Ref to Geoff (via PGN)</A>
<LI><A HREF="/Risks/4.38.html#subj5">  "Misinformation"?? (Dick Karpinski)</A>
<LI><A HREF="/Risks/4.38.html#subj6">  Burnham Book -- A Recommendation (Alan Wexelblat)</A>
<LI><A HREF="/Risks/4.38.html#subj7">  Engineering Ethics (Dan Ball)</A>
<LI><A HREF="/Risks/4.38.html#subj8">  Re: Stock Market Volatility (Richard A. Cowan)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.39.html">Volume 4 Issue 39 (11 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.39.html#subj1">  Re: As the year turns ... (Jerry Saltzer)</A>
<LI><A HREF="/Risks/4.39.html#subj2">  911 computer failure (PGN)</A>
<LI><A HREF="/Risks/4.39.html#subj3">  Engineering tradeoffs and ethics (Andy Freeman, Ken Laws, George Erhart)</A>
<LI><A HREF="/Risks/4.39.html#subj4">  Re: computerized discrimination (Randall Davis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.40.html">Volume 4 Issue 40 (14 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.40.html#subj1">  Phone Cards (Brian Randell)</A>
<LI><A HREF="/Risks/4.40.html#subj2">  It's No Joke!! (Microwave oven bakes 3 yrs of PC data) (Lindsay Marshall)</A>
<LI><A HREF="/Risks/4.40.html#subj3">  Automation bottoms out (PGN)</A>
<LI><A HREF="/Risks/4.40.html#subj4">  Amtrak train crash with Conrail freight locomotive -- more (PGN)</A>
<LI><A HREF="/Risks/4.40.html#subj5">  Re: Cellular risks (Robert Frankston)  </A>
<LI><A HREF="/Risks/4.40.html#subj6">  Re: Ask not for whom the chimes tinkle (Tom Perrine via Kurt Sauer)</A>
<LI><A HREF="/Risks/4.40.html#subj7">  Re: Engineering ethics (PGN)</A>
<LI><A HREF="/Risks/4.40.html#subj8">  Repetitive Strain Injury and VDTs (Mark Jackson) </A>
<LI><A HREF="/Risks/4.40.html#subj9">  Safety Officers and "Oversight" (Henry Spencer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.41.html">Volume 4 Issue 41 (19 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.41.html#subj1">  Audi 5000 recall (Dave Platt)</A>
<LI><A HREF="/Risks/4.41.html#subj2">  UK EFT Risks (Brian Randell)</A>
<LI><A HREF="/Risks/4.41.html#subj3">  Another Bank Card Horror Story (Dave Wortman)</A>
<LI><A HREF="/Risks/4.41.html#subj4">  Stock Market behavior (Rob Horn)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.42.html">Volume 4 Issue 42 (23 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.42.html#subj1">  A scary tale--Sperry avionics module testing bites the dust? (Nancy Leveson)</A>
<LI><A HREF="/Risks/4.42.html#subj2">  Computer gotcha (Dave Emery)</A>
<LI><A HREF="/Risks/4.42.html#subj3">  Re: Another Bank Card Horror Story (Robert Frankston)</A>
<LI><A HREF="/Risks/4.42.html#subj4">  Stock Market behavior (Howard Israel, Gary Kremen)</A>
<LI><A HREF="/Risks/4.42.html#subj5">  Engineering models applied to systems (Alan Wexelblat)</A>
<LI><A HREF="/Risks/4.42.html#subj6">  Re: British EFT note (Alan Wexelblat)</A>
<LI><A HREF="/Risks/4.42.html#subj7">  Train Wreck Inquiry (Risks 2.9) (Matthew Kruk)</A>
<LI><A HREF="/Risks/4.42.html#subj8">  Cost-benefit analyses and automobile recalls (John Chambers)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.43.html">Volume 4 Issue 43 (26 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.43.html#subj1">  "Cable `Hackers' Claim Scrambler is History"; other breaches (PGN)</A>
<LI><A HREF="/Risks/4.43.html#subj2">  Re: VideoCypher II (Michael Grant)</A>
<LI><A HREF="/Risks/4.43.html#subj3">  Re: DES cracked? (Douglas Humphrey)</A>
<LI><A HREF="/Risks/4.43.html#subj4">  Re: Billions (Brian Randell)</A>
<LI><A HREF="/Risks/4.43.html#subj5">  GM On-Board Computers (Wes Williams)</A>
<LI><A HREF="/Risks/4.43.html#subj6">  Active control of skyscrapers (Peter G. Capek)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.44.html">Volume 4 Issue 44 (29 Jan 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.44.html#subj1">  Air Traffic Control -- More Mid-Air Collisions and Prevention (PGN)</A>
<LI><A HREF="/Risks/4.44.html#subj2">  Time warp for Honeywell CP-6 sites (P. Higgins)</A>
<LI><A HREF="/Risks/4.44.html#subj3">  GM On-Board Computers (Martin Harriman)</A>
<LI><A HREF="/Risks/4.44.html#subj4">  Loose coupling (Ephraim Vishniac)</A>
<LI><A HREF="/Risks/4.44.html#subj5">  Units RISKS and also a book to read (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/4.44.html#subj6">  Re: Unit conversion errors (Alan M. Marcum, Keith F. Lynch)</A>
<LI><A HREF="/Risks/4.44.html#subj7">  DP Ethics: The "Stanley House" Criteria (Pete McVay)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.45.html">Volume 4 Issue 45 (2 Feb 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.45.html#subj1">  DATE-86, or The Ghost of Tinkles Past (Rob Austein)</A>
<LI><A HREF="/Risks/4.45.html#subj2">  Computerised Discrimination (an update) (Brian Randell)</A>
<LI><A HREF="/Risks/4.45.html#subj3">  Another non-malfunctioning alarm (Jeffrey Thomas)</A>
<LI><A HREF="/Risks/4.45.html#subj4">  Re: Engineering models applied to systems, <A HREF="/Risks/4.42.html">RISKS-4.42</A> (Joseph S. D. Yao)</A>
<LI><A HREF="/Risks/4.45.html#subj5">  Re: A scary tale--Sperry avionics module testing bites the dust? (D.W. James)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.46.html">Volume 4 Issue 46 (9 Feb 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.46.html#subj1">  TV-program on PBS: NOVA - Why Planes Crash (Werner Uhrig, Michael Harris)</A>
<LI><A HREF="/Risks/4.46.html#subj2">  Electronic steering (Steve McLafferty)</A>
<LI><A HREF="/Risks/4.46.html#subj3">  Senior to Repay Bank 25,000 Dollars (Steve Thompson)</A>
<LI><A HREF="/Risks/4.46.html#subj4">  Recursive risks in computer design (McCullough)</A>
<LI><A HREF="/Risks/4.46.html#subj5">  Library Failure (Chuck Weinstock)</A>
<LI><A HREF="/Risks/4.46.html#subj6">  CP-6 time warp update (the true story) (John Joseph via Paul Higgins)</A>
<LI><A HREF="/Risks/4.46.html#subj7">  Glitch in the Computers and Society Digest mailing list... (Dave Taylor)</A>
<LI><A HREF="/Risks/4.46.html#subj8">  More on British Phone fraud (Will Martin)</A>
<LI><A HREF="/Risks/4.46.html#subj9">  Wall Street Journal article on Risks (Jerome H. Saltzer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.47.html">Volume 4 Issue 47 (16 Feb 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.47.html#subj1">  The fielding is mutuel! (PGN)</A>
<LI><A HREF="/Risks/4.47.html#subj2">  Another worm story (Dave Platt)</A>
<LI><A HREF="/Risks/4.47.html#subj3">  Re: The student's extra $25,000 (Ronald J Wanttaja)</A>
<LI><A HREF="/Risks/4.47.html#subj4">  Problems with the B-1B Bomber (Bill McGarry)</A>
<LI><A HREF="/Risks/4.47.html#subj5">  Super-Smart Cards Are Here. (Leo Schwab)</A>
<LI><A HREF="/Risks/4.47.html#subj6">  Iranamok Computer-Databased (Craig Milo Rogers)  </A>
<LI><A HREF="/Risks/4.47.html#subj7">  Re: electronic steering (Tom Adams, Amos Shapir)</A>
<LI><A HREF="/Risks/4.47.html#subj8">  Re: Nova: Why Planes Crash (Alan M. Marcum)</A>
<LI><A HREF="/Risks/4.47.html#subj9">  Re: Library computerization (Will Martin)</A>
<LI><A HREF="/Risks/4.47.html#subj10">  Second British Telecom Fraud (Lindsay F. Marshall)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.48.html">Volume 4 Issue 48 (18 Feb 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.48.html#subj1">  Four near air misses in 1986; Radar failure (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/4.48.html#subj2">  Computer failure causes flight delays (Rodney Hoffman)</A>
<LI><A HREF="/Risks/4.48.html#subj3">  Real RISKS (as opposed to virtual risks) of aircraft (Eugene Miya)</A>
<LI><A HREF="/Risks/4.48.html#subj4">  Trojan Horse alert (Al Stangenberger)</A>
<LI><A HREF="/Risks/4.48.html#subj5">  Computerized Town Data Vanish (Jerry Leichter)</A>
<LI><A HREF="/Risks/4.48.html#subj6">  Re: UCSD work on human error (Alexander Glockner)</A>
<LI><A HREF="/Risks/4.48.html#subj7">  Connector risk (Rob Horn)</A>
<LI><A HREF="/Risks/4.48.html#subj8">  Re: Electronic steering (Brint Cooper)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.49.html">Volume 4 Issue 49 (22 Feb 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.49.html#subj1">  A misplaced report (Danny Cohen)</A>
<LI><A HREF="/Risks/4.49.html#subj2">  Relevance (Amos Shapir)</A>
<LI><A HREF="/Risks/4.49.html#subj3">  Re: London ATC (Jonathan Clark)</A>
<LI><A HREF="/Risks/4.49.html#subj4">  Disk space cleanup causes problems with on-line Bar Admission exam     (David Sherman)
</A>
<LI><A HREF="/Risks/4.49.html#subj5">  Automatic Call Tracing for Emergency Services (Mark Jackson)</A>
<LI><A HREF="/Risks/4.49.html#subj6">  Re: The student's extra $25,000 (Kee Hinckley)</A>
<LI><A HREF="/Risks/4.49.html#subj7">  Re: Electronic steering (Hien B. Tang)</A>
<LI><A HREF="/Risks/4.49.html#subj8">  Re: TV-program on PBS: NOVA - Why Planes Crash (Henry Spencer)</A>
<LI><A HREF="/Risks/4.49.html#subj9">  Re: RJ (phone) connectors for terminals (Jordan Brown)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.50.html">Volume 4 Issue 50 (23 Feb 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.50.html#subj1">  Principles of RISKS (James H. Coombs)</A>
<LI><A HREF="/Risks/4.50.html#subj2">  "Demon computer" (PGN)</A>
<LI><A HREF="/Risks/4.50.html#subj3">  NSA Risks (Alan Wexelblat)</A>
<LI><A HREF="/Risks/4.50.html#subj4">  Results of a recent security review (Mary Holstege)</A>
<LI><A HREF="/Risks/4.50.html#subj5">  Electronic steering    (Kevin J. Belles, Rick Sidwell, Kevin Oliveau, Mark L. Lambert)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.51.html">Volume 4 Issue 51 (25 Feb 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.51.html#subj1">  HiTech version of NixonTapes (Pete Lee)</A>
<LI><A HREF="/Risks/4.51.html#subj2">  Re: Automatic Call Tracing for Emergency Services (Lee Naish) </A>
<LI><A HREF="/Risks/4.51.html#subj3">  Air Traffic Control, Auto-Land (Matthew Machlis)</A>
<LI><A HREF="/Risks/4.51.html#subj4">  Electronic steering (Spencer W. Thomas, excerpt from William Swan)</A>
<LI><A HREF="/Risks/4.51.html#subj5">  Hurricane Iwa and the Hawaii blackout of 1984     (James Burke via Matthew P Wiener)
</A>
<LI><A HREF="/Risks/4.51.html#subj6">  Summary of a Talk by SANFORD (SANDY) SHERIZEN on Computer Crime (Eugene Miya)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.52.html">Volume 4 Issue 52 (26 Feb 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.52.html#subj1">  B-1 plagued by problems (PGN)</A>
<LI><A HREF="/Risks/4.52.html#subj2">  Computer loses bus (Mark Biggar)</A>
<LI><A HREF="/Risks/4.52.html#subj3">  Human errors (Brian Randell)</A>
<LI><A HREF="/Risks/4.52.html#subj4">  Possessed terminal? (pom)</A>
<LI><A HREF="/Risks/4.52.html#subj5">  Entertainment risks (Walt Thode)</A>
<LI><A HREF="/Risks/4.52.html#subj6">  Automatic Call Tracing for Emergency Services (James Roche, Charley Wingate)</A>
<LI><A HREF="/Risks/4.52.html#subj7">  "Active" car suspensions (Graeme Dixon)</A>
<LI><A HREF="/Risks/4.52.html#subj8">  Altitude-Detecting Radar (Matthew Machlis)</A>
<LI><A HREF="/Risks/4.52.html#subj9">  Re: Results of a recent security review (Andrew Klossner)</A>
<LI><A HREF="/Risks/4.52.html#subj10">  Re: Sherizen talk; auto-landing (Eugene Miya)</A>
<LI><A HREF="/Risks/4.52.html#subj11">  Air Traffic Control, Auto-Land (Scott E. Preece)</A>
<LI><A HREF="/Risks/4.52.html#subj12">  Risks of autopilots (and risks of solutions) (Bill Janssen)</A>
<LI><A HREF="/Risks/4.52.html#subj13">  Another difference between electronic control in cars and fighters    (Brent Chapman)
</A>
<LI><A HREF="/Risks/4.52.html#subj14">  Re: Hurricane Iwa (Scott Dorsey) </A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.53.html">Volume 4 Issue 53 (1 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.53.html#subj1">  Setuid Patent (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/4.53.html#subj2">  On PGN's editorial comment on human misuse of computers (Eugene Miya)</A>
<LI><A HREF="/Risks/4.53.html#subj3">  An aside on the B-1 (Eugene Miya)</A>
<LI><A HREF="/Risks/4.53.html#subj4">  Autolander discussion (Nancy Leveson)</A>
<LI><A HREF="/Risks/4.53.html#subj5">  Re: Air Traffic Control, Auto-Land (Dean Pentcheff)</A>
<LI><A HREF="/Risks/4.53.html#subj6">  Electronic Steering (Ray Chen, Herb Lin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.54.html">Volume 4 Issue 54 (2 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.54.html#subj1">  Rockford Illinois Destroyed by Computer! (Chuck Weinstock)</A>
<LI><A HREF="/Risks/4.54.html#subj2">  Ma Bell's Daughter Does Dallas (PGN)</A>
<LI><A HREF="/Risks/4.54.html#subj3">  FAA Does Houston (PGN)</A>
<LI><A HREF="/Risks/4.54.html#subj4">  Tempest Puget, or The Sound and the Ferries (PGN)</A>
<LI><A HREF="/Risks/4.54.html#subj5">  Re: proper use of suid (Jef Poskanzer)</A>
<LI><A HREF="/Risks/4.54.html#subj6">  Process Control (Chuck Weinstock)</A>
<LI><A HREF="/Risks/4.54.html#subj7">  Risks in switching to computerized `people meters' (Bill Janssen)</A>
<LI><A HREF="/Risks/4.54.html#subj8">  A lovely algorithm (Lindsay)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.55.html">Volume 4 Issue 55 (3 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.55.html#subj1">  Air Cargo system in chaos (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/4.55.html#subj2">  ATM Cards Devoured (again!);  Royal Shakedowne for Tickets (Robert Stroud)</A>
<LI><A HREF="/Risks/4.55.html#subj3">  Re: Risks in the NSC computer archives (Carlton Hommel)</A>
<LI><A HREF="/Risks/4.55.html#subj4">  Re: A Scary Tale--Sperry Avionics ... (Kevin Driscoll)</A>
<LI><A HREF="/Risks/4.55.html#subj5">  Re: Altitude encoders: $1500 for Mode C?  No, $750. (Jordan Brown)</A>
<LI><A HREF="/Risks/4.55.html#subj6">  One more on fly/steer-by-wire (Jonathan Clark)</A>
<LI><A HREF="/Risks/4.55.html#subj7">  Steer-by-wire cars (Doug Rudoff)</A>
<LI><A HREF="/Risks/4.55.html#subj8">  Software Safety in ACM Computing Surveys (Daniel S. Conde) </A>
<LI><A HREF="/Risks/4.55.html#subj9">  Computerized `people meters' for TV audience ratings (Niall Mansfield)</A>
<LI><A HREF="/Risks/4.55.html#subj10">  More on Dallas Phone outage (Mark Linnig)</A>
<LI><A HREF="/Risks/4.55.html#subj11">  Soliciting suggestions for 1988 CSC panel on liability (Gene Spofford)</A>
<LI><A HREF="/Risks/4.55.html#subj12">  Conference on computing and society in Seattle -- REMINDER (Jon Jacky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.56.html">Volume 4 Issue 56 (5 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.56.html#subj1">  Computer problems produce false weather warnings (Mike Linnig)</A>
<LI><A HREF="/Risks/4.56.html#subj2">  Some postscript notes about Hurricane Iwa (Bob Cunningham)</A>
<LI><A HREF="/Risks/4.56.html#subj3">  Tempest Puget (Bill Roman)</A>
<LI><A HREF="/Risks/4.56.html#subj4">  Computer Aided Dispatching (James Roche)</A>
<LI><A HREF="/Risks/4.56.html#subj5">  Teflon flywheels and safe software (Hal Guthery)</A>
<LI><A HREF="/Risks/4.56.html#subj6">  Autoland and Conflict Alert (Alan M. Marcum)</A>
<LI><A HREF="/Risks/4.56.html#subj7">  Re: Air Traffic Control, Auto-Land (Amos Shapir)</A>
<LI><A HREF="/Risks/4.56.html#subj8">  Re: An aside on the B-1 (Henry Spencer)</A>
<LI><A HREF="/Risks/4.56.html#subj9">  Plane Crashes (David Purdue)</A>
<LI><A HREF="/Risks/4.56.html#subj10">  In defense of drive-by-wire (Mike McLaughlin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.57.html">Volume 4 Issue 57 (6 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.57.html#subj1">  Re: Air Traffic Control, Auto-Land (David Redell)</A>
<LI><A HREF="/Risks/4.57.html#subj2">  911, drive-fly by wire, risks, and the American work ethic (Wes Williams)</A>
<LI><A HREF="/Risks/4.57.html#subj3">  Re: drive by wire (Bennett Todd)</A>
<LI><A HREF="/Risks/4.57.html#subj4">  Autoland (Peter Ladkin)</A>
<LI><A HREF="/Risks/4.57.html#subj5">  Re: Puget Sound Ferry Boats (Bjorn Freeman-Benson)</A>
<LI><A HREF="/Risks/4.57.html#subj6">  Credit Card Limits (Clive Dawson)</A>
<LI><A HREF="/Risks/4.57.html#subj7">  NSA Monitored McFarlane House, Magazine Reports (Don Hopkins)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.58.html">Volume 4 Issue 58 (8 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.58.html#subj1">  The Sperry Plan, FAA Certification, and N-Version Programming (Nancy Leveson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.59.html">Volume 4 Issue 59 (8 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.59.html#subj1">  Safe software (Geraint Jones)</A>
<LI><A HREF="/Risks/4.59.html#subj2">  Computer Problem causes airline financial loss (Rob Horn)</A>
<LI><A HREF="/Risks/4.59.html#subj3">  Re: Altitude Encoders... expensive for some (Ronald J Wanttaja)</A>
<LI><A HREF="/Risks/4.59.html#subj4">  Influence of goal selection on safety (Henry Spencer)</A>
<LI><A HREF="/Risks/4.59.html#subj5">  Re: Puget Sound Ferry Boats     (Dennis Anderson, Robert Frankston, Bjorn Freeman-Benson)
</A>
<LI><A HREF="/Risks/4.59.html#subj6">  GOES satellites, Scotchbrite, Gnomic Maxims, and Mr. Bill (Martin Harriman)</A>
<LI><A HREF="/Risks/4.59.html#subj7">  Spreadsheet budget helping legislators (Scot E. Wilcoxon)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.60.html">Volume 4 Issue 60 (9 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.60.html#subj1">  Feel better now? (Martin Minow)  [Risk probabilities in nuclear power]</A>
<LI><A HREF="/Risks/4.60.html#subj2">  Computers in the Arts (or The Show Must Go On ...) (Jeannette Wing)</A>
<LI><A HREF="/Risks/4.60.html#subj3">  Sensitive Intelligence Document Published On Magazine Cover(Stevan Milunovic)</A>
<LI><A HREF="/Risks/4.60.html#subj4">  Mode-C Transponders (Phil R. Karn)</A>
<LI><A HREF="/Risks/4.60.html#subj5">  Physical risks and software risks (Eugene Miya)</A>
<LI><A HREF="/Risks/4.60.html#subj6">  Safe software (Scott E. Preece)</A>
<LI><A HREF="/Risks/4.60.html#subj7">  Helicopter rotor failures (Peter Ladkin)</A>
<LI><A HREF="/Risks/4.60.html#subj8">  Re: Electronic steering (D. V. W. James)</A>
<LI><A HREF="/Risks/4.60.html#subj9">  Altitude Encoders... expensive for some (Herb Lin)</A>
<LI><A HREF="/Risks/4.60.html#subj10">  F-104 (Elliott S. Frank)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.61.html">Volume 4 Issue 61 (10 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.61.html#subj1">  More on human errors (Brian Randell)</A>
<LI><A HREF="/Risks/4.61.html#subj2">  Re: Teflon flywheels and safe software (Brian Randell)</A>
<LI><A HREF="/Risks/4.61.html#subj3">  Re: Computers in the Arts (Alan Wexelblat, Jeffrey R Kell)</A>
<LI><A HREF="/Risks/4.61.html#subj4">  Local telephone service problems (Jonathan Thornburg)</A>
<LI><A HREF="/Risks/4.61.html#subj5">  Computer Failure Delays Flights at Atlanta Airport (PGN)</A>
<LI><A HREF="/Risks/4.61.html#subj6">  Ozone hole a false alarm? (Henry Spencer)</A>
<LI><A HREF="/Risks/4.61.html#subj7">  More on Requiring Mode C transponders (John Allred, Ken Calvert)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.62.html">Volume 4 Issue 62 (11 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.62.html#subj1"> "Software Safety: What, Why, and How" (Minireview by Jim Horning)</A>
<LI><A HREF="/Risks/4.62.html#subj2">  Beef with Restaurant's Hi-Tech Computer (Yigal Arens)</A>
<LI><A HREF="/Risks/4.62.html#subj3">  Electronic Steering (Mike Brown)</A>
<LI><A HREF="/Risks/4.62.html#subj4">  Enhanced 911 risks (Mike Brown)</A>
<LI><A HREF="/Risks/4.62.html#subj5">  Computers in the arts (Don Craig, Glenn Trewitt)</A>
<LI><A HREF="/Risks/4.62.html#subj6">  Mode C (Ken Calvert)</A>
<LI><A HREF="/Risks/4.62.html#subj7">  Re: Plane Crashes (Ronald J Wanttaja)</A>
<LI><A HREF="/Risks/4.62.html#subj8">  Re: Results of a recent security review (Arnold D. Robbins)</A>
<LI><A HREF="/Risks/4.62.html#subj9">  Risks of Maintaining RISKS -- and a reminder for BITNET readers (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.63.html">Volume 4 Issue 63 (12 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.63.html#subj1">  Re: Teflon flywheels and safe software (Al Mok)</A>
<LI><A HREF="/Risks/4.63.html#subj2">  Re: Electronic Steering (Bob Ayers)</A>
<LI><A HREF="/Risks/4.63.html#subj3">  Inputs For Quantitative Risk Assessment (Hal Guthery)</A>
<LI><A HREF="/Risks/4.63.html#subj4">  Re: Active car suspension (Geof Cooper)</A>
<LI><A HREF="/Risks/4.63.html#subj5">  Ozone hole a false alarm? (Mark Brader)</A>
<LI><A HREF="/Risks/4.63.html#subj6">  Phone problems (RISKs in auto-dialers) (David Barto)</A>
<LI><A HREF="/Risks/4.63.html#subj7">  Re: Mode C Transponders (Jan Wolitzky)</A>
<LI><A HREF="/Risks/4.63.html#subj8">  Automatic Landing Systems (Hugh LaMaster)</A>
<LI><A HREF="/Risks/4.63.html#subj9">  F-111 Losses (Rob Fowler)</A>
<LI><A HREF="/Risks/4.63.html#subj10">  Re: Computers in the Arts (Computer lighting) (Shannon Nelson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.64.html">Volume 4 Issue 64 (16 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.64.html#subj1">  Computer-lighting board nearly causes WWIII (Brent Laminack)</A>
<LI><A HREF="/Risks/4.64.html#subj2">  Computerized telephone sales pitch meets emergency broadcast number    (Brent Laminack)
</A>
<LI><A HREF="/Risks/4.64.html#subj3">  Furniture risks -- Vanishing Diskettes (Lee Breisacher)</A>
<LI><A HREF="/Risks/4.64.html#subj4">  Reprise on the UK Government's ACARD Report (Brian Randell)</A>
<LI><A HREF="/Risks/4.64.html#subj5">  Last minute changes (Roy Smith)</A>
<LI><A HREF="/Risks/4.64.html#subj6">  Risk in ``High'' Financing (Michael Wester)</A>
<LI><A HREF="/Risks/4.64.html#subj7">  Risk at Crown Books (Scott R. Turner)</A>
<LI><A HREF="/Risks/4.64.html#subj8">  Human errors in computer systems -- another reference (Jack Goldberg)</A>
<LI><A HREF="/Risks/4.64.html#subj9">  Requests for War Stories in Scientific Programming (Dennis Stevenson)</A>
<LI><A HREF="/Risks/4.64.html#subj10">  TFR and F-111s (Eugene Miya)</A>
<LI><A HREF="/Risks/4.64.html#subj11">  An Open University Text Book (Brian Randell)</A>
<LI><A HREF="/Risks/4.64.html#subj12">  US NEWS article on 'Smart' Weapons - questions and concerns (Jon Jacky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.65.html">Volume 4 Issue 65 (19 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.65.html#subj1">  Largest computer crime loss in history? (Gary Kremen)</A>
<LI><A HREF="/Risks/4.65.html#subj2">  Health hazards of poorly placed CRT screens (Gregory Sandell)</A>
<LI><A HREF="/Risks/4.65.html#subj3">  Re: Computerized telephone sales pitch ... (Robert Frankston)</A>
<LI><A HREF="/Risks/4.65.html#subj4">  Re: phone key-pad speed vs accuracy (Andrew Klossner)</A>
<LI><A HREF="/Risks/4.65.html#subj5">  ATM experience (Joe Herman)</A>
<LI><A HREF="/Risks/4.65.html#subj6">  Computerized Telemarketing (Rob Aitken)</A>
<LI><A HREF="/Risks/4.65.html#subj7">  Submission impossible? (PGN)</A>
<LI><A HREF="/Risks/4.65.html#subj8">  Risk at Crown Books (Christopher Garrigues)</A>
<LI><A HREF="/Risks/4.65.html#subj9">  Altitude Encoders... expensive for some (Herb Lin)</A>
<LI><A HREF="/Risks/4.65.html#subj10">  RTD Ghost Story:  a Phantom Warehouse (Eric Nickell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.66.html">Volume 4 Issue 66 (22 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.66.html#subj1">  Question for Risks Readers on Overcoming Information Overload with Technology    (Dave Taylor)
</A>
<LI><A HREF="/Risks/4.66.html#subj2">  Fumes from PC's (Lauren Weinstein)</A>
<LI><A HREF="/Risks/4.66.html#subj3">  Re: health hazards of poorly placed CRT screens (Brinton Cooper)</A>
<LI><A HREF="/Risks/4.66.html#subj4">  How to lose your ATM card (Jan Kok)</A>
<LI><A HREF="/Risks/4.66.html#subj5">  Re: ATM experience (Bruce McKenney)</A>
<LI><A HREF="/Risks/4.66.html#subj6">  Re: Increased Telephone Switching Capabilities (Dan Graifer)</A>
<LI><A HREF="/Risks/4.66.html#subj7">  Releasing the phone line (edg)</A>
<LI><A HREF="/Risks/4.66.html#subj8">  Automatic dialing devices in Canada (Michael Wagner)</A>
<LI><A HREF="/Risks/4.66.html#subj9">  Overconfidence in Airplane Computers? (Ted Lee)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.67.html">Volume 4 Issue 67 (24 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.67.html#subj1">  Winch is the greatest risk in a theater? (Dave Wortman)</A>
<LI><A HREF="/Risks/4.67.html#subj2">  DC9 Computer Failure (Earl Boebert)</A>
<LI><A HREF="/Risks/4.67.html#subj3">  Health hazards associated with VDU use: eyestrain (John J. Mackin)</A>
<LI><A HREF="/Risks/4.67.html#subj4">  Who called? (Jerome M Lang)</A>
<LI><A HREF="/Risks/4.67.html#subj5">  Car Phone Intercept -- implications of captured data (Alex Dickinson)</A>
<LI><A HREF="/Risks/4.67.html#subj6">  Re: Increased Telephone Switching Capabilities (Michael Wagner)</A>
<LI><A HREF="/Risks/4.67.html#subj7">  Re: Telephone switches (Bjorn Freeman-Benson)</A>
<LI><A HREF="/Risks/4.67.html#subj8">  Re: ATM experience (Roy Smith)</A>
<LI><A HREF="/Risks/4.67.html#subj9">  Risks of ATM machines (Mike Linnig)</A>
<LI><A HREF="/Risks/4.67.html#subj10">  Bank troubles, M.E. magazine (David Chase)</A>
<LI><A HREF="/Risks/4.67.html#subj11">  Re: "The Choking Doberman..." (Elliott S. Frank)</A>
<LI><A HREF="/Risks/4.67.html#subj12">  Newspaper article on Audi 5000S (Mark Brader)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.68.html">Volume 4 Issue 68 (26 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.68.html#subj1">  Re: Health hazards associated with VDU use: eyestrain (Barry Gold)       ... and fluorescents (Re: <A HREF="/Risks/4.67.html">RISKS-4.67</A>) (Brad Davis)
       ... and related injuries (Jeremy Grodberg)
</A>
<LI><A HREF="/Risks/4.68.html#subj2">  Conference on Computers and Law (David G. Cantor)</A>
<LI><A HREF="/Risks/4.68.html#subj3">  Re: runaway motors (Don Lindsay)</A>
<LI><A HREF="/Risks/4.68.html#subj4">  The social implications of inadvertent broadcasts (Donn Seeley)</A>
<LI><A HREF="/Risks/4.68.html#subj5">  Re: Increased Telephone Switching Capabilities (Andrew Klossner)</A>
<LI><A HREF="/Risks/4.68.html#subj6">  Re: phone number of caller (Don Lindsay, Jeremy Grodberg)</A>
<LI><A HREF="/Risks/4.68.html#subj7">  Hang-ups (Paul Wilcox-Baker)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.69.html">Volume 4 Issue 69 (27 Mar 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.69.html#subj1">  Cellular phone fraud busts (thanks to Geoff Goodfellow)</A>
<LI><A HREF="/Risks/4.69.html#subj2">  "... and its fate is still unlearned..."; robotic exploration of Mars     (Martin Minow)
</A>
<LI><A HREF="/Risks/4.69.html#subj3">  Re: Returned mail -- "Host unknown" (Richard Schedler and PGN)</A>
<LI><A HREF="/Risks/4.69.html#subj4">  Re: Phone problems  (Larry E. Kollar)</A>
<LI><A HREF="/Risks/4.69.html#subj5">  Re: ATM experience (Brent Chapman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.70.html">Volume 4 Issue 70 (1 Apr 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.70.html#subj1">  Rocket Shot Down By Faulty ``Star Wars'' Weapon (Phil R. Karn)</A>
<LI><A HREF="/Risks/4.70.html#subj2">  ATMs, phones, health hazards, and other sundry subjects (PGN)</A>
<LI><A HREF="/Risks/4.70.html#subj3">  Computer Risks in Theatre (Warwick Bolam)</A>
<LI><A HREF="/Risks/4.70.html#subj4">  PC fumes (Dick King)</A>
<LI><A HREF="/Risks/4.70.html#subj5">  A real eye-catching headline (David Chase)</A>
<LI><A HREF="/Risks/4.70.html#subj6">  Risks of being fuzzy-minded (Ted Lee)  </A>
<LI><A HREF="/Risks/4.70.html#subj7">  ATM discussions (gins)</A>
<LI><A HREF="/Risks/4.70.html#subj8">  Re: ATM experience ... it actually gets worse (Allen Brown)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.71.html">Volume 4 Issue 71 (5 Apr 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.71.html#subj1">  Re: A real eye-catching headline -- nuclear safety      (Jerry Saltzer, Peter G. Neumann, Henry Spencer)
</A>
<LI><A HREF="/Risks/4.71.html#subj2">  A non-fail-safe ATM failure (Don Chiasson)</A>
<LI><A HREF="/Risks/4.71.html#subj3">  Fumes from computers and other electronic appliances (Richard Thomsen)</A>
<LI><A HREF="/Risks/4.71.html#subj4">  Open University Fire (Lindsay F. Marshall)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.72.html">Volume 4 Issue 72 (8 Apr 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.72.html#subj1">  New kind of computer-technology-related deaths? (PGN)</A>
<LI><A HREF="/Risks/4.72.html#subj2">  Conrail Sale Funds Transfer (Chuck Weinstock)</A>
<LI><A HREF="/Risks/4.72.html#subj3">  Re: "Inherently safe nuclear reactors" (Phil Ngai)</A>
<LI><A HREF="/Risks/4.72.html#subj4">  A different RISK? (in-flight control computers) (Peter Ladkin)</A>
<LI><A HREF="/Risks/4.72.html#subj5">  Fumes from computers and other electronic appliances (Mark W. Eichin)</A>
<LI><A HREF="/Risks/4.72.html#subj6">  VDT related skin cancer? (Chris Koenigsberg)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.73.html">Volume 4 Issue 73 (11 Apr 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.73.html#subj1">  Unintentional information dissemination (George W. Dinolt)</A>
<LI><A HREF="/Risks/4.73.html#subj2">  Computers &amp; Personal Privacy (Steve Thompson)</A>
<LI><A HREF="/Risks/4.73.html#subj3">  Air Traffic Control in the UK (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/4.73.html#subj4">  Air Traffic Control in the USA (PGN)</A>
<LI><A HREF="/Risks/4.73.html#subj5">  Re: "Inherently safe nuclear reactors" (Jim Carter)</A>
<LI><A HREF="/Risks/4.73.html#subj6">  Submarine reactor safety (Jim Hunt)</A>
<LI><A HREF="/Risks/4.73.html#subj7">  Re: A different RISK? (in-flight control computers) (Ronald J Wanttaja)</A>
<LI><A HREF="/Risks/4.73.html#subj8">  Risks"-taking" of in-flight control computers (Eugene Miya)</A>
<LI><A HREF="/Risks/4.73.html#subj9">  Software Risks with Cable TV (Walt Thode)</A>
<LI><A HREF="/Risks/4.73.html#subj10">  The UNIX rwall problem ["My Broadcast"] (Jordan K. Hubbard) </A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.74.html">Volume 4 Issue 74 (14 Apr 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.74.html#subj1">  Re: In-flight control computers (Henry Spencer)</A>
<LI><A HREF="/Risks/4.74.html#subj2">  Trojan Horse alert (Al Stangenberger)</A>
<LI><A HREF="/Risks/4.74.html#subj3">  The Limits of Software Reliability (Brian Randell)</A>
<LI><A HREF="/Risks/4.74.html#subj4">  Re: Conrail Sale Funds Transfer -- and a 747 overflow (Henry Spencer)</A>
<LI><A HREF="/Risks/4.74.html#subj5">  Re: VDT related skin cancer? (Henry Spencer)</A>
<LI><A HREF="/Risks/4.74.html#subj6">  Re: Open University Fire (Henry Spencer)</A>
<LI><A HREF="/Risks/4.74.html#subj7">  DES Second Review Notice [on the RISKS OF STANDARDS] (David M. Balenson)</A>
<LI><A HREF="/Risks/4.74.html#subj8">  Bank Computers (Not ATM's) (Ken Ross)</A>
<LI><A HREF="/Risks/4.74.html#subj9">  The Marconi Affair (Brian Randell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.75.html">Volume 4 Issue 75 (22 Apr 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.75.html#subj1">  Flight control risks (Peter Ladkin)</A>
<LI><A HREF="/Risks/4.75.html#subj2">  ``More on risky high-g piloting'' (Tom Perrine)</A>
<LI><A HREF="/Risks/4.75.html#subj3">  Checklist stops risks? (Joseph Beckman)</A>
<LI><A HREF="/Risks/4.75.html#subj4">  Radiation risk at airports? (Paul Stewart)</A>
<LI><A HREF="/Risks/4.75.html#subj5">  How to post a fake (Chuq Von Rospach, Rob Robertson)</A>
<LI><A HREF="/Risks/4.75.html#subj6">  Re: Bank Computers (Not ATMs) (Kuhn)</A>
<LI><A HREF="/Risks/4.75.html#subj7">  Correction to Conrail Sale Funds Transfer (Mark Brader)</A>
<LI><A HREF="/Risks/4.75.html#subj8">  "Reliability Theory Applied to Software Testing" (HP Journal)(Rich Rosenbaum)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.76.html">Volume 4 Issue 76 (22 Apr 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.76.html#subj1">  Risks of Warranties (Jim Horning)</A>
<LI><A HREF="/Risks/4.76.html#subj2">  Re: Checklist stops risks? (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/4.76.html#subj3">  Newer highly maneuverable planes on board and checklists (Eugene Miya)</A>
<LI><A HREF="/Risks/4.76.html#subj4">  Aircraft risks (Peter Ladkin)</A>
<LI><A HREF="/Risks/4.76.html#subj5">  Neutron beam detection (Scott Dorsey)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.77.html">Volume 4 Issue 77 (23 Apr 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.77.html#subj1">  'Hackers' hit the Jackpot  (Michael Bednarek)</A>
<LI><A HREF="/Risks/4.77.html#subj2">  Fidelity Mutual Funds Money Line feature (Chris Salander via Barry Shein)</A>
<LI><A HREF="/Risks/4.77.html#subj3">  VCRs, Telephones, and Toasters (Martin Ewing)</A>
<LI><A HREF="/Risks/4.77.html#subj4">  Checklists, Aircraft risks, and Neutrons (Eugene Miya)</A>
<LI><A HREF="/Risks/4.77.html#subj5">  Neutron Beams for Explosives Detection (Marco Barbarisi)</A>
<LI><A HREF="/Risks/4.77.html#subj6">  Forgery on Usenet (Brad Templeton)</A>
<LI><A HREF="/Risks/4.77.html#subj7">  Re: How to post a fake (Wayne Throop)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.78.html">Volume 4 Issue 78 (26 Apr 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.78.html#subj1">  Re: Fidelity Mutual Funds Money Line feature (Martin Ewing, Brint Cooper)</A>
<LI><A HREF="/Risks/4.78.html#subj2">  Re: Forgery on Usenet (Matt Bishop)</A>
<LI><A HREF="/Risks/4.78.html#subj3">  Re: VCRs, Telephones, and Toasters (Mark Jackson)</A>
<LI><A HREF="/Risks/4.78.html#subj4">  References on computer-professional certification (John Shore)</A>
<LI><A HREF="/Risks/4.78.html#subj5">  CPSR/Boston presentation: "Reliability and Risk"</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.79.html">Volume 4 Issue 79 (2 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.79.html#subj1">  Risks of RISKS resurgent -- CSL DEAD FOR THREE DAYS, STILL HALF DEAD</A>
<LI><A HREF="/Risks/4.79.html#subj2">  Re: Fidelity Mutual Funds Money Line feature (Amos Shapir)</A>
<LI><A HREF="/Risks/4.79.html#subj3">  Wheels up (Martin Minow)</A>
<LI><A HREF="/Risks/4.79.html#subj4">  Special Risk Assessment issue of 'Science' (Rodney Hoffman)</A>
<LI><A HREF="/Risks/4.79.html#subj5">  Radiation hazards to computers (Wm Brown III)</A>
<LI><A HREF="/Risks/4.79.html#subj6">  Neutron beam detection (Richard H. Lathrop)</A>
<LI><A HREF="/Risks/4.79.html#subj7">  Computer Database Blackmail by Telephone (Steve Summit)</A>
<LI><A HREF="/Risks/4.79.html#subj8">  Liability Law in the UK (Brian Randell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.80.html">Volume 4 Issue 80 (5 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.80.html#subj1">  Computer Risks at the Department of Transportation (PGN)</A>
<LI><A HREF="/Risks/4.80.html#subj2">  Computerized advertising network used to fence hot circuits (PGN)</A>
<LI><A HREF="/Risks/4.80.html#subj3">  EPROMS and "Wimpy" Energy Physics (Patrick Powell)</A>
<LI><A HREF="/Risks/4.80.html#subj4">  Re: Wheels up (Richard M. Geiger, Jerry Hollombe&gt;</A>
<LI><A HREF="/Risks/4.80.html#subj5">  Liability for software "unless you buy our method" (John Gilmore)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.81.html">Volume 4 Issue 81 (7 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.81.html#subj1">  Cadillac to recall 57,000 for computer problem (Chuq Von Rospach)</A>
<LI><A HREF="/Risks/4.81.html#subj2">  Public E-Mail Risks? (Brian M. Clapper)</A>
<LI><A HREF="/Risks/4.81.html#subj3">  Wheels up (and simulators) (Eugene Miya, Doug Faunt, Matt Jaffe)</A>
<LI><A HREF="/Risks/4.81.html#subj4">  Subject: Re: the Marconi deaths (an update) (Brian Randell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.82.html">Volume 4 Issue 82 (10 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.82.html#subj1">  Information Age Commission (PGN)</A>
<LI><A HREF="/Risks/4.82.html#subj2">  Another computer taken hostage (Joe Morris)</A>
<LI><A HREF="/Risks/4.82.html#subj3">  Larceny OF Computers, not BY Computers (Pete Kaiser)</A>
<LI><A HREF="/Risks/4.82.html#subj4">  Risks of superconductivity (Eugene Miya)</A>
<LI><A HREF="/Risks/4.82.html#subj5">  UK Liability Law (follow-up)  (Brian Randell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.83.html">Volume 4 Issue 83 (12 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.83.html#subj1">  Risks of sharing RISKS (Ted Lee)</A>
<LI><A HREF="/Risks/4.83.html#subj2">  Information Commission (Jim Anderson)</A>
<LI><A HREF="/Risks/4.83.html#subj3">  ``How a Computer Hacker Raided the Customs Service'' (Michael Melliar-Smith)</A>
<LI><A HREF="/Risks/4.83.html#subj4">  Computer thefts (Jerry Saltzer)</A>
<LI><A HREF="/Risks/4.83.html#subj5">  Bomb Detection by Nuclear Radiation (Michael Newbery)</A>
<LI><A HREF="/Risks/4.83.html#subj6">  Computer floods summer course registration at U. of Central Florida     (Mark Becker)
</A>
<LI><A HREF="/Risks/4.83.html#subj7">  A password-breaking program (Dean Pentcheff)</A>
<LI><A HREF="/Risks/4.83.html#subj8">  Sidelight on the Marconi Deaths (Lindsay F. Marshall)</A>
<LI><A HREF="/Risks/4.83.html#subj9">  Software Reliability book by Musa, Iannino and Okumoto (Dave Benson)</A>
<LI><A HREF="/Risks/4.83.html#subj10">  "The Whistle Blower" (Jeff Mogul, via Jon Jacky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.84.html">Volume 4 Issue 84 (12 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.84.html#subj1">  Re: Information Age Commission     (Herb Lin, Richard Cowan, Bob Estell, David LaGrone, Michael Wagner)
</A>
<LI><A HREF="/Risks/4.84.html#subj2">  Re: Information Age Commission; Summer Courses at UCF (William Brown III)</A>
<LI><A HREF="/Risks/4.84.html#subj3">  Re: A password-breaking program (Dean Pentcheff, Jerry Saltzer, Dave Curry)</A>
<LI><A HREF="/Risks/4.84.html#subj4">  Re: Computer thefts (Michael Wagner)</A>
<LI><A HREF="/Risks/4.84.html#subj5">  Re: Computer-related Cadillac recall (Jeffrey R Kell)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.85.html">Volume 4 Issue 85 (14 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.85.html#subj1">  Holiday reading (Jim Horning)</A>
<LI><A HREF="/Risks/4.85.html#subj2">  Hey, buddy, wanna buy a phone call cheap? (PGN)</A>
<LI><A HREF="/Risks/4.85.html#subj3">  Re: Information Age Commission (Ted Lee, SEG)</A>
<LI><A HREF="/Risks/4.85.html#subj4">  Information Age Commission and the number of readers of RISKS (David Sherman)</A>
<LI><A HREF="/Risks/4.85.html#subj5">  Lockable computers (Pat Hayes)</A>
<LI><A HREF="/Risks/4.85.html#subj6">  How a Computer Hacker Raided the Customs Service -- Abstrisks (a nit)     (Paul F Cudney) 
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.86.html">Volume 4 Issue 86 (18 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.86.html#subj1">  ATM Fraud (Chuck Weinstock)</A>
<LI><A HREF="/Risks/4.86.html#subj2">  Between Iraq and a Hard Place [Protect Your Phalanx] (William D. Ricker)</A>
<LI><A HREF="/Risks/4.86.html#subj3">  Wozniak Scholarship for Hackers (Martin Minow)</A>
<LI><A HREF="/Risks/4.86.html#subj4">  Information Overload and Technology? (David Chess)</A>
<LI><A HREF="/Risks/4.86.html#subj5">  Passwords, thefts (Andrew Burt)</A>
<LI><A HREF="/Risks/4.86.html#subj6">  Passwords, sexual preference and statistical coincidence? (Robert W. Baldwin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.87.html">Volume 4 Issue 87 (20 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.87.html#subj1">  Computer Libel: A New Legal Battlefield (PGN from Digital Review)</A>
<LI><A HREF="/Risks/4.87.html#subj2">  Electric chair tested by car insurer (Bill Fisher from Machine Design)</A>
<LI><A HREF="/Risks/4.87.html#subj3">  Computers and Open Meetings laws (Barbara Zanzig)</A>
<LI><A HREF="/Risks/4.87.html#subj4">  Re: Phalanx (Chuck Weinstock)</A>
<LI><A HREF="/Risks/4.87.html#subj5">  Choosing a password (Jonathan Bowen)</A>
<LI><A HREF="/Risks/4.87.html#subj6">  Re: Passwords, thefts (Michael Wagner)</A>
<LI><A HREF="/Risks/4.87.html#subj7">  Nuclear Plant Emergency Plan: In Event of Quake, Smash Toilets    (UPI via Don Hopkins, Michael Grant, and Geoff Goodfellow)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.88.html">Volume 4 Issue 88 (21 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.88.html#subj1">  Re: Phalanx (Phil Ngai)</A>
<LI><A HREF="/Risks/4.88.html#subj2">  Open meeting laws (Dave Parnas)</A>
<LI><A HREF="/Risks/4.88.html#subj3">  Concerning UN*X (in)security (Mike Carlton)</A>
<LI><A HREF="/Risks/4.88.html#subj4">  Ed Joyce, Software Bugs: A Matter of Life and Liability (Eugene Miya)</A>
<LI><A HREF="/Risks/4.88.html#subj5">  Risks and system pre-login banners (PGN)</A>
<LI><A HREF="/Risks/4.88.html#subj6">  Risks of Running RISKS, Cont'd. (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.89.html">Volume 4 Issue 89 (24 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.89.html#subj1">  Factory Robots Killing Humans, Japan Reports (PGN)</A>
<LI><A HREF="/Risks/4.89.html#subj2">  Mysterious BART power outage (PGN)</A>
<LI><A HREF="/Risks/4.89.html#subj3">  More on the Master Password attack (PGN)</A>
<LI><A HREF="/Risks/4.89.html#subj4">  Measures, countermeasures, and under-the-countermeasures (PGN)</A>
<LI><A HREF="/Risks/4.89.html#subj5">  Phalanx (Scott Dorsey, Henry Spencer)</A>
<LI><A HREF="/Risks/4.89.html#subj6">  rhosts (Anthony A. Datri)</A>
<LI><A HREF="/Risks/4.89.html#subj7">  Computer Bill of Rights (Eugene Miya)</A>
<LI><A HREF="/Risks/4.89.html#subj8">  Credit Information Access (Ron Heiby)</A>
<LI><A HREF="/Risks/4.89.html#subj9">  Open meeting laws (Jonathan Handel)</A>
<LI><A HREF="/Risks/4.89.html#subj10">  Privacy and Email - The Law Takes Notice (Jerry Leichter)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.90.html">Volume 4 Issue 90 (25 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.90.html#subj1">  Laser guided missiles... (Herb Lin)</A>
<LI><A HREF="/Risks/4.90.html#subj2">  Computer use costs civil servants $1,270 (Matthew Kruk)</A>
<LI><A HREF="/Risks/4.90.html#subj3">  Liability in Expert Systems (David Chase)</A>
<LI><A HREF="/Risks/4.90.html#subj4">  Electronic Communications Privacy Act (Dave Curry)</A>
<LI><A HREF="/Risks/4.90.html#subj5">  ATM security (Kenton Abbott Hoover via Martin Minow)</A>
<LI><A HREF="/Risks/4.90.html#subj6">  Communications Technology Aids Criminals (Larry Lippman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.91.html">Volume 4 Issue 91 (28 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.91.html#subj1">  Electromagnetic Interference in Japan (Lindsay F. Marshall) </A>
<LI><A HREF="/Risks/4.91.html#subj2">  Risk of Inappropriate Technology to Prevent Password Overwrite     (Paul Stachour)
</A>
<LI><A HREF="/Risks/4.91.html#subj3">  Passwords and Statistics (Earl Boebert)</A>
<LI><A HREF="/Risks/4.91.html#subj4">  Why Cellular phones at the Indy 500? (Robert Adams)</A>
<LI><A HREF="/Risks/4.91.html#subj5">  Information Security Products and Services Catalog by NSA (Kurt F. Sauer)</A>
<LI><A HREF="/Risks/4.91.html#subj6">  Re: TRW "Credentials" (John R. Levine)   [Other messages overlapped, omitted]</A>
<LI><A HREF="/Risks/4.91.html#subj7">  Phalanx Schmalanx (PGN, Mike Trout, Torkil Hammer)</A>
<LI><A HREF="/Risks/4.91.html#subj8">  Laser guides (Jon A. Tankersley)</A>
<LI><A HREF="/Risks/4.91.html#subj9">  Re: Risks of running Risks (Jeff Woolsey, Will Martin)</A>
<LI><A HREF="/Risks/4.91.html#subj10">  Re: Computer thefts (David Phillip Oster)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.92.html">Volume 4 Issue 92 (30 May 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.92.html#subj1">  Computer matching of cats and dachshunds (Rick Kuhn)</A>
<LI><A HREF="/Risks/4.92.html#subj2">  Electromagnetic Interference (EMI) &amp; Liability (Richard S D'Ippolito)</A>
<LI><A HREF="/Risks/4.92.html#subj3">  Horror story about inadvertent wiretapping (Gordon Davisson)</A>
<LI><A HREF="/Risks/4.92.html#subj4">  ATM fraud (Bob Johnson)</A>
<LI><A HREF="/Risks/4.92.html#subj5">  Computer thefts (Mike Alexander, Brint Cooper)</A>
<LI><A HREF="/Risks/4.92.html#subj6">  Shooting Down Exocet Missiles (Mark S. Day)</A>
<LI><A HREF="/Risks/4.92.html#subj7">  Phalanx is unreliable? (Lorenzo Strigini)</A>
<LI><A HREF="/Risks/4.92.html#subj8">  Stark Incident (Eugene Miya)</A>
<LI><A HREF="/Risks/4.92.html#subj9">  Technical error in item "Phalanx Schmalanx" (Mark Brader)</A>
<LI><A HREF="/Risks/4.92.html#subj10">  Phalanx; Laser guides (Phil Ngai)</A>
<LI><A HREF="/Risks/4.92.html#subj11">  Laser guided anti-tank weapons (Eugene Miya)</A>
<LI><A HREF="/Risks/4.92.html#subj12">  Unfair testing (Paul Peters)</A>
<LI><A HREF="/Risks/4.92.html#subj13">  "Credentials", Privacy, etc. (Willis Ware, Alan R. Katz)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.93.html">Volume 4 Issue 93 (1 Jun 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.93.html#subj1">  Soviet Air Defense Penetration (Martin Minow, Eugene Miya)</A>
<LI><A HREF="/Risks/4.93.html#subj2">  Exocet, PHALANX, chaff, and missile defense (Sean Malloy)</A>
<LI><A HREF="/Risks/4.93.html#subj3">  Re: Phalanx Schmalanx (Mike Iglesias)</A>
<LI><A HREF="/Risks/4.93.html#subj4">  Re: Computer thefts (Brian Matthews)</A>
<LI><A HREF="/Risks/4.93.html#subj5">  TRW's Credentials (Jonathan Handel)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.94.html">Volume 4 Issue 94 (2 Jun 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.94.html#subj1">  Australian Computer Crime (Donn Parker)</A>
<LI><A HREF="/Risks/4.94.html#subj2">  PCs and Computer Fraud (PC Week via PGN)</A>
<LI><A HREF="/Risks/4.94.html#subj3">  Technological vs. (?) human failure (Nancy Leveson)</A>
<LI><A HREF="/Risks/4.94.html#subj4">  Risk of Inappropriate Technology to Prevent Password Overwrite(Henry Spencer)</A>
<LI><A HREF="/Risks/4.94.html#subj5">  A twist on modems calling people (Steve Valentine)</A>
<LI><A HREF="/Risks/4.94.html#subj6">  Risks of Compulsive Computer Use (Steve Thompson)</A>
<LI><A HREF="/Risks/4.94.html#subj7">  Perhaps the Bill of Rights you sought? (Bruce Wisentaner)</A>
<LI><A HREF="/Risks/4.94.html#subj8">  Error(s) in "Phalanx Schmalanx" (Mike Trout)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.95.html">Volume 4 Issue 95 (3 Jun 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.95.html#subj1">  COMPASS '87, of particular interest to the RISKS audience (Stan Rifkin)</A>
<LI><A HREF="/Risks/4.95.html#subj2">  Re: Run-time checks (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/4.95.html#subj3">  Risks of Inappropriate Technology to Prevent Password Overwrites     (Michael Robinson)
</A>
<LI><A HREF="/Risks/4.95.html#subj4">  Clarification of PL/I array checking (Michael Wagner)</A>
<LI><A HREF="/Risks/4.95.html#subj5">  Risks for computer junkies (Robert Hartman)</A>
<LI><A HREF="/Risks/4.95.html#subj6">  Re: When Computers Ruled the Earth (Bank Stupidity) (Ed Sachs)</A>
<LI><A HREF="/Risks/4.95.html#subj7">  Clarification on CHAPPARAL and VULCAN (Bill Gunshannon) </A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/4.96.html">Volume 4 Issue 96 (6 Jun 87)</A>
<DD><UL>
<LI><A HREF="/Risks/4.96.html#subj1">  Lightning Strikes Twice At NASA (Matthew P Wiener)</A>
<LI><A HREF="/Risks/4.96.html#subj2">  Iraqi cockpit navigation system placed Stark in exclusion zone? (Jon Jacky)</A>
<LI><A HREF="/Risks/4.96.html#subj3">  Run-time checks    (Howard Sturgis, Henry Spencer, James M. Bodwin, Alan Wexelblat)
</A>
<LI><A HREF="/Risks/4.96.html#subj4">  Error Checking and Norton's Assembly Language Book (James H. Coombs)</A>
<LI><A HREF="/Risks/4.96.html#subj5">  Re: Risks of Compulsive Computer Use (Douglas Jones)</A>
<LI><A HREF="/Risks/4.96.html#subj6">  A reference on Information Overload; a Paradox of Software (Eugene Miya)</A>
<LI><A HREF="/Risks/4.96.html#subj7">  Computerholics (James H. Coombs)</A>
<LI><A HREF="/Risks/4.96.html#subj8">  Naval Warfare -- on possible non-detonation of missiles (Mike McLaughlin)</A>
</UL></DL>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/5/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-115</DOCNO>
<DOCOLDNO>IA012-000123-B019-297</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.2.html 128.240.150.127 19970217003059 text/html 5862
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:29:31 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/3.01.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 2</H1>
<H2> Thursday, 5 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Are SDI Software predictions biased by old tactical software? 
</A>
<DD>
<A HREF="#subj1.1">
Herb Lin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Are SDI Software predictions biased by old tactical software?
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 5 Jun 1986  01:58 EDT
</i><PRE>

      [Since Herb was evidently up late, since I was up late also, and
       since distribution of this message may stave off many overlapping
       responses to Bob Estell and prompt many rebuttals as well, it seems
       appropriate to distribute this response from Herb Lin as a special
       one-message issue that you can read along with RISKS-3.1.  SDI is 
       probably one of the most significant debate subjects of our lifetimes
       and deserves thorough coverage.  Yes, it does mix politics and
       technology.  It must.  There is simply no other way.  So, don't be
       UP IN ARMS-D.  But let us keep any subsequent discussion cogent and
       sensible.  PGN]

    From: &lt;estell at nwc-143b&gt;

    ...  At some personal risk, let me say at the outset that SDI, 
    as ballyhooed in the popular press, may never work - certainly not in this 
    decade.  

It is NOT the public press that says that SDI will create a perfect
defense.  It is the President and the Secretary of Defense.

    ...Similarly, one errant 
    SDI computer need not fail the entire network - anymore than one failing
    IMP need crash the entire ARPANET.

That point has never been made by the critics either.  The problem is
not that it WOULD, but that some fundamental design error COULD fail
the entire system.  There is no way to rule that out.

    ...  A missile defense is worth having if it is good 
    enough to save only 5% of the USA population in an all-out nuclear attack.

Not necessarily true.  If having a defense that can kill 5% of the
current Soviet threat prompts the Soviets to increase their missile
force by a factor of two, we are not better off, and the missile
defense would not be worth having.

   That shield might save 75% of the population in a terrorist attack, launched
   by an irresponsible source; this is far more likely than a saturation attack
   by a well armed power like the USSR.  

Where will the Libyans get even one ICBM?  Besides, we NOW have the
capability to build defenses against one missile aimed against the US,
and we don't need SDI for that.  We solved that problem in the 1960's.
The hard problem is the saturation attack.

    ... I am saying that if we don't try, we won't progress...

    But my point is that we must not shun the challenge to TRY to improve the
    software in the field, and the tools used to design and build and test it.

But if trying makes war and nuclear buildups more likely, then we may
not progress either.  Actions are taken or not taken in a context;
most responsible critics of SDI argue that there is a downside to
"just doing research".  That downside has to be evaluated.

Specifically, a system that works with questionable reliability or
effectiveness is most useful in the aftermath of a thinned-out
retaliatory blow, i.e., one that most closely resembles your terrorist
attack.  Thus, it is not unreasonable to interpret the building of
defenses as an offensive act.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-116</DOCNO>
<DOCOLDNO>IA012-000123-B019-321</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.3.html 128.240.150.127 19970217003115 text/html 12427
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:29:40 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 3</TITLE>
<LINK REL="Prev" HREF="/Risks/3.02.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.04.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 3</H1>
<H2> Friday, 6 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Watch this Space 
</A>
<DD>
<A HREF="#subj1.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Unshakeable Faith in Technology 
</A>
<DD>
<A HREF="#subj2.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  SDI as a defense against terrorists?             
</A>
<DD>
<A HREF="#subj3.1">
Bruce Wampler
</A><br>
<A HREF="#subj3.2">
 Martin Moore
</A><br>
<A HREF="#subj3.3">
 Bernie Gunther
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Basis for SDI Assumptions? 
</A>
<DD>
<A HREF="#subj4.1">
Herb Lin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Watch this Space
</A>
</H3>
<address>
Eugene miya 
&lt;<A HREF="mailto:eugene@ames-aurora">
eugene@ames-aurora
</A>&gt;
</address>
<i>
5 Jun 1986 1910-PDT (Thursday)
</i><PRE>

The following is a personal observation and not an opinion of my employer.

Next week the President's Commission will be reporting its findings on the
Challenger incident.  Already leaks have occurred, and I find some of them
in Time magazine.  While I cannot completely comment on the bureaucracy
problems in NASA, it is interesting to note that part of the solution to the
launch decision problem is adding more members (contractors and astronauts)
to the final launch decision process.  There is an irony to that.  One on
hand we have been trying to reduce bureaucracy, to make committees smaller,
and so forth, and one would ideally have astronauts and contractors
"represented" by a "good" bureaucrat, and yet the solution is to increase
the size and complexity of some committees.  Yes, safety should be first,
but how do you achieve safety?  Or should I say achieve safety and balance
it with complexity?

This complexity actually has another system to compare it to: SDI.  I don't
want to completely open a can of worms, but we should keep our eyes open on
this other space program and see how it handles complexity in contrast the
to manned space program.  Several weeks ago, Danny Cohen at USC-ISI reported
somewhere (I thought it was Science, but I saw it in stronger language) that
SDI developers (i.e., the aerospace community) have been very conservative
about their use of computers and that SDI needs the state-of-the-computing-art.
Cohen said something to the effect that we have to push aerospace companies
to use the most advanced computing techniques available.  Space companies
have always tried to use tried-and-true technologies and have varied them
only one slow degree at a time.  I would like to point out to the
readerships of both the space and risks digests that these two different
forces are now acting upon companies like Lockheed, Rockwell, and so forth,
and it will be interesting to watch how they develop.

Both systems are quite complex, conservative to some degree, but supposedily
diverging forces are pushing for more conservativism and less conservatism.

From the Rock of Ages Home for Retired Hackers:

--eugene miya
  NASA Ames Research Center
  eugene@ames-aurora.ARPA
  "You trust the `reply' command with all those different mailers out there?"
  {hplabs,hao,dual,ihnp4,decwrl,allegra,tektronix,menlo70}!ames!aurora!eugene

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Unshakeable Faith in Technology
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 5 Jun 1986  09:35 EDT
</i><PRE>

A small consolation is that the SDI advocates no longer use the
Shuttle as an example of the finest in American technology.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
SDI as a defense against terrorists?
</A>
</H3>
<address>
Bruce Wampler
&lt;<A HREF="mailto:unmvax!wampler@ucbvax.Berkeley.EDU ">
unmvax!wampler@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Thu, 5 Jun 86 09:58:58 mdt
</i><PRE>

	Offense is much easier than defense.  The mention of terrorists
brings to mind an obvious BIG hole in the whole SDI concept.  If I were a
terrorist (or even the USSR after some SDI was in place), I'd take a serious
look at the wide open U.S. society, the thousands of miles of shoreline and
the leaky borders with Mexico and Canada.  Why bother trying to get through
a massive defense system (as unreliable as it might be) when you can land a
boat or drive a pickup across the border with a nuclear device and plant it
under City Hall in Anytown, USA?  And if anyone has any doubts, just take a
look at the unstoppable influx of drugs and illegal aliens.

	Maybe what SDI should really be is a big perimeter around our
borders to stop such things.  Now if someone can just get the algorithm
to distinguish heroin, aliens, and plutonium...

Dr. Bruce E. Wampler
University of New Mexico
Department of Computer Science
Albuquerque, NM 87131

..{ucbvax | seismo!gatech | ihnp4!lanl}!unmvax!wampler

</PRE>
<HR><H3><A NAME="subj3.2">
SDI as a defense against terrorists?
</A>
</H3>
<address>

&lt;<A HREF="mailto:mooremj@eglin-vax">
mooremj@eglin-vax
</A>&gt;
</address>
<i>
6 Jun 86 08:25:00 CDT        [Hooray.  A Date Appears!]
</i><PRE>
To: "risks" &lt;risks@sri-csl&gt;

At the risk of beating a dead horse, I would like to take issue with this
statement by Bob Estell:

&gt;That shield might save 75% of the population in a terrorist attack, launched
&gt;by an irresponsible source; this is far more likely than a saturation attack
&gt;by a well armed power like the USSR.  

The risk of such an attack (a terrorist attack with an ICBM) is nearly 
nonexistent.  In the first place, it is a lot easier and cheaper to perform
a terrorist attack, even a big one, with nothing more exotic than conventional
explosives; consider, e.g., the destruction of the two main water conduits 
serving New York City (I just read a mediocre novel with this as its premise.)

Secondly, even if the terrorists decide to go the exotic route, chemical or
biological weapons are much easier to produce (or otherwise obtain) and 
deliver.  Several years ago someone mailed packages of white powder to various
DoD sites.  The powder was the crystalline form of Lance, a nerve gas; tasting
the powder would cause instant death and smelling it would cause permanent
brain damage.

Thirdly, even if the terrorists decide they just *have* to use an atomic bomb,
it is much more practical to either build it in place (see "Build Your Own
A-Bomb and Wake Up the Neighborhood" by George W. Harper in the April 1979
issue of _Analog_) or to deliver it by more conventional methods (probably
ship, but possibly airplane.)  It is much harder to build an effective
ICBM than it is to build an effective A-bomb; a crude bomb will still do the
job, but a crude ICBM will most certainly miss your target, assuming that it
doesn't blow up in your face first. 

Finally, even if the terrorists somehow managed to obtain a few missiles
with H-bombs attached, nowhere near 25% of the US population would be 
endangered.  At a guess, the smallest area containing 25% of the population
would be the entire Boston-Washington strip, with Los Angeles, Chicago, and
Atlanta (I've never liked Atlanta) thrown in for good measure.  It would
take a *lot* of bombs accurately delivered to kill 25% of the population.
Furthermore, as Herb Lin pointed out, the technology is already there to
defend against limited attacks.

				Martin Moore (mooremj@eglin-vax.arpa)

</PRE>
<HR><H3><A NAME="subj3.3">
SDI as a defense against terrorists?
</A>
</H3>
<address>
&lt;<A HREF="mailto:mck-csc!bmg@EDDIE.MIT.EDU">
mck-csc!bmg@EDDIE.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 6 Jun 86 10:47:36 EDT
</i><PRE>

Libya will soon be able to buy an ICBM from Brazil.  I read this in a
recent article in either Time magazine or the New York Times.  

How about a single missle from Cuba?

Bernie Gunther


</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Basis for SDI Assumptions?
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@xx.lcs.mit.edu">
LIN@xx.lcs.mit.edu
</A>&gt;
</address>
<i>
Fri, 6 Jun 1986  09:23 EDT
</i><PRE>
ReSent-To: risks@SRI-CSL.ARPA

    From: bcsaic!douglas at uw-june &lt;Doug Schuler at uw-june&gt; [...]
    What is the story on the software for the Sargent York gun?  Was a "high
    level" language used? If so, and the complexity still defeated the project,
    it bodes ill for SDI which consists of [the logical equivalent of?]
    thousands (hundreds?) of Sargent York guns launched into space.  If a
    high-level language was used, there is still life in the "historical"
    argument described by Bob Estell.

I don't think the Divad failed because of software, if software is
construed in the narrow sense of improperly written lines of code.
However, the problem WAS a system integration problem, and thus does
have some relevance to software issues.  The stated reason for Divad's
failure was that it was unable to hit Soviet choppers at long enough
range.

Consider the time that Divad shot at a latrine fan during a test, looking
for the rotating blades of a helicopter.  The Divad radar looked for a
particular Doppler shift in the return signal, and you can imagine how the
fan could mimic a helicopter blade.  Is this a software problem?  It seems
to me that you could argue it both ways, but in either case, I don't think
the presence of a high-level programming language would have helped.

     [Flawed algorithms often appear as "undependable" software, although
      they can of course equally well be embedded in hardware.  We should 
      not try to make too much of the hardware-software distinction.  The
      "blame" usually rests on the shortcomings of the designers and 
      implementers...  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-117</DOCNO>
<DOCOLDNO>IA012-000123-B020-9</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.4.html 128.240.150.127 19970217003245 text/html 13996
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:29:57 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 4</TITLE>
<LINK REL="Prev" HREF="/Risks/3.03.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.05.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 4</H1>
<H2> Monday, 9 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Watch this Space 
</A>
<DD>
<A HREF="#subj1.1">
Mark Jackson
</A><br>
<A HREF="#subj1.2">
 Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Software developer's liability 
</A>
<DD>
<A HREF="#subj2.1">
Paul Schauble
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  What an Algorithm!! 
</A>
<DD>
<A HREF="#subj3.1">
Brian Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Sgt. York's Latrine, and other stories 
</A>
<DD>
<A HREF="#subj4.1">
Mike McLaughlin
</A><br>
<A HREF="#subj4.2">
 Ken Laws
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Watch this Space (RISKS-3.3)
</A>
</H3>
<address>
&lt;<A HREF="mailto:MJackson.Wbst@Xerox.COM">
MJackson.Wbst@Xerox.COM
</A>&gt;
</address>
<i>
9 Jun 86 10:57:10 EDT (Monday)
</i><PRE>
To: Eugene Miya &lt;eugene@ames-aurora.ARPA&gt;
cc: RISKS@SRI-CSL.ARPA

Your comments on the conflict between reducing bureaucracy and increasing
the number of persons in the loop take us rather far afield from the risks
of computer use...but they are similar to some concerns I've had for some
time, and the "complexity" issue has relevance to this list, so what the heck.

In my opinion one of the *major* challenges facing humans is the need to
find better ways of structuring organizations, and training individuals to
function within organizations.  Our present performance ranges from barely
adequate to abysmal; the current consequences of this performance level are
extremely serious, and the prospects are that these consequences will get
worse.  Blindly intoning "we need less bureaucracy" is no help.

Those are strong statements; let me explain.  When the number of persons
necessary to an enterprise rises much above that appropriate to a single
work-group some *organizational* as opposed to *individual* division of
responsibility becomes necessary.  (Xerox doesn't build copiers by getting
several thousand employees together, telling them all to "build copiers at a
profit," and leaving them to their own devices thereafter.)  As the
compartmentalization of the organization increases, the relationship between
the output of each unit and the goals of the organization becomes less
clear.  "Do your job right" becomes an unsatisfactory performance criterion;
specifications become of necessity more formal.  It becomes possible for
individuals or sub-organizations to prosper by appearing to meet proper
criteria, or by actually meeting improper criteria; such performance may
actually hinder the successful fulfillment of the intended organizational
goals.  Individual behavior tends toward that which is *actually* rewarded
by the organization, as opposed to that which is *stated* to be desired.
It's like entropy; all the forces are toward declining performance, and
because it's a coupled (people/structure) problem the trends are extremely
difficult to reverse.

It is presently fashionable to point to the government as a bad example of
rampant bureaucracy.  This is to an extent fair; I believe there are two
reasons that the problem is generally worse in government than in the
business sector:

  1) We desire of our government that it be one of "laws not of men"; this
  requires formal specification of acceptable performance (laws and
  regulations).  If OSHA published simple, common-sense guidelines ("don't
  unduly endanger your employees") they'd be thrown out by the courts on
  the perfectly sound grounds that the proscribed behavior was undefined;
  instead we get five-page definitions of an acceptable ladder and such.

  2) The constraint on organizational reasonableness which acts on
  business (don't be so unprofitable as to go bankrupt) is somewhat
  stronger than that on government (don't be so expensive and unresponsive
  as to cause the voters to rebel).

But the differences are those of degree, not of kind; I suspect that #1
above is the more important, and I am extremely skeptical of those who
contend that a good dose of free enterprise will serve to solve, by
Darwinian selection, the organizational problem.  And the problem applies to
not-for-profit, military, and all other "large" organizations as well.

Draw what parallels with large hardware/software systems you wish; AI buffs
may note the analogy with the notorious difficulty of programming "common
sense", for example.

Mark

"Absolute truth?  What's that?"
"It's a five-to-four decision of the Supreme Court."
			-- Dan O'Neil

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Watch this Space (RISKS-3.3)
</A>
</H3>
<address>
Eugene miya 
&lt;<A HREF="mailto:eugene@ames-aurora.arpa">
eugene@ames-aurora.arpa
</A>&gt;
</address>
<i>
9 Jun 1986 1521-PDT (Monday)
</i><PRE>

I just came from a televising of Rogers and Fletcher (our own internal TV
feeds).  Permit me to clarify the forthcoming dilemma.  The matter is not
solely a problem of "bureaucracy."  "Bureaucracy" is an artifact, and the
word had a tainted denotation.  Another, perhaps clearer artifact would be
the trend in NASA from a centralized to a decentralized (NASA Centers really
became "Centers") and now back to a more centralized agency (command at NASA
HQ) versus the more decentralized approaches SDI (Cohen et al.) are proposing
(admitted automated).

  Aside:  Are automated bureaucracies any better than human bureaucracies?

The gist of what I hear Mr. Jackson saying is on the nature of organizing
complex systems (a la Simon's Sciences of the Artificial).  I would also
like to point out that Jacob Bronowski pointed out just before he died that
the great challenge facing humans was the balance of individuals (I
extrapolate to include centralized authority) to groups (decentralized).

The point of my posting was to note that we have an interesting juncture and
we should be prepared to note the different paths taken for future
comparisons (and future mis-intepresentations).  Another interesting
thought occurs to me about SDI, but that will be a separate note which I
will Cc: to Arms-d.

Again, the viewpoints expressed are personal and not views of the Agency.

From the Rock of Ages Home for Retired Hackers:

--eugene miya
  NASA Ames Research Center
  eugene@ames-aurora.ARPA
  "You trust the `reply' command with all those different mailers out there?"
  {hplabs,hao,dual,ihnp4,decwrl,allegra,tektronix,menlo70}!ames!aurora!eugene

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Software developer's liability
</A>
</H3>
<address>
 Paul Schauble 
&lt;<A HREF="mailto:Schauble@MIT-MULTICS.ARPA">
Schauble@MIT-MULTICS.ARPA
</A>&gt;
</address>
<i>
Sat, 7 Jun 86 23:29 EDT
</i><PRE>
To:  Info-Law@SRI-CSL.ARPA, Risks@SRI-CSL.ARPA

These two items are from the June 3, 1986 issue of PC WEEK.

  IRS I: The Internal Revenue Service has thrown a chill over the PC software
  business. It recently ruled that creators of computer programs that help
  taxpayers prepare their tax returns may be subject to penalties if the
  program gives bad advice. The ruling will put the software developers on the
  same footing as flesh-and-blood tax advisors:  at risk.

  IRS II: TCS Software of Houston is already in trouble with the IRS. The
  company was contacted by the IRS because its tax-preparation software
  program, Client Tax Series-1040, was listed as the tax preparer on the 1985
  tax return of one Richard P. Jamerson.

The IRS was up in arms because Mr. Jamerson had used a fictitious Social
Security number, hadn't included a check with the tax return, hadn't signed
the return or included a W-2 form.  Fortunately for TCS, Mr. Jamerson owes
no taxes since he doesn't exist.  He is the totally fictitious example that
goes out with the TCS package to show users how the software package works.
Apparently, one of the sample returns was inadvertently mailed to the IRS.

          Paul      Schauble at MIT-Multics.arpa

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
What an Algorithm!!
</A>
</H3>
<address>
Brian Bishop 
&lt;<A HREF="mailto:BISHOP@USC-ECL.ARPA">
BISHOP@USC-ECL.ARPA
</A>&gt;
</address>
<i>
Fri 6 Jun 86 14:37:26-PDT
</i><PRE>
To: risks@SRI-CSL.ARPA

&gt;-&gt;   	Maybe what SDI should really be is a big perimeter around our
&gt;-&gt; borders to stop such things.  Now if someone can just get the algorithm
&gt;-&gt; to distinguish heroin, aliens, and plutonium...

   I don't know about you, but I would be much more afraid of that algorithm 
than I would be of a Soviet nuclear attack. 

BfB

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Sgt. York's Latrine, and other stories
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Fri, 6 Jun 86 16:27:59 edt
</i><PRE>

The latrine fan story keeps going around and around.  The radar never saw a
latrine, much less one with a fan.  The Doppler return of a hypothetical fan
on a hypothetical latrine would differ significantly from the fans on a
helicopter.  The story is full of the same stuff as the latrine.  Let's not
fall into it again.
                     [Thanks, Mike.  You've got a lot of fans as we go
                      around in circles.  "Curses, Air-foiled again?"]

</PRE>
<HR><H3><A NAME="subj4.2">
Sgt York's Latrine
</A>
</H3>
<address>
Ken Laws 
&lt;<A HREF="mailto:Laws@SRI-AI.ARPA">
Laws@SRI-AI.ARPA
</A>&gt;
</address>
<i>
Mon 9 Jun 86 22:18:56-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

According to 60 Minutes (or was it 20/20?) the DIVAD did not shoot at a
latrine fan.  It was distracted by a small ventilation fan, but I'm not sure
that it even targeted on the thing.  The fan wasn't on a latrine; the
analogy to a bathroom fan was created by a PR man who was trying to explain
to reporters how small it was.  The "software problem" was much easier to
fix than the PR problem.

I'm an expert-systems enthusiast precisely because such bugs do crop up in
all real-world systems.  Expert systems "technology" is a form of
institutionalized hacking -- programming by successive approximation, or
debugging as part of the design effort rather than part of the maintenance
effort.  It's related to the pancake theory ("Plan to throw the first
version away.  You will anyway."), but goes deeper: plan to throw every
version away, but use the current one if you have to.

                  [Perhaps that is the radioactive pancake theory.
                  ("They're too hot to eat, but they're fun to make.
                  If you really get hungry there's always one ready,
                  and it's probably better than starving to death.")  PGN]

Effort continues on optimal algorithms and proofs of correctness, but too
often we optimize the wrong thing or omit real-life complexities from our
proofs.  (Computers are particularly vulnerable.  How do you prove that a
gamma-ray burst during a critical routine won't change a crucial bit?)
Those who build expert systems take the opposite tack: that systems will
always contain bugs, so each piece should be robust enough to function in
spite of numerous sources of uncertainty and error.  This is similar to the
renewed NASA policy that every critical shuttle system have a backup.  I
think it's a healthy viewpoint.
					-- Ken Laws

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-118</DOCNO>
<DOCOLDNO>IA012-000123-B020-27</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.5.html 128.240.150.127 19970217003300 text/html 11382
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:31:29 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 5</TITLE>
<LINK REL="Prev" HREF="/Risks/3.04.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.06.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 5</H1>
<H2> Tuesday, 10 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A powerful metal detector and magnetic personalities with bank cards     
</A>
<DD>
<A HREF="#subj1.1">
Matthew P. Wiener
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Shuttle Launch Decisions 
</A>
<DD>
<A HREF="#subj2.1">
Don Wegeng
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Estell's defense of SDI 
</A>
<DD>
<A HREF="#subj3.1">
Martin Purvis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Sgt. York's Latrine, and other stories 
</A>
<DD>
<A HREF="#subj4.1">
Mike McLaughlin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A powerful metal detector and magnetic personalities with bank cards 
</A>
</H3>
<address>
Matthew P. Wiener
&lt;<A HREF="mailto:weemba@brahms.berkeley.edu ">
weemba@brahms.berkeley.edu 
</A>&gt;
</address>
<i>
Sat, 7 Jun 86 02:27:54 pdt
</i><PRE>
To: risks@sri-csl.arpa

    [This item illustrates the need for awareness of the technology by people
     in the environment.  The interference problem is also relevant to RISKS.]

In the Thursday 5 June 1986 issue of The New York Times, there is an article
about an accident that occurred with a magnetic resonance imager--the first
serious accident of this type.

The device uses a huge magnet with a hollow cylinder for the patient to lie
inside.  The accident occurred in a converted semitrailer used for mobile
diagnosis.  A technician was in the hollow when two steel tines, weighing
more than 80 pounds each, were ripped off by the magnet from an
(intentionally) approaching forklift, and ended up knocking the man 15 feet
away, and breaking many bones.

The magnet complicated rescue work.  A doctor could not approach until he
removed his stethoscope.  A paramedic's scissors flew off when he tried to
cut the injured man's pants.  A policeman nearly had his gun pulled from his
holster.  Rescuers were slow to grasp just how strong the magnetic field
was, and to realize that all metal objects had to be removed in order to
approach the injured.  And finally--here's where the computer connection
comes in!--the magnetic bank cards of the rescuers were erased.

The magnet's emergency shutdown could not be used, as it hadn't been fully
installed yet.  So it took 20 minutes instead.

The article pointed out that in normal usage these difficulties are not
present, as normally special equipment is used and all nearby personnel are
familiar with its power.  But as revealed by the accident, emergency workers
do not have such training.  (They also do not have training for lots of
special and exotic situations.  There is a certain iatrogenic irony
in this situation -- which is not uncommon in medical practice.)

          ["Iatrogenic" implies that a problem is caused or made worse
            inadvertently by doctors and/or medicine in what might 
            otherwise be perceived as an attempted cure or improvement.
            [[As a result, one suffers from inadvertigo?]]  The use of
            "irony" seems like an attractive pun in this context.  
            Thanks.  PGN]

Note--some details are slightly unclear from the article I read.  If anyone
wants more details, you are referred to a recent letter in The New England
Journal of Medicine, by(?) Drs. Syverud and Fowler.   -Matthew

ucbvax!brahms!weemba	Matthew P Wiener/UCB Math Dept/Berkeley CA 94720

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Shuttle Launch Decisions
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
10 Jun 86 09:00:41 EDT (Tuesday)
</i><PRE>
To: RISKS@SRI-CSL.ARPA
From: dw &lt;Wegeng.Henr@Xerox.COM&gt;

After watching the reports on TV giving the conclusions of the Rogers
Commission, a question occurred to me that may be relevant to Risks. A lot
of attention has been given to the fact that some of the rocket engineers
recommended against launching the Challenger. What I haven't heard anyone
talk about is whether such recommendations before a launch were common. The
media coverage has always implied that the engineer's protests were an
unusual event, but is this really the case? I can easily imagine a scenario
where before every launch a different engineer recommends against launching,
but management decides that their reasons are not adequate (after all, one
of management's jobs is to evaluate such recommendations) and goes ahead and
launches as scheduled. After awhile the situation might become similar to
the little boy who cried wolf.

I'm not trying to defend NASA, or implying that the above scenario
describes the situation. I'm just trying to understand the context of
their decision to launch Challenger. Can anyone shed any light on this?

/Don
       [I hope one of our readers can respond.  With regard to the software
        problems, there have been complaints that the new mission software
        was frequently delivered only at the very last minute, and that no
        extensive simulation testing could be done.  The impression is given
        that whatever the state of the software was at the final scheduled
        delivery date, that is what was delivered -- irrespective of how
        buggy it might be.  I think it would be very helpful to understand
        the circumstances better.  Tasteful reports on this subject -- as
        well as the more general question raised by Don -- would be welcome.
        PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Estell's defense of SDI
</A>
</H3>
<address>
&lt;<A HREF="mailto:CS.PURVIS@R20.UTEXAS.EDU">
CS.PURVIS@R20.UTEXAS.EDU
</A>&gt;
</address>
<i>
Tue 10 Jun 86 21:57:50-CDT
</i><PRE>
To: risks@SRI-CSL.ARPA

Estell makes the following comment:
	
  The "complexity" and "historical" arguments even interact.  
  Peter Denning observed years ago that the difficulty of understanding a 
  program is a function of size (among other things).  He speculated that 
  difficulty is proportional to the SQUARE of the number of "units of under-
  standing" (about 100 lines of code).  Old tactical software, in assembly 
  language, tends to run into the hundreds of thousands of lines of code; 
  e.g., a 500,000 line program has 5000 units of understanding, with a diffi-
  culty  index of 25 million.  That same program, written in FORTRAN, might 
  shrink to 100,000 lines thus only 1000 units of understanding, thence a 
  difficulty index of one million.  That's worth doing!

I believe that the same program written in a "high level" language,
like Fortran, would probably have about the same number "units of
understanding" ~ 5000, in this case.  Assuming that the "units of
understanding" are understood to be higher level concepts, Fortran
would enable one to write those units with fewer lines of code.  But I
wouldn't expect the number of those units to decline with nearly the
same scale factor.

Of course the likelihood of a typographical error would be reduced by
such a scale factor, but that's not the major concern here.

--Martin Purvis

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re:  Sgt. York's Latrine, and other stories
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Tue, 10 Jun 86 12:36:24 edt
</i><PRE>
Cc: neumann@sri-csl
ReSent-To: risks@SRI-CSL.ARPA

I believe there were several retractions - enough for me to believe, at any
rate.  If I hadn't been so tired when I sent that bit to Peter I would have
expounded further on the delightful topic of various matters hitting the
fan, etc.

I *hope* that whoever designed the helicopter-rotor-selection algorithm did
more than simply search for cyclic doppler.  There are too many things out
in the real world that rotate but aren't helicopters.  
	- Wind turbines on a barn
	- The rotating beacon at some airports
	- Windmills
	- Cooling fans on the roof of a large building
	- Cooling fans on top of a diesel/electric locomotive 

By the way, I have patronized a fair number of outhouses down in the Shenandoah
Valley - While almost all needed (desperately!) ventilating fans, only one or
two had them - and they sounded like squirrel cage blowers within a ventilating
pipe, not likely to be picked up by Sgt. York's radar.  Nose yes, radar no.

	- Mike McLaughlin	&lt;mikemcl@nrl-csr&gt;

                 [I understand that, inspired by these reports, particle
                  physicists are now working on a new approach: Latrinos.  
                  Note: I expect that future submissions to RISKS on this 
                  subject will get flushed.  (Please replace all DIVADs.)
                  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-119</DOCNO>
<DOCOLDNO>IA012-000123-B020-46</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.6.html 128.240.150.127 19970217003316 text/html 15769
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:31:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 6</TITLE>
<LINK REL="Prev" HREF="/Risks/3.05.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.07.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 6</H1>
<H2> Thursday 12 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks from inappropriate scale of energy technologies 
</A>
<DD>
<A HREF="#subj1.1">
Michael J. Natkin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Shuttle Software 
</A>
<DD>
<A HREF="#subj2.1">
David C. Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  An additional SDI problem: sensor technology 
</A>
<DD>
<A HREF="#subj3.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Privacy in the electronic age 
</A>
<DD>
<A HREF="#subj4.1">
Dave Platt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Sgt York software 
</A>
<DD>
<A HREF="#subj5.1">
Larry Campbell
</A><br>
<A HREF="#subj5.2">
 Mark Vilain
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Risks from inappropriate scale of energy technologies
</A>
</H3>
<address>
    "Michael J. Natkin" 
&lt;<A HREF="mailto:mjn%brown.csnet@CSNET-RELAY.ARPA">
mjn%brown.csnet@CSNET-RELAY.ARPA
</A>&gt;
</address>
<i>
10 Jun 86 (Tue) 23:46:50 EDT
</i><PRE>

  One of the most important categories of long term risks to the public
from technology seems to have been overlooked in Risks so far.  The
assumption that more technology is automatically good is so ingrained
in our thinking that it is hardly questioned.  We measure our welfare
in terms of Gross National Product, not by how many people have enough
to eat, or by distribution of income.

  In particular a vast amount of our technical, capital and human
resources are expended developing monolithic energy technologies
without regard to end use needs. The public has long been duped into
the idea that centralized energy management has it's best interest in
mind as we develop ever increasing electrical capacity. But centralized
reactors and other "hard" technologies are extremely susceptible to
terrorist attack and other failures, as has been mentioned before.

  The public has been told that it doesn't have the expertise to make
decisions about such high risk high technologies as SDI and nuclear
power, and in some sense this is true. But the technocrats have
preempted the public's right to make the moral and political policy
which guides the choices.

  I think that we should be pursuing a policy course which develops
technology that can be put safely in the hands of non-technical people.
This might take the form of small burners which use the methanol from
organic wastes, windmills, or non-electrical solar collectors, to name a few
possibilities.  Localized, distributed technologies have many advantages,
including ease of repair, localization of risk from outage, and major
reductions in distribution losses and cost of distribution equipment and
labor. I strongly recommend Amory Lovins' "Soft-Energy Paths" to others
interested in issues of appropriate scale in technology.

       Michael Natkin
CSnet: mjn@brown
 ARPA: mjn%brown@csnet-relay
 UUCP: ...!{allegra,decvax,ihnp4}!brunix!mjn
 
</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Shuttle Software
</A>
</H3>
<address>
David C. Smith 
&lt;<A HREF="mailto:DCSmith@SRI-AI.ARPA">
DCSmith@SRI-AI.ARPA
</A>&gt;
</address>
<i>
Wed 11 Jun 86 08:55:30-PDT
</i><PRE>
To: risks@SRI-CSL.ARPA

The cover story of the September, 1984, CACM is "A Case Study: The Space
Shuttle Software System".  As with other CACM case studies, this one is
a discussion, or interview, with several people involved with the subject
matter, in this case 6 individuals from the IBM Federal Systems Division.
An Outline of the Interview included in the article contains:

  Project Overview
  The Shuttle Computers
  Project Organization
  Testing Facilities
  Detailed System Operation--No Redundancy
  Redundant Set Operation
  System Problems
  The Interprocess Variable Problem
  Concluding Remarks

The issue also contains several other articles in a Special Section on
Computing in Space, including "Design, Development, Integration: Space
Shuttle Primary Flight Software System", written by 2 senior technicians
from the IBM FSD.

It seems like a good place for a novice to the shuttle and its systems
(like myself) to get some basic information about the shuttle computers
and the complexity of the systems.

Dave Smith

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
An additional SDI problem: sensor technology
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@ames-aurora.arpa">
eugene@ames-aurora.arpa
</A>&gt;
</address>
<i>
11 Jun 1986 1124-PDT (Wednesday)
</i><PRE>

The view expressed within are the view of the author and not of my agency
nor of the Federal government.  ------------------------------ A lot of
interest has been expressed regarding the focus of the problems of SDI: the
software, in particular battle management.  Note the Science article of May
9 1986.  However, I wonder about the other components of the system.  Where
there are various groups watchdogging computing, but the more hardware
oriented, EE areas such as radar have fewer opposition elements. Recent
postings on cruise missiles and the integration of DIVAD move me to post this.

Sensor technology is one area which worries me.  SDI battle management
makes certain assumptions about the ability to detect and identify targets.
I think that most computer people don't understand the nature of radar
to worry about the problems of `target' detection and ranging.  That is
all that radar is: detection (boolean) and ranging (distance=rate times
time). A first starting references is Skolnick's text on Radar. (Dated)

Inherent problems with a ranging system include: Range and azimuth
ambiguities, difficulties with empirically determined signatures.  Most
people don't seem to understand that knowing the geometry of systems are
important.  Satellite images [some radar maps to be used in offensive
missiles] are not photographs (you must call them images) because their
geometry is from a linear and not a point perspective, so distance
determination for things like cruise missiles cannot be done using a
straight edge.  Radar (simple) is like looking at the world using a
monochromatic spot light from the point where you are looking: you don't get
shadows (an important distance cue).  Note: I have not talked about clutter,
or noise (ever wonder how high speed jets detect jets from ground objects,
or how AWACS which points down get insignificant ground objects cleared?).

While there exist solutions, all of them involve tradeoffs in complexity,
cost, and new emergent problems.  Solutions in Doppler systems,
phased arrays, stereo transmit/receive systems, but just the inherent
simplicity of the concept and the over-generalization of use worries me.
This is a case where "high-level language" solutions may not be
high-enough.

--eugene miya, NASA Ames Research Center, eugene@ames-aurora.ARPA
  {hplabs,hao,dual,ihnp4,decwrl,allegra,tektronix,menlo70}!ames!aurora!eugene

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Privacy in the electronic age
</A>
</H3>
<address>
Dave Platt 
&lt;<A HREF="mailto:Dave-Platt%LADC@HI-MULTICS.ARPA">
Dave-Platt%LADC@HI-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 11 Jun 86 10:47 PDT
</i><PRE>

A news clipping from this morning's "Los Angeles Times" (page 2, The News
in Brief):

   The House Judiciary Committee voted 34 to 0 for a bill seeking to
   bring constitutional guarantees of the right to privacy into the
   electronic age.  The legislation would extend laws that now protect
   the privacy of the mails and land-line telephone conversations to also
   cover electronic mail and some telephones that use radio waves.
   The bill was cleared at the request of Rep. Robert W. Kastenmeier
   (D-Wis.), chairman of Judiciary's subcommittee on courts, civil
   liberties and administration of justice.

Anyone know the details?  Just what privacy coverage would be afforded
by this bill in its present form?  How would the bill's provisions
affect the sysops of private electronic bulletin-board systems, for
example?  Would this bill clarify the legal standing of electronic
transactions and messages re their use as evidence in court?

     [Very strange.  RISKS-3.1 noted that the House sent a bill to the 
      Senate on 3 June that covered "federal interest" computers.  Is this
      an additional bill, or a modification of one already sent over?  
      Maybe someone in the House is reading RISKS and noted the apparent
      flaws in the bill that I mentioned in RISKS-3.1?  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Sgt York software
</A>
</H3>
<address>
&lt;<A HREF="mailto:decvax!bellcore!genrad!panda!wjh12!maynard!campbell@ucbvax.berkeley.edu">
decvax!bellcore!genrad!panda!wjh12!maynard!campbell@ucbvax.berkeley.edu
</A>&gt;
</address>
<i>
Wed, 11 Jun 86 01:52:39 edt
</i><PRE>

In RISKS 3.4, Mike McLaughlin (mikemcl@nrl-csr) and Ken Laws (laws@sri-ai)
dispute the Sargent York latrine fan story. [...]

I quote from a story by Gregg Easterbrook in the November 1984 issue of
_The Washington Monthly_:

    During a test one DIVAD locked on to a latrine fan.  Michael Duffy,
    a report for the industry publication _Defense Week_, who broke this
    aspect of the story, received a conference call in which Ford officials
    asked him to describe the target as a "building fan" or "exhaust fan"
    instead.

_The Washington Monthly_ and _Defense Week_ are both reputable publications.
Does anyone have a citation for a retraction in _Defense Week_, or should we
assume that the TV networks swallowed Ford's story whole?

Larry Campbell                             The Boston Software Works, Inc.
ARPA: campbell%maynard.uucp@harvard.ARPA   120 Fulton Street, Boston MA 02109
UUCP: {alliant,wjh12}!maynard!campbell     (617) 367-6846

</PRE>
<HR><H3><A NAME="subj5.2">
Sgt. York software
</A>
</H3>
<address>
Marc Vilain 
&lt;<A HREF="mailto:MVILAIN@G.BBN.COM">
MVILAIN@G.BBN.COM
</A>&gt;
</address>
<i>
Wed 11 Jun 86 12:48:29-EDT
</i><PRE>
To: risks@SRI-CSL.ARPA
cc: mvilain@G.BBN.COM, reid%oz@MC.LCS.MIT.EDU

Here is some information on the DIVAD software that hasn't appeared yet in
this forum.  [It] is abstracted from a longer note compiled by Reid
Simmons from material he received from Gregg Easterbrook (both his article
in the Atlantic, and personal communications).

According to Easterbrook, the DIVAD did target a latrine exhaust fan in
one series of tests.  The target was displayed to the gunners that man
the DIVAD.  But the Sgt. York did not shoot at the latrine, or even
swivel its turret in the latrine's direction, having prioritized the
target as less important than other targets in its range.

In another series of tests (Feb. 4 1984), U.S. and British officials
were to review the DIVAD as it took upon a rather cooperative target: a
stationary drone helicopter.  On the first test run, the DIVAD swiveled
its turret towards the reviewing stand as "brass flashed" and the
officials ducked for cover.  It was stopped only because an interlock
was put in place the night before to prevent the turret from being able
to point at the reviewing grandstand.  Afterwards, the DIVAD shot in the
general direction of the helicopter but the shells traveled only 300
yards.  The official explanation is that the DIVAD had been washed the
night before, screwing up its electronics.  Easterbrook wonders what
would happen if it rained in Europe when the DIVAD was being used.

Easterbrook goes on to claim that the snafus the DIVAD experienced were
very much due to software.  The main problem was that the pulse-Doppler
tracking radar and target acquisition computer were a very poor match.
Easterbrook claims that the hard problem for the software (tracking
fast, maneuvering planes) was easiest for the pulse-Doppler radar which
needs a moving target.  On the other hand, the hard part for the radar
(detecting stationary helicopters) was the easiest to aim at.  The DIVAD
mixed two opposing missions.

Easterbrook goes on to say that human gunners are often more successful
than their automated counterparts.  They can pick up on visual cues, such
as flap position on approaching aircraft, to determine what evasive
maneuvers the enemy might make.  These kinds of cues are not visible to
things like pulse-Doppler radars.  Further, evasive courses of action
are hard for human gunners to counter, but even harder for target
tracking algorithms (again the lack of visual cues comes as a
disadvantage).  For example, the DIVAD expected its targets to fly in a
straight line (which my military friends tell me is not too likely in a
real combat).

There is lots more to the Sgt. York story, not all of which is relevant
here.  If there is a moral to be drawn specifically for RISKS, it's
that as advanced as our technology may be, it may not always be the
match of the problems to which it is applied.  This was certainly the
case with the unfortunate DIVAD.

marc vilain

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-120</DOCNO>
<DOCOLDNO>IA012-000123-B020-62</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.7.html 128.240.150.127 19970217003326 text/html 14452
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:31:57 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 7</TITLE>
<LINK REL="Prev" HREF="/Risks/3.06.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.08.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 7</H1>
<H2> Friday, 13 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Eastport Study Group report ("Science" article) 
</A>
<DD>
<A HREF="#subj1.1">
Pete Kaiser
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  An additional SDI problem: sensor technology 
</A>
<DD>
<A HREF="#subj2.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Shuttle software and CACM 
</A>
<DD>
<A HREF="#subj3.1">
James Tomayko [and Herb Lin]
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Privacy laws 
</A>
<DD>
<A HREF="#subj4.1">
Bruce O'Neel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A mini-editorial on running the RISKS Forum 
</A>
<DD>
<A HREF="#subj5.1">
PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Eastport Study Group report ("Science" article)
</A>
</H3>
<address>
Systems Consultant
&lt;<A HREF="mailto:kaiser%renko.DEC@decwrl.DEC.COM  ">
kaiser%renko.DEC@decwrl.DEC.COM  
</A>&gt;
</address>
<i>
Thursday, 12 Jun 1986 04:54:22-PDT
</i><PRE>

"Science", in the issue of 9 May 1986, contains an article on "Resolving the
Star Wars Software Dilemma".  The subhead reads:

  A panel of computer scientists has concluded that computers will be able
  to manage a strategic defense system -- but only if battle management is
  designed in from the beginning.

More, from within the article:

  ...The report is in fact a scathing critique of the way the Pentagon
  handles high-technology weapons design in general and software
  development in particular.  It deals with important questions about the
  limits of computing, the nature of reliability, the organization of
  large, complex systems, and the nature of strategic defense itself.

  And in a striking paradox, it validates what the program's many critics
  have been saying about the infeasibility of Star Wars software.  ...

  First, they say, battle management is tractable only if SDIO and its
  defense-industry contractors give up their tacit assumption that
  software is an "applique," something that can be sprinkled on
  preexisting weapons and sensors like pixie dust to turn them into a
  working defense system.  This assumption was quite evident in SDIO's
  so-called "Phase I" architecture studies, which were completed in 1985
  and which seemed to concentrate almost exclusively on hardware.

The "paradox", as I read the Study Group's findings in the article, is that
although it might be possible to design systems that did effective battle
management (in some interpretation of "effective") by integrating software
and hardware from the earliest stages of design, there is no sign whatever
that this could happen in the real world of military contractors and
politics.  Thus, in the report's view, it is effectively impossible to build
workable Star Wars systems.

Recommended, but not comforting, reading.  (The name of the full report from
the Eastport Study Group is "Summer Study 1985: A Report to the Director of
the Strategic Defense Initiative Organization", December 1985.)

---Pete        
Kaiser%furilo.dec@decwrl.dec.com         decwrl!furilo.dec.com!kaiser
DEC, 2 Iron Way (MRO3-3/G20), Marlboro MA 01752  617-467-4445

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: An additional SDI problem: sensor technology
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@uw-june.arpa ">
jon@uw-june.arpa 
</A>&gt;
</address>
<i>
Thu, 12 Jun 86 22:32:55 PDT
</i><PRE>

&gt; (Eugene Miya writes:) ... Where there are various groups watchdogging
&gt; computing, but the more hardware oriented, EE areas such as radar have
&gt; fewer opposition elements.

Sensors and signal processing comprise a larger portion of 
the SDI effort than anything else, according to many reports.

The most informative comments I have heard were by Michael Gamble, a 
vice president (I think) at Boeing, and head of that company's 'Star Wars'
research programs. He administers about half a billion dollars worth of
contracts.  In a talk to the Seattle chapter of the IEEE on Nov. 14, 1985,
he noted that the total SDI budget requests for fiscal years 1985 through 
1990 would total about $30 billion, broken down as follows:  Sensors $13B,
directed energy weapons $7B, kinetic energy weapons $7B, Battle Management
$1B, Survivability $2B.  Sensors comprise almost half the total. (I do not
know whether these proportions are maintained in the somewhat reduced 
budgets that get approved.)

Gamble also explained why he thought missile defense was once again 
plausible, after being debunked in the early 70's.  "What has changed 
since then?" he asked rhetorically, and gave five answers, three of which 
involved sensors: first, long wave infrared detectors and associated cooling
systems, which permit small warheads to be seen agains the cold of space;
second, "fly's eye" mosaic sensor techniques (like the ones used on the 
F-15 launched ASATS and in the 1984 "homing overlay experiment") -- these
are said to "permit smaller apertures" (I didn't catch the significance of
that);  and third, low-medium power lasers for tracking, designation, and
homing.  The other two factors were long-life space systems and powerful
onboard computing capabilities.

There is a large computing component in the sensor field: digital signal
processing.  However, this area is not so well known to computer science
types.  Boeings largest SDI contract - over $300M - is for the "Airborne
Optical Adjunct," an infrared telescope and a lot of computers mounted 
in a 767 airliner, apparently for experiments in sensing and battle
management for midcourse and terminal phase.  Two of the systems people
involved in this project gave a seminar at the UW computer science department
last January.  They mentioned that the signal processing was being handled
by the sensor people and they just regarded it as a black box.

I can think of two reasons why this area has received relatively little 
attention.  First, there were no galvanizingly absurd statements about sensors 
from relatively prominent SDI proponents - nothing like James Fletcher 
calling for "ten million lines of error-free code," or all that bizarre stuff
in the Fletcher report and elsewhere about launching pop-up X-ray lasers 
under computer control.  Second, there is a lot secrecy in the sensor area--
unlike battle management, where the important issues do not turn on classified
material.  Gamble noted that "there is not that much that is classified about
SDI, except things like, 'How far can you see?  How far do you have to see?'"
Needless to say, talking in detail about sensors would reveal how much we know
about Soviet warhead characteristics, how good our early warning systems 
really are, and so forth.

-Jonathan Jacky
University of Washington

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Shuttle software and CACM
</A>
</H3>
<address>
&lt;<A HREF="mailto:James.Tomayko@sei.cmu.edu">
James.Tomayko@sei.cmu.edu
</A>&gt;
</address>
<i>
Thursday, 12 June 1986 09:04:12 EDT
</i><PRE>

As referenced in the recent RISKS, the CACM case study is a somewhat decent
introduction to the Shuttle onboard software. However, I would like to warn
readers that the case study editors interviewed IBM FSD personnel *only*,
with no attempt to talk to the customer, NASA, or the users, the astronauts.

I was under contract with NASA for three years to do a study of its use of
computers in space flight, and my interviews with crews and trainers
provided a somewhat more critical view of the software. Also, it is useful
to remember that the primary avionics software system documented in the CACM
study runs on four computers. Last count was that there are something over
200 processors on the orbiter (Source: Jack Garman, Johnson Space Center).

So, please take the CACM articles with a grain of salt.

Jim Tomayko
Software Engineering Institute

P.S. To forestall some mail: The earliest NASA will release my Technical
Report is late 1987. 

  [In addition, Herb Lin responded to David Smith, included here for emphasis:
   "This issue of CACM *is* a pretty good review of shuttle software.  On
    the other hand, you must remember that the interview was with the
    people who were in primary charge of the project.  Thus, you would be
    rather unlikely to hear about problems and so on that remained
    unresolved.  That claim doesn't diminish the value of the article,
    but it should prompt caution in accepting the general impression it
    gives that all was (or is) just fine...  Herb"  ]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
     Privacy laws
</A>
</H3>
<address>
          Bruce O'Neel  
&lt;<A HREF="mailto:ZWBEO%VPFVM.BITNET@WISCVM.WISC.EDU">
ZWBEO%VPFVM.BITNET@WISCVM.WISC.EDU
</A>&gt;
</address>
<i>
Thu, 12 Jun 86 10:55 EDT
</i><PRE>
To: Risks digest &lt;RISKS@SRI-CSL.ARPA&gt;

In response to the House law about computer communications privacy, I
believe that the following is correct.  Right now, communications are
protected if they are telephone, mail, and other "traditional"
technologies.  One can not "wiretap" you without a warrant.  The current
laws don't cover computer communications or car phones or other "new"
communications technology.  According to what I read in Wash. Post
this bill would consider car phone communications, computer communications,
and others the same as the mail and land based phone calls.

      Bruce O'Neel  &lt;zwbeo@vpfvm.bitnet&gt;

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
A mini-editorial on running the RISKS Forum
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@SRI-CSL.ARPA">
NEUMANN@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Fri 13 Jun 86 00:25:40-PDT
</i><PRE>
To: Neumann@SRI-CSL.ARPA

Life is usually a delicate balance among many tradeoffs.  Running
RISKS is no different:

  The subject of Risks to the Public in Computer Systems involves
  tradeoffs among technical, social, economic, and political factors.
  These are very hard to assess, because each person's basis for
  judgment is likely to be different.  (All of these factors are
  relevant in the broad sense, although we generally try to focus on
  the technical issues.)  Some risks are intrinsic in technology; the
  question is under what circumstances are they worthwhile -- and that
  involves all of the factors (and more).

  If messages were too superficial or issues too infrequent, most of
  you would lose interest.  If issues and/or messages were very long or
  too frequent, you would most likely be overwhelmed.  (But I occasionally
  get requests for single-message mailings from BITNET subscribers [who
  have not yet discovered undigestifiers?], although that presents many
  difficulties.)

  If I put too much of my time into RISKS, my other responsibilities may 
  suffer.  If I put too little time in, you may suffer.   

  If I turn down the threshold and accept contributions that violate
  the masthead requirements (relevancy, soundness, objectivity,
  coherence, etc.), we all suffer.  If you contribute junk and I don't
  reject it, you and I suffer.  If I turn up the threshold and reject
  many contributions, I defeat one of the main purposes of RISKS,
  which is to be an open forum.  

  If RISKS were to take itself too seriously, or alternatively to become 
  too frivolous, that would be bad.  [I try to keep my pun level down,
  but occasionally I may slip a little.])

So, thanks for sticking with us in this experiment in communication on a
vital topic.  Please complain to RISKS-Request or to me when you are
really unhappy.  It can only help.  Peter

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-121</DOCNO>
<DOCOLDNO>IA012-000123-B020-84</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.8.html 128.240.150.127 19970217003339 text/html 13946
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:32:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 8</TITLE>
<LINK REL="Prev" HREF="/Risks/3.07.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.09.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 8</H1>
<H2> Sunday, 15 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Challenger, SDI, and management risks 
</A>
<DD>
<A HREF="#subj1.1">
Dick Dunn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Risks from inappropriate scale of energy technologies 
</A>
<DD>
<A HREF="#subj2.1">
Chuck Ferguson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Distributed versus centralized computer systems 
</A>
<DD>
<A HREF="#subj3.1">
Peter G. Neumann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Privacy legislation 
</A>
<DD>
<A HREF="#subj4.1">
Michael Wagner
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Challenger, SDI, and management risks
</A>
</H3>
<address>
Dick Dunn
&lt;<A HREF="mailto:nbires!rcd@ucbvax.Berkeley.EDU ">
nbires!rcd@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Fri, 13 Jun 86 12:24:29 mdt
</i><PRE>

The Challenger failure has an implication for SDI that I've not seen
discussed much.  I regard the solid-rocket failure as primarily a management
failure and only secondarily an engineering failure.  Why?  Because
according to the Rogers group reports, there had been serious concern with
the possibility of failure of the O-ring seals, but it got lost or
suppressed along the way.  Challenger's ill-fated launch was apparently made
in spite of best engineering advice to the contrary.

How does this apply to SDI?  I'll give a sketch; I hope that other people
will add more.  SDI is under fire from several places (substantial part of
Congress, various public-interest groups, many influential technical
people).  It is therefore important for the supporters (willing and/or
appointed) of SDI to present a convincing case that SDI can "do the job."
There is tremendous pressure to justify SDI.  Translate this into "there is
tremendous pressure to argue the case that SDI can be built and can work--
whether or not it really can."  To be blunt, there is a tremendous incentive
to cover up any potential inability to build an SDI system or any inadequacy
once it is built.  Of course, if the SDI system is built, and is used, and
fails, there will be much more lost than seven lives and some megabucks of
hardware.  (I have a hard time typing the word "terabucks":-) There probably
Wouldn't even be a presidentially-appointed blue-ribbon investigative
committee...

The hard questions:  Do we have a way to manage a project of the magnitude
of SDI that will give us any halfway-reasonable assurance that the project
will work?  Is there any technique that can be applied to reward those who
discover problems and punish those who cover them up, instead of the other
way around?

(My own experience, unfortunately, tells me that these aren't really hard
questions.  Rather, they are questions which are easily answered "no!"  The
difficulty in managing any large project, particularly one which involves a
lot of software, is legendary.)

In summary, I'm saying that Challenger failed not for technical reasons--
I believe that the technical problems are real but surmountable--but for
managerial reasons.  Further, I think that we need to talk about SDI
feasibility in more than technical terms; we need to address whether we
could manage the project even if all of the technical problems were
surmountable.  The answer is anything but a clear "yes".

Dick Dunn

     [From The New York Times, Sunday, 15 June 1986:

     New York - The ''Star Wars'' anti-missile plan has been seriously and
     extensively damaged by the Challenger disaster and other setbacks in
     the American space program, aerospace analysts say.  Officials of the
     anti-missile defense program, formally called the Strategic Defense
     Initiative, deny any serious damage to the program, but aerospace
     experts say the problems within the space program have sent shock waves
     through research programs. ...  ]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Re: Risks from inappropriate scale of energy technologies
</A>
</H3>
<address>
 Chuck Ferguson - SCTC 
&lt;<A HREF="mailto:CTFerguson@HI-MULTICS.ARPA">
CTFerguson@HI-MULTICS.ARPA
</A>&gt;
</address>
<i>
Thu, 12 Jun 86 20:06 CDT
</i><PRE>
To:  RISKS-FORUM Digest  &lt;RISKS@SRI-CSL.ARPA&gt;

In RISKS-3.6, Michael Natkin states:

  The public has long been duped into the idea that centralized energy
  management has its best interest in mind as we develop ever increasing
  electrical capacity.  But centralized reactors and other "hard" technologies
  are extremely susceptible to terrorist attack and other failures, as has
  been mentioned before.

Centralized power supplies may be "extremely susceptible" to terrorists but
their susceptibility to failure is not as high as being claimed.  It is true
that the consequences of a failure might be great; however, for a large
centralized power plant it is economical to expend greater resources to
prevent their failure (e.g., redundancy) than for the components of a
distributed system.  Furthermore, I submit that all current power systems
have some degree of distributed or redundant functionality to allow periodic
maintenance shutdowns if for no other reason.

I further submit that there is a significant risk associated with
distributed systems which is being ignored.  Many such systems are
themselves dangerous when poorly maintained or operated improperly.  There
are also hazards associated with storing combustible fuels near a dwelling
or other populated area.  Witness the following:

  o  How many chimney fires have you heard about since the "energy
     crisis" began?  A fireplace is a relatively low-tech device yet
     some people manage to make them dangerous.
     
  o  Why is it that several houses burn down at the start of every
     cold season?  An oil-fired furnace is a relatively low-tech
     item also, yet every year someone's gets choked with soot and
     catches fire.
     
  o  Ever heard of a methane gas explosion in a sewer system?  I
     recently heard an amusing story about a manure fire at a horse
     ranch - ten years worth of horse manure had been piled in one
     place until one day it spontaneously caught fire.

One would be surprised how much damage some people can do with low-tech
alternative energy.  To paraphrase one of the better known 'computer
security experts' [emphasis added], "Terrorists can never compete with
incompetents".  I wonder whether more people lose their lives each year in
the commercial production of power or in incidents similar to the above.

With respect to the public "being duped" - sounds like another
conspiracy theory to me (yawn).

         Chuck Ferguson, Honeywell, Inc., Secure Computing Technology Center

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Distributed versus centralized computer systems
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Sun 15 Jun 86 22:32:04-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Although Chuck's note does not seem as closely related to RISKS as some of
his past contributions, it suggests various additional comments.  A myth of
distributed computing systems is that distribution avoids centralized
vulnerabilities.  WRONG! The 1980 ARPANET collapse gave us an example of an
accidentally propagated virus that contaminated the entire network.  The
first shuttle synchronization problem is a further example.

By distributing what has to be trusted, there may be more vulnerabilities --
unless the distributed components are TOTALLY autonomous -- in which case we
are not really talking about DISTRIBUTED systems, but rather SEPARATE
systems.  Security flaws in the systems and networks can result in
transitive vulnerabilities, or permit global compromises by iteration.

Further, the point raised by Chuck regarding maintenance is an important one
in distributed computer systems, especially if some of the distributed sites
are remote.  Well, then, you say, let the field engineers dial up the remote
site.  But then that path provides a monstrous new vulnerability.  Then we
get solutions like the remote backup scheme proposed a while back that gets
special privileges...  Also, remember the fundamental flaws in the standard
two-phase commit protocols, three-clock algorithms, and so on.  Once again
it might be useful to consider truly robust algorithms such as interactive
consistency and Byzantine agreement.  However, for every more complex
would-be technical solution there are often further technical problems
introduced.  For every assumption that things have gotten better there seem
to be even grosser counterexamples and further vulnerabilities outside of
the computer systems.  Thus,

  It is folly to trust software and hardware if an end-run can bypass or
  compromise the trusted components.  But it is also folly to assume that
  sabotage is significantly less dangerous just because a system is
  distributed.  That may be true in certain cases, but not generally.

Peter                 [Please excuse me if I have repeated some things that
                       I said in earlier RISKS in a different context.]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Privacy legislation (RISKS-3.6)
</A>
</H3>
<address>
Michael Wagner
&lt;<A HREF="mailto:ubc-vision!utcs!wagner@seismo.CSS.GOV ">
ubc-vision!utcs!wagner@seismo.CSS.GOV 
</A>&gt;
</address>
<i>
Sat, 14 Jun 86 11:26:37 edt
</i><PRE>

  &gt;A news clipping from this morning's "Los Angeles Times" (page 2, The News
  &gt;in Brief):
  &gt;
  &gt;   The House Judiciary Committee voted 34 to 0 for a bill seeking to
  &gt;   bring constitutional guarantees of the right to privacy into the
  &gt;   electronic age.  The legislation would extend laws that now protect
  &gt;   the privacy of the mails and land-line telephone conversations to also
  &gt;   cover electronic mail and some telephones that use radio waves.

Does anyone have any idea how the last part (radio telephones) could be
legally supported in view of other legal freedoms?  I thought that one
was free to listen to any frequency one wished in the US (Canada too).
You don't have to trespass to receive radio signals.

Contrast this with the mails. The privacy of the mails is supported by
property laws.  That is, you put your mail into a box which belongs to
the post office.  If anyone breaks into that box (or the van which
picks up the mail, etc) they are breaking property laws.  Similarly for
land lines.  One has to 'trespass' to tap a land line.

It seems to me that the legislators have 'extended' the laws over an
abyss.  Or have I missed something?

The relevancy to RISKS, of course, is that most people don't think about
the technology that radio-telephones use.  I'm sure most people assume
"it's a phone - it's (relatively) safe".  Not true, of course.  In fact,
some people have used their own handsets to make phone calls on other
peoples phones!

Michael Wagner

  [I do not recall having pointed out in this forum the ease with which
   the cellular phone schemes can be spoofed, e.g., getting someone else
   to pay for your calls.  There is another security/integrity problem
   waiting to be exploited.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-122</DOCNO>
<DOCOLDNO>IA012-000123-B020-101</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.9.html 128.240.150.127 19970217003356 text/html 15967
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:32:21 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 9</TITLE>
<LINK REL="Prev" HREF="/Risks/3.08.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.10.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 9</H1>
<H2> Friday, 20 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Informing the Senate on SDI 
</A>
<DD>
<A HREF="#subj1.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A medical risk of computers 
</A>
<DD>
<A HREF="#subj2.1">
Karen R. Sollins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks of VDTs 
</A>
<DD>
<A HREF="#subj3.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Minor addition on Risks of Distributed Energy 
</A>
<DD>
<A HREF="#subj4.1">
Ted Lee
</A>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Informing the Senate
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.DEC.COM ">
horning@src.DEC.COM 
</A>&gt;
</address>
<i>
Wed, 18 Jun 86 12:21:05 pdt
</i><PRE>

The information in this message is political, not technical. However,
it concerns the process of supplying technical information to those who
must make political judgements, so I believe that it is germane to Risks.

Recent news accounts have indicated that the outcome in the Senate of
requests for increased SDI funding is very unclear. Senators are having
to take positions on a matter they don't fully understand, and many of
them would like to be better informed.

I was contacted by an aide to Senator Proxmire for information about how
David Parnas's criticisms of SDI software are viewed in the professional
community. General Abramson and the SDIO have had some success in
spreading the message that David Parnas is an isolated crank who is not
taken seriously by those who actually build software.

I was able to express my own opinion and concerns, but cannot speak
credibly for the entire professional community. Pound-for-pound, Risks
probably contains more people qualified to make an informed judgement on
this issue than any other group I know how to reach. Whatever your views,
I would urge you to take the time to write a letter expressing them to

	Mr. Douglas Waller
	Office of Senator William Proxmire
	United States Senate
	Washington, DC 20510
	
Based on my experience, you can expect your letter to receive personal
attention, and to carry weight according to your credentials and the
cogency of your arguments. (This is in sharp contrast to my experience
writing to my own senators and congressman.)

In addition to stating your own views clearly, it would probably help to
indicate how they relate to Parnas's criticisms and (if you have read it)
to the Eastport Report. In my own letter, I also devoted a paragraph to
sketching my credentials; I don't much care for such self-advertisement,
but thought I should give a starting point for any checking they cared to
do, and the reasons why I felt qualified to comment on reliability and on
aerospace software.

Jim H.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
a medical risk of computers
</A>
</H3>
<address>
"Karen R. Sollins" 
&lt;<A HREF="mailto:sollins@XX.LCS.MIT.EDU">
sollins@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 20 Jun 1986  10:37 EDT
</i><PRE>

My particular concern in the story that follows is that the designers and
programmers probably can't know ALL the conditions for which to check.  We
all know that complete testing of complex systems is impossible.  All too
often we are put into a position of trading risks and benefits, and at least
the risks (as in this case) are not and cannot be known completely.

Of course, another difficult question here is who is responsible for what
happened and what should be done about it.  Clearly for those three
patients involved and their families and friends no amount of placing
responsibility, punishment, or compensation can make up for what was done
to them.
			Karen Sollins

_______________
MAN KILLED BY ACCIDENT WITH MEDICAL RADIATION
(excerpted from The Boston Globe, June 20, 1986, p. 1)
by Richard Saltos, Globe Staff

A series of accidental radiation overdoses from identical cancer therapy
machines in Texas and Georgia has left one person dead and two others with
deep burns and partial paralysis, according to federal investigators.

Evidently caused by a flaw in the computer program controlling the highly
automated devices, the overdoses - unreported until now - are believed to
be the worst medical radiation accidents to date.

The malfunctions occurred once last year and twice in March and April of
this year in two of the Canadian-built linear accelerators, sold under the
name Therac 25.

Two patients were injured, one who died three weeks later, at the East
Texas Cancer Center in Tyler, Texas, and another at the Kennestone Regional
Oncology Center in Marietta, Ga.

The defect in the machines was a "bug" so subtle, say those familiar with
the cases, that although the accident occurred in June 1985, the problem
remained a mystery until the third, most serious accident occurred on April
11 of this year.

Late that night, technicians at the Tyler facility discovered the cause of
that accident and notified users of the device in other cities.

The US Food and Drug Administration, which regulates medical devices, has
not yet completed its investigation.  However, sources say that discipline
or penalty for the manufacturer is unlikely.

Modern cancer radiation treatment is extremely safe, say cancer
specialists.  "This is the first time I've ever heard of a death" from a
therapeutic rediation accident, said FDA official Edwin Miller.  "There
have been overtreatments to various degrees, but nothing quite as serious
as this that I'm aware of."

Physicians did not at first suspect a rediation overdose because the
injuries appeared so soon after treatment and were far more serious than an
overexposure would ordinarily have produced.

"It was certainly not like anything any of us have ever seen," said Dr.
Kenneth Haile, director of radiation oncology of the Kennestone radiation
facility.  "We had never seen an overtreatment of that magnitude."

Estimates are that the patients received 17,000 to 25,000 rads to very
small body areas.  Doses of 1,000 rads can be fatal if delivered to the
whole body.

The software fault has since been corrected by the manufacturer, according
to FDA and Texas officials, and some of the machines have been retured to
service.

... (description of the accidents)

The Therac 25 is designed so that the operator selects either X-ray or
electron-beam treatment, as well as a series of other items, by typing on a
keyboard and watching a video display screen for verification of the
orders.

It was revealed that if an extremely fast-typing operater inadvertently
selected the X-ray mode, then used an editing key to correct the command
and select the electron mode instead, it was possible for the computer to
lag behind the orders.  The result was that the device appeared to have
made the correct adjustment but in fact had an improper setting so it
focussed electrons at full power to a tiny spot on the body.

David Parnas, a programming specialist at Queens University in Kingston,
Ontario, said that from a description of the problem, it appeared there
were two types of programming errors.

First, he said, the machine should have been programmed to discard
"unreasonable" readings - as the injurious setting presumably would have
been.  Second, said Parnas, there should have been no way for the
computer's verifications on the video screen to become unsynchronized from
the keyboard commands.

        [This story was also reported by Jim Kirby.  It is very rare that I
         get MULTIPLE copies of such a report.  Statistically, that suggests
         that there must be many things that never get reported...  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks of VDTs
</A>
</H3>
<address>
Alan Wexelblat 
&lt;<A HREF="mailto:wex@mcc.arpa">
wex@mcc.arpa
</A>&gt;
</address>
<i>
Mon, 16 Jun 86 11:50:07 CDT
</i><PRE>

Excerpted from an article by Loren Stein of the Center for Investigative
Reporting in San Francisco, published in the July 1986 issue of the
Progressive:

"[...]Effictive with the 1986 budget, the Reagan administration has cut off
$1.5 million in funds for the non-ionizing radiation [the kind emitted by
VDTs] research program in North Carolina's Research Triangle Park, a
program in operation since [...] 1971.  `For several years,' says Jerold
Mande, an assistant to Albert Gore Jr. of Tennessee, `the administration
has tried to eliminate the program and each year the House defended it.
But the last time around, they gave up.'

"[...]Until recently, many scientists believed that non-ionizing radiation
could not affect the body unless its electric field produced heat or an
electric shock.  But in 1984, _Spectrum_, a leading engineering journal
declared that `a growing mass of evidence has virtually ended that debate.'

"`Evidence of the effects [of non-ionizing radiation] on the nervous system
and the immune system of animals was already well-established by the end of
the '70s,' wrote Eric Lerner, a former contributing editor of _Spectrum_
`while evidence of effects on the genetic material has accumulated most
rapidly over the past few years.'  These discoveries may mean that our
bodies are far more sensitive to non-ionizing radiation than previously
thought [...].

"Two of the EPA's most important experiments in non-ionizing radiation -
now shelved - underwent years of detailed preparation and were on the verge
of actual testing.  One involved the lifelong exposure of rats to low-level
radio-frequency radiation.  `I really looked forward to this experiment,'
says Tell.  `We had finally, after five years, gotten all the facilities
set up to support the experiment.  It took so much time, manpower, and
money.  Now it's through.'

"Another key project tried to replicate some dramatic findings for Jose
Delgado's research laboratory in Madrid, Spain.  In 1982, associates at
this labe discovered that extremely weak-pulsed magnetic fields - only one
five-hundredth the strength of the Earth's natural magnetic field - caused
chick embryos to develop malformed hearts and central nervous systems.

"[...]The EPA [...] will not participate in an international effort to
verify Delgado's findings - an effort made possible by the EPA's
development of equipment that is being shipped to Canada, Sweden, and three
other places to create identical test environments. [...]

"Funding for non-ionizing radiation research has been slashed in other
Government programs as well.  An eagerly anticipated reproductive study
involving 4000 VDT operators of child-bearing age by the National Institute
of Occupational Safety and Health was among the casualties.

"The EPA research branch is no longer necessary, claim some officials,
because the agency will soon publish voluntary guidelines for exposure to
RF radiation; overexposure can raise body temperature, which animal
research indicates may be harmful to pregnant women and their unborn
children. [EPA claims there's no conclusive evidence of harm.]

"Other experts [say] the EPA guidelines will suffer from the dismantling of
the agency's non-ionizing radiation research team. [...]Tell's office is
issuing the soon-to-be-published RF radiation guidelines; he says
`Obviously, we need biological experiments.  They've helped us tremendously.'

[Senator Gore has an interest in this and fought to keep the research.
Technical comments will be given to the EPA on the guidelines and the EPA
will not have the expertise to evaluate them.]

Alan Wexelblat
ARPA: WEX@MCC.ARPA
UUCP: {ihnp4, seismo, harvard, gatech, pyramid}!ut-sally!im4u!milano!wex

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Minor addition on Risks of Distributed Energy
</A>
</H3>
<address>
&lt;<A HREF="mailto: TMPLee@DOCKMASTER.ARPA">
 TMPLee@DOCKMASTER.ARPA
</A>&gt;
</ADDRESS>
<I>
Wed, 18 Jun 86 10:54 EDT
</I>
<P>
Two observations to add to Chuck Ferguson's comment on distributed
energy.  In the debate over the safety of nuclear energy it has been
proposed that a further alternative to the ones mentioned in Risks is
solar energy.  Those so doing ignore the fact that (whether the weather
cooperates or not in terms of percentage of sun) in the part of the
country he and I come from it would be necessary to clear the snow off
some types of solar energy devices in the winter.  The number of likely
deaths from people climbing on their roofs to shovel off their solar
cells is guaranteed to exceed the probable number of deaths from a
nuclear power plant accident.
</P><P>
The point here is not the specific technologies involved, but the two
recent messages on the topic just prompted to think of this one more
example (its going to be hot and humid here today, and somehow snow came
to mind) of how in comparing risks of various potential solutions one
must take everything into consideration.  (Isn't it also true that
coal-fired plants actually release a fair amount of low-level radiation
that somehow gets ignored?  and how many more deaths and injuries are
there amongst coal-miners than uranium miners ...  oops, got carried
away.  Note of course that any of these conjectures may be wrong and one
would have to insist on credible statistics before making any
conclusions.)
</P>
<ADDRESS>
Ted
</ADDRESS>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-123</DOCNO>
<DOCOLDNO>IA012-000123-B020-126</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.10.html 128.240.150.127 19970217003412 text/html 15235
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:32:38 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 10</TITLE>
<LINK REL="Prev" HREF="/Risks/3.09.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.11.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 10</H1>
<H2> Friday, 20 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Privacy Legislation &amp; Cellular Swiss Cheese (RISKS-3.8)
</A>
<DD>
<A HREF="#subj1.1">
Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Privacy Legislation (RISKS-3.6) [divulging] 
</A>
<DD>
<A HREF="#subj2.1">
Dan Franklin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Privacy Legislation (RISKS-3.6) [radar detectors] 
</A>
<DD>
<A HREF="#subj3.1">
Herb Lin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Privacy Legislation &amp; Cellular Swiss Cheese (RISKS-3.8)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 19 Jun 86 11:19:03 EDT (Thu)
From: the tty of Geoffrey S. Goodfellow &lt;crcwdc!geoff@seismo.CSS.GOV&gt;

I co-authored an article on the ease of which cellular can be spoofed,
COMINT'd and SIGINT'd in the November issue of PERSONAL COMMUNICATIONS
TECHNOLOGY.  An on-line copy of the article may be FTP'd with 'anonymous'
login from [SRI-CSL]&lt;Geoff&gt;Article.Celllar-Sieve or by sending me a
message requesting one by reply copy.

With respect to the impending facade of Privacy Through Legislation,
here is a good report on it which appeared on the Info-Hams mailing list.
Pay special attention to such gems as how Cordless phones are not included,
and the different level of protection afforded to Cellular abusers vs. the
traditional mobile telephone IMTS systems on 150 and 450 Mhz.

	Geoff Goodfellow
	Cellular Radio Corp.
	Vienna, VA

[Note:	This  HamNet  Electronic Edition is  a	limited   excerpt
from   the  full published edition [Vol 8 #11 -- 6/01/86] of  The
W5YI  Report.	  Selected   and   prepared   by   Scott,   W3VS.
Commercial redistribution of this copy is prohibited.]

Up  to	the minute  news  from	the  worlds  of  amateur   radio,
personal  computing  and   emerging   electronics.     While   no
guarantee  is  made,  information is  from  sources  we   believe
to  be	reliable.    May  be reproduced providing credit is given
to The W5YI Report.


o Electronic Privacy Bill Passes Subcommittee
  -------------------------------------------

Legislation extending protection  against  unwarranted	interception  of
electronic  communications  by	outsiders  passed  its	first  and  most
difficult test during mid-May.	RF signals present throughout our  homes
will no longer be public domain if HR 3378 ultimately becomes law.

After weeks of negotiation, the House Judiciary Subcommittee on  Courts,
Civil Liberties and the Administration of Justice reached  a  compromise
agreement  with  the  Department  of  Justice  setting	the  stage   for
subcommittee  approval.    The	mark-up  session  was  packed  with  120
spectators crowded into a room designed for 60.

Most of Justice's problems  had  to  do  with  adding  barriers  to  law
enforcement efforts.  The bill, as approved, requires the government  to
obtain	detailed  search  warrants  to	intercept  and	use   electronic
messages in transit.  The subcommittee acknowledged that they still  had
a couple of things to  work  out  in  the  "foreign  counterintelligence
field."

The legislation, the Electronic Communications Privacy	Act  brings  the
Wiretap  Act  of  1968	up-to-date  by	including  such   communications
services as cellular radio, computer data transfer, electronic mail  and
satellite communications not in use when the act was first passed.   The
final draft of HR 3378 was  unanimously  approved  after  two  suggested
amendments  (which  made  sense  to  us)  were	defeated.    The   final
subcommittee vote had been delayed three times previously.

The bill is far reaching and will effect nearly every  American  in  one
way  or  another.    While  legislators,  the  media,  and  the  various
electronic industries are  widely  portraying  the  bill  as  protecting
cellular privacy, it doesn't at all.  Cellular phones,	of  course,  are
the space age version of the old car radio telephone.

The bill particularly affects hobby,  industrial  and  government  radio
users and  listeners  in  that	it  details  what  can-  and  cannot  be
monitored.   Supporters  of  the  legislation  include	such  industrial
giants as IBM, AT&amp;T, MCI, Motorola, GE, GTE, Bell telephone,  all  three
TV networks, ... and various telephone, videotex,  electronic  mail  and
computer equipment trade organizations.

Since most of us are concerned	with  the  personal  use  of  electronic
communications and the right to monitor  the  radio  spectrum,	we  will
focus on that aspect.

A  new	definition  of	electronic  eavesdropping  has	been   proposed.
Instead of "acquisition of the content", it is now "interception of  the
transmission of the content."

A penalty of up to a year in jail and $10,000 fine would be  imposed  on
those intercepting certain transmissions not intended  for  the  general
public in the shortwave band...such as remote broadcast pickup	stations
operating around  26  MHz  and	perhaps  ship-to-shore	radio  telephone
conversations.	  Any  encrypted  (scrambled)  transmissions  are   also
protected.

Strangely, scanner owners are subject to the year in  jail/$10,000  fine
if they tune in the old 150/450  MHz  carphone	service  -  but  only  6
months in jail and a $500 fine if they	listen	to  a  900  MHz  celluar
phone call!

Specifically exempted from coverage by the bill are all  amateur  radio,
CB and GMRS (General Mobile Radio Service) communications.    Ham  auto-
patch  telephone  calls  therefore  are  not  affected	even  though   a
participant expecting privacy might not be aware that the radio  portion
of the call is being widely transmitted.

The radio portion of a private telephone call terminated by  a	cordless
phone is also not privacy protected "since these  calls  can  be  easily
intercepted." The subcommittee noted that the FCC  requires  manufactur-
ers to include privacy disclaimers with cordless equipment.

Actually, just about any radiotelephone call can be easily  intercepted,
but the legislators perceived some as  harder  than  others.	Cellular
phone calls can even be received on consumer TV sets.

Broadcast services not intended for the public (such as  a  piggy-backed
FM subcarrier service) may not be monitored.

Radio services not protected by the bill include "any  station	for  the
use  of  the  general  public,	or  that  relates  to  ships,  aircraft,
vehicles, or persons in distress" as well as "any marine,  aeronautical,
governmental,  law  enforcement,  civil  defense,  or	public	  safety
communications ...readily accessible  [not  encrypted]	to  the  general
public." Thus, you can	listen	to  ongoing  law  enforcement  manuevers
....even Air Force One, but not a random phone call you	might  hit  upon
in the spectrum.

What can be monitored by satellite  dish  owners  was  specifically  not
resolved since	this  question	is  currently  before  the  House  Tele-
communications Subcommittee.

Private fixed microwave links, FM subcarriers, and  broadcast  auxiliary
or remote pickup stations were specifically protected.

Rep. Mike DeWine (R-Ohio) offered two  amendments  at  the  subcommittee
mark-up session dealing with cellular phone calls.

DeWine, a former prosecuting attorney, said that while he was  in  basic
agreement with the intent of the bill, he was troubled by the fact  that
old television sets  still  being  sold  can  inadvertantly  overhear  a
cellular phone call.  He  also	said  that  scanner  marketing	was  not
covered by the bill... "If a scanner stops at a cellular  phone  channel
...this bill means that (a scanner listener)  could  be  imprisoned  for
six months ...even if he did not disclose the information.

He  acknowledged  that	the  Justice  Department  told	them  that  they
wouldn't enforce scanner (or TV) cellular listening but "it's  basically
bad public policy to create a  law  that  everyone  knows  will  not  be
enforced... It brings about a disrespect for the  law.	  ...It  weakens
anybody's faith in the criminal justice system.    We  are  not  talking
about  difficult  enforcement.	  What	we  are  talking  about  is   an
impossibility,	unless	we   are    willing    to    violate	people's
Consititutional Rights and go into their own homes..."

The bill "...creates the  illusion  of	protection,"  DeWine  testified.
"The facts are that it will no more protect (cellular) the day after  we
pass this bill than the day before..."

Rep. DeWine suggested an amendment that would outlaw the  overriding  of
an encrupted telephone conversation.  He said laws  already  exist  that
prohibit divulging  intercepted  information.	 He  is  concerned  that
"...the cellular phone industry will use this bill to tell  people  that
they have an expectation of privacy when, in fact, they do not."

Chairman Kastenmeier agreed that the bill could not easily be  enforced,
but that encruption cost was prohibitive ($2,500 for a mobile,	$164,000
for a base station.) Declaring that he didn't want to  make  America  an
encrypted society, he urged defeat of the amendment.

Holding  up  a	scanner  advertisement	which  promoted  listening    to
"radiotelephone conversations that offer more  real-life  intrigue  that
most soap operas," Kastenmeier said "we cannot encourage this!	We  have
set down the rules of the road whereby that is off limits...	Scanners
are very useful devices, and they will continue to be,	excepting  there
ought to be some things that  are  protected  against  even,  yes,  even
against scanners." A voice  vote  defeated  the  amendment  by	a  clear
majority.

A second amendment was introduced by DeWine,  eliminating  the	6  month
prision sentence from the cellular penalty.  That too was rejected.

With no further amendment being offered,  the  substitute  draft  of  HR
3378 was unanimously adopted by voice vote.  The Subcommittee agreed  to
report the bill out to the Judiciary Committee for further action.

HR 3378 is still very far from being a law.  It must be approved by  the
Judiciary Committee  and  the  full  House  ...then  reconciled  with  a
similar bill pending before the Senate Copyright  Committee.	It  gets
signed into law by the	president.    The  reality  of	the  matter  is,
however, that government control over radio wave reception in your  home
will indeed be eventually enacted in some form.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Re:  RISKS-3.8
</A>
</H3>
<address>
    Dan Franklin 
&lt;<A HREF="mailto:dan@bbn-prophet.arpa">
dan@bbn-prophet.arpa
</A>&gt;
</address>
<i>
Fri, 20 Jun 86 14:38:35 EDT
</i><PRE>

&gt; Does anyone have any idea how the last part (radio telephones) could be
&gt; legally supported in view of other legal freedoms?  I thought that one
&gt; was free to listen to any frequency one wished in the US (Canada too).
&gt; You don't have to trespass to receive radio signals.

Receive them, yes; tell anyone else what you heard, no.  As I understand
the law, if a radio signal is part of a conversation--that is, clearly
directed at some specific other person--you are forbidden to divulge the
contents of that signal to a third party.  You might be forbidden to make
any other use of it, too; I don't remember for certain.

So eavesdropping is already suspect in current law, and it would not be
such a big change to say, for instance, that you could not *intentionally*
receive radiotelephone signals.  If your neighbor's radiotelephone
happened to come in on your stereo, you wouldn't then be breaking the law.
I do not actually know what the new law says, but there do exist ways to
safeguard privacy without compromising the "right to receive".

	Dan Franklin

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Privacy legislation (RISKS-3.6)
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 17 Jun 1986  00:32 EDT
</i><PRE>

   [On the same topic...]

Not true.  States routinely ban the use of radar detectors, and that
is nothing more than "listening to a frequency."  

   [Well, things seem to be changing.  In California, PASSIVE detectors
    are now legal, and can be bought at Radio Shack among others.  Mail
    order outfits are also doing a boom business.  I presume this is true
    in other states as well.  ACTIVE JAMMERS are of course still illegal.
    [[This messasge does not constitute an endorsement on the advisability
      of using a detector, or of the reliability of any such product.  I
      won't even contemplate the risks involved of using one.]]  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-124</DOCNO>
<DOCOLDNO>IA012-000123-B020-148</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.11.html 128.240.150.127 19970217003423 text/html 13645
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:32:53 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 11</TITLE>
<LINK REL="Prev" HREF="/Risks/3.10.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.12.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 11</H1>
<H2> Monday, 23 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A medical risk of computers (overdose during radiation therapy) 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Secure computer systems 
</A>
<DD>
<A HREF="#subj2.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Radar Detectors (Re: Privacy legislation in <A HREF="/Risks/3.10.html">RISKS-3.10</A>) 
</A>
<DD>
<A HREF="#subj3.1">
Jeff Makey
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Telco Central office woes in Southfield, MI. 
</A>
<DD>
<A HREF="#subj4.1">
via Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Reducing the managerial risks in SDI 
</A>
<DD>
<A HREF="#subj5.1">
Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Economic Impact of SDI:  Transcript Info 
</A>
<DD>
<A HREF="#subj6.1">
Richard A. Cowan
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: A medical risk of computers (overdose during radiation therapy)
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@uw-june.arpa ">
jon@uw-june.arpa 
</A>&gt;
</address>
<i>
Sat, 21 Jun 86 13:11:44 PDT
</i><PRE>

&gt; (Karen Sollins quotes story from Boston Globe - to paraphrase, patient
&gt; would be badly overdosed if operator first selected electron beams then
&gt; changed selection to X-rays.  David Parnas observed that two kinds of errors
&gt; were made; first, system should not have accepted inconsistent or unsafe 
&gt; input specifications, second, synchronization problem elicited when operator
&gt; types rapidly.

I work in a radiation therapy department, so my observations may be of 
interest.

First, this is a VERY SCARY STORY.  It was estimated that patients got 
17,000 to 25,000 rads in a single treatment.  For comparison, typical 
therapeutic doses are in the range 4000 - 6000 rads, delivered in 20 to 30
separate daily treatments administered over a month or more.  What is really
alarming here is that the therapy machines are set up to deliver dose rates
on the order of 100 rads per minute.  I believe that most therapists would 
assert that there was no way, physically, that a machine could deliver tens
of thousands of rads in a few seconds.  That was my reaction when I first
read the story in the New York Times (Sat. June 21, p.8, national edition).
The New York Times story mentioned that when the accidents first occured, 
the operators thought the patients had somehow been electrically shocked (by
leakage currents through the couch or something) rather than overdosed.

The New York Times story did not mention the x-ray/electron confusion, and 
that is the key to this accident.  A modern radiation therapy machine is based
on a linear accelerator that produces an electron beam with an energy of 
25 MeV or so.  You may direct the electrons directly into the patient (at this
energy electrons are ionizing radiation), or, to produce X-rays, you put a
heavy metal target in the electron beam, and when the electrons hit the target
X-rays come out the other side.   The target is moved in and out of the beam
automatically.  Here is my speculation of what happened: I suspect that the
current in the electron beam is probably much greater in X-ray mode (because
you want similar dose rates in both modes, and the production of X-rays is 
more indirect).  So when you select X-rays, I'll bet the target drops into 
place and the beam current is boosted.  I suspect in this case, the current
was boosted before the target could move into position, and a very high
current electron beam went into the patient.

How could this be allowed to happen?  My guess is that the software people
would not have considered it necessary to guard against this failure mode.
Machine designers have traditionally used electromechanical interlocks to
ensure safety.  Computer control of therapy machines is a fairly recent
development and is layered on top of, rather than substituting for, the old
electromechanical mechanisms.  I suspect there was supposed to be an
interlock between beam current and target position, which should have
prevented the beam from going on at all.  Maybe there was, but it was
broken, too.

I stress that I am not familiar with the design of this particular machine 
and that these are just speculations.

I should also mention that these are the first incidents I have heard of 
where an overdose was delivered due to an error in the therapy machine dose
rate.  Overdoses in radiation therapy do occur, but in all the cases I have
heard of they are due to incorrect planning and patient positioning:
that is, the radiation beams pass through the wrong part of the patient 
and irradiate healthy tissues rather than the tumor, or the therapists 
incorrectly estimate the dose rate inside the body that will be produced 
by a specified machine dose rate.

-Jonathan Jacky
Department of Radiation Oncology
University of Washington, Seattle WA

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Secure computer systems
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 17 Jun 1986  00:22 EDT
</i><PRE>

I have a question for the RISKS readership.

I want to make an arrangement in which I can feed data to a computer
in the physical possession of an adversary.  The output of the program
can be certified via a public-key encryption system.  The question if
this: can the computer hardware be designed so that its programming
cannot be compromised, even though the data would be entered by the
adversary?  Alternatively, can the computer detect attempts to
compromise it?
 
(Assume that the data is known to be good.)

  [Herb, You have almost gotten to the MUTUAL SUSPICION problem, where a
  vendor provides the program and a customer provides the data -- and where
  neither trusts the other.  Limited solutions can be conceived, but many
  assumptions must be made about the integrity of the communication paths, the
  trustworthiness of the environment in which the mutually trusted arbiter
  must run, the absence of all sorts of side effects (such as Trojan horses)
  and covert channels, the adequacy of the hardware if a general solution is
  sought, the nontamperability of the hardware and the trusted software, and
  so on.  In your specific case, the answer is to a first approximation NO,
  although if you start making (unreasonable?) assumptions, MAYBE.  Peter]

    &lt;&lt;I'm not concerned about the hardware being maintainable 
    (though it can be replaceable at great cost).  Herb&gt;&gt;

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Radar Detectors (Re: Privacy legislation in <A HREF="/Risks/3.10.html">RISKS-3.10</A>)
</A>
</H3>
<address>
Jeff Makey 
&lt;<A HREF="mailto:Makey@LOGICON.ARPA">
Makey@LOGICON.ARPA
</A>&gt;
</address>
<i>
21 Jun 86 20:49 PDT
</i><PRE>

Radar detectors are presently legal in 48 states.  Only in Connecticut,
Virginia, and (I think) the District of Columbia are they illegal.  As
I understand it, Virginia's law is based on the idea that it is illegal
to use radio frequencies in the commission of a crime.  Thus, it would
seem that using a radar detector in Virginia is illegal only if you are
committing a crime (e.g., speeding) when the police use radar on you.
This sounds too good to be true, so it probably is :-).  I know nothing
about the specifics of Connecticut's or DC's laws on radar detectors.

If you are interested in the risks of NOT using a radar detector I
would be happy to explain why I am a very satisfied owner of one.  This
issue isn't really appropriate for RISKS (even though the good ones
*do* contain computers!) so let's keep this sort of discussion private.

                         :: Jeff Makey
                            Makey@LOGICON.ARPA

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Telco Central office woes in Southfield, MI.
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: 22 Jun 86 09:47:20 EDT (Sun)
From: the tty of Geoffrey S. Goodfellow &lt;crcwdc!geoff@seismo.CSS.GOV&gt;
ReSent-To: RISKS@SRI-CSL.ARPA

Clipped from the Telecom digest...

------- Forwarded Message

Date: 21 Jun 86 03:22-EDT
From: Moderator &lt;seismo!XX.LCS.MIT.EDU!Telecom-REQUEST&gt;
Subject: TELECOM Digest V5 #122

TELECOM Digest                          Saturday, June 21, 1986 3:22AM
Volume 5, Issue 122

Date: Fri, 13 Jun 1986  06:06 MDT
From: Keith Petersen &lt;W8SDZ@SIMTEL20.ARPA&gt;
Subject: Northern Telecom DMS-100 digital switch problems

On Wednesday, May 28, the Southfield, MI (suburb of Detroit) Michigan
Bell ESS office's Northern Telecom DMS100 digital switch went down for
almost the whole afternoon, reportedly depriving 35,000 subscribers of
service (they couldn't even get a dial tone).

Thursday, May 29, it occurred again sometime in mid-morning and the
digital switch was down for almost the entire business day (it came
back around 5:30 pm local time), this time reportedly taking out
50,000 subscribers, including the police and fire departments.

In an interview, a spokesman for Michigan Bell was quoted as saying
they don't know what caused the problem.  He went on to say they are
working closely with Northern Telecom to find the cause.

A spokesman for Northern Telecom, in a recent telephone conversation,
said that some 20-30 software updates for the DMS100 were necessary to
cure certain problems with passing 212a and V22.bis modem signals
through the switch.  It is unclear at this time if these updates have
any bearing on the outages of the past two days.  According to sources
at Michigan Bell and Northern Telecom, the updates have not been done
to the DMS100 digital switch in the Southfield central office.  They
are reportedly scheduled to be done on June 7th.

Stay tuned...

- --Keith Petersen
Arpa: W8SDZ@SIMTEL20.ARPA
uucp: {ihnp4,allegra,cmcl2,dual,decvax,mcnc,mcvax,vax135}!seismo!w8sdz

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Economic Impact of SDI:  Transcript Info
</A>
</H3>
<address>
Richard A. Cowan 
&lt;<A HREF="mailto:COWAN@XX.LCS.MIT.EDU">
COWAN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue 17 Jun 86 19:47:52-EDT
</i><PRE>
To: arms-d@MC.LCS.MIT.EDU, risks@MC.LCS.MIT.EDU

About 5 months ago I advertised a transcript/tape for a debate on the
economic implications of Star Wars, held at MIT on November 21, 1985.

Finally, I have uploaded it from my Mac, and it is available online.
The debate is between:

Lester Thurow, MIT Economist
Leo Steg, GE Space Systems Division (retired)
Bernard O'Keefe, Chairman of EG&amp;G

For FTP'ing it, it is located in  MIT-XX:&lt;cowan&gt;economics.sdi

If you can't FTP it, tell me and I'll send it to you.
-rich

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-125</DOCNO>
<DOCOLDNO>IA012-000123-B020-172</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.12.html 128.240.150.127 19970217003441 text/html 15423
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:33:10 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 12</TITLE>
<LINK REL="Prev" HREF="/Risks/3.11.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.13.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 12</H1>
<H2> Tuesday, 24 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
License Plate Risks 
</A>
<DD>
<A HREF="#subj1.1">
Chuck Price
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  SDI is for ICBMs, Not Terrorists 
</A>
<DD>
<A HREF="#subj2.1">
Mark Day
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Still another kind of clock problem 
</A>
<DD>
<A HREF="#subj3.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Estimating Unreported Incidents 
</A>
<DD>
<A HREF="#subj4.1">
Ken Laws
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Estimating Unreported Incidents -- and the risks of using statistics 
</A>
<DD>
<A HREF="#subj5.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Privacy legislation (RISKS-3.8) and radio eavesdropping    
</A>
<DD>
<A HREF="#subj6.1">
Jerry Mungle
</A><br>
<A HREF="#subj6.2">
 Jeff Mogul
</A><br>
<A HREF="#subj6.3">
 Jim Aspnes
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
License Plate Risks
</A>
</H3>
<address>
Chuck Price
&lt;<A HREF="mailto:price@src.DEC.COM ">
price@src.DEC.COM 
</A>&gt;
</address>
<i>
Mon, 23 Jun 86 09:56:05 pdt
</i><PRE>

I heard the following tale on KCBS this morning.  [I intersperse a few
details from the SF Chron, 23 Jun 86.  PGN]

It seems that this fellow [Robert Barbour] desired personalized license
plates for his car.  Since he loved sailing, he applied for ``SAILING'' and
``BOATING'' as his first two choices [seven years ago]. He couldn't think of
a third name of NAUTICAL intent, so he wrote ``NO PLATE'' in as his third
choice.

You guessed it. He got ``NO PLATE''.

A week or so later, he received his first parking ticket in the mail.  This
was followed by more and more tickets, from all over the state [2500 in
all!].  It seems that when a police officer writes a parking ticket for a
car with no license plates, he writes ``NO PLATE'' on the ticket.

Our friend took his problem to the DMV, which informed him that he should
change his plates.

The DMV also changed their procedures. They now instruct officers to write
the word ``NONE'' on the unplated parking tickets.

Wonder who's gonna get those tickets now?

-chuck price

     [Obviously some poor sap whose license plate says ``NONE''!]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
SDI is for ICBMs, Not Terrorists
</A>
</H3>
<address>
Mark S. Day 
&lt;<A HREF="mailto:MDAY@XX.LCS.MIT.EDU">
MDAY@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Mon 23 Jun 86 12:04:46-EDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Bob Estell states that   "SDI does not equate to ICBM defense."

This is simply not true.  Even in Reagan's first speech about rendering
nuclear weapons "impotent and obsolete" (Mar 23, 1983), he went on to
say that he was
    "directing a long-term research and development program to begin to
     achieve our ultimate goal of eliminating the threat posed by 
     STRATEGIC NUCLEAR MISSILES."  [Emphasis added]

From its inception, SDI has been intended to defend against and deter a
massive attack by ICBMs.  As others have previously pointed out in RISKS,
terrorists don't need to deal with ICBMs and would be foolish to try.  
At the Stanford debate on SDI feasibility, Maj. Pete Worden (special asst.
to the Director of SDIO) answered a question about terrorists and smuggling
bombs into the country by saying "We are trying to deter something that
is reasonably military, not a terrorist act."

SDI is intended as a defense against Soviet ICBMs and (on particularly 
optimistic days at SDIO) Soviet cruise missiles.  It is not intended to 
save the United States population from every nuclear threat.

--Mark

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Still another kind of clock problem
</A>
</H3>
<address>
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
23 Jun 86 10:00:39 PDT (Monday)
</i><PRE>
To: RISKS-Request@SRI-CSL.ARPA

You might be amused by the anomalous dates [in an earlier message from
Rodney to me, not included].  Our power was off all weekend for some work.
When I came in this morning, no computer servers were working yet --
including the time servers.  So I set the date and time on my machine
myself, including stuff like "Hours offset from Greenwich Mean Time" and
"First day of Daylight Savings Time"! (Luckily they have proper default
values.)  I then interrupted (instead of booted) into another volume.
Because of that, this volume's clock tried unsuccessfully to locate a time
server and, by default, resumed ticking from when I left Friday evening! And
once it begins ticking, it apparently never checks again for a time server.

When I typed in my RISKS contribution and sent it, it had that Friday
timestamp, though it was Monday and I was (correctly) citing a Sunday
news article.

	--Rodney

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Estimating Unreported Incidents 
</A>
</H3>
<address>
Ken Laws 
&lt;<A HREF="mailto:Laws@SRI-AI.ARPA">
Laws@SRI-AI.ARPA
</A>&gt;
</address>
<i>
Fri 20 Jun 86 16:21:04-PDT
</i><PRE>
To: Risks-Request@SRI-CSL.ARPA

  [In RISKS-3.8, I noted how rarely I get two reports of the same incident,
   and wondered how many do not get reported at all.  PGN]

There is actually a statistical technique (based on the Poisson distribution, 
I'm sure) for estimating the number of unreported items from the frequencies
of multiply reported ones.  It was developed for estimating true numbers of
Malaysian butterfly species from collected ones, and has recently been used
to validate a newly discovered Shakespeare poem from the percentages of
words that were used 0, 1, ... times in the accepted Shakespearean literature.
					-- Ken Laws

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Estimating Unreported Incidents -- and risks of using statistics
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Tue 24 Jun 86 01:09:31-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Ah, Ken's message brings us to the risks of computer authentication! The
poem in question really did not read like authentic "Shakespeare" to me; it
seemed vastly too pedestrian, childish, and uncharacteristically repetitive.
But then, don't get us started on who actually wrote the works attributed to
William Shakespeare.  That might be a little risky for this Forum.
(However, for some fascinating background, see Charlton Ogburn's book "The
Mysterious William Shakespeare -- the Myth &amp; the Reality", pursuing the case
that the man known as "William Shakspere" was functionally illiterate, with
almost no documents bearing his signature or handwriting and no known
contemporary literary activity, and that he could not possibly have written
the works attributed to "Shakespeare".)  (By the way, I don't think it was
Marlowe, Bacon, or -- as Ogburn contends -- Edward de Vere &lt;the 17th Earl of
Oxford&gt; who wrote the works of Shakespeare.  But, there are also some
multi-ghost-author theories that would make the use of computer analysis for
style comparisons to authenticate the alleged poem as belonging to the works
of supposedly a single author quite speculative!) [You thought I was
drifting away from computer risks, didn't you?]  

At any rate, let us be very careful with such statistical arguments in that
case -- and in other computer-related cases as well.  For example, with
respect to computers in banking and credit applications, the cases of
intentionally undocumented internal frauds are known to be very
considerable; using such statistical arguments to estimate unreported
incidents is very suspicious.  People certainly aren't "normal".  Why should
distributions of unknown or extraordinary cases be expected to be normal?

PGN
            
</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Privacy legislation (RISKS-3.8) and radio eavesdropping
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
16 Jun 1986 06:09:22 PDT
</i><PRE>
From: Jerry Mungle &lt;JMUNGLE@USC-ISIF.ARPA&gt;
To: RISKS FORUM (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;

Re: Michael Wagner's query about privacy of radio telephone...

    [Here are THREE more messages on this subject.  Each adds a little more 
     to what Dan Franklin contributed in <A HREF="/Risks/3.10.html">RISKS-3.10</A>.  This time I did not
     have the patience to edit each one down to its nub, so please read them
     accordingly...  PGN]

    For quite a while telephone traffic has been carried by satellite
links.  It is quite easy to receive such transmissions using nothing
more sophisticated than a backyard dish antenna, and the demultiplexing
needed to recover a conversation is doable by undergraduate EEs.  I believe
it is quite illegal to "intercept" phone conversations (or data transmissions
via phone lines) in this fashion.  However, it is *very* difficult to detect
such activities.

    I do not believe it should be illegal to monitor ANY radio communication,
as the airways are public property.  But there seems to me to be precedence
for laws regulating reception of radio transmissions (beware, I am not a 
lawyer).

    The risks to computer systems lies in the ease with which data transmitted
over phone lines may be intercepted.  This relative ease is offset to some
degree by the difficulty of finding the particular phone link one wishes
to monitor.  But, given a reasonable level of support, it should be possible
to eavesdrop on conversations/data transmission which one desires to hear.
Sales figures, marketing info, experimental data.... lots of valuable data
go unencrypted over the phones every day.

</PRE>
<HR><H3><A NAME="subj6.2">
Re: Privacy legislation (RISKS-3.8) and radio eavesdropping
</A>
</H3>
<address>
Jeff Mogul 
&lt;<A HREF="mailto:mogul@su-shasta.arpa">
mogul@su-shasta.arpa
</A>&gt;
</address>
<i>
17 Jun 1986 1128-PDT (Tuesday)
</i><PRE>

In RISKS-3.8, ubc-vision!utcs!wagner@seismo.CSS.GOV (Michael Wagner) asks:
    Does anyone have any idea how the last part (radio telephones) could be
    legally supported in view of other legal freedoms?  I thought that one
    was free to listen to any frequency one wished in the US (Canada too).
    You don't have to trespass to receive radio signals.

It's been a decade or so since I was familiar with current US communications
law (as a licensed Amateur Radio operator, I had to pass several exams
covering this sort of thing), but I recall that although there is no
prohibition against receiving radio signals, there is a prohibition against
divulging what you receive to any other party.  Of course, this doesn't
apply to all radio services (it's not against the law to reveal baseball
scores you heard on an AM broadcast station) and I doubt it's often enforced.

Compare this to what a computer system manager might face when unraveling a
mail snafu.  I might not be able to avoid seeing the text of an unencrypted
message (as I watch packets moving between hosts) but it would certainly be
unethical for me to reveal what I saw, or indeed to make any use of it.
Ideally, the technology would be such that I could not accidentally see the
contents of a message while performing a management function, but in today's
world I think the only enforceable prohibition is against divulging or using
electronic mail, not against seeing it.  (Of course, seeing by means of
unauthorized access is also prohibitable.)

-Jeff Mogul

</PRE>
<HR><H3><A NAME="subj6.3">
Re: Privacy Legislation (<A HREF="/Risks/3.10.html">RISKS-3.10</A>)
</A>
</H3>
<address>
Jim Aspnes 
&lt;<A HREF="mailto:asp@ATHENA.MIT.EDU">
asp@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 23 Jun 86 11:39:45 EDT
</i><PRE>

    Date: Tue, 17 Jun 1986  00:32 EDT
    From: LIN@XX.LCS.MIT.EDU
    To:   ubc-vision!utcs!wagner@SEISMO.CSS.GOV (Michael Wagner)
    Cc:   RISKS-LIST:@XX.LCS.MIT.EDU, risks@SRI-CSL.ARPA
    Subject: Privacy legislation (RISKS-3.6)

       [On the same topic...]

    Not true.  States routinely ban the use of radar detectors, and that
    is nothing more than "listening to a frequency."  

Most states do not actually ban the use of radar detectors, but rather
the operation of a motor vehicle containing one; as I understand it,
if you want to sit at home and detect your burglar alarm, you are
entirely within the law.  There is no constitutional or federal
restriction on how states can regulate your driving.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-126</DOCNO>
<DOCOLDNO>IA012-000123-B020-193</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.13.html 128.240.150.127 19970217003500 text/html 17840
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:33:28 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 13</TITLE>
<LINK REL="Prev" HREF="/Risks/3.12.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.14.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 13</H1>
<H2> Thursday, 26 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Risky Gap Between Two Design Cultures 
</A>
<DD>
<A HREF="#subj1.1">
Jack Goldberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of nuclear power 
</A>
<DD>
<A HREF="#subj2.1">
Dan Franklin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Research programs that pay for themselves 
</A>
<DD>
<A HREF="#subj3.1">
Rich Cowan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Having an influence from "within the system" 
</A>
<DD>
<A HREF="#subj4.1">
Rich Cowan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RISKS in running RISKS -- continued 
</A>
<DD>
<A HREF="#subj5.1">
PGN and an unhappy Mailer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The Risky Gap Between Two Design Cultures
</A>
</H3>
<address>
Jack Goldberg 
&lt;<A HREF="mailto:JGOLDBERG@SRI-CSL.ARPA">
JGOLDBERG@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Wed 25 Jun 86 12:01:12-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

Over the centuries of experience in dealing with hazards, mechanical and
civil engineers developed a culture of safe design, with principles and
practices appropriate to the various kinds of products.  This culture was
expressed in the design of mechanisms that implemented various safety
functions, such as barriers to undesired motion, redundancy in the event of
local failures, self-adjustment to losses of tolerance, and so on.  For each
kind of product, particular mechanisms were developed to accomplish these
functions, e.g., pawls, detents, rails, ratchets, fuses.

The advent of computers and inexpensive sensors and motors made possible
tremendous economies in manufacture by eliminating all those particular
mechanisms and their often costly assembly (consider the dramatic comparison
in complexity of mechanism between the original teletype machine and a
modern typewriter/printer).  Mechanical design of the new systems has been
dramatically simplified, and the complex functions, including safety
functions, have been relegated to a control program.  In a sense, the design
is created on a blank slate.

Who creates that design?  Generally someone who is a professional
programmer, often a novice, who has inherited the culture of that
profession.  There are many aspects to that culture, but it rarely includes
the lore and practices of safe design (and the exposure to the machinery of
legal liability) that is the inheritance of mechanical and civil engineers.
It is often based on a partitioning of responsibility between the
hypothetical (and often anonymous) "customer" and the programmer-supplier, a
partitioning that hides the ultimate users from the designer.  Also, too
often, the programmer's education in matters of the physical world has been
compromised by the demands of training for his profession.

Often, the practitioners in the new culture see themselves as generalists,
able to solve any new problem, and they move frequently from one application
area to another.  Consequently, they seldom have the time to study and
understand the things that users or designers in a particular field know or
assume to be obvious, and so they must imagine and re-invent them.
Tragically, those imperfectly mastered things sometime seriously affect safety.

In short, the culture of safety that traditional engineers have expressed in
particular mechanisms has been tossed out along with those mechanisms, and
is being re-discovered, painfully, by a new generation of designers that has
no connection with the traditional culture.  In this light, risks arising in
contemporary computer-based system design may be seen as a consequence of a
gap between two design cultures.  The gap is both generational and
professional; there are many safety engineers in industry, but they and
programmers speak different languages.

In a different context, awareness of the loss of knowledge by experts in
various practices, due to their lack of replacement in the work force, has
stimulated some computerists to try to capture that knowledge.  How well
they are doing that is another matter, but it may be that some conscious
gap-bridging between the cultures would save the world some amount of
misfortune and misery.

                                    Jack Goldberg, SRI International

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Risks of nuclear power
</A>
</H3>
<address>
    Dan Franklin 
&lt;<A HREF="mailto:dan@bbn-prophet.arpa">
dan@bbn-prophet.arpa
</A>&gt;
</address>
<i>
Tue, 24 Jun 86 14:03:42 EDT
</i><PRE>

TMPLee@DOCKMASTER.ARPA discusses nuclear energy vs. solar energy and "taking
all the risks into account".  The risk he is primarily concerned with is the
risk of falling off a solar energy device while cleaning off the snow.

If we are going to take all the risks into account, let's face it: the risks
to those involved in the actual energy production are simply insignificant
in the debate on nuclear vs. other forms of energy.  That debate focuses
almost entirely on the risks to innocent bystanders.  These are the risks
that always matter most, precisely because people do not willfully undertake
them, but rather end up subjected to them, and people are not willing to be
*subjected* to nearly as much risk as they are willing to *decide* to take,
or let others decide to take.

The fundamental political problem of nuclear power is that it has a small
probability of being disastrously more injurious to bystanders than any
other form of power generation except dams.  (Solar power satellites which
deliver their power by microwave are a future contender.)

TMPLee's mention of low-level radiation emitted by coal-fired plants is, of
course, directly relevant to this issue.  But in the wake of Chernobyl, as
in the wake of TMI (and in the wake of Pilgrim's safety problems...), the
small probability of disaster clearly needs to be discussed.

	Dan Franklin

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Research programs that pay for themselves
</A>
</H3>
<address>
Richard A. Cowan 
&lt;<A HREF="mailto:COWAN@XX.LCS.MIT.EDU">
COWAN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu 26 Jun 86 00:08:21-EDT
</i><PRE>
To: risks@SRI-CSL.ARPA

Let me add a few comments to Bob Estell's point #6:
 &gt;   "Going to the moon in the '60's cost the USA nothing!...
 &gt;   The DIFFERENCE between tax dollars paid by those wearing pacemakers, and 
 &gt;   the "aid to their families" that would have been paid had those heart 
 &gt;   patients died or been disabled, is more than $25 billion." 

  There are two problems with these types of conclusions.  First of all,
there are plenty of big non-space or non-military government programs that
we could spend our money on that are equally likely to have spinoffs; there
must be a reason why SDI should be built rather than these projects.  But
the classification barriers of SDI will inevitably reduce spinoffs.  Not
only that, but some things in SDI will certainly be useless commercially.
Pacemakers don't need to survive nuclear explosions.

  Secondly, any government program has an opportunity cost which is not
factored into your calculation: when we devote scientific resources to the
private sector, we lose out on the benefits we would have gained if those
resources weren't used up by the government.  An example is mentioned in a
May issue of the weekly trade paper "Electronics News": a Japanese witness
at some hearings on US competitiveness points out that the United States
spends hundreds of millions on high-strength, lightweight carbon materials
for aircraft wings, while the Japanese developed the same materials very
cheaply for golf clubs and tennis racquets.

   Are there things which we could use more than we could use SDI?  Are
there other government expenditures (perhaps national health insurance)
that would REALLY cost nothing?  Well, I recently heard that aside from
public police forces and the military, about $300 billion per year is spent
on security (including locks, alarms, etc.)  To get an idea where this
comes from, consider that MIT's police force costs a couple million, and
all universities put together must spend about $1 billion.

Now if businesses instead spent $100 billion of this money on raising the
minimum wage $2, spent $50 billion on reducing unemployment by reducing the
work week, and $20 billion went to the government to improve housing
programs and public facilities to keep young people occupied, then perhaps
the need for so much security would be reduced, because the root causes of
crime would be diminished.  It would therefore "cost nothing" for the
private sector to divert $170 billion of its security bill and improve the
social stability and welfare of the country.  The problem with such a plan
is that the benefits come only in the long term; only the greater short
term costs are seen on corporate balance sheets.

-rich

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Having an influence from "within the system"
</A>
</H3>
<address>
Richard A. Cowan 
&lt;<A HREF="mailto:COWAN@XX.LCS.MIT.EDU">
COWAN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu 26 Jun 86 00:11:07-EDT
</i><PRE>
To: risks@SRI-CSL.ARPA

And now a few comments on Bob Estell's point 10 on working for SDI:
&gt; "But if we do take the opportunity, then we can use the
&gt; managers' short term interests to an advantage; i.e., we can honestly say
&gt; that "Star Wars" [R2D2 et al] is not possible today; and then diligently
&gt; work to produce what is reasonable."

You have here touched upon what I believe is -- more often than not -- a
delusion:  that it is more effective to work within the system to change
it than to protest it from without.  In this case, working within the
system means working on Star Wars to demonstrate part of it to be feasible
or infeasible.

There are several problems with this.  First, within a large institution
you may be isolated from resources, or a diversity of viewpoints needed to
make an impartial decision.  This is less true with Star Wars than with
other programs because there's lots of mainstream publicity.  It is also
less true in a university than in a defense contractor.

Second, and more importantly, what an engineer says is likely to get
manipulated for political reasons -- like the ignored warnings before the
space shuttle disaster.  If of 10,000 engineers working on SDI, 5000
include negative critical material in their research reports, and the other
5000 are completely uncritical of SDI, what do you think Congress will
hear?  Well, I can guarantee that they will hear mostly glowing reports
about research progress from upper-level managers and lobbying
organizations of the companies doing SDI research.  If your strategy
to change things is to become one of those upper-level managers, you may
have to compromise your values to achieve promotion, and temper your
criticisms to avoid losing "credibility" once you get there.

Yet Congress is hearing the other side on SDI.  How?  Because engineers are
not relying on the companies they work for to communicate their insight.
They are going outside the normal channels of communication -- like the
1600 scientists working at government labs who recently petitioned Congress
to curtail SDI spending.  And ultimately, communicating one's concerns
directly to people in the community is necessary.

What is unfortunate, and I believe dangerous in a democracy, is that
people working for the government are afraid of speaking out on public
policy issues for fear of reprisal.  The recent statements by
Undersecretary of Defense for Research and Engineering Donald Hicks may
have heightened this fear.  Fortunately, the Pentagon has recently
dissociated itself from Hicks' statements.  (Science, May 23)

-rich

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Returned mail: Service unavailable
</A>
</H3>
<address>
Mail Delivery Subsystem
&lt;<A HREF="mailto:MAILER-DAEMON@nprdc.arpa ">
MAILER-DAEMON@nprdc.arpa 
</A>&gt;
</address>
<i>

</i><PRE>
[Actual Subject:  RISKS in running RISKS -- continued]

   [One of the greatest annoyances in running a large mailing enterprise such
    as RISKS is fielding the incessant net-barfs, including having my mailbox 
    cluttered with multiple copies of the Forum on net addresses that don't 
    work now and then.  (Some mailers that keep retrying periodically, and 
    send back advisories each time.)  Here is a fine example -- which of 
    course more generally represents another type of risk in distributed 
    systems.  PGN]

    [FOOTNOTE:  The more general problem of copious rejected mail would be
    an order of magnitude worse if we went to individual messages rather
    than the current digest format.  (I now have requests from BITNET and 
    USENET to do send out undigestified messages, and would love to let them
    do the undigestifying.  Perhaps more regional reforwarding centers would 
    minimize rejects and reduce mailing list maintenance substantially.  But,
    I nevertheless get mystery rejection notices for people not even on my
    list, because of redistribution problems elsewhere.)]

   ----- Transcript of session follows -----
&gt;&gt;&gt; DATA
&lt;&lt;&lt; 554 &lt;malloy&gt;... Mail loop detected
&gt;&gt;&gt; QUIT
&lt;&lt;&lt; 554 sendall: too many hops (30 max)           [... but quite a brew-haha!]
554 &lt;malloy@hull&gt;... Service unavailable: Bad file number

   ----- Unsent message follows -----
Received: from pacific.ARPA by nprdc.arpa (4.12/ 1.1)
	id AA00971; Tue, 24 Jun 86 03:04:28 pdt
Received: from hull.aegean.arpa (hull.ARPA) by pacific.ARPA (4.12/4.7)
	id AA11313; Tue, 24 Jun 86 03:04:01 pdt
Received: from nprdc.arpa (aegean) by hull.aegean.arpa (2.2/SMI-2.0)
	id AA14974; Tue, 24 Jun 86 02:50:15 pdt
Received: from pacific.ARPA by nprdc.arpa (4.12/ 1.1)
	id AA00967; Tue, 24 Jun 86 03:04:07 pdt
Received: from hull.aegean.arpa (hull.ARPA) by pacific.ARPA (4.12/4.7)
	id AA11309; Tue, 24 Jun 86 03:03:40 pdt
                        [... many hops omitted ...  I think you get the idea.  
                             Notice the clock drift while you're at it.]
Received: from hull.aegean.arpa (hull.ARPA) by pacific.ARPA (4.12/4.7)
	id AA11281; Tue, 24 Jun 86 03:01:05 pdt
Return-Path: &lt;NEUMANN@SRI-CSL.ARPA&gt;
Received: from nprdc.arpa (aegean) by hull.aegean.arpa (2.2/SMI-2.0)
	id AA14942; Tue, 24 Jun 86 02:47:19 pdt
Received: from pacific.ARPA by nprdc.arpa (4.12/ 1.1)
	id AA00935; Tue, 24 Jun 86 03:01:10 pdt
Received: from nprdc.arpa (aegean.ARPA) by pacific.ARPA (4.12/4.7)
	id AA11271; Tue, 24 Jun 86 03:00:39 pdt
Received: from SRI-CSL.ARPA (sri-csl.arpa.ARPA) by nprdc.arpa (4.12/ 1.1)
	id AA00926; Tue, 24 Jun 86 03:00:30 pdt
Date: Tue 24 Jun 86 01:41:53-PDT
From: RISKS FORUM    (Peter G. Neumann, Coordinator) &lt;RISKS@SRI-CSL.ARPA&gt;
Subject: <A HREF="/Risks/3.12.html">RISKS-3.12</A> [...]

     [But, gee Mr. Wizard, it worked just fine on the previous issues!]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B27-127</DOCNO>
<DOCOLDNO>IA012-000123-B020-210</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/3.14.html 128.240.150.127 19970217003520 text/html 15732
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 00:33:42 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 3: Issue 14</TITLE>
<LINK REL="Prev" HREF="/Risks/3.13.html">
<LINK REL="Up" HREF="/Risks/index.3.html">
<LINK REL="Next" HREF="/Risks/3.15.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/3.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 3: Issue 14</H1>
<H2> Friday, 27 June 1986 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A Personal View on SDI 
</A>
<DD>
<A HREF="#subj1.1">
Harlan Mills
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Privacy legislation (<A HREF="/Risks/3.10.html">RISKS-3.10</A>) 
</A>
<DD>
<A HREF="#subj2.1">
Jerome H. Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks in burning wood 
</A>
<DD>
<A HREF="#subj3.1">
Mike McLaughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Mailer explosion 
</A>
<DD>
<A HREF="#subj4.1">
Sean Malloy
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A Personal View on SDI from Harlan Mills
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@SRI-CSL.ARPA">
Neumann@SRI-CSL.ARPA
</A>&gt;
</address>
<i>
Fri 27 Jun 86 13:35:07-PDT
</i><PRE>
To: RISKS@SRI-CSL.ARPA

   [The following note has been circulated privately by Harlan Mills,
    noted practitioner of structured programming and other software
    engineering techniques, and is included here with his permission.  PGN]

	Two of my friends, whose intelligence and integrity I respect and
admire greatly, namely David Parnas and James Horning, have stated their
belief that the SDI concept is impractical.  At the same time other groups
of scientists and engineers, from dozens to hundreds to thousands are
declaring their opposition to SDI on various grounds from infeasibility to
conscience.  Yet, we do not seem to find comparable groups of scientists
and engineers on the pro side of SDI in public forums.  Is it because there
is no pro side?  Or is there some other reason?  I think there is another
reason.

	First, there are many scientists and engineers actively working on
SDI research.  Does that mean they are for SDI or are simply hypocrites?
I think for most of them that neither is the case.  There is another
reason possible.  I believe it is the case with me.

	I personally do not know enough to be for or against SDI.
But I do know enough to want our country to be strong in technology.
As a citizen, I depend on our system of government, and particularly
our Congress, to decide about SDI.

	I regard SDI as a political question that will be ultimately
settled in our political system by the 525 members of our Congress.
I trust them to make the wisest disposition possible of this question.
It seems too complex a qustion to settle on a simple up or down vote.
It will take time, experience, and reflection to progressively deal with it.
Much of that experience and reflection will be political and diplomatic;
some of it will be military and technical in nature.  I believe the intent
of most scientists and engineers working on SDI is to explore the technical
side intelligently enough to provide the widest range of options possible
for the political and diplomatic side.

	In order to pursue the SDI question, the administration,
particularly the military, must organize a substantial and serious effort
that itself involves a narrower form of political effort.  It must
advocate a position and lobby Congress for the opportunity to pursue SDI
military and technical research in a responsible way.  But I do, indeed,
believe that members of Congress, with the facts, the checks and balances
of our political system, and constitutional guarantees (e.g., a free
press) will resolve the question of SDI intelligently in due course and
process.

	So I regard the positions of my friends Parnas and Horning, and of
many other scientists and engineers, as thoughtful and courageous acts of
technical or political conviction.  In particular, Parnas and Horning are
expert witnesses in computer science and software engineering.  People in
the administration and members of Congress should and do listen to them.
In matters of theory in computer science or software engineering, I have
never had an occasion to differ or disagree with either of them.  But I do
not always agree with their extrapolations into engineering expectations
in large systems such as required by SDI.

	In the first place, I believe it is somewhat misleading to convert
the problem of SDI feasibility into the question of software perfection.
The problem is deeper than software.  The recent shuttle tragedy reminds
us that any man-made system can fail for many reasons beside software.
So the problem is even worse than simply software.  The best man can do in
any physical system is to reduce the probability of failure to low levels,
not to zero.  If the hardware fails more often then the software, it is
wiser to improve the hardware even though the software is not perfect.

	In the second place, I believe that engineering expectations and
achievements in large systems depend as much on the checks and balances
of good management processes as on engineering theory.  We never get away
from the fallibility of people, but we can reduce the fallibility of
organizations of people below the fallibilities of their individuals.
And with sound engineering theory, there is no real limit to that reduction
in fallibility of organizations.  For me, they key is the combination of
sound engineering theory and good management process -- both are necessary
and neither is sufficient.

	So my extrapolations into what is possible for SDI software are
more open ended than those of Parnas or Horning.  But, as Parnas and
Horning both suggest, we surely will not get there doing business as usual
in the DoD software acquisition process.  Thus, as with the Congress, I
expect DoD to rise to the occasion as the needs arise.  After all, it's
our DoD, as well as our Congress.

	In another era, in the late 40's I was involved in a losing cause
on the issue of "One World or None."  As a student, I was convinced by the
arguments of my elders that atomic theory should be declassified and that
the U.S. should lead the way with an open science policy throughout the
world.  The science world was split then -- Niehls Bohr on one side,
Edward Teller on the other (and Robert Oppenheimer, I think, caught in
the middle).  But, of course, the cold war and Korea settled things
irreversibly.  In spite of the excesses of a few individuals, I believe
our Congress and administration came through that period as well
as possible in steering a science policy course.  I was personally
disappointed in a dream of open science and abundant peace, but I do not
see how it could have been pulled off if our government could not see how.

	That is how I look at SDI.  I would like to help my country be
strong in science and engineering.  The adminstration and the military
are agents of the country in that endeavor.  But, I depend on the Congress
to make the final, collective, decisions, in how to best reflect that
strength for peace in political, diplomatic, and military matters.

	However, as events unfold and we all learn more, both about SDI
needs and engineering theory, if I come to the same belief as Parnas and
Horning, you can be sure that I will join them, and try to bring my
opinions to the administration and Congress, too.  I want to be on the
right side, whether it loses or not!
                                             Harlan Mills

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Privacy legislation (<A HREF="/Risks/3.10.html">RISKS-3.10</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Fri, 27 Jun 86 15:16:13 EDT
</i><PRE>
From: Jerome H. Saltzer &lt;Saltzer@ATHENA.MIT.EDU&gt;

The reported privacy legislation proposal for radio-based telephone
conversations is quite analogous to some of the proposals that circulated
for several years around the cable and satellite TV industry.  In that case
as well as this, technology bluffing is dominating the conversation.  The
overall scenario is that economic interests are claiming that technology
can't supply privacy economically, so draconian laws are the best way to
proceed.  Responsible engineers should object to this line of reasoning
whenever they notice it being misused.

Since in-the-clear radio communications are trivially, even accidentally
interceptable, the public interest requires that the first avenue to explore
in protecting them be narrowly technological (scrambling) rather than
broadly targeted legal approaches that can have surprising side effects on
the bill of rights.  But commercial interests that don't want to think about
extra costs or delay in getting to market use technological intimidation to
produce public positions that scrambling is too expensive.

The cable and satellite broadcast communities have come to realize that laws
don't help as much as they hoped and they have to scramble anyway.  It would
be nice if we could somehow get that fact across to the legislators who are
being bamboozled by the cellular telephone business.

The worst part about passing a law to cover for temporarily missing
technology is that when the technology to solve the problem does arrive, the
laws don't magically disappear; they stick around, forgotten, to cause
trouble and surprises later when an enterprising District Attorney discovers
they have undreamed-of possibilities.

A related comment on banning listening said. . .

  &gt; Not true.  States routinely ban the use of radar detectors, and that
  &gt; is nothing more than "listening to a frequency."

States often legislate things that wouldn't pass constitutional muster; this
is an example that at least some legal specialists identify as unlikely to
stand up.  The word around here is the real challenge to radar detector bans
is awaiting the first time that the state of Connecticut tickets F. Lee
Bailey.
					Jerry Saltzer

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks in burning wood
</A>
</H3>
<address>
Mike McLaughlin
&lt;<A HREF="mailto:mikemcl@nrl-csr ">
mikemcl@nrl-csr 
</A>&gt;
</address>
<i>
Fri, 27 Jun 86 11:21:19 edt
</i><PRE>

Risks has carried a lot lately regarding the risks associated with nuclear
energy.  Some discussion has compared nuclear with coal and hydro.  The 
emphasis has been on "disasters," such as Chernobyl or dams breaking. 

May I respectfully submit that not all disasters are sudden. 

Wood smoke is a pollutant.  It may smell nice (except for poplar and a
few others), but if you burn enough of it, nasty things happen.  

Coal smoke is a pollutant.  It never smells nice, and it makes for acid rain
and other nasty things.  These nasty things are slow, but some of us 
recognize the long term effects of generating power through coal as an
ecological disaster.  

Most natural hydrocarbon combustion byproducts (excuse me, "smoke") also
contain carcinogens.  They are as effective at producing cancer as alpha,
beta, gamma, and all those other funny names.  Just different cancers.
I see no value in having any cancer, different or not.

In an attempt to tie this to computers somehow, so that PGN will not toss 
this in his bit bucket:  

Will some reader please gather a creel of Crays and compare the long-term
hazards to the populace, Sialis sialis and Cornus florida of nuclear pol-
lutants (sudden or slow) vs. hydrocarbon pollutants (sudden or slow) while
holding Terra's total energy demand as a constant?

Thank you.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Mailer explosion
</A>
</H3>
<address>
Sean Malloy
&lt;<A HREF="mailto:malloy@nprdc.arpa ">
malloy@nprdc.arpa 
</A>&gt;
</address>
<i>
Thu, 26 Jun 86 06:50:03 pdt
</i><PRE>

     I'm sorry about the explosion of the mailer demons here. At NPRDC, we
have a network consisting of two VAXen, eight or nine Sun workstations, and
a couple of PCs and ATs, all EtherNeted together.  The mail program was
recently brought up on the Suns, and it was suggested that people wishing to
receive their mail on the Suns rather than on PACIFIC (the VAX our code has
primary accounts on) should put .forward files in their home directories on
PACIFIC, which would cause mail sent to &lt;username&gt;@pacific to be forwarded
to a system specified in the .forward file.

     So I made a .forward file, and expected my mail to be forwarded from
malloy@pacific to malloy@hull. But I hadn't expected that a network mail
alias simplification would blow my mail all over creation. To simplify
maintaining the mail alias file on the Suns, the file /usr/lib/aliases on
PACIFIC gets copied to the Suns whenever it is changed. This means that the
Suns think my mail address is malloy@pacific.

     As a result, any mail coming in between Friday (6/20) morning when I
set up the .forward file, to Monday morning when I deleted it because it
wasn't working right (one of my coworkers mentioned losing mail to me) was
received by pacific, where the mailer-demon read the .forward file, and sent
it on to malloy@hull. Hull received the mail, checked the /usr/lib/aliases
file, and sent it back to malloy@pacific.  Twenty-nine loops later, the
mailer-demon explodes, and my mail gets thrown back at whoever sent it.

	Sean Malloy 	(malloy@pacific)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/3.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.3.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/3.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
