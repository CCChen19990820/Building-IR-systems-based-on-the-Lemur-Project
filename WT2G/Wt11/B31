<DOC>
<DOCNO>WT11-B31-1</DOCNO>
<DOCOLDNO>IA012-000129-B044-192</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.53.html 128.240.150.127 19970217020354 text/html 26576
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:02:20 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 53</TITLE>
<LINK REL="Prev" HREF="/Risks/6.52.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.54.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 53</H1>
<H2>  Friday 1 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Virus attacks RISKS 
</A>
<DD>
<A HREF="#subj1.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  First International Conference on Secure Information Systems 
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Wednesday's time trouble at SRC (and fault-tolerant systems)    
</A>
<DD>
<A HREF="#subj3.1">
Tim Mann via Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Two old viruses 
</A>
<DD>
<A HREF="#subj4.1">
Bill Kennedy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Credit card limits 
</A>
<DD>
<A HREF="#subj5.1">
Richard Wiggins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Bankcard authorizations 
</A>
<DD>
<A HREF="#subj6.1">
John Pershing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Things that go POOF! 
</A>
<DD>
<A HREF="#subj7.1">
Vander-Vlis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Diving tables 
</A>
<DD>
<A HREF="#subj8.1">
Joel Kirsh
</A><br>
<A HREF="#subj8.2">
 Keith Anderson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Terminals and checking the facts 
</A>
<DD>
<A HREF="#subj9.1">
A.E. Mossberg
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Virus attacks RISKS 
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
1 Apr 88 00:00
</i><PRE>

Today, I'm afraid I must confess that one of my recent postings to Risks
contained a Virus that Peter (no doubt inadvertently) distributed to the
RISKS audience.  The virus doesn't infect your programs or data files
directly, but in a manner analogous to the "Christmas card" virus discussed
here a few months ago, it causes increased network traffic.

As the virus establishes itself, you will note its affect by the increased
amount of electronic mail you receive every day.  For some of you, the
increase is linear; but for others, I'm afraid you're on the early part of a
exponential curve.

Although the virus was easy to create, I'm afraid that I don't know how to cure
it.  In fact, I believe I'm beginning to note its effects on my own system.

Humbly, Martin Minow

   [I've been wondering where the dramatic increase was coming from.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
First International Conference on Secure Information Systems
</A>
</H3>
<address>
Dennis Ritchie
&lt;<A HREF="mailto:drm@reserch.uucp ">
drm@reserch.uucp 
</A>&gt;
</address>
<i>

</i><PRE>
Message-ID: &lt;6.0225x10toda23@reserch.uucp&gt;
Date: 31 Mar 88 16:00:00 PST
Expires: 1 May 88 00:00:00 GMT
Sender: taylor@hplabsz.HPL.HP.COM       
Organization: AT&amp;T Bell Labs, Unix Research

FOR IMMEDIATE RELEASE  %  FOR IMMEDIATE RELEASE   [O.K. You are released.  PGN]

The System Security Society of Southern Saskatchewan and the University
of North Saskatchewan, Hoople campus announce the First International
Conference on Secure Information Systems. This conference will feature
a star studded panel of security and system experts from across the
computing spectrum giving boring papers and comparing notes on
security problems and possible solutions for existing and future operating
systems ane networking environments. 

Papers that will be given at the conference include:

	Richard Brandow, MacMag magazine: Computer Viruses as a form
		of social terrorism
	
	Dennis Ritchie, AT&amp;T: Trojan Horses: Security Hole or Debugging Aid?

	Richard M. Stallman, Free Software Foundation: Passwords are a 
		Communist Plot, or Give Me Access to Your Computer, Dammit!
	
	Chuq Von Rospach, Fictional Reality: A Secure USENET, an Exercise
		in Futility.
	
	Greg Woods, NOAO: Benign Dictatorships in Anarchic Environments: A
		Case Study

	Peter Honeyman, University of Michigan: Security Features in
		Honey-DanBer UUCP, or Why a Flat Name Space is Good.
	
	John Mashey, MIPS Computers: RISC security risks on Usenet

	Peter G. Neumann, SRI: The RISKS Of Risk Discussion, or
		Why This Conference Should be Classified.

	William Joy, Sun Microsystems: Unix is Your Friend.

	Donn Parker, SRI: Breaking Security for Fun and Profit: A Survey

	Lauren Weinstein, The Stargate Project: Stargate Encryption;
		Turning Free Data into Revenue.

	Mark Horton &amp; Rick Adams, The UUNET project: Security Aspects
		of Pay for Play on USENET.

	C. Edward Brown, National Security Agency: How to get USENET
		feeds when you don't exist, A Case Study.

	Gordon Moffett, Amdahl Corp.: The USENET anarchist's cookbook;
		An alternative to the backbone cabal

	John Quarterman, University of Texas: The USENIX social agenda
		and national security; A summary of Usenet discussions
		from Star Wars to Tar Wars.
	
	Landon C. Noll &amp; Ron Karro, Amdahl Corp.: Public Key Encryption
		in Smail3.1; How to send E-mail that the NSA can't read
	
	A. I. Gavrilov, KGB, North American Information Bureau: Exporting
		American Military Information via Encoded USENET Signatures,
		Theory and Practice.

The Conference will be held March 2 through 4, 1989 on the campus of the
University of North Saskatchewan in Hoople, Saskatchewan, Canada. Registration
is $195 until December 1, 1989, $295 afterward. For more information please
contact Professor Peter Schickele, Department of Computer Science, University
of North Saskatchewan, Hoople, Saskatchewan, Canada 1Q5 UI9. 

Note: This conference is a rescheduling of the conference originally
scheduled for October, 1988 but cancelled after the United States Department
of Commerce decided that the material was too sensitive to allow
non-American citizens to read (including the material written by the
Canadians on the committee). Because of this, the conference has been moved
to Canada, which doesn't have a complete Freedom of Speech written into it's
constitution, but has better things to do than worry about ways of
circumventing civil rights. Americans having trouble getting their papers
cleared for distribution at the conference should contact Professor Shickele
about setting up a direct uucp link for the troff source.

   [I received FIVE copies of this important announcement, so I must assume
   that some of you may have received multiple copies.  However, for those
   of you who missed it, it seemed worth including here.  I fixed the 
   mispeling of Prof. Schickele's name.  I'm sure he wouldn't mind.  
   I also fixed the spelling out of Sask., for esthetic reasons.  Otherwise
   this is as the message was received.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Wednesday's time trouble at SRC (and fault-tolerant systems)
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.dec.com ">
horning@src.dec.com 
</A>&gt;
</address>
<i>
1 Apr 1988 1440-PST (Friday)
</i><PRE>

     Forwarded Message:

Date: Fri, 1 Apr 88 14:12:02 PST                             [Not a joke.]
From: mann (Tim Mann)

I've learned a bit more about what went wrong with our time service on
Wednesday; here are the details for those who are interested.  

Background:  SRC's time service is based on three master clocks.  Two of
the clocks get their time signals from radio station WWV in Colorado,
while the other gets its time signal from the GOES earth satellite.  The
master clocks are plugged into Fireflies, which periodically read them and
broadcast the time on the net.  Every Firefly on the net receives these
broadcasts, and takes a fault-tolerant average to get the time to which it
adjusts its local clock.  This amounts to taking the median if all three
time providers are heard from, the mean if two are heard, or the reported
value if only one is heard.  So we tolerate any single fault:  if one time
provider gives out bogus times, but the other two still work correctly,
clients are not fooled.  If two providers fail, clients can be fooled.

Around March 23, Mike Schroeder had trouble with his Firefly, which hosts
one of the WWV clocks.  Our hardware guys came up and fixed it, but left
the console baud rate switch in the wrong position, so the time server
couldn't read the clock.  Now there were only two time servers, so clients
took the mean and still got the right time.  Unfortunately, the current
time service implementation doesn't send a message to a human when this
happens; it just logs the event in a place that's seldom looked at.  So
Mike's clock stayed down until yesterday afternoon, March 31.

Then on Wednesday afternoon (March 30), something really unusual happened.
The WWV clock connected to my Firefly suddenly decided that it was July 8
(the 190th day of the year) instead of March 30 (the 90th day).  About two
hours later it switched back to March 30.  But the incorrect readings had
some bad consequences.  

First, because there were now two faulty clocks, the client hosts could no
longer cope.  They took the mean of the two time providers that were reporting
and started trying to advance their clocks to the 140th day of the year by
running fast.  The speedup was limited to 10% by a sanity check I put into the
implementation, so it took quite a while before anyone noticed the incorrect
time on his Firefly.  (Again, when the 10% limit is hit, the current
implementation just logs the event in an obscure place.)

The second bad consequence came from the way the current implementation
initializes the time on bootup.  Instead of averaging all the time
servers, it just believes the first one it hears.  So two people rebooted
their machines on Wednesday afternoon, noticed that the time read "July
8", and phoned me.  At that point I got to work picking up the pieces,
and phoned the WWV receiver's manufacturer.

The next day one of the chief technical people from the time receiver
company came out to try to figure out what had happened.  In the end he
ascribed it to a mysterious bug in the firmware release we were running,
and gave me a new set of PROMs with an improved algorithm for rejecting
erroneous data that shows up due to noise in the radio signal.

This incident teaches two lessons about engineering a fault-tolerant system,
neither of which should come as a surprise.  First, a fault-tolerant system
must report the faults it tolerates so they can be fixed, rather than masking
them entirely.  Second, a fault-tolerant system must tolerate faults in all
phases of its operation---it is not okay if faults during normal operation are
tolerated, but faults during initialization cause undetected errors.
                                                                       --Tim
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Two old viruses
</A>
</H3>
<address>
Bill Kennedy
&lt;<A HREF="mailto:bill@ssbn.wlk.com ">
bill@ssbn.wlk.com 
</A>&gt;
</address>
<i>
29 Mar 88 19:41:16 CST (Tue)
</i><PRE>

Someone asked for a virus dated prior to 1984.  Back in 1974 I was working at a
large firm with no fewer than three 360's lashed together and a bright young
fellow wrote a program named "rabbit".  When rabbit was submitted it had found
a way of taking a copy of itself and tossing it back, twice, into the ASP input
jobstream.  One of ASP's famous qualities was how it got stingier and stingier
about talking to its console when it began to get constipated.  Needless to
say, rabbit constipated it so it was harder to kill the longer it ran.  The
bright young fellow was (justifiably) discharged.

Also in response to the computer theft story I know a fellow who founded the
first retail computer store in Texas.  One day Dallas police came into his
store (not in Dallas) and asked if he was familiar with a particular brand of
Southwest Technical Products (*that* dates it!) video terminal.  He said he
was.  They asked him if he knew how to operate the computer that came with the
SWDP terminal, he was.  Would he comne down to headquarters and look at some-
thing?  Sure...  When he got the system to boot up he was unsure what the
police wanted.  They explained that they had just arrested a burglar and this
computer was in his apartment.  Neither the computer nor the terminal were
"hot", the police had found sales receipts for each and the way they found the
store was from a receipt for repair work done to the terminal.  When the disk
directory was played out for the detectives they nearly jumped for joy! The
burglar had carefully and faithfully recorded each job, goods stolen, where
fenced if fenced, and where stored if not fenced.  Dallas and the surrounding
cities cleared about eighty offenses just on a simple printout of the burglar's
data files.  The thief had also programmed it himself!

Bill Kennedy ...{rutgers,cbosgd,ihnp4!petro}!ssbn!bill  or bill@ssbn.WLK.COM

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Credit card limits
</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard_Wiggins@um.cc.umich.edu">
Richard_Wiggins@um.cc.umich.edu
</A>&gt;
</address>
<i>
Wed, 30 Mar 88 00:11:56 EST
</i><PRE>

A standard problem with credit card limits is that a firm can run your card to
the limit with a hold, and you are then out of credit until the hold is
resolved. (I, for one, would like definitive word on when holds are removed.)
 
Two cases in which holds for estimated amounts are used:

When you check into a hotel, they guess how much you are likely to spend based
on the number of days and the room rate, plus a fudge factor for food or phone
charges you might ring up. If you stay beyond your original plans, they
continue to call in for additional authorizations, usually at the same
estimated rate, regardless of how much you may have spent.

If you have an accident in a rental car, and you don't have the damage
insurance from the rental agency, they may tie up your credit -- up to the
limit, of course -- until you make a settlement. When a car I'd rented from
National in Salt Lake City was struck by a deer a couple of years ago, they
were quite sanguine when I called to report the problem. When I physically
returned a few days later, they looked at the police estimate of $1100 and
wanted to charge it to my credit card. I persuaded them that I was adequately
insured, but they insisted on running through a blank charge slip and making me
sign it. Since it was a long walk to the terminal I very reluctantly agreed.
(My insurance paid, not my plastic.)

Now, one could imagine cases where a negligent or hostile clerk typos in the
authorization process, and say, sends through a request for 10X the proper
amount. You may have enough credit for that, but not for the next charge!
 
In light of all this, it seems prudent to carry more than one credit card,
even if the same "brand".

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Bankcard authorizations
</A>
</H3>
<address>
John Pershing 
&lt;<A HREF="mailto:PERSHNG@ibm.com">
PERSHNG@ibm.com
</A>&gt;
</address>
<i>
1 Apr 88 09:31:31 EST
</i><PRE>

The credit authorization process is essentially one big calculated risk.
What typically happens is:  the authorization request is submitted to the
merchant's bank, which forwards it to the appropriate clearinghouse (one
for each of the major cards).  If the clearinghouse does not respond
promptly (e.g., within 10 seconds), it counts as a tacit approval.  We
mustn't keep the customer waiting!

The clearinghouse's computer looks up the card number in its "negative file" of
cards that are lost, stolen, or in arrears, and rejects the transaction if it
finds an entry.  Otherwise, it forwards the transaction to the bank that owns
the account.  If the owning bank does not respond promptly (e.g., within 5
seconds), it counts as a tacit approval.  The clearninghouse then sends the
answer ("yea" or "nay") back to the merchant's bank, and thence to the
merchant.

Assuming that the computers at the banks and clearinghouses are all up 100% of
the time, along with the communication networks, and that they are not so
bogged down that they cannot respond in time, then the system always works.
It's that simple! (...chuckle...)

Anybody want to venture a guess at the transaction load seen, e.g., by the
MasterCard clearinghouse during the week before Christmas?  Does anybody still
wonder how a few bad authorizations manage to slip through the cracks?  Can
anybody think of a better way?

      John A. Pershing Jr.,       IBM Research, Yorktown Heights

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Things that go POOF!
</A>
</H3>
<address>
&lt;<A HREF="mailto:Vander-Vlis@DOCKMASTER.ARPA">
Vander-Vlis@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 31 Mar 88 08:35 EST
</i><PRE>

Having worked in a NYC bank for five years I must disagree with an earlier
statement that a decomposed check is untraceable.  The only way that the check
could disappear without a trace is if it decomposed before the teller could
process it.  This is usually done at the end of the day.  Each check must be
marked with the banks cancellation stamp.  This stamping is performed by a
machine which, at the same time, takes a photograph of the check for bank
records.  When that check finally decomposes, there will be an accounting
discrepancy between two financial institutions which (believe it or not) will
be traced back to that photograph.  This knowledge comes from the painful
personal experience of sitting with a microfilm reader looking through all
checks processed on a certain day in search of one bleepin' check.

This plot would more than likely be uncovered even if the check decomposed in
the teller's drawer.  If you ever watched your teller when making a deposit you
know that he/she writes down the amount of cash as well as the amount of each
check.  If while proving their till for the day the teller can't come up with
matching debits and credits they will cross-check their deposit slips with
their checks and find the slip which doesn't have a check to go with it.
Although they can not fault the depositor for the loss of the check, if this
were to happen frequently, the bank would eventually become aware of it.
Incidentally, this is an old scam.  I'm surprised that it actually made the
news at all.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
diving tables
</A>
</H3>
<address>
Joel Kirsh 
&lt;<A HREF="mailto:KIRSH@NUACC.ACNS.NWU.Edu">
KIRSH@NUACC.ACNS.NWU.Edu
</A>&gt;
</address>
<i>
Wed, 30 Mar 88 10:12 CST
</i><PRE>

The user interface on the new diving computers is certainly critical, but most
divers are still using the standard US Navy tables (which are orders of
magnitude cheaper).  These tables contain still another RISK, that of making
unreasonable assumptions about the relevant characteristics of the user.

The allowable depths, times, and recommended decompression stops in the USN
tables were determined from a population of physically fit, well-trained, and
highly motivated subjects (ie USN divers).  Even so, when followed exactly, the
tables are expected to result in a finite percentage (on the order of 5%) of
decompression injuries.

</PRE>
<HR><H3><A NAME="subj8.2">
Diving Computers
</A>
</H3>
<address>
Keith 'Dain Bramaged' Anderson 
&lt;<A HREF="mailto:KANDERSON%HAMPVMS.BITNET@MITVMA.MIT.EDU">
KANDERSON%HAMPVMS.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 30 Mar 88 11:08 EST
</i><PRE>

I recently read a letter in this digest questioning the safety of the new
diving computers ("The Edge" and "The Skinnydipper", by a company I forget the
name of) and decided to add my 2 bits.

I have to explain a little about diving to explain these computers.

Air is made up of approximately 80% nitrogen.  At sea level, our bodies are
saturated with nitrogen.  When a diver decends, the pressure exerted on his or
her body increases one atmosphere for every 33 feet he decends (one at sea
level, two 33 ft under, three at 66 ft under etc.).  This increase forces more
nitrogen into solution in the diver's body.  If the diver absorbs too much
nitrogen, it will bubble out of solution as he or she acends to lower pressure.
Nitrogen bubbles in the bloodstream are bad (ahem).  The Navy compiled tables
using _men_ in the prime of health, of limits as to the amount of time a diver
could stay at any depth (down to 150 ft) and then surface normally and not get
the bends.  These are the maximum No-decompression limits tables.  These tables
have a 5% failure rate.  Another way to avoid the bends is to dive to a certain
depth for a certain time, and then on acending, stop at 10 feet under for a a
certain time to allow nitrogen to be outgassed, and then surfacing.  These are
called decompression dives, and also have a set of tables.  What none of these
tables allow for is the fact that if a diver dives to 90 feet for a while, and
then acsends a little and spends the rest of his or her dive at 60 feet, the
nitrogen absorbed at 90 feet will be outgassed at 60 ft until the 60 saturation
point.  What the new computers do is credit the diver with time spent at a
lesser depth, and debit him or her for deeper depths.  These computers also
follow tables that are more conservative than the standard Navy tables, thus
making for a safer dive.

The message that appears telleing a diver to acend more slowly is to prevent a
different problem.  The air coming out of a SCUBA tank arrives in the lungs at
the same pressure as the surrounding water.  If a diver fills his or her lungs
with air at 90 psi (the pressure it is recieved at at 20ft), and then ascends
to 10 ft under, the pressure decreases to 45 psi, so the air in the divers
lungs tries to double its volume.  The lungs have no nerves that tell the brain
that they are being stretched too much, so they tear.  This also is bad.  The
simple way to avoid this problem is to ascend slowly enough that the air has a
chance to be expelled, and a new, lower pressure breath may be taken in.
Divers have a bad habit of swimming to the surface too quickly ( the new
optimum rate of acent is 20 feet per minute (!) this means it should take 5
minutes to acend from 100 feet down), and so the computers constantly warn
divers to acend more slowly.

As for the question of bad human interfacing, a diver checks his or her air
pressure frequently (wouldn't you ?), and the computers are designed to clamp
onto the same hose that leads to the pressure guage, thus making it rather hard
to miss.

Keith Anderson, Hampshire College, Kanderson@hampvms

P.S. you have just received the majority of the classwork in a SCUBA course.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: Terminals and checking the facts (<A HREF="/Risks/6.52.html">RISKS-6.52</A>)
</A>
</H3>
<address>
a.e. mossberg 
&lt;<A HREF="mailto:aem@miavax.miami.edu">
aem@miavax.miami.edu
</A>&gt;
</address>
<i>
Fri, 1 Apr 88 13:49:20 EDT
</i><PRE>
Organization: Univ of Miami Dept of Math and Computer Science - Hertz Lab

	I'm afraid Jerry's flames are well deserved, before sending the
letter I merely checked the TVI9220 and WYSE 85 manuals (the first, a
'vt220' compatible, the second, a 'vt200' compatible).  They list a vt 
command for entering block mode (DECEDM) but only wyse and televideo 
specific commands for sending the contents of the screen.  In the case
of the televideo, the command is only in 9220 mode.

a.e.mossberg Bitnet: aem@miavax.miami.edu@cunyvm
             uucp: ...!uunet!miavax!aem 	SPAN: aem@mthvax.span (3.91)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.52.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.54.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-2</DOCNO>
<DOCOLDNO>IA012-000129-B044-209</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.54.html 128.240.150.127 19970217020409 text/html 26721
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:02:35 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 54</TITLE>
<LINK REL="Prev" HREF="/Risks/6.53.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.55.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 54</H1>
<H2>  Monday 4 April 1988  </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: April Fool's Warning from Usenet</A>
<DD>
<A HREF="#subj1.1">Gene Spafford</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
Intolerant Fault-Tolerance</A>
<DD><A HREF="#subj2.1">Jerome H. Saltzer</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
How Computers Get Your Goat</A>
<DD><A HREF="#subj3.1">PGN</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
Old viruses</A>
<DD><A HREF="#subj4.1">Jerry Leichter</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
Re: Notifying users of security problems</A>
<DD><A HREF="#subj5.1">Andy Goldstein</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
The "previous account" referred to in</A><A HREF="/Risks/6.51.html">RISKS-6.51</A>
<DD><A HREF="#subj6.1">Les Earnest</A><BR>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
Just Another Unix Spoof</A>
<DD><A HREF="#subj7.1">Paul Cudney</A><BR>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: April Fool's Warning from Usenet</A>(<A HREF="/Risks/6.52.html">RISKS-6.52</A>)
</H3>
<ADDRESS>
Gene Spafford
&lt;<A HREF="mailto:spaf@purdue.edu">spaf@purdue.edu</A>&gt;
</ADDRESS>
<PRE>
Date: 4 Apr 88 23:34:57 GMT

In Risks 6.52, Cliff Stoll forwarded a posting on the Usenet about forged
articles.  He attributed it to me, and unfortunately either Cliff or Peter
trimmed most of the news header lines out.  Why was it unfortunate?  Because
the article was itself a forgery, and the headers exhibited all of the
indicators the posting warned were in bogus articles!

It was a marvelous joke except for the fact I've gotten about 40 mail
messages so far from people who didn't realize that it was a forgery.  Now
it shows up in Risks!

I am 99% certain who did it, and I can't wait for next April 1....

Gene Spafford
NSF/Purdue/U of Florida  Software Engineering Research Center,
Dept. of Computer Sciences, Purdue University, W. Lafayette IN 47907-2004
Internet:  spaf@cs.purdue.edu	uucp:	...!{decwrl,gatech,ucbvax}!purdue!spaf

    [Mortifications from the Moderator, who tries to keep RISKS Readable
    by Hewing Headers.  In this case I should have left the entire sequence
    in, to add to the evidence described in the message.  Very clever.   PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">Intolerant Fault-Tolerance</A>(<A HREF="/Risks/6.53.html">RISKS-6.53</A>)</H3>
<ADDRESS>
Jerome H. Saltzer 
&lt;<A HREF="mailto:Saltzer@ATHENA.MIT.EDU">Saltzer@ATHENA.MIT.EDU</A>&gt;
</ADDRESS>
<I>
Sun, 3 Apr 88 14:10:38 EST
</I><PRE>
&gt; From: mann (Tim Mann)  . . .
&gt; This incident teaches two lessons about engineering a fault-tolerant system,
&gt; neither of which should come as a surprise.   First, a fault-tolerant system
&gt; must report the faults it tolerates ...

@begin(Soapbox)

This lesson reported by Tim Mann bears underlining.  I would guess that the
single design mistake I have seen repeated most often in 25 years of observing
computer systems is that one: providing what appears to be fault tolerance, but
neglecting to provide a means of reporting when a fault has been encountered
and successfully masked.  As a result, many so-called fault-tolerant systems
actually run for much of their lifetime in a state where a single fault will
bring them down.  A redundant system that is thought to be operating well back
from the edge of a catastrophe cliff may actually be standing on the edge
without its users or operators being aware.

Examples are legion, even in the systems we use every day:

    -  backup tapes with write errors undiscovered till they are needed.
    -  packets mysteriously lost in the Ethernet or the gateway; the
       higher-level protocol successfully retries.
    -  the non-responding internet name server; the next one in the list
       responds.
    -  mail links that are down more often than up; but up enough that
       the mail usually gets through.

A system that provides redundancy but omits any mechanism to call for
repair when the redundancy is invoked is more complex and expensive than
a non-redundant system, but it ISN'T really fault-tolerant.

A closely related problem occurs when a fault-tolerant system with properly
engineered fault reporting is operated in a mode where its calls for help get
ignored or given such low priority that they might as well not be there.  The
blame in this case isn't with the original engineers (unless they buried the
calls for help in the middle of a log full of uninteresting events), but the
RISK is the same.

Next time someone shows off a "fault-tolerant" system that seems to be able to
survive having a 45-caliber slug fired through one component, as part of the
demo ask to see the trouble report that the system generated in response to the
incident.  If there isn't one, take your business elsewhere.

@end(Soapbox)
					Jerry Saltzer

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
``How Computers Get Your Goat''
</A>
</H3>
<ADDRESS>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</ADDRESS>
<I>
Sat 2 Apr 88 10:46:01-PST
</I><PRE>

Anyone who has used a personal computer has been forced to wait while the
machine completed some task.  A University of Texas at Arlington researcher
has found that such waiting can produce anxiety and theorizes that such
anxiety reduces productivity.  The researcher, Jan L. Guynes, used
psychological tests to classify 86 volunteers as either Type A or Type B
personalities.  The volunteers were given 20 minutes to make editing
corrections on text in a personal computer, in which delays were programmed.
She found that a slow, unpredictable computer increased anxiety in both
groups equally, even though Type A personalities were generally more anxious
before undertaking the editing task, and that such added anxiety may affect
performance.

New York Times item, from the SF Chronicle, 30 March 1988, p. A3.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Old viruses
</A>
</H3>
<ADDRESS>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</ADDRESS>
<I>
Mon, 4 Apr 88 17:31 EST
</I><PRE>

In a recent RISKS, Bill Kennedy mentions a program he saw on an IBM 360 back in
1974 which submitted multiple copies of itself.  This rang a bell; I remember
hearing talk of a similar program at Princeton.  Since I graduated in 1973, the
idea goes back at least that far.  No one claimed to have actually run it
themselves - it was always something they had heard about someone else doing.
But the possibility was certainly understood, and I recall discussions about
the consequences, and speculations about how many copies of itself the program
should submit for maximum effect.  (Anything more than an average of one was
certain to clog the system eventually; but you could modulate how long it would
take for the system to slowly grind to a halt.)

There was also discussion of counter-moves.  Given the way OS/360 and ASP were
structured, the best approach we could come up with was to remove the account
the program - just as in Bill Kennedy's story usually named "RABBIT" or
"RABBITS" - was running in.  Given the general insecurity of OS/360, however,
it wasn't hard to get different copies of RABBITS to run under many different
accounts.  Such a RABBITS program could be quite difficult and expensive to
kill - clearing out the queues on a batch-oriented system is not something to
be done lightly!

BTW, the great-granddaddy of all such programs wasn't a virus at all - it arose
innocently as a bug in some early version of OS/360.  The exact details are
lost in the mists of time, but they went something like this:  If your program
abend'ed (aborted), you got a post-mortem dump.  Some sort of job setting
requested that the dump be printed.  Often, you could quickly determine that
the dump was of no interest.  So you asked the operator to kill the print job.
Unfortunately, the "print dump on abend" switch stayed on:  Killing the print
job lead to a post-mortem dump....
							-- Jerry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Notifying users of security problems
</A>
</H3>
<ADDRESS>
Andy Goldstein
&lt;<A HREF="mailto:goldstein%star.DEC@decwrl.dec.com ">
goldstein%star.DEC@decwrl.dec.com 
</A>&gt;
</ADDRESS>
<I>
Mon, 4 Apr 88 15:28:53 PDT
</I><PRE>

&gt; Date: 31 Mar 88 01:25:29 PST (Thursday)
&gt; From: "hugh_davies.WGC1RX"@Xerox.COM
&gt; Subject: Re: Notifying users of security problems
&gt; In RISKS 6.50, Andy Goldstein (goldstein%star.DEC@decwrl.dec.com) states..
&gt; "Sending out notice of the presence of a bug without a correction or
&gt; workaround is of course even more irresponsible." ...
&gt; When I first saw this I couldn't believe what I was reading. ...
&gt; Please, Andy, tell me I've got it wrong!

Maybe you did misunderstand me; I should have been more precise in
the statement you quoted. I was referring specifically to security bugs.
That said, I stand by my statement. Let me try to explain...

When a piece of software is shipped containing a bug, knowledge of that
bug is contained in the software, in a manner of speaking. At the same
time, in most cases knowledge of the bug is not held by any person.
That is, the bug was created inadvertantly and unknowingly by the
author(s) of the software, and no one has discovered it yet.

A bug does its damage when it is somehow invoked, by use or misuse of a
certain feature, or by the unhappy confluence of certain conditions. By
and large, ordinary bugs are encountered by users innocently going about
their business. That is, no prior knowledge of the bug by the user is
involved in encountering the bug; knowledge of the bug by the system is
sufficient. Furthermore, the effect of the bug is in general to cause
system behavior which is undesirable to the user. Consequently,
knowledge of the bug will often permit the user to work around it or
defend against it. Since a virus spreads without knowledge of the user,
it too falls into this category. Sharing information about most types of
bugs, including the existence and nature of particular viruses, is
productive and worthwhile.

Now let us compare security bugs to ordinary bugs. I define a security
bug as one which permits a user to violate a system's security controls
in some significant way (e.g., allowing an ordinary user to become
superuser or whatever). Security bugs are by and large not encountered
by people innocently going about their business. They are usually found
by the adventurous by inspecting system sources, and are invoked only
through creative abuse of obscure system features. (I cannot argue this
point with logic, but many years of experience dealing with security
bugs tell me it is so.) Most system users (I mean users, not
administrators) do not care about security bugs. They do not stand in
the way of their getting their work done. The people who care about
security bugs are hackers (and of course the system managers trying to
fend them off). From the point of view of the hacker, a security bug is
an undocumented feature of the system that allows him to do what he
wants to do.

So we get to the critical distinction between security bugs and
others: Because invocation of a security bug requires a deliberate,
unusual action, a security bug is only harmful to an installation when
malicious users gain knowledge of the bug. The best analogy I can
think of is a lock manufacturer discovering that one of its locks can
be easily picked using a previously unknown technique. The challenge
we have with security bugs, therefore, is

(1) not shipping them to begin with
(2) fixing them as promptly as possible when they are discovered
(3) keeping knowledge out of the hands of the bad guys until they
    can be fixed.

Points (1) and (2) are of course mere matters of engineering,
manufacturing and distribution. Because we will never achieve
instantaneous development and distribution of bug fixes, (3) is the
kicker. I have heard many arguments that system managers should be
permitted to learn about security bugs, either from the manufacturer
or informally via the grapevine. With respect to the VAX/VMS user
community, I disagree with this conclusion for several reasons:

(1) The knowledge won't do them any good. We are long past the time
    when every computer installation had its wizard who knew (or
    thought he knew) how to fix every problem that might come up.

    [Digression: I'm sure half the university system managers have just
    hit the ceiling. Universities are unique in having available a large
    pool of cheap, highly talented labor. Among our engineering and
    commercial customers, technically skilled labor is expensive and
    hard to come by. Our working assumption is that the majority of
    our customer base does not, or would rather not have to, understand
    the internals of VMS to use it.]

(2) The news may do them harm. Would you, as DP manager of Bank of
    America, install a "security patch" that originated from, say,
    UC Berkeley?

(3) The knowledge may do them harm. Nowadays, any fairly well-off high
    school kid can buy himself a microvax and be a bona-fide system
    manager. There is no practical way to tell the good guys from the
    bad guys anymore. The larger the number of people know of the
    existence of a security problem, the more likely it is that a
    bad guy will gain the necessary knowledge to exploit it.

Consequently, DEC has taken the following approach to dealing with
security bugs in the future:

(1) When a security bug is discovered, engineering will develop a fix
    as rapidly as possible. The fix will be distributed to customers
    as rapidly as circumstances warrant. To the extent possible, the
    fix will be constructed so as to make it difficult to
    reverse-engineer the bug from the fix.

(2) Once the fix has been distributed, all customers will be notified
    of the existence of the problem and informed of the urgency of
    installing the fix. Thus we let the cat out of the bag (hopefully)
    only after users have been given the tools with which to skin it.

While this policy of secrecy does carry the possibility that a small number of
users may incur duplicated effort investigating a security bug, we feel this is
a worthwhile trade towards ensuring the safety of the majority of the customer
base. I also emphasize that this policy applies only to security bugs that have
no operational workaround.
                                        Andy Goldstein,  VMS Development

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
The "previous account" referred to in <A HREF="/Risks/6.51.html">RISKS-6.51</A>
</A>
</H3>
<ADDRESS>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</ADDRESS>
<I>
01 Apr 88  1620 PST
</I><PRE>

e-t-a-o-n-r-i Spy and the F.B.I.    

Reading a book got me into early trouble -- I had an F.B.I. record by age
twelve.  This bizarre incident caused a problem much later when I needed a
security clearance.  I learned that I could obtain one only by concealing my
sordid past.

A friend named Bob and I read the book "Secret and Urgent," by Fletcher Pratt
[Blue Ribbon Books; Garden City, NY; 1942] which was an early popular account
of codes and ciphers.  Pratt showed how to use letter frequencies to break
ciphers and reported that the most frequently occurring letters in typical
English text are e-t-a-o-n-r-i, in that order.  (The letter frequency order of
the story you are now reading is e-t-a-i-o-n-r.  The higher frequency of "i"
probably reflects the fact that _I_ use the first person singular a lot.)
Pratt's book also treated more advanced cryptographic schemes.

Bob and I decided that we needed to have a secure way to communicate with each
other, so we put together a rather elaborate jargon code based on the
principles described in the book.  I don't remember exactly why we thought we
needed it -- we spent much of our time outside of school together, so there was
ample time to talk privately.  Still, you never could tell when you might need
to send a secret message!

We made two copies of the code key (a description of how to encrypt and decrypt
our messages) in the form of a single typewritten sheet.  We each took a copy
and carried it on our persons at all times when we were wearing clothes.

I actually didn't wear clothes much.  I spent nearly all my time outside
school wearing just a baggy pair of maroon swimming trunks.  That wasn't
considered too weird in San Diego.

I had recently been given glasses to wear but generally kept them in a hard
case in the pocket of the trousers that I wore to school.  I figured that this
was a good place to hide my copy of the code key, so I carefully folded it to
one-eighth of its original size and stuck it at the bottom of the case, under
my glasses.

Every chance I got, I went body surfing at Old Mission Beach.  I usually went
by streetcar and, since I had to transfer Downtown, I wore clothes.
Unfortunately, while I was riding the trolley home from the beach one Saturday,
the case carrying my glasses slipped out of my pocket unnoticed.  I reported
the loss to my mother that night.  She chastised me and later called the
streetcar company.  They said that the glasses hadn't been turned in.

After a few weeks of waiting in vain for the glasses to turn up, we began
to lose hope.  My mother didn't rush getting replacement glasses in view
of the fact that I hadn't worn them much and they cost about $8, a large
sum at that time.  (To me, $8 represented 40 round trips to the beach by
streetcar, or 80 admission fees to the movies.)

Unknown to us, the case had been found by a patriotic citizen who opened
it, discovered the code key, recognized that it must belong to a
Japanese spy and turned it over to the F.B.I.  This was in 1943, just
after citizens of Japanese descent had been forced off their property and
taken away to concentration camps.  I remember hearing that a local grocer
was secretly a Colonel in the Japanese Army and had hidden his uniform in
the back of his store.  A lot of people actually believed these things.

About six weeks later, when I happened to be off on another escapade, my
mother was visited by a man who identified himself as an investigator from
the F.B.I.  (She was a school administrator, but happened to be at home
working on her Ph.D. dissertation.)  She noticed that there were two more
men waiting in a car outside.  The agent asked a number of questions about
me, including my occupation.  He reportedly was quite disappointed when he
learned that I was only 12 years old.

He eventually revealed why I was being investigated, showed my mother the
glasses and the code key and asked her if she knew where it came from.  She
didn't, of course.  She asked if we could get the glasses back and he agreed.

My mother told the investigator how glad she was to get them back, considering
that they cost $8.  He did a slow burn, then said "Lady, this case has cost the
government thousands of dollars.  It has been the top priority in our office
for the last six weeks.  We traced the glasses to your son from the
prescription by examining the files of nearly every optometrist in San Diego."
It apparently didn't occur to them that if I were a REAL Japanese spy, I might
have brought the glasses with me from headquarters.

The F.B.I. agent gave back the glasses but kept the code key "for our records."
They apparently were not fully convinced that they were dealing just with kids.

Since our communication scheme had been compromised, Bob and I devised a new
key.  I started carrying it in my wallet, which I thought was more secure.  I
don't remember ever exchanging any cryptographic messages.  I was always ready,
though.

A few years later when I was in college, I got a summer job at the Naval
Electronics Lab, which required a security clearance.  One of the questions on
the application form was "Have you ever been investigated by the F.B.I."
Naturally, I checked "Yes."  The next question was, "If so, describe the
circumstances."  There was very little space on the form, so I answered simply
and honestly, "I was suspected of being a Japanese spy."

When I handed the form in to the security officer, he scanned it quickly,
looked me over slowly, then said, "Explain this" -- pointing at the F.B.I.
question.  I described what had happened.  He got very agitated, picked up my
form, tore it in pieces, and threw it in the waste basket.

He then got out a blank form and handed it to me, saying "Here, fill it out
again and don't mention that.  If you do, I'll make sure that you NEVER get a
security clearance."

I did as he directed and was shortly granted the clearance.  I never again
disclosed that incident on security clearance forms.

On another occasion much later, I learned by chance that putting certain
provocative information on a security clearance form can greatly speed up
the clearance process.  But that is another story.
                                                   	Les Earnest

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Just Another Unix Spoof -- ISO abandoned
</A>
</H3>
<ADDRESS>
Paul Cudney
&lt;<A HREF="mailto:cudney@sm.unisys.com ">
cudney@sm.unisys.com 
</A>&gt;
</ADDRESS>
<I>
Sat, 2 Apr 88 13:19:08 PST
</I><PRE>

Are you engaging in fault-encouragement behavior?  If so, here is
Just Another Unix Spoof (JAUS) to chew on.  /Paul

Path: sdcrdcf!ucla-cs!rutgers!bellcore!faline!thumper!kremvax!meese
From: meese@kremvax.arpa
Newsgroups: comp.protocols.tcp-ip,comp.protocols.iso
Subject: OSI abandoned!
Message-ID: &lt;880401@kremvax.arpa&gt;
Date: 1 Apr 88 00:00:01 GMT
Organization: Soviet Sanctuary for Victims of American Persecution
Posted: Fri Apr  1 00:00:01 1988

	WASHINGTON -- In a simultaneous announcement that took the
computer industry by surprise, OSI leaders today said that they were
abandoning their effort to promote the OSI Protocol Suite in favor of
the existing US Department of Defense (DoD) ARPANET Protocol Suite. 

	The official reason cited for the decison was a new report from
the Office of Technology Assessment stating that the manpower required
to fully implement and test even the few OSI protocols that are now
defined would consume the entire output of American university computer
science programs for the rest of the century, and that printing and
distributing the necessary protocol specifications would consume the
entire American and Canadian paper supplies for the next five years. 

	However, one high-placed source speaking on condition of
anonymity said, ``The whole OSI thing was a practical joke one of the
guys cooked up a few years ago.  Nobody ever expected anybody to take it
seriously.  I mean, who would believe an organization supposedly
dedicated to tearing down barriers to free and open communications
between computers when it's run by a former director of the National
Security Agency? I guess computer people are a lot more gullible than we
thought.  We kept dropping hints, making the whole thing more and more
ridiculous. We hoped that people would eventually catch on, but it didn't
work.  Finally, our consciences got to us.''

	In related news, officials at the Mitre Corporation in Bedford,
Massachussetts reported that one of their employees, as yet publicly
unidentified, froze ``as solid as stone'' when he heard the announcement. 
Medical experts have as yet been unable to communicate with the victim
or get him to relax his facial muscles, which are reportedly locked into
what was described as an ``enormous grin''. 

	AP-NR-04-01-88 0001EST

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.53.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.55.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-3</DOCNO>
<DOCOLDNO>IA012-000129-B044-230</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.55.html 128.240.150.127 19970217020427 text/html 28652
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:02:54 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 55</TITLE>
<LINK REL="Prev" HREF="/Risks/6.54.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.56.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 55</H1>
<H2>  Tuesday 5 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Battle of the Virus Hunter 
</A>
<DD>
<A HREF="#subj1.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Software &amp; War 
</A>
<DD>
<A HREF="#subj2.1">
Chief Dan Roth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A new RISK prevention scheme? 
</A>
<DD>
<A HREF="#subj3.1">
Eric Haines
</A><br>
<A HREF="#subj3.2">
 not John Saponara
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Yet Another UnTimely Risk 
</A>
<DD>
<A HREF="#subj4.1">
Paul Cudney
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Olde Virus Shoppe 
</A>
<DD>
<A HREF="#subj5.1">
Barry Hayes
</A><br>
<A HREF="#subj5.2">
 Douglas Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: (c) Brain VIRUS 
</A>
<DD>
<A HREF="#subj6.1">
Chief Dan Roth
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Risks in diving computers 
</A>
<DD>
<A HREF="#subj7.1">
Rich Sands
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  RISKS in philosophyland 
</A>
<DD>
<A HREF="#subj8.1">
David Thomasson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Risks of NOT giving race/ethnicity 
</A>
<DD>
<A HREF="#subj9.1">
David Rogers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: More On Race and Ethnicity Questions... 
</A>
<DD>
<A HREF="#subj10.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  April Forgeries 
</A>
<DD>
<A HREF="#subj11.1">
Charles Daffinger
</A><br>
<A HREF="#subj11.2">
 Rahul Dhesi
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Battle of the Virus Hunter
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:nsc!taux01!taux01.UUCP!amos@Sun.COM ">
nsc!taux01!taux01.UUCP!amos@Sun.COM 
</A>&gt;
</address>
<i>
4 Apr 88 21:35:56 GMT
</i><PRE>

An interesting wager was made in a live TV interview here this afternoon: A
software house has announced a product that can warn users of the presence of a
virus - any virus - on their PC. It was written by the guy who discovered the
'Israeli Virus'.  Another software house, which produces an 'inoculation'
program against that virus, claims that a detection of every type of virus by a
single program is impossible, and offered a 10,000 shekel bet (about $6200)
against it, which was promptly accepted. They will have a show-down within 2
weeks - this is going to be interesting to watch!

Amos Shapir  National Semiconductor (Israel)
6 Maskit st. P.O.B. 3007, Herzlia 46104, Israel  Tel. +972 52 522261

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Software &amp; War
</A>
</H3>
<address>
Chief Dan Roth 
&lt;<A HREF="mailto:chiefdan@vax1.acs.udel.edu">
chiefdan@vax1.acs.udel.edu
</A>&gt;
</address>
<i>

</i><PRE>
Date: 5 Apr 88 01:07:31 GMT

According to an article in the Christian Science Monitor, the communist rebels
in the Phillipines are being hampered by a virus (CSM's terminology) which was
meant as part of a software protection scheme.  

The rebels have imported a large number of Casio-manufactured laptop computers
for coding communications and other "on-the-run" uses in the guerilla war.
However, they also have been using pirated software.  The software has a
built-in "feature" which the rebels are finding quite a disadvantage -- the
pirated copies work fine for awhile but then suddenly an "anti-piracy feature"
erases all the files on the disk.  Not exactly helpful in a battle situation.

(The original article was in the Thursday, March 31st CSM.)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A new RISK prevention scheme?
</A>
</H3>
<address>
John Saponara
&lt;<A HREF="mailto:saponara@tcgould.tn.cornell.edu ">
saponara@tcgould.tn.cornell.edu 
</A>&gt;
</address>
<i>
Tue, 5 Apr 88 11:01:10 EDT
</i><PRE>

Thought you might like this one.  I found it on the net, but don't recall
where it was.  The source is some Cray related magazine, I believe.

CRAY - A traditional Shinto ceremony was performed at Cray's systems 
    check-out building in Chippewa Falls to introduce a protective
    spirit into a new X-MP/24.  The ceremony was requested by Century
    Research Center Corp. (CRC), the Japanese service bureau that 
    ordered the system.

      There were two purposes to the ceremony:  to help protect the
    system during shipping and to ensure that it will run smoothly once
    it is installed on site.  "The ceremony places a spirit in the
    computer that ensures the company will prosper as customers use
    the system." (Tony Hagiwara, manager of the shipping firm that
    will deliver the system to Japan.)

      The Shinto ceremony traditionally is performed in Japan as a kind of
    blessing for significant events, such as an important purchase or
    the dedication of a new building.  

      Ceremony participants included:  the President of Cray Research Japan, 
    Cray's Coordinator of country services, Cray's Director of marketing 
    support, the President of CRC, the Director of CRC's systems 
    engineering division, and an employee of the shipping firm.  
    Each participant laid an evergreen branch on the table before the 
    computer system, bowed, clapped hands twice, and bowed again.  When 
    all had finished, the six participants each had a cup of sake and the 
    brief ceremony was over.

      An easel with the names of Cray Research and CRC written in Japanese,
    was brought from Japan for the ceremony.  It will return to Japan
    with the Cray system and sit nearby the system once it is installed,
    so that the spirit will continue to guard the system, helping keep
    its operation trouble-free.

Eric Haines
(not John Saponara, no matter what the header of this mail says!)

</PRE>
<HR><H3><A NAME="subj3.2">
Yet Another UnTimely Risk 
</A>
</H3>
<address>
Paul Cudney
&lt;<A HREF="mailto:cudney@sm.unisys.com ">
cudney@sm.unisys.com 
</A>&gt;
</address>
<i>
Tue, 5 Apr 88 00:06:55 PST
</i><PRE>

Before the beginning of computing was time, and with time was change.  You
might think we would all be familiar enough with calendar time to cope with
it easily, even to the point of designing systems to accommodate both the
predictable and the politically inevitable.  Within the space of two months
we have been surprised by reports of problems handling this most pervasive
measure of our existence.  We have been further surprised by the difficulty
in making what most would consider a minor change to a system, such as
changing the date Daylight Savings Time goes into effect (or not), as you
can see from the following notice.  Perhaps the design of a calendar watch
algorithim should be required in every software engineering course.

I see several lessons here for RISKS readers.  Care to volunteer a few?

&gt; From sysadmin Mon Apr  4 20:20:53 PST 1988
&gt; Subject: R&amp;D is off by an hour
&gt; Date: 4 Apr 88 23:57:58 GMT
&gt; Organization: System Development Group, Santa Monica
&gt;
&gt; The R&amp;D clock has been manually adjusted by an hour to partially
&gt; compsensate for a software bug.  The problem is that R&amp;D's release of
&gt; Berkeley Unix predates the US Congress's decision last year to move up
&gt; transition to daylight savings time from the end of April to the beginning
&gt; of April.
&gt;
&gt; A fix isn't easy because it relies on relinking every piece of software
&gt; that prints human-readable dates.
&gt;
&gt; Here's an example session that illustrates the problem.
&gt;
&gt;         R&amp;D-1% date Mon Apr 4 15:57:37 PST 1988 R&amp;D-2% date -u Mon Apr 4
&gt;         23:57:37 GMT 1988
&gt;
&gt; It's 3:57pm PDT, even though 'date' says "PST"; the GMT time is off by an
&gt; hour because it's really 22:57:37 GMT.
&gt;
&gt; If your software communicates with the outside world or otherwise relies
&gt; on an accurate clock, you should take this into account.  For example, the
&gt; GMT Date: headers at the start of news articles posted at R&amp;D are all
&gt; off by an hour; see the header of this article for an example.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Olde Virus Shoppe
</A>
</H3>
<address>
Barry Hayes 
&lt;<A HREF="mailto:bhayes@cascade.stanford.edu">
bhayes@cascade.stanford.edu
</A>&gt;
</address>
<i>
4 Apr 1988 1352-MST (Monday)
</i><PRE>

Way way back in, I think, 1978 or so, we created a bug on the time-sharing
system at Dartmouth, DTSS.  Not really a classical virus, but a fun bug anyway.

There was a kind of file protection called "slave trap programs".  You could
set up a file so that whenever a program would open that file, a slave trap
program would run and its termination status would give the access rights
allowed to the program trying the open.

Well, one day we played with the consequesnces of this scheme and wrote a
program which, when used as its own slave trap, would change its own name and
then terminate.  The end result was a file, usually called ELUDE-23 since the
length of the program was 23 words, which, when you tried to open it, would
change its name to ELUDE-NN, where NN would be the seconds in the time of day.

This confused people, of course, but also caused problems for a few programs.
There was a program which would go into every directory on the system and copy
over fragmented files, for instance.  It issued a system call that would open
every file at once to avoid overhead.  The result from this call was, for each
file, a directory entry, a status return for an open, and a file descriptor.
It wasn't very happy when it started getting "file not found" status.

By the way, you out there somewhere Steve?

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Olde Virus Shoppe
</A>
</H3>
<address>
Douglas Jones 
&lt;<A HREF="mailto:jones%pyrite.CS%cs.uiowa.edu@RELAY.CS.NET">
jones%pyrite.CS%cs.uiowa.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 4 Apr 88 13:59:20 mst
</i><PRE>

One of the classic ways to crash a UNIX system is to create an executable
file, call it virus, containing code such as the following:

     echo "virus" &amp; virus &amp; virus

When run, this shell script prints "virus" on the terminal in parallel with
starting two more copies of itself.  The resulting proliferation of processes
quickly fills the process tables of the system.  I have used this for years
as a test of UNIX systems, since it is faster to type it in than read the
manuals to find out how they manage resource exhaustion.

On older UNIX systems (with no per-user resource limits), this would crash
the system as soon as an essential system process could not be created.
On newer systems, this effectively disables the user who starts it, and it
is hard to kill.  The mess can be ended by renaming or deleting the
file, at which point, remaining processes will be unable to create new ones;
killing individual processes rarely has a useful effect.

I encountered a related problem in an advanced course on fault tolerant
computing last spring.  We have an Encore multiprocessor at Iowa largely
dedicated to running student programming assignments.  I assigned a project
in which students were to write fault tolerant code on the Encore.
The people at the computer center began to notice some very unusual loading
on the machine soon after students began working on this project.
The skeleton of a typical fault tolerant program is outlined below:

	loop { one iteration is completed for each failure }
	     if fork = 0 { fork is a UNIX system call to create a process }
             then { child process begins executing here }
                  loop { until failure is detected in parent }
                       -- code to restore key variables from checkpoint
                  endloop
             else { parent process continues executing here }
		  loop { until failure is detected in child }
                       -- code doing useful job and being monitored by child
		       -- code to checkpoint key variables in stable storage
                  endloop
             endif
        endloop

The most obvious problems with this arose when the code to await a failure was
wrong and always terminated the loop in question.  In this case, huge groups
of processes were rapidly created, much like the shell script above.

A more subtle problem arose when students got working programs but forgot to
include any code to terminate the program when they were done testing.
At least one student didn't realize that his processes weren't going away when
he was done, and each of his experimental sessions created another fault
tolerant team of CPU bound processes.  When the system operators noticed these
accumulating, they set out to kill them and got quite frustrated when
replacements appeared for each process they killed.
                      					Douglas W. Jones

</PRE>
<HR><H3><A NAME="subj5.2">
Re: (c) Brain VIRUS in RISKS DIGEST 6.52
</A>
</H3>
<address>
Chief Dan Roth 
&lt;<A HREF="mailto:chiefdan@vax1.acs.udel.edu">
chiefdan@vax1.acs.udel.edu
</A>&gt;
</address>
<i>

</i><PRE>
Date: 5 Apr 88 00:57:38 GMT

The "(c) Brain" virus is not a new virus.

It is a basically harmless virus which first emerged here at the University of
Delaware early last fall.  I say *basically* harmless, because (unless its been
modified) it doesn't attempt to do any harm to the disks.  However, those with
a better understanding of DOS on the IBM-PC tell me that in certain very
specific cases (I believe involving non-standard data formats) some data could
be lost.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Risks in diving computers
</A>
</H3>
<address>
Rich Sands
&lt;<A HREF="mailto:rms@gubba.SPDCC.COM ">
rms@gubba.SPDCC.COM 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 4 Apr 88 15:04:34 GMT
Reply-To: gubba!rms@husc6.harvard.edu (Rich Sands)

J.M.Hicks comments on dive computers:
&gt;   Poor human interfaces have been discussed in this forum many times, but
&gt;what opinions do people have of users' behaviour when a simple system is
&gt;replaced by a complicated system that they do not understand and they
&gt;can probably ignore because it takes a conservative view?

As a regular diver and user of an Orca 'EDGE' dive computer, I think
that these devices are a perfect example of how computer technology can
dramatically REDUCE the risk of an inherently risky activity. Using the
old-style Navy dive tables is tricky, requires substantial training, and
can be fouled up even by experienced divers. The dive computer's user
interface is MUCH easier to use and understand than the manual tables.
In this case, computers replace a very complicated system with a much
simpler system, not the other way around.

Sport divers go through a certification program that emphasizes safety,
graphically explains what can happen to you if you ignore the rules, and
in general produces a very safety-conscious diver. They know that dive
computers can keep them safe only if they heed the computer's warnings
and understand its operation. I think that most divers would pay a lot
of attention to the 'ASCEND MORE SLOWLY' message that their computer
flashes at them. There are many other risks in using the EDGE much
more serious than this warning message, such as the tendency for the
on/off switch to get caught on things, shutting the computer off and
losing the accumulated nitrogen absorption data.

There will always be people who do not heed safety rules, either on
purpose, or from ignorance.  The former will abuse dive computers just
as surely as they abuse the tables now.  The latter will find the
computers much less intimidating and understandable than the tables,
making them safer. 

The newest computer by Orca, called the 'Skinny Dipper', replaces the
'ASCEND MORE SLOWLY' message with a red flashing LED. The current depth
is not obscured anymore, and the warning is much more noticable since
there is almost no red light underwater and anything bright red really
gets the diver's attention. It also has a locking on/off switch.

Why worry now about the risks of slight imperfections in an otherwise
risk-reducing technology? Worry instead about making this excellent
safety device inexpensive enough to be in the hands of all sport divers,
THEN worry about the details!
                                               --  rms

UUCP: {ihnp4,harvard,husc6,linus,ima,bbn,m2c}!spdcc!gubba!rms 
Compuserve: 71360,1067	BIX: richsands 

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     RISKS in philosophyland
</A>
</H3>
<address>
        David Thomasson 
&lt;<A HREF="mailto:ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU">
ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 05 Apr 88 00:10:38 EDT
</i><PRE>

Several recent items in RISKS maintained tenuous connection with
computers while discussing the more humanistic issue of discrimination.
One writer went at his subject with such vigor that he rounded
things off with a battle cry:

  &gt;Get out there and challenge the bigots! Both you and the society will grow.

The same writer then sounded a cautionary note:

  &gt;I've often wondered *why* the same person who will not accept or tolerate
  &gt;shoddy work or thinking on the job, will choose to ignore or tolerate or
  &gt;accept or embrace any shoddy societal norm.

Although I'm happy to see RISKS extending its content to include
philosophical issues, I continue to blanch at some of the arguments
and assertions that are made. For example, the same writer who issued
the above-quoted caveat told of being invited to join an officers'
club. In a moment of dudgeon, the writer replied to the club:

  &gt;I TAKE OFFENSE AT AN INVITATION TO JOIN ANY ORGANIZATION WHICH
  &gt;DISCRIMINATES IN ANY WAY, ...AND DISCRIMINATION BY RANK OR PAY
  &gt;IS DISCRIMINATION JUST AS SURELY AS DISCRIMINATION BY COLOR, AGE,
  &gt;ETHNICITY, GENDER OR RELIGION.

Why would -- or should -- one disapprove of *any* kind of discrimination?
The implicit claim here is that discrimination in any form whatever is
morally wrong. And I cannot see how this assumption can be exempted from a
charge of shoddy thinking about morality, the same kind of shoddiness that
the writer wonders and warns about. Are youth clubs morally suspect because
they restrict membership to *youths*? Is Phi Beta Kappa culpable for
excluding stupid people? Are ballet companies open to reproach for
discriminating against clumsy oafs?  (And by the way, what *is* so morally
offensive about a club for officers??)
    I am not trivializing the issue here. If one thinks it is a simple
matter of separating the "bad" kinds of discrimination from the "good" (or
"acceptable") kinds, try phrasing a general principle that will make that
distinction. I find it more than a little disturbing when people who are
obviously very bright and extremely competent in their fields (computer
science and related fields) burst onto the philosophical scene and start
shooting out the lights.
   Consider another recent RISKS item about discrimination. The writer
says he applied for a driver's license and noticed that the application
asked for his race. "It seemed to me that my race had nothing to do with
driving a car, so I left it blank." By the same reasoning, one might just
as well refuse to give one's name, sex and address, since they too have
nothing to do with driving a car. Perhaps -- *perhaps* -- including such
information on a driver's license could be justified on some ground
other than driving competence. Perhaps?
   I am not out to toss cold water on RISKS' recent ventures into such issues
as discrimination. By all means, challenge bigots. But for God's sake get down
off old Rosinante and do it with a little more style and intelligence.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of NOT giving race/ethnicity
</A>
</H3>
<address>
David Rogers
&lt;<A HREF="mailto:drogers@riacs.edu ">
drogers@riacs.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 4 Apr 88 20:12:39 GMT
Organization: RIACS, Moffett Field, CA 94035

Most financial aid forms ask for ethnicity (the modern way to phrase `race'
questions).  When I was at Berkeley, I, in my fervor, refused to answer such
things, or at the minimum, checked OTHER.  (At least they gave an OTHER box!)
They would happily accept any such forms, probably because they were tired of
arguing with students like me.

The risk?  I later asked an aid officer what they did with these forms:  they
just assign all such people to the `white' group for the purposes of
calculating aid, since that is the `least desirable' ethnicity when it comes to
calculating aid.

When open conflict arises about the answers to questions on forms, that is
usually better than this much more insidious procedure, that of assigning the
user an `answer' which is (usually) the least desirable of the options.  The
use of computers will make this `when in doubt, assume the worst' type of
defaulting even more common, and nearly impossible to detect.
                                                                David Rogers

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: More On Race and Ethnicity Questions...
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 5 Apr 88 13:12:16 EDT
</i><PRE>

&gt; ... If you *really, really* think about it, there is no way to justify a
&gt; RACE or ETHNICITY question, unless you accept the notions of quotas...

In fairness, it should be mentioned that in a community with discrimination
problems, security-clearance forms (and no others) might have real reason to
ask such a question, for the same reason that they have legitimate reason to
ask about unorthodox sexual habits:  blackmail potential.  Mind you, I admit
that (a) it's harder to get a good blackmail threat out of racial issues, (b)
if we assume, for example, the southern US some decades ago, such a question
really ought to be something like "any Negro ancestry?"  rather than just
"race?", and (c) fortunately, this sort of nonsense isn't much of an issue any
more.  But in the wrong place at the wrong time, I can see how a real security
issue could arise.  It's not inherently ridiculous, although in the examples
cited it certainly is silly.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
April Forgeries (Re: <A HREF="/Risks/6.52.html">RISKS-6.52</A>)
</A>
</H3>
<address>
Charles Daffinger 
&lt;<A HREF="mailto:cdaf@iuvax.cs.indiana.edu">
cdaf@iuvax.cs.indiana.edu
</A>&gt;
</address>
<i>
Mon, 4 Apr 88 23:17:09 EST
</i><PRE>

     [Most of you have chortled appropriately at the Spafford Spoof.  Charles'
     message is apparently intended for those of you who need more explicit
     references to the self-referential evidence left by the forged forgery
     warning.  By the way, Charles neglected to remark that <A HREF="/Risks/6.52.html">RISKS-6.52</A> was 
     not put out on 1 April either.  PGN]

Here's the article warning about forgeries:  Note the strange date, note
that spaf's message is dated *after* the message it was enclosed in, and
a couple of self-references in the posting!  Enjoy!

In article &lt;12386860573.13.NEUMANN@KL.SRI.COM&gt; you write:
&gt;RISKS-LIST: RISKS-FORUM Digest   Friday 1 April 1988   Volume 6 : Issue 52
&gt;

&gt;Contents:
&gt;  April Fool's warning from Usenet (Gene Spafford via Cliff Stoll)
&gt;----------------------------------------------------------------------
&gt;
&gt;Date:     Thu, 31 Mar 88 12:17:48 PST
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
&gt;From: cliff@Csa5.LBL.Gov (Cliff Stoll)
&gt;Subject:  April Fool's warning from Usenet
&gt;
&gt;Here's the warning from USENET's  news.announce.important:
&gt;
&gt;From: spaf@cs.purdue.EDU (Gene Spafford)
       ==================================
&gt;Subject: Warning: April Fools Time again (forged messages on the loose!)
&gt;Date: 1 Apr 88 00:00:00 GMT
       ^^^^^^^^^^^^^^^^^^^^^
&gt;Organization: Dept. of Computer Sciences, Purdue Univ.
&gt;
&gt;Warning: April 1 is rapidly approaching, and with it comes a USENET
&gt;tradition. On April Fools day comes a series of forged, tongue-in-cheek
&gt;messages, either from non-existent sites or using the name of a Well Known
                                             ==============================
&gt;USENET person. In general, these messages are harmless and meant as a joke,
=======
[...]
&gt;
&gt;        o Posted dates. Almost invariably, the date of the posting is forged
&gt;          to be April 1.                   =================================
           =============

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
April Forgeries (Re: <A HREF="/Risks/6.52.html">RISKS-6.52</A>)
</A>
</H3>
<address>
Rahul Dhesi
&lt;<A HREF="mailto:iuvax!bsu-cs!dhesi@rutgers.edu ">
iuvax!bsu-cs!dhesi@rutgers.edu 
</A>&gt;
</address>
<i>
Mon, 4 Apr 88 23:25:38 EST
</i><PRE>
Organization: CS Dept, Ball St U, Muncie, Indiana

... Of course, it's possible that it was a double-forgery, i.e., that Gene 
Spafford forged it himself.  -- Rahul Dhesi  
                                                  [Sorry.  Not THIS TIME.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.54.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.56.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-4</DOCNO>
<DOCOLDNO>IA012-000129-B044-243</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.56.html 128.240.150.127 19970217020510 text/html 26300
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:03:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 56</TITLE>
<LINK REL="Prev" HREF="/Risks/6.55.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.57.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.55.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.57.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 56</H1>
<H2>  Thursday 7 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Guess what?  A modified FLUSHOT!  
</A>
<DD>
<A HREF="#subj1.1">
James Ford
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Scrambled FAT from hell (EDRAW) 
</A>
<DD>
<A HREF="#subj2.1">
Jay F. Rosenberg via Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Notifying users of security problems 
</A>
<DD>
<A HREF="#subj3.1">
Eric Postpischil
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Another quarter heard from (re: viruses) 
</A>
<DD>
<A HREF="#subj4.1">
T.M.P. Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Virus distribution idea 
</A>
<DD>
<A HREF="#subj5.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Kerberos documentation -- [Third-Party Authentication] 
</A>
<DD>
<A HREF="#subj6.1">
Jennifer Steiner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Terminals:  Why the discussion was interesting 
</A>
<DD>
<A HREF="#subj7.1">
Jerry Leichter
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
     Guess what?  A modified FLUSHOT!
</A>
</H3>
<address>
        James Ford 
&lt;<A HREF="mailto:JFORD1%UA1VM.BITNET@CUNYVM.CUNY.EDU">
JFORD1%UA1VM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 06 Apr 88 10:17:12 CDT
</i><PRE>

As some know, I recently got a copy of THE DIRTY DOZEN from Eric's BBS.  The
description of the CHRISTMAS EXEC was (almost) non-existant, so I uploaded
some back issues of RISKS to the board.....leaving my BITNET address on the
text.

Well, I have received a reply from someone who is writing a paper/text on
trojans, and he had this warning about FLUSHOT:

&gt; FLUSHOT.......... FLUSHOT3 is OK. Watch out for FLUSHOT4. There
&gt; is a Trojan Horse version of it going around. Some unscrupluous
&gt; person modified the "cure" so it became a disease. For any of the
&gt; FLUSHOT programs, the valid programs have a separate ASCII text
&gt; documentation of the program. The hacked version, made a text
&gt; file that is embedded in an executable file. Any version without
&gt; Ross Greenberg's documentation in a text file should be avoided.

  Yet another bug on the loose.........(sigh)

                            James Ford

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Scrambled FAT from hell -- a brief report.  (EDRAW)
</A>
</H3>
<address>
Geoff Goodfellow
&lt;<A HREF="mailto:geoff@fernwood.mpk.ca.us ">
geoff@fernwood.mpk.ca.us 
</A>&gt;
</address>
<i>
Tue, 5 Apr 88 21:45:03 PST
</i><PRE>

From: unbent@ecsvax.UUCP (Jay F. Rosenberg)
Newsgroups: comp.sys.ibm.pc
Subject: Scrambled FAT from hell -- a brief report.
Keywords: HD crash scrambled FAT EDRAW Quattro interaction
Date: 5 Apr 88 12:53:58 GMT
Organization: UNC Chapel Hill

     Having spent 2 hours last night recovering from a thoroughly 
scrambled FAT, I thought it appropriate to hold a small post-mortem.
     The culprit *appears* to have been a shareware program called EDRAW 
(Version 3.2), which I picked up as PCSIG Disk #828 from a local 
university's public bbs.  As near as I can diagnose the phenomenon from 
the rather incredible list of messages I received from CHKDSK, what 
happened was this:
     I had installed Borland's Quattro spreadsheet program.  As far as I 
can tell (by using assorted MACE tools), when Quattro installs, it marks 
various disk sectors as protected, probably in aid of finding its own
overlays.  (MACE had been respecting these and not moving them about 
during unfragmenting operations.)  EDRAW apparently did *not* recognize 
and/or respect this protection.  When I used the program to make some 
sketches and symbols and proceeded to save them to the disk, then, EDRAW 
evidently wrote good parts of them over these protected sectors.  The 
result was the most incredible mess of truncations and crosslinks I've 
ever seen.
     Whether and, if so, how the various memory resident utilities I had 
installed entered into the scenario of destruction, I do not know.
     Responses, reactions, comments, and alternative diagnoses will be 
most welcome.  I've learned a lot from the net over the years.  One
thing I learned:  Keep current backups!  I did.  Go ye, and do likewise!

JAY ROSENBERG  Dept. of Philosophy  CB# 3125  UNC  Chapel Hill, NC  27599
...{decvax,akgua}!mcnc!ecsvax!unbent         ...tucc!tuccvm!ecsvax!unbent  
   unbent@ecsvax.UUCP      unbent@ecsvax.BITNET      unbent@unc.BITNET      

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Notifying users of security problems
</A>
</H3>
<address>
&lt;<A HREF="mailto:postpischil%alien.DEC@decwrl.dec.com">
postpischil%alien.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
Wed, 6 Apr 88 08:40:03 PDT
</i><PRE>

In Risks Digest 6.54, Andy Goldstein says that knowledge of security bugs,
during the period in which they are being corrected, will not do VAX/VMS
system managers any good and so should not be distributed until a fix is
available.

I disagree for two reasons.  First, there are work-arounds to any problem.
Almost every site has a big red button (or equivalent) that will make any
computer system secure, and a very few sites might have information sensitive
enough to warrant the button's use.  For another few sites, the VMS software
might be only a portion of their computing resources, a portion they can do
without or with limited use for a period.  And probably a larger number of
sites can control network and physical access.  Many sites can restrict
accounts, temporarily removing general accounts.  (Unless the bug is so basic
it can be used to access the system without even the simplest account.)
Another work-around is to use captive accounts.  And other sites may be
satisfied with establishing some sort of auditing procedures so they can tell
who is being naughty and stop it if not prevent it beforehand.

The second reason is that the publisher is not entitled to make these
decisions.  How can one honestly sell a supposedly secure system knowing it is
not secure?  Are sales to be stopped while the bug is being corrected, or will
the salespeople lie when the potential customer asks about security?  Is one
going to renege on the customers who have paid money to be informed of bugs?
It is not entirely a matter of whether the publisher thinks the customer can
make use of the knowledge or not; the customer has a right to know they are not
secure regardless of what the publisher thinks about it.
                               			         edp (Eric Postpischil)
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Another quarter heard from (re: viruses)
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 6 Apr 88 00:41 EDT
</i><PRE>

The info-apple (Apple II series) interest group has been having sporadic
missives on viruses lately (of course.)  One of them expressed thorough
disbelief.  It was responded to quite handily; the response, which 
cites most of the original ostrichian comments, seemed worth sharing
with the RISKs population. -- Ted


[3382] (130 lines) Network_Server.Daemon 04/05/88  1032.6 edt Tue info-apple
Subject:  viruses ARE possible
From: info-apple-request@BRL-SMOKE.arpa@BRL-SMOKE.ARPA

&gt;Date:         Mon, 4 Apr 88 15:37:46 CDT
&gt;From:         SCHUESSLER &lt;GA.NES%ISUMVS.BITNET@CUNYVM.CUNY.EDU&gt;
&gt;Subject:      Viruses: Fact or Fiction?

&gt;Well, folks, I am totally confused about this virus stuff.  In reading
&gt;about them in a local paper (Today section DesMoines Register) about
&gt;monitors exploding, and hard disks crashing, I don't see how anybody
&gt;could possibly write a virus that would get by enough people to become
&gt;dangerous.  Please examine my reasoning, and point out where I missed
&gt;something.

They get by because they generally don't do anything damaging right away.

&gt;Suppose I wish to write a virus.  I have read that the operating system
&gt;is the place where they're supposed to be put. Here are some problems:
&gt;
&gt;  1. How do I add routines to prodos w/o changing the block length?
&gt;     I don't know about anyone else, but I think I would
&gt;     probably notice that Prodos would take longer to boot, or
&gt;     that it was 32 blocks instead of 31.

You might, but you probably wouldn't notice it right away.  Anyway, ProDOS is
*not* the only place to hide it.  Could tack it into other applications, or
even in the boot blocks (there is some unused space there for booting SOS on
the Apple ///).  Heck, you could even hide some code in the DIRECTORY (which
gets read into RAM during the boot process anyway, while the boot blocks are
looking for the PRODOS file).  (This would cause a problem when the directory
started getting full.)

Also, there is most likely some space in PRODOS that isn't currently
used (I haven't looked lately).

&gt;  2. Viruses are supposed to "spread" themselves. Spreading implies
&gt;     (to me at least) saving themselves on other disks in other drives,
&gt;     which would be extremely obvious if you did a catalog of drive1
&gt;     and it went to drive2, or it would suddenly start working on the
&gt;     disk w/o direct commands from the keyboard.  Equally suspicious
&gt;     would be a slow catalog listing (with a virus 'spreading' itself
&gt;     sometime during the execution of the command).

It wouldn't take very long to spread itself, and it would not do it
spontaneously.  For example, it could writ itself into the boot blocks
one out of every 20 times you write to your main directory.  It wouldn't
take too long, since your drive would already be in the right area of
the disk anyway (main directory = blocks 2-5, boot blocks=0-1).  Writing
to disk already takes a variable amount of time depending on where the
free blocks happen to be on disk, so one or two more block writes with
no head movement would be hard to notice (ESPECIALLY on a 3.5 drive or
a hard drive.  Or a RAM drive [with or without a battery backup!].)

&gt; 3.  The next thing in question is the delayed effect, which no doubt
&gt;     is done by incrementing a counter each time it is executed.  In
&gt;     order to retain this value, it must be stored back on the disk
&gt;     which causes another timing problem as far as working with the
&gt;     disk is concerned.

Counters could be in RAM as well as on disk, or it could skip conters
completely and trigger based on some semi-random number or some set of
conditions on disk.  -- Even if you use counters, it might not have to
do any extra disk writes (for example, increment 2 unused bytes in the
root block of your directory whenever the block is being written ANYWAY).

&gt; 4.  To spread itself, it must know the volumes on line, which
&gt;     have prodos copies that are not infected already (which will
&gt;     take a bit of code to check for) and then probably set some
&gt;     flags to point to the clean copies so that when executed next
&gt;     it can spread itself.

Nope, it doesn't have to be that complicated.  Just infect disks as they are
accessed by the running application, and set it up so it doesn't matter if the
thing you're infecting is already infected or not.

&gt; 5.  Finally, there is the problem of doing all the things viruses
&gt;     are famous for in 200 bytes or less.  I don't know about anyone
&gt;     else....maybe it's just me, but I can't do all that fancy I/O
&gt;     in 200 bytes or less ( which is supposed to be the optimum length).
&gt;     That's w/o the fancy routine to time the spreading with save/bsave
&gt;     load/bload's which would be a nightmare in itself.

You can do a *lot* in 200 bytes, although there's not much reason to
limit them to being that small.  It only takes 18 bytes to say
"WRITE_BLOCK number 0 on the last-accessed device" in machine.
(Doing file-level I/O rather than block-level I/O would take a few
more bytes, but not *that* many more.)

&gt;With all that to worry about, why would anyone go through all the trouble?

I don't know, but it only takes *one* deranged person.  If your hard drive
has just fallen victim to someone's virus, you won't really care *why*
they went to the trouble.

&gt;Maybe I could see it possible for someone who just uses the software, and
&gt;doesn't do the programming/doodling around with operating systems to miss
&gt;the differences, but I hardly think that it would result in a major crisis
&gt;to society.

But people are so eager to give the latest nifty software to their favorite
bulletin boards that the viruses can potentially spread *very* quickly.
If we teach people to be careful the problem can be kept under control, but
it gets harder as operating systems get larger and more complex--there are
lots more interesting ways to "infect" IIgs's than IIe's, for example (desk
accessories, RAM vectors that survive an Apple-Ctrl-Reset, patching system
tool vectors, etc).

&gt;  Also--Is it legal to create a 'harmless' virus to see if it works
&gt;       and you supply an antidote?

I don't know if it's legal, but it's pretty stupid--everyone will hate you
when they find out about it.  (Someone [in Canada?] wrote a "harmless"
virus for the Mac that displayed a World Peace message on a certain date.
This pissed lots of people off &amp; I think caused a few problems for people
even though it was supposd to be harmless.  This virus [or was it another
one?] has accidentally made its way into some factory-fresh copies of at
least one piece of commercial software for the Mac.)

&gt;  | |    Niko Schuessler    | |
&gt;  | |    GA.NES@ISUMVS      | |
&gt;  | | Iowa State University | |

--David A. Lyons  a.k.a.  DAL Systems
  PO Box 287 | North Liberty, IA 52317
  BITNET: AWCTTYPA@UIAMVS
  CompuServe: 72177,3233
  GEnie mail: D.LYONS2

---[3382]---

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Virus distribution idea
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Wed, 6 Apr 88 15:20:39 CST
</i><PRE>

I just received a survey in the mail from a company in Boston called
The LEK Partnership, on the subject of spreadsheet software. It is a
form of survey different from other surveys I have previously
received from various sources, which were usually multiple-choice paper
forms. This one is a diskette with an accompanying letter and some
printed material. There is also a Business-Reply diskette mailer and
a dollar bill. The letter describes the survey as being "a computer
interview." The instructions are to boot any IBM PC or compatible with
this diskette and "the rest is automatic." You then put the diskette
back in the mailer and drop it in the mail to go back to the sender.

Now, what immediately occurred to me was, "What a beautiful way to
disseminate a virus!" Adding the dollar bill is a nice touch, but most
computer users would be intrigued enough by the concept to at least
stick the diskette in their machine and see what it was like, even if no
money or other incentive accompanied it. Just to put it in your machine
would be enough to spread a virus on that diskette, and the fact that
you send the diskette back to them not only eliminates the evidence, but
would also let hidden programs pull some amount of data from your files and
stash it on the diskette for the use of the sender. (I agree that the
latter is pretty farfetched, given the vagaries of naming PC files, and
the low likelihood that simple software could find anything of value or
interest on any random PC out there.)

A party interested in doing this could rent a mailing list from any of
several magazines, and get access to many corporations and government
agencies, bypassing network security and reaching areas isolated from
any networks. It wouldn't be cheap, but it would be effective (at least
the first time). It might be a reasonable method of economic sabotage.

Let me hasten to add that I have no reason to suspect this vendor of
doing such a thing, nor have I heard of anything like this happening.
The company seems legitimate; they provide an 800 number in their cover
letter for recipients to call. The survey is not anonymous, though --
the diskette has a serial number, which matches a number on the label on
the envelope, so they know who got which diskette, even if it does not
request a name and address as part of the on-line dialog.

The virus possibility just sprang to mind as I read the letter; I suppose
that's a reflection on my evil nature. :-) I have not yet put this diskette
into a PC, but I have run demo diskettes from other vendors without thinking
first about the RISKS I'm voluntarily accepting by doing so. (Since I
don't yet use a PC myself on a regular basis, its been other peoples'
PCs who have run the RISKS, so that might explain my blithe attitude! :-)

This is all speculation, of course, but we've been thinking and talking
so much about viruses (viri?) lately that it seems natural to view such
things with suspicion. I don't know now if I will ever run this diskette!

Are there any organizations out there who have a codified policy for
dealing with this sort of thing? That is, some clearinghouse or
checkpoint for looking at software or checking diskettes received from
public-domain or random sources, where skilled personnel using isolated
hardware check it out and pronounce it "cleared" before it can be loaded
or used on any of that organization's other machines? It may be costly
and cause delays, but it may become necessary. 

Regards,
Will Martin

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Kerberos documentation [Third-Party Authentication]
</A>
</H3>
<address>
Jennifer Steiner
&lt;<A HREF="mailto:steiner@athena.mit.edu ">
steiner@athena.mit.edu 
</A>&gt;
</address>
<i>
Thu, 07 Apr 88 16:57:39 EDT
</i><PRE>
Organization: Project Athena, MIT Cambridge MA

Documentation on MIT Project Athena's authentication service, Kerberos, is
available for anonymous ftp on "athena-dist.mit.edu", in ~ftp/pub/kerberos.

Documents include the paper given at the Winter 1988 Usenix Conference (text or
postscript), a detailed design document (text or postscript), and manual pages.

If you can't ftp, and would like a hardcopy, send your request (and US/PTT mail
address) to info-kerberos@athena.mit.edu.

We are currently running a beta test of the software.  When the beta test has
been completed, we plan to put the code in the public domain (except for the
encryption library, which probably can't be exported out of the U.S.).  I'll
post a pointer when the code is available.

Please post any followup messages to comp.misc.

Jennifer Steiner, Project Leader, Kerberos Development, MIT Project Athena


Below is the abstract from the Usenix paper:

In an open network computing environment, a workstation cannot be trusted to
identify its users correctly to network services.  Kerberos provides an
alternative approach whereby a trusted third-party authentication service is
used to verify users' identities.  This paper gives an overview of the Kerberos
authentication model as implemented for MIT's Project Athena.  It describes the
protocols used by clients, servers, and Kerberos to achieve authentication.  It
also describes the management and replication of the database required.  The
views of Kerberos as seen by the user, programmer, and administrator are
described.  Finally, the role of Kerberos in the larger Athena picture is
given, along with a list of applications that presently use Kerberos for user
authentication.  We describe the addition of Kerberos authentication to the Sun
Network File System as a case study for integrating Kerberos with an existing
application.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Terminals:  Why the discussion was interesting
</A>
</H3>
<address>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</address>
<i>
Mon, 4 Apr 88 18:26 EST
</i><PRE>

The last couple of RISK's have had articles from me and others on details of
block mode terminals and the risks they do or don't pose.  In all the rush of
detail, what I see as the important point, and the reason I got involved in
the discussion at all, was lost.

"Naive" users of computers have only the most limited idea about how they
work, what their limitations are, and what, if anything, can be done about
those limitations.  Since they have no basis for reaching a deeper under-
standing - if they DID, they wouldn't be "naive" users! - they tend to treat
computer risks in one of two ways:  Either they assume the omnipotent computer
is safe and never goes wrong - an attitude encouraged by salesman, providers
of computer services of all sorts, government - or they are battered by sad
experience to thinking that "computers always screw up and there's nothing
anyone can do about it" - an attitude paradoxically encouraged by all the same
people (except perhaps the salesmen).

As people learn more about computers, they continue to get pulled in both
directions.  On the one hand, they learn more and more about how to make
things work; on the other, they learn more and more about the extraordinary
ways in which things can fail.  There's a certain tendency to just throw one's
hands up in despair and claim things will never be right, so why bother to
try?

The only thing that comes out of such an attitude is poorly designed, risky
systems.  No, we can't eliminate all risks and vulnerabilities; but we can
damn well try to understand what they are and perhaps eliminate enough to
remove our systems from the "clear and present danger" category.  Perrow's
"Normal Accidents" can easily be read as one of those cries of despair, but
the book is valuable exactly because it sometimes rises above that level.
I've heard reports - it would be nice to see a reference - that the Colonel
Murphy of eponymic fame is VERY distressed by the universal invocation of his
"Law" as proof that systems can never work right.  That's missing the point
Murphy wanted to get across:  That if you design errors IN, you will get
errors OUT.  Good engineering means designing errors out - out of the whole
system (human users, with all their complexity, and all), to the greatest
extent you can.

Terminals, ALONG WITH THE SYSTEMS THEY CONNECT TO AND THE TRAINING OF THEIR
USERS, *can* be made secure.  It takes a significant, continuing effort, and
that effort can all too easily be undone by careless "extensions"; but it is
NOT impossible.  The same can be said of many other risks and vulnerabilities:
They can be eliminated, or reduced to acceptable levels, if we are willing to
make the appropriate investments.  We - the societal we, including all those
"naive" users out there - will not be willing to make those investments until
we are convinced that (a) the risks and vulnerabilities are there - something
that recent events have probably gotten across; (b) something can be done
about them.  We "computer sophisticates" are the ones with the responsibility
for making (b) true - and of convincing society at large that it can be true.
We will have a great deal of trouble doing that if we all sit here moaning
about how "impossible" it is!
							-- Jerry

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.55.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.57.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-5</DOCNO>
<DOCOLDNO>IA012-000129-B044-272</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.57.html 128.240.150.127 19970217020532 text/html 26932
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:03:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 57</TITLE>
<LINK REL="Prev" HREF="/Risks/6.56.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.58.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.56.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.58.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 57</H1>
<H2>  Thursday 7 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Drive-by-light" automobile to be demonstrated 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Air Force replacing flight training with simulation 
</A>
<DD>
<A HREF="#subj2.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Cockpit Automation Risks 
</A>
<DD>
<A HREF="#subj3.1">
Alan M. Marcum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Ada and exploding missiles 
</A>
<DD>
<A HREF="#subj4.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Bank money machines 
</A>
<DD>
<A HREF="#subj5.1">
Rick McTeague
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: On UnTimely RISKS (RISKs of political consideration) 
</A>
<DD>
<A HREF="#subj6.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  How Computers Get Your (Clarified) Goat! 
</A>
<DD>
<A HREF="#subj7.1">
Glen Matthews
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Philosophy and discrimination 
</A>
<DD>
<A HREF="#subj8.1">
John Lavagnino
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Comment on "Diving Risks" 
</A>
<DD>
<A HREF="#subj9.1">
Phil Pfeiffer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: The risks of rumours 
</A>
<DD>
<A HREF="#subj10.1">
Henry Spencer and Ken De Cruyenaere
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Re: High Tech Trucking 
</A>
<DD>
<A HREF="#subj11.1">
George Michaelson
</A><br>
<A HREF="#subj11.2">
 John Haller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Block mode terminals 
</A>
<DD>
<A HREF="#subj12.1">
Steve Bellovin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Drive-by-light" automobile to be demonstrated
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Wed, 06 Apr 88 21:45:51 PDT
</i><PRE>

The following article about a "drive-by-light" automobile appeared in the 
column OPTONET: INDUSTRY BRIEFS in the newspaper OE REPORTS, April 1988, 
p 16.  OE REPORTS is a publication of SPIE (Society of Photo-Instrumentation
Engineers).

"A fibre-optic LAN-controlled automobile will be demonstrated this month at the
Hanover Trade Fair. ... The automobile uses polymer optical fibre (POF)
components and systems.  In the fibre-optic automobile, everything from
headlamps to electronic trunk locks will be controlled by a few meters of POF
and networking techniques."

(There was a diagram of the car showing modules labelled only "module 1" etc.
with lines connecting them up.  There were a lot of modules in the passenger
compartment and dashboard and one under the middle of the hood, but none
in the wheel wells.  I get the impression this is actually supposed to be
more of a trade-show attention-getter than an attempt to develop a practical
way to build a car.)
                              - Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Air Force replacing flight training with simulation
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Wed, 06 Apr 88 21:31:34 PDT
</i><PRE>

The following report appears in ELECTRONICS, March 3 1988, in the 
MILITARY/AEROSPACE NEWSLETTER column.  No author is named:

"SIMULATORS GAIN GREATER ROLE IN FLIGHT TRAINING

The Air Force is cutting in half the number of aircraft used for training and
relying more heavily on simulators to train fighter pilots and gunners.  "It
used to be that 25% of all our aircraft were for training, but now we're going
to 12.5%," says (an Air Force spokesperson). ... The $30 million system (to
simulate the F-15E trainer) which includes five mainframe computers and 25
video displays, will get a real workout: the Air Force expects eight flight
crews to work two-hour shifts on the simulator every day."

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Cockpit Automation Risks (Re: <A HREF="/Risks/6.50.html">RISKS-6.50</A>)
</A>
</H3>
<address>
Alan M. Marcum
&lt;<A HREF="mailto:marcum@sun.com ">
marcum@sun.com 
</A>&gt;
</address>
<i>
7 Apr 88 23:42:54 GMT
</i><PRE>

In RISKS DIGEST 6.50, jon@june.cs.washington.edu (Jon Jacky) related stories
from the NY Times regarding cockpit automation risks.  Two of these, in my
opinion, are more the result of poor procedures than the result of cockpit
automation.

The China Airlines 747 incident (where the crew lost control of a 747 after
losing an engine) was really caused by the captain failing to follow
established Boeing procedures for handling loss of one engine.  Proper
procedures stipulate that the autopilot should be disengaged upon failure of
one engine during cruise; the captain left the autopilot engaged, leading to
the results described in Mr. Jacky's message.  (Incidentally, loss of one
engine while enroute in a 747 is NOT considered an emergency.)

The Eastern Airlines L-1011 crash in the Everglades was a direct result of the
flight crew's neglecting their primary job: flying the airplane.  It was not so
much a matter of an inadvertent disengagement of the autopilot as it was the
flight crew's failure to perform their primary duty that caused the accident.

(The Eastern L-1011 has become a classic case study in aviation circles.  A
re-enactment of the accident, in a simulator using text from the transcript
of the cockpit voice recorder, was video taped a few years ago.  The video
tape is used by numerous airlines in their crew training.  The tape was also
shown as part of a _Nova_ episode entitled, "Why Planes Crash."  That
re-enactment is, simply, the most frightening thing I have ever seen.

Alan M. Marcum				Sun Microsystems, Technical Consulting
marcum@nescorna.Sun.COM			Mountain View, California

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Ada and exploding missiles
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Wed, 06 Apr 88 21:21:30 PDT
</i><PRE>

&gt; In RISKS 6(36), Jerry Harper asks:
&gt; (Is it true that missiles were recently destroyed on launch that had
&gt; their guidance systems coded in Ada?

I very much doubt it.  I researched the Ada story quite thoroughly about two 
years ago for an article I was writing.  At that time, almost no software
about to be fielded in weapons was being coded in Ada, despite DoD
requirements.  The reason was that compilers then available either did not
produce code at all, or did not produce sufficiently high-performance code,
for the small processors used in missiles and other weapons.  I have been
following the story since then and things appear to have improved a little
but there is still a problem, moreover lead times are quite long.  So I
doubt Ada could have been at fault.

I have not heard of any recent missile losses caused by software faults.
In fact the only case I know of was the very famous loss of Mariner I in
1962, which has been discussed at length in RISKS.  (I notice that a company
called Northwest Instrument Systems, Inc. of Beaverton, Oregon has been 
advertising an embedded code debugger with full page ads featuring a photo
of a missile exploding a short distance from a launcher, captioned "The
ultimate bug."  The ad has appeared in ELECTRONICS and ELECTRONIC ENGINEERING
TIMES.  I presume that a certain amount of license has been taken, in that
the pictured incident is not to be literally attributed to a software 
problem.)

&gt; Didn't some famous computer scientist express grave reservations about Ada?

Yes.  C.A.R. Hoare of Oxford used the occasion of his Turing Award lecture
in 1980 to say:

"I appeal to you, representatives of the programming profession of the United
States, and citizens concerned with the welfare and safety of your own country
and of mankind:  Do not allow this language in its present state to be used in
applications where reliability is critical, i.e., nuclear power stations,
cruise missiles, early warning systems, anti-ballistic missile systems.  The
next rocket to go astray as a result of a programming language error may not
be an exploratory space rocket on a harmless trip to Venus: It may be a
nuclear warhead exploding over one of our own cities.  An unreliable
programming language generating unreliable programs constitutes a far greater
risk to our environment and to our society than unsafe cars, toxic pesticides,
or accidents at nuclear power stations.  Be vigilant to reduce that risk, not
to increase it."

Reference:
C.A.R. Hoare, "The emperor's old clothes," COMMUNICATIONS OF THE ACM, 24(2),
Feb. 1981, pps. 75 - 83.  Also reprinted _The Ada Programming Language: A
Tutorial_, ed. by Sabina H. Saib and Robert E. Fritz, New York, IEEE, 
1983, 487 - 495.  No doubt also reprinted in the book, ACM Turing Award 
Lectures: The First Twenty Years: 1966 - 1985, ACM Press/Addison Wesley 1987.

&gt; Is the Pentagon insisting on the use of Ada for all military software?

Not exactly all.  Defense Directive 3405.2, March 30 1987, orders the use
of Ada in all new weapons systems.  The DoD also buys a lot of software that
is not used for weapons control.  A similar directive issued in 1983 ordered
the use of Ada in all "mission-critical" systems after January 1, 1984, and
was almost totally ineffective.  Contractors found that the compilers then
available were unsuitable, and petitioned DoD for waivers, which
they received.  DoD's position is that the compiler technology is now much
more mature, and waivers will be quite difficult to get.

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
      Bank money machines
</A>
</H3>
<address>

&lt;<A HREF="mailto:RAMCTE01%ULKYVX.BITNET@CUNYVM.CUNY.EDU">
RAMCTE01%ULKYVX.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 6 Apr 88 12:20 EDT
</i><PRE>

Several months ago, I was making a $20 cash withdrawal from my bank's
automated teller machine. While waiting for my money to come out, the CRT
went blank; several seconds later, a message saying "Please Wait" appeared.
I theorized that the machine was being reloaded with money - just a guess.

After 15-20 seconds, the screen cleared and put up the normal "Welcome to
First National Bank Teller/24" message. No money. No card. No receipt.

Being the kind of person who likes to figure out how/why things work, needing
the money so I could eat dinner, and having the good fortune of being with my
wife, I borrowed her card to see if the machine would do the same thing again.

The strange sequence of events did not recur, and everything proceeded
normally. When the money/receipt door opened, however, I received TWO $20
bills; one that I expected, and the other from the previous (failed)
transaction.

I found out later that a momentary power failure had blacked out a large part
of the city, including my bank branch, just after my $20 was ejected into the
cash drawer and just before the machine returned my card and opened the door.

Had I been un-curious, well-fed, and alone, or had the power failure been
longer in duration than my patience, I would have shrugged my shoulders and
walked away after the failed transaction, and the next guy would have gotten
my $20 (and a bit of trouble, had he/she not been honest about it). I suppose
that everything would have gotten straightened out eventually...

I was going to suggest to the bank that they change the sequencing of
events to handle this possibility a little better when they replaced the
locking money doors with they're-always-unlocked-lift-em-yourself type.

I still wonder, though, if there are some other hitches where such a power
failure could mean trouble for a system handling cash.


A humorous, true, but perhaps not as RISKy story:

A local bank uses full-sized "play-money" to train employees to load
the teller machines with cash. At one branch, the practice money was
inadvertently left in the machine. Customers were quick to point out
this oversight to the branch personnel.

The first person to receive the bogus cash, though, did not immediately
notify the bank. By chance, this person was the next-door neighbor of
the bank's CEO. After laughing it off with the CEO, the neighbor went
back to the branch the next day and made his monthly mortgage payment,
in "cash", to the bank.

Rick McTeague, Electrical Engineering Department, Speed Scientific School
University of Louisville, Louisville, KY  40292

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: On UnTimely RISKS (RISKs of political consideration)
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@ames-nas.arpa">
eugene@ames-nas.arpa
</A>&gt;
</address>
<i>
Wed, 06 Apr 88 11:10:46 PDT
</i><PRE>

From: cudney@sm.unisys.com (Paul Cudney)
  &gt;Before the beginning of computing was time, and with time was change.  You
  &gt;might think we would all be familiar enough with calendar time to cope with
  &gt;it easily, even to the point of designing systems to accommodate both the
  &gt;predictable and the politically inevitable.

Is it the fault of computers when the political definition of what "Time"
is changes?  The collection of political lobbying groups included those
industries involved in outdoor barbeques (large part) as well as a society
to help those with night blindness.  The legal definition of Daylight Savings
Time has changed more in the past 15 years than all prior years.

How many people were aware of the change of the laws regarding daylight
savings?  I'm not condeming the change, I think however, we rely heavily
upon media watchers.  Some of these loobying groups, BTW, are still trying
to change the definition of Daylight Saving Time in the fall to include two
more weeks.  So I hope you guys get your software changed before then.

Perhaps, we should compromise and average the 1/2 hour.....;-)

Also, the article on the Cray Shinto blessing was a Cray Press release and
will probably be published in Cray Channels.  This isn't anything special
(in Japan).  See "The Faces of Japan" hosted by Dick Cavett.

--eugene miya,   NASA Ames

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     How Computers Get Your (Clarified) Goat!
</A>
</H3>
<address>
Glen Matthews 
&lt;<A HREF="mailto:GLEN%MCGILL3.BITNET@CORNELLC.CCS.CORNELL.EDU">
GLEN%MCGILL3.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
Wed, 06 Apr 88 09:19:27 EST
</i><PRE>

The New York Times article reported by PGN on April 2 unfortunately has a
minor error of fact. The study referred to, which is incidentally in the
current issue of the Communications of the ACM, used the MUSIC/SP editor.
The author of the article apparently assumed that this was some sort of PC.
However, MUSIC/SP is an operating system that runs on IBM mainframes. (It is
developed by McGill and marketed by IBM.)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Philosophy and discrimination
</A>
</H3>
<address>
John Lavagnino
&lt;<A HREF="mailto:<LAV%BRANDEIS.BITNET@MITVMA.MIT.EDU> ">
&lt;LAV%BRANDEIS.BITNET@MITVMA.MIT.EDU&gt; 
</A>&gt;
</address>
<i>
Thu, 7 Apr 88 12:43 EST
</i><PRE>

David Thomasson's complaints of philosophical shoddiness in some recent
RISKS pieces on discrimination seem off the mark to me, perhaps owing to
the concerns of *my* field (literary criticism).  In all the instances I
recall, and particularly Les Earnest's, nobody was talking about the
question of what the ideal Motor Vehicle Bureau should ask you on their
application.  Les Earnest's was a *story* that told of becoming uneasy
about certain classifications in the light of substantial evidence of
their misuse.  Thomasson would have us ignore how information is used in
society, and once you do that then of course a discrimination's bad
effects will often disappear from view; you can pretend that a Southern
state, in the early 60s, would ask about your race merely because it's
useful for identification. Just because they can cite good reasons
doesn't mean their real reasons aren't bad.

I don't say that it's useless to discuss these questions without relating them
to real life.  But surely one theme of the RISKS list is that something which
looks fine in the lab can become quite different out in the field.

John Lavagnino, Department of English and American Literature, Brandeis Univ.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Comment on "Diving Risks"
</A>
</H3>
<address>
Phil Pfeiffer
&lt;<A HREF="mailto:pfeiffer@cs.wisc.edu ">
pfeiffer@cs.wisc.edu 
</A>&gt;
</address>
<i>
Tue, 5 Apr 88 15:59:16 CDT
</i><PRE>

&gt; Date: Wed, 30 Mar 88 10:12 CST
&gt; From: Joel Kirsh &lt;KIRSH@NUACC.ACNS.NWU.Edu&gt;
&gt; The user interface on the new diving computers is certainly critical, ...

Since the people at the shop where I buy my gear are not experts on
decompression theory, they were understandably reluctant to make specific
comments on this article, and did not want their names used.  But, it is their
understanding that many top-name manufacturers *are* using the new, improved,
safer data as the basis for their computerized decompression meters.  Since
this is comp.risks, and not rec.scuba, I don't think the subject to be worth
an "in-depth" treatment, but I would suggest that anyone concerned about
buying a particular manufacturer's meter simply give the manufacturer a call
and ask what tables are being used.  One thing worth saying is that a number
of different systems have been devised over the past fifteen years for
reducing the expected incidence of DCS to more acceptable levels than had been
observed with the old USN tables.

-- Phil Pfeiffer, (608) 262-6625
..!{harvard,ihnp4,seismo,topaz,akgua,allegra,usbvax}!cs.wisc.edu!pfeiffer

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: The risks of rumours
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 5 Apr 88 12:59:47 EDT
</i><PRE>

&gt; A colleague told me the other day that he'd heard that the Australian
&gt; Federal Police were going through the various Universities, armed with
&gt; a search warrant, looking for pirated software on PC hard disks...

A similar rumor has been making the rounds of the Ontario universities
lately.  It too appears to have been without foundation in fact, but it
did make a lot of people nervous for a little while.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

    ALSO From: Ken  De Cruyenaere &lt;KDC%UOFMCC.BITNET@CORNELLC.CCS.CORNELL.EDU&gt;,
    University of Manitoba   Winnipeg 

    ("The R.C.M.P. have raided several eastern universities in search of
    pirated software ") The rumors have proven to be just that, rumors, with
    no basis in fact.  There are rumors that people were scrambling to remove
    software and equipment in advance of the impending "raids".

        [Sounds a little like April Fool's leftovers.  PGN]

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Re: High Tech Trucking
</A>
</H3>
<address>
George michaelson
&lt;<A HREF="mailto:munnari!ditmela.oz.au!george@uunet.UU.NET ">
munnari!ditmela.oz.au!george@uunet.UU.NET 
</A>&gt;
</address>
<i>
4 Apr 88 23:01:15 GMT
</i><PRE>
Organization: CSIRO Division of Information Technology

in article &lt;12386323646.17.NEUMANN@KL.SRI.COM&gt;, mcvax!geocub!anthes@uunet.UU.NET (Franklin Anthes) says:
&gt; 
&gt;  Over here in France a black-box system has existed for quite a while now.
&gt; It isn't a computer, and its output goes to a paper disk, so it probably
&gt; can be tampered with.

The Tachometer is used all over Europe, I assume because of an EC (euopean
community) law which each member state then ratified.

In the UK where laws have been passed restricting the number of hours 
of continuous driving AND the total in any 24 hr period, Inspectors 
(and police) can ask to see the disk, and the device (according to truck 
drivers I've hitched with) is frequently cited in accident/insurance claims.

This implies it's speed/time/distance logging is accurate enough to satisfy
the legal process, If a tacho says your exceeded the speed limit and it's 
working OK you can be had up for it.

Also fitted to public transport vehicles. Not just Long distance Trucks 
but also small haulage vans must be so fitted.

PS the output is displayed on the Drivers dashboard so (s)he can decide
how to spread the working hours over the day, or pull over if a time limit
is exceeded. I always thought a 'black box' was a passive data capture unit
sealed away out of sight. 

-someone in the UK can comment on how it's changed accident statistics since
being introduced. At the time there were the usual -public-freedoms-are
-being-assaulted claims mostly be haulage bosses who had to spend cash
retro-fitting the things into wagons. 

surely the simpler the o/p device (eg direct to paper) the happier one
is with the result? OK there are limiting factors of complexity at play
here, but in the context of COMPUTER failure I'd rather have a chart
logger there any day!

	George Michaelson

55 Barry St, Carlton, Vic 3053, Phone:	(03) 347 8644 			

</PRE>
<HR><H3><A NAME="subj11.2">
Re: High Tech Trucking (<A HREF="/Risks/6.51.html">RISKS-6.51</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ames!ihnp4!ihlpl!jhh@ucbvax.Berkeley.EDU">
ames!ihnp4!ihlpl!jhh@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Tue, 5 Apr 88 09:04:17 PDT
</i><PRE>

A friend of mine used to be a trucker.  The solution used to avoid recording
of excessive travel and speeds was to pull the fuse powering the device.  I
doubt that a tamperproof device has yet been made.
                                                          John Haller

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Block mode terminals
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@research.att.com">
smb@research.att.com
</A>&gt;
</address>
<i>
Wed, 6 Apr 88 11:18:25 EDT
</i><PRE>

Many HP terminals have block mode, in assorted variant forms.  I was mildly
bitten by one such terminal last week.  On this one (a 2621), one can
enable block mode, in which case the terminal doesn't send any data
to the machine until you hit RETURN.  When you do, it moves the cursor
to the beginning of the line, then moves it along the line as it sends
each character, finally sending (and executing) a RETURN at the end of
the line.  Furthermore, the terminal is smart enough that it knows where
you started typing on the line; hence a prompt won't be transmitted back
to the machine.  The intended purpose of this whole feature is to allow
local editing (i.e., insert/delete character), even on machines that don't
have any software support for it.  I don't recall if the 2621 allows the
host to initiate transmission, but some other HP terminals (such as the
2645) definitely do.

What was the glitch?  Well, unknown to me, the terminal was in block mode.
Because it's smart enough to cope with the host echoing characters (this
was a UNIX(r) system), I never noticed it.  Then I had to enter a password;
to my great surprise, the password was being displayed as I typed it...

Steve Bellovin      	ulyssesf!smb		smb@ulysses.att.com

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.56.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.58.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-6</DOCNO>
<DOCOLDNO>IA012-000129-B044-296</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.58.html 128.240.150.127 19970217020548 text/html 28216
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:04:13 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 58</TITLE>
<LINK REL="Prev" HREF="/Risks/6.57.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.59.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.57.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.59.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 58</H1>
<H2>  Monday 11 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computers are a drain on police cruisers 
</A>
<DD>
<A HREF="#subj1.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  What happened to personal responsibility? 
</A>
<DD>
<A HREF="#subj2.1">
George Michaelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Intolerant Fault-Tolerance 
</A>
<DD>
<A HREF="#subj3.1">
Tom Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Another Security Clearance Story 
</A>
<DD>
<A HREF="#subj4.1">
Ronald J Wanttaja
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A new VMS security hole? 
</A>
<DD>
<A HREF="#subj5.1">
Jonathan Corbet
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Notifying users of security problems 
</A>
<DD>
<A HREF="#subj6.1">
John O. Rutemiller
</A><br>
<A HREF="#subj6.2">
 William Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  April Fool's Warning 
</A>
<DD>
<A HREF="#subj7.1">
Piet Beertema
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Viruses 
</A>
<DD>
<A HREF="#subj8.1">
Fred Cohen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Virus Distribution 
</A>
<DD>
<A HREF="#subj9.1">
Peter G. Rose
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: The "(c) Brain" virus is not a new virus.  
</A>
<DD>
<A HREF="#subj10.1">
Rob Elkins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  There is a VT220 with block mode available from DEC.  
</A>
<DD>
<A HREF="#subj11.1">
David E A Wilson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Enfranchising the disenfranchised: our responsibility? 
</A>
<DD>
<A HREF="#subj12.1">
Tom Betz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj13">
  Discrimination and careless arguments 
</A>
<DD>
<A HREF="#subj13.1">
David Thomasson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computers are a drain on police cruisers
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Sun, 10 Apr 88 16:26:24 EDT
</i><PRE>

Abridged from an article by Jack Lakey in the Toronto Star, April 9, 1988.

Booster cables are fast becoming the Metro[politan Toronto] police officer's
best friend.

Deputy Chief Bill McCormack says the force is having problems with batteries
dying in some police cruisers equipped with both computers and radios.
However, McCormack denied that the dead batteries are compromising the ability
of the force ... to respond quickly to emergencies.  "We always have cars
available on an emergency basis...  But I quite agree that it's a problem and
some of the equipment we have in place is the cause of it."

The computer and radio draw power from the battery when the cruiser isn't
running. ...  At the scene of a murder ... last Sunday, a Star reporter watched
as two cruisers -- both Plymouth Caravelles -- needed boosts from other police
vehicles to get started.  An officer driving the second vehicle said many
cruisers equipped with radios and computers were having similar problems. ...
the force uses heavy-duty batteries in the cars.  Two suspects in the murder
were arrested ... another Star reporter watched police boosting a third cruiser
that wouldn't start.

Police have noticed the problem is most common to a particular year and model,
but McCormack didn't want to identify the manufacturer.  "We're going to be
consulting with the manufacturer on finding a way to upgrade the power to the
battery ... But we are finding that it happens with the older cars or spares."
Allan Gibb, fleet administrator for the ... Metro police, said the power drain
was an "operational problem" common to any vehicle heavily equipped with
electronics.  However, police departments in Winnipeg and Calgary, where most
cruisers are equipped with computers, said they haven't had any problems
maintaining battery power.

Abridged and posted by Mark Brader

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
What happened to personal responsibility?
</A>
</H3>
<address>
&lt;<A HREF="mailto:munnari!ditmela.oz.au!george@uunet.UU.NET">
munnari!ditmela.oz.au!george@uunet.UU.NET
</A>&gt;
</address>
<i>
09 Apr 88 12:20:35 +1000 (Sat)
</i><PRE>

I've just finished re-reading L.T.C Rolts classic 'Red For Danger'
which is an updated version of the book, with new text by G Kichenside.
-alas Rolt died in 1974 and this edition was published by PAN in 1986.

This book should be required reading for all COMP.RISK-ers.
Technology *always* brings problems of "risks", and how we dealt
with those faced yesterday lends weight to how we could/should 
approach similar problems today. 

Reading the book I was struck by how often Rolt said (obvious BNF paraphrase):

     "...at the board of enquiry the {&lt;driver&gt;|&lt;guard&gt;|&lt;signalman&gt;|&lt;other&gt;}
      was rightly found innocent of the charge of manslaughter due to
      {&lt;extenuating circumstances&gt;|&lt;genuine act-of-god&gt;} ..."

Rolt also highlights the problems the Inspectorate faced persuading
Railway Companies to adopt basic working practice, or upgrade equipment 
to be in line with current practice. Then as now there was an ongoing
design cycle, existing systems were being kludged to work under increasing
loads and beyond design parameters.

	(1) even though "hardware" failed in many cases, a bolt sheared,
	    a retaining wall collapsed, a signal was not visible SOMEONE
	    stands up and says "yes, it was my responsibility". They could
	    be "let off" but it wasn't possible to say "the machine was
	    to blame".

	(2) *when* hardware failed, "rules" were changed to reflect
	    experience, designs re-worked, fail-safe factors increased.
	    the problem was getting $-obsessed people to become accountable 
	    for the consequences of $-based decisions.

	(3) "software" (I think the rules governing single-track usage
	    and point-settings and even how to behave when a train stops
	    in an emergency can be described as programs can't they?) was
	    very often to blame, but usually the problem lay with human
	    "interpretation" of the rules, or conflict in their application.

Railways are among the most public users of computer-based systems
we have. To sit in a 30mph steam train was not only a joy, you placed
your life in the hands of engineers who were ultimately accountable. To
sit in a 125mph bullet train or a high-speed local subway is no longer
quite so joyful. You *still* place you life in the hands of the company,
but is it the Engineers, software or otherwise that carry the can?

	-George Michaelson

ACSnet:	G.Michaelson@ditmela.oz.au	
Postal:	CSIRO, 55 Barry St, Carlton, Vic 3053
Phone:	(03) 347 8644 				Fax:	(03) 347 8987

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Intolerant Fault-Tolerance
</A>
</H3>
<address>
&lt;<A HREF="mailto:Tom.Lane@ZOG.CS.CMU.EDU">
Tom.Lane@ZOG.CS.CMU.EDU
</A>&gt;
</address>
<i>
Sat, 09 Apr 88 19:26:19 EDT
</i><PRE>

Here's another "amen" to Tim Mann's and Jerome Saltzer's comments about
reporting faults masked by fault-tolerant systems (RISKS 6.53, 6.54).
I have another example to add to the list.

  For the past several weeks, considerable net bandwidth in Usenet newsgroup
comp.sys.hp has been devoted to discussion of a posted set of benchmark
numbers, which allegedly demonstrated that a certain new HP machine was not 3x
faster than its predecessor (as claimed by HP), but actually more like 15x
slower.  Other people were unable to duplicate the original poster's results.
It eventually emerged that the machine he tested had a bad floating-point
processor.  The operating system detected this at bootup and *silently*
installed software emulation traps for all the floating-point instructions...

                 				tom lane
BITNET: tgl%zog.cs.cmu.edu@cmuccvma
UUCP: &lt;your favorite internet/arpanet gateway&gt;!zog.cs.cmu.edu!tgl

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Another Security Clearance Story 
</A>
</H3>
<address>
Ronald J Wanttaja
&lt;<A HREF="mailto:ames!uw-beaver!ssc-vax!wanttaja@ucbvax.Berkeley.EDU ">
ames!uw-beaver!ssc-vax!wanttaja@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Thu, 7 Apr 88 23:10:30 pst
</i><PRE>

It's one thing to be truthful on a background questionare for a security
clearance.  It's entirely *another* thing when nothing in the chain...
human or computer... actually LOOKS at the data input!

This I'm afraid, is one of those "friend of a friend" stories you hear in
the high-security world.  But it certainly seems possible.

A person was filling out the background investigation form for a clearance,
when he came upon the question,

"Have you or any member of your family ever attempted to 
overthrow of the government of the United States?"

The guy thought about it for a while.  Then answered 'yes.'

Months went by.  His questionaire routinely traveled up the chain.
Finally, someone noticed his response to that question.  Down came the
FBI, hauling our hero off to one of those high security interview rooms:

"Why did you answer yes to that question?"
"Because it's true."
The Feds leaned closer and invited him to explain.

"It's true.  My Great-great grandpappy fought for the South during the War
Between the States"  (Civil War to you Yankees)

They changed the question to read "Have you or any member of your IMMEDIATE
family..."

                        	  Ron Wanttaja

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
A new VMS security hole?
</A>
</H3>
<address>
Jonathan Corbet
&lt;<A HREF="mailto:gaia!jon@husc6.harvard.edu ">
gaia!jon@husc6.harvard.edu 
</A>&gt;
</address>
<i>
9 Apr 88 17:25:40 MST (Sat)
</i><PRE>

It was interesting to read Andy Goldstein's remarks on DEC's new policy on
security patches.  Such a policy was certainly needed after the delays
associated with the SECURESHR problem last fall.

What made it more interesting, though, was the arrival, via Federal Express, of
another one of those urgent-install-it-right-now patches from DEC yesterday
morning.  Yes, it is another security patch, but this time, nobody seems to
have heard about the hole yet.  It looks to me like DEC is living up to its
word on this one.  Good news.

But, now that the cat is out of the bag, does anybody out there know what the
situation is?  This patch contains about 1200 blocks of stuff -- lots of fixes!

Jonathan Corbet
National Center for Atmospheric Research, Field Observing Facility

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Re: Notifying users of security problems
</A>
</H3>
<address>
"John O. Rutemiller" 
&lt;<A HREF="mailto:Rutemiller@DOCKMASTER.ARPA">
Rutemiller@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 8 Apr 88 10:43 EDT
</i><PRE>

I believe the procedure outlined by Andy Golstein in RISKS 6.54 is a sound way
to manage the problem, with acceptable compromises.  Eric Postpischil's work
arounds in RISKS 6.56 fail to take a couple of points into consideration.

&gt; Almost every site has a big red button (or equivalent) that will make
&gt; any computer system secure, and a very few sites might have information
&gt; sensitive enough to warrant the button's use.

This big red botton may do wonders in keeping intruders out of the system, but
it also prevents users who NEED to do work from accessing the system.  Also,
your reasoning seems to indicate that the system should stay in this state
until the security flaw is fixed.  How long will that be?  Can your site stand
to be down for one month or maybe longer?

&gt; For another few sites, the VMS software might be only a portion of
&gt; their computing resources, a portion they can do without or with
&gt; limited use for a period.

Emphasize the word FEW.

&gt; Many sites can restrict accounts, temporarily removing general
&gt; accounts.

Removing general accounts (the existence of which has its own problems)
does not prevent attacks from those with valid accounts.

&gt; And other sites may be satisfied with establishing some sort of
&gt; auditing procedures so they can tell who is being naughty and stop it
&gt; if not prevent it beforehand.

If you simply announce that a flaw exists without a fix, the most
auditing will tell you is that you have just been had. :-)

John Rutemiller

</PRE>
<HR><H3><A NAME="subj6.2">
Re: notifying users of security bugs 
</A>
</H3>
<address>
William Smith
&lt;<A HREF="mailto:wsmith@m.cs.uiuc.edu ">
wsmith@m.cs.uiuc.edu 
</A>&gt;
</address>
<i>
Fri, 8 Apr 88 15:24:23 cdt
</i><PRE>

  &gt;From: goldstein%star.DEC@decwrl.dec.com (Andy Goldstein)
  &gt;Subject: Re: Notifying users of security problems

  &gt;So we get to the critical distinction between security bugs and
  &gt;others: Because invocation of a security bug requires a deliberate,
  &gt;unusual action, a security bug is only harmful to an installation when
  &gt;malicious users gain knowledge of the bug. 

This is patently false.  If my Unix kernel has a security bug that let anyone
delete a file owned by root, and I *accidentally* (not maliciously) type rm *
while I am accidentally in /, I will have invoked the security bug and force
the sysadmin to reload the system.  Or, if I misspell a command and execute a
different command that causes the system to crash, the security bug is still
harmful, but I am am not malicious.

You need to protect the system from inadvertant misuse by normal users as much
as you need to protect it from malicious users.  Each system adminstrator
should have the right to decide which set of users is more prevalant at his or
her site and act accordingly.  Some sites require their administrators to be
paranoid as you are suggesting.  Other sites can fire or remove the accounts of
malicious users and do not need to be paranoid.  A simplistic model of the risk
of system security bugs says that (bug + malicious-user) =&gt; danger.  A more
accurate analysis would also say that (bug + hapless-user) =&gt; danger.  How
likely a user might stumble over the bug is also a factor.  To fix an obscure
bug may not be worth the risk of breaking the operating system when the fix is
installed.

Bill Smith     pur-ee!uiucdcs!wsmith    wsmith@a.cs.uiuc.edu

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Viruses
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
10 Apr 88 18:47:13 EDT (Sun)
</i><PRE>
From: fc@ucqais.uc.edu (Fred Cohen)

For details on theory of computer viruses, call Fred Cohen (513)475-6575

We can detect all viruses, but cannot decide whether or not a program is
infected. That is, if we detect all files as suspects of containing viruses,
we catch all viruses. Whether or not a program contains a virus is undecidable
(i.e., we cannot write a program that determines whether or not another program
contains a virus correctly and in finite time in all cases). I suspect that
the Israeli defense is useless against most of the viruses we have done
experiments on - I wish I was on the attacker's side of that bet!!! - FC

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
April Fool's Warning (Re: <A HREF="/Risks/6.55.html">RISKS-6.55</A>)   [The last word was the first!]
</A>
</H3>
<address>
Piet Beertema
&lt;<A HREF="mailto:mcvax!cwi.nl!piet@uunet.UU.NET ">
mcvax!cwi.nl!piet@uunet.UU.NET 
</A>&gt;
</address>
<i>
Mon, 11 Apr 88 16:28:13 +0200
</i><PRE>

	&gt;Subject: April Fool's warning from Usenet
	&gt;From: spaf@cs.purdue.EDU (Gene Spafford)
	&gt;      ==================================
	&gt;Date: 1 Apr 88 00:00:00 GMT
	       ^^^^^^^^^^^^^^^^^^^^^

          [Piet points out that the key line that I inadvertently deleted
          -- and already noted so doing -- was the path:]

... which contained ...!kremvax!perdue!spaf 
(kremvax was one of the sites warned for!).

    [Piet of course is famous as the perpetrator of the Chernenko hoax four
    years ago.  That was the Ur-hoax and deserves many kudos.  RISKS has
    received quite a few queries from neophytes who were not around on 1 April
    1984.  They may find the message "from" mcvax!moskvax!kremvax!Chernenko and
    the delightfully annotated ensuing responses in their entirety -- including
    all of the header stuff! -- in ACM SIGSOFT Software Engineering Notes vol 9
    no 4, July 1984, pp. 6-8.  Or ask Piet if he still has it on line.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Virus Distribution
</A>
</H3>
<address>
&lt;<A HREF="mailto:EAE114%URIMVS.BITNET@MITVMA.MIT.EDU">
EAE114%URIMVS.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 11 Apr 88 19:27 EDT
</i><PRE>

Will Martin's fears about a possible Virus in a 'computer Interview' seem a
little overblown to me.  In the first place, putting your address on your virus
sounds like a good idea to get yourself in serious trouble. (How hard/easy is
it to trace someone through a mailing address?  Does the Postal service have
ANY verification?)  Anyway, if your really concerned about a diskette, just
park the head on your hard-disk, or pull its cable, or whatever, and run the
diskette in isolation.  Then just be sure to power-down before you do anything
else.

I've heard rumors that the Macintosh OFF switch only pretends to power down, so
maybe this won't work.  Is this true?  If so, why does apple do that?

Peter G. Rose

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: The "(c) Brain" virus is not a new virus.  (<A HREF="/Risks/6.55.html">RISKS-6.55</A>)
</A>
</H3>
<address>
Rob Elkins 
&lt;<A HREF="mailto:relkins@vax1.acs.udel.edu">
relkins@vax1.acs.udel.edu
</A>&gt;
</address>
<i>
11 Apr 88 14:42:47 GMT
</i><PRE>

  &gt;It is a basically harmless virus which first emerged ...

That may not be exactly true.  From reading RISKS extensivly, it seems to me
that the command.com virus may not be harmless.  It may have "evolved" since
its discovery into something more harmful, and I remember reading that it had
sort of date trap set for Friday the 13th.  It is still in your best interest
to copy the data on any infected disks onto fresh disks and reformat the 
infected disks.

Rob Elkins

BITNET: FFO04688@UDACSVM   UUCP: ...!sun!vax1.acs.udel.edu

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
There is a VT220 with block mode available from DEC. (Re: <A HREF="/Risks/6.52.html">RISKS-6.52</A>)
</A>
</H3>
<address>
David E A Wilson
&lt;<A HREF="mailto:munnari!uowcsa.oz.au!david%uowcsa.cs.uow.oz.OZ@uunet.UU.NET ">
munnari!uowcsa.oz.au!david%uowcsa.cs.uow.oz.OZ@uunet.UU.NET 
</A>&gt;
</address>
<i>
11 Apr 88 05:44:39 GMT
</i><PRE>
Organization: Uni of Wollongong, NSW, Australia

	Jerry Leichter is not quite correct in saying that NO VT220 made
by DEC has BLOCK mode. In Australia, DEC modified the standard VT220 to
create a VT220-Z (VT220 + VT131/2 block mode) as a special for the
New South Wales Department of Health. They then also made it available
to anyone else who wanted to buy it. Whether or not this has the security
hazard described in RISKS 6.51 I cannot tell as I no longer work for the
NSW Dept of Health.

David E.A. Wilson		ACSnet:	david@uowcsa.oz
Dept. of Computing Science	UUCP:	...!munnari!uowcsa.oz!david
Uni. of Wollongong		ARPA:	david%uowcsa.oz@uunet.UU.NET

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Enfranchising the disenfranchised: our responsibility?
</A>
</H3>
<address>
Tom Betz
&lt;<A HREF="mailto:cmcl2!phri!dasys1!tbetz@rutgers.edu ">
cmcl2!phri!dasys1!tbetz@rutgers.edu 
</A>&gt;
</address>
<i>
2 Apr 88 10:47:02 GMT
</i><PRE>

Kim Greer writes:

  &gt; ... if someone does not like the state they are in they should do
  &gt; something to change it.  

I would go so far as to say that there is nobody who can use a VCR who can
not use a computer for &gt;something&lt;.

  &gt; ... If someone is "disenfranchised" from using computers because they 
  &gt; can't read, let them learn how to read.

Unfortunately, much easier said than done.  Computers can, however, be a
useful tool for aiding the teaching of reading/writing.
     
  &gt;... But people are generally able to do anything they really want to...

     I know, through a skills training program for welfare mothers living in 
motels because they have no other home, of one woman who has managed to buy 
her kids an Adam, a C=64, and a TI-99A, all on a welfare budget.  This 
woman, though a part of the most disenfranchised classes in America today, 
has obtained (leaving aside for the moment the question of whether or not 
she uses them for this purpose) the tools to join into this peculiar 
Republic we here are a part of, using a very powerful lobbying tool to guide 
our elected officials.  Recent proof of the power of this medium is the 
defeat of the FCC's connect charge for computer systems.  

A question I would find most interesting to discuss here would be the 
question of this Republic within the Republic.  How are the lives of those 
who are too ill-educated to use these tools effectively going to be affected 
by the increased power of those of us who &gt;do&lt; use them?

Do we have a responsibility to do whatever we can to spread the power around
to these people? How can we do this?  How can our computers help us help them?

     Serious questions....

Tom Betz                        {allegra,philabs,cmcl2}!phri\
Big Electric Cat Public Unix           {bellcore,cmcl2}!cucard!dasys1!tbetz
New York, NY, USA                               {sun}!hoptoad/         

</PRE>
<A NAME="subj13"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj13.1">
     Discrimination and careless arguments
</A>
</H3>
<address>
        David Thomasson 
&lt;<A HREF="mailto:ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU">
ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 11 Apr 88 15:09:18 EDT
</i><PRE>

In an earlier note I pointed out what I take to be weak points in some recent
RISKS items about discrimination. Literary critic John Lavagnino replied that
my complaints are "off the mark." As irony would have it, Lavagnino's reply
further substantiates my precautions about shoddy arguments.

  &gt;In all the instances I recall, and particularly Les Earnest's,
  &gt;nobody was talking about the question of what the ideal Motor
  &gt;Vehicle Bureau should ask you on their application.

Nor was I. Explaining why he refused to reveal his race on a license
application, Earnest argued as follows (I paraphrase):  (1) Race has nothing
to do with driving a car. Therefore, (2) asking for an applicant's race isn't
justifiable. My point was not about ideal motor vehicle bureaus; it was about
logic: (2) doesn't follow from (1). The suppressed premise is: (1A) If X has
nothing to do with driving a car, then X cannot justifiably be put on a
license application. *If* once accepts that premise, then most of the
information on drivers licenses is unjustified:  name, address, color of eyes,
color of hair, etc. And this, of course, is patent silliness.

  &gt;Les Earnest's was a *story* that told of becoming uneasy about certain 
  &gt;classifications in the light of substantial evidence of their misuse.

No, Earnest did not give any evidence at all that racial information on
drivers license applications had been misued. He simply lumped this anecdote
in with others that did suggest such misuse.

  &gt;Thomasson would have us ignore how information is used in society, and once
  &gt;you do that then of course a discrimination's bad effects will often 
  &gt;disappear from view; you can pretend that a Southern state, in the early 
  &gt;60s, would ask about your race merely because it's useful for 
  &gt;identification. Just because they can cite good reasons doesn't mean their 
  &gt;real reasons aren't bad.

Rather than ignore such information, I would suggest that writers *present*
it. Here, Lavagnino confuses two separate actions:  gathering information, and
misusing information. Asking for race on a driver's license is, I suggest,
justified because it is useful in identifying the licensee. If the state then
uses that information for other (discriminatory) purposes, *that* action is
not justified and should be stopped. But one must not confuse the reasons that
justify including such information with its subsequent misuse. The state could
just as easily misuse information about one's address or age. It is this
*misuse* of information, and not the gathering of it, that is wrong. Careful
argument requires that such distinctions be made, especially on the overheated
hot topic of discrimination.

    [We are drafting in RISKS relevance, but this reply is still useful.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.57.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.59.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-7</DOCNO>
<DOCOLDNO>IA012-000129-B044-322</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.59.html 128.240.150.127 19970217020603 text/html 19461
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:04:29 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 59</TITLE>
<LINK REL="Prev" HREF="/Risks/6.58.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.60.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.58.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.60.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 59</H1>
<H2>  Tuesday 12 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Robot suicide 
</A>
<DD>
<A HREF="#subj1.1">
Tom Slone
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Computer Risks? UUCP map entries? 
</A>
<DD>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Comment on "Diving Risks" -- Fail Safe Design? 
</A>
<DD>
<A HREF="#subj3.1">
Mark W. Eichin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  ``How Computers Get Your Goat'' 
</A>
<DD>
<A HREF="#subj4.1">
Kevin B. Kenny
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Should You Trust Security Patches?  
</A>
<DD>
<A HREF="#subj5.1">
Steve Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Race? 
</A>
<DD>
<A HREF="#subj6.1">
John Macdonald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  A Cray-ving for RISK prevention 
</A>
<DD>
<A HREF="#subj7.1">
Matt Fichtenbaum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: What happened to personal responsibility? 
</A>
<DD>
<A HREF="#subj8.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Discrimination 
</A>
<DD>
<A HREF="#subj9.1">
John Lavagnino
</A><br>
<A HREF="#subj9.2">
 Darin McGrew
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Nonviral biological analogies -- a reference 
</A>
<DD>
<A HREF="#subj10.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  New constituency for RISKS (Soviets embrace UNIX)  
</A>
<DD>
<A HREF="#subj11.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Vendor speak with "functioned" tongue! 
</A>
<DD>
<A HREF="#subj12.1">
Chris McDonald
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Robot suicide
</A>
</H3>
<address>
Tom Slone
&lt;<A HREF="mailto:potency@violet.Berkeley.EDU ">
potency@violet.Berkeley.EDU 
</A>&gt;
</address>
<i>
Tue, 12 Apr 88 11:41:26 PDT
</i><PRE>

"A Budd Company assembly robot has apparently committed suicide.  The
robot was programmed to apply a complex bead of fluid adhesive, but the
robot 'ignored the glue, picked up a fistful of highly-active solvent,
and shot itself in its electronics-packed chest."
--Motor Trend, 11/86
                                    [Inspired by Budd's McFrenzy?  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Computer Risks? UUCP map entries?
</A>
</H3>
<address>
&lt;<A HREF="mailto:                                              [Anonymously Contributed]">
                                              [Anonymously Contributed]
</A>&gt;
</address>
<i>

</i><PRE>
Date: Sun Apr 10 13:34:33 1988

I was just going through the UUCP map entries, and noticed quite a few "home
systems" mentioned. Did it ever occur to these people that the UUCP map entries
make a great shopping list for burglars? "Lemme see now, IBM PC/AT, nahhhhhh, I
hates them segment registers, SUN 3/50, nah, m'az well steal a VT-100, ahhhhhh
SUN 3/280-LS/MFT, big disk, just what I need for doing the floor plan of First
Federal..." I just finished creating a map entry for my home system, and I
stopped to think, "would I put a sign on the front of my home saying I have a
few thousand dollars worth of computer equipment inside". I doubt it very much.
But people (me included, I guess!) routinely post map entries for the (netnews)
world. Am I being excessively paranoid, or is it a healthy mistrust of my
fellow creatures? I realize the possibility of a Bad Person using the maps for
"shopping" was probably unlikely a few (2? 3?) years ago, but with the
proliferation of netnews systems, especially "public" netnews systems, I'm sure
the probability went up.

   [Anonymouse traps waiting to spring?  No, this is just the old inference
   problem, which has been discussed here amply, and which is clearly
   exacerbated by the networking of databases.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Comment on "Diving Risks" -- Fail Safe Design?
</A>
</H3>
<address>
Mark W. Eichin 
&lt;<A HREF="mailto:eichin@ATHENA.MIT.EDU">
eichin@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 8 Apr 88 00:42:25 EST
</i><PRE>

Re: diving ascent computer: Does the version with a flashing LED as warning
ALSO have a test button (or some other test) to see if the LED has failed?
If not, divers could grow to trust it, then if (when!) the LED fails, they
would be in danger of accident...

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
``How Computers Get Your Goat'' (<A HREF="/Risks/6.54.html">RISKS-6.54</A>)
</A>
</H3>
<address>
Kevin B. Kenny
&lt;<A HREF="mailto:kenny@b.cs.uiuc.edu ">
kenny@b.cs.uiuc.edu 
</A>&gt;
</address>
<i>
Mon, 11 Apr 88 12:45:46 CST
</i><PRE>

  : ...  The researcher, Jan L. Guynes, used psychological tests to classify 86
  : volunteers as either Type A or Type B personalities...  She found that a 
  : slow unpredictable computer increased anxiety in both groups equally...

I read a study several years back which, while not classifying Type A vs. Type
B subjects, studied psychological response to response time.  The results of
the study were that the VARIANCE in the response time was significant; the
mean was much less so.  The conclusion could be that `unpredictable' is the
key word in the preceding paragraph.

See Harold Sackman, Man-Computer Problem Solving, Auerbach, Princeton NJ, 1970.

                                                 Kevin

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Should You Trust Security Patches?  (Re: <A HREF="/Risks/6.58.html">RISKS-6.58</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@research.att.com">
smb@research.att.com
</A>&gt;
</address>
<i>
Tue, 12 Apr 88 10:27:15 EDT
</i><PRE>

These wonderful new security patches that were sent out without
publicity -- how do you know the fix really came from DEC?

Just a thought to keep you really paranoid...
                                               	  --Steve Bellovin

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Race?  (Re: <A HREF="/Risks/6.55.html">RISKS-6.55</A>)
</A>
</H3>
<address>
John Macdonald
&lt;<A HREF="mailto:harvard!linus!utzoo!spectrix!John_M@rutgers.edu ">
harvard!linus!utzoo!spectrix!John_M@rutgers.edu 
</A>&gt;
</address>
<i>
Mon Apr 11 18:54:37 1988
</i><PRE>
Organization: Spectrix Microsystems Inc., Toronto, Ontario, Canada

I would have thought that the appropriate answer to the question "Race:" on a
driving license application would be "never" or "Formula One" or any similar
experience.  It is a quite reasonable question for them to be asking :-).

      [A grammatically correct answer to "Race?" would be "No (I don't)."  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
A Cray-ving for RISK prevention (Re: <A HREF="/Risks/6.55.html">RISKS-6.55</A>)
</A>
</H3>
<address>
Matt Fichtenbaum
&lt;<A HREF="mailto:mlf@genrad.com ">
mlf@genrad.com 
</A>&gt;
</address>
<i>
Mon, 11 Apr 88 09:14:30 edt
</i><PRE>

&gt;CRAY - A traditional Shinto ceremony was performed at Cray's systems check-out
&gt;building in Chippewa Falls to introduce a protective spirit into a new X-MP/24

Quite a feat of Cray, eh?

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: What happened to personal responsibility?
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 12 Apr 88 14:57:31 EDT
</i><PRE>

&gt; ... To sit in a 30mph steam train was not only a joy, you placed
&gt; your life in the hands of engineers who were ultimately accountable. To
&gt; sit in a 125mph bullet train or a high-speed local subway is no longer
&gt; quite so joyful. You *still* place you life in the hands of the company,
&gt; but is it the Engineers, software or otherwise that carry the can?

Why, nobody, of course.

If you want a good example of what I'm talking about, consider the Challenger
disaster.  I think there is little doubt that specific people could plausibly
be held responsible for it, although there might be some debate about exactly
who.  Now, look at the aftermath.  How many people have been arrested on
criminal charges as a result?  None.  How many people have been fired in
disgrace as a result?  None.  (A few have run into trouble for talking too
much about the incident, but not for causing it!)  How many companies have
been disbarred from government business as a result?  None.  What penalties
were assessed against Morton Thiokol?  Well, after a long debate it was
agreed that ten million dollars would be deducted from payments on their
SRB contracts.  (Note that (a) the replacement value of a shuttle orbiter
is approximately two *billion* dollars, (b) both NASA and its customers
have been hard-hit by the long hiatus in spaceflight and other side effects
of the disaster, (c) Morton Thiokol has received many millions of dollars in
fix-the-SRBs contracts, and (d) the issue of an alternate source for SRBs,
a major worry to M-T, has been postponed for some years.)

To avoid a repetition of the Challenger disaster, people need an incentive
to avoid one.  For the lawyers and MBAs who run most aerospace companies,
that means a financial incentive.  Only if technical disaster translates
into financial disaster will the bean-counters see to it that the whole
company has a firm commitment to avoiding it.  Only then will a "no" from
the engineers be backed up by the management, even if it hurts.  So how much
of a financial disaster has Morton Thiokol undergone?  None!

Look at the results, not the rhetoric.  Who was responsible for Challenger?

Nobody.

Henry Spencer @ U of Toronto Zoology {allegra,ihnp4,decvax,pyramid}!utzoo!henry

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Re: Discrimination and careless arguments
</A>
</H3>
<address>
John Lavagnino
&lt;<A HREF="mailto:<LAV%BRANDEIS.BITNET@MITVMA.MIT.EDU> ">
&lt;LAV%BRANDEIS.BITNET@MITVMA.MIT.EDU&gt; 
</A>&gt;
</address>
<i>
Tue, 12 Apr 88 11:46 EST
</i><PRE>

David Thomasson writes:

&gt; Lavagnino confuses two separate actions: gathering information,
&gt; and misusing information.

Can we believe in this separation after reading the accounts of actual
practice that appear in RISKS?  And can we believe in Thomasson's (unstated)
assumption that the various bureaus of our government have no connection with
each other?  I'm afraid I can't.  His analysis of Earnest's story reduces it
to a mere fallacy by throwing out all evidence of the meaning of race in that
place and time; that evidence he dismisses as just a bunch of anecdotes,
because he assumes there are no connections, but to me it's clear that it's
what leads to Earnest's reaction to the license application. Thomasson's
conclusion is further based on his (unstated) opinion that no objection to
governmental activities may be made without irrefutable evidence of
misbehavior -- which is a reasonable opinion, but it's an opinion all the
same, and there are others on the matter, such as Earnest's.

This method amounts to throwing out all the evidence and assuming that
you haven't thereby distorted the problem you set out to study; again,
think about that procedure from a RISKS point of view.

John Lavagnino, Department of English and American Literature, Brandeis Univ.

</PRE>
<HR><H3><A NAME="subj9.2">
Discrimination
</A>
</H3>
<address>
Darin McGrew
&lt;<A HREF="mailto:ibmuupa!mcgrew@ucbvax.Berkeley.EDU ">
ibmuupa!mcgrew@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Mon, 11 Apr 88 15:57:24 PST
</i><PRE>
Organization: IBM TCS Development, Palo Alto

In RISKS 6.55, David Thomasson &lt;ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU&gt; says:
&gt; If one thinks it is a simple matter of separating the "bad" kinds of
&gt; discrimination from the "good" (or "acceptable") kinds, try phrasing a
&gt; general principle that will make that distinction.

This is rather off the subject of computer risks, but it shows a related
problem.  "Bad discrimination" is that which is based on qualities that should
be irrelevant to the choice being made.  "Good discrimination" is that which
is based on qualities that are relevant.

The problem comes from the decision of what qualities are relevant to a given
decision.  When we disagree about the relevance of certain qualities, my right
to be considered apart from "irrelevant" qualities will conflict with your
right to consider all my "relevant" qualities.  Problems also arise when I
perceive that you considered irrelevant qualities when you didn't.

This problem shows up with computer systems when information is considered
relevant by one person, and not by another.  This causes people to ignore
warning indicators because they learn that the engineer considered a lot of
"irrelevant" information important.  It also causes hidden failures (eg, of
failsafe systems) because the engineer didn't consider something important to
be "relevant."

Darin McGrew		ucbvax!ibmuupa!mcgrew
I speak for myself, not for my employer.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Nonviral biological analogies -- a reference
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@ames-nas.arpa">
eugene@ames-nas.arpa
</A>&gt;
</address>
<i>
Fri, 8 Apr 88 21:51:44 PDT
</i><PRE>

Since we are talking about the biological analogy of computer viruses, I
would like to call attention to a book to further continue (non-viral)
biological analogies.  The author would like to get people thinking about them:

%A B. Huberman, ed.
%T Computational Ecologies
%I North-Holland
%D 1988

It does not deal with viruses per se, but does wish to consider distributed
systems in an ecological context.  
                                          --eugene miya

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
New constituency for RISKS (Soviets embrace UNIX) 
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Thu, 24 Mar 88 09:22:45 PST
</i><PRE>
Organization: University of Washington

&gt;From Electronic Engineering Times, March 7 1988

UNIX POPULARITY EXTENDS INTO USSR by Ray Weiss

Unix popularity is spreading.  It has even reached the Soviet Union, where
Unix classes will be held this summer.  

A series of one-week classes will be taught in English by instructors from
an American company, Lurnix.  The classes, to be held in Peraslava some 60
miles north of Moscow, will be open to both Soviets and foreigners.  In fact, 
Lurnix is setting up a tour for Americans that would like to combine
travel to the USSR with a study of the operating system.

One hangup is the current export policies.  They allow Unix object code to
be exported, but Unix source code is embargoed.  Without source code, Unix
cannot be easily adapted to different host computers or special peripherals.
Consequently, the classes will concentrate on Unix system administration and
programming under the Unix operating system. ...

The last project Lurnix worked on was a study that explored networking 
between grade schools and its effect on learning.  The study was funded
by the Carnegie Corp.

The new classes are part of an effort to establish Unix s a standard in 
the country's schools.

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Vendor speak with "functioned" tongue!
</A>
</H3>
<address>
Chris McDonald  STEWS-SD 678-2814 
&lt;<A HREF="mailto:cmcdonal@wsmr10.ARPA">
cmcdonal@wsmr10.ARPA
</A>&gt;
</address>
<i>
Tue, 12 Apr 88 15:30:47 MST
</i><PRE>

We recently received a quantity of Unisys terminals.  In the operator's manual
I was surprised to read the following on the subject of function keys.  You can
define the keys "to do such things as: Transmit a special password or
instruction to the host..."

I find it curious that a firm that has indicated its intention to build
"trusted systems" against the National Computer Security Center's Orange Book
criteria should use such an example.  

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.58.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.60.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-8</DOCNO>
<DOCOLDNO>IA012-000129-B044-341</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.60.html 128.240.150.127 19970217020617 text/html 27272
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:04:43 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 60</TITLE>
<LINK REL="Prev" HREF="/Risks/6.59.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.61.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.59.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.61.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 60</H1>
<H2>  Wednesday 13 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Quebec's Centralized Filing System 
</A>
<DD>
<A HREF="#subj1.1">
Glen Matthews
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  State taxes on a new computer system 
</A>
<DD>
<A HREF="#subj2.1">
Steven McBride
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Feynman &amp; the Challenger disaster 
</A>
<DD>
<A HREF="#subj3.1">
Wm. Randolph Franklin and Willie Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risks of computerized editing? 
</A>
<DD>
<A HREF="#subj4.1">
Haynes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  New risk to computer users identified -- VCRs 
</A>
<DD>
<A HREF="#subj5.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Pilotless Combat Planes 
</A>
<DD>
<A HREF="#subj6.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  April Fool once more 
</A>
<DD>
<A HREF="#subj7.1">
Piet Beertema
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Macintosh off switch 
</A>
<DD>
<A HREF="#subj8.1">
Mike Linnig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Diving 
</A>
<DD>
<A HREF="#subj9.1">
Rich Sands
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Discrimination and careless arguments 
</A>
<DD>
<A HREF="#subj10.1">
Les Earnest
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Discrimination -- unmuddling the muddlies 
</A>
<DD>
<A HREF="#subj11.1">
David Thomasson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  What was the question? (John 
</A>
<DD>
<A HREF="#subj12.1">
J.G.) Mainwaring
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
     Quebec's Centralized Filing System
</A>
</H3>
<address>
Glen Matthews 
&lt;<A HREF="mailto:GLEN%MCGILL3.BITNET@CORNELLC.CCS.CORNELL.EDU">
GLEN%MCGILL3.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
Wed, 13 Apr 88 10:34:39 EST
</i><PRE>

The following article appeared in the Montreal Gazette on Tueday, April 13
1988. In light of previous scandals about information being obtained about
individuals from government files for commercial purposes, I'd be leery of this
one. (Interesting that the law in 1984 giving citizens the right to know what
information is being held on them, also makes it easier to abuse the system.)

YOU'RE ON FILE: DIRECTORY TELLS WHERE TO CHECK by Nancy Wood

Quebecers should know that government departments and agencies have millions
of files (read: entries! gm) holding information about them, the Access to
Information Commission said yesterday. The commission was launching a 635-page
directory of 489 government databanks containing more than 20 million files.
The databanks, half of which are computerized, are held by 26 departments and
98 agencies. Another 25 agencies told the commission they had no files to
reveal (??? gm). The department of the solicitor-general refused to make public
provincial police files. The Tourism and Income Security departments also
refused to answer all the commission's questions.

Interim chairman Therese Giroux said these departments may face legal action if
they don't co-operate. "We think the time has come to be maybe a little more
radical", she said. There are still pockets of resistance to the law which, in
1984 (appropriately! gm), gave citizens the right to know what files are being
held on them.

The standard file on a Quebecer will contain: name, date of birth, sex, ethnic
origin, marital status, social insurance number, medicare number, hair colour,
eye colour, height and physical handicaps, certificates and diplomas received,
medical background, traffic violations, religious affiliation. In addition, the
government knows what kind of car you drive, how many Quebec Savings Bonds you
own, whether you have been treated for a tumor, whether you have had a fire,
and your standing as a Hydro-Quebec customer. There are 3.5 million files on
Quebecers who attended school in the province.

The point of the directory is to allow Quebecers easy access to a list of the
kinds of files kept so that they can ask to see their own files and correct any
inaccuracies. Giroux said it is every citizen's duty to know what kind of
information is held by the government, and those who feel concerned should
check their files. Communications Minister Richard French told reporters only a
small number of Quebecers will want to do so, but they should be free to do so.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
State taxes on a new computer system
</A>
</H3>
<address>
Steven McBride 
&lt;<A HREF="mailto:shamus@BOEING.COM">
shamus@BOEING.COM
</A>&gt;
</address>
<i>
Wed, 13 Apr 88 09:14:45 pdt
</i><PRE>

Paraphrasing from a 15 March article by Charles Trentelman
  in the Ogden Standard-Examiner.

Ira Menacker turned in his state income tax form expecting to receive a
$268 refund. Instead, he received a notice saying he and his wife owed
Utah $23,254,712.74 -- taxes of $20,769,223.02, plus interest of
$2,485,479.72, less credit of $268.

Lee Shaw, spokesman for the State Tax Commission said the state was using a new
computer system to process taxes and "a lot of things we are doing on our
income-tax system are being done for the first time."  The problem with the
Menacker return was caused by a "data entry error, an editing error compounded
by the fact that the system itself didn't kick that (the return) out on an
error code." Mr Shaw also said "a computer does not make a small error, a
computer will really make a glorious mistake."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
  Feynman &amp; the Challenger disaster
</A>
</H3>
<address>
wrf%juliet@CSV.RPI.EDU 
&lt;<A HREF="mailto:Wm. Randolph Franklin">
Wm. Randolph Franklin
</A>&gt;
</address>
<i>
13 Apr 88 10:14:28 EDT (Wed)
</i><PRE>

There is an excellent article on the investigation into the Challenger disaster
by Richard Feynman in the Feb Physics Today.  Given the picture of parts of
NASA he paints, it's a wonder anything flew.  However, he did praise the
subcontractors doing the computers - unlike at Morton Thiokol, the engineers
and the managers communicated.

    [Those of you who wish to and can FTP 34,000 characters, FTP KL,
    LOGIN anonymous, PASSWORD nonnull, CD STRIPE:&lt;RISKS&gt;, GET RISKS-6.FEYNMAN 
    ..., contributed earlier by Willie Smith.  I was hoping to do a summary of
    it, but at this rate may never get to it...  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Risks of computerized editing?
</A>
</H3>
<address>
99700000
&lt;<A HREF="mailto:haynes@ucscc.UCSC.EDU ">
haynes@ucscc.UCSC.EDU 
</A>&gt;
</address>
<i>
Wed, 13 Apr 88 15:23:06 PDT
</i><PRE>

I guess either Associated Press or the Santa Cruz Sentinel is using a computer
to eliminate sexist language from their news stories.  A story this morning
about a railroad accident said the train was being driven by the firefighter.
Took me a moment there to translate firefighter back to fireman, which doesn't
translate correctly to firefighter if you're talking about a locomotive.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
New risk to computer users identified -- VCRs
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.stanford.edu ">
chapman@csli.stanford.edu 
</A>&gt;
</address>
<i>
Wed, 13 Apr 88 09:15:28 PDT
</i><PRE>

Letitia Baldridge, manners maven, quoted in the April 13 issue of the San
Francisco Chronicle:

VCRs!  Manners are so bad because people look at computer screens all day
and VCRs all night. . . .You go to their homes as a guest, and you end up
asking:  Where are the hangers?  Where are the tissues?  Where are the guest
towels?  And where, where are those pretty little soaps?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Pilotless Combat Planes
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
13 Apr 88 12:38:47 PDT (Wednesday)
</i><PRE>

Edited and excerpted from the 'Los Angeles Times', Sunday, April 10, 1988, Part
I, page 1:

      IDEA OF PILOTLESS COMBAT PLANES IS TAKING OFF
             By Melissa Healy

DAYTON, Ohio - Capt. Gary G. Presuhn, an Air Force navigator who helps fly some
of the nation's hottest new jets off the desert runways of Edwards Air Force
Base, is sitting inside a simulated aircraft cockpit in a medical research
laboratory here, wearing a bizarre, bug-eyed helmet that makes him look like
Darth Vader and feel like Luke Skywalker [pictured].  Wires trail away from the
helmet to an electronic device that monitors his eye movements.  Presuhn, 33,
is peering into the future of aerial warfare.  And curiously, he's not in it.

If scientists, engineers and dreamers here at Wright-Patterson Air Force Base
can harness technology to their vision of the future, computers one day will do
all or most of what Presuhn does now, flying in the second seat of supersonic
military planes and providing crucial assistance to the pilot.  Eventually,
scientists hope, the same computers might even take over the duties of
Presuhn's partner, [the pilot].

Presuhn's high-tech helmet, a sort of wrap-around instrument panel that tells
its wearer everything from his plane's altitude to the approach of enemy
missiles, is concrete evidence that -- after years of resistance by tradition
-minded brass -- the American military is beginning to accept the idea of
replacing scarce and vulnerable men with thinking machines....

Smart machines hold enormous promise, experts say.  They will be able to do
many of the things humans now do, thereby helping the military cope with
expected shortages of trained personnel.  They will be able to do some things
no human could do, increasing the capability and punch of American forces.  And
they will permit U.S. commanders to order up valuable but -- for human pilots
-- suicidal battlefield assignments without concern for casualties....

The nation's military leaders and defense technologists have stepped up efforts
to move men out of the cockpits -- and out of danger -- and leave the driving
to machines....  [F]liers like Presuhn, who at age 33 belongs to the first
generation of the video era, are more philosophical [than, for example, the
Mercury astronauts] about their eventual replacement, this time by computer
software.  "My seat's disappearing anyway," Presuhn said.  "In my life, it's
not going away.  But eventually, I can see it's going to be gone."

.... Today, ... the forces that drive projects such as "Super Cockpit" --
including a budget-minded and casualty-sensitive Congress -- are beginning to
overwhelm many, if not all, of the traditional objections [to reducing the role
of men in military systems].  As a result, the Pentagon is forging ahead with
several unmanned aircraft projects and with research efforts that threaten to
make navigators and pilots dispensable....

"I see unmanned vehicles for many roles as a definite trend," Donald
Fredericksen, the Defense Department's tactical warfare chief, has told
Congress.  "The technology is there.  It's clear that we can use them for a lot
of missions that are too dangerous for men or too expensive to do with manned
aircraft."  The Defense Department is expected to pour some $6.5 billion into
designing and building pilotless aircraft by 1995, according to one industry
estimate.

[Discussion of the SCI "pilot's associate" project...]  Program officials speak
of designing a "phantom crew" to aid tomorrow's pilots.  One day, [researchers]
at Wright-Patterson envision a world of air combat in which a single pilot
aloft in his command plane will direct the attacks of an army of "robotic
wingmen," who know no fear and leave no widows.

[Discussion of the soon-to-be-deployed "Tacit Rainbow," a kamikaze drone, and
of Boeing's "Seek Spinner" and of the long history of Air Force resistance to
removing men from the cockpit....]

In some cases, the state of technology has made the move toward pilotless
aircraft not only possible but almost necessary.  Engineers are finding that
the greatest constraint to making tomorrow's fighter jets faster and more agile
is neither physics nor technology.  It is the ability of the man in the cockpit
to withstand the physical punishment of higher-performance flight.... In the
long run, some scientists believe pilots may become unjustified obstacles to
the progress of maneuverability.

For now, however, few believe that even Wright-Patterson's magic can replace
the judgment of a seasoned pilot when it comes to executing a last-minute
change of plan or escaping a cleverly-designed trap. "The pilot bring to the
system an adaptability, a skill and a cunning that we cannot reproduce with
machines," [Thomas A.] Furness [one of the lead engineers in the "Super
Cockpit" project in which Presuhn is a subject] said.  "I'm not saying the
pilot has to be in the airplane, but he has to be in the loop."

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
April Fool once more
</A>
</H3>
<address>
Piet Beertema 
&lt;<A HREF="mailto:mcvax!cwi.nl!piet@uunet.UU.NET">
mcvax!cwi.nl!piet@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 13 Apr 88 11:39:09 +0100
</i><PRE>

Oops, I was wrong, it wasn't "kremvax" that was in the Path: of
"Gene"'s April Fool warning message, but (a misspelling of) the
other site I invented. Here's the Path: as I got it here:

   Path: mcvax!uunet!seismo!sundc!pitstop!sun!moscvax!perdue!spaf
						 ^     ^
	Piet
                 [Piet's trick from 1984 was rigging the mailer tables
                 so that when you ANSWERed the Chernenko message, HE
                 got the reply.  This one was less subtle.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
RE: Macintosh off switch
</A>
</H3>
<address>
Mike Linnig 
&lt;<A HREF="mailto:LINNIG%eg.ti.com@RELAY.CS.NET">
LINNIG%eg.ti.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Wed, 13 Apr 88 18:10 CDT
</i><PRE>

&gt; From: EAE114%URIMVS.BITNET@MITVMA.MIT.EDU
&gt; Subject: Virus Distribution
&gt; I've heard rumors that the Macintosh OFF switch only pretends to power down, 
&gt; so maybe this won't work.  Is this true?  If so, why does apple do that?
&gt; Peter G. Rose

The Macintosh off switch certainly cuts power.  I've heard that the older
LISA computers had an auto-restart feature that allowed a program to set a
hardware widget to turn the LISA back on a a predetermined time.  I'd bet
though that memory was truely erased by the powerdown (but not the hard
disk!).
                     	Mike Linnig, Texas Instruments

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Diving
</A>
</H3>
<address>
Rich Sands
&lt;<A HREF="mailto:rms@gubba.SPDCC.COM ">
rms@gubba.SPDCC.COM 
</A>&gt;
</address>
<i>
13 Apr 88 14:01:52 GMT
</i><PRE>
Organization: Richard Sands, Brookline, MA.

Both the Orca EDGE and Skinny Dipper dive computers go through an extensive
self-test when turned on, including activating every possible message
display and indicator.  The instruction manuals tell you what the self-test
should look like, so you can verify that the displays are properly going
through their paces.  They also recalibrate themselves to the surface air
pressure every time they are powered on, and warn you if you are diving at
too high an altitude for their nitrogen absorption model to be accurate. The
liability issues in selling such a device are obvious, and Orca has really
done their homework, as far as I can see. If at any time you exceed the
computer's operating ranges, it really starts flashing warnings at you.

There are other computers on the market, but I have no direct experience
with them. The problems that RISKS readers are identifying may exist in
other products, I don't know.

rms                     Compuserve: 71360,1067	BIX: richsands 
UUCP: {ihnp4,harvard,husc6,linus,ima,bbn,m2c}!spdcc!gubba!rms

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Discrimination and careless arguments    
</A>
</H3>
<address>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</address>
<i>
13 Apr 88  1756 PDT
</i><PRE>

At the risk of going further afield from the purpose of Comp.risks, I wish
to prolong the discussion of "race."  In Vol. 6, #58, David Thomasson
seems to argue that I made careless arguments in the "mongrel" stories,
then he puts forth the following argument.
&gt; . . . Explaining why he refused to reveal his race on a license
&gt; application, Earnest argued as follows (I paraphrase):  (1) Race has
&gt; nothing to do with driving a car. Therefore, (2) asking for an applicant's
&gt; race isn't justifiable. My point was not about ideal motor vehicle
&gt; bureaus; it was about logic: (2) doesn't follow from (1). The suppressed
&gt; premise is: (1A) If X has nothing to do with driving a car, then X cannot
&gt; justifiably be put on a license application. *If* once accepts that
&gt; premise, then most of the information on drivers licenses is unjustified:
&gt; name, address, color of eyes, color of hair, etc. And this, of course, is
&gt; patent silliness.

Yes, that _is_ patent silliness.  The things that Mr. Thomasson lists at the
end are useful identification properties.  "Race" is not, unless you are a
racist.

Further on, Thomasson says:
&gt; Asking for race on a driver's license is, I suggest, justified because it
&gt; is useful in identifying the licensee.

Thomasson apparently believes that everyone belongs to some race and that
that race is determinable.  He probably also believes that all dogs belong
to some breed.  I would like to accompany him to a city pound somewhere and
listen to him identify all the mutts there.

In the 1960s, the Commonwealth of Virginia included in the category of
"Colored" everyone who they called Negro, Indian (both American and most
people from India), other dark-skinned groups, and anyone who was
detectably a mixture of any of these with some other "race."  Was this a
useful identification property?  I think not.

Color of skin and color of hair _are_ useful for identification and may
reasonably be included on a drivers license.  I know a lady with very dark
skin and bright orange hair.  What race would you say she belongs to?  I
saw a number of comely ladies in Amsterdam awhile back with pale skin and
bright green hair.  How should we classify them?

For that matter, if I claim that I am a Martian, can you prove I am wrong?
You probably don't even know what a Martian looks like.
                                                              Les Earnest

    [There is considerable redundancy among this and the following two
    messages, but I would rather not do burn any abridgements.  PGN]

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
     Discrimination -- unmuddling the muddlies
</A>
</H3>
<address>
        David Thomasson 
&lt;<A HREF="mailto:ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU">
ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 13 Apr 88 16:49:09 EDT
</i><PRE>

A brief attempt to clear up more muddled argument: Regarding my distinction
between *gathering* information (such as race on a driver's license) and
*misusing* such information, John Lavagnino writes:

&gt;Can we believe in this separation after reading the accounts of actual
&gt;practice that appear in RISKS?

I don't know whether you *can* believe in it, but you *should*, since
they are manifestly separate actions. One who gathers information about
race (or about anything else under the sun) ought not to be presumed
guilty of misusing it, since the misuse comes later if at all.

&gt;And can we believe in Thomasson's (unstated) assumption that the
&gt;various bureaus of our government have no connection with each other?

I didn't state this assumption because I never made it. If
a motor vehicles bureau gave its information to another bureau, this would
not be an obvious misuse of that information by either agency. In fact
there are practical reasons for government agencies
to share certain information (*if* both are justified in gathering it in
the first place). The alternative is for each agency to operate independently,
needlessly repeating the same information-gathering process -- the sort of
wastrel bureaucratic busywork that we so often complain about. Government
bureaus do and should have some connections. Evidently, Lavagnino sees
something heinous in this (as I do not) because he is unable to see that
gathering information is not the same thing as misusing it.

&gt;Thomasson's conclusion is further based on his (unstated) opinion that
&gt;no objection to governmental activities may be made without irrefutable
&gt;evidence of misbehavior -- which is a reasonable opinion, but it's an
&gt;opinion all the same, and there are others on the matter, such as
&gt;Earnest's. This method amounts to throwing out all the evidence and
&gt;assuming that you haven't thereby distorted the problem you set out to study.

Three points: (1) Again, I didn't state such an opinion, because I don't hold
it. (2) Note that Lavagnino's critical method leans heavily on attributing
positions to me that I neither stated nor implied, and then attacking those --
a classic Straw Man approach. (3) The view wrongly attributed to me is that we
should proceed by "throwing out all the evidence," etc. Lavagnino says that
this is "reasonable." I initially set out to show that arguments in RISKS
sometimes are terribly muddled. I rest my case.

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
 What was the question?
</A>
</H3>
<address>
John (J.G.) Mainwaring 
&lt;<A HREF="mailto:CRM312A%BNR.BITNET@CORNELLC.CCS.CORNELL.EDU">
CRM312A%BNR.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
13 Apr 88 16:59:00 EDT
</i><PRE>

It seems to me that most of the replies to Les Earnest on the race question on
forms miss the point entirely.  Of course he objects to the question as
irrelevant, but claims that an even bigger problem is being able to answer the
question at all, and cites the unverifiable possibility of middle eastern
ancestry in his own case.  This clearly casts doubt on the usefulness of the
race question for any purpose, not just its relevance to driving. It is an
uncertain identifying attribute, even though it often works.  Most people can
name a colour for their eyes which most other people will accept.  Hair colour
tends to be more vague, and not everyone chooses to keep the colour the same at
all times.  Race can be a highly unsatisfactory descriptive attribute.  At the
time of the story, in the 60's, most people assumed that anyone with any negro
ancestry should give their race as 'negro'.  This meant that by no means
everyone described as negro was immediately visually identifiable as such.
There have been people who claimed to be able to immediately recognize members
of the Jewish 'race' on sight, but at least that does not seem to have been
attempted with driving licences anywhere in the US.  As a side light, it is
interesting to note a sexist bias in racial prejudice.  If you believe an
attribute has negative connotations, you will believe it is inherited from
either the mother or the father.  If it is neutral or positive, it is assumed
to be inherited from the father alone (eg nationality on census forms).  The
risk inherent in this is the assumption that because a question can be
formulated, the answers will be of any value, especially when they come from a
broad spectrum of respondants.  It is closely related to the 'NO PLATE/NOPLATE'
item in recent issues of the RISKS forum, and is probably the root cause of my
own irrational reaction to forms created by bodies such as the IRS.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.59.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.61.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-9</DOCNO>
<DOCOLDNO>IA012-000129-B044-359</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.61.html 128.240.150.127 19970217020631 text/html 21278
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:04:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 61</TITLE>
<LINK REL="Prev" HREF="/Risks/6.60.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.62.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.60.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.62.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 61</H1>
<H2>  Thursday 14 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Obscure C contest gaffe 
</A>
<DD>
<A HREF="#subj1.1">
Matthew P Wiener
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of Lap-Tops in Exams 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Macintosh Power switch 
</A>
<DD>
<A HREF="#subj3.1">
Greeny
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Crimes of the Depressed 
</A>
<DD>
<A HREF="#subj4.1">
Vin McLellan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  More evidence for an old risk -- Enigma 
</A>
<DD>
<A HREF="#subj5.1">
Dave Mankins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Norwegian embezzlement 
</A>
<DD>
<A HREF="#subj6.1">
Eirik Kim Pedersen via David Edwards
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Race, identification, and muddly thinking 
</A>
<DD>
<A HREF="#subj7.1">
David Thomasson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  "Race" as ID 
</A>
<DD>
<A HREF="#subj8.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: File "RISKS-6.FEYNMAN" -- and a ghost story 
</A>
<DD>
<A HREF="#subj9.1">
Jerry Leichter
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Obscure C contest gaffe
</A>
</H3>
<address>
Matthew P Wiener
&lt;<A HREF="mailto:weemba%garnet.Berkeley.EDU@violet.berkeley.edu ">
weemba%garnet.Berkeley.EDU@violet.berkeley.edu 
</A>&gt;
</address>
<i>
Sun, 20 Mar 88 20:16:47 pst
</i><PRE>

The obscure C contest, whose past winners were recently distributed on
comp.sources.unix, had a curious gaffe.  The programs were named after the
winners, and the Makefiles produced similarly named binaries.  The user's
mindset is to puzzle with the programs to figure out what they're doing.
The documentation is deliberately cryptic, and all unusual behavior is
considered par for the course.

So guess what happens when Larry Wall is a winner?

I tried out "wall" as indicated, and got all my input echoed back
in a broadcast message, and error messages about various ttys being
unwriteable.  Hmm, thinks I, what's Larry up to this time?  I try
some more input, and get this same stupid echo and error messages.
Hmm, thinks I, maybe running it in Emacs isn't a good idea.  Etc.

So I ended up annoying a dozen people for a minute before I noticed
the discrepancy between the documentation's references to "lwall" and
the Makefile's references to "wall".  Oops, thinks I.  "wall" is the
standard UNIX facility for writing a message to all users.

For an amusing variant of this, consider the possible reactions among
some users were his name Larry Rogue.  ("Gosh, 1000 bytes and it plays
a full game of rogue!  How does he doooo that?")

And while I'm at it, let me predict that within a year or two, a
fiendishly obscure virus is going to be among the winners.

ucbvax!garnet!weemba	Matthew P Wiener/Brahms Gang/Berkeley CA 94720

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of Lap-Tops in Exams
</A>
</H3>
<address>
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Thu, 14 Apr 88 08:51:24 -0800
</i><PRE>

Harvard Business School faculty member Mark Albion has confirmed that
students can take their finals on blue books or they can use lap-top
computers.  There are potential problems with taking an exam using a lap-top
computer.  Some of the exams last up to four hours, presenting the risk that
a computer's batteries will die during the test.  And Albion said that on at
least one occasion, a computer glitch erased a student's whole exam.
[From Bob Greene's column in the San Francisco Chronicle, 13 April 1988]

A usually reliable source suspects that the students get blank disks from the
professor, so they can't be tempted to bring in a disk with lot of information
on it! But what about storing your course notes?  What about modems linking
students to one another for interactive collusions?  What about Trojan horsing
the competition?  What about planting a Trojan horse on the diskette so that
when the professor tries to load it, HIS memory is contaminated -- e.g., with
a program to change the grade database?  The fertile minds of students can
undoubtably come up with other exciting scenarios.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
  Re: Macintosh Power switch
</A>
</H3>
<address>
GREENY 
&lt;<A HREF="mailto:MISS026%ECNCDC.BITNET@CORNELLC.CCS.CORNELL.EDU">
MISS026%ECNCDC.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
Wed 13 Apr 1988 21:22 CDT
</i><PRE>

&gt;...Ive heard that the macintosh power switch really doesnt turn off the power

This is correct but only with respect to the MAC ii and the Lisa....
on both of these machines, when one turns off the power, the machine transfers
control to a SHUTDOWN MANAGER which then takes care of powering down the
hard drives, and what not....to turn on the machine one simply presses the
power switch again.  *OR* in the case of the Mac II one can simply select
SHUTDOWN from the Special menu and the machine will shutoff on its own --
to reactivate the machine, one hits the RESET key on the keyboard.

When shutdown is selected on an SE or a Plus or whatnot, the SHUTDOWN
MANAGER simply displays a message saying (basically) "its ok to shut
off your mac now..." and does nothing else....you have to take care of
powering down your hard drive, etc...

hope this helps....for more info on this see Inside Macintosh vol. V (I
think....) available from Addison-Wesley
                                                  Greeny

Bitnet:MISS026@ECNCDC
Disclaimer: If it's really me on this account, then I might be responsible,
            but if it's not, then who can you blame?

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Crimes of the Depressed
</A>
</H3>
<address>
"Vin McLellan" 
&lt;<A HREF="mailto:SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu 14 Apr 88 04:43:46-EDT
</i><PRE>

   The April 18th issue of Business Week had an interesting aside in a major
story on "Stress: The Test Americans Are Failing," a general round up on the
impact of layoffs, mergers, and technological changes, particularly in
middle management. With automation already undermining job security,
particularly among middle managers, post-Crash budget cuts have led to to
widespread layoffs among white collar professionals. All of this
excacerbates the long-term trend of middle managers coming to the conclusion
that their corporate "parent" is quite willing to betray them, to sacrifice
them as a budgetary footnote, and thus doesn't deserve loyalty... perhaps
not even honesty.

   The Wall Street culture displays new and growing problems in alcohol use,
fear, anxiety, and poor morale among employees and executives. Reports the
Business Week research team: "Often employees who lose their jobs react with
furious anger. 'In the extreme, they shoot somebody,' says (grad school prof
Robert Dewar.) Acts of sabotage, particularly of records and computer
data,are common. Human resource executives at half a dozen big companies
privately admit to destructive outbursts by laid-off managers."
  
  Donn Parker of SRI used to talk a lot about corporations never realizing
how much trust they had invested in employees with EDP access, authority,
and responsiblity. It sounds like some, just because they've acted with the
callous capitalism we expect of MBA-trained managers, are learning the hard
way. These corporate rebellions seem to be seldom reported -- except when a
broker shoots his former boss, as happened last week here in Boston -- but
there is an sad saga of RISKS unfolding out there. Where does it impact
security budgets? Perhaps in demand for post-password access systems, tokens
and biometrics. What executive (what employee for that matter) can't learn a
few other employees' passwords in any given week?

Vin Mclellan, The Privacy Guild, Boston, MA               (617) 426-2487

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
More evidence for an old risk -- Enigma 
</A>
</H3>
<address>
Dave Mankins 
&lt;<A HREF="mailto:dm@diamond.bbn.com">
dm@diamond.bbn.com
</A>&gt;
</address>
<i>
Thu, 14 Apr 88 10:31:04 EST
</i><PRE>

Alfred Hodges biography of Alan Turing, ``Alan Turing: The Enigma'', relates
the story of deciphering the Enigma encryption system.  The key to the
decipherment was making a clever guess as to the plaintext (successful guesses
were known as `cribs') for a single word in a message, and then matching the
message against that word in hopes of finding the proper setting for the
rotors of the Enigma, which would allow you to decrypt the whole message.

While this might seem like a hopeless task, military messages have a
stereotyped form and a limited vocabulary (words like ``attack'' and
``General'' keep cropping up), making the task much easier.  Hodges says (p.
184):

	Nor was it a trivial matter to guess the probable word, nor to
	match it against the cipher-text.  A good cipher clerk, indeed, 
	could make these operations impossible.  The right way to use
	the Enigma, like any ciphering machine, was to guard against
	the probable word attack by such obvious devices as prefacing
	the message with a variable amount of random nonsense, inserting
	X's in long words, using a `burying procedure' for stereotyped or
	repetitious parts of the transmission, and generally making
	the system as unpredictable, as un-mechanical, as was possible
	without the loss of comprehensibility to the legitimate receiver.
	If this were done thoroughly the accurate `cribs' required for
	the Bombe [the cryptanalytic device designed principally by
	Turing for attacking the Enigma code] could never be found.
	But perhaps it was too easy for the Enigma user to imagine
	that the clever machine would take care of itself, and there
	were often regularities for the British cryptanalysts to
	exploit.

Cracking the Enigma naval code made it possible for convoys to avoid
U-boats, and made it possible for the British Navy to locate and destroy
U-boats.  The sudden change in the tonnage sunk by the U-boat offensive once
the naval Enigma was cracked led to an investigation by the Germans.  Says
Hodges (p. 201):

	In fact, the operation _had_ betrayed Alan's success, for the German
	authorities decided that the positions of the supply vessels had
	somehow been disclosed, and set up an investigation.  Their experts,
	however, ruled out the possibility that the Enigma cipher had been
	broken.  Instead, they pinned the blame upon the British secret
	service, which enjoyed a high reputation in German ruling circles.
	It was a diagnosis remote from the truth.  [Hodges elsewhere says
	the British military, told the Enigma decryptions came from the
	Secret Service, ignored them for the most part, since the Secret
	Service had a reputation for being wrong 80% of the time.]  They 
	had assigned an _a priori_ probability of zero to Enigma decryption,
	and no weight of evidence sufficed to increase it...

	The Bombe method, which was central to the system, hung upon a single 
	thread.  If, to be on the safe side, the Germans had gone over to a
	double encipherment of _every_ message, then there would have been
	no more cribs, and all would have been lost.  At any time, the mere
	suspicion that something had gone wrong might stimulate such a 
	change...

It's an old moral: your security may be foolproof, but the people trying
to subvert it might not be fools.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Norwegian embezzlement
</A>
</H3>
<address>
&lt;<A HREF="mailto:NMIEP%NOBERGEN.BITNET@CUNYVM.CUNY.EDU">
NMIEP%NOBERGEN.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 21 Mar 88 19:42:06 EMT
</i><PRE>
Resent-From: David L. Edwards &lt;DLE@csl.sri.com&gt; from Security@Rutgers

Maybe the latest incident on computer embezzlement? Two employees of the
largest Norwegian clearing house, Bankenes Betalingsentral BBS, are charged
with attempted fraud.

The scheme was apparently in accordance to the old dream of redirecting
transactions to other accounts. The particular day of the attempt, there were
to be a large number of social security benefit transfers. The possible
outcome is said to be app. ! 250 million. One of the two had an operator
type job, with access to tapes. However, the whole thing was set up in
such a way that it was easilly detected by regular security checks.

This hopefully shows that security does work, and that the notion that
no cases have ever been spotted due to security routines, is not true.

Eirik Kim Pedersen

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
     Race, identification, and muddly thinking
</A>
</H3>
<address>
        David Thomasson 
&lt;<A HREF="mailto:ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU">
ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 14 Apr 88 15:49:40 EDT
</i><PRE>

Les Earnest writes in reply to my earlier note:

&gt;Thomasson apparently believes that everyone belongs to some race
&gt;and that that race is determinable. He probably also believes
&gt;that all dogs belong to some breed. I would like to accompany
&gt;him to a city pound somewhere and listen to him identify all the
&gt;mutts there.

"Apparently believes...probably believes" -- more Straw Men. In fact, I
believe that virtually everyone can be put into some racial category that is
very useful for purposes of identification, even though such categories are
not biologically precise. As for the rest of the above, Earnest's argument has
gone to the dogs.

&gt;The things that Mr. Thomasson lists [hair color, eye color] at
&gt;the end are useful identification properties. "Race" is not,
&gt;unless you are a racist.

Granted the biological imprecision of racial categories, one must consider
their usefulness in identifying people. In three years with a police
department, I never knew of a case in which this imprecision worked against
the purpose of identification.  I knew of hundredes of cases in which racial
classification helped greatly. This is a matter of plain fact, and to suggest
that one is a racist for pointing it out is absurd. By the way, the term
"racist" is only as clear as one's definition of "race" -- something that
Earnest says is signally unclear. Once again, confusion runs rife in RISKS.

&gt;Color of skin and color of hair _are_ useful for identification
&gt;and may reasonably be included on a drivers license.

I agree. In my experience, "race" has been roughly equivalent to "color of
skin" in police work. So, while it's true that "race" is biologically
imprecise (even incorrect), those who use race for identification purposes
aren't concerned about biology -- no more so than when they use "build" --
stocky, thin, average, etc. Should we brand the latter as "buildists"?

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 "Race" as ID
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Thu, 14 Apr 88 15:41:07 CST
</i><PRE>

Inspired by the follow-on discussion of "race" as a valid datum for driver's
licesnses and suchlike documents: Obviously, since "race" is such an 
undefinable term, and an individual's "race" cannot be accurately determined
by merely looking at them, the ID factor should be changed to "skin color".

How would one know what to put in a "skin color" block on a form? Well,
you would have a chart, with various colors on it, like a paint-chip 
match-up chart or the kind of things medical technicians use to match 
the colors in a test tube when they are mixing reagents with specimens.
Each chart-entry color block would have a number, and you'd put that
number on the form.

But, you ask, where on my skin would I match this chart? Well, that IS a
problem -- a fair-skinned person's skin color can vary from pale white
in the winter to fiery red or reasonably tan in the summer or after
exposure to UV light, and this is likely to be apparent on parts of the
body exposed to the sun -- face, hands, arms, maybe even legs or torso.
Darker-skinned people also have variations in their skin color, though
the range may be less dramatic.

Therefore, the "official" area of comparison will have to be some part of the
body normally NOT exposed to sunlight. Where will that be? Well, I guess, for
reasons of decency, the only part allowable will be the buttocks. Normally
covered, yet readily exposable for comparison purposes. Therefore, after this
procedure is implemented, the normal citizen's response on being approached by
a policeman or other official who will need to identify them will be to turn
their backs, pull down their pants, and bend over, presenting the skin on their
buttocks for an official comparison....

:-) Adds new dimension to the old "Assume the position!" command, eh? :-)
Will Martin  

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: File "RISKS-6.FEYNMAN" and a ghost story 
</A>
</H3>
<address>
LEICHTER-JERRY@CS.YALE.EDU
&lt;<A HREF="mailto:"Jerry Leichter ">
"Jerry Leichter 
</A>&gt;
</address>
<i>
Thu, 14 Apr 88 17:16 EST
</i><PRE>

    [Sorry about the FTP difficulty.
    Jerry and I had a dialogue on an FTP problem that seems to permit
    get stripe:&lt;risks&gt;risks-6.feynman ... TO WORK, BUT NOT  
    cd stripe:&lt;risks&gt; FOLLOWED BY get risks-6.feynman ...     Beats me.
    Also, some systems are CASE SENSITIVE, and add further confusion.  PGN]

Reminds me of a great "ghost story" from the days when we had a pair of 20's
here.  A bad block in just the wrong spot on the disk - in the directory
structures, I guess - could lead to a crash whenever it got touched.  Such
a bad block appeared in a bulletin board; every time a message got posted
to the bulletin board, the system would crash.

The kicker:  It was the CRASHES bulletin board, where information about system
crashes was posted.
							-- Jerry

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.60.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.62.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-10</DOCNO>
<DOCOLDNO>IA012-000129-B044-379</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.62.html 128.240.150.127 19970217020645 text/html 23238
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:05:12 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 62</TITLE>
<LINK REL="Prev" HREF="/Risks/6.61.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.63.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.61.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.63.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 62</H1>
<H2>  Friday 15 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Neural Hype 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Bay Meadows Sued Over Computer Betting Glitch 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Carl's Jr. alleged inside trading caught "by computer" 
</A>
<DD>
<A HREF="#subj3.1">
Dave Suess
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  DoD simulations 
</A>
<DD>
<A HREF="#subj4.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  The Israeli virus bet 
</A>
<DD>
<A HREF="#subj5.1">
Y. Radai
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Types A and B: doesn't anyone read CACM? 
</A>
<DD>
<A HREF="#subj6.1">
Eric Roskos
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Accountability 
</A>
<DD>
<A HREF="#subj7.1">
George
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Neural Hype
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>

</i><PRE>
Date: Fri, 15 Apr 88 17:32:31 WET DST

The following article (reprinted without permission), appears - I am
embarrassed to say - on the front page of the April 14 issue of The Times, no
less. I hope that it is largely based on the reporter's imagination and his
misunderstanding of what he was told by the Imperial College researchers - so
that it is the reporter rather than the researchers who constitutes the
"computer-related risk to the public"!

Brian Randell, Computing Laboratory, University of Newcastle upon Tyne
UUCP  =	...!ukc!newcastle.ac.uk!Brian_Randell    PHONE = +44 91 232 9233


COMPUTER IN A TANTRUM HOLDS UP "BABY" PROJECT

By Robert Matthews, Technology Correspondent

A computer built at Imperial College, London as a crude simulation of the human
mind has startled its creators by going on strike and refusing to cooperate
with their work.

Mr Michael Gera, a scientist in the Neural Computing Group at the college, said
yesterday that the computer, known as a neural net, had simply refused to carry
on with its lessons when it was given a task it considered was beneath its
capabilities: "You might say it had an attack of boredom".

Mr Gera and his colleagues had designed the machine to test a theory about the
way in which human babies learn to communicate. They attempted to simulate the
working's of the baby's mind by instructing the computer to turn itself into a
"neural net", a collection of dozens of electronic devices which mimic the
operation of neurons, or brain cells.

Some theories in psychology claim that babies learn to talk to their parents by
babbling randomly, and looking for responses. For example, babbling that sounds
like "mama" wins a response, with mother pointing to herself. Then baby
remembers that "mama" corresponds to the object doing the pointing.

In the first set of experiments with the machine at Imperial, Mr Gera switched
on the neural network and let it babble away. When the machine hit upon a
sequence of babbling that Mr Gera had decided was the electronic equivalent of
a sensible word, the machine was given a suitable response. Sure enough, the
machine soon picked up a crude "vocabulary".

Mr Gera has gone a step further in a second set of experiments, still under
way.  The machine is told that a specific object it is being shown corresponds
to the electronic equivalent of, say, a black cat. Later, another type of cat
is shown to the machine, which is then expected to recognise quickly that this
new object is also a cat, and say the word accordingly.

However Mr Gera has made the unnerving discovery that unless the objects shown
to the machine are sufficiently different and exciting, it goes into a huff. He
said: "It just sits there and goes on strike".

The Imperial team, led by Professor Igor Aleksander, has seen the machine throw
its weight about on a number of occasions.

The long-term aim of the research is to develop neural nets capable of tasks
still beyond today's most powerful computers. Those "supercomputers" are
excellent at tasks such as solving equations, but virtually useless at tasks
requiring intelligence.

However, events suggest that the next generation of computers will have to be 
taught good behaviour before they can be given responsibility.

Mr Adrian Rogers, another member of the team, said: "Neural nets are a little
unruly sometimes. We don't know enough about them to put them in charge of,
say, a nuclear reactor."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Bay Meadows Sued Over Computer Betting Glitch
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Fri 15 Apr 88 11:03:50-PDT
</i><PRE>

Peter Frankel, a San Mateo CA real estate investor on 29 June 1987 placed
$9600 in cash at the parimutuel window at Bay Meadows racetrack on a
Pick-Nine, 20 minutes before post time.  The clerk was unable to coax the
computer system to issue a ticket for the bet, in several tries.  However,
the window manager held on to his money and computerized betting card.  HE
PICKED ALL NINE CORRECTLY, but was told he could not collect becuase he did
not have a ticket.  The track lawyers (said his lawer, Monzione) "got cute
on us and said that for them to give Mr. Frankel his money would mean they
were involved in illegal gaming."  He did get his $9600 back, but is now
suing for the expected $265,000 -- plus damages for a real estate that fell
through because he was unable to collect.  

San Francisco Chronicle article by Bill Workman, 15 April 1988

   [Apparently the software had rejected the bet as a single transaction.
   Could it be that no one had previously tried a Pick Nine? or that the
   product of the number of horses in each race was greater than some
   programmed limit?  or was there a Trojan horse race?  or did they 
   guess that Frankel was psychic?]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Carl's Jr. alleged inside trading caught "by computer"
</A>
</H3>
<address>
Dave Suess (CSL) 
&lt;<A HREF="mailto:zeus@aerospace.aero.org">
zeus@aerospace.aero.org
</A>&gt;
</address>
<i>
Thu, 14 Apr 88 19:13:03 -0700
</i><PRE>

I just heard a news tidbit on local news about the charges handed out 
today by the SEC accusing Carl Karcher Enterprise insiders (Carl and
family, mostly) of selling significant holdings just prior to the news
of a large dip in quarter earnings being announced.

According to a spokesman (for the SEC?), "our computer detected a [local
flurry of trading just before a significant financial news release]".  The
trading activity was noted back in '85, I think, since the news release 
involved a dip in profits from the previous year during the Olympics in L.A.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
DoD simulations
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.stanford.edu ">
chapman@csli.stanford.edu 
</A>&gt;
</address>
<i>
Thu, 14 Apr 88 17:28:56 PDT
</i><PRE>

I received a copy of the GAO report, "DoD Simulations:  Improved Assessment
Procedures Would Increase the Credibility of Results," (GAO/PEMD-88-3, December
1987).  This is a 154-page report on three DoD simulations; two that were done
for the DIVAD air defense gun (the one that had so many problems it was
cancelled) and one for the Stinger missile.  The two DIVAD simulations were
called ADAGE (Air Defense Air to Ground Engagement) and Carmonette; the Stinger
simulation was called COMO III (COmputer MOdel).

I won't go through the entire list of conclusions from this report, but
the following points are worth passing on:

  "One consistent weakness in all three simulations that potentially
  poses a major threat to credibility is the limited evidence of efforts
  to validate simulation results by comparing them with operational
  tests, historical data, or other models. . . .

  "Validation can be difficult, but it must be dealt with if simulation
  results are to be credible. . . .

  "Some of the results of the simulation analysts to show that the models
  we examined closely represent reality were very limited.  Some
  validation was not even attempted.  In general, the efforts to validate
  simulation results by direct comparison t data on weapon effectiveness
  derived by other means were weak, and it would require substantial work
  to increase their credibility.  Credibility would also have been helped
  by better dcoumentation of the verification of the computer program and
  by establishing that the simulation results were statistically 
  representative. . . .

  "In commenting on a draft of this report, DoD generally found the report to 
  be technically correct and concurred with GAO's two recommendations. . . ."

Another interesting section of the report is a fairly long technical
description of how "ground battle" is simulated in DoD simulations. 
This description includes some fairly sustained criticism of the models
studied, but it also offers quite a bit of information on what model
builders are supposed to take into consideration.

Here's an interesting example of what went wrong with one of the models:

  ". . . The ADAGE does not model direct attacks by aircraft on the DIVAD
  itself, since it does not model duels.  Instead, the attrition of the weapon
  was played in the Campaign [a subset of the simulation], which uses
  expected-value equations to calculate the probability of damage to ground
  targets by class from air attacks and assumes a random selection of targets
  within one target class.  Similar procedures were used to assess damage to
  DIVAD weapons in the ground war.

  "This approach led to a problem in which the DIVAD was labelled 'the immortal
  DIVAD.'  ADAGE results implied that it took 10 times the number of
  air-to-ground missiles indicated by the Carmonette model to kill one DIVAD.
  Analysis by the study advisory group indicated that classifying the DIVAD in
  a target class by itself caused the ADAGE model to shoot all the helicopter
  missiles at the one DIVAD. . . ."

Gary Chapman, Executive Director, 
Computer Professionals for Social Responsibility

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
    The Israeli virus bet
</A>
</H3>
<address>
Y. Radai 
&lt;<A HREF="mailto:RADAI1%HBUNOS.BITNET@CUNYVM.CUNY.EDU">
RADAI1%HBUNOS.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri,  15 Apr 88 17:51:53 +0300
</i><PRE>

   In RISKS 6.58 Fred Cohen remarked in connection with the virus bet which
was made on Israeli television (described in RISKS 6.55) that he suspects
that "the Israeli defense is useless against most of the viruses we have
done experiments on - I wish I was on the attacker's side of that bet!!!".
I'm sure that there are many others who would also be willing to be on that
side of the bet.  However, before jumping to conclusions it would be wise to
know how the detection program works and what the bet was over.
   First of all, it should be clear that the "defender" does not claim that his
program fixes infected files or prevents infection, or even that given a file,
it can correctly decide whether it contains a virus.  He claims only that if
his program has been used between the time that a file has been created on a PC
disk and the time that such a file becomes infected by a virus, that infection
will be reported by the program.  And the bet was whether the "attacker" (who
was given a copy of the detection program on April 10) can, within two weeks,
create a virus which will not be detected by this program in the sense just
described.  (Actually, the precise terms of the bet have not yet been fixed,
and much depends on how it is worded; more on that below.)
   The program, written by Yuval Rakavy and Omri Mann, works according to a
principle that is not at all new.  (In addition to theoretical work on the
subject, I know of two other already marketed programs for PCs which work
similarly.)  For every file (or for any specified set of files) it computes a
"fingerprint" or "checksum", i.e. a certain function of the bits in the file,
which is sufficiently intricate that even with knowledge of the algorithm, it
would be impossible to alter a program to achieve a specific purpose without
changing the checksum.  Of course, the idea is that if there's a change in the
size, date, time or checksum of a file which wasn't supposed to have been
altered, the file has presumably been infected by a virus.  (In addition to
files, the program also automatically checksums the boot block.)
   It seems to me that whether a program such as this can really "detect any
virus" depends on how one defines "detect" and "virus".  In trying to conceive
of a virus which could avoid detection, I considered the possibility of
creating a situation in which a checksum alteration would be ambiguous.  For
example, suppose software were created which added destructive code to each
executable file which a compiler creates.  Of course the checksum of such a
file would change with each new compilation, but that is to be expected; there
would be no reason to conclude that it contains destructive code.  Would we say
that the program has failed to detect a virus?  True, if such a file were
copied to other disks, it could do damage to them on some later target date.
But the destructive code would be unable to infect other files since that
would cause a check-sum mismatch.  If it is agreed that by definition, a virus
necessarily propagates by altering healthy files in some manner before
performing its most lethal damage, then this is not a virus but a Trojan horse,
and the checksum program would not have failed to detect a virus.
   Of course, Fred Cohen or someone else may think of an idea which neither the
defender, the attacker nor I have thought of.  But given the above information,
would Fred still claim that this defense is useless against most of the
viruses, and would he still be willing to be on the attacker's side of the bet?

   Y. Radai, Hebrew Univ. of Jerusalem, RADAI1@HBUNOS.BITNET

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Types A and B: doesn't anyone read CACM? (Re: <A HREF="/Risks/6.54.html">RISKS-6.54</A>, 59)
</A>
</H3>
<address>
Eric Roskos
&lt;<A HREF="mailto:uunet!daitc!csed-1!csed-47!roskos@rutgers.edu ">
uunet!daitc!csed-1!csed-47!roskos@rutgers.edu 
</A>&gt;
</address>
<i>
Fri, 15 Apr 88 10:02:04 EDT
</i><PRE>

  : ...  The researcher, Jan L. Guynes, used psychological tests to classify 86
  : volunteers as either Type A or Type B personalities...  She found that a 
  : slow unpredictable computer increased anxiety in both groups equally...

It's been interesting to see all this discussion based on a newspaper article
on "a researcher, Jan L. Guynes," no one citing the fact that this newspaper
article was no doubt derived from a paper published in our field's own journal, 
Communications of the ACM, in the March, 1988 Issue, on page 342!


Incidentally, something I have not seen mentioned in your digest is that the
_New_York_Times_ is currently exploiting computer viruses to sell
newspapers.  An advertisement which runs almost everyday on WBMW, a radio
station in Manassas, VA, shows a man who is impressing a colleague with his
up-to-the-minute news knowledge of facts by saying,

	"Who would imagine that cross-country skiing would be so popular?"

	(His colleague, who obviously doesn't read the _Times_, comments
	that he didn't know that.)

	"Yes, and did you know that now computers have viruses, sneaky little
	 programs that make them sick?  And they're even contagious!"  (He then
 	 goes on to tell about some other timely information; and ends up 
  	 saying how he learned it all from the _Times_...)

Eric Roskos, IDA (...daitc!csed-1!roskos, or csed-1!roskos@DAITC.ARPA

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Accountability
</A>
</H3>
<address>
&lt;<A HREF="mailto:munnari!ditmela.oz.au!george@uunet.UU.NET">
munnari!ditmela.oz.au!george@uunet.UU.NET
</A>&gt;
</address>
<i>

</i><PRE>
Date: 14 Apr 88 23:13:57 +1000 (Thu)

I think what Henry Spencer said is all too depressingly true, but I also
think its more indicative of a social failure than a true RISK
(actually, so is the whole thread of my argument! whoops!) because it's
about the failure of a chain of command to control the situation.

-That cash is the only effective incentive for producing results is the 
ultimate disaster of our times, and when lives are at stake it really stinks.

However, I'm not trying to suggest only the threat of legal accountability
makes for correct solutions. I do think it's a vital link in the chain.

Actually, the ATM debate &amp; also the 'social consequences of DB' stuff
are (to my mind at least) also less RISK-y than the good old 

      "Japanese robot murders family of 3 on easter outing" 

stories I used to read in ACM RISKS! -The trouble is so few genuinely
amusing RISKS seem to crop up these days.

Ditto to VIRUS' -they all show how when people don't accept responsibility
for their actions (-installing and running an ATM, indiscriminate data
capture in a DB, spreading dirty disks around campus) chaos ensues.

Even if the ATM network or a police DB is completely bug-free, it has social
issues which make me scared of its existence. I'm not scared of a VLSI,
only of the potential for it to be broken! -If AMEX or the LAPD try
to say "its a bug-free system" *THEN* we can stomp 'em!

I still think however there is an unanswered problem for ENGINEERING which
RISKS addresses: when an 'active' component of a 'reductionist' or
mechanistic setup (which I suppose a very formalized chain of command
during a launch sequence could be said to resemble, although I'm trying
to say computer system or program or chip without using those words) 
fails in the system, somebody should bloody well stand up and say 
	"it was my decision to do xyz..." 
-and disclaimers should be banned in law.

Marxists used (do they still?) talk about the "organic content" of capital,
the idea that even in a completely mechanized society the historical human
effort that built the machine (that builds the machines...)  is the endower
of "labour value" as opposed to "use value". I think this is extremely
important for computerized systems, where the human element may be merely
the selection of logic or algorithm. It is *soo* tempting to say:

	 "hell... nobody was to blame, the machine did it all itself"

but there will *always* be some 'organic content' in this way. If we ever
get a Turing Testable robot, I'll let it carry responsibility for its actions
but until then I'm afraid the builders in all senses of the word should be
responsible for its behaviour.

More importantly, somebody commissions the system. In the case of Morton
Thiokol "blame" lies across many levels, but outsiders like me tend to lay more
emphasis on the swine who pressurized the engineers into disregarding the
weaknesses, not the engineers themselves.  O-ring failure was forseen, and then
conveniently forgotten.  (That's why I'd argue it was a social or
human-organizational failure and not a RISK in this group's sense of the word).

Rolt was writing about forseeable failure in structural mechanics:  a bridge
that fell down, an embankment poorly sloped, a signal methodology that had
deadlock or was not truly stable. Blame isn't for having a whipping boy --
although all too often that's all that it *is* used for, it identifies where in
the chain of command a bad decision was made *so that it can be prevented next
time round*.

I suppose all I'm saying is that if it was forseeable or deduceably likely a
programmer is in some way culpable when the system breaks down.
                                                                     (yes/no ?)

   [Edited lightly -- but not for content - except for the final (non)sentence,
   which I left alone.  By the way, I don't think we've come anywhere near
   "Japanese robot murders family of 3 on Easter outing".                 PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.61.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.63.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-11</DOCNO>
<DOCOLDNO>IA012-000129-B045-14</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.63.html 128.240.150.127 19970217020657 text/html 28053
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:05:25 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 63</TITLE>
<LINK REL="Prev" HREF="/Risks/6.62.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.64.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.62.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.64.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 63</H1>
<H2>  Sunday 17 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Phantom of the Arpanet 
</A>
<DD>
<A HREF="#subj1.1">
Cliff Stoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  New VMS security problems? 
</A>
<DD>
<A HREF="#subj2.1">
Klaus Brunnstein and Darren Griffiths
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Printers as perforators 
</A>
<DD>
<A HREF="#subj3.1">
Stephen Page
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Another ATM story 
</A>
<DD>
<A HREF="#subj4.1">
Win Treese
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Accountability 
</A>
<DD>
<A HREF="#subj5.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  BENEFITS! of RISKS (Post Office Stamp Machines) 
</A>
<DD>
<A HREF="#subj6.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Color blindness 
</A>
<DD>
<A HREF="#subj7.1">
Rick Sidwell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Race, Sex, and other imponderables 
</A>
<DD>
<A HREF="#subj8.1">
Joe Dellinger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Ethnics and UCB 
</A>
<DD>
<A HREF="#subj9.1">
Peter da Silva
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Enfranchising the disenfranchised: our responsibility? 
</A>
<DD>
<A HREF="#subj10.1">
Paul Shields
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Diving ascent computer 
</A>
<DD>
<A HREF="#subj11.1">
Mike
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Productivity: Progress, Prospects, and Payoff --  Preliminary Program     
</A>
<DD>
<A HREF="#subj12.1">
Charles Youman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 The Phantom of the Arpanet
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:    cliff@Csa3.LBL.Gov ">
    cliff@Csa3.LBL.Gov 
</A>&gt;
</address>
<i>
Sun, 17 Apr 88 19:28:43 PDT
</i><PRE>

Extra! Extra! Read all about it!  

Yes, informed sources report that this week's newspapers may carry a 
story about how a persistent intruder broke into over 30 US computers.  
This tale, brewing for about 2 years, tells of a methodical attack on 
hundreds of military and defense contractor's computers.  Unknown to 
him, we silently monitored him at Lawrence Berkeley Laboratory, 
where we traced his connections and recorded all his keystrokes.  

The intruder used a variety of networks, including the Milnet/Arpanet, MFEnet,
Tymnet, Datex-P, and analog telephone services.  Despite his convoluted
pathways, we traced him back to his lair in West Germany.  By cooperative
efforts of law enforcement people and network managers, we developed traceback
methods to trace him halfway around the world in less than 2 minutes.

A part of the story is in the German popular magazine QUICK of April 12, 1988.
Apparently, they somehow got a copy of my laboratory notebook.  From those
notes, they wove a tale of high-tech intrigue, starring a mad scientist who
dwelled in a "communal living situation" in Berkeley.  Following their
publicity, reporters have interviewed me, and I expect newspaper publicity in
either the Daily Planet or some other great metropolitan newspaper.

But the complete story will appear in the May issue of the Communications of
the ACM.  We had planned no publicity until the issue was in the mail, but
alas, the German magazine printed it, and the cat was out of the bag.  The
real scoop is in the May CACM, so make sure your ACM dues are paid up!

Cheers to all RISKeeS,
Cliff Stoll      CPStoll@lbl.gov

     [I am very grateful to Cliff, the super-scoop-er, for contributing this 
     mere bag-cat-tell tale teaser.  This is the eve of the annual IEEE
     Symposium on Security and Privacy, at which more than a few RISKS
     participants will be taken away from their RISKS fixes -- so they'll
     just have to watch the papers.  Stay tuned for further developments.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
New VMS security problems? (<A HREF="/Risks/6.58.html">RISKS-6.58</A>)
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>

</i><PRE>
Organisation: University of Hamburg, FRG, Faculty for Informatics
Date: April 15, 1988

After some contacts with some well-informed DEC users and DEC
software engineers, I have gathered the following information:

The `urgent update' solves some problems with Local Area VAX clusters
(LAVc), associated with VAX Workstation Software (VWS).  Following the `new
DEC philosophy', DECs security staff doesnot wish to more precisely inform
its users; moreover, only a few DEC software engineers have been informed.
The update contains 1134 blocks (plus Kid Install), and it contains totally
new images of 5 VWS modules: SYS, TTDRIVER, WTDRIVER,UIBSG, DBGSSISHR,
together with a list of several more patches. The reason for this update has
evidently been discussed in the German DECUS meeting, held in Aachen, March
1988; when the discussion is available in printed form, I will inform you.

Unfortunately, the update may have produced a new secutity problem, as
indicated in the INFO-VAX letter of Darren Griffith which I add for your
information:

     ----------copy of D.Griffith INFO-VAX letter--------------
Delivery-date: Tuesday, April 12, 1988 at 13:59 GMT+0100
Send-date: Monday, April 11, 1988 at 13:50 GMT-0100
From:Darren Griffiths &lt;S=dagg;OU=csa4;O=lbl;P=gov;C=nn&gt;
To:&lt;S=info-vax;OU=kl;O=sri;P=com;C=nn&gt;
Subject:DEC's security patch.  Just say no!

Date:     Thu, 7 Apr 88 20:10:22 PDT

DEC recently released a mandatory update to VMS that fixes some problems in
SYS, TTDRIVER, WTDRIVER, UISBG and DBGSSISHR.  Upon installing this update
on a LAVc some problems were experienced, people running VAXstations that
use the VAX Workstation Software may want to read this before installing the
fixes on their systems.

It seems that one of the fixes was to a known problem with the way device
protections are assigned under VWS.  When you create a new window the software
creates a new device WTAx: that is basically a copy of the template workstation
device WTA0:.  The "problem" that was "fixed" is that some of the protection
bits get changed when the new device is created, the fix stops this from
happening.  The problem does introduce a security hole so I am trying to avoid
being too specific. 

So far all of this sounds quite nice, the problem is corrected and things
should go on as normal.  Unfortunately another problem is introduced.  When you
create your first window on the workstation LOGINOUT is running with a system
UIC and the window is created by opening the template device WTA0 and having
another device created for you, when you then decide that it would be exciting
to have a second window and you try to auto-login, the process is created with
your UIC and privileges.  LOGINOUT opens up WTA0: expecting to get a device
allocated to it, the device is created but cannot be allocated to you because
the security patch fixed the protection bits very nicely and your process
doesn't have privilege to look at the device. 

This problem can be avoided in four ways.  

   1)   Don't install the patches at all.

   2)   The problem doesn't occur if your **DEFAULT** privileges include
        something like READALL, that way you will be able to get the DEVICE.
        Note that all you need is read access to be able to allocate a
        non-shareable device like a workstation window.

   3)   If you've already installed the patch and don't want to be give
        everyone privileges you can remove the patched version of
        SYS$SYSTEM:TTDRIVER.EXE, put the old one back and reboot.

   4)   You can uncomment the lines in SYS$MANAGER:UISBG.DAT that allow
        you to have another option in the workstation menu that will let
        you login without auto-login.  This way you just have to type 
        your username and password each time a window is created.


I have contacted DEC about the problem and hope to have an answer very soon,
I'll let the net know when this answer comes in.  If anyone has any questions
or further information let me know.

   --Darren
 
   Lawrence Berkeley Labs
   DAGG@LBL.GOV
   ------------------end of Darren's e-letter------------------   

After having discussed the problem described here with DEC
security experts, there could be a problem with AUTO-LOGIN
when a second window is opened; nevertheless, I follow DEC's
advice that users should NOT follow one of `Darren's four ways'
since this might re-install the security problem just patched away.

Klaus Brunnstein, University of Hamburg, Faculty for Informatics

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Printers as perforators
</A>
</H3>
<address>
Stephen Page 
&lt;<A HREF="mailto:sdpage%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK">
sdpage%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Sat, 16 Apr 88 13:03:54 bst
</i><PRE>

In RISKS Volume 6 : Issue 49 the following program fragment appeared:
	10 PRINT 1000
           GOTO 10
      1000 FORMAT ('+', 132*'-')

This reminded me of a colleague at the University of Queensland who used
to use a loop with the same FORMAT statement to almost-perforate forms
("tear along dotted line"). The risk, of course, was not when he had got
it right, but in all the attempts to find the right value for the
iteration limit... The operators became pretty fed up with reloading the
paper when the value was too high and he sliced it through!

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Another ATM story
</A>
</H3>
<address>
&lt;<A HREF="mailto:treese@ATHENA.MIT.EDU">
treese@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 16 Apr 88 23:25:28 EDT
</i><PRE>

A friend of mine recently received a new ATM card in the mail, with a notice
saying the old one had expired.  In the following, card A is the old, expired
card, and card B is the new one.  Here's what happened:

1. Not realizing that A had expired, he used it in an ATM.  Since it had
	expired, the machine ate the card.
2. The bank discovered the card in the machine, and a "new card event"
	occurred -- he was issued a third card (C).  Apparently, the
	bank did not check to see *why* the card was in the machine.
3. Next, he tried to use card B.  This time, the machine ate it because
	previous cards were invalidated when the bank issued card C.

Now, his question is: will the machine eat card C when he uses it? The
person he talked to at the bank assured him it would not, but he's a
little skeptical....
                              	Win Treese, 	DEC/Project Athena

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Accountability
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@ames-nas.arpa">
eugene@ames-nas.arpa
</A>&gt;
</address>
<i>
Fri, 15 Apr 88 21:17:34 PDT
</i><PRE>

&gt;I suppose all I'm saying is that if it was forseeable or deduceably likely a
&gt;programmer is in some way culpable when the system breaks down.
&gt;                                                            (yes/no ?)

As noted by another RISKS author in the same issue: it's under our
noses.  See John Shore's article in the April 1988 CACM.

--eugene miya

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
BENEFITS! of RISKS (Post Office Stamp Machines)
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@ames-nas.arpa">
eugene@ames-nas.arpa
</A>&gt;
</address>
<i>
Fri, 15 Apr 88 10:05:08 PDT
</i><PRE>

We always talk about computer induced RISKS in this group.  I encounter
a wrongly programmed cash register every month and the system crackers
are scanning telephone pre-fixes all the time (my answering machines
fields these).  Let's talk about some personal BENEFITS! 8-)

Yesterday, I went to the post office to purchase several rolls of stamps for
an ACM chapter mailing.  The Office has these vending machines with a big
added box to the side to recognize and collect large sums of money.  I don't
know if they have micros in them (I hope so otherwise this isn't a computer
BENEFIT).  I've done this before, but I feel a bit uncomfortable putting
$20s into these machines (just the size).  With the increase in postage, I
now also have to put $5s in as well.

The $5s I got from McDonalds (near the on-base Post Office) were a bit worn.
The first was not accepted (fair enough).  The second had some trouble, but
it was taken.  Time to insert the next $20 for a roll.  It would not take it.
But it was clean and just came from my automatic teller.  I looked up to
discover that the $5 had registered twice ($10) even though it took only
one bill!  Now that's postage!  Let me know when Email can do this.

Anyway, these machines have "programmed limits" on the amount of money
they can process.  It won't take $20 (I need a ROLL for a stamp machine
and these cost $25).  I can't get change, the coin return is not hooked up
to the bill recognizer, so I have to buy some smaller packages of stamps.
The ACM (me in this case) comes out $5 in stamps ahead.

Forget color copiers (oops, almost said that trademark) and change makers,
how do I repeat what I just did?

--eugene miya  NASA Ames Research Center, Moffett Field, CA

   [Be sure to read the instructions FIRST.  They say PLEASE READ THE 
   INSTRUCTIONS BEFORE DEPOSITING BILLS...  There can be some nasty 
   side-effects if you don't -- e.g., if the selction you want is OUT --
   no facility for a refund.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
color blindness
</A>
</H3>
<address>
Rick Sidwell 
&lt;<A HREF="mailto:sidwell@commerce.UCI.EDU">
sidwell@commerce.UCI.EDU
</A>&gt;
</address>
<i>
Thu, 14 Apr 88 21:00:54 -0700
</i><PRE>

In Risks 6.61, Will Martin suggests using a color chart for finding the
answer to the "Skin color:" question on various forms.  Although his
suggestion was made in a humorous sense, I would like to point out a risk
to this as well as other areas more applicable to this forum.  Not all
people see colors in the same way.  Many people are color blind to one
extent or another (actually, the preferred medical term is color deficiency,
since most "color blind" people can see some colors just fine--I prefer
color blindness since most people know what it means).  I personally am
red-green color blind, which means that I have difficulty distinguishing
some shades of red, green, and brown (pink and purple are also sometimes
difficult).  When we recently purchased an aquarium, I, enjoying scientific
experiments, purchased a number of water test kits to monitor pH, ammonia
levels, water hardness, etc.  Every time I test the water, I carefully mix
the water with the reagent... and ask my wife what the result is!

Many potential risks associated with color blindness have been identified
and dealt with.  For example, the colors in most traffic lights are chosen
to be identifiable to color blind people--the reds and greens which can
cause problems are ignored.  However, many software developers do not
consider such matters.  For example, I recently saw a videotape demo of
a distributed systems modeling tool which used color to indicate the
state of the various parts--green meant one thing, and gold meant another.
The problem is, I couldn't tell them apart easily.  A good design practice
is to let the user customize the colors to his or her own tastes and
abilities, but this raises another risk:  that you get used to your own
customized setup, and have problems interacting with other people
who use a different one.  For example, when I use Unix, I have an alias
"ty" which uses the program "more" to display a file a screenfull at
a time.  When a novice Unix user needs help, I invariably try to use
my personal command on their account, which doesn't work.

A related problem is the fact that red is often used to indicate danger or
urgency.  Red is also the hardest color for me to see--some shades seem much
darker than they really are.  On many color terminals and computers (such as
the IBM PC), I can barely read red characters on a black background--the color
choice for many important warning messages.  Many color blind friends have the
same problem.  May I suggest treating red as black, and for urgent messages
either using white on red or red on white?  I probably don't need to stress the
importance of color choice (and possibly field testing with color blind people)
for systems where a missed warning message can cause a serious risk.

Rick Sidwell
                                  [I trust Stendhal was not color blind!  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Race, Sex, and other imponderables
</A>
</H3>
<address>
Joe Dellinger 
&lt;<A HREF="mailto:joe@hanauma.STANFORD.EDU">
joe@hanauma.STANFORD.EDU
</A>&gt;
</address>
<i>
Fri, 15 Apr 88 01:56:44 pdt
</i><PRE>

	In the end any attempt to neatly categorize animals of any kind,
including people, is bound to fail... there must always be problematical
borderline cases. This goes for such obvious cases as Race and Religion,
but applies equally well to such things as gender, nationality, and species.

	Eastern Blue Jays interbreed with Scrub Jays in Texas and
Stellar's Jays in Colorado. But they are still considered separate
species, because the indeterminate cases are so rare --- 99.9% of the
time the birds you see WILL look like one of the ones in the field guide.
If intermixing continues, the distinction will eventually have to be dropped.
For example, red-shafted and yellow-shafted flickers are now considered
only commonly-occuring color patterns of one species.

	The same goes with race in people --- it is a useful identifying
trait only because the "problem" cases have been for the most part exceptions.
As the number of mixed-race people increases, as it must, the distinction
gradually loses statistical value.

	The only sure way to create clean-cut categories is to force
your measured property onto some well-defined set like the Real Numbers
and put in an arbitrary dividing line, or to legislate that indeterminate
cases are not legally recognized.

If the value on line 16 is at least 14,451 but not over 14,550 and your
filing status is 1 or 3 your California tax is $338...

    [Note that if you use the tax schedule instead of the tax table, you get
    a (slightly) different result.  And whether or not you round to even
    dollars or not throughout your return also produces different results.
    Clean-cut, but not clear-cut.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Ethnics and UCB (Re: RISKS DIGEST 6.55)
</A>
</H3>
<address>
Peter da Silva
&lt;<A HREF="mailto:nuchat!sugar!peter@uunet.UU.NET ">
nuchat!sugar!peter@uunet.UU.NET 
</A>&gt;
</address>
<i>
15 Apr 88 14:09:36 GMT
</i><PRE>

Re: a message about "RACE=OTHER" defaulting to "RACE=WHITE".

This is hearsay, so take it with a grain of salt, but I was told by a friend
that he started filling the ethnicity slot on forms at UCB with "prussian".
This apparently did not default to "white".

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Enfranchising the disenfranchised: our responsibility? 
</A>
</H3>
<address>
Paul Shields
&lt;<A HREF="mailto:yunexus!nccnat!root@uunet.UU.NET ">
yunexus!nccnat!root@uunet.UU.NET 
</A>&gt;
</address>
<i>
Thu, 14-Apr-88 03:56:17 EST
</i><PRE>

Tom Betz writes in RISKS DIGEST 6.58:
 
&gt; A question I would find most interesting to discuss here would be the 
&gt; question of this Republic within the Republic.  How are the lives of those 
&gt; who are too ill-educated to use these tools effectively going to be affected 
&gt; by the increased power of those of us who &gt;do&lt; use them?

They are going to be affected greatly.  "Power Corrupts" is not precisely
what I'm getting at, but power permits abuse.

Did the FCC know what hit them when those x-thousand letters arrived? 
Put that power in the hands of the few who would abuse it, and they will. 
So it's important to temper their ability to do so.  Can someone be 
slandered through a public forum if there are 100 other people in the forum 
willing to stand up and help defend them? 

When it's out of the public eye, then it's a different thing.  With power 
comes responsibility, and networks have to be able to teach responsibility 
and tolerance to their members to assure that they are not used wrongly. 

&gt; Do we have a responsibility to do whatever we can to spread the power around
&gt; to these people? 

To prevent abuse, we must give those who would be abused the ability to 
defend themselves.  In order to do this, we must get them to use the tools.

&gt;               How can we do this?  How can our computers help us help them?

Good question. It's difficult.  But I think distance education is a 
start. Promote the use computer networks as an educational tool throughout 
the world.  Teach people to speak, read and write.  As this happens, 
new communities are created:  isolated people discover that they are not 
alone in life, that others share their thoughts and feelings.  This will
give them the initiative to bring themselves up out of dispair.

&gt;      Serious questions....

The world has a number of BIG problems to solve, like pollution, wars, 
overpopulation, and famine.  Perhaps, through computer networks, we can 
enable the world the to save itself. 

Paul Shields, Technical Support Manager for the 
Native Computer Communications Network, York University, Toronto Canada.
shields@yunccn.UUCP, ...utzoo!yunexus!gen1!yunccn!shields

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
 Diving ascent computer
</A>
</H3>
<address>
&lt;<A HREF="mailto:F026%CPC865.UEA.AC.UK@CUNYVM.CUNY.EDU">
F026%CPC865.UEA.AC.UK@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
14-APR-1988 09:02:50 GMT
</i><PRE>

&gt; .. test button to see if the LED has failed

Better still would be to have (say) a green LED for positive indication of 'it
is safe to ascend'. Green might be difficult to see underwater. Maybe just a
solid red LED for 'safe' and a *seperate* flashing red LED for 'wait'.
                                                                          Mike

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Productivity: Progress, Prospects, and Payoff --  Preliminary Program
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Fri, 15 Apr 88 11:55:11 EST
</i><PRE>
From: Charles Youman (youman@mitre.arpa) &lt;m14817@mitre.arpa&gt;
Organization: The MITRE Corp., Washington, D.C.

Preliminary Program -- PRODUCTIVITY:  PROGRESS, PROSPECTS, AND PAYOFF
    27th Annual Technical Symposium of the Washington DC Chapter of ACM
    Gaithersburg, Maryland  June 9, 1988
Sponsors:
     Washington DC Chapter, Association for Computing Machinery;
     Institute for Computer Sciences &amp; Technology, National Bureau of Standards
Key Dates:
     Register by June 1, 1988 and save over 10% of at door rate
     Register by May 1, 1988 and save an additional 15%
     Special rate for full time students

Productivity is a key issue in the information industry.  Information
technology must provide the means to maintain and enhance productivity.  The
symposium "Productivity:  Progress, Prospects, and Payoff" will explore
theoretical and practical issues in developing and applying technology in an
information-based society.

Keynote address:  "Near Term Improvements in Productivity"
     Howard Yudkin, President and CEO, Software Productivity Consortium

Plenary panel:  "What Are the Impediments to Improving Productivity?"
     Walter Douherty, IBM
     Phil Kiviat, SAGE Federal Systems
     Marshall Potter, U.S. Navy
     Al Scherr, IBM

Parallel sessions:
     Processes and Tools for Higher     Software Economics and Reuse
       Software Productivity            Uncertainty in Software Requirements
     Software Specification Tools         Development       
     Panel-Data Management Standards    Expert Systems and Knowledge 
       A Key to Enhanced Productivity     Engineering in Software Engineering

For more information, contact the Symposium General Chairman: 
Charles E. Youman, DC Chapter ACM, P.O. Box 12953, Arlington, VA 22209-8953
(703) 883-6349                                            youman@mitre.arpa

PRODUCTIVITY: PROGRESS, PROSPECTS, AND PAYOFF -- Preliminary Program 
                                  [Please Pardon Persistent Alliteration.  P.]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.62.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.64.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-12</DOCNO>
<DOCOLDNO>IA012-000129-B045-41</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.64.html 128.240.150.127 19970217020711 text/html 22326
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:05:38 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 64</TITLE>
<LINK REL="Prev" HREF="/Risks/6.63.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.65.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.63.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.65.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 64</H1>
<H2>  Monday 18 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of reprogramming keyboards 
</A>
<DD>
<A HREF="#subj1.1">
John Coughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Fear of flying? 
</A>
<DD>
<A HREF="#subj2.1">
Daniel B Dobkin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Flight international" magazine about civil avionics 
</A>
<DD>
<A HREF="#subj3.1">
L. Strigini
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Another STARK investigation; faulty simulation implicated? 
</A>
<DD>
<A HREF="#subj4.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Ethnics and UCB 
</A>
<DD>
<A HREF="#subj5.1">
Bob Ayers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: More evidence for an old risk -- Enigma 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: DEC's recent security patch 
</A>
<DD>
<A HREF="#subj7.1">
Darren Griffiths
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Risks of reprogramming keyboards
</A>
</H3>
<address>
John Coughlin 
&lt;<A HREF="mailto:JC%CARLETON.BITNET@CORNELLC.CCS.CORNELL.EDU">
JC%CARLETON.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
18 Apr 88 11:21:00 EDT
</i><PRE>

   Last week a user of one of our mainframe systems called me with a couple of
problems.  She had logged on to a printer terminal to produce a hardcopy of
important electronic mail messages.  After a couple of messages had printed,
garbage characters appeared on her terminal.  "Sounds like a problem with flow
control, this shouldn't be difficult to set right," I assured her.  She then
explained that when she later logged on to her CRT, the messages which she has
tried to print had been deleted from her email folder.  She insisted that she
had not typed the DELETE command herself. It was not very likely that some
malicious individual had selectively deleted the exact same range of messages
which had been displaying, so I was at a loss to explain their disappearance.
I was able to restore most of her email from backup tapes, after which I
proceeded to investigate her terminal problem.

   The mainframe she uses recognizes several different flow control algorithms
for asynchronous terminals, although DC1/DC3 is the only one honoured under
most conditions.  The user's hardcopy terminal had a microswitch set to use
ACK/ETX protocol, so I switched it to use DC1/DC3.  Before I had changed the
position of the microswitch the terminal would have been sending ACKs to the
mainframe, which would have passed them through to its typeahead buffer. Now, I
knew that this user's logon was one of a large group which operate within a
more-or-less canned environment.  All users within this group share a set of
key bindings defined using a program called the Input Manipulation Processor
(which is aptly known as IMP for short).  I discovered (to my horror) that one
such IMP key binding mapped ^F (the ACK character) to the string 'DELETE'
followed by a carriage return. So what must have been happening is this:

   1. The  unfortunate  user enters the mail program and directs  it  to
      display a range of messages (this also has the effect of selecting
      them for further operations).

   2. At  some point the terminal's buffer is getting full,  so it  ACKs
      the mainframe to instruct it to stop sending for a while. This ACK
      is translated to  a  DELETE  command,  which  is  placed  into the
      typeahead buffer for processing. Meanwhile, the mainframe keeps on
      blasting data at the terminal.

   3. The terminal's buffer is overrun,  so many characters are lost and
      garbage is spewed  upon  the  paper.  Hidden  at  the  end of this
      garbled  mess is an illegible message informing the user that some
      of her email messages have been deleted, as "requested".

   This experience brings to light three RISKS.  First, it is risky to set up
naive users to have automagical key bindings of which they are unaware.  Such
users are not likely to understand the possible ramifications under unusual
circumstances (or even normal operation).  Second, destructive commands, such
as deletions not requiring confirmation, should not be bound to 'magic'
keystrokes such as PF keys, escape sequences and so on, for *any* user. This
just makes it too easy to cause irreversible damage with a typing mistake.
Finally, system-defined keystrokes are not a good place to start redefining
one's keyboard.  Communications control characters (DC1, DC3, ACK, etc.) and
interrupt keys (BREAK/ATTN, ^C or ^Y on many systems, etc.) should probably be
left alone.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
fear of flying?
</A>
</H3>
<address>
Daniel B Dobkin 
&lt;<A HREF="mailto:dbd@vx2.GBA.NYU.EDU">
dbd@vx2.GBA.NYU.EDU
</A>&gt;
</address>
<i>
Mon, 18 Apr 88 11:52:56 EST
</i><PRE>

The following is excerpted, without permission, from the May 1988 issue
of "Private Pilot" magazine:

  The problem of maintenance is sometimes aggravated by the occasional
  mechanic or technician who doesn't believe that any pilot can report symptoms
  accurately and therefore ignores whatever the pilot says.  I encountered
  this with an instrument years ago, when the technician flatly refused to
  believe what the instrument was doing.  Instead, he just assumed it was
  something else for which he performed some unnecessary repair and returned
  the instrument with the original defect still preseent.  This resulted in
  four separate attempts to correct the malfunction.  Admittedly, some pilots
  are not precise in their reports, an this naturally leads to some degree of
  skepticism on the mechanic's part, but in most cases a few questions and a
  little discussion will clarify the uncertainties.

  The most important way to avoid this trap is to tell the mechanic exactly
  what you observed, @i{without interpretation}.  There's plenty of chance to
  compare your conclusions with his after he knows what symptoms there are.
  If you tell a person your conclusion in advance, it can bias and channel his
  thinking into a particular problem, which may be incorrect and delay the
  ultimate resolution.

This was passed on to me by a friend who reports similar failures of
communication between the systems group and the data center operators; he
has been awakened at 4:30 too many times by operators who report their
analyses of the problem, rather than the clear, concise descriptions he
needs.  Of course, at that hour he is more likely to follow the operator's
erroneous logic at first, thereby prolonging his discomfort; during the day,
SOP is to reject the operator's conclusions and attempt to coax him into
describing the problem.
                                              \dbd

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     "Flight international" magazine about civil avionics
</A>
</H3>
<address>
L. Strigini 
&lt;<A HREF="mailto:STRIGINI%ICNUCEVM.BITNET@CNUCE-VM.ARPA">
STRIGINI%ICNUCEVM.BITNET@CNUCE-VM.ARPA
</A>&gt;
</address>
<i>
Mon, 18 Apr 88 18:00 SET
</i><PRE>

The April 16 issue of "Flight international" features a 4-page article
"Software versus the black box", about current trends in civil avionics
(software-based fly-by-wire, etc.).

There is much about the A-320 (partially critical: maintainance still
difficult, for instance), some discussion of the pros and cons of
innovation: e.g. some think multifunctional displays to be difficult to deal
with in emergencies, more software in fewer black boxes should simplify
maintenance (of the boxes) but increase complexity, etc.

On software diversity: comments by several people to the effect
that it is possible to build "a lot more" than in the past in software,
but "Software risk cannot be quantified in meaningful terms" (attributed
to Brian Tucker, GEC Avionics): hence the need to protect oneself
somehow. On the other hand, one of the managers in the Airbus
program is quoted as saying "Common mode failures are not possible"
("confidently" says the magazine. !!!).

Other topics: the huge costs of avionics maintainance and ways to deal
with it (redundancy, self-reconfiguration to keep aircraft
flying, automated diagnosis to help repair, expert systems - of course);
proposals to "increase" airport capacity by better precision
in arrival times of flights (computers making sure an aircraft fits
exactly in the time slot reserved for it).

It may make interesting reading for RISKS readers, in particular because it
is written for non-computer specialists with an interest in computer risks.
Final quote: "What the airlines want .. is avionics designed for
certification and operating profits - a discriminate use of new technology".
Worth considering in relation to the recent discussions about responsibility.

Lorenzo Strigini

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Another STARK investigation; faulty simulation implicated?
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Mon, 18 Apr 88 16:52:15 PDT
</i><PRE>

From IEEE INSTITUTE 12(5) May 1988 p. 1:

FRIGATE DEFENSE SYSTEM IS INVESTIGATED BY CONGRESS by John A. Adam

Apparently unsatisfied by US Navy reports, the Congress is investigating
the combat capability of FFG-7 class frigates - those similar to the USS
STARK.  The STARK failed to deter two Exocet missiles, fired by an Iraqi
fighter jet in the Persian Gulf May 17, 1987, that resulted in 37 deaths
and more than $100 million in damage to the ship. ...
The investigation was requested in November 1987 by Rep. Barbara Boxer
(D-Calif), a member of the House Armed Serviced Committee and its 
investigations subcommittee. ... (Much discussion of weapons systems 
under investigation...) 

(Former STARK captain Glenn R.) Brindel told THE INSTITUTE that the Navy
combat systems doctrine manual said both the SPS-55 surface search radar
and the SPS-49 air search radar should detect Exocets fired from aircraft
at ranges over 15 miles.  "That is just a bunch of baloney," he added.
It gave the persons in the ship's combat information center a false sense
of security, he said.  The Navy's reported to have found that the 
capability listed in the manuals, put out by the commanders of the Atlantic
or Pacific surace fleets to address the capabilities of each ship class 
against specific missiles, was "significantly overoptimistic."  Boxer's aide
says the GAO is investgating how these capabilities are derived.  Brindel
says much of the data for these manuals is based on simulations. ...

The NAVY TIMES, quoting an unnamed source, reported on March 28 that (in a 
live test) Exocets (obtained for testing) "popped up" and were detected 
briefly by the frigate's radar while they were at high altitude.  But
after the missiles swooped low over the wave tops and began homing in on
the ships, the frigate was unable to detect them. (This test occured before
the STARK attack.  Discussion followed of whether the fleet was informed 
of the test results).

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Ethnics and UCB (<A HREF="/Risks/6.63.html">RISKS-6.63</A>)
</A>
</H3>
<address>
Bob Ayers
&lt;<A HREF="mailto:ayers@src.dec.com ">
ayers@src.dec.com 
</A>&gt;
</address>
<i>
Mon, 18 Apr 88 09:52:03 PDT
</i><PRE>

    This is hearsay, so take it with a grain of salt, but I was told by a
    friend that he started filling the ethnicity slot on forms at UCB with
    "prussian".  This apparently did not default to "white".

Of course not. It defaulted to blue.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: More evidence for an old risk -- Enigma 
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 18 Apr 88 06:02:29 EDT
</i><PRE>

Those interested in this should probably also read Patrick Beesly's book
"Very Special Intelligence" (1977).  It's the story from the user end:
an account of the British Admiralty's Operational Intelligence Centre,
which was charged with putting intelligence information together into a
useful form for naval operations.  In particular, it was effectively the
nerve center for the Battle of the Atlantic.  It had a dedicated teletype
link to the Bletchley Park cryptanalysts.  Apart from the inherent interest
of the user's-eye view, most of what OIC did is declassified, unlike a lot
of the detailed doings of the cryptanalysts.

Concerning "probable word" attacks on ciphers, Beesly observes that a
possible factor in the success of the cryptanalysts was that situation
reports from weather aircraft were often sent to shore in relatively low-
security ciphers and then rebroadcast verbatim in the high-security naval
ciphers.  Later in the war the Admiralty had to make a substantial effort to
discourage the RAF from shooting down those aircraft, without revealing why!

He also sheds some light on the question of why the cryptanalysis was not
discovered.  The Germans did persistently suspect either treachery or
cryptanalysis.  Against the former they took increasingly elaborate
precautions.  The possibility of the latter was investigated not once but
several times.  Unfortunately, the investigation was always run by the
signals people themselves, and the conclusion invariably was that they
were not at fault, i.e. the ciphers were unbreakable.

The situation wasn't as obvious as people might think, also.  Encryption
keys changed daily, and the cryptanalysts were often two or three days
behind in finding the new ones.  Cryptanalysis was often incomplete. And
the Germans used increasingly-elaborate map codes for geographic locations,
meaning that a message was often hard to interpret even if cryptanalysis
was complete.  The result was that OIC had to work hard to put things
together with other intelligence reports (e.g. direction-finding and actual
sightings), and errors did creep in.  These errors showed, and made it
harder to see that cryptanalysis was involved.

(For the same reasons, Beesly has a low opinion of some of the popular
books on wartime cryptanalysis.  Some of them make it sound like the Allies
knew everything the Germans were doing, and if any Allied ships were lost,
it was because of Machiavellian scheming by Allied commanders.  Beesly
makes it clear that it just wasn't that simple.)

A contributing factor may have been something that Beesly mentions as a
problem with OIC:  because there were few people qualified, cleared, and
available to do the work, and the workload was heavy, and the atmosphere was
one of constant crisis, nobody ever really got a chance to stand back for a
while and think about the deeper implications of events.  Nobody was charged
with looking for things like signs of hostile cryptanalysis.  Only a lucky
hunch by a senior man would reveal such a situation.  The British got lucky:
early in 1943 the head of OIC, Rodger Winn, noted for his lucky hunches,
concluded (correctly) that the *Germans* were reading the *Allied* naval
ciphers, and made enough of a stink to get things done about it.  Evidently
none of his German counterparts ever had a similar stroke of insight.

Beesly's account also has something to say about the perils of becoming
obviously dependent on one information source.  OIC had little cryptanalytic
intelligence for most of 1942, because the Germans had changed ciphers
and the cryptanalysts took a long time to solve the new one.  The OIC
people decided to try to continue detailed tracking of all U-boats,
recognizing that there would be many more errors.  Many people thought that
this was silly and wasn't going to work.  In fact it worked moderately
well, and the skeptics were proved wrong, but only because Winn and others
insisted that this "obviously" ridiculous scheme was worth trying.

Henry Spencer @ U of Toronto Zoology   {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Re: DEC's recent security patch
</A>
</H3>
<address>
Darren Griffiths
&lt;<A HREF="mailto:dagg@Csa1.LBL.Gov ">
dagg@Csa1.LBL.Gov 
</A>&gt;
</address>
<i>
Mon, 18 Apr 88 16:42:34 PDT
</i><PRE>

This is a follow up to my recent article.  In the article I talked about
problems with the latest security patch from DEC.  In summary the problems
were caused by a fix to the TTDRIVER that helped stop trojan horse programs.
The fix, in some situations also broke the VAX Workstation Software, stopping
uses from autologging into a window.  Other things that were broken include
programs like PHOTO that use psuedo-terminal drivers to act as session loggers.

It seems that some of the programs that use psuedo-terminal drivers will
have to be modified before they will be able to work again.  This is
unfortunate, but it is necessary to provide extra security on VMS systems.
I believe DEC is planning to send out a letter describing these problems.

The problems with workstation software being broken can easily be fixed.
Patches to WTDRIVER.EXE and UISBG.EXE were distributed with the security
update, when these patches are installed the workstation software will work
as advertised with a secure TTDRIVER.  The problem is that the procedure
that checks to see if the workstation has VWS installed has a bug in it, and
it sometimes reports that the workstation software isn't installed when it
is.  If this happens the good software won't be installed and things will be
broken.  The easy fix is to look in the install save set for four images:

   WTDRIVER031.EXE;1   WTDRIVER032.EXE;1  
   UISBG031.EXE;8      UISBG032.EXE;1       

Take the ones appropiate for your versions and place them in
SYS$SYSTEM:WTDRIVER.EXE and SYS$SYSTEM:UISBG.EXE, that should fix things up.

I do encourage everyone to install these security fixes.  They ARE important
and they do help protect your system.  DEC has been getting a lot of flames
regarding their policy towards security issues, I am not sure that all of these
flames are deserved.  DEC engineers have spent a lot of time helping find this
problem, and they have always been eager to look for problems and suggest
solutions.  Before we go and flame DEC, why not spend some time flaming the
people (pond-scum?) who are trying to break into systems and wasting valuable
time and resources.  It is people like this who are the true cause of the
problem, not companies like DEC. 

I have heard comments recently that suggest it is the computer manager's
responsibility to maintain a secure environment for the users.  While this is
true it can only be taken so far.  It is reasonable to ask home owners to lock
their front door when they leave, it is not reasonable to ask them to hire
security guards and install a $10,000 alarm system.  At the same time it is
reasonable to ask computer managers to have a secure environment, it is not
reasonable to ask them to spend a good part of their life tracking down idiots
who persist on penetrating systems, particularly when the majority of these
systems have no useful or interesting information online.
                                                                  --darren

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.63.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.65.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-13</DOCNO>
<DOCOLDNO>IA012-000129-B045-50</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.65.html 128.240.150.127 19970217020738 text/html 22294
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:06:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 65</TITLE>
<LINK REL="Prev" HREF="/Risks/6.64.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.66.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.64.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.66.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 65</H1>
<H2>  Wednesday 20 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Creating Alternatives to Whistleblowing 
</A>
<DD>
<A HREF="#subj1.1">
Vin McLellan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Safety nets under falling bridges 
</A>
<DD>
<A HREF="#subj2.1">
Rob Horn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Datamation, 15 April 1988, on "Risk" 
</A>
<DD>
<A HREF="#subj3.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Poorly designed error messages 
</A>
<DD>
<A HREF="#subj4.1">
Bob Larson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RISKy Airline Meals 
</A>
<DD>
<A HREF="#subj5.1">
Mark Jackson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Response-time variability -- prior art 
</A>
<DD>
<A HREF="#subj6.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Security of OS: who is responsible? Klaus Brunnstein
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Israeli Viruses 
</A>
<DD>
<A HREF="#subj8.1">
Fred Cohen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Time-zone problem 
</A>
<DD>
<A HREF="#subj9.1">
Peter Webb
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Creating Alternatives to Whistleblowing
</A>
</H3>
<address>
"Vin McLellan" 
&lt;<A HREF="mailto:SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue 19 Apr 88 05:56:14-EDT
</i><PRE>

    On April 14, an MIT graduate student organization sponsored a 
forum on Ethics in Engineering and Science which turned into
a discussion of whistle-blowing: what can lead an engineer to
consider it, how it can be done, and how badly one can expect
to be punished for being the messenger bearing troublesome news.

    Sylvia Robins, the Rockwell software engineer from the space 
vehicle program who protested fraudulent and fudged testing, 
lack of required security, and contract featherbedding up the 
line within her company, Unysis, and then jumped into the 
hierarchy of the prime contractor, Rockwell, was a brisk, 
impressive, and inspiring example of the breed as she spelled 
out the difference between a salary hack and a self-respecting 
professional. 

    With lives and important missions at stake, she said, 
she couldn't and wouldn't participate in massive and normative
fraud. As a result, Robins said, she has been bugged, tapped, 
followed, slandered, had her property vandalized, and was subjected 
to repeated threats, even assaults. Robins' story has been reported 
in detail elsewhere (and recent federal charges seem to substantiate
many of her specific complaints) but she gave the MIT kids
a few thought-provoking bulletins from the real world.

    According to Robins, at Rockwell the Corporate Ombudsman and
the Corporate Ethics Office are both managed by the corporate
security staff -- the very thugs who apparently saw their duty
in orchestrating the campaign against her within and around the
company. (When she returned to her office after she finally went
public with her charges at a press conference, the walls at 
Rockwell closed in around her -- literally. The partitions that
shaped her workspace had been moved to crowd her desk: she
could reach out, seated at her desk, and touch both sides of the
room.) 
 
    Lone messengers really do get the shaft, she said, no
matter how real or accurate their complaints -- although sometimes,
even so, a woman has to do what is right. Robins said she now 
realizes that many engineers unexpectedly find themselves confronted 
with major ethical issues on the job; in the past six months, she 
said, some 160 engineers have contacted her for advice in how to deal 
with such situations in their work. Among her bitter lessons, 
she said, was that anyone caught in her position should try to 
build a consensus among peer engineers and, if at all possible, 
to present major complaints in a group petition. A whole department
is harder to ignore, slander, or ostracize. For a lady with a rep
for a carbon steel spine, her suggestions and attitudes were 
politically savvy and not confrontational.

    Beside the pert matronly Robins, a slouched yet looming 
presence on the MIT stage was fellow panelist Ralph Nader. 
(Astonishingly, this was only the third time in 15 years that 
Nader -- still probably the leading critic of poor and unsafe
engineering knowingly foisted upon the public -- had been
invited to speak at MIT.)  While the planning of the forum left
much to be desired, in that Nader was given only 20 minutes to
address a crowd largely drawn by his name, his sardonic and 
bitter humor brought an edge to what had been a sometimes 
blithering panel. After paying warm homage to the courage and
honor of Ms. Robins -- and worrying aloud how many of the students 
before him could have survived the brutish campaign Robins
endured -- Nader left the podum with an interesting observation,
almost a challenge, to both the students and career engineers. 
 
  In the mid-1970s, he noted, rising concern over social issues 
among law students was directly reflected in the sort of questions
the students asked of the corporations which sought to recruit them
from the campuses. And those questions, he said, quickly and quite
directly shaped the image of themselves the major law firms
learned to project -- and were soon reflected in the work practice 
of the best law firms themselves, those most successful in recruiting
top students. Specific questions about the amount of time a law 
firm committed to pro bono legal work, for example, *introduced*
the practice of pro bono work in many large law firms. 

    If engineering is truly a profession, with minimal standards 
of technical prowess and personal integrity to be upheld, said Nader,
engineering students could similarly have a major impact on 
corporate behavior by asking about specific policies and practices
which could protect a dissident or worried professional within a 
corporate setting, perhaps guarrantee him or her a hearing (before 
engineering peers, in matters of technical or professional integrity)
when immediate corporate superiors were hostile or unsympathetic.

   A lawyer, albiet one skilled in corporate infighting, Nader 
couldn't go into details for his suggestion. RISKS, however, is 
an unusual forum that reaches deeply into academic, corporate, 
and government engineering. Could we hear some suggestions for those
students? What questions could be asked?  What corporate structures 
and/or procedures could guarrantee an honorable engineer who confronts
an issue of ethics on the job a viable alternative to the 
self-sacrifice of public whistle-blowing? 

Vin McLellan
The Privacy Guild       (617) 426 2487
Boston, Ma.             

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Safety nets under falling bridges
</A>
</H3>
<address>
Rob Horn 
&lt;<A HREF="mailto:BBN!ulowell!infinet!rhorn@husc6.harvard.edu">
BBN!ulowell!infinet!rhorn@husc6.harvard.edu
</A>&gt;
</address>
<i>
Mon, 18 Apr 88 21:30:21 est
</i><PRE>

Brian Urquhart wrote

  ``I believed then, as most conceited young people do, that a strong
  rational argument will carry the day if sufficiently well supported by
  substantiated facts.  This, of course, is nonsense.  Once a group of
  people have made up their minds on something, it develops a life and
  momentum of its own which is almost impervious to reason or argument.''

This belief was based on his experience as intelligence officer prior to the
Arnhem attack and in the UN where he reached Under-Secretary General.  It is
relevant to risks because engineers seem to fall into the perenially young
category in their faith that evidence can change decisions.

Most of the discussion of whistle-blower protection etc. make as much sense
as putting a safety net under a poorly engineered bridge.  It may help
reduce injuries but it ignores the more fundamental problem.  The problem is
that momentum is built up in the system beyond the point where a decision
can be reversed.  This is inherent in Feynman's and others' complaints about
the Challenger disaster.  The problem is not the O-rings, it was that the
momentum to launch was allowed to get so strong.  This was clear for months
prior to launch.  Aviation Week was full of stories about rushed schedules,
botched work, confusion, fatal and near fatal accidents.  Yet no one could
stop the launch.

When a system has reached this point disaster is inevitable.  All you can do
is try to soften the blow.  Yet the focus of debate here and elsewhere is on
issues that arise too late.  When the system has reached the point that a
whistle-blower needs protection you are already past the point of no return.

Much more important, but much harder, is understanding the human decision
and organizational structures that lead to this momentum.  How do you
destroy this overwhelming force to completion without destroying the will to
succeed?
		Rob Horn, Infinet, 40 High St., North Andover, MA
...harvard!adelie!infinet!rhorn	...ulowell!infinet!rhorn ..decvax!infinet!rhorn

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Datamation, 15 April 1988
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com">
minow%thundr.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
19 Apr 88 16:00
</i><PRE>

The cover article is on "Risk."  "When you become dependent on any resource,
you become more vulnerable."   Martin.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Poorly designed error messages
</A>
</H3>
<address>
Bob Larson
&lt;<A HREF="mailto:blarson%skat.usc.edu@oberon.USC.EDU ">
blarson%skat.usc.edu@oberon.USC.EDU 
</A>&gt;
</address>
<i>
Tue, 19 Apr 88 00:33:02 PDT
</i><PRE>
Organization: USC AIS, Los Angeles

The message in a recent RISKS about starting from false assumptions when 
someone gives you their conclusions rather than the symptoms (which I
assume many of us have discovered the hard way) got me thinking about
how the bad conclusions are reached.

Primos has a "standard" error message "Access Violation".  On a number of
occasions, people come to me (as the local primos "guru") asking me to help
me find the file they can't access when they get this message.  The error
message is used exclusivly for MEMORY access violations.  (This is one of
several messages that usually indicate a bad pointer.)  File messages
include "insufficent access rights" and "not found" to cover files that
can't be opened due to insufficent access rights.

While not a huge error, this poorly designed error message has probably
caused many man-months of time wasted looking for the wrong problem.

Bob Larson  blarson@skat.usc.edu  {sdcrdcf,cit-vax}!oberon!skat!blarson

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
RISKy Airline Meals
</A>
</H3>
<address>
&lt;<A HREF="mailto:MJackson.Wbst@Xerox.COM">
MJackson.Wbst@Xerox.COM
</A>&gt;
</address>
<i>
19 Apr 88 07:50:52 EDT (Tuesday)
</i><PRE>

The following is from the letters column of the "Travel" section of the
April 17 /New York Times/.   Mark

  To the editor:

  The perils of ordering special meals on airline flights cannot be
  overlooked.  A while back we traveled from Fort Lauderdale to Detroit with
  Delta Airlines and ordered a cold seafood plate instead of the regular meal.
  Delta responded with a hot seafood plate.  We wrote them a letter to
  complain and they apologized.

  However, since then we have been on three morning Delta flights where
  breakfast was served.  Each time we were brought a cold seafood plate.  We
  did not want it.  We did not order it.  Somehow, our name has gotten into
  the computer, and every time we fly we get the cold seafood plate.

  The last time it happened, the flight attendant referred to us as "Mr. and
  Mrs. Seafood" instead of Mr. and Mrs. Stanton.

 					Roger Stanton, Grosse Pointe, Mich.

/A spokeswoman for Delta Airlines replies:/

  There are two codes that can be used to tell the computer that a request for
  a special meal has been made, one for a specific flight, the other for all
  flights a passenger might take.  In Mr. Stanton's case, the agent apparently
  used the wrong code.  That has now been corrected.  We encourage passengers
  to request special meals at the time the flight reservation is made, but it
  can be done up to three hours before flight time for most meals, eight hours
  for kosher meals.  Passengers should specify whether they want a standing
  order or a one-time-only order.

                [At 35,000 feet, on a clear day you can seafood forever,
                especially if you are standing -- or Stanton.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Response-time variability -- prior art
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
19 Apr 88 09:55
</i><PRE>

The recent re-invention of response-time variability reduction techniques
forced me to dig out an article I published in an obscure journal in 1977.
In the Decus Proceedings vol. 4, no. 2, I wrote a long article on system
performance and usability.  To quote:

    One example of a simple method to improve the way a system seems
    to perform is illustrated by the program segment [as follows]:
	100 PRINT "Prompt";
	200 INPUT request
	300 start = [get time of day]
	400 ... Calculate result ...
	500 elapsed = [time of day] - start
	600 IF (elapsed &lt; 5) THEN sleep(5 - elapsed)
	700 PRINT result
    ... This has several implications:
    -- Response times are less dependent on system load.
    -- The operator learns when to expect a response from the system
 	and thus is able to build a rhythm by knowing when to look
	back at the terminal.
    -- The system response degrades more slowly.  If the actual response
	time varies from one second to six seconds, the operator will
	see only a one-second variation, instead of an almost five-
	second variation.
    ...
    In general, your programs should be written so that the operator
    feels that "they're always there;" that they will always do something
    reasonable in a resonable time.  Early computers often had loudspeakers
    attached to some part of the CPU.  The operator heard what was happening:
    how far the production run ahd progressed, when it was about time to
    change tape reels.  ...

    In all cases, try to keep the feeling that the system "listens" to
    the operator at all times, and -- especially -- "tells" the operator
    what is happening.

I don't claim originality for these ideas: I was taught them by the
customers I supported in Sweden in the early 1970's.  I guess my mistake was
not wrapping them inside some theoretical framwork ("System usability and
implications for the eight queens problem") and publishing them in CACM.  Of
course, if I did so, the people who needed the information might not have
seen it.
                                    Martin.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Security of OS: who is responsible?  (<A HREF="/Risks/6.64.html">RISKS-6.64</A>) 
</A>
</H3>
<address>
&lt;<A HREF="mailto:Klaus Brunnstein">
Klaus Brunnstein
</A>&gt;
</address>
<i>
19-Apr-88 07:45:48-PDT
</i><PRE>

In his information how to cope with an error in DEC's Kid Install software
for its recent security update for Vax Workstation Software, Darren compares
the security of an operating system to a house.  Inhabitants are, according
to his example, themselves responsible to prohibit thieves from easy access
by just using their keys and locks.

Unfortunately, the example is misleading: while every `user' of a house
knows about access and how to control it, complex operating systems have so
many doors that nobody can understand the diverse control techniques. While
house are designed, as socio-technical systems, according to a
user-understandable model, an operating system is designed as a technical
system without virtually any reference to users concepts. 

In this situation, the designers responsibility to guarantee a `safely
usable operation system' (especially when a design or programming error is
probable) cannot so simply be transferred to the users (also in the case of
non-benevolent users). I therefore greet DEC's activities to provide better
professional standards in dealing with security updates.

Klaus Brunnstein, University of Hamburg, Fed.Rep.Germany

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Israeli Viruses
</A>
</H3>
<address>
Fred Cohen
&lt;<A HREF="mailto:fc@ucqais.uc.edu ">
fc@ucqais.uc.edu 
</A>&gt;
</address>
<i>
19 Apr 88 02:18:53 EDT (Tue)
</i><PRE>

I should point out that I wrote the research papers that detailed the class
of methods proposed for detecting viruses by the Isreali team - they were
published in Computers and Security in 1987 - the checksums I have seen are
fairly easy to forge, but even the very strong ones like the one I published
can be broken given enough time. They are a "Complexity Based Integrity
Maintenance Mechanism" (the name of one of those papers).  Indeed, I suspect
that I could still write a virus that they could not detect, as I have done
considerable research into the topic and understand the underlying
mechanisms. I should note that the source code for such a high quality
checksum is to be published in the April issue of C+S, so you'd better take
all the cash you can get right away, before the public finds out they can
get the same or better protection for free. - FC

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
time-zone problem                
</A>
</H3>
<address>
Peter Webb
&lt;<A HREF="mailto:webb@applicon.COM ">
webb@applicon.COM 
</A>&gt;
</address>
<i>
Fri, 15 Apr 88 10:30:17 EDT
</i><PRE>

	I have learned that Telnet announced, on April 7, that everyone who
uses its Electronic Bulletin Board service should ignore any and all bills
for daytime usage, from Sept 1987 to Feb 1988. Apparently, calls to Telnet are
often automatically re-routed by the local phone company.  In some cases the
calls are forwarded to an exchange in a different time zone than that of the
originating user.  Under the correct circumstances, ie a user dialing in less
than an hour after night/evening rates go into effect and having his or her 
call forwarded to a node in a time zone at least one hour earlier, this can
lead the Telnet system to believe the call was placed during daytime
hours, and to consequently bill the user at daytime rates.  The problem is
excaberated by Telnet's policy of billing an entire session at daytime rate
if any part of it occurs during daytime hours

				Peter Webb.

{allegra|decvax|harvard|yale|mirror}!ima!applicon!webb, 
{mit-eddie|raybed2|spar|ulowell|sun}!applicon!webb, webb@applicon.com

     [Again!  This has happened to the competition as well.  If it wasn't so
     late and I wasn't commuting to the Security and Privacy meeting, I'd
     dig up three or four previous cases in RISKS.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.64.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.66.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-14</DOCNO>
<DOCOLDNO>IA012-000129-B045-79</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.66.html 128.240.150.127 19970217020756 text/html 21823
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:06:21 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 66</TITLE>
<LINK REL="Prev" HREF="/Risks/6.65.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.67.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.65.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.67.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 66</H1>
<H2>  Thursday 21 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risk of parolee database that is out of date 
</A>
<DD>
<A HREF="#subj1.1">
Robert White
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Lap-Tops, etc. in final exams -- a common-mode fault 
</A>
<DD>
<A HREF="#subj2.1">
Andrew Duane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Airline Risks 
</A>
<DD>
<A HREF="#subj3.1">
David R. Hampton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Another ATM story 
</A>
<DD>
<A HREF="#subj4.1">
Dave Fiske
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  More on HP benchmark story: how it might have been avoided 
</A>
<DD>
<A HREF="#subj5.1">
Tom Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Mongrelism 1:  Fuzzy concepts lead to fuzzy decisions 
</A>
<DD>
<A HREF="#subj6.1">
Les Earnest
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Mongrelism 2:  Genetic Classification and the Urge to Merge 
</A>
<DD>
<A HREF="#subj7.1">
Les Earnest
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of RISKS -- textual tampering 
</A>
<DD>
<A HREF="#subj8.1">
Doug Claar
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risk of parolee database that is out of date
</A>
</H3>
<address>
&lt;<A HREF="mailto:ncar!scicom!qetzal!rcw@rutgers.edu">
ncar!scicom!qetzal!rcw@rutgers.edu
</A>&gt;
</address>
<i>
19 Apr 88 16:31:43 MDT (Tue)
</i><PRE>

The failure of the Colorado Department of Corrections to keep an on-line
listing of parolees up to date on the Colorado Bureau of Information computer
system is a very real threat to the safety of the public. Law enforcement
agencies access this list when arrests are made or when giving traffic
citations.

The threat is real, and I have first hand experience with it.  My brother was
murdered in January, 1986 in the early evening at a grocery store where he was
working.  The previous day, the perpetrator was stopped for a routine traffic
violation.  The CBI computer did not reveal his parolee status at that time,
nor did it reveal that he was wanted on charges of shoplifting, assault, and
armed robbery in other counties of the state.

The officer suspected something was awry, but was powerless to do anything for
want of probable cause.  The officer even went so far as to call the Department
of Corrections.  My brother was dead two days before the clerk finally returned
his call.

It turns out that the state is approximately six months behind in their data
entry tasks, and have been so for at least the past five years. It strikes me
that such a database is next to useless, and is an example of a project that is
better funded properly or funded not at all.

Robert White       ihnp4!upba!qetzal!rcw

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Lap-Tops, etc. in final exams -- a common-mode fault
</A>
</H3>
<address>
Andrew Duane X5993
&lt;<A HREF="mailto:decvax!cg-atla!duane@ucbvax.Berkeley.EDU ">
decvax!cg-atla!duane@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Tue, 19 Apr 88 14:18:33 edt
</i><PRE>

Back in High School (1975 to be exact), calculators were not too common, and
PROGRAMMABLE ones almost non-existant. Nonetheless, there was one student in my
Advanced Chemistry class that owned an HP-35 programmable.  The teacher finally
decided to let us share it during the exam. We quickly adopted the following
strategy: the first student would work out the solution to the first problem,
storing all relevant intermediate results in the memories. He or she would pass
it to the next student, who would copy the results, and tackle the next
problem.  Additionally, several "important" formulas had been preloaded onto
certain entry points. After two rounds about the room, we had finished all the
problems. Our downfall: a common one to RISKS readers. Someone had made a
rather stupid mistake on a problem, and we all had copied it!

Andrew L. Duane (JOT-7)  w:(617)-658-5600 X5993  h:(603)-434-7934
Compugraphic Corp., 200 Ballardvale St., Wilmington, Mass. 01887		

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Airline Risks
</A>
</H3>
<address>
"David R. Hampton" 
&lt;<A HREF="mailto:Hampton@DOCKMASTER.ARPA">
Hampton@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 20 Apr 88 07:42 EDT
</i><PRE>

The following article is taken from the Huntington, WV Herald Dispatch
from Friday April 15th, 1988.  It is, as always, reprinted without permission.

          BLAST RIPS JET IN MIDAIR, BUT IT LANDS SAFELY
          By Kelly P. Kissel, Associated Press

  CHARLESTON- An engine on a Piedmont airlines jet exploded Thursday, sending
debris tearing through the walls.  The pilot wrestled the craft under control
and made an emergency landing in Charleston.  A passenger said there was a
hole "big enough that I could crawl through it."  The explosion caused the
Fokker F-28 jet, which was flying at 31,000 feet, to lose pressure.  Some
oxygen masks didn't work, two passengers said.  Two stewardesses suffered
minor injuries when the plane plunged after the explosion, officials said.
Flight 486, which carried 56 passengers and a crew of four, was flying from
Charlotte, N.C., to Columbus, Ohio, when it's right jet turbine disintegrated
about 9:45 a.m., Piedmont officials said.  [...]

  Turbine blades and engine parts ripped all the way through the plane,
leaving holes on both sides.  A hole on the right side, next to the
engine that disintegrated, was 2 feet wide and 6 feet high.  On the
opposite side, the hole was 2 feet by 1 foot.  [...]

  The Piedmont spokesman said he didn't know when the engines had been checked
last but said there was no reason to suspect a problem.  "Our engines are
maintained by computer.  If there's a problem incipient in them it would show
up," McGuire [the spokesman] said.  "That's why we were suprised."  He said
the rest of the plane, including the oxygen masks, is checked in the same
manner and that complaints about some inoperable masks would be investigated.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Another ATM story
</A>
</H3>
<address>
Dave Fiske
&lt;<A HREF="mailto:davef@brspyr1.brs.com ">
davef@brspyr1.brs.com 
</A>&gt;
</address>
<i>
Tue, 19 Apr 88 16:08:45 est
</i><PRE>

Here's an interesting ATM problem I once encountered.  I don't think
I've seen anyone else mention this one.

Once, when trying to make a withdrawal, the machine proceeded normally,
until it got to the part where the lid to the money-dispensing bin is
supposed to open.  It didn't and wouldn't.  Because my transaction had
seemed to take place, I called the bank the next morning to make sure
the withdrawal hadn't beed debited from my account.  The person I spoke
to checked, and said everything was okay with my account, and explained
that what caused the problem was that, prior to my attempted
transaction, someone must have forgotten to take their money from the
bin.  Apparently the system is programmed to lock up the bin, obviously
to keep anyone else from taking the cash, but it seemingly performs all
transactions properly.

This is somewhat interesting, since apparently the system designers had
anticipated the possibility that someone might forget to take their
money (a situation which strikes me as so absurd that I probably would
have overlooked it), but chose a rather confusing response for it.
Confusing in that all legitimate users following the flawed transaction are
uncertain what happened and whether or not their transactions were
completed or not, and therefore undoubtedly generating a number of
calls to the bank.  It's not enough to anticipate a situation--the
appropriateness of the response, given human nature and expectations,
is important, too.

Dave Fiske (davef@brspyr1), BRS Information Technologies, Latham, NY

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
More on HP benchmark story: how it might have been avoided
</A>
</H3>
<address>
&lt;<A HREF="mailto:Tom.Lane@ZOG.CS.CMU.EDU">
Tom.Lane@ZOG.CS.CMU.EDU
</A>&gt;
</address>
<i>
Wed, 20 Apr 88 09:05:45 EDT
</i><PRE>

In RISKS 6.58, I told a story about how failure tolerance kept some HP
salespeople from noticing that the floating point coprocessor in a demo
machine was dead; this led to some very embarrassing benchmark results for a
potential customer.  Here's some additional info that might be of interest.

Jeffrey R Kell (&lt;JEFF@UTCVM.bitnet&gt;) wrote me:
&gt;I'm not sure of what system the benchmark was on, but on the newer RISC-based
&gt;machines the operating system checks to see if a coprocessor is "present"
&gt;or not; I suppose a "broken" one might appear "absent" as well.

Yes, that's also true on the older HP Series 300 machines that I'm familiar
with.  Those machines are "self-configuring", which means that at powerup
the boot ROM runs around and finds how much memory is plugged in, what
interface cards and coprocessors are present, etc; then it tests them all.
The boot ROM displays a list of the selftest results, and things that have
been detected but fail the selftest are prominently marked.  If something is
sufficiently broken that the boot ROM doesn't even see it, the only
notification you get is that it doesn't show up in the selftest list.
The list isn't there long since the ROM then proceeds to load an operating
system.  If you aren't paying attention when you turn the machine on (which
most people aren't...) you lose.  Presumably this is what happened to the HP
salespeople above.

Some of the even earlier Series 200 machines had a provision for dealing
with that problem too.  The 200s had a small PROM which was custom-burned
for each machine, containing the computer serial number.  There was also
provision for the PROM to contain a list of attached equipment; the boot ROM
could then check to make sure that it had found everything that was supposed
to be there.  Unfortunately HP decided that the custom PROMs added too much
to manufacturing cost.  (I believe, though, that the necessary code is still
in the Series 300 boot ROM; so a determined person could program his own
PROM, put it on a breadboard interface card, and plug it in.)

The PROM was also treated as a piece of optional equipment, so if it died
the machine would still boot, but you would lose this protection...

I don't know whether any such provisions exist in the newer Series 800
machines, which were the culprits in my original tale.
                                  				tom lane
UUCP: &lt;your favorite internet/arpanet gateway&gt;!zog.cs.cmu.edu!tgl
BITNET: tgl%zog.cs.cmu.edu@cmuccvma

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Mongrelism 1:  Fuzzy concepts lead to fuzzy decisions  
</A>
</H3>
<address>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</address>
<i>
17 Apr 88  1907 PDT
</i><PRE>

Some people found the mongrel stories amusing, some found them educational,
and at least one person found them disturbing, apparently because they
made fun of deeply held beliefs.  So be it.

I regret to report that I have three more things to say on this topic [here
and following].  I really do hope that we can put this to bed soon.  In
fact, if the discussion continues unabated I will shortly propose the
formation of newsgroup comp.race to discuss the computational aspects of
race determination.  I offer here a preview by showing the current
theoretical basis for the field, which can be stated in a single line:
									.

I particularly enjoyed reading the insightful remarks of John Mainwaring
in comp.risks 6:60 and the educational humor of Will Martin in 6:61.

In comp.risks 6:61, David Thomasson says:
&gt; "Apparently believes...probably believes" -- more Straw Men. In fact, I
&gt; believe that virtually everyone can be put into some racial category that is
               ^^^^^^^^^
&gt; very useful for purposes of identification, even though such categories are
&gt; not biologically precise. As for the rest of the above, Earnest's argument 
&gt; has gone to the dogs.
This is cute, but very evasive.  Thomasson neglects to identify the exceptions
to "virtually?"

In the same article, Thomasson later remarks:
&gt; In my experience, "race" has been roughly equivalent to "color of
&gt; skin" in police work. So, while it's true that "race" is biologically
&gt; imprecise (even incorrect), those who use race for identification purposes
&gt; aren't concerned about biology . . .
Here he finally comes to grips with reality.  We are left to wonder why
the police don't use skin color for identification, given that they don't
understand biology.

		"Black" and "White" are Relative

Nearly all of the people in the U.S. who call themselves Black are
genetic mixtures of African and European peoples.  Because our culture
is predominently European, anyone who has detectably African features is
called "Black," even if they are genetically, say, 7/8 European.  If we were
a predominently African country, these same people would likely be called
"White" because they have detectably European features.  In other words,
current racial classifications are made relative to the "norm," which
makes them intrinsically subjective and rather unreliable.

However, it will shortly be possible to make unambiguous racial classifications
as discussed in the next posting.
                                        	Les Earnest

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Mongrelism 2:  Genetic Classification and the Urge to Merge 
</A>
</H3>
<address>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</address>
<i>
18 Apr 88  0217 PDT
</i><PRE>

Given that the human genetic code is now in the process of being unravelled,
it should soon be possible to classify people into racial groups in a
meaningful way.  One way to do this, once we can reliably disassemble the
code for any given person, is to define various racial standards in terms of
this code, such as a standard Negro, a standard Caucasian, a standard
Chinese, etc.  Of course, some people will want to carry this a step further
and define a standard Texan or even a standard South Philadelphian.

Once we choose a set of standards, then everyone can be classified as being
members of the racial group whose standard is closest to their own genetic
code.  The Hamming Distance between pairs of codes would be a reasonably
good measure of genetic distance.  That is, given that genetic codes are
base 4, we could simply count the number of differences in the base 4 code
string.

Thus, after we get over the argument over which are the standard races, it
should be possible to assign everyone unequivocally to a racial group,
except for the rare individuals who happen to be _exactly_ halfway between
the two closest standards.

While this wonder of future science will support nearly unequivocal racial
classifications, it clearly will not be useful for visual identification.
In fact, I can't think of anything that it _would_ be good for, other than
providing a formalized basis for bigotry.  For purposes of individual
identification, the person's full genetic code will be far more useful.

			The Urge to Merge

Whether or not we solve the problem of racial discrimination and conflict
through education and political action, human biology will probably solve it
for us in the long run.  Recent studies indicate that if there are no more
major influxes of foreign populations into the U.S., distinguishable racial
groups will essentially disappear in this country within 300 years because
of "the urge to merge."  In other words, the U.S. is destined to become a
nation of mongrels.

This likely will be disappointing to white supremicists and black activists,
who will _both_ soon be members of shrinking minorities.  In fact, they may
be already.  I predict that new rallying cries will be heard as the mongrels
become the majority -- maybe things like "Beige is Beautiful."

	Les Earnest

P.S. With respect to the "urge to merge," I can report that my family is
doing its share.  One of my sons, Mark, lives in Alaska and is married to
a Yupick Eskimo lady named Cathy Lincoln.  (She also has a Yupick name
that sounds something like attempting to clear your sinus while spitting
out an ingested bee.)

Mark is generally well received in Eskimo communities, though he
occasionally encounters some prejudice.  They call him a "gussack" which
has about the same meaning there as "gringo" does further South.
"Gussack" is a Yupick word that was derived about two centuries ago from
the Russian word "cossack."  You can imagine how that came about.

Mark and Cathy have three beautiful little mongrels, who can look forward
to participating in the (hopefully) peaceful overthrow of the WASP
group that has run this country for the last 400 years.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
risks of RISKS -- textual tampering              [de-ment-ia praecox]
</A>
</H3>
<address>
Doug Claar 
&lt;<A HREF="mailto:dclaar%hpda@hplabs.HP.COM">
dclaar%hpda@hplabs.HP.COM
</A>&gt;
</address>
<i>
Tue, 19 Apr 88 13:52:49 pdt
</i><PRE>

In our copy of RISKS DIGEST 6.60, occurrences of "ments" have been replaced
with "&lt;newline&gt;&lt;newline&gt;w". Several examples have been captured below. Makes
interesting reading!
                       [I have edited together from 4 messages from Doug.  PGN]
   -------
     Re: Discrimination and careless argu
   
   ws!es Earnest)
   -------
   Quebecers should know that government depart
   
   w and agencies have millions
   -------
   The databanks, half of which are computerized, are held by 26 depart
   
   w and
   -------
   Interim chairman Therese Giroux said these depart
   
   w may face legal action if
   -------
   helmet to an electronic device that monitors his eye move
   
   w.  Presuhn, 33,
   -------

The editing 'improvement' changes midway through the article on Pilotless
combat planes to replacing "ment" with "&lt;newline&gt;ent" once, and then slips 
back in towards the end of the digest!

I wonder, does your copy have the little #! rnews 682 on the end? This might
be a clue as to who de-ment-ed our copy...             [NO, NOT MINE!  P.]
   
Doug Claar, HP Information Software Division
UUCP: { ihnp4 | mcvax!decvax }!hplabs!hpda!dclaar -or- ucbvax!hpda!dclaar
ARPA: dclaar%hpda@hplabs.HP.COM

                     [Anyone want to take the blame for this "ment"al lapse?  
                     No one else has reported it yet.  Could Doug's terminal 
                     have been Trojan horsed?  Could have been serious.
                     Your deportment might have gotten you deported. PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.65.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.67.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-15</DOCNO>
<DOCOLDNO>IA012-000129-B045-104</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.67.html 128.240.150.127 19970217020811 text/html 22142
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:06:36 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 67</TITLE>
<LINK REL="Prev" HREF="/Risks/6.66.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.68.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.66.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.68.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 67</H1>
<H2>  Sunday 24 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Prestel case concluded 
</A>
<DD>
<A HREF="#subj1.1">
Peter Dickman
</A><br>
<A HREF="#subj1.2">
 M. Douglas McIlroy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Mysterious British Death Toll at 10 -- another computer engineer dead 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  SDI feasibility and the OTA report 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Trustworthiness of time-stamps 
</A>
<DD>
<A HREF="#subj4.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  KAL 007 once again
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Military Aircraft Crashes in Germany 
</A>
<DD>
<A HREF="#subj6.1">
Michael Wagner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  BIX Ad (Risks of US Mail)  
</A>
<DD>
<A HREF="#subj7.1">
Fred Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  "Momentum" of engineering projects 
</A>
<DD>
<A HREF="#subj8.1">
Charles H. Buchholtz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Viruses at Customs 
</A>
<DD>
<A HREF="#subj9.1">
Robert Slade
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Viruses -- SCIENCE and Computers&amp;Society 
</A>
<DD>
<A HREF="#subj10.1">
Howard Israel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  RISK! in Datamation 
</A>
<DD>
<A HREF="#subj11.1">
Jim Horning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Re: Engine explosions due to overspeed, crew stupidity    [Unverified]    
</A>
<DD>
<A HREF="#subj12.1">
Joseph Nathan Hall
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Prestel case concluded
</A>
</H3>
<address>
Peter Dickman 
&lt;<A HREF="mailto:pwd%computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK">
pwd%computer-lab.cambridge.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
24 Apr 88 01:08:39 +0100 (Sunday)
</i><PRE>
Organisation: University of Cambridge Computer Laboratory

Overseas readers of the article below should note that:

The House of Lords is the final court of appeal as well as (the unelected)
half of the legislature in the UK. Five 'Law Lords' (usually ex-judges and
the like) will sit in judgement on cases that get that far.

Legal precedents can be set in the courts when it comes to interpreting the
law, hence Lord Lane's comments in what follows: the judges can decide if
the existing Forgery Acts apply to passwords etc but cannot spontaneously
make up a new law to cover the problem in question.

Prestel is a dial-up electronic mailing system.

The Duke of Edinburgh is Prince Philip (the spouse of the Queen) - this case
therefore gained some notoriety, at the time, in the tabloid press because of
its 'Royal connection'.   [And the mailbox was not really his private
mailbox, but rather a demonstration mailbox for him, according to private
communication to PGN from someone at Prestel.]

              = = = = = = = = = = = = = = = = = = = = = =
Reprinted without permission from 'The Guardian', London 22 April 1988:

COMPUTER HACKERS WIN TEST CASE

  The House of Lords yesterday ruled that the two computer "hackers" who broke 
into British Telecom's Prestel computer information service were not guilty of 
forgery.
  In what was regarded as a test case, five Law Lords unanimously upheld a 
Court of Appeal ruling that accountant Stephen Gold and computer magazine 
editor Robert Schifreen had gained access to the data bank by a "trick" which
was not a criminal offence.
  Mr Gold, of Watt Lane, Sheffield, and Mr Schifreen, of Edgeware Gardens, 
Edgeware, North-West London, had used micro-computers to gain entry to Prestel 
computers in 1984.
  They made unauthorised alterations to data and charged account-holders
without their knowledge.
  Mr Schifreen was said to have got into the Duke of Edinburgh's Prestel 
messages file and left messages. "They were not terribly interesting," he 
said. They were mostly about the birth of Prince William.
  Lord Brandon of Oakbrook said: "Their object in carrying on these activities 
was not so much to gain any profit for themselves as to demonstrate their 
skill as hackers. It never occurred to them that they might be committing any 
offence under the Forgery and Counterfeiting Act, 1981." In the Appeal Court, 
Lord Lane, the Lord Chief Justice, had said: "Their conduct amounted in 
essence to dishonestly gaining access to the relevant Prestel data bank by a 
trick. That is not a criminal offence. If it is thought desirable to make it 
so that is a matter for the legislature rather than the courts."
  Lord Brandon said that he shared Lord Lane's view that the prosecution was
an attempt to "force the facts of the case into the language of an act not
designed to fit them."
  The men had been convicted of nine offences at Southwark crown court in
1986.  Last year they successfully overturned that ruling.
  Lords Keith of Kinkel, Templeman, Oliver and Goff agreed in dismissing the 
prosecution's appeal against the Court of Appeal's ruling.
  Afterwards Mr Schifreen said: "I knew from the start that the Forgery Act is 
not designed to apply to unauthorised access to computers."

</PRE>
<HR><H3><A NAME="subj1.2">
Prestel case concluded
</A>
</H3>
<address>
&lt;<A HREF="mailto:doug%alice@research.att.com">
doug%alice@research.att.com
</A>&gt;
</address>
<i>
Sun, 24 Apr 88 08:40:18 EDT
</i><PRE>

                   [Doug McIlroy happened to be in London that day.  
                   Here are some excerpts from his message.  PGN]

London Times, Page 1, April 22:

  The courts held that the prosecution had to prove that the hackers had
  made a "false instrument" which they intended to pass off as genuine.
  But this thesis was absurd because one and the same machine served as
  both instrument and dupe.  [Turing hoist on his own petard.] The facts
  of the case did not fit the language of the act.  The two hackers had
  wanted to prove their skill, rather than to gain any benefit.

The Times also observed that hacking for gain or to inflict damage can be
construed as an offense, such as fraud or malicious damage, and that a
commission is studying whether a bill is needed to stop hacking for amusement.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Mysterious British Death Toll at 10 -- another computer engineer dead
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Sun 24 Apr 88 15:41:02-PDT
</i><PRE>

The total is now 10 of British scientist involved in defense work who have
died under mysterious circumstances in the past two years.  Russell Smith, 23,
assistant scientific officer at ultrasecret UK Atomic Research Energy Plant in
Harwell, was ruled to have killed himself on 2 February 1988 by jumping from a
cliff.  Trevor Knight, 52, was found dead in his car in March 1988.  He worked
for the Marconi defense firm, as did several of the previous dead scientists.
Most of the 10 mysterious deaths resembled suicides, but only three cases were
actually ruled so by inquests.  [Source: San Francisco Chronicle, 22 April
1988, p. A30.  Previous cases were noted in earlier RISKS.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
SDI feasibility and the OTA report
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Sun 24 Apr 88 15:28:43-PDT
</i><PRE>

Today's Washington Post and AP wires have some more info on the unpublished
congressional report that the system would likely "suffer a catastrophic
failure" the first time (and only) time it was used.  The OTA report cautioned
that the sheer complexity suggested that "there would always be unresolvable
questions about how dependable ... (the computer) software was."

... "extrapolating from past experience ... it appears to OTA that the 
complexity of (ballistic missile defense), the uncertainty ... of the
requirements it must meet, and the novelty of the technology it must control
would impose a significant probability of software-induced catastrophic failure
in the system's first real battle."  (The Post, quoting the report) 

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Trustworthiness of time-stamps
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Sun 24 Apr 88 17:02:24-PDT
</i><PRE>

In a classical asynchronous-attack scam (somewhat similar to the time-of-check-
to-time-of-use [TOCTTOU] perpetrations), fourteen postal employees and three
associates in NY City were accused of using insider knowledge to postmark their
envelopes on time in the 1987 Super Bowl "Pick the Score" contest, and then
stuff in the actual final score: NY Giants 39, Denver 20.  Only 167 entries had
the exact score, and at least 107 of those came from insiders.  Selected
randomly from those entries, there were 14 contest winners -- 8 of whom
apparently won through fraudulent means, collecting $85,000 out of the $100,000
awarded.  The tip-off came when the $50,000 grand prize winner had a fight with
her postal employee boyfriend, and reported the scam.  [Source: New York Times,
20 April 1988, p.1] The implications on the opportunities to fake on-line
computer time-stamps are self-evident.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
KAL 007 once again
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Fri 22 Apr 88 10:52:27-PDT
</i><PRE>

The 9 April 1988 issue of the Washington Post carried a news item on the
shoot-down of KAL Flight 007.

A KAL pilot said that the pilot of the downed plane may have been the indirect
victim of his autopilot computer.  He asserted that KAL pilots had previously
been reprimanded for having to return to their take-off point to correct an
autopilot error.  This involved an expensive fuel dumping in each case.

The autopoilot is designed so that if one of its three computers disagrees, or
the crew enters the trip coordinates (start and ending) incorrectly, the
aircraft must return to its starting point (!!) so that the data can be
re-entered.

It has been suspected that the pilot of KAL 007 entered incorrect course data,
but did not take action to correct the error, so as to avoid punishment.

  [For those of you new to this problem, the most plausible theory thus
  far seems to be that the copilot had inadvertently left the autopilot
  set on HDG 246 instead of switching to INERTIAL when passing over the 
  outbound checkpoint, at which point they should have changed course.]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Military Aircraft Crashes in Germany
</A>
</H3>
<address>
Michael Wagner +49 228 8199645 
&lt;<A HREF="mailto:WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU">
WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri, 22 Apr 88 14:30
</i><PRE>

I haven't seen this reported in RISKS, so I thought I'd pass it along.  In the
last 3 weeks, 3 military aircraft have crashed in Germany.  All were
practicing low-flying maneuvers at the time.  Two were F-16s; one was a
Mirage.  The press says that, in each case, a much worse disaster was only
narrowly avoided (I can't judge how accurate this is).  The crashes occured
just down the flight path from:  a nuclear generating station, a munitions
dump, and an inhabited village.  It seems that many air forces use the Eiffel
and Hunsruck areas (not far from me, actually, as the jet flies!) as practice
areas for low-flying missions (presumably because it's so challenging).  The
German government is reported to be considering disallowing or restricting
such flights in future.

In all, 35 military aircraft have fallen out of the skies here since 1960.  I
have no idea how this compares with other countries.
                                                            Michael

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
BIX Ad (Risks of US Mail)
</A>
</H3>
<address>
Fred Baube 
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Fri, 22 Apr 88 14:07:11 -0500
</i><PRE>

I just got an offer in the mail to try BIX. The mailing includes
a BIX login name, in the same impression as my name and address,
so I presume the login name is associated with me.  They say that
should I cancel, I'll be billed only for access time.

What's to stop someone from fishing the card out of the trash ?  if I use
the offer, can I claim that as an excuse not to pay ?  These are familiar
issues I'd think, it's just that the delivery system they use is prone to
abuse.  I do not believe that I am under any obligation to shred, burn, or
otherwise render unreadable unsolicited mail.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
"Momentum" of engineering projects
</A>
</H3>
<address>
Charles H. Buchholtz
&lt;<A HREF="mailto:chip@eniac.seas.upenn.edu ">
chip@eniac.seas.upenn.edu 
</A>&gt;
</address>
<i>
Fri, 22 Apr 88 18:33:53 edt
</i><PRE>

Rob Horn brought up an interesting issue when he spoke of the momentum that
a project gathers, which prevents it from changing direction when objections
are raised.  I have an understanding with my supervisors which, among other
things, serves as a governor on a projects momentum.

When I first begin working, I (metaphorically) give my supervisor a number
of tokens, "good for one emergency each".  My supervisor also receives
tokens at a given rate per year.  One token is "spent" each time I am asked
to do something outside usual practice.  "It's an emergency! Can you come in
on the weekend and finish it?" - one token.  "I know it's not clean, and not
documented, but we need a fast and dirty fix!" - one token.  The theory is
that occasional emergencies are unavoidable, but constant emergencies are
poor planning; the tokens provide a method of determining which is the case.
On a few occasions my supervisor has decided, "it's not such an emergency,
after all", to save the token for a *real* emergency.

The number of tokens provided, and the definition of an "emergency", can vary
according to the company and individuals involved.  I have noticed that this
system motivates supervisors not to make commitments that can't be met without
"cutting corners".
                                        ---Chip

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Viruses at Customs
</A>
</H3>
<address>
Robert_Slade@mtsg.ubc.ca 
&lt;<A HREF="mailto:Robert_Slade@mtsg.ubc.ca@um.cc.umich.edu">
Robert_Slade@mtsg.ubc.ca@um.cc.umich.edu
</A>&gt;
</address>
<i>
Wed, 20 Apr 88 07:43:16 PDT
</i><PRE>

I am still working on the virus file (cf volume 6 number 45).  It is now longer
than 360K and so will be archived and shipped with a copy of PKXARC (if you
use it etc.)  However, the means of distribution to the States is through
my wife, who runs a theological college in Vancouver.  American mail is
stamped with US postage and taken to border towns in Washington where some
of the American students live and work.  Often there are challenged at the
border as to what they are carrying.
 
What with all the concerns over technology transfer and so forth, I can just
see the conversation between the hapless student (my wife told him he was
carrying a file of virus material) and the customs agent ("...you're trying
to bring *what* into the country?")  If some of you don't get your disks
back, contact customs and immigration.  (Come to think of it, we haven't
seen Russ since he took that last set of disks down last week...)

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
 Viruses 
</A>
</H3>
<address>
Howard Israel 
&lt;<A HREF="mailto:HIsrael@DOCKMASTER.ARPA">
HIsrael@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Mon, 18 Apr 88 18:11 EDT
</i><PRE>

There is an article in "SCIENCE", Vol 240, 8 April 1988, pg 133-4 (News &amp;
Commentary Section) by Eliot Marshall about viruses:  "The Scourge of
Computer Viruses".  This article among other things, says that "Computers &amp;
Security" April issue is devoted to the subject of viruses.

AT&amp;T Bell Laboratories, Whippany, NJ

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
RISK!   [DATAMATION -- more]
</A>
</H3>
<address>
Jim Horning
&lt;<A HREF="mailto:horning@src.dec.com ">
horning@src.dec.com 
</A>&gt;
</address>
<i>
19 Apr 1988 1457-PDT (Tuesday)
</i><PRE>

The cover of the April 15, 1988 DATAMATION features the teaser "RISK! A new,
potentially dangerous element has been introduced into global markets and
businesses.  The very same information systems that have enabled both to
flourish in the 1980s could cause them to perish in the '90s.  In a world of
highly distributed pc power, complex networks, and database systems, risk has
become the third factor in the IS equation."  The cover story itself ends with
"If you think today's vulnerabilities are going to be tough to cope with, wait
until tomorrow."  [...]
                                              Jim H.

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Re: Engine explosions due to overspeed, crew stupidity    [Unverified]
</A>
</H3>
<address>
Joseph Nathan Hall
&lt;<A HREF="mailto:jnh@ece-csc.ncsu.edu ">
jnh@ece-csc.ncsu.edu 
</A>&gt;
</address>
<i>
Sun, 24 Apr 88 20:54:07 EDT
</i><PRE>

I don't have the particulars of the following event, although I could probably
come up with them if necessary ...

I remember hearing a story about a cockpit wager where one member of the
crew asserted that the autopilot got its engine speed (or something similar)
info directly from the speed sensor, while another member of the crew disagreed
and said that the autopilot got its info from the RPM gauge circuit.  They
decided to test this out in flight (this was a commercial airliner) by
shutting off one of the RPM gauges at the breaker ...

Sure enough, the autopilot got the message that the engine had slowed down
dramatically (to 0 RPM) and so it increased fuel flow.  Shortly the
engine oversped and stalled, blew up, and sent a blade through the cabin.
The story goes that everything went fine until a woman began screaming 
hysterically, saying that the man who had been sitting next to her in the
window seat had just *vanished*, seatbelt and all, through the 1-1/2 foot
hole in the cabin wall ...

The details probably aren't correct -- it's been a while since I heard
this -- but the spirit of the thing is.
                                               	-joseph hall

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.66.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.68.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-16</DOCNO>
<DOCOLDNO>IA012-000129-B045-129</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.69.html 128.240.150.127 19970217020830 text/html 22225
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:07:00 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 69</TITLE>
<LINK REL="Prev" HREF="/Risks/6.68.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.70.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.68.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.70.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 69</H1>
<H2>  Monday 25 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Social INsecurity 
</A>
<DD>
<A HREF="#subj1.1">
Kenneth R. Jongsma
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks in momentum 
</A>
<DD>
<A HREF="#subj2.1">
Robert Adams
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  BIX Ad (Risks of US Mail)  
</A>
<DD>
<A HREF="#subj3.1">
Henry Mensch
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  At the tone, leave your message at your own risk 
</A>
<DD>
<A HREF="#subj4.1">
Mark Mandel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A shortie on color blindness 
</A>
<DD>
<A HREF="#subj5.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Suicidal bandwagon 
</A>
<DD>
<A HREF="#subj6.1">
Geraint Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  YAVR (Yet Another Virus Report) -- "Scores" 
</A>
<DD>
<A HREF="#subj7.1">
Fred Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Requests for advice to the U.S. Congress on viruses 
</A>
<DD>
<A HREF="#subj8.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  National Policy on Controlled Access Protection 
</A>
<DD>
<A HREF="#subj9.1">
Chris McDonald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Accountability 
</A>
<DD>
<A HREF="#subj10.1">
Henry Spencer
</A><br>
<A HREF="#subj10.2">
 Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Searching for interesting benchmark stories 
</A>
<DD>
<A HREF="#subj11.1">
Eugene Miya
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Social INsecurity
</A>
</H3>
<address>
&lt;<A HREF="mailto:portal!cup.portal!Kenneth_R_Jongsma@Sun.COM">
portal!cup.portal!Kenneth_R_Jongsma@Sun.COM
</A>&gt;
</address>
<i>
Thu Apr 21 17:29:16 1988
</i><PRE>

The following is excerpted from the April 11 issue of Business Week article
entitled "Social Security's Big Surplus Was Just a Mirage".

Only a few weeks ago, Social Security experts were afraid Congress might use
the mounting surplus of the retirement system's trust fund to cut payroll taxes
or raise benifits...  [Some discussion on how new projections say there won't
be a surplus.]  In addition, Social Security Actuaries have found that a flawed
computer program overstated projected receipts.  [Followed by discussion on
what needs to be done.]

No additional detail was provided on what the nature of the computer flaw was.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks in momentum
</A>
</H3>
<address>
&lt;<A HREF="mailto:demo%somewhere%littlei.UUCP%reed.UUCP%reed%tektronix.tek.com@RELAY.CS.NET">
demo%somewhere%littlei.UUCP%reed.UUCP%reed%tektronix.tek.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Fri Apr 22 11:52:52 1988
</i><PRE>
Organization: Intel Corp., ISO Systems Development, Hillsboro, OR

In RISKS 6.65 , Rob Horn &lt;BBN!ulowell!infinet!rhorn@husc6.harvard.edu&gt; writes:
&gt; Much more important, but much harder, is understanding the human decision
&gt; and organizational structures that lead to this momentum.  How do you
&gt; destroy this overwhelming force to completion without destroying the will to
&gt; succeed?

	I have several times considered writing one of those single topic books
entitled "Momentum Mangement".  Within any business organization, one
must both manage the momentum of the group (reactive) and direct the
group by creating and directing its momentum (proactive).

	"Momentum management" would not only be useful in business.  We didn't
get Michael Jackson T-shirts, coffee mugs, and TV trays just because
he was a good performer.  Everyone jumped on the bandwagon and the
momentum increased.  This happens in everything: art, music, UNIX\(tm,
X Window System\(tm, space shuttle, &lt;your project here&gt;.

	What is the risk in all this?  As has been said many times before in
RISKS, there are dynamics to the whole system that must be managed as
closely as the operation of the parts.  The archives of this digest are
full of examples of systems that failed due to some overall dynamic
even though all of the components of the system operated correctly.

	-- Robert Adams     	...!uunet!littlei!adams


</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
BIX Ad (Risks of US Mail) 
</A>
</H3>
<address>
Henry Mensch
&lt;<A HREF="mailto:henry@GARP.MIT.EDU ">
henry@GARP.MIT.EDU 
</A>&gt;
</address>
<i>
Mon, 25 Apr 88 02:45:23 EDT
</i><PRE>

If I'm correct there is no risk here, since any unsolicited
merchandise which you receive via the US Mail can be considered a
gift.  Of course, this won't stop them from trying to collect :(

Henry Mensch  E40-379 MIT, Cambridge, MA
                      {ames,cca,decvax,rochester,harvard,mit-eddie}!garp!henry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 At the tone, leave your message at your own risk
</A>
</H3>
<address>
Mark Mandel 
&lt;<A HREF="mailto:Mandel@BCO-MULTICS.ARPA">
Mandel@BCO-MULTICS.ARPA
</A>&gt;
</address>
<i>
Mon, 25 Apr 88 09:02 EDT
</i><PRE>

Last week I called someone with an important message, to call a third
person.  He wasn't at his desk and a secretary took it, along with my name
and number.  A few moments later she called me back and said, "I'm sorry,
but I was typing your message in, and when I hit ENTER it erased the name
and number of the man he was supposed to call.  Would you give them to me
again, please?"  Obviously she was using a computer-based message system, or
at least a word processor.  What would she have done if she'd lost MY name
and phone number as well?
                             [Have you ever not had a call returned?  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 A shortie on color blindness
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@ames-nas.arpa">
eugene@ames-nas.arpa
</A>&gt;
</address>
<i>
Mon, 18 Apr 88 13:38:17 PDT
</i><PRE>

On color blindness, first I am not color blind, but an interesting prank
was fulled years ago at Caltech.  There is an infamous signal for a pedestrian
only crossing for California.  Why wait?  The undergrads reverse the red and
green filters.  Held traffic up a long time.  People crossed all the time.
Note: this would not have worked with color blind drivers (mostly male)
who use light position.

%T The Legends of Caltech
%A Available on request, my copy is at home.
%I
%D

--eugene miya

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Suicidal bandwagon
</A>
</H3>
<address>
Geraint Jones 
&lt;<A HREF="mailto:geraint%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK">
geraint%prg.oxford.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Mon, 25 Apr 88 21:20:16 BST
</i><PRE>

PGN (RISKS 6.67)  has picked up on another couple of deaths in Britain.  So now
you know that we are mortal.
    Does anyone happen to know how many people in Britain do (slightly defence-
related)  work with computers,  and how likely someone between twenty and fifty
and in that  sort of job is to die a violent death?  I do not know the figures,
but I cannot help  feeling that the  only thing that is  obviously  significant
about these deaths is that  there has been a spate of press reports about them.
    There is a `programmed trading' effect in newspaper stories too,  or hasn't
anyone else noticed  that that which is  `news' tends to be  that which is like
what was news yesterday.
                                                                             gj

[ btw, for the benefit of the San Fransisco Chronicle, the only thing that is
   `ultrasecret' about AERE Harwell is which buses one must catch to find it. ]

      [Someone else commented to the effect that the number 10 was probably 
      about average...  What made the first 8 strange was that almost all 
      involved people related to one set of projects and one company, within
      a short period of time, and were described in the press as potentially
      simulated suicides.  Given the supposed secrecy of the projects, it
      could be difficult to get much in the way of real details.  Sure,
      someone is indeed trying to sell newspapers, and this story is certainly
      grist for the would-be conspiracy theorists.  I thought it might be 
      worth noting here as a follow-up.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Requests for advice to the U.S. Congress on viruses
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 25 Apr 1988  20:16 EDT
</i><PRE>

A part of the Defense Authorization Bill for FY 1989 is likely to direct the
Defense Department to report to the Congress on what it has done and plans to
do in order to cope with viruses in computer systems belonging to or used by
the DoD.

I am the Congressional staff person assigned to work this issue for the House
Armed Services Committee.  What should I insist that the report cover?

Herb Lin        e-mail LIN@XX.LCS.MIT.EDU      phone (202) 225-7740

House Armed Services Committee, 2120 Rayburn House Office Building,
Washington DC  20515

All replies will be kept in confidence.
    
     [Herb, I hope the identities of the replies will be kept in confidence,
     but not the replies themselves!  And I hope that it will cover Trojan
     horses and flawed operating systems, not just viruses.  Actually, the
     National Computer Security Center's Orange Book does provide some help.

     RISKS readers, please respond to Herb.  I would expect that he might 
     wish to anonymize the replies and get some feedback from you all.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
YAVR (Yet Another Virus Report) -- "Scores"
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Mon, 18 Apr 88 16:26:40 -0500
</i><PRE>
From: Fred Baube &lt;fbaube@note.nsf.gov&gt;

"New `Virus' Infects NASA Macintoshes"
Washington Post, Mon 18 Apr 88, excerpted without permission

This reports a new virus at NASA offices in DC and other locations around
the country. Apple Conputer and the federales are trying "to track down the
virus' creator".

This one is called "Scores" and has not erased any data, but can cause
"malfunctions in printing and accessing files", "difficulty in running
Macintoshes' drawing program", and frequent crashes.

"The Scores virus can be detected by the altered symbols [in] Scrapbook and
Note Pad. Instead of the Macintosh logo, the user would see a symbol that
looks like a dog-eared piece of paper.  Two days after the virus is
transmitted, it is activated and begins to randomly infect applications .."

EDS saw the same virus a few weeks ago but isolated and eradicated it.
"Like most major corporations, EDS is reticent about discussing its ways of
fighting these viruses for fear that the creators will only modify the
program to avoid detection."
                                 [Sorry this is a week old.  
                                 It slipped through the crack.  PGN]

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
National Policy on Controlled Access Protection
</A>
</H3>
<address>
Chris McDonald  STEWS-SD 678-2814 
&lt;<A HREF="mailto:cmcdonal@wsmr10.ARPA">
cmcdonal@wsmr10.ARPA
</A>&gt;
</address>
<i>
Mon, 18 Apr 88  8:41:20 MST
</i><PRE>

I just received a copy of NTISSP No. 200, issued 15 July 1987--our pony express
takes a long time to get to New Mexico.  The policy applies to executive branch
agencies and departments of the Federal Government and their contractors who
process classified or sensitive unclassified information in automated
information systems.

Essentially the policy states:  "All automated information systems which are
accessed by more than one user, when those users do not have the same
authorization to use all of the classified or sensitive unclassified
information processed or maintained by the automated information system, shall
provide automated Controlled Access Protection for all classified and sensitive
unclassified information.  This minimum level of protection shall be provided
within five years of the promulgation of this policy."  The policy then defines
"Controlled Access Protection" as equivalent to the C2 level of protection
defined in the "Trusted Computer System Evaluation Criteria" or Orange Book.

Since I received the NTISSP after the passage of the Computer Security Act of
1988 (HR-145), I was wondering if the application of the NTISSP to
"unclassified systems" has been deferred or whether we in DoD are to implement
the policy as stated.

Thanks, Chris                                       White Sands Missile Range

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Accountability
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 20 Apr 88 10:45:56 EDT
</i><PRE>

&gt; ... more indicative of a social failure than a true RISK ... because it's
&gt; about the failure of a chain of command to control the situation.

I would diagnose it differently, unless you mean this in the broadest possible
sense.  The problem is not that the people on top are not properly in charge;
the problem is that the people on top do not *WANT* to be held responsible
for results (or lack thereof).  The more complex the organization, the
easier it is to point fingers at someone (anyone) else, until responsibility
is so diffused that nobody is ever really to blame when something goes wrong.

Particularly in that sort of setup, it is important to supply incentives
for doing it right that affect the whole organization rather than specific
individuals.  (Note that I am addressing pragmatic tactics here, not right
versus wrong.  I believe very strongly in individual responsibility, but
when dealing with, say, Morton Thiokol, it's not an easy notion to enforce.)
Major reductions in cash flow tend to get everyone's attention.

&gt; -That cash is the only effective incentive for producing results is the 
&gt; ultimate disaster of our times...

While I agree that it's an undesirable situation, I feel compelled to point
out that it's not a problem of "our times"; historically, life has always
been cheap.  Society has, on the whole, become considerably *more* humane
in recent times.

Henry Spencer @ U of Toronto Zoology    {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<HR><H3><A NAME="subj10.2">
re: Accountability
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Wed, 20 Apr 88 13:29:51 PDT
</i><PRE>

Several observers have suggested that something about computers - maybe
the way they are employed in organizations, maybe something intrinsic in
the way the interact with people's thoughts and feelings - tends to
diffuse accountability and makes people feel less responsible for the
consequences of their actions.  This view is expressed most eloquently
by Joseph Weizenbaum in his book COMPUTER POWER AND HUMAN REASON, WH Freeman,
1976.  In an interview with Marion Long in the LA TIMES' WEST magazine
supplement, (Jan 19, 1986, p. 4) Weizenbaum said,

"The dependence on computers is merely the most recent - and most extreme -
example of how man relies on technology in order to escape the burden of
acting as an independent agent; it helps him avoid the task of giving
meaning to his life, of deciding and pursuing what is truly valuable."

- Jon Jacky, University of Washington

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Searching for interesting benchmark stories (RISKS of benchmarking)
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@ames-nas.arpa">
eugene@ames-nas.arpa
</A>&gt;
</address>
<i>
Fri, 22 Apr 88 11:54:58 PDT
</i><PRE>

I just saw Tom Lane's posting on benchmarking [<A HREF="/Risks/6.66.html">RISKS-6.66</A>], and it caught me
by surprise.

When hardware is delivered, we (users) expect it to run, and we also expect it
to run well.  The problem is when something runs badly there is a lot of finger
pointing and a tendency to "kill the bearer of bad news."  I present two
examples.

We had a supercomputer here for a while (now at another site) that is one
of those "vector architectures": supposed to run fast on vectors.  I was
running some simple tests, and I swore that it was running in the slower scalar
mode.  I approached the system folks, and sure enough for some reason, the
system libraries had been compiled into significantly slower scalar code.
They quickly recompiled the stuff and "we were back in business."
The machine is now at another site, but running a different OS.

In another case several years ago, I was running on one of the new generation
mini-supercomputers.  I noticed a strange behavior of a program. Pass 1
took time X, pass 2 took time 2X (twice as long), pass 3 took 3X.  Apparently
others had noticed this problem, I thought it was a compiler problem, and
it turned out to be a cache (hardware) problem.  (rectified)

Benchmarking at this "level of the stratosphere" can literally make or break
companies.  The NBS (and a few others) collect benchmarks, but they don't
collect benchmark results for fear of liability.  Linpack, the LLNL loops, and
the Dhrystone are exceptions.  The problem is (unlike Boisjoly) that these are
not all or nothing situations.  Sure, the program runs, it produces correct
(and sometimes incorrect) results.

Oh, a third example came to mind.  Years ago, I was working to understand what
made network protocols run.  As young-un, I had oldsters tell me: it's the
bandwidth of the wire for high speed (Mb/S) networks.  I believed them.  They
didn't know what they were talking about: turns out to be memory (the operating
system specifically).

We tend to assume a lot about our machines without rigourous testing.  I also
notice that functional testers usually don't include performance measurements.

On other forms of performance evaluation:
I have to admit that I am not a fan of queueing theory when it comes to
measuring the predicted performance of computer systems.  I also realize
I'm not alone.  My approach is empirical, similar to how cardiologists
look at cardiograms.  (Show me [something useful].)

I am willing to collect interesting benchmark stories like Tom Lane's.
"it's not enough that it run, it has to run in the right ways" stories.
I'm uncertain the best way to do this.  A single posting won't be enough.
So the audience is welcome to send me interesting stories, and I will
collect them.  In cases where I can, I will try to verify them.
I wish to avoid "popular" stories like the DO-loop.

--eugene miya, NASA Ames Research Center, eugene@ames-aurora.ARPA
				soon to be aurora.arc.nasa.gov
  {uunet,hplabs,hao,ihnp4,decwrl,allegra,tektronix}!ames!aurora!eugene

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.68.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.70.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-17</DOCNO>
<DOCOLDNO>IA012-000129-B045-151</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.70.html 128.240.150.127 19970217020844 text/html 27670
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:07:10 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 70</TITLE>
<LINK REL="Prev" HREF="/Risks/6.69.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.71.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.69.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.71.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 70</H1>
<H2>  Tuesday 26 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
KAL007 and Bourland's Electronic Warfare Theorem 
</A>
<DD>
<A HREF="#subj1.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Powerhouse Patrons Behind ID Tokens 
</A>
<DD>
<A HREF="#subj2.1">
Vin McLellan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Virus Sores and Scores 
</A>
<DD>
<A HREF="#subj3.1">
John Norstad via Vin McLellan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Britain launches software safety study 
</A>
<DD>
<A HREF="#subj4.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Yet Another UnTimely Risk 
</A>
<DD>
<A HREF="#subj5.1">
John S. Quarterman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  A slight correction... on Harwell 
</A>
<DD>
<A HREF="#subj6.1">
Mike Salmon
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Computer Viral Center for Disease Control? 
</A>
<DD>
<A HREF="#subj7.1">
TMPLee
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
KAL007 and Bourland's Electronic Warfare Theorem
</A>
</H3>
<address>
Clifford Johnson 
&lt;<A HREF="mailto:GA.CJJ@forsythe.stanford.edu">
GA.CJJ@forsythe.stanford.edu
</A>&gt;
</address>
<i>
Mon, 25 Apr 88 23:06:55 PDT
</i><PRE>

   A KAL pilot said that the pilot of the downed plane may have
   been the indirect victim of his autopilot computer.
     [For those of you new to this problem, the most plausible theory thus
     far seems to be that the copilot had inadvertently left the autopilot
     set on HDG 246 instead of switching to INERTIAL when passing over the
     outbound checkpoint, at which point they should have changed course.]

I contest the summary characterization of the inadvertent setting of the
autopilot as a "the most plausible theory thus far" to explain KAL007's winding
course.  My honest opinion is that the most plausible explanation of all the
facts is that the route was calculated to stimulate Soviet radars for
intelligence gathering purposes.  To this day there has been no public
congressional investigation into the KAL007 incident, even though the Air Force
irregularly destroyed radar tapes of the flight, and even though Japanese tapes
of the incident, et alia, strongly indicate that the course of KAL007 was
deliberate.  A statutorily required investigation by the National Transport
Safety Board was inexplicably cancelled, documents lost, and gag orders placed
on all civilian employees.

See Shootdown, Viking (1986), by R.W.  Johnson, for a thorough review of the
astonishing evidence that KAL007 was in fact on an espionage mission.  He
carefully *eliminates* the accidental autopilot setting theory, and all other
seriously-taken specific navigational-error hypotheses.  If you haven't heard
of KAL015's bizarre duplicity, or of the deceptive maneuvers shown on Japansese
radar tapes, you haven't begun to understand the weight of affirmative evidence
that KAL007's route was wilful. Books like Hersch's on the subject are silly to
dismiss the espionage hypothesis in a footnote, while simply ignoring such
evidence.

As for my main point re the autopilot explanation, KAL007's route was more
"organic" than linear, with in-flight course changes, including remarkable
curves, each of which would have had to have been mistakenly made in order for
the autopilot error explanation to hold.  This is a case where the
characteristics of the several course "errors" do not conform, in a basic
sense, to the characteristics of computer error.  In particular, the 246 degree
fix simply does not account for KAL007's route.  This hypothesis is not "most
plausible," it's not even a possible explanation.  True, a pressured and
hopelessly understaffed international inquiry, before the release of most of
the still pitiful evidence now published, concluded that the 246 degree
hypothesis provided a possible explanation of the incident, but this was an
illogical (and apparently political) statement, so plainly untrue that the
international pilots' organization took the trouble to formally denounce the
assertion.

Perhaps computer professionals likewise have a responsibility to make it clear
that the hypothesis is woefully insufficient, and amounts to little more than
an application of the convenient Electronic Warfare Theorem:  "If possible, get
an expensive electronic device (i.e. a computer) to make a decision; if the
decision turns out to be wrong, one of its tape units can be disconnected and
two programmers fired in retribution."  (Bourland, "Non-Decision Theory",
Memorandum to the Director of Research, DOD, Dec. 1961.) In conjunction with
all the other facts, Occam's razor forces me to prefer the espionage
hypotheses, at least until the Congress publicly investigates the incident.  In
the meantime, I think it is objectively clear that all the
autopilot-error-cum-sleeping explanations that have done the rounds are all
fatally inadequate.  If we suggest that such explanations are plausible, or
seek only the "least implausible" sequence of snafus, we may erroneously
squelch the rightful reasonings of those who will continue, against the
political odds, to press for a public inquiry.

As for the "new" hypothesis that the tardy realization of error caused a
continuation of the erroneous course, this fails to account for the fact that
KAL007 suddenly swooped, late in its course, even further into Russian
territory, rather than away from it, as would have been the obvious reaction
upon discovery of error.  Nor was this due to panic, for even at the last
KAL007 radioed its position in perfectly normal tones, even reporting, quite
casually, in its last moments, that it had ascended to a new altitude, whereas
*three* Japanese radars indicated that KAL007 completed a steep dive before
making this final false report.  (This followed upon consecutive false position
reports for KAL007 that had been relayed by the follow-on flight KAL015,
despite an order from a ground controller that KAL007 should report its
position directly.)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Powerhouse Patrons Behind ID Tokens
</A>
</H3>
<address>
"Vin McLellan" 
&lt;<A HREF="mailto:SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue 26 Apr 88 03:05:13-EDT
</i><PRE>

      A new venture in token-based ID authentication -- and a hint of a broad
new thrust in EDP security -- has emerged with the first product from the
Applied Information Technologies Research Center, a little-known R&amp;D consortium
organized in 1984 by a number of universities and leading U.S. vendors of
information service products.

     AITRC, in Columbus, Ohio, about to beta test a credit card-sized
calculator which impliments a challenge-response ID authentication. A software
module on a host CPU sends a 7-digit challenge to a remote terminal, the user
keys that number into his "calculator," presses a special authentication button
to process that number (and a token-specific seed) through a one-way crypto
algorithm -- then reads off the 7-digit response code on the calculator's LCD
screen. That number, transmitted to the host, verifies the token as one issued
to a specific user.

    Tokens (also called "hand-held password generators") are said by IBM to
increase the certainty of end user authentication by at least a full order of
magnitude over mere passwords.  Tokens impliment the second of the three ID
authentication options (something known, something held, something inherent to
the user) and have drawn rising interest as the relative frailty of classic
password systems becomes apparent and risks proliferate.

    The two leading vendors, Security Dynamics in Cambridge, Ma., and Sytek of
Mountain View, Ca., are NSA-certified -- so their tokens can be integrated into
access control systems for secure DoD computers -- and SD last week obtained a
GSA scheduled contract which allows no-bid purchases by federal agencies.  But
the AITRC development may mark tokens even more forcefully as the future
direction for the industry.

    AITRC is jointly funded by CompuServ, Meade Data Central, Chemical
Abstracts, the Online Computer Library Center and John Wiley &amp; Sons; as well as
Carnegie Mellon University, University of Pittsburgh, Wright State University,
Ohio State, the Ohio State University Research Foundation, BDM Corp., and
Batelle Institute.  No lightweights there.

      AITRC hopes to see licensed token/calculators marketed at $10 apiece
by the end of this year, according to AITRC president George Minot --
although the members of the AITRC consortium could potentially use and offer
them to their clients for even less, he said, since consortium members get
royalty-free access to the technology.

     At $10 per unit, AITRC would revolutionize the pricing of tokens --
which currently range between four and ten times that for comparable
devices. Minot conceeded, however, that projected price is based on high
volume production (minimum100,000) overseas.  The AITRC token is built upon
the 4-bit NEC calculator chip, works as a standard calculator, and is
powered by a 2-year lithium battery.  According to Minot, the device is also
designed to be "initialized," or registered on the host, from any remote
terminal or push button telephone.

Vin McLellan, The Privacy Guild, Boston, Ma.              (617) 426-2487

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Virus Sores and Scores
</A>
</H3>
<address>
"Vin McLellan" 
&lt;<A HREF="mailto:SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue 26 Apr 88 03:36:16-EDT
</i><PRE>

Relayed from:
INFO-MAC Digest         Saturday, 23 Apr 1988      Volume 6 : Issue 40

From jpd@eecs.nwu.edu Mon Apr 18 10:11:09 1988
Subject: The Scores Virus
Date: 18 Apr 88 16:11:09 GMT

My colleague Bob Hablutzel got a copy of the Scores virus last Thursday and
disassembled it, and I've been studying and testing it ever since. So far I've
reverse-engineered about half the code and have a thorough understanding of how
it works.  This note is a preliminary report on what I know so far, after four
days of research.  It also outlines plans for a disinfectant program.

The virus is definitely targeted against applications with signatures VULT and
ERIC.  I don't know if any applications with these signatures exist or are
planned to be released.

The virus infects your system folder when you run an infected program.

The virus lies dormant for two days after your system folder is first infected.
After two, four, and seven days various parts wake up and begin doing their
dirty work.

Two days after the initial infection the virus begins to spread to other
applications.  I haven't completely finished figuring out this mechanism, but
it appears that only applications that are actually run are candidates for
infection.

After four days the second part of the virus wakes up.  It begins to watch for
the VULT and ERIC applications.  Whenever VULT or ERIC is run it bombs after 25
minutes of use.  If you don't have a debugger installed you'll get a system
bomb with ID=12.  If you have MacsBug installed you'll get a user break.

After seven days the third part of the virus wakes up.  Whenever VULT is run
the virus waits for 15 minutes, then causes any attempt to write a disk file to
bomb.  If you don't do any writes for another 10 minutes the application will
bomb anyway, as described in the previous paragraph.  There's also more code to
force a bomb after 45 minutes, but I can't see any way that this code can be
reached, given the forced bomb after 25 minutes.

The virus identifies VULT and ERIC by checking to see if the application
contains any resources of type VULT or ERIC.  Applications with signatures VULT
and ERIC normally contain these resources, but other applications normally
don't.

I verified the behaviour of the virus by using ResEdit to add empty resources
of types VULT and ERIC to the TeachText application.  TeachText bombed as
described above on an infected system, even though TeachText itself was not
infected! While running my experiments I was in ResEdit on the infected system
and heard the disk whir.  Sure enough, ResEdit was infected.  I've been running
on an infected system with an infected ResEdit for three days.  I reset the
system clock to fool the various parts of the virus into thinking it was time
for them to wake up.  The Finder has also become infected.  ResEdit, Finder,
and the rest of the system seem to be functioning normally.  Only my version of
TeachText modified to look like VULT or ERIC has been affected by the virus.

If you repeat any of these experiments be very careful to isolate the virus.
I'm using a separate dual floppy SE to perform my experiments, and I've
carefully labelled and isolated all the floppies I'm using.  My main machine is
an SE with a hard drive, where I have MPW and my other tools installed.  It's
OK to look at infected files on the main machine (e.g. with ResEqual, DumpCode,
etc.), but don't run any infected applications on the main machine - that's how
it installs itself and spreads.  Children should not attempt this without adult
supervision :-)

An infected application contains an extra CODE resource of size 7026, numbered
two higher than the previous highest numbered CODE resource.  Bytes 16-23 of
CODE resource number 0 are changed to the following:

   0008 3F3C nnnn A9F0

where nnnn is the number of the new CODE resource.

You can repair an infected application by replacing bytes 16-23 of CODE 0 by
bytes 2-9 of CODE nnnn, then deleting CODE nnnn.  I've tried this using ResEdit
on an infected version of itself, and it works. The MPW utility ResEqual
reports that the result is identical to the original uninfected version.

The virus creates two new invisible files named Desktop (type INIT) and Scores
(type RDEV) in your system folder, and adds resources to the files System, Note
Pad File, and Scrapbook File.

Note Pad File and Scrapbook File are created if they don't already exist.  Note
Pad File is changed to type INIT, and Scrapbook File is changed to type RDEV.
Both of these files normally have file type ZSYS.  The icons for these two
files change from the usual little Macintosh to the generic plain document
icon.  Checking your system folder for this change is the easiest way to detect
that you're infected.

Copies of the following five resources are created:

      Type     ID  Size  Files
     -----  ----- -----  -------------------------------------
      INIT      6   772  System, Note Pad File, Scrapbook File
      INIT     10  1020  System, Desktop, Scores
      INIT     17   480  System, Scrapbook File
      atpl    128  2410  System, Desktop, Scores
      DATA  -4001  7026  System, Desktop, Scores

A disinfectant program would have to repair all infected applications and clean
up the system folder, undoing the damage described above.  I don't yet know
exactly which files can be infected, but I know for sure that Finder (file type
FNDR) can get infected, and that applications (file type APPL) can get
infected.  For safest results the disinfectant should examine and disinfect the
resource forks of all the files on the disk.  I recommend the following
algorithm:

Scan the entire file hierarchy on the disk, and for each file on the disk check
it's resource fork.  Delete any and all resources whose type, ID, and size
match the table above.  Delete all files whose resorce forks become empty after
this operation.  If the resource fork's highest numbered CODE resource is
numbered two more than the next highest numbered CODE resource, and if it's
size is 7026, then patch the CODE 0 resource as described above, and delete the
highest numbered CODE resource.  Also examine all files named Note Pad File and
Scrapbook File.  If their file type is INIT or RDEV, change it to ZSYS.

I'm fairly confident that a disinfectant program implemented using the
algorithm above would sucessfully eradicate the virus from a disk, restore all
applications to their original uninfected state, and not harm any non-viral
software on the disk.  It should work even on disks with multiple infected
system folders.  I also believe that it should work even if run on an infected
system, and even if the disinfectant program becomes infected itself! There's a
small chance that it could delete too many resources, and hence damage some
other application, but that's a small price to pay for a clean system.

Getting rid of a virus is tricky, even with a disinfectant program.  The
disinfectant program should be placed on a floppy disk along with a system
folder.  Make a backup copy of this disk.  The machine should be booted using
the startup disk you just made, and then the disinfectant should be run on all
the hard drives and floppies in your collection, including the backup copy of
the startup disk you just made.  Don't run any other programs or boot from any
other disks while disinfecting - you might get reinfected.  When you're all
done, reboot from some other (disinfected) disk and immediately erase the
startup disk you used to do the disinfecting, which may be (and probably is)
infected itself.  This should absolutely, positively get rid of all traces of
the virus.  The backup disk you made and disinfected should contain an
uninfected copy of the disinfectant program in case you need to use it again.

There are at least two red herrings in the virus.  It uses a resource of type
'atpl', which is usually some sort of AppleTalk resource.  As far as I can
tell, however, the virus does not attempt to spread itself over networks.  The
'atpl' resource is used for something else entirely.  This is not a bug.  Also,
the virus creates the file Desktop in your system folder.  This is done on
purpose.  It is not a failed attempt to modify the Finder's Desktop file in the
root directory.  The file is used by the virus, and has nothing to do with the
Finder.

I don't know why the virus seems to cause reported problems with MacDraw,
printing, etc.  Perhaps it's a memory problem - the virus permanently allocates
16,874 bytes of memory at system startup (four blocks in the system heap of
sizes 772, 40, 8, and 334, and one bock at BufPtr of size 15360).  I've only
found one possible bug in the virus code, and it looks pretty harmless.  The
code is very sophisticated, however, and I can easily understand how I might
have overlooked a bug, or how it might interact in strange unintended ways with
other applications and parts of the system.

When we've finished completely cracking this virus we'll probably distribute
another report.  I've posted these preliminary results now to get the
information out as quickly as possible.  We also hope to write the disinfectant
program, if someone else doesn't write it first.

I've decided not to distribute detailed information on how this virus works.
I'll distribute detailed technical information about what it does and how to
get rid of it, but not internal details.  This was a very difficult decision to
make, because normally I firmly believe in the enormous benifit of the free
exchange of code and information.  The Scores virus is a very interesting and
complicated piece of code, I've learned a great deal about the Mac by studying
it, and I'm sure other people could learn a great deal from it too.  But I
don't want to teach twisted minds how to write these incredibly nasty bits of
code.  If I write the disinfectant program, however, I will distribute its
source, because I do want to teach untwisted minds how to get rid of them.

So please don't bombard me with requests for more information.  You may be the
nicest, most honest, incredibly important person, but I won't tell you how it
works.  I'll make only two exceptions, and that's for a very few of my
colleagues at Northwestern University, and for qualified representatives of
Apple Computer.

Thanks to Howard Upchurch for giving us a copy of the virus, and to Bob
Hablutzel for helping me crack it.

John Norstad
Northwestern University
Academic Computing and Network Services
2129 Sheridan Road
Evanston, IL 60208

Bitnet:   JLN@NUACC
Internet: JLN@NUACC.ACNS.NWU.EDU

Monday morning, April 18, 1988.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re:  Yet Another UnTimely Risk  (<A HREF="/Risks/6.55.html">RISKS-6.55</A>)
</A>
</H3>
<address>
John S. Quarterman
&lt;<A HREF="mailto:longway!jsq@sally.utexas.edu ">
longway!jsq@sally.utexas.edu 
</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 25 Apr 88 22:50:50 -0500

   Re: &gt;From: cudney@sm.unisys.com (Paul Cudney)

Proper handling of timezones is a much harder problem than generally realized.
Fortunately, it has been solved.  An international group including Arthur David
Olson, Robert Elz, and Guy Harris produced a public domain package for UNIX
more than a year ago.  It handles past time, future time, System V time,
daylight time, double daylight time, partial hour shifts, multiple shifts in a
year, and even solar time.  Timezone rules are kept in files, not in compiled
code.  A rather complete database of rules has been compiled.

This package has been adopted by Sun, and by Berkeley (shortly after the 4.3BSD
release), among others.  It is in use on at least three continents.

PS:  Don't confuse it with what's in the latest POSIX draft standard,
which is useless.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Britain launches software safety study
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Tue, 26 Apr 88 09:05:09 PDT
</i><PRE>

From ELECTRONICS ENGINEERING TIMES, April 11 1988, p. 18:

IEE JUDGES SAFETY OF SOFTWARE by Roger Woolnough

The Institute of Electrical Engineers, Britain's premier organization of
professional EE's, has been awarded a government contract to study the use
of software in safety-critical systems.  The one-year project will be
undertaken in collaboration with the British Computer Society (BCS).

The IEE/BCS study will examine the present use of software in safety-related
systems, and describe likely trends in regulations and codes of practice
across all types of industries and application areas.  It also will identify
areas where regulations and codes are lacking, or where there are
inconsistencies between those used in different sectors.

The third part of the study will investigate the need for certification of
products, organizations, and engineers.  The certification of engineers
could include both those involved in design and those undertaking safety
assessment.

- Jon Jacky, University of Washington

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 A slight correction... on Harwell (<A HREF="/Risks/6.67.html">RISKS-6.67</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:F026%CPC865.UEA.AC.UK@CUNYVM.CUNY.EDU">
F026%CPC865.UEA.AC.UK@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
26-APR-1988 14:48:06 GMT
</i><PRE>

The UKAEA's Atomic Energy Research Establishment at Harwell is no more
'ultra secret' than (say) your local government food-testing lab.
It is a secure site, I'll grant you, but you'd find it a lot easier to get
in to than many large companies.
                                               Mike

 Mike Salmon, Climatic Research Unit, University of East Anglia, Norwich, UK
JANET: m.salmon@uea.cpc865 | BITNET: m.salmon%cpc865.uea@ukacrl | BIX: msalmon

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Computer Viral Center for Disease Control?
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 26 Apr 88 01:47 EDT
</i><PRE>
Cc: Lin@XX.LCS.MIT.EDU

Herb Lin's comments about the DoD funding bill asking for a specific
report on viruses prompts me to ask a more general question:  does
anyone know of anyone systematically trying to do I guess what one would
call an epidemiology of viruses?  Has someone been trying to keep track,
say, of exactly what particular installations have reported (to whom?
-- good question) having been hit by the MacWorld virus?  by the Israeli
virus(es)?  by the "NASA" virus just mentioned?

(General note:  the epidemiolgy wouldn't help solve the problem -- there
really is only one technical solution, fraught with lots of
administrative nightmares -- but it might, but only just might, help
signal whether the potential threat has materialized enough to create
the kind of crises atmosphere needed to implement the solution.)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.69.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.71.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-18</DOCNO>
<DOCOLDNO>IA012-000129-B045-165</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.71.html 128.240.150.127 19970217020900 text/html 20648
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:07:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 71</TITLE>
<LINK REL="Prev" HREF="/Risks/6.70.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.72.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.70.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.72.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 71</H1>
<H2>  Wednesday 27 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Is the Press impressing or depressing?  (They're pressing!)  
</A>
<DD>
<A HREF="#subj1.1">
Cliff Stoll
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  New traffic and automobile techniques at Hannover Fair 
</A>
<DD>
<A HREF="#subj2.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks of fire protection for computers 
</A>
<DD>
<A HREF="#subj3.1">
Dave Cornutt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Two viruses 
</A>
<DD>
<A HREF="#subj4.1">
Phil Goetz
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Is the Press impressing or depressing?  (They're pressing!)
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:cliff@Csa3.LBL.Gov ">
cliff@Csa3.LBL.Gov 
</A>&gt;
</address>
<i>
Thu, 28 Apr 88 16:48:49 PDT
</i><PRE>

Hi Gang!

On the risks of dealing with the press

How do you get the news out?  What happens when you talk to reporters?  How
accurate are news reports?  As a part of my work on computer security, I had
a chance to research these questions.  Here's my report.  It has nothing to
do with computer risks, so died-in-the-wool RISKies ought to skip it.

In August 1986, we discovered someone breaking into LBL's computers, becoming
superuser, and then attacking other MILNET sites.  Instead of closing our
doors to this bastard, we monitored and traced him for about a year.  Since he
was privileged, we were at risk:  at any time he might wreck our system.  We
needed to keep our research a secret.

We contacted a few Bay area systems people and compared notes.  Within a month,
someone leaked a bit of this to the San Francisco Examiner, and reporter John
Markoff mentioned LBL in an article on computer breakins.  The article talked
about someone with the pseudonym "Pink Floyd".  Three weeks after the article
appeared, the LBL intruder scanned our accounting files for user Pink Floyd --
aah, our intruder wasn't the same person, but surely read the news.

After getting burned by these leaks, we tried to keep our work silent.  It
wasn't easy.  Everyone wanted copies of our logbooks, althoug rarely did anyone
volunteer to help.

The FBI always wanted info, but would never tell me of any progress or
cooperation.  In January 1987, I gave a copy of my logbook to the FBI, who
passed it to German authorities.

In June 1987, the SOB was arrested, and I thought we could go public.  But the
FBI said that would screw up their indictments, so I kept my mouth shut.  Every
2 weeks, I'd call them, and they'd say, "We're making progress.  Don't
publicize anything or you'll sink the case."

In December, 1987, John Markoff of the San Francisco Examiner again picked up
LBL on his radar.  Two people in Silicon Valley pointed him towards me, saying
that I knew about some hackers coming from Germany.  I told him about the old
Chaos VMS breakins, which wasn't news.  Didn't lie to him, I just didn't tell
him what I knew.

By Jan 1988, I doubted that the FBI would do anything, although they kept
saying otherwise.  I wrote an article and submitted it to the Communications of
the ACM.  The referees did a super job, and the paper was scheduled for the May
issue.  We wanted a joint announcement in May to publicize both CACM and LBL.

In late February, Quick magazine of Germany called.  They wanted to take my
picture for an article on some hackers.  They didn't want to interview me, nor
did they ask any questions.  We were puzzled, but LBL's Public Info Dept said
to let 'em take my picture.  They did, but I told them nothing about what we
had done.

By early April, our plans were pretty well fixed.  CACM would be in the mail by
May 9th, so CACM and LBL would jointly announce the news on that day.  Karen
Frenkel of CACM along with LBL's public info guy, Chuck Hurly, made these
plans, and things were going well.

Going well until April 14th.  The German magazine, Quick is a bit like a color
National Enquirer:  sensationalism and scantily clad hussies.  They ran a story
titled, "The Hunt for the Data Pirate".  The story's based on my lab notebook.
Someone in Germany gave them a copy of my January 1987 notebook, and they wove
a story around it.  The German guy hides behind a pseudonym, and they never
interviewed me.  Indeed, the bulk of the story is from my notes.  It's slightly
distorted since they've misinterpreted sections of my notes.  Aaargh -- what
should we do?

Friday, April 15th:  Wire services pick up the Quick article, and reporters
start calling.  We answer them, but say little.  We schedule a press confrence
for Tuesday, April 19th, where we'll spill the beans.  But LBL's Public Info
guy says that we owe an early release to John Markoff, since he twice stumbled
on the story, but each time I kicked dust in his eyes.

According to LBL's public information dept, you gotta be honest with the press,
or you'll get stung.  In our case, we owed something to John Markoff.  By now,
he's at the New York Times.  We worked an agreement where I gave him a detailed
interview on Saturday, and the NY Times would publish the story on Tuesday,
April 19th.  This way, we could alert the ACM folks, and have the press
conference on Tuesday morning.

Things foul up.  Saturday evening, the NY Times editors decide not to embargo
the story.  They'll run it Monday morning because, "Quick magazine's already
printed the story, so it's already been public".  A Monday morning release
would destroy a Tuesday press conference:  why come to hear yesterday's news?
Ignoring cogent arguments and pleadings, the Times will run it Monday morning,
no matter what.  There'll be hell to pay...

Monday morning, April 18th.  Front and center, above the fold, "Breach Reported
in US Computers"...  LBL tells me to be invisible, so I hide out at the Oakland
IEEE Symposium on Security and Privacy.  The CACM folks are justifibly upset -
we hadn't told them, yet the Communications of the ACM was prominently in the
article.  A jillion reporters call my phone.

Press conference on Tuesday morning.  Lots of fun.  3 dozen reporters, all
asking good, sharp questions.  Ya can't dodge 'em, so you answer the best you
can.  Afterwards, they crowd around and you the TV folks ask easy questions,
and the others ask barbed, jagged questions that snag at a half dozen issues.
Everything from Admiral Poindexter's "Sensitive but unclassified" policy to
set-user-ID questions.


Sensationalism?  Distortion?  

Hardly. Markoff's New York Times article distilled interviews with about 6
people, and was a much better summary than I could have written.  The tone of
the article conveyed information, not speculation.  I was astounded by its
comprehensive accuracy.

Follow-on articles in Bay area newspapers were impressively accurate and
non-sensational.  The newspaper reports in the Oakland Tribune, SF Chronicle,
and Examiner went into depth of how we tracked the guy, and the relationships
between LBL and other agencies.  SF Chronicle and Pittsburgh Post reporters
phoned the mysterious Laszlo Balogh in Pittsburgh, finding him to be a
self-described arms dealer for the Saudis.  Lee Gomes of the Oakland Tribune
interviewed the guy in Hannover and found he's very touchy about saying who he
worked for.  Even the Contra-Costa Times, hardly a great metropolitan
newspaper, meticulously separated speculation from facts.

Two weeks later, I'm finding reporters still digging out facts, and digging
into primary sources for information.  My opinions of journalists has changed
180 degrees:  behind our newspapers are damned hard working, incisive
reporters. There might be dodo reporters out there, but I haven't met 'em yet.


Lessions I've learned:
                                       
1)  The press tries hard.  More and more, I trust what I read.

2)  Secrets can't be kept forever.  Information diffuses.

3)  Timing a press release is important, but tough.

4)  Reporters won't sit on a story.

5)  Avoid sensationalism and distortion by speaking plainly and directly.

6)  Keep a notebook of everything that happens.  

7)  When you know facts, speak on the  record.  When you're speculating, 
    say so.

8)  Publicity is like the wind.  You can tell it's coming, but not what'll 
    be uncovered.

9)  The press is good for us.  Keeps us honest, makes us reflect on 
    what we're doing, and spreads the word.  


And now for a word from our sponsor:  For the real good stuff, run down to your
corner magazine rack and get a copy of the May issue of Communications of the
ACM.  Compare what's in my article to what's in May 2nd Time magazine or the
April 18th NY Times, then judge for yourself.


Finally, my deep thanks to the RISKS people who knew about what we 
were doing and kept the faith.  Each of you helped through your 
comments, support and advice, as well as through your public silence.
  
</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
New traffic and automobile techniques at Hannover Fair (<A HREF="/Risks/6.65.html">RISKS-6.65</A>)
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>

</i><PRE>

Some German automobile manufacturers are demonstrating new computerized
communication technologies at their exhibition sites on Hannover Fair being
held April 20-27, 1988.

Mercedes demonstrates a new device which cannot only count a car (as is usually
done with electromagnetic detectors fixed under the street) but also identify
any cars specific `magnetic characteristic field'.  According to extensive
measurements, any individual car has an `individual magnetic print' different
from any other. The detector box is simple to install (above ground, not buried
into it), and by connecting it to other devices, installation and maintenance
is said to be rather easy. When connected to a `traffic control system', any
individual car may be identified on its ways by the stations it passes. Under
these auspices, some German media have asked the question whether such a device
should be installed, and for which purposes.  While a spokesman of the Federal
Minister for Traffic said, that he foresees only a usage as a traffic counting
device (though an inexpensive one)and that he hopes that todays costs may be
reduced significantly, a spokesman of the Federal Minister for Interior said,
that his ministry would `very carefully analyse the potential of such a
device'. So far, the discussion is only in the initial stage. Is there a
discussion on a similar device anywhere else?

Volkswagen, on its site, exhibited a project study to automatize
highway-driving. According to the study, cars will be equipped, within 10
years, with (at least) a rather simple set of distance measuring devices which
work much simpler than the `automatic pilots' discussed in the field. On a
special lane, cars follow, with only 0.5 meters distance, a `pilot car'; a
front device controls that the distance doesnot vary when the pilot car changes
velocity. To the left of the lane, a low wall is needed in order to control the
car to stay in the lane. Instead of running into the well known problems of
analysing the changing environment to simulate a human driver (as is done in
most studies), Volkswagen reduces the problem to find a proper `pilot car' or a
queue of cars behind one pilot, then to properly and safely feed-behind, and
then to switch on the automatic guidance system. Such a simple approach may
significantly reduce the risks of highway driving (assumed you may rely on the
pilot) in an unexpensive manner. Moreover, development and implementation of
such a less complex system may use less time. My personal view is that the
risks of such an approach are significantly less than with the `intelligent
all-situation automatic pilot' which I see developing in most aumobile
laboratories.

Klaus Brunnstein, University of Hamburg, Fed.Rep.Germany

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Two viruses
</A>
</H3>
<address>

&lt;<A HREF="mailto:PGOETZ%LOYVAX.BITNET@CUNYVM.CUNY.EDU">
PGOETZ%LOYVAX.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 26 Apr 88 15:00 EST
</i><PRE>

   Here are descriptions of a virus and a nasty program header which run on the
Apple II family.

===============
                        The Elk Cloner V2.0

   I found the Elk Cloner V2.0 #005 on a disk of mine in 1981 or 82.  I'm
fairly certain it could not have been written before the publication of
Beneath Apple DOS, so I would date it around mid-1981...  It works exclusively
with DOS 3.3.

THE VIRUS

1.  It is installed by booting an infected disk.  I'm not sure how it initially
gains control; apparently it is loaded in with some trash from T0 SA which DOS
loads for no apparent reason.  (BTW, since HackerDOS rearranges DOS on the
disk, the Cloner would trash it.  It might trash master disks, I don't know.)
If you use a modified DOS which marks T2 S3-8 as free for use (as HackerDOS
does), it would overwrite any file stored there.
   A JMP $9B00 which was installed when the disk was infected jumps to this
code (I think) and loads the virus from T2 S3-S8 into $9000-95FF.

2.  Next, it inserts its claws into DOS:
   A. Hooks into the Do Command code at $A180 and makes every command
reset the DOS parse state to 0.  I have no idea why it does this.  It has
no obvious effects.
   B. Hooks into the RUN, LOAD, BLOAD, and CATALOG commands to make them check
the disk accessed &amp; infect it if necessary.
   C. Create a USR vector for the Cloner diagnostics:

B=USR(10)       Prints a cute poem:

ELK CLONER:
   THE PROGRAM WITH A PERSONALITY

IT WILL GET ON ALL YOUR DISKS
IT WILL INFILTRATE YOUR CHIPS
YES IT'S CLONER!

IT WILL STICK TO YOU LIKE GLUE
IT WILL MODIFY RAM TOO
SEND IN THE CLONER!

B=USR(11)       Prints ELK CLONER V2.0 #005 (version check)

B=USR(12)       Read the disk &amp; prints BOOT COUNT: (#)

B=USR(13)       Infects a disk

3. Increments the boot count

4. Checks for any special event for this boot:

Boot # (hex)    Effect

A       Point reset vector to $FF69 (monitor)
F       INVERSE
14      Click the speaker
19      FLASH
1E      Switch letters at $B3A7-B3AA so filetypes T I A B will appear as I T B A
23      Change DOS signal character from ctrl-D to ctrl-E
28      Lockout the computer on reset (dangerous one!)
2D      Run the current program on any keypress (locks out the machine, also
          dangerous. BTW, this is done by setting the hibit of $00D6.)
32      Print above poem on reset
37, 3C, 46      Screw with the INIT code.  I think it will give you an I/O
          ERROR, but I haven't tried.  3C and 46 might be dangerous in that
          it might not init a whole disk.  I don't know.
41      'Crash' to monitor on every DOS command
4B      Reboot
4C      Reboot
4D      Reboot
4E      Reboot
4F      Write 0 to the boot count &amp; start all over again!

5. Sits back &amp; infects disks.

This is how the program is structured:
9000            Version number
9001-9073       Setup
9074-908F       [Check a disk for infection] code
9090-90D9       Replacement code for LOAD, BLOAD, &amp; CATALOG
90DA-9178       [Infect] code
9179            Read VTOC
9181            Write VTOC
91A8            Print routine
91E4            Serial #
91E5            Marked with a 0/1 if a disk is infected/uninfected
91EC-9243       Diagnostics
9244-9328       Poem
9343-9435       Special events by boot count
9500-9532       Code which loads Cloner on boot
95E1-95FF       ASCII: MATT BE&lt;ctrl-D&gt;JOHN HINKLYJOHN HINKLE&lt;ctrl-D&gt;
                (The author's hero?)

These are within the VTOC:
B3BE    Zeroed, I don't know why
B3BF    Boot count
B3C0    Zeroed, don't know why
B3C2    Infection mark: Version number (=(9000))
   There may be several versions out.  The version number would be used so
later versions would write over older versions, for a new improved
infection.

THE TEST

Any of these methods will work:

1. Check T$11 S0 Byte 7. If it is non-zero, the disk might be infected.
2. Check T1 S0 B$80-82. If they are 4C 00 9B, you have the Cloner.
3. Check T2 S3 - T2 S8 for the Cloner.
4. From Applesoft, immediately after boot, enter B=USR(11).

THE VACCINE

   If you write a 2 to T$11 S0 Byte 7, Cloner version 2 will not infect that
disk. I have verified this.

THE CURE
   Write something (like 00:1 AD 88 C0 4C 59 FF) to sector 0 so you can't boot
that disk.

PRECAUTIONS
   The Cloner will not work unless you boot an infected disk.  It cannot infect
a write-protected disk.  I have infected disks I use all the time.  Just mark
them as infected &amp; don't boot them.

===============
                        Disease DOS

   This isn't a DOS at all, nor a virus, but a nasty program which is added
to the front of a program.  The author posted it to a bulletin board with an
explanatory file.  I don't know if they threw him off the BBS or promoted him.
(Promotion: higher disk quota, file access, more downloads permitted, etc.)
   When the program is run, it decrements a boot count &amp; erases the current
track after a number of runs.  It might be used by a pirate who doesn't like
the fellow he is giving a program to, or who doesn't like people in general.
   You can detect it by scanning your disks for the sequence BD 8C C0 B0 F6,
an unusual sequence which shouldn't be on any normal disk.  (I haven't checked;
it could be on DOS 3.3, but I doubt it.)  It won't be
divided between sectors because it is in the first few bytes of the file.
Or you can read T$11 S0 Byte 4, which is the number of boots remaining before
wipeout.  Any commercial (read: non-standard) disk might be non-zero there.

===============

   Note that a write-protect tab will deter either program: The Cloner can't
spread, &amp; neither can increment/decrement the boot count.

   And, no, I won't send you either program.  So don't ask.

Phil Goetz

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.70.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.72.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-19</DOCNO>
<DOCOLDNO>IA012-000129-B045-191</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.72.html 128.240.150.127 19970217020915 text/html 22923
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:07:41 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 72</TITLE>
<LINK REL="Prev" HREF="/Risks/6.71.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.73.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.71.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.73.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 72</H1>
<H2>  Thursday 28 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Yet another skunk in the squirrel story 
</A>
<DD>
<A HREF="#subj1.1">
Rick Jaffe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Garbage ($20) in, garbage ($20) out 
</A>
<DD>
<A HREF="#subj2.1">
Joel Kirsh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: KAL 007 
</A>
<DD>
<A HREF="#subj3.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Civil aviation risks 
</A>
<DD>
<A HREF="#subj4.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Creating alternatives to whistleblowing 
</A>
<DD>
<A HREF="#subj5.1">
John Gilmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: textual tampering 
</A>
<DD>
<A HREF="#subj6.1">
John Gilmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re:Fault tolerant systems... 
</A>
<DD>
<A HREF="#subj7.1">
Hugh Davies
</A><br>
<A HREF="#subj7.2">
 Andrew Klossner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  DoD (and the rest of us) protecting ourselves against viruses 
</A>
<DD>
<A HREF="#subj8.1">
John Gilmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: Computer Viral Center for Disease Control?  
</A>
<DD>
<A HREF="#subj9.1">
Prentiss Riddle
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Yet another skunk in the squirrel story
</A>
</H3>
<address>
Rick Jaffe
&lt;<A HREF="mailto:umix!oxtrap!rsj@rutgers.edu ">
umix!oxtrap!rsj@rutgers.edu 
</A>&gt;
</address>
<i>
Wed, 27 Apr 88 14:02:29 edt
</i><PRE>

I hadn't previously seen this particular risk relating to the story of
"the squirrel that skunked NASDAQ".

(from "SIAC Preps Net for DP Backup Site", _Network World_, vol. 5, no. 17)

"Unfortunately, when NASDAQ switched data centers, it learned that
most of its largest customers didn't have communications lines
connecting them with the alternate site."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Garbage ($20) in, garbage ($20) out
</A>
</H3>
<address>
Joel Kirsh 
&lt;<A HREF="mailto:KIRSH@NUACC.ACNS.NWU.Edu">
KIRSH@NUACC.ACNS.NWU.Edu
</A>&gt;
</address>
<i>
Wed, 27 Apr 88 15:00 CDT
</i><PRE>

(without permission from The Chicago Tribune, April 27th: )

    NEW YORK (AP) "... Because some hapless employee loaded an canister
of $20 bills into the slot for $5 bills, the First Federal Savings and
Loan Association of Rochester's branch at 1st Avenue and 14th Street 
launched an accidental exercise in income redistribution.
    "Although the cash machine panel has a 24-hour telephone for reporting
problems ... the response was ... 'one or two calls,' according to bank
spokesman Robert Nolan.
    "Instead, a line of eager card holders quickly formed at the machine.
    ...
    "Nolan said the machine's records would show who used it and how large
a withdrawal each person requested.  He said customer accounts would be
charged for the amount overpaid.
    "...But it was unclear whether the bank would be able to prove that all
the bills in the $5 slot were really $20s.
    "...Overpayments like Sunday's are said to be extremely rare."
    "'It's much more common for the reverse to happen - a customer is
shortchanged,' said John Love of Bank Network News, an industry newsletter."


[If the Post Office has automatic stamp dispensers that can discriminate
between $1s, $5s etc., why don't ATM's have a similar test at the output?  JK]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: KAL 007 (<A HREF="/Risks/6.70.html">RISKS-6.70</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Wed, 27 Apr 88 11:15:32 PDT
</i><PRE>

   The article in RISKS 6.70 by Clifford Johnson sent me reeling.  I don't
have direct access to any primary sources of information on the KAL007
incident, but this story sounds like bunk to me.  Here's an example of a
major error:

	To this day there has been no public congressional investigation 
	into the KAL007 incident, even though the Air Force irregularly 
	destroyed radar tapes of the flight, and even though Japanese tapes
	of the incident, et alia, strongly indicate that the course of 
	KAL007 was deliberate.  A statutorily required investigation by 
	the National Transport Safety Board was inexplicably cancelled, 
	documents lost, and gag orders placed on all civilian employees.

    Let's begin with part of the last sentence.  "statutorily required 
investigation by the [NTSB] was inexplicably cancelled".  To quote NTSB
Part 830.1 Applicability:

    This part contains rules pertaining to:
   (a) Notification and reporting aircraft accidents and incidents and
certain other occurrences in the operation of aircraft when they involve
CIVIL AIRCRAFT OF THE UNITED STATES wherever they occur, or FOREIGN CIVIL
AIRCRAFT WHEN SUCH EVENTS OCCUR IN THE UNITED STATES, ITS TERRITORIES OR
POSSESSIONS. [emphasis added]

   The KAL 007 incident does thus not even require a report.  To my
knowledge, there is no US statute requiring investigation of military
actions against nor accidents involving aircraft of US manufacture.  As 
for "radar tapes", it seems unlikely that such tapes would have been 
useful, as the flight was outside of the coverage range of both US 
and Japanese ground radars.

   The rest of the article proceeds with various claims that are counter
to information printed in a host of reliable publications including 
the New York Times and Aviation Week.  Johnson refers to _Shootdown_ by
R.W. Johnson, who provides "astonishing" evidence that KAL007 was on
an espionage mission.  This certainly is astonishing, as all other
available information leads away from this conclusion.

    What we had here was a civilian aircraft blundering into airspace that
is a military espionage playground.  The Soviets appear to have demonstrated
incompetence in shooting down a civilian aircraft when they were after a 
US military intelligence aircraft.

   What has all this to do with RISKS?  If we classify a massive error as a 
deliberate act, we dismiss the need for investigation as to why the error 
occured, and remove all possibility of discovering and/or correcting any
problems.  The "deliberate act" explanation is a variation on "pilot error".
If an accident is simply hand-waved away as "pilot error", we lose the
opportunity to understand what in the system allowed that error to 
occur, and we do nothing to decrease risk and the possibility that the
error will occur again.  The really interesting things that have come
up in the investigation of this incident are the multiplicity of ways
that such an error could occur.  It has given us much food for thought
in designing systems that are more safe.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Civil aviation risks (not computers, interesting anyway)
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Wed, 27 Apr 88 09:13:48 PDT
</i><PRE>

Here is a story about manufacturing defects in commercial airliners
and how they were discovered and fixed.  It is excerpted from

FAA, BOEING AND PROBLEM-SOLVING by Polly Lane, SEATTLE TIMES Sun Apr 17 88

"Maintenance being performed on an American Airlines 767 in the carrier's
Tulsa maintenance center was fairly routine, until a mechanic discovered
that cargo fire-extinguisher lines were crossed.  The swapped lines meant
trouble.  Should a pilot discover an in-flight fire in the rear cargo 
compartment, he would immediately tigger the extinguisher system - but it
would go off in the front compartment instead.

The mechanic reported his find to a Boeing Co. representative at American's
center and to the Federal Aviation Administration.  The Boeing rep called 
Boeing officials here (in Seattle) later that day, March 3, and followed
uyp with a telex the following morning, a Friday.  By Friday afternoon,
inspectors were looking at 767's on the assembly line at Everett to determine
whether it was an isolated case ... They found some repeat instances
- they didn't say how many - during inspections the following week.

On March 9, Boeing reported the findings to the FAA.  The next day, a week
after the discovery in Tulsa, Boeing sent a service letter advising customers
of the potential problem.

The FAA backed up Boeing's letter by issuing a telegram, known as an
airworthiness directive, to owners and operators of 767's.  After a worldwide
check it was determined that 27 of the 190 767's in service had
fire-extinguishing hoses that were swapped. ...

The FAA telegram was the result of a system dictated by Federal law. ... The
directive to fix the 767 fire-extinguishing system was relatively urgent, but
not serious enough for the FAA to ground the airplanes until corrections were
made.  That hasn't happened since 1979, after an American Airlines DC-10
crashed at Chicago, killing 275. ...

In the case of the 767 fire-extinguishing system, Boeing changed the size of
the hose connections so lines to the front and rear were different.  The
change would help prevent future mistaken connections. ... Designers also
suggested the lines be separated so there is no chance of a repeat
misconnection. ... "

( I know it isn't a computer-related incident, but I was impressed by
several lessons:

1. Mistakes can be made during assembly; it is not valid
to assume that the product that is delivered is the one that was designed.

2.  Systems that are used infrequently are hiding places for latent errors.

2.  It is important to have in place a responsive error reporting and 
correcting system. ) 

- Jon Jacky, University of Washington

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Creating alternatives to whistleblowing [<A HREF="/Risks/6.65.html">RISKS-6.65</A>]
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.edu ">
hoptoad.UUCP!gnu@cgl.ucsf.edu 
</A>&gt;
</address>
<i>
Wed, 27 Apr 88 00:08:46 PDT
</i><PRE>

The week I left Sun Microsystems (years ago), I was the featured
speaker at the regular weekly software meeting.  I offerred some
suggestions to 'dissidents' who were having trouble with management.
(Of course, since my efforts to be a dissident and remain at Sun had
failed, perhaps nobody took them seriously.)  If enough RISKS folks
care, I will transcribe the relevant parts of the tape.

For me the ethical issues were around things like:

 * If I see a problem, should I let it continue even though it's not
   in my 'area of responsibility'?

 * Should I let newly hired folks (typically managers) move the company
   in directions where I think it's wrong for it to go?

 * How much time should I spend kowtowing to management structures versus
   going straight to the people who know what's up and how to fix it?

 * What should I do when I end up with a manager who is actively trying
   to fire me?

Note that the net itself forms a communications medium for whistleblowers;
many people report problems they're having with a company's equipment
to the net, when they can't get satisfaction from the company in private
discussions.  Sun's fixes to the TFTP security hole, and to install
subnetting, were both done in response to publicity on the net.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: textual tampering
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.edu ">
hoptoad.UUCP!gnu@cgl.ucsf.edu 
</A>&gt;
</address>
<i>
Wed, 27 Apr 88 00:29:06 PDT
</i><PRE>

&gt; In our copy of RISKS DIGEST 6.60, occurrences of "ments" have been replaced
&gt; with "&lt;newline&gt;&lt;newline&gt;w".

This is a common problem when compressed text files are damaged in transit.
Compress works by remembering common strings of bytes, and replacing each with
a 9-to-16-bit code.  The decoding process uses the text as it is produced to
rebuild a copy of the string table built by the encoding process.  If one of
the codes is altered, it changes the table entry involved, and future
references to that code will be translated to bad data.  Not all copies of the
string will necessarily be affected, depending where the encoding algorithm
breaks the text into strings.

The reason for the "#! rnews 682" at the end is because netnews is packaged
into batches, separated by #! rnews lines containing a byte count.  Since the
RISKS article shrunk from the decompression problem, the beginning of the next
article was grabbed [a RISK of counted byte strings].  The news software
notices that there is no #! rnews after the article, but it has already
processed the corrupted message; it skips forward looking for another #! rnews.

I have seen cases where uucp's checksums did not detect errors introduced
by horrible phone lines, and TCP-IP is recently full of horror stories
about the UDP and TCP checksum algorithms, so this happens often enough
to be able to see the pattern.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
DoD (and the rest of us) protecting ourselves against viruses
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.edu ">
hoptoad.UUCP!gnu@cgl.ucsf.edu 
</A>&gt;
</address>
<i>
Wed, 27 Apr 88 01:31:30 PDT
</i><PRE>

The first thing anybody who wants protection against viruses should do is to
stop buying computers that don't have, or don't use, memory protection.  There
is NO protection in a system where main memory, the operating system, and I/O
devices and drivers are all open to subversion by any random user program.

Of course any machine containing an 8088 or 8086 is wide open.  Any 68000,
68010, or 68020 without an MMU, ditto.  This cuts out all the existing micros
except high end ones running Unix.

Note that even if you install an MMU into a Mac-2, the MacOS will not
use it; you have to run A/UX [Unix] to get memory protection.

Note that OS/2 is not a protected environment, since it runs MSDOS programs in
"real mode", even on an 80386.  Real mode basically means full access to the
bare metal.  It is also easy to circumvent system security in protected mode;
protected mode virus programs can get permission to do I/O instructions by
claiming to need high speed access to a graphics board or other special
hardware.  At this point the system is wide open again; they could write some
data out to a disk drive and then instruct the disk drive to read it back into
any location in physical memory -- say, over the interrupt vectors or the
global memory protection table.

It may be possible to run a castrated version of OS/2 that does not permit I/O
instructions and does not run MSDOS programs, but then why would you bother
running it?  It's just another incompatible, proprietary OS.  Unix already runs
well protected on the same hardware, there are plenty more applications for
Unix than OS/2, and Unix provides the same programming and user environment
from the 8088 all the way up to Amdahls and Crays.

This is not to say that operating systems that provide memory protection are
secure; it's just saying that if you want security, memory protection is step
#1, without which everything else is useless.

</PRE>
<HR><H3><A NAME="subj7.2">
Re: Computer Viral Center for Disease Control? (RISKS 6.70)
</A>
</H3>
<address>
Prentiss Riddle
&lt;<A HREF="mailto:ut-sally!im4u!woton!riddle@uunet.uu.net ">
ut-sally!im4u!woton!riddle@uunet.uu.net 
</A>&gt;
</address>
<i>
27 Apr 88 15:47:11 GMT
</i><PRE>
Organization: Shriners Burns Institute, Galveston

A computer virus CDC is not a bad idea.  If it is ever implemented,
let's hope that it is part of the private nonprofit sector, or at least
in some relatively open part of the government well removed from the
security agencies -- otherwise the center will be subject to the real
or imagined RISK that it is a front for computer "germ warfare"
research.  (Visions of another DES scandal readily come to mind.)

-- Prentiss Riddle ("Aprendiz de todo, maestro de nada.")
-- Opinions expressed are not necessarily those of my employer.
-- riddle%woton.uucp@cs.utexas.edu  {ihnp4,uunet}!ut-sally!im4u!woton!riddle

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re:Fault tolerant systems...
</A>
</H3>
<address>
&lt;<A HREF="mailto:"hugh_davies.WGC1RX"@Xerox.COM">
"hugh_davies.WGC1RX"@Xerox.COM
</A>&gt;
</address>
<i>
27 Apr 88 01:25:31 PDT (Wednesday)
</i><PRE>

I have read this story in several places in the UK computer press.  Regrettably
I have long since trashed the source material, but I'm fairly sure about it..

Tandem make a fault tolerant computer system which is very popular with
financial institutions. It has a lot of redundant hardware, so that failure of
one subsystem doesn't bring down the whole machine. One of the favourite
'tricks' whilst demonstrating this feature is to get a bystander to point at a
(random) board in the machine and then pull it out, proclaiming 'Look, it's
till up!!!'.

Unfortunately, DP managers at customer sites were doing this to impress their
friends (colleagues, bosses?). So the story goes, the machine was then dialling
Tandem (by itself) to report the 'failure' resulting in a deluge of spurious
fault reports at Tandems HQ. The story continues that Tandem have now put in a
timer to stop the machine dialling until the DP man has had a chance to plug
the board back in.

eugene@ames-aurora.ARPA asked about strange benchmarking type stories. When we
first got our (well, perhaps I'd better not say) supermini, we were plagued
with problems where random chunks of files would have their contents swapped,
so you'd end up with things like 'ekil sgniht htiw pu dne d'uoy' - only
hundreds (sometimes thousands) of bytes. The hardware men blamed the software
and the software men blamed the hardware (as usual). After about 6 weeks of
fixing files, we finally discovered we were running microcode for a machine
without an FPP, and ours had an FPP. As soon as we corrected that, the problem
went away.  We never did discover what floating point arithmetic had to do with
swapping bytes in files....

Hugh Davies, Rank Xerox, England.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Avoiding fault tolerance of broken floating point unit
</A>
</H3>
<address>
Andrew Klossner 
&lt;<A HREF="mailto:andrew%frip.gwd.tek.com@RELAY.CS.NET">
andrew%frip.gwd.tek.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Tue, 26 Apr 88 16:25:01 PDT
</i><PRE>
Organization: Tektronix, Wilsonville, Oregon

  "There was also provision for the PROM to contain a list of attached
  equipment; the boot ROM could then check to make sure that it had found
  everything that was supposed to be there.  Unfortunately HP decided that the
  custom PROMs added too much to manufacturing cost."

The engineers of the Tektronix 6130 workstation devised yet another
solution to this problem.  After the diagnostics (boot ROM and friends)
finish looking over the system, they compare the list of attached
equipment with the previous list, stored on disk.  If they don't match,
a message is printed and system boot won't procede until the operator
keys an acknowledgement, at which point the disk list is updated.

The bad points are: you have to use other methods to be sure that
everything works the first time you boot (when there is not yet an
equipment list on disk); and, if the configuration changes (either
because you unplugged something or because a component failed), the
system won't reboot itself back to fully operational state after a
power failure.

  -=- Andrew Klossner   (decvax!tektronix!tekecs!andrew)       [UUCP]
                        (andrew%tekecs.tek.com@relay.cs.net)   [ARPA]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.71.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.73.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-20</DOCNO>
<DOCOLDNO>IA012-000129-B045-220</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.73.html 128.240.150.127 19970217020944 text/html 28642
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:07:56 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 73</TITLE>
<LINK REL="Prev" HREF="/Risks/6.72.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.74.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.72.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.74.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 73</H1>
<H2>  Friday 29 April 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
RISKS of Amateur Radio Call-sign License Plates 
</A>
<DD>
<A HREF="#subj1.1">
Stanley F. Quayle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Social Security Numbers on Driver's Licenses 
</A>
<DD>
<A HREF="#subj2.1">
Stanley F. Quayle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  A Short List of Nits about "Normal Accidents" by Perrow 
</A>
<DD>
<A HREF="#subj3.1">
Stanley F. Quayle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  A perspective on viruses 
</A>
<DD>
<A HREF="#subj4.1">
Bill Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Write-protection for hard disks 
</A>
<DD>
<A HREF="#subj5.1">
Bill Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  FPP and garbled text 
</A>
<DD>
<A HREF="#subj6.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Swapping Cash Containers 
</A>
<DD>
<A HREF="#subj7.1">
Joseph M. Beckman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Reference Legends of Caltech (Stop ending mail requests!) 
</A>
<DD>
<A HREF="#subj8.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Center for Viral Monitoring -- I'm trying! 
</A>
<DD>
<A HREF="#subj9.1">
Chip Copper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  ATM blues 
</A>
<DD>
<A HREF="#subj10.1">
Bob Sidebotham
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Yet another ATM story 
</A>
<DD>
<A HREF="#subj11.1">
Bruce Hamilton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  YADBR (Yet Another DB Risk) 
</A>
<DD>
<A HREF="#subj12.1">
George Michaelson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
RISKS of Amateur Radio Call-sign License Plates
</A>
</H3>
<address>
bcd-dyn!sfq@csl.sri.com 
&lt;<A HREF="mailto:Stanley F. Quayle">
Stanley F. Quayle
</A>&gt;
</address>
<i>
Fri, 29 Apr 88 12:55:05 EDT
</i><PRE>

The discussions about "NOPLATE" reminded me of an incident that occurred
two years ago.  Also related is the hazards of using the first match from a
database.

I was in an auto accident.  The other driver was clearly at fault; however,
the police check the computer for both drivers and vehicles as a routine
measure.  The policeman called my plate in:  N8SQ.  I have amateur radio
callsign plates.

The response on the radio was something like:  "1974 Ford pickup truck, Farmer
Jones, Circleville, Ohio.  No wants or warrants."  The policeman looked at me:
the plates weren't on a truck, my name wasn't Jones, I wasn't from Circleville,
etc.  He was sure he'd caught a live one!

Just then, over the radio came, "Wait a minute...  There's ANOTHER one!  1986
Pontiac 6000, Stanley Quayle, ..."  *whew*!

Amateur radio callsigns start with A, K, N, or W.  They have an optional
letter, a required digit (0 through 9), and one to three letters.

In Ohio, truck license plates start with N, have an optional letter, one to
three digits, and one to three letters.

This was the first I'd heard of the problem.  However, since then, I've seen
a car and truck with the same vanity plate, owned by different people.  Truck
plates are a different "series" than car plates, it seems.  But they forgot
to tell the computer that.

Stanley F. Quayle	UUCP: cbosgd!osu-cis!bcd-dyn!sfq
(614) 424-4052		USPS: 505 King Ave., Columbus, OH  43201
N8SQ @ W8CQK		Fido: Stanley Quayle, Node 1:226/610
My opinions are mine.  What more of a disclaimer could you need?

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Social Security Numbers on Driver's Licenses
</A>
</H3>
<address>
bcd-dyn!sfq@csl.sri.com 
&lt;<A HREF="mailto:Stanley F. Quayle">
Stanley F. Quayle
</A>&gt;
</address>
<i>
Fri, 29 Apr 88 12:55:05 EDT
</i><PRE>

Ohio requires SSN for issuing a driver's license.  I don't like it, but they're
within the federal law (as amended).

However, they print the SSN on the face of the license, along with the
DMV-issued license number.

A chain of stores in the area requires a driver's license for
identification when paying by check.  The cashier enters the SSN from the
license on the register.  After a few seconds, at least in my case, an
approval code returns.

This store uses price scanners.  It would be possible to establish a profile
of each check-paying customer with this system.  They can also do the same
with each credit-card customer.

They can link the credit-card numbers with SSN for those customers who rent
video tapes, since both are required on the video application.

The question is, do I complain to the store?  If they haven't thought of this
already, I don't want to give them any ideas.

And, yes, I'm trying to pay by cash.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 A Short List of Nits about "Normal Accidents" by Perrow
</A>
</H3>
<address>
bcd-dyn!sfq@csl.sri.com 
&lt;<A HREF="mailto:Stanley F. Quayle">
Stanley F. Quayle
</A>&gt;
</address>
<i>
Fri, 29 Apr 88 12:55:05 EDT
</i><PRE>

I finally read this book, after hearing about through this group.  A few things
bother me about it.

First, a little background on myself, to make any possible biases evident.
I fly airplanes recreationally, and have a Master's degree in Nuclear
Engineering.

First, the smallest nit:  Twice in the book, once in the text and once in the
glossary, "LNG" is defined as "Liquified Nitrogen Gas".  Probably a common-mode
failure.  Of course, it's liquified natural gas.  Much more flammable.

Medium nit:  References to the pilots with personal airplanes in southern
California.  He makes it sound like all pilots who like to fly are rich and
inconsiderate.  I almost stopped reading right there.  At least I don't have
any prejudices against book authors.

And, the nuclear power nit:  Well, he has a point.  My own opinion is that the
current crop of nuclear power plants are too complicated and too difficult
to control and maintain.  Some of his facts sound like he doesn't understand
nuclear power very well.  (Sorry, no specific examples right now.)  The length
he goes to bury nuclear power appears to be born from a dislike of the concept
rather than analysis of it.  And he doesn't mention any of the proposals for
inherently-safe reactors.  There are designs available now that are simple 
and that don't have complex interactions.

Overall, however, it is a fascinating book.  The parts about marine safety
are really shocking.  I'm glad that I'm living a long way from water.

By all means, read this book.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 A perspective on viruses
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 29 Apr 88 15:33 EDT
</i><PRE>

One should not be surprised that the discussion of viruses by computer users
should focus on how to protect their own systems.  However, as I read RISKS I
become concerned that is how the problem is perceived.

A virus is a special case.  It is a social disease.  It attacks not only a
target system, but a population of systems, and social order all at the same
time.  I am sure that if you have imported one into your system and if it does
something destructive, you will see primarily in terms of the destruction that
it does.  However, similar damage could have been done by any Trojan Horse or
even by your own error.

The problem with the virus is not in the damage that it does to one system, but
with the damage that it does to a population and to the fabric of trust that is
essential to the sharing of programs and other data and to commerce in general.

Suppose that viruses become so pervasive that even those who have never seen
one become afraid to use any program that they did not write themselves.
Suppose that because of the publicity received by viruses, the public at large
were to loose confidence in all computers, in the information they generate,
and in information in general.

If you think that that is far-fetched, then I ask you to think back to the
panic that followed the Tylenol contamination.  In a society in which 1500
hundred people a year die early because of the use of asbestos, another 15000
from the use of fossil fuels, 40,000 from the use of the automobile and 200,000
from the use of tobacco, the level of concern was out of any realistic
proportion to the number of deaths.  But it was not out of proportion to the
effect of the loss of confidence in the medicine supply or even of the food
supply.  I suggest that it was the unconscious concern for the effects of the
potential loss of confidence that caused the panic.

The perpetrators of the virus know very well how it will behave in the target
system, but they have no idea how it will behave in the population.  The
XMASCARD program did not do any damage in the user's machine, but it brought a
multi-million dollar network to its knees.  The scope and sensitivity of that
network was not only beyond the perpetrator's knowledge, but it was beyond his
comprehension.

The perpetrators of these toys are, like the sorceror's apprentice, playing
with powers far beyond their knowledge or control.  The potential for damage is
far beyond their puny powers to predict, skills, motives, or their intent.
They are toying with the mechanisms of cooperation and coordination that
characterize humanity.  They are to be pitied for their ignorance, but they are
not to be tolerated, much less admired or emulated.  A society that depends for
its own proper functioning upon any mechanism, dare not tolerate any
interference with the intended operation of that mechanism.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Write-protection for hard disks
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 29 Apr 88 17:16 EDT
</i><PRE>

On April 22, 1988 I received two back issues of a newsletter entitled 
"Computer Virology" along with along with a product description for the 
Disk Defender (tm).

  "Computer Virology is published in Evanston, Illinois by Director
  Technologies, Inc.  Director Technologies is the manufacturer of DISK
  DEFENDER, a product which write protects in hardware all or part of a
  personal computer hard disk.  It is our belief that hardware write protection
  is the only 100% reliable virus protection for the operating system and
  commonly used programs.  If you have any comments, questions, suggestions or
  article submissions, please address them to:

  Director Technologies, Inc., Technology Innovation Center
  906 University Place, Evanston, IL 60201     312-491-2334

[Quoted without permission from the masthead of the newsletter.  I am in no
way associated with this firm.  This is not a recommendation or endorsement of
their product.]

The product appears to be a half-card that installs between the drive and the
hard disk drive controller card.  It can make a portion of the or all the hard
disk "write-protected."  It has an outboard component with a 3-position switch
which permits you to select between "full|zone|none."  The outboard switch can
be removed in order to remove the discretion from the user.  In other words, it
is a hardware write-protect tab for a hard drive zone.  The size of the zone
appears to be chosen by setting dip-switches on the card itself.

To suggest that it is 100% effective against a virus is to overstate.  Studies
in biology suggest that a virus can thrive even in a population in which a
large percentage of the members are immune, if a there is sufficient commerce
among the non-immune members.  This is not an argument against vaccines but
only a caution about the limits of their effectiveness.

Depending upon design of the virus, the target system and population, and the
chosen distribution vector, the effectiveness of this mechanism against the
spread of the virus might vary from high to none at all.

Good hygiene is the general defense against viruses, but there are limits to
how effective it can be.  Nonetheless, the individual can and should protect
himself within those limits.

Bill Murray      WHMurray at DOCKMASTER

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
FPP and garbled text
</A>
</H3>
<address>
jcmorris@mitre.arpa
&lt;<A HREF="mailto:Joe Morris ">
Joe Morris 
</A>&gt;
</address>
<i>
Fri, 29 Apr 88 11:26:34 EDT
</i><PRE>
Organization: The MITRE Corp., Washington, D.C.

In RISKS 6:72, Hugh Davies comments on a problem with text being garbled due
to the software and hardware disagreeing about the presence of a floating
point processor.

I'm told that at least in DEC's VAX line, the ULTRIX (UNIX-like) system can
be made to handle characters with significantly higher speed by adding
an FPP to the computer.  Apparently the FP opcodes provide some kind of
fast path which can be exploited by programs which are processing strings,
even if no floating point calculations are performed.

Perhaps some parts of the system recognized the presence of the hardware
while others didn't.  If A interfaces with B and each has a different set
of assumptions about the environment, the results can be "interesting" if
they also assume that everybody agrees.  (Remember the analysis of the 
word "assume"?  It makes an ASS out of U and ME.)

There is an indirect RISK here in that an optional feature on the computer
is named in a way which fails to describe its function.  Who would have
thought that floating point hardware would improve character processing?

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Swapping Cash Containers
</A>
</H3>
<address>
"Joseph M. Beckman" 
&lt;<A HREF="mailto:Beckman@DOCKMASTER.ARPA">
Beckman@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 29 Apr 88 08:58 EDT
</i><PRE>

I assume when people load containers into ATMs, they replace the ones
already loaded with another set.  They then return the first set for
accounting purposes.

Seems like the problem of having people install cash containers in ATMs
incorrectly could be (partially) solved by a technique mentioned in at
least two other areas in RISKS.  In the last issue (6.72), we heard how
an airline company fixed a problem of crossing their fire extinguishing
lines by making the connections different sizes.  Some time ago, there
was a discussion on plugging medical equipment into the wrong sockets.
(Come to think of it, a third area was the ability to plug some computer
equipment (LAN connections?)  into a wrong socket (no pun intended))

The different containers could have a small bit of metal or plastic
added to them that would fit only in the proper slot in the ATM.  This
at least reduces the risk; you still have to have the person originally
loading the container do so with the correct denomination.  Another
simple fix (but not as robust) would be to color code each container.

Joseph

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Reference Legends of Caltech (Stop ending mail requests!)
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@ames-nas.arpa">
eugene@ames-nas.arpa
</A>&gt;
</address>
<i>
Thu, 28 Apr 88 11:18:18 PDT
</i><PRE>

%A Willard A. Dodge, Jr.
%A Reuben B. Moulton
%A Harrison W. Sigworth
%A Adrian C. Smith, Jr.
%T Legends of Caltech
%I California of Institute of Technology, Alumni Association
%C Pasadena, CA 91125
%D 1983
%K ARCHES program, senior ditch day, room stacking, color blindness
and traffic jams, Rose Bowl Hoax 1961 (U of WA [1]).

I am surprised at the number of peple who think this is just a text file
which you can just FTP.  [Oh, Aaron Schuman, you can just look at my copy.]
Please do not send me mail on this. This is a published book which
costs $10 and has important photos inside it.  (Text is completely
inadequate to describe this book, it has photographic proof.)
If you want a copy, please contact the Caltech Bookstore.
The general number for Caltech is (818)-356-6811.
P.S. There is also a Climber's Guide to the Caltech Campus (EE Dept.)
which I also have a copy (for a different type of RISK).

Any resemblence to the film "Real Genius" by M. Coolidge is intentional.
The Book does not contain recent stories of 1) the Rose Bowl Attack
on the score bowl (MIT 6 Caltech 25) [documented in earlier RISKs],
or 2) the recent changing of the Hollywood sign.  This will all have
to be covered in some future edition.

Of computer interest is the ARCHES program which was used to stuff
1.5 million entry addresses into a McDonald's contest in the 1970s.
This 11 line FORTRAN program is the reason why game cards make
comments about no electronic reproduction.

Please note: I was never a Caltech student.  I have many friends there and
was a Caltech employee at its Jet Propulsion Lab and at the Institute (CS
Dept.)  itself for which I have the greatest respect [I would rather donate
money to them than my old UC campus, it's better spent at Caltech].

--eugene miya

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Center for Viral Monitoring -- I'm trying!
</A>
</H3>
<address>
Chip Copper 
&lt;<A HREF="mailto:copper%bgsu.edu@RELAY.CS.NET">
copper%bgsu.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Wed, 27 Apr 88 10:18:06 EDT
</i><PRE>

I have been trying to keep track of Macintosh viruses, but unfortunately
my input is limited to articles in this group and on the news networks.

I've tried to send out surveys and solicit virus information from several
different sources, but everyone refuses to give you any information on
the virus.

I have no idea of how to legitimatize myself!  I am sincerely interested
in studying and tracking these rascals, but everyone assumes I'm just
trying to do further damage to the community.  Phone calls don't help!
Letterhead doesn't help!  Calls from officials at my University don't help!
I realize people have to cautious, but I'm stumped!  How do we solve a
problem no one is willing to discuss?

Everyone who gets a virus posts a message telling what it does and how
to rip it out of an infected system.  Ask for any other information on the
virus, and you hit a brick wall.

I am willing to study and track all Macintosh viruses, but it will take
the cooperation of those getting the viruses to help solve the problem.

I welcome ANY feedback on this!  Any suggestions?  Any of you out there
who have viruses willing to cooperate?  Any government agency
out there willing to investigate me and verify my intentions?

(A frustrated)  Chip Copper, Ph.D. 
Assistant Professor
Department of Computer Science
Bowling Green State University
Bowling Green, Ohio 43403-0214
(419) 372-8142  (My office)
(419) 372-2337  (Department office)

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
ATM blues
</A>
</H3>
<address>
Bob Sidebotham 
&lt;<A HREF="mailto:bob+@andrew.cmu.edu">
bob+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Wed, 27 Apr 88 12:00:16 -0400 (EDT)
</i><PRE>

My wife deposited a cheque in a Pittsburgh National Bank ATM.  After the ATM
had accepted the cheque, it aborted the transaction for some reason.  She
complained to the bank, and they assured her that everything would be taken
care of.  What actually happened is that all of our cheques this month
bounced...

Some years ago, I banked with the Canadian Imperial Bank of Commerce.  The
Commerce's system for deposits was different from any I've seen in the U.S.:
After keying in the particulars of your deposit, the system issued you a
deposit ticket which you then inserted into the envelope with the deposit.
When the transaction completed, you got the standard receipt.

This simple scheme was very useful because (1) it allowed you to deposit money
without getting frostbite while writing the particulars on the envelope, (2) it
provided a transaction identifier which the bank could (and presumably did) use
to verify that the transaction was committed, without any possible ambiguity,
and (3) it guarded against any mistakes that you might make (listing a
different chequing account, etc.), which would be compounded by an error on the
part of the ATM (such as aborting the transaction), and (4) it provided a
printed verification of the particulars of the transaction that the user could
check just before committing his end of the transaction.

I suppose it's possible that the American systems print this information
directly on the envelope as it's sucked into the ATM, but that doesn't seem
very likely.  In any event this would obviate the advantage of *knowing* that a
readable printed record was actually enclosed with the deposit.

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Yet another ATM story
</A>
</H3>
<address>
&lt;<A HREF="mailto:"Bruce_Hamilton.OsbuSouth"@Xerox.COM">
"Bruce_Hamilton.OsbuSouth"@Xerox.COM
</A>&gt;
</address>
<i>
25 Apr 88 18:19:07 PDT (Monday)
</i><PRE>

A few weeks ago I went to a local First Interstate Bank branch and tried to
withdraw some cash, using my Xerox Federal Credit Union card.  I got a rather
vague message back, something like "unable to complete transaction".  Thinking
it might be a local ATM problem, I went a couple of miles down the road to the
El Segundo First Bank.  That ATM told me "Your card is damaged".

The next morning I called XFCU and ordered another card (which takes them
over a week to mail to me).  I also retried the old card at XFCU.  Lo and
behold, it worked! It has since worked at many ATM's, including the one that
gave me the bogus "damaged" message.

I wonder how much these vague or bogus error messages are costing the financial
institutions in this country?  What's so difficult about putting up a message
like, "Unable to communicate with your bank's computer at this time.  Try again
in a few hours."?
                                        --Bruce

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
YADBR (Yet Another DB Risk)
</A>
</H3>
<address>
&lt;<A HREF="mailto:munnari!ditmela.oz.au!george@uunet.UU.NET">
munnari!ditmela.oz.au!george@uunet.UU.NET
</A>&gt;
</address>
<i>
27 Apr 88 10:26:31 +1000 (Wed)
</i><PRE>

George Michaelson, CSIRO Division of Information Technology
ACSnet: G.Michaelson@ditmela.oz.au                   Phone: +61 3 347 8644
Postal: CSIRO, 55 Barry St, Carlton, Vic 3053 Oz       Fax: +61 3 347 8987

(written by Colin Brammall in Computerworld Australia, reproduced
 without permission)

   HEADLINE: GOSSIP DATABASE - Uni dossier of 'soft' info

   SYDNEY - A computer-based intelligence-gathering system, which creates
dossiers of "soft information" such as rumour, gossip, ideas and
personal assessments has been developed at the University of N.S.W.

   Several Federal Government [that means Australia not USA] bodies
including the Army and the Department of Industrial Relations have
been shown the product, which runs on any DEC vax machine.

   It has apparent potential for intelligence bodies such as Asio and Asis
and even for Federal cabinet, as well as for departmental and
private-enterprise hierarchies.

   The basis is a high-level messaging system linked to a database which
electronically duplicates face-to-face meetings. It is intended to pull
together relevant information that might otherwise remain in
individuals minds.

   The discussion/conference is simple. "If people read a message and they
want to add to the information, or challenge it, they comment on it,
which causes a conference to be created, and a debate opens up with all
interested people on the system," said Cyril Brookes, professor of
information systems at UNSW, who headed the team which developed the
system.

   The keyword/message system is based on a thesaurus of terms unique to
the user organisation, designed to cover all the concepts that anybody
in the organisation is likely to message about.

   Each message is coded with one or more of the thesaurus terms, and is
given a level of importance. The highest level might be for the
minister/chairman of the board, the next for all first assistant
secretaries/general managers and so on.

   Each user builds an interest profile, putting an order on the system
for messages containing certain topics, sub-topics and keywords, and
levels of importance.

   Professor Brookes said the system reported informal information in much
the same way that traditional databases reported formal information
through such things as exception alerting and as-necessary detail.

   Because soft information did not pop completely in one place or time,
the system brought together all the people who had  information to
contribute.

"we have been fascinated for 10 years or so about the lack of attention
paid by the computer community to informal or soft information" Brookes
said.

"it is my view that the informal data are the most under-utilised
resource that managers have available to them."

   Normal databases recorded history he said. "The future, which is what
decisions are about, is not related to history tremendously. The clues
to what is going to happen are in peoples minds and in their informal
contacts."

   Bulletin boards and messaging systems do not do the job because they do
not massage the information.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.72.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.74.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-21</DOCNO>
<DOCOLDNO>IA012-000129-B045-255</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.74.html 128.240.150.127 19970217021004 text/html 24205
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:08:31 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 74</TITLE>
<LINK REL="Prev" HREF="/Risks/6.73.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.75.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.73.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.75.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 74</H1>
<H2>  Sunday 1 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
KAL007 and Bourland's Electronic Warfare Theorem 
</A>
<DD>
<A HREF="#subj1.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Prestel Hacking 
</A>
<DD>
<A HREF="#subj2.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Uncritical acceptance of computer results 
</A>
<DD>
<A HREF="#subj3.1">
Paul L. Schauble
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Supermarket buying habits databases 
</A>
<DD>
<A HREF="#subj4.1">
Richard Wiggins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Virus protection 
</A>
<DD>
<A HREF="#subj5.1">
Phil Goetz
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
KAL007 and Bourland's Electronic Warfare Theorem
</A>
</H3>
<address>
Clifford Johnson 
&lt;<A HREF="mailto:GA.CJJ@forsythe.stanford.edu">
GA.CJJ@forsythe.stanford.edu
</A>&gt;
</address>
<i>
Sat, 30 Apr 88 10:43:57 PDT
</i><PRE>

    From: Steve Philipson &lt;steve@ames-aurora.arpa&gt;
       The article in RISKS 6.70 by Clifford Johnson sent me reeling.

The evidence in R.W.Johnson's Shootdown sent me reeling too.

    To quote NTSB Part 830.1 Applicability:
        This part contains rules pertaining to:
       (a) Notification and reporting aircraft accidents and incidents and
    certain other occurrences in the operation of aircraft when
    they involve CIVIL AIRCRAFT OF THE UNITED STATES wherever
    they occur, or FOREIGN CIVIL AIRCRAFT WHEN SUCH EVENTS OCCUR
    IN THE UNITED STATES, ITS TERRITORIES OR POSSESSIONS.
    [emphasis added]

Besides the careful rebuttals in Shootdown, and besides the fact that the
NTSB automatically began an investigation in recognition of its plain duty,
the statutory definition indisputably applies.  KAL007 was off course RIGHT
FROM TAKEOFF - the cause of the accident happened in the U.S.A., maybe in
Washington.,D.C.  The error was major by the time the flight left the
guiding auspices of U.S.A.  controllers. I know the wording you quote was
the official excuse for squelching the inquiry, but that's all it was, a
lame excuse.  Do you seriously contend that the NTSB has no duty to
investigate why American-made planes with navigational systems that are
standard might take off in the wrong direction from U.S. airfields?

  Johnson refers to _Shootdown_ by R.W. Johnson, who provides "astonishing"
  evidence that KAL007 was on an espionage mission.  This certainly is
  astonishing, as all other available information leads away from this
  conclusion.

One of the astonishing things about the evidence in Shootdown is the fact that
it shows amazing failures to report key evidence in the United States press.  I
doubt if you can find any potentially important piece of information not
covered in Shootdown, and books like Hersh's are a joke by comparison.  I
understand your incredulity, because the U.S. media has all but successfully
stamped out proper consideration of the evidence.  There is a sort of
presumption that the press would report and evaluate key evidence, and that it
has kept quiet is interpreted as a sort of proof that the evidence does not
exist.  Indeed, you make this very argument, citing the reliability of the NYT.
But the New York Times in not reliable in reporting such matters.  For example,
after the U-2 shootdown, it parroted Eisenhower's lying denial, although it was
later learned that the editor had known about the illegal spy flights for
months, without informing the readership.  The disinformative disregard of
KAL007 facts by the American press is noted in detail as appropriate throughout
Shootdown.

  What has all this to do with RISKS?  If we classify a massive error as a
  deliberate act, we dismiss the need for investigation as to why the error
  occured, and remove all possibility of discovering and/or correcting any
  problems.  The "deliberate act" explanation is a variation on "pilot error".
  If an accident is simply hand-waved away as "pilot error", we lose the
  opportunity to understand what in the system allowed that error to occur, and
  we do nothing to decrease risk and the possibility that the error will occur
  again.

So you think that the NTSB should have investigated the cause of KAL007's
taking off in the wrong direction?  Here, here!

  The really interesting things that have come up in the investigation of this
  incident are the multiplicity of ways designing systems that are more safe.

No one designed a safer navigation computer because of all these theories.
All of the multiplicity of theories of errors have been demonstrated to be
fatally inconsistent with KAL007's course, unless one chooses to believe
that the radars were all wrong.  It's the inability to devise even one not
incredible sequence of errors to fit the route that is of interest.  And
that is why my submission belonged on RISKS.  There are instances in which
we should point to the inadequacy of "computer/operator error" explanations,
i.e. excuses, and in my opinion this is one of those instances.

Since virtually all my information is from Shootdown, I will simply refer
readers to this book for further facts, and not respond further myself re
KAL007.  But setting this aside, I'd be interested any other applications of
Bourland's Electronic Warfare Theorem.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Prestel Hacking
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Sun, 1 May 88 13:33:11 +0100
</i><PRE>

  The most celebrated "telephone hacking" court case in Britain so far involved
penetration of British Telecom's Prestel viewdata service. Legal history seemed
to have been made when the perpetrators were convicted of having committed
forgery! However the Appeal Court threw out the conviction, and this decision
has just been finally confirmed by the House of Lords. Thus in Britain, at any
rate, it seems that new laws will be needed to cope with such activities.
 
  On April 28, the Guardian carried a lengthy article, written by one of
the hackers. It is given here, in its entirety (without permssion), for the
editor to hack out those parts which are most likely to be of interest to
the RISKS readership. [Why should PGN have a British Telecom-like monopoly on
bad puns!]
 
Brian Randell
 
 
HACKERS LET OFF THE HOOK
 
Steve Gold explains what really happened in the Prestel case, resolved by the
the Lords last week:
 
  "The first inkling I had that there was a world ready to be dialled up was
when British Telecom installed international direct dialling in my home town,
Sheffield, back in 1971. I soon discovered that you could dial certain codes
and, subject to a slight deterioration in call quality, not incur any charges.
 
  This cost me dear. In May 1975, along with several other Sheffield students,
I was fined (pounds)100 for placing national and international telephone calls
without payment.
 
  Several years later, in 1983, I bought a computer. And while I was fiddling
away with my Sinclair Spectrum, East Midlands Allied Press was busy negotiating
with British Telecom to launch a microcomputing service on Prestel: Micronet
800. Initially the service was available to users of the Acorn BBC micro, but
soon Micronet and Prestel launched a Sinclair Spectrum hard-wired modem, the
Prism VTX5000. In August 1984 I bought one for (pounds) 74.95.
 
  I was equipped to use Prestel, but Prestel was boring. While waiting to be
admitted to Micronet 800, I discovered that, if you sounded plausible enough,
you could gain editing rights to unrouted pages on the Prestel database. These
pages were known as the prestel Scratchpad.
 
  A friend and I joined forces and developed a software editor for the
Spectrum/VTX5000 combination and, much to Prestel's incredulity, began to use
it to edit Prestel pages offline and upload them to the database. Before long,
Micronet 800 hired us to edit pages on their database.
 
  In the summer of 1984, an electronic acquaintance (we had never met) told me
that he'd discovered a simple ID of ten 2s and a password (1234) which gained
admission to Prestel without paying.
 
  That was Robert Schifreen, and the ID was a Mr G. Reynolds, whose profile
on Prestel identified him as a member of BT staff. He was entitled to look
at areas on the database not normally accessible to members of the general
public.
 
  Those pages contained the nucleus of how Prestel worked, right down to the
telephone numbers of Prestel computers we'd never even heard of. One of these
"development computers" had an unusual log-on frame: it welcomed modem users
with, and prompted them to enter, their ID and password. It had a series of
numbers on its log-on frame which both Robert and myself recognised as a
Prestel ID and password.
 
  Keying in these numbers resulted in the user logging on (that is, gaining
admission to the database) as the system manager. The system manager could do
things with Prestel that no other user could do. this included interrogating
the user files to obtain IDs and passwords by the cartload.
 
  Thus, at the press of a few keys, the system manager could obtain information
that enabled him or her to log on as any other subscriber on the system. Also,
using information-provider IDs and passwords, it was possible to alter or amend
pages.
 
  We had hacked Prestel at the highest level.
 
  However, power brings responsibility, and since we were both active
contributors to the Micronet database, we approached Micronet's staff to show
them. Micronet duly contacted Prestel, who were made aware of the incredible
loophole in their security.
 
  Prestel strove to protect the integrity of their database. Changing
everyone's ID on the database was not worthwhile, in its opinion. Information
providers - high-ranking subscribers who rented their own pages - were seen as
a high risk, since anyone using their IDs and passwords (obtained using the
system manager ID) could alter or delete pages at will.
 
  So within a matter of days, Prestel changed the information-provider
passwords. But they made a mistake. Instead of changing them completely, they
merely transposed the access and editing passwords! Since Robert and I were
editors on the system (using Micronet-supplied IDs) we were notified that our
original passwords of (say) ABCD and 1234 had turned into 1234 and ABCD.
 
  After a phenomenal process of deduction, we applied the same transposition to
a selection of information-provider passwords in our possession. They worked.
 
  Fortunately for BT, information providers realised the crassness of Prestel's
attempt to plug its security and changed their own passwords, thereby barring
normal (but unauthorised) access to Prestel editing facilities to Robert and
myself.
 
  But amazingly, Prestel had left a trapdoor for us to use. The high-speed
update ports, by which information providers could edit their pages in bulk,
required only an editing password. Most information providers kept their own
editing password, believing that their access passwords had been changed.
 
  After noting a little judicious editing, Prestel was faced with the awful
truth: it's security division had said that the hacker problem had been
resolved, yet pages were being changed again under their noses. Prestel finally
changed its information-provider IDs and passwords, thereby plugging the gap.
And that seemed to be that.
 
  We had told Prestel (via Micronet) about the security lapse. We'd also had a
little fun at Prestel's expense. Prestel recognised what we had done, and that
we hadn't done anything stupid such as altering or deleting pages on the
database. The incident passed into history, or so we thought.
 
  During October and November, Prestel placed a telephone tap on Robert's north
London home telephone line. After monitoring his activities they found he was
frequently calling a Sheffield number (he was comparing notes with me). By
January 1985, they thought they had enough information to prosecute us both.
 
  Had we know about it, we would have expected a prosecution under the Theft
Act - for theft of (minute amounts of) electricity. But Prestel and BT were
worried about computer-hacking. IDs and passwords were being exchanged at an
alarming rate. Prestel IDs (as passwords) were assuming the same level of
security as train numbers. ID spotters (apprentice hackers) were hanging around
on Prestel, using the message boards (chatlines) to exchange passwords.
 
  BT logged Robert sending me an electronic mail message (using someone else's
ID and password). The message contained the ID and password of that account.
BT later produced that message in court as confirmation of our hacking
activities. Unknown to BT (and Robert) however, I had already obtained this
particular ID and password from the Prestel chatlines. I already knew that
these particular details were passing around dozens of users.
 
  Prestel had problems. Hordes of youthful users were staging multiple log-ons.
One particular group even boasted of its intention to "clock' an account one
weekend.
 
  Like car mileometers, Prestel accounts had a rolling tally of the charges on
an account. These went up to (pounds) 9,999.99, at which point the meter would
roll over to zero and start again. The chatline boasters intended continually
to access chargeable areas of the database until the (pounds) 10,000 mark was
broached. Such pointless activities took place often in 1985. Prestel thought
they had tracked two major hackers in Robert and myself. In fact they had
latched onto two journalists who were compiling a dossier of online security
breaches. The real hackers were - and are - still at large.
 
  On Tuesday March 26, two groups of police officers and BT staff
simultaneously raided my house in Sheffield and Robert's house in north
London. We were both driven to Holborn police station in London and held
overnight and throughout most of the following day. It was with some amazement
that I discovered in the course of my interview with Detective Inspector John
Austin and BT security chief Ron Aston, that I had been arrested for hacking.
Up to that point I had suspected that someone - probably an online acquaintance
- had committed a major bank robbery.
 
  We were subsequently charged with committing a number of offences contrary
to the Forgery Act 1981. Forgery is, we were told, a serious offence and can
carry a prison sentence of ten years. Ten years - just for breaking into
Prestel, and telling them what we had done!
 
  Rather than printing dud fivers in our kitchens we had "forged" an area of
Ram (random access memory) in the Prestel computer - using our modems over the
telephone line - which existed for about one fortieth of a second before being
wiped clean. Could BT provide the instrument (the area of Ram) in court, the
judge asked. No, since the area of Ram was etherial. It was, in fact, an area
of the program known as the user segment. Our guilt or innocence hinged on
how an electronic signal was interpreted by the court.
 
  We were convicted and fined, but the case came up for appeal in July last
year. The three Appeal Court judges - presided over by Lord Justice Lane -
mulled over the arguments. Several weeks later, Lord Lane announced he was
quashing the conviction, calling the case a blatant attempt to mould the facts
of the case to fit the scope of the Forgery Act.

  I was dismayed to discover that BT had applied to take the case further, to
the House of Lords. But the highest court in the land concurred with Lord Lane's
decision from the Appeal Courts that, if hacking was to be considered a crime,
then a change in the law was required.
 
  We are free, but the issue remains unresolved."

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Uncritical acceptance of computer results
</A>
</H3>
<address>
&lt;<A HREF="mailto:portal!cup.portal.com!Paul_L_Schauble@Sun.COM">
portal!cup.portal.com!Paul_L_Schauble@Sun.COM
</A>&gt;
</address>
<i>
Sat Apr 30 17:04:33 1988
</i><PRE>

My mental library of computer system risks contains an item about an experiment
involving electronic calculators. The researchers assembled a group of
engineering undergraduate students and gave them gimmicked calculators. These
calculators would give answers that were related to the numbers entered, but
which were wrong by various amounts. They then gave the students problems
from their lab work to calculate. They were looking to see how far wrong the
calculators could be before the students noticed problems.

As I recall the results of the experiments, they effectively never did notice.
It seems that the fine art of estimating reasonable answers as a check went
out with slide rules.

Now, I need a specific reference to this study. A friend is considering doing
something similar to update the work to computers. I recall reading about the
original sometime in the mid seventies. Can anyone help out?

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Supermarket buying habits databases
</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard_Wiggins@um.cc.umich.edu">
Richard_Wiggins@um.cc.umich.edu
</A>&gt;
</address>
<i>
Fri, 29 Apr 88 23:22:40 EDT
</i><PRE>

Stanley Quayle's report of supermarkets using Social Security Numbers
to keep up with buying habits is a matter for concern, but it's
probably not uniquely nefarious.
 
In Michigan we have driver licenses that are not based on SSN.
Instead, they are a hash function on the person's name.  (In
fact, the same function is used by some other states; I once
knew someone who moved to Michigan and was surprised to learn
his driver license number remained the same.)
 
Supermarkets that I use also perform online validation of checks.
A department store that I shop at also allows credit card
customers to cash checks.  When you do so, they key in the
driver license number as well.  Once I noticed the clerk make
a typo as she typed mine in.  Before I could speak up, the
register said "Approved" and she'd finished the transaction.
 
It seems clear that in fact the check approval process is simply
querying a list of hot numbers.  If your driver license number
has not been added to the list, you are approved, and the
transaction continues.  This is a read-only transaction.
 
Now, clearly down the road there is cause for concern.  As
storage capacity gets cheaper and  cheaper it might become
economical for stores to keep up with this information.
I've read claims that stores would like to send personalized
brochures based on your buying habits.
 
In fact, I've wondered if stores like Sears don't already do
so.  I assume Sears keeps mailing me its Big and Tall catalog
because I occasionally order their products.
 
So, although I think the supermarkets have too much traffic
to keep up with how many avocados each of us buys, it may only
be a matter of time until they  can.  When they do, I don't
think those of us in states that don't use SSN have any
greater privacy than Ohioans.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Virus protection
</A>
</H3>
<address>

&lt;<A HREF="mailto:PGOETZ%LOYVAX.BITNET@CUNYVM.CUNY.EDU">
PGOETZ%LOYVAX.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Sat, 30 Apr 88 16:04 EST
</i><PRE>

Somebody (I forget who) said,

&gt;To suggest that [write-protection] is 100% effective against a virus is to
&gt;overstate.  Studies in biology suggest that a virus can thrive even in a
&gt;population in which a large percentage of the members are immune, if a there
&gt;is sufficient commerce among the non-immune members...

&gt;Depending upon design of the virus, the target system and population, and the
&gt;chosen distribution vector, the effectiveness of this mechanism against the
&gt;spread of the virus might vary from high to none at all.

   Now, think about that for 2 or 3 seconds.  If you turn on your machine,
write-protect all the drives, run a virus unknowingly, and turn off your
machine, you will NOT be infected by any possible virus.  It is IMPOSSIBLE
unless you have bubble memory or FRAMs or something like that.  When you
turn the machine on next, it is in the same startup configuration as before.
The biology analogy is unapplicable.
   Of course, if you are using your computer as a terminal, you might
move a virus between accounts on a mainframe, or between different
computers you dial up.  But your computer is protected.

Conclusion: Write-protecting the hard drive can offer 100% protection.

Phil Goetz

   [But you are assuming that between the time you "turn on your machine"
   and the time you write-protect all the drives that you have not already
   been done in.  How do you know the operating system has not already been 
   compromised?  How about workstations on which files must be downloaded
   from a file server?  How about workstations with no hard disk?  In general
   there is no such thing as 100% protection (despite Fred Cohen saying he can
   detect all viruses).  There are far too many vulnerabilities in most
   systems, with lots of security flaws and opportunities for Trojan horses
   that run with all of your normal privileges... "Anything you can do, I
   can do better," said the Trojan horse.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.73.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.75.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-22</DOCNO>
<DOCOLDNO>IA012-000129-B045-282</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.75.html 128.240.150.127 19970217021020 text/html 27144
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:08:44 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 75</TITLE>
<LINK REL="Prev" HREF="/Risks/6.74.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.76.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.74.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.76.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 75</H1>
<H2>  Monday 2 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The effectiveness of write-protection 
</A>
<DD>
<A HREF="#subj1.1">
WHMurray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Brain virus remembered 
</A>
<DD>
<A HREF="#subj2.1">
Fred Cohen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  To speak of the disease is to invoke it? (Viruses)  
</A>
<DD>
<A HREF="#subj3.1">
Fred Cohen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Fear of Fear of Viruses 
</A>
<DD>
<A HREF="#subj4.1">
John Chambers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  New BITNET LISTSERV group for discussing viruses 
</A>
<DD>
<A HREF="#subj5.1">
Kenneth R. van Wyk
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: KAL007 
</A>
<DD>
<A HREF="#subj6.1">
Don Wegeng
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  "Human Error" and RISKS of being deceased 
</A>
<DD>
<A HREF="#subj7.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Pitfalls of simulation (economic models) 
</A>
<DD>
<A HREF="#subj8.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Re: bad checks 
</A>
<DD>
<A HREF="#subj9.1">
Brian Kantor
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: NORMAL ACCIDENTS 
</A>
<DD>
<A HREF="#subj10.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Re: Stores and SSNs and Perrow 
</A>
<DD>
<A HREF="#subj11.1">
David Chase
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  W.H.J. Feijen on Formal Specification of Programs 
</A>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 The effectiveness of write-protection
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Mon, 2 May 88 10:38 EDT
</i><PRE>

Phil Goetz quotes (without attribution to me, probably out of deference to my
age) as follows:

  &gt;To suggest that [write-protection] is 100% effective against a virus is to
  &gt;overstate.  Studies in biology suggest that a virus can thrive even in a
  &gt;population in which a large percentage of the members are immune, if a there
  &gt;is sufficient commerce among the non-immune members...

  &gt;Depending upon design of the virus, the target system and population, and 
  &gt;the chosen distribution vector, the effectiveness of this mechanism against 
  &gt;the spread of the virus might vary from high to none at all.

Those of you that read the original posting may remember that the reference in
the original posting was not to "write-protection" in general but to a specific
hard-disk write protection mechanism that could write protect up to 80% of the
hard-disk.  You may also recall that the ellipsis at the end of the first
paragraph represents:

  &gt;This is not an argument against vaccines but only a caution
  &gt;about the limits of their effectiveness.

Mr. Goetz asserts:

  &gt;Conclusion: Write-protecting the hard drive can offer 100% protection.

I concede the following:

Write-protecting 100% of the hard drive 100% of the time can offer 100%
protection against any contamination or infection of the hard drive.  100%
protection of 100% of all hard drives (an absurd case) can provide 100%
protection against any infection of those hard drives.  However, even write
protection of 100% of 100% of the hard drives will not be 100% effective
against 100% of viruses.  [I refer Mr.  Goetz to Mr.  Cohen for proof of that
assertion.]

The assertion in the second pargraph was also made in the narrow context of the
particular implementation of write-protection which was the subject of the
posting.  However, upon inspection, I conclude that it stands by itself.  I
leave it to Mr. Goetz' peers to instruct him as to why.

Mr. Goetz concedes:

  &gt;Of course, if you are using your computer as a terminal, you might move a
  &gt;virus between accounts on a mainframe, or between different computers you 
  &gt;dial up.  But your computer is protected.

The interesting characteristic of a virus is not how it behaves in the target
machine but how it behaves in the community.  The interesting characteristic is
the ability of the virus to replicate rather than its ability to infect.  The
XMASCARD program did not infect; it only replicated.  After it replicated a
sufficient number of times, the number of copies overwhelmed the community.

The issue here is not how or whether you can protect yourself.  Rather it is
how viruses will behave in a community of systems many of which are not
protected.  It is whether or not Mr. Goetz will have to write protect his
hard disk.  It is whether or not the community will be sufficiently orderly
and well behaved that we can safely share programs and other data that we
did not create ourselves.

Forgotten, but not gone.                                      Bill Murray

William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
2000 National City Center Cleveland, Ohio 44114
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Brain virus remembered
</A>
</H3>
<address>
fc@ucqais.uc.edu (Fred Cohen)  
&lt;<A HREF="mailto:pyramid!uccba!ucqais!fc@unix.SRI.COM">
pyramid!uccba!ucqais!fc@unix.SRI.COM
</A>&gt;
</address>
<i>
1 May 88 20:51:23 EDT (Sun)
</i><PRE>

Some info on the brain virus not previously mentioned by those who were
trying to quell it - it modifies several .com files, maybe all of them
eventually, without changing file sizes or dates - this was found by
using a cryptographic checksum on a golden unit, infecting it, and
looking at the results. Apparently, at Miami U of OHIO, they were
accidentally reinfecting every time they cleaned a disk because they
had NO GOLDEN UNITS! We found a 2 year old disk and are going to use
this as a beginning from now on. We also got help from a programmer who
wrote a little routine that checks for changes in the interrupt vectors
and halts the machine as soon as they change. We are in the process of
installing an improved self defending command interpreter, but are having
a hard time because we cannot get sources for the system files we are
trying to protect. Once again, protectionism causes more problems than
benefits. Oh yeah, did I forget to mention, that since you cannot write
protect lotus, etc because of copy protection, you cannot keep them from
getting infected - I thought I should bring it up. Finally, even if you
rewrite the boot sector, the brain we found remains active through the
com files it modified. So much for the cures I've heard about. As always,
suggestions are welcomed, but I think we will get it under control before
the summer break (2 days away). If we don't it could be real trouble for
the rest of you. - Fred

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
To speak of the disease is to invoke it?  (Viruses)
</A>
</H3>
<address>
fc@ucqais.uc.edu (Fred Cohen) 
&lt;<A HREF="mailto:pyramid!uccba!ucqais!fc@unix.SRI.COM">
pyramid!uccba!ucqais!fc@unix.SRI.COM
</A>&gt;
</address>
<i>
1 May 88 21:09:54 EDT (Sun)
</i><PRE>

In WHMurray's recent article to this bboard, I hear the same sounds
I have heard for years when attempting to discuss computer viruses
in an open forum. To speak of the disease is to invoke it. Did anyone
ever consider that the disease is inevitable, but the defense is not.

Society does not progress by failing to recognize threats, by hiding
its head in the sand, or by ignoring gaping holes in its integrity.
It survives by identifying corruption and eliminating it. Those who
would permit society to live in a situation so frail that a single
attacker could bring it to its knees, and then try to cover up that
knowledge by hiding it from those best prepared to put up a defense
are begging for the destruction of that society. Imagine howbad the
virus situation would be 20 years from now if we didn't find out about
it now! We would have cars that could be infected, automated airliners
waiting for an accident to happen, automated defense systems that
could strike individuals deads directly from space, all existing in an
environment without integrity.

To hide the truth is not to make the world safe. Only the truth can
set us free from the oppressive forces that lack integrity but live
in a dearth of secrecy. I think we need to start to spend our efforts in
computer security on protecting integrity, not secrecy, and I will say
it in public forums, dispite the best efforts of some of our government
agencies to keep me from doing it. Furthermore, I will continue to encourage
others to do so.

Don't get me wrong,. I don't think we should glorify attackers, I think we
should start to talk about rational defenses that protect the individual.
Don't forget that society is made up of individuals, and that by protecting
those individuals, we protect the society as well. It is the attempt to
protect the society by allowing individuals to come to harm that rationalizes
needless wars, police actions, illegal arms deals, and the whole slew of other
corrupt practices that are bringing our society down. It is the truth that
will set us free, but only if we are brave enough to face it.

	Sorry for the flaming nature of this, but I feel strongly on this
	issue, and have had enough from those who would silence important work.

				Fred

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Fear of Fear of Viruses (Re: <A HREF="/Risks/6.73.html">RISKS-6.73</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ames!necntc!adelie!minya!jc@ucbvax.Berkeley.EDU">
ames!necntc!adelie!minya!jc@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Mon, 2 May 88 01:23:22 PDT
</i><PRE>

You've described a general problem, of people refusing to document security
problems out of fear that some unscrupulous readers (or children) will use
the information.  The result, of course, is that honest computer users are
kept ignorant while the dishonest ones slowly learn the tricks.

I've discovered one approach that is often successful at tricking people
into telling me about the problems.  I tell them that I don't believe them.
Very often they will respond by trying to demonstrate my ignorance, and of
course, the only way they can do this is to demonstrate the problem.

You can vary the form of the insult quite a bit.  For instance, if they have
named a particular commercial product and claimed that it is infected, you
can suggest that they have a financial interest in another product, and are
using scare tactics to discredit a competitor.  (This isn't hypothetical, of
course; people have done this.)

Recently, there was a debate in unix.wizards about a supposed security
problem with the Bourne-shell's IFS feature.  The same debate raged, with
nobody willing to document the problem.  I finally got fed up, and announced
that I didn't believe there was a problem; that they were just shooting off
their mouths, trying to sound like security wizards when they weren't.  I
got lots of flames that didn't document any problems, but among them was one
letter containing a piece of code that used IFS to create a shell that was
setuid to root.  It's now part of my collection of security bugs.

As for viruses, I have the feeling that most people talking on the subject
are rather ignorant, and can't tell you or me anything.  Perhaps if you
challenge them, you can find a few who will try to show that they know more
than you....

John Chambers &lt;{adelie,ima,maynard,mit-eddie}!minya!{jc,root}&gt; (617/484-6393)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     New BITNET LISTSERV group for discussing viruses.
</A>
</H3>
<address>
"Kenneth R. van Wyk" 
&lt;<A HREF="mailto:LUKEN%LEHIIBM1.BITNET@CUNYVM.CUNY.EDU">
LUKEN%LEHIIBM1.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 02 May 88 15:54:24 EDT
</i><PRE>

For anyone who may be interested, I've started a LISTSERV discussion
forum on BITNET, entitled VIRUS-L.  It is dedicated to the discussion
of computer viruses, including present viruses and their progress, and
the prevention/detection of viruses.

To subscribe to the list, as with any LISTSERV-run list, send a message
to the appropriate LISTSERV; in the message, say:  SUB listname your name.
That is, send a mail message to LISTSERV@LEHIIBM1, stating SUB VIRUS-L your
real name.  To subsequently sign off of a LISTSERV group, send a message
to the appropriate LISTSERV stating SIGNOFF listname.  Please do not
send these requests to the list itself, as they will be distributed to
the entire list [and] do nothing other than annoy people...  :-)

Once subscribed, send list submissions to VIRUS-L@LEHIIBM1.

VIRUS-L is currently open to the public.

Regards,

Ken van Wyk

Kenneth R. van Wyk, 
User Services Senior Consultant, Lehigh University Computing Center, 
Internet: &lt;LUKEN@VAX1.CC.LEHIGH.EDU&gt;, BITNET: &lt;LUKEN@LEHIIBM1&gt;          

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: KAL007
</A>
</H3>
<address>
Don Wegeng 
&lt;<A HREF="mailto:Wegeng.Henr@Xerox.COM">
Wegeng.Henr@Xerox.COM
</A>&gt;
</address>
<i>
2 May 88 09:01:09 EDT (Monday)
</i><PRE>

In regards to the continuing debate in RISKS about the KAL007 incident, it
appears that one side of the argument is putting all of its faith in the
version of the story reported in the book "Shootdown". It seems to me that you
are always at RISK when you chose to put all of your faith in a single source,
be it a pressure sensor in an engine, the phone company's billing system, an
elected official, or a book about an aircraft that was shot down.

   [... and the OTHER side of the story is putting its faith on information
   that is all derived from one set of interrelated sources???  If you wish to
   speak in analogs with fault-tolerant computing, beware of the common-mode
   failures that can undermine supposedly redundant systems.  By the way,
   one difficulty with trying to prove a conspiracy theory is that everyone on
   the inside will deny it (which may thus seem credible), whether or not the
   theory is true.  So, you are ALWAYS AT RISK, period.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
"Human Error" and RISKS of being deceased
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Mon, 02 May 88 09:12:28 PDT
</i><PRE>

In the Letters column of the 1 May 1988 NEW YORK TIMES MAGAZINE (p. 14),
a Steven Goldberg writes concerning an earlier article (27 March) on civil
aviation accidents.  He observes, "In the 'all accidents' category, the 
pilot is found responsible for the accident in only 38.6 percent of the 
cases.  However, in the 'fatal accidents' the pilot is found responsible
61.5 percent of the time.  It may be that there is a benign explanation for
the fact that a pilot who is dead is far more often blamed than one who can
defend himself.  But the prima facie conclusion, in the absence of such an
explanation, is that considerations other than safety lead the authorities to
blame the pilot, who can not speak for himself."

- Jon Jacky, University of Washington

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Pitfalls of simulation (economic models)
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Mon, 02 May 88 09:26:51 PDT
</i><PRE>

The 1 April 1988 issue [!!] of DATAMATION includes an article, "Economic
Modeling Gains Despite Accuracy Concerns," by Gary McWilliams (pps. 43-54).
I am not familiar with this field, and the article never really explains
what the inputs and outputs of the models are, where they come from or 
how they are validated.  Nevertheless, people apparently use them to 
forecast economic trends and seem to regard them as useful.  One model,
called Project Link, includes more than 20,000 equations.  

Much of the article appears to be based on an interview with Sam Cole,
economist and model builder at SUNY Buffalo, and author of GLOBAL MODELS AND
THE INTERNATIONAL ECONOMIC ORDER (Oxford Pergamon, 1977).  The article reports,

"The World Bank uses a global model in its lending, says Cole, sometimes to 
the detriment of its debtors.  'When the World Bank lends [a country] money,
it expects that country to have a [repayment] plan, and usually pursuades the
country to accept World Bank forecasts.  Since its forecasts are usually 
wrong, these countries end up with debts and no way to repay them,' says
Cole.  The World Bank's use of optimistic growth forecasts often are built
into the models for political reasons, according to Cole."

- Jon Jacky, University of Washington

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Re: bad checks
</A>
</H3>
<address>
Brian Kantor
&lt;<A HREF="mailto:brian@ucsd.edu ">
brian@ucsd.edu 
</A>&gt;
</address>
<i>
Mon, 2 May 88 13:24:37 PDT
</i><PRE>

In the middle 70s I was responsible for designing a simple on-line
inquiry system for automating bad-check lookup for one of those
firms that guarantee checks for retail merchants.

The way this works is that for a monthly fee (based on average
purchase amount and volume), the guaranteee firm would automatically
guarantee any check up to some limit, and provide a guarantee for
any higher amount check that was verified with them.

Initially this consisted of having the guarantee firm's telephone
operators page through a thick paper listing of bad checks and
returning a code 1, 2, 3, or 4 (1=accept:guaranteed, 2=accept:follow
ID procedures and we'll guarantee it, 3=do not accept:no guarantee,
4=do not accept:detain customer, police notified). For example,
checks listed as "stolen" would return a code 4 (yes, they stored
the range of check numbers so that they wouldn't flag unstolen checks
on the same account).  The default (we don't know that check) was
code 2 [i.e., what the store should have done without the guarantee
service].  Merchants would be paid by the guarantee service for a
guaranteed check that didn't clear, and the guarantee service would
then assume the responsibility of collecting on the bad check.
Each inquiry was recorded for amount, the assigned approval number
and code, check customer number (a reference to the name used to
verify/guarantee the check), and the merchant number.  This
was printed in a ledger and cleared from the system each night.

A new entry for someone was given code 2 until they'd been inquired
about several times over some period of time (I seem to recall more
than twice in 30 days), at which time they'd be advanced to code
1 on the assumption that they hadn't bounced any checks yet.  Since
the merchant's best interest was served by reporting bad checks
ASAP, this seemed to work.  Downgrade to code 2, 3 and 4 was manual
and done by accounting types at the guarantee firm from bad check
collections referred by the customer merchant.  Perhaps they also
used other data; I don't know.

The whole premise was that each guarantee office usually served
repeat check customers: it could build a payment history database.
I think the assumption was that people who wrote several checks
without bouncing them would probably continue to do so.

We built the database for online inquiry by storing the last name
Soundex-indexed (as a sort of hashing technique, if you will), and
listing other information such as SSN, driver's license number,
account number on the check, etc in a cross-reference.  If more
than one "hit" occured when an operator keyed in a last name, he
was prompted for more information to resolve the hits, or he could
page through a summary of the records on line to see if one fit
the profile of the check being submitted.

Clearly the RISK here is misidentification: the more information
they stored and the more the merchant's clerk collected for check
verification, the better they could do at eliminating false denials.
The system was clearly biased towards generating accepts to avoid
pissing off honest customers, but to contain the losses of the
guarantees.  Last I heard they were still using revisions of that
software and making a chunk of money.

Note that most of the actual data used to determine check acceptance RISK was
not stored online.  Probably it is now, but at that time (about 15 years ago)
the disk storage was too dear and the retrieval time simply wasn't important:
paper files in file drawers was quite good enough.  Since the review was manual
anyway, it seemed reasonable to have the relevant documents in human-readable
form.  One of them - the returned check - was always on paper anyway.  This all
ran on a Microdata REALITY system with 64K of main memory (the max) and one 10
Meg hard drive.  Nowadays you'd do it on an ATKlone.
                                                     Brian Kantor, UC San Diego

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: NORMAL ACCIDENTS
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Mon, 02 May 88 09:06:43 PDT
</i><PRE>

The May 1, 1988 issue of the NEW YORK TIMES MAGAZINE has a feature article
about Tom Clancy, author of the best-selling thrillers HUNT FOR RED OCTOBER
and RED STORM RISING.  In the background of the obligatory picture of the
author in his study by his bookshelves, you can clearly see NORMAL ACCIDENTS
by Perrow (p. 55, right edge of page, halfway down).

- Jon Jacky, University of Washington

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Re: Stores and SSNs and Perrow
</A>
</H3>
<address>
chase@orc.olivetti.com 
&lt;<A HREF="mailto:David Chase">
David Chase
</A>&gt;
</address>
<i>
Sat, 30 Apr 88 00:15:17 -0700
</i><PRE>

In reply to two articles by Stanley F. Quayle:
&gt; This store uses price scanners.  It would be possible to establish a
&gt; profile of each check-paying customer with this system....If they
&gt; haven't thought of this already, I don't want to give them any ideas.

Don't worry; they've already thought of it and do it.  My wife reports
that Stew Leonard's in Norwalk, Connecticut is one store that does; by
name, and what you buy, and if it was on sale.  Paying cash is the
only sure way to avoid this.

(on Normal Accidents)
I think Perrow was studying nuclear power as it existed from 1979 to
1984, not as it might exist.  I don't think his conclusions on nuclear
power are weakened at all if someone tells me that we could build
safer plants, but don't.  You can rightly say that safe plants haven't
happened for economic, political, legal, and bureaucratic reasons, and
you still haven't weakened his conclusions.

David Chase, Olivetti Research Center, Menlo Park

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
W.H.J. Feijen
</A>
</H3>
<address>
&lt;<A HREF="mailto:adrion%capri.tcp.cs.umass.edu@RELAY.CS.NET">
adrion%capri.tcp.cs.umass.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Sun, 1 May 88 14:47:20 EDT
</i><PRE>

Harvard Distinguished Lecturer Series, GB/SIGPLAN, and GB/SIGSOFT Present:
   
     W.H.J. Feijen, Visting Professor at University of Texas, Austin
     Professor at Technologie Universitat, Eindhoven, Netherlands

Speaking on MAY 3rd, 7:00 pm, Lecture Hall B, Harvard Science Center,
Cambridge, MA, Prof. Feijen promises to update Software Engineers on the
latest developments in the Formal Specification of Programs.  He is co-author
with Edsger W. Djikstra of the recently released "Methods of Programming".  (A
large crowd is expected.)  Host is Professor Mark Schneider, Harvard Univ.
    
</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.74.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.76.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-23</DOCNO>
<DOCOLDNO>IA012-000129-B045-297</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.76.html 128.240.150.127 19970217021032 text/html 21076
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:09:01 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 76</TITLE>
<LINK REL="Prev" HREF="/Risks/6.75.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.77.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.75.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.77.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 76</H1>
<H2>  Tuesday 3 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Supporting data for Hirsh's explanation of the KAL007 incident 
</A>
<DD>
<A HREF="#subj1.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  KAL007 
</A>
<DD>
<A HREF="#subj2.1">
Steve Philipson
</A><br>
<A HREF="#subj2.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  USS Stark 
</A>
<DD>
<A HREF="#subj3.1">
Bahn
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Ada in strategic weapon systems including nuclear attack warning 
</A>
<DD>
<A HREF="#subj4.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Virus protection 
</A>
<DD>
<A HREF="#subj5.1">
David Collier-Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  To speak of the disease is to invoke it?  (Viruses) 
</A>
<DD>
<A HREF="#subj6.1">
WHMurray
</A><br>
<A HREF="#subj6.2">
 Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Detectability of viruses 
</A>
<DD>
<A HREF="#subj7.1">
Fred Cohen
</A><br>
<A HREF="#subj7.2">
 PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Supporting data for Hirsh's explanation of the KAL007 incident
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy%murphy.ics.uci.edu@ROME.ICS.UCI.EDU">
nancy%murphy.ics.uci.edu@ROME.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Mon, 02 May 88 19:19:11 -0700
</i><PRE>

It is interesting to consider whether Hirsh's explanation of how the KAL007
navigation error could have been accidental stacks up against other experiences
with navigation errors in commercial aircraft.  Hirsh claims that pilot
navigation error is the most likely explanation for the KAL incident.

In a magazine called Flight Crew (Fall 1979), Arnold Reiner wrote an article
called "Preventing Navigation Errors During Ocean Crossings," in which he
reports that such errors are common.  He states:

  "During the first six months of 1978, the International Air Transport 
   Association (IATA), reported that 49 North Atlantic flights were observed
   off track in excess of 24 nautical miles. [A "gross navigation error" is
   defined as a cross track error exceeding 24 miles and must be reported
   and the pilot held accountable if observed.] ... The number of navigation 
   errors is assuredly greater than IATA statistics indicate, because at jet 
   cruising levels, VOR reception often exceeds the range of coastal radars, 
   thus permitting errant crews to regain track undetected.... During the first
   six months of 1978, 16 flights were observed off track by more than 50
   miles, while eight were spotted by coastal radars 100 miles or more off
   track.  The three greatest cross track errors were 180, 400, and 700 miles.
   Averaging the number of observed gross navigation errors into the number
   of days in the first half of 1978 yields one gross navigation error each
   3.6 days."

I believe the KAL007 flight was 250 miles off track, which is within the bounds
of previous incidents that were assuredly accidental.  I have no data to
determine whether navigation errors are more or less frequent or have a
different average size over the North Pacific as opposed to the North Atlantic.

The reasons involving pilot error given in the article for these incidents
(which is written as a warning to pilots of how to avoid such problems) are of
general interest with respect to decreasing risks of navigation errors and
include:  multiple copies of computerized flight plans (e.g., where an enroute
reclearance had been entered on one copy but not the one used to extract
waypoint information; "present position" loading errors (e.g., many inertial or
Omega navigation systems will accept a present position that is substantially
distant from the aircraft's actual position without triggering a malfunction
code or other warning -- Hirsh describes a relatively common practice by pilots
of downloading the inputs from one of the redundant computers to the other in
order to save time instead of redundant loading so that input errors can be
detected); erroneous loading of enroute waypoints (e.g., forgetting to load
tenths of minutes which can produce errors in tens of miles, forgetting to
advance the waypoint selector to the next waypoint and then loading a new
waypoint on top of one previously loaded; loading the wrong hemisphere; copying
waypoints onto a slip of paper first and then transposing the digits when
loading them); crews not monitoring present position or track frequently enough
to detect significant track deviations; autopilot problems (e.g., temporarily
disconnecting the autopilot to manually circumvent things like thunderstorms,
returning to track, and then forgetting to reengage the autopilot Nav mode).

Although Reiner's article is written a while ago, more recent stories I have
heard do not make it sound like these problems have since been eliminated.
Several of the possible explanations based on pilot error given by Hirsh are
very close to those noted above as having been responsible for similar
incidents (over a different ocean).  Note that there was a recent incident
where a Continental plane was far off track over the Atlantic (and nearly hit
another plane).  It does not appear that the Continental pilot was warned by
ground controllers of his wayward course.

       [Reference: Seymour M. Hirsh, "The Target is Destroyed", 1986.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: KAL007 (<A HREF="/Risks/6.75.html">RISKS-6.75</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Mon, 2 May 88 20:10:23 PDT
</i><PRE>

    ......                                                    By the way,
   one difficulty with trying to prove a conspiracy theory is that everyone on
   the inside will deny it (which may thus seem credible), whether or not the
   theory is true.  So, you are ALWAYS AT RISK, period.  PGN]

  Really?  Given what we've been talking about with whistle-blowers, 
don't you think that the truth will leak out eventually?  At least sometimes?

&gt;  ...             But the prima facie conclusion, in the absence of such an
&gt; explanation, is that considerations other than safety lead the authorities to
&gt; blame the pilot, who can not speak for himself."

   It could also be that fatal accidents are more often due to bad judgment
than non-fatal accidents.  A high percentage of "fatals" are due to the
classic "continued VFR into IMC", which translates into challenging mother
nature by scud running (trying to sneak under the clouds) and losing the
challenge.  Another major killer is what I call "gross stupidity":  flying
while drunk or on drugs, buzzing your neighbor's house, low level
aerobatics, etc.  A favorite adage of mine is as follows:

   A superior pilot uses superior judgment to avoid using superior skill.

  The worst pilot error is that one which gets you into a situation that
you can't fly out of.  Maybe that's why more fatals are classified that way.

</PRE>
<HR><H3><A NAME="subj2.2">
Re: Laying conspiracy theories to rest 
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Tue 3 May 88 16:20:05-PDT
</i><PRE>

With respect to whether whistle-blowers do get the true story out, it is
intriguing to consider the article by Eliot Marshall in the 22 April 1988
issue of SCIENCE -- "Sverdlovsk: Anthrax Capital" -- which reconsiders the
April 1979 deaths in Sverdlovsk.  The Soviet explanation involved tainted meat
resulting from anthrax in the grain feed -- although official Soviet secrecy
certainly fueled the alternative theories.  According to Marshall,
``Sverdlovsk's "mystery epidemic" of 1979 lost much of its mystery this month
when a group of Soviet doctors came to the United States and met with
scientists and reporters to give a firsthand account of what happened.''  They
seem to have convinced their American counterparts that this explanation is
indeed justified.  However, Marshall quotes US Government sources that they
still believe that a germ warfare experiment was involved.  Thus, nine years
later this case is still subject to uncertainty.  [If another explanation is
in fact the correct one, it has remained hidden -- at least in unclassified
circles.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 USS Stark
</A>
</H3>
<address>
&lt;<A HREF="mailto: Bahn@HIS-PHOENIX-MULTICS.ARPA">
 Bahn@HIS-PHOENIX-MULTICS.ARPA
</A>&gt;
</address>
<i>
Tue, 3 May 88 07:31 MST
</i><PRE>

The US Congress has decided to convene hearings on the Stark incident and 
possible performance failures on computerized air-search radars.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Ada in strategic weapon systems including nuclear attack warning
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Mon, 02 May 88 20:43:43 PDT
</i><PRE>

The following appears in Darryl K. Taft, "Ada problems attributed to
management, not language," GOVERNMENT COMPUTER NEWS, April 29, 1988 p. 55:

"The Air Force has about 34 programs using Ada (Maj. Gen. Eric B.) Nelson
said.  Among those Nelson listed the Advanced Tactical Fighter, the small
Intercontinental Ballistic Missile, the Milstar Satellite Mission Control
System and the Command Center Processing Display System Replacement program.

This last system being developed at (Electronic Systems Division (ESD) at
Hanscom Air Force Base, Bedford Mass.) "accomplishes tactical warning and
attack assessment for this nation," Nelson said.  "Information on ballistic
missile activity headed for the United States is sent to the leaders that
make the big decisions.  Based on that system this country decides whether
to retaliate or not with our own nuclear forces," he said.

- Jon Jacky, University of Washington

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Virus protection
</A>
</H3>
<address>
David Collier-Brown
&lt;<A HREF="mailto:geac!daveb@uunet.UU.NET ">
geac!daveb@uunet.UU.NET 
</A>&gt;
</address>
<i>
3 May 88 17:07:58 GMT
</i><PRE>
Summary: Nearby virii are dangerous to imperfect humans.
Organization: The Geac Biology Department.

In RISKS DIGEST 6.74, PGOETZ (%LOYVAX.BITNET@CUNYVM.CUNY.EDU) comments:
| Somebody (I forget who) said,
|| To suggest that [write-protection] is 100% effective against a virus is to
|| overstate.  Studies in biology suggest that a virus can thrive even in a
|| population in which a large percentage of the members are immune, if a there
|| is sufficient commerce among the non-immune members...

|    Now, think about that for 2 or 3 seconds.  If you turn on your machine,
| write-protect all the drives, run a virus unknowingly, and turn off your
| machine, you will NOT be infected by any possible virus.

I'm sorry, but you've misunderstood the statement.  The virus thrives on
other people's unprotected disks, and runs in your unprotected memory,
attempting to "infect" your machine.  If your machine is never
	1) connected to another machine, or
	2) running an unprotected disk
at the same time you use your normal disk (ie, unprotect it to do
some work), then you are safe.  As you suggest.

But if there's a virus thriving nearby, it gets multiple tries to infect
your machine. You have to be **perfectly** consistent in protecting your
disk...  Which tends to be difficult, unless you only use a few, pre-virus
programs on a standalone machine.
  That's the point of the biological analogue.

David Collier-Brown, Geac Computers International Inc., 350 Steelcase Road,
Markham, Ontario, CANADA, L3R 1B3 (416) 475-0525 x3279 

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
To speak of the disease is to invoke it?  (Viruses)
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 3 May 88 11:03 EDT
</i><PRE>

In <A HREF="/Risks/6.75.html">RISKS-6.75</A>, Fred Cohen begins:

  &gt;In WHMurray's recent article to this bboard, I hear the same sounds
  &gt;I have heard for years when attempting to discuss computer viruses
  &gt;in an open forum. To speak of the disease is to invoke it.

I admit to a certain amount of ambivalence on this issue.  I believe that there
is some risk of turning a vulnerability into a problem by talking about it too
much.  There is an undeniable phenomenon of copy-catism in society.  Serial
killers clump in time.  So do teen suicides.  There is also a tendency in our
society to glorify the perpetrator of a crime and stigmatize the victim.

The computer virus is different from the natural virus.  The incidences of
natural viruses are independent of what we say about them; the incidences of
computer viruses are not.

Now I make my living advising my clients on how to keep the computer safe, how
to use it to protect its contents, and how to use it safely.  I have a
responsibility to them and to the public at large to understand the nature and
size of this risk and to advise them accordingly.  I also have a responsibility
not to make the problem worse.

I am caught in a double bind.  We are collectively caught in a double bind.  To
deny the vulnerability may make the problem worse; to talk about it may make it
worse.

All that having been said, I come down on the side of truth telling.
Collectively we have made that decision.  We call the decision democracy.  It
is the decision that given the truth, collectively and most of the time, we
will make the correct judgements, and at least collectively, behave in our own
self interest.  So far it seems to have worked even in the face of lies and
liars ( of which viruses and their perpetrators may be among the more benign).

Specifically, I support the right and responsibility of Fred Cohen to speak on
this subject in public forums, however his opinions may agree or differ from my
own.  I oppose the kind of protective government, however well intentioned,
that believes that bureaucrats have the responsibility or the ability, to
protect us from our own errors.

My perception of the truth is that, so far, we have a vulnerability rather than
a problem.  It is the threat to public confidence, rather than the threat to
individual systems that is the issue.  That the perpetrators of viruses are, at
best experimenting, at worst playing, with powers beyond their ken or control.

William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
2000 National City Center Cleveland, Ohio 44114                          
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840                

</PRE>
<HR><H3><A NAME="subj6.2">
Re: To speak of the disease is to invoke it?  (Viruses)
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue, 3 May 88 13:58:17 EDT
</i><PRE>

&gt; ... Imagine howbad the
&gt; virus situation would be 20 years from now if we didn't find out about
&gt; it now! We would have cars that could be infected, automated airliners
&gt; waiting for an accident to happen, automated defense systems that
&gt; could strike individuals deads directly from space, all existing in an
&gt; environment without integrity.

Mmm, I would be inclined to consider this an example of the "Floppy Disk
Fallacy" ("my PC uses floppy disks, so obviously professional programmers
working on Crays must use floppy disks").  Not everyone is as casual about
security as the PC crowd.  Although there are reasons to worry about the
safety of automated airliners and military systems, virus infection is
not plausibly one of them.  In the aerospace-software community, I am told,
it is not unheard-of to verify the *binaries* manually to make sure they do
the right thing, because the compilers are not fully trusted.  Although
these folks are thinking about programming errors rather than viruses, they
already care seriously about integrity.  (Whether they care *enough*,
especially when commercial pressures get serious, is a different issue.)

People doing life-critical work probably should take some precautions.
But quivering in fear that MSDOS viruses will infect airliners is like
quivering in fear of hackers dialing up NORAD's computers and starting
World War III (when in fact NORAD's computers simply do not *have* dialup
access, because those people take security seriously and always have).

Henry Spencer @ U of Toronto Zoology {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Detectability of viruses
</A>
</H3>
<address>
Fred Cohen
&lt;<A HREF="mailto:fc@ucqais.uc.edu ">
fc@ucqais.uc.edu 
</A>&gt;
</address>
<i>
3 May 88 00:20:33 EDT (Tue)
</i><PRE>

I am Fred Cohen, and I said it is undecidable whether or not a program is
a virus, and that it is therefore impossible to detect all viruses and not
detect any non-viruses in finite time with a computer that obeys the Turing
model of computers. I did not say I could "detect" all viruses, but that if
we decided that all programs were suspect, we could surely detect all viruses
as being part of the suspect set. DO NOT SPREAD TRANSITIVE INTEGRITY CORRUPTION
BY MISQUOTING OTHERS. - FC

P.S. Write protecting hard disks only protects them from modification and thus
infection over the period of their write protection. It does not prevent other
infections that may occur to other parts of the world that can remember. - FC

</PRE>
<HR><H3><A NAME="subj7.2">
Detectability of viruses
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Tue  3 May 88 11:30:40-PDT
</i><PRE>

By the way, Fred's message in <A HREF="/Risks/6.58.html">RISKS-6.58</A> begins, 

  "We can detect all viruses, but cannot decide whether or not a program is
  infected."

Although I don't think either one of us misled anyone, I'm sorry for any 
confusion.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.75.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.77.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-24</DOCNO>
<DOCOLDNO>IA012-000129-B045-324</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.77.html 128.240.150.127 19970217021050 text/html 22570
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:09:19 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 77</TITLE>
<LINK REL="Prev" HREF="/Risks/6.76.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.78.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.76.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.78.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 77</H1>
<H2>  Wednesday 4 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
$15.2 million Pennsylvania lottery scam 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of marketing computer products 
</A>
<DD>
<A HREF="#subj2.1">
Mark Eckenwiler
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  ERIC and VULT identified 
</A>
<DD>
<A HREF="#subj3.1">
WHMurray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Virus Distribution Idea 
</A>
<DD>
<A HREF="#subj4.1">
Fred McKay
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  ATM card / Mail Verification 
</A>
<DD>
<A HREF="#subj5.1">
Bruce Howells
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Paying Cash to Avoid Records? 
</A>
<DD>
<A HREF="#subj6.1">
Russ Nelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  More on engine overspeed and autothrottle 
</A>
<DD>
<A HREF="#subj7.1">
Leonard N. Foner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  More SS# RISKS 
</A>
<DD>
<A HREF="#subj8.1">
Les Earnest
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
$15.2 million Pennsylvania lottery scam
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Wed 4 May 88 14:09:30-PDT
</i><PRE>

  HARRISBURGH, PA (AP) -- Authorities accused a computer operator from a
company that helps run the state lottery of forging a winning $15.2 million
ticket and another man with trading it in for the jackpot.
  Mark S. Herbst, 33 of Harrisburgh, was arraigned Tuesday less than a week
after he traded in the ticket for the first $469,989 installment of the prize
from a Super 7 drawing last July 15.  He was jailed in lieu of $50,000 bail.
  Jailed in lieu of bail Monday night was Henry Arthur Rich, also 33 of
Harrisburgh.
  Officials alleged Rich used of computer at his firm, Control Data Corp.,
to identify unclaimed jackpots and to print a copy of the unclaimed winning
ticket, which he gave to Herbst to cash in.
  Officials became suspicious, in part because the bogus ticket was printed on
a blank from a Scranton lottery-ticket outlet, while a computer check showed
the actual winner was sold in Bucks County.
                                   [Source: San Jose Mercury News, 4 May 1988]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Risks of marketing computer products
</A>
</H3>
<address>
&lt;<A HREF="mailto:apollo!eck@csl.sri.com">
apollo!eck@csl.sri.com
</A>&gt;
</address>
<i>
Tue, 3 May 88 18:01:00 EDT
</i><PRE>

I just received some marketing information from Radian Corporation (of Austin,
TX) about their product CHARM ( = Complex Hazardous Air Release Model).

Basically, CHARM provides software simulation of airborne toxic substances
release (isopleths based on cloud density, wind, temperature, etc.).

Radian states that "[m]ore than 85 users in industry and local, state, and
federal agencies are using CHARM to develop emergency response plans, to train
personnel in emergency response procedures, and to rapidly assess real-world
situations should they arise [sic]."

For some reason, after reading the above I am morbidly amused by the fact
that Radian includes in the License Agreement the usual disclaimers:

    "The program is provided 'as is'..."

    "The entire risk...is with the customer."

    "Radian does not warrant...that the operation of the program
     will be uninterrupted or error-free."

Mark Eckenwiler      eck@apollo.uucp    ...!mit-eddie!apollo!eck
Disclaimer: My comments are provided "as is."  By reading them you
            implicitly indemnify me against claims for loss or damage.

     [Before anyone responds, recall the flurry of RISKS contributions
     begun by Jim Horning's "Risks of Warranties" in <A HREF="/Risks/4.76.html">RISKS-4.76</A>.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 ERIC and VULT identified
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 3 May 88 18:22 EDT
</i><PRE>

"ERIC" and "VULT" Identified

ERIC and VULT, the specific targets of the SCORES Apple MacIntosh virus,
were internal projects at EDS in Dallas according to EDS spokesman Bill
Wright.  These labels identify proprietary trade secret programs that were
once, but no longer used at EDS.

While SCORES was specifically designed to destroy these applications, it
would infect anything.

All the above was gleaned from "Macintosh Today," May 2, 1988 which also
contained a highly speculative article entitiled "Viruses:  Nothing to
sneeze at." If you believe this article, computers have seen their day.  In
the future, viruses will make them unuseable.

William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
2000 National City Center Cleveland, Ohio 44114                          
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840                

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Virus Distribution Idea
</A>
</H3>
<address>
&lt;<A HREF="mailto:FMCKAY%HAMPVMS.BITNET@MITVMA.MIT.EDU">
FMCKAY%HAMPVMS.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 20 Apr 88 15:09 EST
</i><PRE>

 6 Apr 88 15:20:39 CST
&gt; From: Will Martin -- AMXAL-RI &lt;wmartin@ALMSA-1.ARPA&gt;
&gt; Subject:  Virus distribution idea [...]
&gt; Now, what immediately occurred to me was, "What a beautiful way to
&gt; disseminate a virus!"

I also recently received an unsolicited request to run an enclosed disk for
the purpose of evaluation.  This disk was from IntelliQuest in Austin.  This
disk was a "User Interface Prototype" reportedly under development by Ashton-
Tate.  Since no AT logos were in place anywhere and I had read all the recent
reports of viruses in RISKS and elsewhere, I was suspicious.  I have an old
Bernoulli Box as my hard disks so I unmounted them and fully intended on
powering down after using the disk.  Upon booting the disk, I was shocked to
see "DRIVE C: NOT READY".  I then place every write protect possible on the
[[[blanks in received mail]]].  I assume one of the first functions done by the
interface is to check the C: directory.  The program booted, but was unable
to impress me.  I was contacted last week by IntelliQuest and spent about 10
minutes talking to them about the product and my negative opinion of it.  I
am confident that modern day electronic vandals would not spend the time or
money to call me from Austin.  In short, trust the dealer but always cut
the cards.
                                        Fred McKay

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
ATM card / Mail Verification
</A>
</H3>
<address>
"Bruce Howells"  
&lt;<A HREF="mailto:engnbsc%bostonu.BITNET@BUACCA.BU.EDU">
engnbsc%bostonu.BITNET@BUACCA.BU.EDU
</A>&gt;
</address>
<i>
Mon, 25 Apr 88  23:43:44 EDT
</i><PRE>

My bank recently mailed out new ATM cards to all of its cardholders, mostly
as advertising for a new network.  Familiar sounding RISK?

The way that this bank handled this risk merits mention:  They placed
telephone calls to each of the card-holders that it mailed new cards
to (at least that's what the voice on the phone told me).

Perhaps such a telephone followup could serve to limit some of the risks
mentioned in previous entries; from personal experience trying to sell
newspapers via telephone in New Jersey, such a verification could be done
quite cleanly, especially since people will be much more willing to
determine if their new ATM card arrived than to subscribe to a newspaper!

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Paying Cash to Avoid Records? (Re: <A HREF="/Risks/6.75.html">RISKS-6.75</A>)
</A>
</H3>
<address>
Russ Nelson 
&lt;<A HREF="mailto:nelson@sun.soe.clarkson.edu">
nelson@sun.soe.clarkson.edu
</A>&gt;
</address>
<i>
Wed, 4 May 88 12:01:59 EDT
</i><PRE>
Organization: Clarkson University, Potsdam, NY

  &gt; ...  Paying cash is the only sure way to avoid this.  [David Chase]

The local videotape rental store has an XT clone w/ a hard disk on
which they keep a record of every tape that you've ever rented.  All
the clerks have access to this information.  Of course, because you're
renting, paying cash is insufficient to preserve your privacy.  Hmmm...
libraries must preserve confidentiality; why not video tape rental shops?

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
More on engine overspeed and autothrottle
</A>
</H3>
<address>
"Leonard N. Foner" 
&lt;<A HREF="mailto:FONER%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
FONER%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
27 Apr 1988  00:48 EDT (Wed)
</i><PRE>

Since I was the individual who told this story to Joseph, I suppose I
should verify it and add some authenticating details to it.

I was told this story by Professor Alan Epstein of the MIT Aero/Astro
department during a talk of his during MIT's Independent Activity Period of
January 1985.  The talk was titled, "Testing Jet Engines:  Why It Takes All the
Money in the World".  Anyone who really wants to nail this down precisely
should ask him.

The reason this story is so important is that it demonstrates the unfortunate
interaction of several design failures, each of which alone should not have led
to cabin depressurization (not to mention the passenger who went out a rather
small hole).  The aircraft involved was some Boeing flavor, 727 or 747 type.

The first failure was in the crew, which should not have been playing
games by doing this sort of experimentation.  They got very long,
unpaid beach vacations for their conduct.

The second failure was in the autothrottle mechanism itself, which did indeed
read its input from the panel display in the cockpit rather than directly from
the tach in the engine.  I can't imagine what possessed the engineer to read
input from something with a breaker in the path, but that's neither here not
there.  Even worse than this, though, was in not detecting an obviously
open-loop (i.e., bogus) value of a sensor, and in thus generating wild control
signals that should never have been generated.  (After all, sensors DO fail.)
We saw this sort of failure in the PDP-11's controlling the blast furnace (in
some RISKS about two months ago).  The control circuit should instead have
insisted on some sort of manual intervention (though, as we'll see below, such
manual intervention could not have arrived in time to save the aircraft), or at
least "failed safe" by leaving the engine running at the same speed as before
(and bleating loudly that something's wrong).

The third failure was in the engine testing itself.  Here are the details.
When the breaker was flipped, the autothrottle circuit for that engine went
open-loop.  When the engine reached 109% of maximum rated power (about a second
later), it stalled the compressor blades.  This means the compressor wasn't
compressing efficiently any more, allowing a blast of essentially white-hot air
to come out the FRONT of the engine.

This blast of air started an oscillation in the front set of engine fanblades,
which rubbed on a cowling and started a fire.  The fire fed the oscillation,
because of timing and positive feedback between pressure regions and the flame
at the cowling.  Elapsed time is now about a second and a half from the breaker
being flipped.

After enough abuse (the fanblades were not designed for highspeed oscillation
in this axis), one of the blades of the frontmost fanblade assembly failed at
the root.  Now, jet engines are designed and tested to withstand a blade
failure.  The failed blade supposed to get chewed up and go out the back of the
jet.  I've watched tests in which they have blown up explosives at the blade
root to simulate just such a failure, in a jet on a stationary test stand at
full power.  Even though the engine is not expected to run after this happens,
it's expected to shut down cleanly without tossing anything radially out the
wall of the engine.

This failure was different, because such tests are not made with the compressor
blades stalled (I suppose that no one ever realized that the jet would be run
stalled, since the normal control channels probably can't run the engine up to
that speed).

Since the compressor was stalled, air was blowing out the front of the jet,
rather than the back.  This forced the broken blade out forwards, at which
point it was no longer constrained by the body of the engine, and was free to
fly off radially---in this case, through the fuselage.  The blade went through
the fuselage less than TWO SECONDS after the breaker was tripped.

The three failures---human, electronic, and mechanical---are an example of how
tightly coupled such failures can be.  They are also an example of just how
fast such failures can occur:  the higher the power level being controlled, the
faster such failures can take place, because there's more energy available to
cause things to fail.  The explosion of the Shuttle was a similar lesson in
power densities.  (For comparison purposes, one 747 on takeoff roll is
generating 400 MW total [100 MW/engine].  An aircraft carrier generates about
120 MW all told; a large nuclear reactor, 1200 MW or 1.2 GW; the Shuttle on
liftoff, about 7 GW.)

Incidentally, while the engine did indeed fail and toss a blade radially, I'm
inclined to believe that the human and control failures were the real failures
here.  Almost any engine can be made to fail if it's purposely driven beyond
its performance envelope (witness the short life of racing car engines, which
run at the ragged edge).  The real problem here was in allowing any AUTOMATIC
control circuit to force the engine outside its envelope.  (I can see why a
human might be given the benefit of the doubt---if the engine is being
overstressed to avoid a head-on collision, for example, I'd rather let the
human do whatever he likes if it might save the aircraft, even at the risk of
blowing something up, rather than keeping the engine nice and safe and letting
it be destroyed [along with the passengers!] in the resulting collision.  If
the engine fails in such a case, well, it wasn't supposed to work under those
circumstances anyway, but if it DOESN'T fail, then allowing deliberate,
considered operation outside its rated envelope might save the aircraft.  But
an AUTOMATIC system should never be given the benefit of such doubt!---because
now you're designing with two sets of inconsistent constraints.)
                                					&lt;LNF&gt;

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
More SS# RISKS 
</A>
</H3>
<address>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</address>
<i>
02 May 88  1958 PDT
</i><PRE>

In RISKS 6.76, Stanley Quayle described another intrusive Social Security
Number practice.  Here is an account of some of the RISKs of _not_ giving
out your SS# freely.  Overall, I find these risks more acceptable than
those on the other side, but there have been times . . .

For the last decade, I have declined to give my social security number to
anyone other than those that are entitled by law to have it.  I have been
refused credit on a number of occasions because of this, but have
encountered no serious problems in getting credit that I needed.  For
example, I have a full complement of credit cards that have no annual fees.

Some of the larger credit data banks, such as the one operated by TRW,
apparently require the SS# in order to access _anything_.  While some
organizations refuse to deal with me, others with more sensible policies
simply check my banking and mortgage references, which show a perfect
credit history, and give me credit.  (I have a sneaking suspicion that one
or more of my credit references may have given away my SS# without
authorization, but I know of no way to determine this.)

When I returned to Stanford University in 1985 and signed up for medical
and dental insurance, I was told that the identifier that would be used
for these services was my SS#.  "Over my dead body," I said.  I pointed
out that doing so would tie my medical records to my government and
financial records and that I preferred to keep these things separate.

The Benefits people expained that "Stanford has contracts with the
insurance companies that require that we give them your Social Security
Number."  I pointed out that they had a contract with me to provide
medical insurance, that I consider my SS# to be confidential, and that it
was up to them to solve this problem.  I also pointed out that it would be
relatively easy to add one field to the personnel data records for an
"Employee ID" that could be used instead of SS#.

Incidentally, I believe that the insurance companies prefer to use SS#
instead of employee number because it makes it easier for them to cross-
connect medical records from different periods, which is occasionally useful
in fraud investigations.  Of course, this same feature also makes it easier
to find medical reports for the purpose of political or other harassment.

The Benefits people dithered over the problem I posed for a couple of
months while I harassed them.  They finally decided that instead of
augmenting the Personnel database, which they apparently regarded as
next-to-impossible, they would give me a phoney SS#, which would be
changed to the correct one just before they sent W-2 forms to the
government at the end of the year.  I was suspicious that this wouldn't
work and said so, but agreed that it would theoretically meet my needs.

The Benefits office asked one thing of me:  that I not tell anyone else
that they were doing this.  They were apparently afraid that there would
be a mass of troublemakers who would exceed their capacity to cope.  They
subsequently demonstrated that they were not even able to cope with me.

I did manage to get my dental checkups paid for the first year, but I had
a hunch that I was not home free.  At the end of the year, I called
Accounting to make sure that my earnings would be reported to the
government under my true SS#.  "Oops," was the reply, "We'll send them a
correction on that."

A few months later I received a copy of a letter to Stanford from TIAA-CREF,
which manages my retirement account, asking where the bizarre SS# came from.
Fortunately, they had somehow been able to figure out who I really was.

Things went fairly smoothely after that until Benefits decided to give me
another phoney SS# in 1986.  That one caused the dental charges to bounce,
so they gave me another phoney number, which also didn't work.  They then
announced that the only way to get those bills paid was for me to use my
true SS#, which they acknowledged they had given to Delta Dental.  I sent
them a rather nasty and threatening note and they subsequently managed to
get the bills paid and to make the new phoney SS# work.

I understand that the Personnel Department is now in the process of
converting to Stanford employee numbers instead of SS# as the basic
identifier, which they should have done long ago.  I would like to think
that I helped stimulate this conversion, but there is no direct evidence.

It is clear that I brought most of the problems described above on myself.
I would (and probably will) do it again.  If you wish to straighten out
the world, you have to do it one piece at a time.
                                                     	Les Earnest

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.76.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.78.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-25</DOCNO>
<DOCOLDNO>IA012-000129-B045-342</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.78.html 128.240.150.127 19970217021104 text/html 22014
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:09:30 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 78</TITLE>
<LINK REL="Prev" HREF="/Risks/6.77.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.79.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.77.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.79.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 78</H1>
<H2>  Thursday 5 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Rambling robot disrupts evening news broadcast 
</A>
<DD>
<A HREF="#subj1.1">
Donn Seeley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Phone fraud -- $150,000 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Blame it on the computer -- lost homework! 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Creating alternatives to whistleblowing 
</A>
<DD>
<A HREF="#subj4.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  KAL 007 
</A>
<DD>
<A HREF="#subj5.1">
Robert Dorsett
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Micros &amp; Airlines - A New Angle 
</A>
<DD>
<A HREF="#subj6.1">
Anand Iyengar
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Ollie North Helps PROFS sales 
</A>
<DD>
<A HREF="#subj7.1">
David A. Honig
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Rambling robot disrupts evening news broadcast
</A>
</H3>
<address>
Donn Seeley
&lt;<A HREF="mailto:donn@cs.utah.edu ">
donn@cs.utah.edu 
</A>&gt;
</address>
<i>
Wed, 4 May 88 22:02:10 MDT
</i><PRE>

New York Times, 2 May 88
Television / Peter Boyer
AT NETWORKS, CHEAP IS CHIC, SO PLEASE PARDON THE ROBOTS

One recent Saturday night, Connie Chung, the anchor of the weekend
version of 'NBC Nightly News,' was reading an urgent story about the
Middle East, when she began to disappear.

The studio camera had inexplicably begun to move from its position, pushing
Ms. Chung's image from the screen as it glided across the studio floor.  Ms.
Chung might have motioned to the cameraman, except there was no cameraman.
The source of her distress was a robot, one of NBC's new self-operating
cameras, that had apparently gotten a case of wanderlust.

... [details about cost-cutting at NBC News, replacement of human
cameramen by three robots at a cost of 'less than $1 million together']  ...

On that eventful Saturday night, Ms. Chung realized that she was moving
out of the camera's frame as she read the Middle East story.  She
considered scooting her chair, which is on wheels, in pursuit of the
robot camera.  But she remembered that she was stationed on a platform,
'and if I did move, I might have fallen off,' she said.

Finally the robot collided with the stage manager, ending its journey
but not its mischief.  Having stopped, the camera began to pan the
anchor desk, turning its lens even farther from the anchorwoman.  Ms.
Chung tried to lean into the picture, managing to get about half her
face into the frame before cutting away to a taped report.

Ms. Chung said that, over all, she has no particular objection to the
use of robots to help NBC's cost efficiency drive.  Had she been asked
on the night of her misadventure, however, her view might have been
different.  Before the broadcast, a computer that prints scripts for
use in the Teleprompter chewed up and rearranged some of her prose.

'I was being killed by machinery that night,' she said.  'If you'd asked me 
that night how I felt about non humans, well, it wasn't very favorable.'

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Phone fraud -- $150,000
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Wed  4 May 88 19:22:33-PDT
</i><PRE>

Two Corte Madera CA teenagers were arrested for using their personal computers
to search through lines of numbers, seeking access to credit card and
toll-free numbers.  They apparently racked up $150,000 in illicit phone calls
during a three-month period.  Their victims included PacBell, MCI, GTE Sprint,
Future Tech, and All Net.  Authorities believe they were part of a Marin
County telephone fraud network.     [Source: SF Chronicle, 4 May 1988, p. A2]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Blame it on the computer -- lost homework!
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Wed  4 May 88 19:12:26-PDT
</i><PRE>

MODERN TIMES: When you were a kid, did you ever tell the teacher ``My dog ate
my homework?''  Update: Navy Lt. John Ratkovich, a student at Naval Postgrad
in Monterey, tells me that when homework was called for the other day, Lt. 
Comdr. Al Jones said ``May DOS ate it.''  Right.  His disc operating system
erased it all, and would a commander tell a fib?  [Herb Caen, SFChron 28Apr88]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Creating alternatives to whistleblowing [<A HREF="/Risks/6.65.html">RISKS-6.65</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 4 May 88 22:41:34 EDT
</i><PRE>

&gt;  * If I see a problem, should I let it continue even though it's not
&gt;    in my 'area of responsibility'?

(This may seem like a non sequitur, but all will become clear...)  A book
that might interest Risks readers is T.N. Dupuy's "A Genius For War"
(Prentice-Hall 1977).  It's an investigation of how, for about a century,
Germany consistently produced the world's best armies -- not just bigger,
but significantly better, man for man.  (Specifically, German armies fought
as if they were about 20% larger than they really were, and they inflicted
50% more casualties than an equal number of other soldiers.)

(Dupuy's book is actually an interesting example of simulation uncovering
real-world surprises.  He started looking into the subject when attempts
at numerical simulation of WW2 battles could not be reconciled with real
life unless a fudge factor was introduced to give the Germans an advantage.
He notes that similar fudge factors can be found in commercial wargames, if
you go looking for them.)

His major conclusion was that individual German soldiers were no better than
their opponents:  Germany's advantage was better officers, produced not by
birth but by superior training.  One aspect of their training particularly
stood out (we're now coming to the relevant part...):  the traditional
stereotype of Germans being obsessed with blind obedience was wrong, dead
wrong, for the officer corps.

In fact, German officers had it hammered into them repeatedly that they
were responsible for getting results, not for following orders, and that
obeying orders was *not* an excuse for fouling up.  If they saw a problem
developing, it was *their* responsibility to see that something was done
about it, orders or no orders, chain of command or no chain of command.
After the Franco-Prussian war, General Moltke inserted the following in
a new training manual:

	"A favorable situation will never be exploited if commanders
	wait for orders.  The highest commander and the youngest
	soldier must always be conscious of the fact that omission
	and inactivity are worse than resorting to the wrong expedient."

Every German officer heard the story of the major, being reprimanded for
fouling up, who tried to defend himself by pointing out that he was
following orders and that orders from a superior officer were legally
equivalent to orders from the King.  Prince Frederick Charles, who was
delivering the reprimand, replied:  "His Majesty made you a major because
he believed you would know when *not* to obey his orders."  This was not
apocryphal folklore; Moltke himself witnessed the incident, and saw to it
that it was incorporated into officer training, to make it clear what the
priorities were.  The result was an army which -- other things being
equal -- consistently performed better than any other army on Earth.
"[This system] enabled men who individually lacked the qualities of a
genius to perform institutionally in a manner that would provide results
ordinarily achievable only by genius."

(Before anyone objects that Germany lost both World Wars, note that there
is wide consensus that this was not the Army's fault.  In WW2 in particular,
it came frighteningly close to winning -- against larger and better-equipped
opponents -- despite extensive political meddling in its decisions and
operations.)

How many companies (for that matter, how many *armies*) tell their staff
anything like that?  How many get results like that?

Henry Spencer @ U of Toronto Zoology   {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
KAL 007 
</A>
</H3>
<address>
Robert Dorsett
&lt;<A HREF="mailto:mentat@huey.cc.utexas.edu ">
mentat@huey.cc.utexas.edu 
</A>&gt;
</address>
<i>
Thu, 5 May 88 13:42:28 CDT
</i><PRE>
Cc: padraig@astro.as.utexas.edu, steve@ames-aurora.arpa

Every 747 I've seen uses an inertial navigation system manufactured by Delco 
Electronics, a subsidiary of General Motors.  It's a fairly primitive unit, 
capable of storing a whopping 10 waypoints at a time.  There are three units 
on the 747, plus an optional card reader.  The INS's cost about $100,000 each. 
Software updates are actually firmware updates, and referenced by version num-
ber, rather than date.  Since operators must purchase upgrades, it's inevitable
that many carriers are operating old, obsolete INS's--perfectly legally.  Many 
carriers wait until a break-down before a board swap, then just swap the latest
version (or the latest version their maintenance department has stockpiled).

The multiple units are used for redundancy inflight, but coordinates can be
entered in an "intermix" mode on the ground, to save time.  Crew procedures
call for cross-verification of waypoints by both the captain and first
officer before or during taxi.

Most third-world airlines do not use the card reader, even if it's installed.
Many third-world airlines have poor or dubious administrative practices, and
keeping the cards up to date (not to mention current copies on each airplane
and compensating for theft or misplacement) is a bit of a task.  

So what is done is the waypoint coordinates are entered from a computerized
flight plan.  These flight plans are obtained from the airline's dispatch
office, which in turn buys them from a service (forget the name).  The
flight plans indicate the airplane's longitude, latitude, fuel burn,
magnetic heading, projected altitude, etc., for every waypoint.  The elapsed
time is also given beside the waypoints.  Waypoints are referred to by both
name (remember, over-water navigation is area navigation) and coordinates
from the perspective of the paper flight plan and the charts.  The INS,
however, only refers to waypoints by coordinates, which can lead to
misinterpretation if, for example, an LED element burns out or a number is
simply misread.  The flight plans start at "enroute climb" and ends at
"entry" at the ATC system at the target airport.  There are four copies of
the flight plans, each one color-coded by a stripe down the left side.

After the INS's are stabilized on the ground, the airplane position is entered.
Then, the waypoints coordinates are entered.  After takeoff, if a "direct"
routing is obtained from ATC, the autopilot is slaved to the INS.  The INS runs
the show until it's time to add more waypoints.  Optionally, a flight director
display can be called on the attitude diplays to cross-check INS flight
commands.

Optimally, the pilots (captain and first officer) verify INS navigational
information with the flight plan.  They are expected to cross-check longitude
and latitude and establish that the airplane's heading matches the projected
heading.  The role of the flight engineer is to make sure that fuel burn is
within acceptable limits.  By the end of the flight, the paper flight plans are
heavily marked to indicate deviations from the ideal flight characteristics.

In a perfect world, the massive sequence of errors that led to the destruction
of the KAL flight would not have occurred.  Even if the captain entered a 
wrong waypoint, it's inevitable that the mistake would be noted later on, 
either via cross-check of the headings or of the actual cross-check of 
longitude and latitude.  The INS units also provide a multitude of information
beyond merely aircraft position, such as ground speed, track, true course,
etc, all of which can be used to verify other characteristics.

However, when we look at other factors, the "off course" theory might gain
more credibility.

First, a long-documented trait of many oriental aircrews is the absolute
assignment of command on the captain.  The captain often does *all* takeoffs
and landings, and, in general, has absolute authority on the ship.  The first
officer is discouraged from voicing his opinions, and, even if he does, such
opinions can be (and often are) completely ignored.  The flight engineer is
almost a non-entity.  There have been cases of first officers getting promoted
to captain with 15,000 hours with absolutely minimal time manipulating the
flight controls of the airplane.  These behavioral characteristics have been
addressed at a recent flight safety conference by the Flight Safety Foundation
in Tokyo, and have been documented for at least 25 years, by sources within the
airlines and Western safety observers.

Second, if the captain (we presume the captain enters the coordinates in the
INS at the beginning of the flight) entered a WRONG waypoint, it might not
be picked up, especially if there was a rushed start and a fast taxi.  For
credibility's sake, we'll assume that there was one waypoint error.

Third, KAL aircrews are not viewed in the best light by the rest of the flying
community.  We can assume that, although they meet professional standards,
there are deficiencies in training and conduct--credible given the earlier 707
blunder into the Soviet Union and numerous safety and operational
discrepancies.

Now, for the worst-case scenario: we have a docile first officer.  Captain
screws up the entry of at least one INS waypoint.  The mistake is not detected
until well into the flight.  Rather than fly an intercept to get back on the
original track (which may waste fuel, at a premium), the captain decides to fly
by dead reckoning, setting the autopilot to "heading select" mode, then flying
the flight plan headings in a parallel course (but farther north) until he
encounters an in-land radio navigational aid and can conveniently reset the
flight plan.  This behavior would suggest a lack of comfort with the INS (or,
perhaps, a triple INS failure), or an unwillingness to deviate significantly
from the paper flight plan and all of its nice pre-calculated values.  He
happens to intrude Soviet airspace at about the same time that a USAF E3A is
expected, and gets shot down.  The visual profile of the 747 is almost
identical with that of the 707 (this is not as improbable as it sounds).

Now, how does all of this relate to RISKS?  We have the obvious entry error,
which most of the theories surrounding the incident seem to accept.  So, we
say: develop a better entry mechanism.  Easier said than done.  More
importantly, we can ask: why didn't the aircrew determine that they were off
course?  They certainly had enough information to determine the fact, assuming
that they were following accepted crew practices.  And, if they detected that
they were off course about the time they started flying the parallel-but-too-
far-north course, why didn't they get back on course?

We might blame the highly automated environment.  The operator error starts the
ball rolling.  The tedious, fatiguing long-distance Pacific run.  The
overreliance of the aircrew on the technology.  The apparent incapacity to
place importance on the fact that they were off course: in the insulated
airliner environment, they might have concluded that a ten-minute deviation
from course wasn't terribly significant, as long as they flew the phantom
course defined by the flight plan.  This "insulated" mentality is quite
possibly a result of degraded flying skills from flying the automated
environment too long.

Over the years, I have seen behavior and read accounts of incidents that could
account for or support all of the above.  The design of cockpits is an
exceedingly important issue, both from short-term performance considerations
and those of long-term behavior modification.  As numerous incidents have
shown, automated cockpits remove the pilots from the control loop.  When that
happens, and, after 10,000 trouble-free flying hours, an insidious error
occurs, the crew might not be able to compensate.  This problem is due to
shortly become MUCH more serious, with the advent of the two-man MD-11 and
747-400, both of which have unprecedented ranges.  A number of foreign airlines
like the airplanes, but not the automation and flight crew configuration, as
evidenced by significant objections from KLM, Singapore, and a variety of
Japanese carriers.

Robert Dorsett, University of TX at Austin  Internet: mentat@walt.cc.utexas.edu
  UUCP:{ihnp4, allegra,decvax}!ut-emx!walt.cc.utexas.edu!mentat
       
</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Micros &amp; Airlines - A New Angle
</A>
</H3>
<address>
Anand Iyengar &lt;Chief Dan&gt; 
&lt;<A HREF="mailto:22116@pyr1.acs.udel.edu">
22116@pyr1.acs.udel.edu
</A>&gt;
</address>
<i>
5 May 88 17:49:45 GMT
</i><PRE>

Although I know a lot has been said about portables and airplanes, I couldn't
resist this new aspect from the Sunday, May 1st, "Philadelphia Inquirer".
** Section R (Travel), page 7 **

            "Emergencies are routine for airport medical team"

   First came the loud tone on the walkie-talkie, then came the call, "Code 
yellow, code yellow." ...
   The emergency code had come this time from a Boeing 747 on its way in
from Boston.  A heavy computer keyboard had popped a latch on an overhead
compartment and fallen out, striking a 35-year-old business executive on the
head. ...
   The man was dazed, had difficulty talking, and complained of weakness on
one side.  A concussion seemed almost certain.  They took his vital signs,
placed a collar on his neck, maneuvered him carefully onto a special chair,
and took him to the jetway where they started an IV and administered oxygen.
A fire rescue team arrived, got the patient onto a backboard, and headed for
Methodist hospital...

Just one more danger of these new-fangled machines.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Ollie North Helps PROFS sales
</A>
</H3>
<address>
"David A. Honig" 
&lt;<A HREF="mailto:honig@BONNIE.ICS.UCI.EDU">
honig@BONNIE.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Wed, 04 May 88 18:18:06 -0700
</i><PRE>

Source: Computerworld "Inside Lines" May 2 1988

According to Paul Hessinger, Chief Technical Officer at Computer Task Group
in Buffalo NY, "IBM received the largest number of orders ever for its
Professional Office System, or Profs in the 14 days after Col. North's
testimony!

Prof's backup files had foiled North's shredding of certain communications
during the "Iran-Contra Affair".

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.77.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.79.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-26</DOCNO>
<DOCOLDNO>IA012-000129-B045-372</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.79.html 128.240.150.127 19970217021120 text/html 25085
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:09:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 79</TITLE>
<LINK REL="Prev" HREF="/Risks/6.78.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.80.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.78.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.80.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 79</H1>
<H2>  Saturday 7 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Abuse of power by the press: PCs down BBall scoreboard clocks! 
</A>
<DD>
<A HREF="#subj1.1">
Richard Cook
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Is the Press impressing or depressing? 
</A>
<DD>
<A HREF="#subj2.1">
Les Earnest
</A><br>
<A HREF="#subj2.2">
 Cliff Stoll
</A><br>
<A HREF="#subj2.3">
 LE
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  KAL007 - the defeaning silence continues 
</A>
<DD>
<A HREF="#subj3.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risks of auditing for risks 
</A>
<DD>
<A HREF="#subj4.1">
Doug Claar
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Viruses and write-protection 
</A>
<DD>
<A HREF="#subj5.1">
Dennis Director
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Harrier ejection-seat accident 
</A>
<DD>
<A HREF="#subj6.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Military Aircraft Crashes in Germany 
</A>
<DD>
<A HREF="#subj7.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of Halon to the environment vs. risks of other fire protection     (Dave Cornutt&gt;
</A>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Abuse of power by the press: PCs down BBall scoreboard clocks!
</A>
</H3>
<address>
303
&lt;<A HREF="mailto:"Richard Cook, ">
"Richard Cook, 
</A>&gt;
</address>
<i>
Fri, 6 May 88 09:45 MDT
</i><PRE>

During the Seattle SuperSonics and Denver Nuggets basketball game last night, 5
May 1988, officials encountered several problems with game clocks. Coverage in
the Boulder, Colorado, `Daily Camera' of 6 May included the following item:

"CLOCK TROUBLES: Seattle Coliseum officials were wringing their hands Thursday
night when the 24-second clock wasn't working when the game started. They
finally got it going with 8:14 to go in the first quarter--but their troubles
were far from over.

With 8:06 left in the second quarter, the scoreboard clock went out. They
got it going again with 6:54 left--but it went out again 30 seconds later
and did not work for the rest of the half.

The problem? It seems the scoreboard circuits were on the same electrical
line that the entire media corps was using to hook up their portable computers.
And, the line finally overloaded and blew out the scoreboard. When Sonics
officials discovered the problem, they frantically moved up and down press
row, asking reporters to switch to battery power."

This is presumably reliable evidence of increased use of portables by the
press since last year's playoffs...

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re:  Is the Press impressing or depressing?  
</A>
</H3>
<address>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</address>
<i>
04 May 88  1900 PDT
</i><PRE>

In RISKS DIGEST 6.71, Cliff Stoll reviews his experiences in running down
a cracker and in dealing with the press.  One of Cliff's remarks that
caught my eye was the following:

&gt; Instead of closing our doors to this bastard, we monitored and traced him
&gt; for about a year.

I am curious about _why_ this was done.  I agree that it is necessary
to spend some time watching crackers to be sure that you understand
their principal tricks, but once you have that information, I see no
point in prolonging the game -- why not start slamming doors and harassing
them off your system?  You may not catch them, but you are likely to get
rid of the problem and the drain on your time a lot quicker that way.

</PRE>
<HR><H3><A NAME="subj2.2">
 Re:  Is the Press impressing or depressing?  
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:    cliff@Csa5.LBL.Gov ">
    cliff@Csa5.LBL.Gov 
</A>&gt;
</address>
<i>
Fri, 6 May 88 15:16:18 PDT
</i><PRE>

Just like Les Earnest, we at LBL take computer security seriously:  
we wish to keep our data intact, and we don't tolerate break-ins.  
Our philosophies differ.  Les slams his doors when he finds someone 
in his system. As outlined on page 490 of this month's CACM, 
remaining open to an intruder is a toughy.  We decided to go after 
such bastards intending to prosecute them.  If they aren't arrested, 
we'll do our best to sue them [cf: Cal. Penal  Code S. 502].  

In this particular case, instead of a sophmoric prankster, we found a 
mercenary who apparently sold stolen information.  He wasn't 
interested in games or academics -- he sought (and received) 
military data.    Simply locking him out of our system would leave 
him free to roam around the networks, breaking into many other systems. 

I believe we owe a debt to our community of Internet nodes.  As in 
a neighborhood, each of us should report burglaries and breakins, 
and cooperate in nailing the SOBs.  For this reason,  we spent a lot of 
time on this work.   Les disagrees, and sees it as a game, rather 
than a service to a community of networked computer users.  

Most of your network partners won't detect a breakin.  Most that detect 
won't follow up.  A few will doggedly chase it down, and prosecute.  
We're in the latter category.

Cliff Stoll

</PRE>
<HR><H3><A NAME="subj2.3">
Re:  Is the Press impressing or depressing?  
</A>
</H3>
<address>
Les Earnest 
&lt;<A HREF="mailto:LES@SAIL.Stanford.EDU">
LES@SAIL.Stanford.EDU
</A>&gt;
</address>
<i>
06 May 88  1724 PDT
</i><PRE>

Regarding my question about why LBL didn't slam the door on their
international cracker, Cliff Stoll says:
&gt; Les disagrees, and sees it as a game, rather than a service to a community
&gt; of networked computer users.

On the contrary, it is precisely because I do _not_ see it as a game that
I do not wish to prolong it.  Indeed, if Stanford spent as much as a week
chasing down each cracker on its systems, it would be necessary to hire more
programmers just to do that.

In fact, there _are_ several people around Stanford who spend large
amounts of time programming special hacks to monitor crackers and then
spending weeks or months observing their activities.  For some reason,
these people seem to be mostly reformed crackers.  Perhaps they are reliving
former exploits.

I _am_ sympathetic to Cliff's argument that this was not an ordinary cracker
and deserved special treatment, but in general it may take quite a bit of
work to distinguish such a person from J. Random Cracker.

	Les Earnest

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
KAL007 - the defeaning silence continues
</A>
</H3>
<address>
Clifford Johnson 
&lt;<A HREF="mailto:GA.CJJ@forsythe.stanford.edu">
GA.CJJ@forsythe.stanford.edu
</A>&gt;
</address>
<i>
Fri,  6 May 88 20:51:18 PDT
</i><PRE>

    From: Don Wegeng &lt;Wegeng.Henr@Xerox.COM&gt;
    In regards to the continuing debate in RISKS about the
    KAL007 incident, it appears that one side of the argument is
    putting all of its faith in the version of the story
    reported in the book "Shootdown". It seems to me that you
    are always at RISK when you chose to put all of your faith
    in a single source, be it a pressure sensor in an engine,
    the phone company's billing system, an elected official, or
    a book about an aircraft that was shot down.

   [... and the OTHER side of the story is putting its faith on information
   that is all derived from one set of interrelated sources???  PGN]

Re Shootdown versus other books on KAL007, I don't think faith comes into it.
All the varieties of hypotheses and facts I've seen in other books are
discussed in depth (with source references) for all facts in Shootdown.  This
is not true of the other books, which by comparison cannot be taken anything
like as seriously.  Shootdown provided some 700 citations (some of which I
checked out and found accurately stated) and weighed the facts without reaching
a definite conclusion other than that an inquiry was warranted. Hirsh, without
citations, and without adding any significant new facts, told a silly story
based on a rather small subset of the facts that suited his flagrantly
unjustified assertion, delivered as fact, that KAL007 was not a spy flight.
Shootdown covered pretty much every point that Hirsh made, whereas Hirsh made
*many glaring* omissions.  Hirsh spent ages recounting a route dismissed by
Shootdown (Ewing's version), and chose to ignore most of the evidence that
pointed to espionage.  (Sure Shootdown had a few mistakes, but nothing
crucial.)  Hirsh made a huge fanfare of the fact that the administration
falsely asserted that it thought the Soviets knew KAL007 was a passenger
flight, a deception admitted a couple of years before Hirsh's "revelations."

    From: Nancy Leveson &lt;nancy%murphy.ics.uci.edu@ROME.ICS.UCI.EDU&gt;
       "During the first six months of 1978, 16 flights were observed
       off track by more than 50 miles, while eight were spotted by
       coastal radars 100 miles or more off track.  The three greatest
       cross track errors were 180, 400, and 700 miles."
    I believe the KAL007 flight was 250 miles off track, which
    is within the bounds of previous incidents that were
    assuredly accidental.  I have no data to determine whether
    navigation errors are more or less frequent or have a
    different average size over the North Pacific as opposed to
    the North Atlantic.

I think KAL007 was about 365 nautical miles off course.  I find it astonishing
that the contrived possibility that KAL007 could have been accidentally off
course is interpreted as proof that this was the case, and so the espionage
possibility is eliminated without even considering its affirmative evidence.
I'm sure that the mere fact that other air flights have been off course is not
a valid comparison.  The other flights seem to have been over the ocean,
whereas KAL007 passed over obvious-to-radar mountain-islands (it wasn't
supposed to) and made consecutive course changes, all "incorrectly."  How many
of the other off-course flights were delayed due to favorable winds shortening
the anticipated flight time, yet signed for additional fuel and rejected paying
cargo, and then began flying unusually slowly, and then had their false
positions relayed by a follow-on flight (KAL015)?  Far from being delayed due
to the same favorable winds, KAL015 took off six minutes *early* and proceeded
so fast that its Mach buzzer would have sounded had it not been switched off.
Facts such as KAL007 being ordered to report directly are suppressed by Hirsh,
who simply tells us that no one was concerned at KAL007's not reporting its own
position.  Hirsh doen't mention the weird speed patterns of both flights, nor
think it worth mentioning that KAL007 and KAL015 were using the wrong
transponder codes, nor that the Japanese radar tapes reported KAL007 dived when
it requested permission to ascend, nor that this maneuver improbably occured
after hours of radio silence, immediately the Soviet pilot reported having
established a lock on KAL007... etc.

As I've said, Shootdown should be read for a review of the quite astonishing
indications that KAL007 was on a deliberate mission, and for an account of the
inadequacy of computer-pilot errors for the actual route.

KAL007 "accidentally" overflew the Soviets' second largest submarine base. I
believe the world record for an off-course flight occured in 1978, when a KAL
flight was 1,000 miles off-course, "accidentally" flying over the Soviets
largest submarine base (Murmansk).  The alarm was sounded by passengers noting
the sun was on the wrong side of the plane.

Hirsh writes of his "one basic finding of the book, that the Korean airliner
was not a spy plane... The publication clearly diminished the zeal of those
public interest groups that had been insisting Flight 007 was deliberately sent
over the Soviet Union."  Hirsh's major finding is relegated to a footnote, that
dismisses the espionage hypothesis on the ground that his unnamed intelligence
sources had not heard of the flight in advance.  Not only a slender reed for
such a conclusion, but an invisible reed.  Hirsh does not address the merits of
those like me and R.W.Johnson who admit grave doubts and ask for an inquiry.
He seems to think his silly book is gospel.  I am left wondering whether he
deliberately left out key evidence, or whether he is as bad an investigative
journalist as his KAL007 book demonstrates.  Hirsh himself found a conspiracy
to cover-up the facts of KAL007's shootdown.  I think that PGN's tentative
suggestion that the matter might still be incompletely unravelled simply
cannot be denied - at least until a public inquiry is instigated.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
risks of auditing for risks...
</A>
</H3>
<address>
Doug Claar 
&lt;<A HREF="mailto:dclaar%hpda@hplabs.HP.COM">
dclaar%hpda@hplabs.HP.COM
</A>&gt;
</address>
<i>
Fri, 6 May 88 17:09:34 pdt
</i><PRE>

Our site is recently underwent corporate audit. Among the things checked for
was pirated PC software. In preparation for this audit, our local EDP folks
ran a little program which looks at program files on the hard disk, and
attempts to figure out what products they represent. This introduced some
risks to the local computing community: First, the program only checks
program names against its database, and not sizes or checksums or...  In
addition, if any one file of a product is recognized, the user is assumed to
have that product. Needless to say, there were lots of false positives.
Since EDP had the secretaries running the program, there was lots of "Do you
have master floppies for X?" "No, I don't have X on my disk."  "Well, you
have to get rid of it, because this says you have it."

The second risk was potentially much more devastating--the secretary brought
around a floppy, stuck it in 'your' system, and ran the program. Of course,
you have relatively little choice in the matter, since it IS the company's
PC. The program was designed to dump its output back onto the floppy, so the
floppy wasn't write protected! (I didn't even think of this until after my
system had been checked). All I could do is hope that, if anyone had a virus
on their PC, their system was tested AFTER mine...

Doug Claar, HP Information Software Division
UUCP: { ihnp4 | mcvax!decvax }!hplabs!hpda!dclaar -or- ucbvax!hpda!dclaar

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Viruses and write-protection
</A>
</H3>
<address>
Dennis Director 
&lt;<A HREF="mailto:dennis%molly.uucp@eecs.nwu.edu">
dennis%molly.uucp@eecs.nwu.edu
</A>&gt;
</address>
<i>
Thu May  5 16:40:20 1988 CDT
</i><PRE>

Enough is Enough!

Regarding the effectiveness of hardware write-protection for protecting the
operating system and programs from computer viruses, I offer the following
challenge:

I have an XT-compatible computer with DOS 3.2 and all of its utilities and
programs in the write-protected portion of the hard disk.  I invite both Dr.
Fred Cohen of the University of Cincinnati and William Murray to come to my
office at the Technology Innovation Center, Northwestern University with the
press or any other mutually agreed upon reliable witness.  I also invite them
to bring along any or all virus infected programs that they have collected or
written for the occasion.  I am (100%) sure that none of these programs will
modify my boot block, my partition table, the operating system files or any of
the DOS programs (.COM or .EXE) stored on my hard disk, which will be hardware
write-protected.  A scratch area of the hard disk will be writeable at all
times.  Simply copying a Trojan Horse into the scratch section of the disk,
should obviously not be considered "infecting my system".

Since Dr. Cohen has stated that "you cannot write protect lotus, etc because of
copy protection" we will also have a copy of Lotus 123 installed and working in
the write-protected section, as we have had for almost two years.  This will be
a fully legitimate copy-protected installed version of 123.  It runs perfectly
from the write-protected zone and cannot be infected.

Why go on debating that which can be simply demonstrated?  Seems like a fair
offer to me!                                                   Dennis Director

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Harrier ejection-seat accident
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 6 May 88 15:49:10 EDT
</i><PRE>

A while ago I mentioned the incident in which a Harrier pilot was apparently
pulled out of his aircraft after the parachute-deployment system on his
ejection seat fired through the canopy.  Flight International just printed
a summary of the final report on the accident.

The problem does indeed appear to have been an accidental firing of the
parachute-deployment system, which is powerful enough to punch its way
through the canopy.  The question is why it fired.  The Harrier flew west
on autopilot until it ran out of fuel, and went down in deep ocean; the
wreckage has not been located despite an extensive search.  (The general
nature of the accident is known because air traffic control, after being
unable to raise the pilot, had another aircraft take a look.)

The inquiry came up with three hypotheses.  In the absence of wreckage,
there is no way to be sure of the answer.  However, two of the hypotheses
require multiple errors and/or multiple failures.  The third is considered
most plausible:  if the seat was lowered, and there was a foreign object
underneath it in just the right place, a connecting linkage on the seat's
underside could have been bent enough to fire the deployment system.  The
Harrier cockpit equipment includes a utility light on a coiled cable; it
is strong enough and large enough to have done the trick, and could have
ended up in the right place if it fell off its bracket.  Also, there is
reason to suspect that the pilot may have lowered the seat at about the
right time:  he was to perform some tests that required a clear view of
the instrument panel, and he was flying into the setting sun, so once he
was flying safely on autopilot he might well have lowered the seat for
a better view of the panel.

Martin-Baker, manufacturers of the ejection seat (with a generally very high
reputation for quality products), are adding a guard over the linkage.  (I'm a
bit surprised that this wasn't done in the original design; somebody assumed
that the cockpit was a controlled environment in which such things couldn't
happen.)  The utility lights have been removed from the Harriers until this is
done.

Henry Spencer @ U of Toronto Zoology   {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Military Aircraft Crashes in Germany
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 6 May 88 15:30:26 EDT
</i><PRE>

&gt; ... The press says that, in each case, a much worse disaster was only
&gt; narrowly avoided ...  The crashes occured just down the flight path from:
&gt; a nuclear generating station, a munitions dump, and an inhabited village.

I can't speak for the munitions dump and the village, but nuclear-reactor
containment buildings are deliberately designed to survive a direct hit
from a crashing airliner (not as fast as a military jet, in general, but
much, much heavier).

&gt; In all, 35 military aircraft have fallen out of the skies here since 1960.  I
&gt; have no idea how this compares with other countries.

I don't have regional numbers on such losses, but even peacetime military
flying is much more dangerous than most people think.  Flight International
regularly publishes flight-safety reviews that list all known crashes and
related incidents; the annual military safety review, at one line per
occurrence, typically covers a couple of pages.

Henry Spencer @ U of Toronto Zoology   {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of Halon to the environment vs. risks of other fire protection
</A>
</H3>
<address>
&lt;<A HREF="mailto:dkc%hotly%ihnp4%mtune@mtunx.att.com">
dkc%hotly%ihnp4%mtune@mtunx.att.com
</A>&gt;
</address>
<i>
Wed, 4 May  16:09:52 1988
</i><PRE>

Due to the recent concerns about depletion of the atmosphere's ozone layer,
there is a possibility that manufacture and sale of certain fluorocarbons may
be banned or severely restricted by international treaty.  One of these
fluorocarbons is Halon.

So, we have to weigh the risks of environmental harm caused by Halon against
the risks posed by other types of systems.  What exactly are the
environmental risks of using Halon?  The questions here are:

1. Does Halon disassociate in the upper atmosphere and produce ozone-destroying
free radicals, like Freon does?  (I suspect that it does, as they're chemically
similar.)

2. How much Halon is discharged into the atmosphere each year?  Of the total
amount of flourocarbons which escape into the atmoshpere, what percentage of it
is Halon?

3. Does this environmental threat outweigh the risks to property and humans
posed by other systems?  (Halon does not conduct electricity, interfere with
respiration, lower the room temperature, leave a solid residue, or lower the
room temperature on discharge.  All other systems -- water, CO2, nitrogen, dry
chemical, etc. -- have at least one of these undesirable properties.)

If Halon were banned, what fire protection system would you use?  Is its use a
serious RISK, or is there a greater RISK in not speaking up for it?

Dave Cornutt, AT&amp;T Bell Labs (rm 4A406,x1088), Holmdel, NJ
UUCP:{ihnp4,allegra,cbosgd,moss,genesis}!hotly!dkc
"The opinions expressed herein are not necessarily my employer's, not
necessarily mine, and probably not necessary"

    [See previous discussions on this subject in RISK-5.27 and 28.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.78.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.80.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-27</DOCNO>
<DOCOLDNO>IA012-000129-B045-391</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.80.html 128.240.150.127 19970217021136 text/html 17415
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:10:03 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 80</TITLE>
<LINK REL="Prev" HREF="/Risks/6.79.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.81.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.79.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.81.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 80</H1>
<H2>  Sunday 8 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Yet another SSN risk 
</A>
<DD>
<A HREF="#subj1.1">
Tom Lord
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of banking 
</A>
<DD>
<A HREF="#subj2.1">
Ritchey Ruff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Auftragstaktik" 
</A>
<DD>
<A HREF="#subj3.1">
Gary Chapman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
yet another SSN risk
</A>
</H3>
<address>
Tom Lord 
&lt;<A HREF="mailto:lord+@andrew.cmu.edu">
lord+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Fri,  6 May 88 13:26:55 -0400 (EDT)
</i><PRE>

Promises from your personel department are almost certainly not sufficient
to protect your Social Security number.  Such a promise presumes that the
department will have good control over its own records and, at least here at
CMU, this is not true.  This morning on my way into the office a box of
trash outside the machine room caught my eye.  The box was full of course
schedules listing each course, its classroom, its instructor, and the
instructor's SSN.  My guess is that something went wrong with the printer as
the job was printing, and that the operators tossed the partial output and
started over.
                                            -Tom

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of banking
</A>
</H3>
<address>
Ritchey Ruff 
&lt;<A HREF="mailto:ruffwork@orstcs.cs.orst.edu">
ruffwork@orstcs.cs.orst.edu
</A>&gt;
</address>
<i>
Sat, 7 May 88 10:24:51 PDT
</i><PRE>

I belong to a credit union (which will remain unnamed for obvious reasons
below) and got the following notice in my end of month statement.  I'll
refer to the credit union as &lt;CU&gt; when ever their name appears in the
flier...  I am typing it in verbatim because of the numerous RISKS issues
bundled in this little flier, including:  SSN's, manuals and instructions,
misinformation, etc.  The CAPS are to represent either bold or caps in the
original.  The format is as close as I could come to exactly the flier, and
many of the typos are really in the flier (I proof read it 3 times to try
to remove all MY typo's ;-).  This should get some RISK dander up!!!

				ILLY
			&lt;CU&gt;'s Audio Teller

* ILLY - Audio Teller
	"Illy" is &lt;CU&gt;'s AUDIO TELLER.  You are "talking" directly to our 
	computer system by simply pushing buttons on the keyboard of your 
	Touch Tone phone!

	Every member has a personal security code.  Your security code is 
	the last four digits of your social security number.  Only you and 
	the computer know this number.  If you need to change your number, 
	you must request this in writing. No numbers will be changed by phone.

* Available hours
	Financial transactions: 7:00 a.m. to 5:30 p.m.
		During this time you are able to perform your own FINANCIAL 
		transactions.  You can transfer funds, request a withdrawal 
		check be mailed, or transfer a loan payment from your share 
		account.
	Inquiry Transactions: 7:00 a.m. to 5:30 p.m. and 
			      9:00 p.m. to 7:00 a.m.
		During this time you can check your share balance, inquire 
		if a certain share draft-check has been paid, or inquire on 
		your loan balance.

* How to use ILLY
	1) &lt;state&gt; residence dial: (xxx) xxx-xxxx
	   &lt;other state&gt; residence dial: (xxx) xxx-xxxx

	   RESPONSE: You have dialed &lt;CU&gt;'s Audio Response System,
	   please enter you account number.
	
	2) Press the touch-tone keys on your telephone that correspond
	   to your account number followed by the "#" sign.

	   EXAMPLE: 188177#

	   RESPONSE: Please enter your security code.

	3) Press the keys on your telephone that correspond to the
	   last four digits of your Social Security number followed
	   by the "#" sign.

	   EXAMPLE: 9000#

	   RESPONSE: Please enter your transaction code.

	4) Press the keys on your telephone that correspond to the
	   appropriate code for the transaction you want to perform
	   from the list below followed by the "#" sign.  (Please
	   see "List of Account Numbers" with special note to the
	   asteriks preceding four accounts)

	   RESPONSE: Please enter your share type.
	
	5) Press the keys on your telephone that correspond to the
	   share type listed below followed by the "#" sign.
		00 = Regular Share Savings
		01 = Share Draft-Checking
		02 = Christmas Savings
		03 = I.R.A. Account
		04 = Mortgage/Escrow Shares
	   
	   EXAMPLE: Share Savings, Enter 00#

	   RESPONSE: Please enter your Transaction code.  Enter another
	   Enter another transaction code, or the # sign to complete the
	   call.

* List of Transaction Codes
	100 - Inquire Share Balance
	101 - Inquire Last Deposit
       *102 - Inquire check (draft) cleared
	190 - Inquire All Shares
	120 - Inquire Loan Balance
	192 - Inquire All Loans
	122 - Inquire Loan Payment Amount and next due date
      **200 - Share to Share Transfer
      **201 - Share Withdrawal-Check issue
      **220 - Loan Payment from Shares

				SPECIAL NOTE
	* During this transaction, only a five digit number can be entered.
	  If your Share Draft-check number has only 3 or 4 digits, then
	  add zeros to the front of the number to make a five digit number.
	  EXAMPLE: Draft number 271 = 00271#
		   Draft number 1253 = 01253#
	
	** During these transactions, you will need to know from what share
	   type you are making your transaction.  The computer will repeat
	   your instructions, and then ask "Is this correct?", press the
	   "Y" key (number 9) on your telephone followed by the # sign.
	   RESPONSE: Transaction complete.

	   IF YOU DO NOT HEAR THE RESPONSE "Transaction complete",
	   NO TRANSACTION HAS BEEN MADE.

	If no transaction has been made, you will hear - Enter your
	transaction code - and you can re-enter your code

				HELPFUL HINTS
	* Have you instruction card handy before placing your call.
	* Know your security code.
	* For Financial Transactions enter dollar amounts in dollars
	  and cents. DO NOT ENTER DECIMAL POINTS.
	  EXAMPLE: $11.22 is entered as 1122#
		   $150.00 is entered as 15000#
	* End each and every function with a "#" (pound) sign.

				QUESTIONS/ANSWERS
	QUESTION: Am I talking to a real person?
	ANSWER: No, you are communicating with &lt;CU&gt;'s In-House Computer system.

	QUESTION: What happens if I enter the wrong code?
	ANSWER: Nothing, the computer will ask you to re-enter a valid code.

	QUESTION: Am I really transferring money from my savings to
	my checking?
	ANSWER: Yes, you are.  Now you can begin writing Share Draft-checks
	against your newly transferred funds.

	QUESTION: When I make a transfer, when are the funds available?
	ANSWER: Immediately.  You control your money movement.

	QUESTION: Is this really safe?
	ANSWER: Absolutely.  No one but you has access yo your security
	code.  Without your security code matching up to your account
	number, the computer will not allow transactions.  It is
	important to protect your security code and not publicize your
	number.

	QUESTION: When will my check be mailed?
	ANSWER: It will leave the Main Office the next business day.

	QUESTION: Can I transfer to someone elses account?
	ANSWER: NO.  You can only transfer within your own accounts.
	Every account has its own security code.

	QUESTION: Is there a charge for this?
	ANSWER: No. ILLY is another convenient service provided by
	your Credit Union to make life easier.

			GROWING TO SERVE YOU BETTER!

What do you RISKer think of this new bank service.  I called &lt;CU&gt;
and they said predictions are that within 5 years most people
in the US with credit union accounts will have this type of service.
I'm writing a letter to this particular CU warning of the RISKs, but
over the phone I got the feeling they expect that Standard Security
Measures for computer transactions will be enough (read---if nobody
knows how the system works, it can be left wide open and be perfectly
secure).

Almost, ALMOST, tempts me to do some hacking (let me see, they claim
they have 200,000 accounts and all accounts have a six digits, so
I should have to try about 5 times to hit a valid account---assuming
they are not sequencial---otherwise I KNOW what allot of them are---any
number smaller than my account number.  The security code is 4 digits, so
several tries will get in here---autodialing is so nice.  How much
does this person have---hmmm, $50,000...I'll mail a check for $20,000
to that swiss bank account of mine...TRANSACTION COMPLETE...;-)

If I see some good arguments I'll use them in my letter asking the CU
to change this system.  Seems like now is the time to deal with this,
instead of waiting for it to spread nation-wide...

A last note: the state where this credit union resides uses your
SSN as the driver's license number.  Thus if you cash a check
you have just given someone all the important info to hack on
your banking account...

-- Ritchey Ruff		ruffwork@cs.orst.edu -or- ...!hp-pcd!orstcs!ruffwork
	(Needless to say, my security code is NOT the default, although 
	 they didn't require a signature on the note to change the
	 security code...sigh...)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Auftragstaktik"
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.stanford.edu ">
chapman@csli.stanford.edu 
</A>&gt;
</address>
<i>
Fri, 6 May 88 10:10:00 PDT
</i><PRE>

This is a follow-up to one of Henry Spencer's messages, the one about the
German Army's emphasis on personal initiative among its military officers.
However, this is on a different tack than Henry's message about
"whistleblowing."

There was a German term for giving a lot of personal initiative,
responsibility, and autonomy to front-line commanders:  the word is
"Auftragstaktik."  This was actually a product of the closing days of World
War I, and then found its way into training of the German officers in the
inter-war years.  The two most outstanding practitioners and advocates of
"Auftragstaktik" were Generals Guderian and Rommell, two of the more
successful Wehrmacht commanders.

What makes this term relevant and interesting today is that its precepts have
been rediscovered by the American Army in the 1980's.  The (relatively) new
U.S. Army doctrine known as AirLand Battle doctrine is explicitly derived from
the German blitzkrieg, and the authors of the new doctrine recognized how
critical "Auftragstaktik" is to the success of the blitzkrieg.  Consider the
following statement from Colonel Huba Wass de Czege, one of the authors of the
1982 Field Manual 100-5 which instituted AirLand Battle doctrine:

  The second important realization was that the chaos of the next battlefield
  will make centralized control of subordinates always difficult, sometimes
  impossible.  This led to the incorporation of	a doctrine of command and 
  control which features decentralization of decisions by the use of mission 
  orders similar to that used by the Wehrmacht early in World War II.  This 
  style of leadership is called Auftragstaktik by the Germans.  ("Army
  Doctrinal Reform," in Clark, Chiarelli, et al., eds., *The Defense Reform 
  Debate: Issues and Analysis*, Johns Hopkins University Press, 1984, p. 107.)

"Auftragstaktik" has been the subject of numerous articles in various military
journals, most often in *Military Review*, the military's chief publication of
scholarly writing, where it has been celebrated as a long overdue reform from
the Army's traditional, set-piece, "engineer" model of the line combat officer.

What makes this interesting in terms of computer technology is that so much of
the computer development that has been undertaken in programs like DARPA's
AirLand Battle Management System seems to run completely counter to this trend
in the Army.   The AirLand Battle Management System is meant to provide
centralized control of combat operations at the corps level--a corps is the
next larger unit above a division--and the original DARPA plans wanted
electronic accountability down to the individual soldier and vehicle.  The
AirLand Battle Management System is supposed to be a huge expert system that
analyzes a battle in progress, makes recommendations of tactics, issues orders
to subunits, watches the battle in real time through vast sensor and satellite
networks, and continues to update the corps commander with new information,
recommendations, and so on.  This is exactly the opposite of what
"Auftragstaktik" entails.

The other worrisome aspect of "Auftragstaktik" in American doctrine is the wide
dispersion of nuclear devices in the U.S. Army in Europe.  Once the INF Treaty
pulls out Pershing 2s and GLCMs, the nuclear devices that will be left in the
U.S. Army arsenal in Europe will all be short-range weapons like nuclear
artillery shells and mines.  A doctrine which gives the "commander on the spot"
maximum authority for initiative and autonomy, combined with the availability
of short-range nuclear weapons, is something that worries a lot of people,
particularly the West Germans.

Finally, one of the most interesting things to watch in the military
establishment is the really severe conflict of interests between technophile
civilian managers and planners (usually people from the defense industry or
academic backgrounds) versus the traditional line military officers.  When I
give talks about autonomous weapons, automated command and control systems,
AirLand Battle Management, etc., and there are line officers in the audience,
their reaction is almost as viscerally angry as that of peace activists.  On
the other hand, my arguments against these systems (which are generally focused
on their risk) are characteristically dismissed by civilian planners and
managers as a smokescreen attempting to hide an agenda of "unilateral
disarmament," with everything that allegedly entails.  There is a lot of
self-aware and well-developed antipathy to technical solutions on the part of
the line officers, but not very much awareness of (or apparently even interest
in) this antipathy on the part of civilian managers and planners.  This gulf of
communication and the disparity in interests are likely sources of a lot of
confused policies in our military, and confused military policies bear a
significant degree of risk all by themselves.

As an aside, the material I have on the contradictions between AirLand Battle
doctrine's "Auftragstaktik" and the trends in computer systems meant to support
new military doctrine got cut out of *Computers in Battle* because it made my
chapter too long.  Most of the material can be found in my two-part article in
the Fall 1985 and Winter 1986 issues of *The CPSR Newsletter*, "AirLand Battle
Doctrine and the Strategic Computing Initiative."

Gary Chapman, Executive Director, CPSR               chapman@csli.stanford.edu

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.79.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.81.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-28</DOCNO>
<DOCOLDNO>IA012-000129-B045-411</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.81.html 128.240.150.127 19970217021206 text/html 25107
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:10:19 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 81</TITLE>
<LINK REL="Prev" HREF="/Risks/6.80.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.82.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.80.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.82.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 81</H1>
<H2>  Monday 9 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Congress, computer breakdowns, and the SDI 
</A>
<DD>
<A HREF="#subj1.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks in timestamps (postmarks) 
</A>
<DD>
<A HREF="#subj2.1">
Alan Wexelblat
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Risks in the phone system 
</A>
<DD>
<A HREF="#subj3.1">
Boyle
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Risks of banking -- audio tellers 
</A>
<DD>
<A HREF="#subj4.1">
Daniel P Faigin
</A><br>
<A HREF="#subj4.2">
 Alan M. Marcum
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Military Aircraft Crashes in Germany 
</A>
<DD>
<A HREF="#subj5.1">
Michael Wagner
</A><br>
<A HREF="#subj5.2">
 Michael Bednarek
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  KAL 007 
</A>
<DD>
<A HREF="#subj6.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Atari ST virus hiding place 
</A>
<DD>
<A HREF="#subj7.1">
Allan Pratt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Viruses and write-protection 
</A>
<DD>
<A HREF="#subj8.1">
Fred Cohen
</A><br>
<A HREF="#subj8.2">
 Bill Murray
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Congress, computer breakdowns, and the SDI
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.stanford.edu ">
chapman@csli.stanford.edu 
</A>&gt;
</address>
<i>
Mon, 9 May 88 11:02:30 PDT
</i><PRE>

Last week while the House of Representatives was voting on a funding bill for
the Strategic Defense Initiative, the House vote-tallying computer broke down.
The computer reported a vote of 358 ayes and 237 nays on an amendment to kill
the SDI program offered by Reps. Ron Dellums and Barbara Boxer.  The House only
has 435 members.

The irony was not lost on the opponents of the SDI.  Nevertheless, the "manual"
count of voice votes revealed defeat of the amendment 299-118.  

-- Gary Chapman, Executive Director, CPSR

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks in timestamps (postmarks)
</A>
</H3>
<address>
Alan Wexelblat 
&lt;<A HREF="mailto:wex%sw.MCC.COM@MCC.COM">
wex%sw.MCC.COM@MCC.COM
</A>&gt;
</address>
<i>
Mon, 9 May 88 09:48:50 CDT
</i><PRE>

PGN's note about the folks who used predated postmarks to cheat on the
Superbowl contest reminded me of the following:

At &lt;major post office&gt; in &lt;major city&gt; where I used to live, it was a
regular practice to stay open until midnight, April 15 to allow the
filing of last-minute tax forms.  These forms would be taken by postal
employees at drive-up booths.  One year, a housemate happened to
notice that his form, dropped off at ~8 PM was stamped "11:59PM".

Apparently this was SOP - set the clocks to a fixed time and turn them
off so they don't advance.  Gives me lots of confidence in the
accuracy of a postmark!

--Alan Wexelblat  UUCP: {harvard, gatech, pyramid, &amp;c.}!sally!im4u!milano!wex

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Risks in the phone system
</A>
</H3>
<address>
&lt;<A HREF="mailto:boyle%antares@anl-mcs.arpa">
boyle%antares@anl-mcs.arpa
</A>&gt;
</address>
<i>
Mon, 9 May 88 14:34:15 CDT
</i><PRE>

A Mother's Day fire in an Illinois Bell switching center in Hinsdale has
pointed up several RISKS resulting from evolution in the telephone system.

According to an Illinois Bell spokesman, "the switch seems to be alright", but
the cables entering the office were severly damaged.  Not surprisingly, phones
in the area served by the office are completely out of service.  However, my
home phones, which are connected to a central office 5-6 miles from Hinsdale,
are virtually out of service.  I can call some local exchanges (those served by
my switch), but I have no long distance service, no access to 611 repair
service(!), no access to information, and no access to a human operator (dial
0).  What is especially annoying is that attempting to use any of these
services simply results in return to dial-tone, rather than a message
indicating that there is a (known) problem.  Estimated time to repair is
variously quoted as three days to two weeks.

It seems to me that several recent trends have exacerbated this problem:
Centralization of operator services (no operator at my central office, so calls
to operator are routed over trunks).  Ditto for 611 and 411.  But, how to
report phone service out of order when you can't get 611?  Similarly, I can't
call Ill. Bell, because all of their numbers are 1-800 ones, which evidentally
must also be routed through the damaged trunk.

I also find it a startling RISK that my central office, which serves several
exchanges, including Argonne National Laboratory, apparently has interoffice
trunks to only one other central office.  It would seem that for reasons of
traffic balancing, if not redundancy, trunks to more than one other central
office would be good practice.

Is anyone in the Bell system listening?  Care to comment?

[I speak only for myself, as you guessed.]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Risks of banking -- audio tellers (Re: <A HREF="/Risks/6.80.html">RISKS-6.80</A>, Ritchey Ruff)
</A>
</H3>
<address>
Daniel P Faigin
&lt;<A HREF="mailto:faigin@sm.unisys.com ">
faigin@sm.unisys.com 
</A>&gt;
</address>
<i>
Mon, 9 May 88 09:13:07 PDT
</i><PRE>
Organization: Unisys - System Development Group, Santa Monica

Our credit union also has an audio response system. I use it periodically, and
tend to like it when I use it. There are a couple of additional comments I
would like to make on top of what Ritchey has said.

For SSN-phobes, our system is worse. Our credit union uses SSNs as account
numbers, and assigns you a random 4-digit PIN. I can see risks in this in
response to line monitoring and playback threats.

However, the playback risks can only result in bounced checks.  Note that
access is limited to only your account, so money can only be moved between your
accounts. If a check is requested, it is mailed ONLY to your address of record.
The only risk there is that someone may intercept the mail. That's a wetware
problem :-).

I did run into one problem with the system. According to federal law, transfers
via systems like this are treated as telephone transfers. This limits you to 3
per month. One month, I exceeded this limit -- or at least I thought I did
because the computer said it could not do the transaction because I had
exceeded the number of transfers for the month. I didn't believe it when it
happened, so I tried it again. It failed again. When I went to the credit union
the next morning to see what had happened, it turned out that, even though I
had gotten the error message, the computer had done the transfers.

Lastly, our system allows you to chain entry by using the * key.  For example,
to transfer money from subaccount 22 to subaccount 66, I can either enter the
sequence
           ssn#pin#27#22#66#30000#1#99#
and wait through all of the prompts, or enter, as a single action,
           ssn*pin*27*22*66*30000*1*99#
I haven't yet had the courage to do everything at once. I typically use * to
get me to the confirmation prompt.
                                                Daniel

W: UNiSYS/Defense Systems/System Development Group (nee SDC)
   2400 Colorado Ave;Santa Monica CA 90406;213/829-7511x5162 (or 213/453-5162)
H: 8333 Columbus Avenue #17; Sepulveda CA 91343
Email: (uucp) faigin@sdcrdcf.UUCP (arpa) faigin@SM.UNISYS.COM

</PRE>
<HR><H3><A NAME="subj4.2">
Risks of banking -- audio tellers (Re: <A HREF="/Risks/6.80.html">RISKS-6.80</A>, Ritchey Ruff)
</A>
</H3>
<address>
Alan M. Marcum
&lt;<A HREF="mailto:marcum@sun.com ">
marcum@sun.com 
</A>&gt;
</address>
<i>
9 May 88 18:06:43 GMT
</i><PRE>
Organization: Sun Microsystems, Mountain View

The credit union to which I belong also has a touch-tone telephone
banking service.  When I signed up for it, they asked me to specify my
"password" (four digits).  Better than defaulting to something from my
SSN (and our state doesn't even use them for drivers licenses).

This system allows you to transfer funds between sub-accounts within
your account (sub-accounts are, for example, savings, checking, and
loans).  There is no provision for transferring funds to anything
outside your account, nor a provision for requesting a check be issued.
Had these facilities been provided, I would not have enrolled in the
service, because of the risk involved.

Alan M. Marcum				Sun Microsystems, Technical Consulting
marcum@nescorna.Sun.COM			Mountain View, California

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Military Aircraft Crashes in Germany (Henry Spencer)
</A>
</H3>
<address>
Michael Wagner new! +49 228 8199645  
&lt;<A HREF="mailto:WAGNER%DBNGMD21.BITNET">
WAGNER%DBNGMD21.BITNET
</A>&gt;
</address>
<i>
Mon, 09 May 88 12:21
</i><PRE>

In RISKS 6.79, Henry Spencer, after quoting my original article, says:
&gt; nuclear-reactor containment buildings are deliberately designed to
&gt; survive a direct hit from a crashing airliner (not as fast as a
&gt; military jet, in general, but much, much heavier).

I didn't mention this in my original posting, but shortly after the crash near
the nuclear reactor, the interior minister got on the radio and told everyone
roughly the same thing.  I suppose this was meant to be reassuring, but it
doesn't seem to have succeeded.  All of these low-level flights are over
populated areas (there are no un- or sparsely- populated areas in this part of
Germany!), and the residents are scared.  There is now a debate going on as to
whether such low-level flights will be tolerated any more.

To try to put this in perspective, a plane crashed into a McDonalds in Munich
about a year ago, so planes falling out of the sky on people's heads is
currently a hot topic here.  An article in "Der Speigel" a while ago talked
about crowding in the air.  It made the air over O'Hare sound like a Sunday
stroll in the park.  Particularly interesting, in light of this discussion, was
the difference in air patterns that the militarily-proscribed airzones made.

Michael

</PRE>
<HR><H3><A NAME="subj5.2">
Re: Military Aircraft Crashes in Germany (<A HREF="/Risks/6.79.html">RISKS-6.79</A>)
</A>
</H3>
<address>
Michael Bednarek
&lt;<A HREF="mailto:munnari!murdu.oz.au!u3369429@uunet.UU.NET ">
munnari!murdu.oz.au!u3369429@uunet.UU.NET 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 9 May 88 02:11:38 GMT
Organization: I.A.E.S.R., Melbourne University

&gt;&gt; In all, 35 military aircraft have fallen out of the skies here since 1960. 

That number (35) is definitely wrong. I lived until 1983 in Germany, and by
that time more than 120 crashes were reported. Mostly Starfighters.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
KAL007 - the deafening noise continues (<A HREF="/Risks/6.79.html">RISKS-6.79</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Mon, 9 May 88 12:42:03 PDT
</i><PRE>

In <A HREF="/Risks/6.79.html">RISKS-6.79</A> Clifford Johnson &lt;GA.CJJ@forsythe.stanford.edu&gt; writes:

&gt;                                         ....  I think that PGN's tentative
&gt; suggestion that the matter might still be incompletely unravelled simply
&gt; cannot be denied - at least until a public inquiry is instigated.

   Almost assuredly the matter is "incompletely unravelled [sic]", but 
it is also certain to remain that way, public inquiry or no.  Such 
investigations are notorious for their failure to find facts and 
establish definitive chains of events.  Take for example the Lindbergh 
kidnapping, Sacco and Vanzetti, J F Kennedy's assassination, or the 
current Contragate investigations.  Such public inquiries have often 
resulted in the wrong answers being "found", or no answers at all.  If 
answers do come out, they emerge many years later, after responsible 
parties are out of public office or deceased.  Even then, such revelations 
are questionable as verification remains difficult.  

   The discussion over the nature of the course deviation is, at best,
academic.  We cannot prevent deliberate course deviations.  However,
we have identified several possible ways for such a deviation to
occur unintentionally.  What we should and are concerning ourselves
with is how to prevent such errors in the future, and to establish
systems and procedures that will prevent loss of life and property 
should other errors occur.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Atari ST virus hiding place
</A>
</H3>
<address>
Allan Pratt
&lt;<A HREF="mailto:ucbcad!ames!atari!apratt@ucbvax.Berkeley.EDU ">
ucbcad!ames!atari!apratt@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Mon, 9 May 88 10:14:26 pdt
</i><PRE>

A perfect hiding place for viruses on the Atari ST has come to my attention.
The reason it's interesting is it is a place where a VERY LARGE virus can
live -- much larger than just the boot sector of a floppy.

The hole exists because the ST formats floppies with five-sector FATs
(File Allocation Tables) even though at most three sectors will be used. 
Since there are two FATs per disk, this leaves four sectors for the
virus.  A boot-sector virus could be five sectors in length without
impacting the user-visible free space on the disk. 

The sectors in question are logical sectors 4, 5, 9, and 10 (where the
boot sector is sector 0).  These sectors are always zeroed by the
built-in formatter (I can't speak for others).  The rationale, I
believe, for the five-sector FATs is so the root directory of the volume
will appear on Side 1 of a double-sided disk, so a single-sided drive
will not be fooled into thinking it can work with the disk. 

I asked PGN about posting this -- about the tradeoff between warning the
friendlies and informing the hostiles about this hiding place.  As PGN
pointed out, "...  the underground will find out anyway.  The crackers
are networked better than everyone else."

So here is my posting.  The cure for an infected disk is to make the
boot sector non-bootable, and zero the four sectors listed above. 

Opinions expressed above do not necessarily	-- Allan Pratt, Atari Corp.
reflect those of Atari Corp. or anyone else.	  ...ames!atari!apratt

    [By the way, there is tons of stuff on VIRUS-L that is not appearing
    in RISKS.  For those of you with a burning interest in viruses, please
    join VIRUS-L, as indicated in <A HREF="/Risks/6.75.html">RISKS-6.75</A>.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Viruses and write-protection [<A HREF="/Risks/6.79.html">RISKS-6.79</A>]
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>

[I MUST ASSUME THIS MESSAGE IS FROM FRED COHEN, EVEN THOUGH HIS MAILER DID 
NOT INCLUDE HIS "FROM:" AND "DATE" FIELDS, USING INSTEAD THE "DATE:" AND 
"FROM:" FIELD FROM THE MESSAGE TO WHICH HE WAS RESPONDING, AS FOLLOWS:
Date: Thu May  5 16:40:20 1988 CDT
From: Dennis Director &lt;dennis%molly.uucp@eecs.nwu.edu&gt;
Subject: Viruses and write-protection                          CURIOUS.  PGN]

[From: Dennis Director &lt;dennis%molly.uucp@eecs.nwu.edu&gt;]
&gt;I have an XT-compatible computer with DOS 3.2 and all of its utilities and
&gt;programs in the write-protected portion of the hard disk.  I invite both Dr.
&gt;Fred Cohen of the University of Cincinnati and William Murray to come to my
&gt;office ...                  I am (100%) sure that none of these programs will
&gt;modify my boot block, my partition table, the operating system files or any of
&gt;the DOS programs (.COM or .EXE) stored on my hard disk, which will be hardware
&gt;write-protected.

	What makes you think all viruses do only this?

&gt;A scratch area of the hard disk will be writeable at all
&gt;times.  Simply copying a Trojan Horse into the scratch section of the disk,
&gt;should obviously not be considered "infecting my system".

	Copying a "Trojan Horse" onto your system would not constitute
	infecting it even if it were in your operating system. Since you
	don't seem to know what a virus, I would suggest that you
	purchase a copy of my dissertation for a more formal definition.
	(sending me $20 will buy it).

	I assume from your comment that it would however be considered
	"infecting your system" if we wrote a virus that infected source
	programs in your "scratch" area. If they then infected floppies
	and other information, this would also be infection, and if when
	you finally did write enable your hardware protected disk to put
	in another "protected" piece of software, the virus spread into
	that area, that would also be considered infecting your system.

&gt;	Since Dr. Cohen has stated that "you cannot write protect
&gt;lotus, etc because of copy protection" we will also have a copy of Lotus
&gt;123 installed and working in the write-protected section, as we have had
&gt;for almost two years.

	Lotus disks that I have seen at a number of sites have had this
	property, that is not to say that it is impossible to make them
	work that way. We contacted Lotus to have them make available
	a version with this property, and they refused. I did not say
	that for all lotus implementations, write protection was not
	possible, only that we (and you if you were in the set of people
	with the versions of lotus we were using) could not write
	protect them and have them work in the systems that we were
	working with. If lotus has backed off of this policy, I would
	only be happy to hear about it, but since your copy is so old,
	it may be that a recent change in their policy has made this
	impossible for newer versions.

&gt; This will be a fully legitimate copy-protected
&gt; installed version of 123.  It runs perfectly from the write-protected
&gt; zone and cannot be infected.

	Neither Bill Murray nor I has ever said that you can modify
	information that is physically write protected, and I doubt
	if either of us ever would. What we said is that it is only safe
	if it is 100% protected 100% of the time. Since you have already
	admitted that it would be possible to infect the writable part
	of your hard disk, I assume that you in fact agree with us.

	On the other hand, you should agree that you do not know for
	certain if there is or is not an infected program on the write
	protected segment of your hard disk, and that when you install
	software on this part of your disk, it is entirely possible that
	without special precautions, you could infect one of those
	temporarily write enabled files. Furthermore, I am not convinced
	by your statement of belief that your disk is in fact write
	protected in hardware. I have seen many people who believed such
	things become unpleasantly surprised.

&gt; Why go on debating that which can be simply demonstrated? Seems
&gt; like a fair offer to me!

	In many cases, it cannot be demonstrated that it is impossible
	to do something simply by trying to do it. If you study the
	philosophy of science (see a famous work by Karl Popper), you
	will find that "FOR ALL" statemewnts covering infinite sets
	cannot be verified by finite numbers of supporting examples.
	They can however be refuted by a single example. If we succeeded
	in infecting your system, it would prove you wrong, but by
	failing to do so, it does not prove you right.

	Also, it is customary when proclaiming perfection (even with the
	various nebulous "except"s here and there) to make it worthwhile
	to demonstrate counter examples. I would suggest that in making
	such a challenge, you offer a $100,000 bet, so that if we decide
	to take you on, it will be worth our time to take you down, and
	so that if we take you on and fail to take you down, you will be
	able to have a very nice meal in your new home.

			Fred Cohen

</PRE>
<HR><H3><A NAME="subj8.2">
 D. Director: "Enough is enough."
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Mon, 9 May 88 12:34 EDT
</i><PRE>

Dennis Director and I agree on the following:  enough is enough.

However, Director seems to believe that somewhere, both F. Cohen and I, have
asserted that write protection is not sufficient for protecting an operating
system from infection by a virus.  We have not.  Indeed, we have both conceded
that 100% protection of a hard disk 100% of the time results in 100% protection
of the hard disk from infection.  That I have so conceded is a matter of
record.  That I have ever asserted otherwise is not a matter of record.  If it
were, I am sure that Director would cite it.

Therefore, Director's challenge to me to prove that which I have never
asserted, can justly be construed as disingenuous.

What I have said, and will continue to say until I begin to get feedback that
the message is being heard, is that making one, or even many, machines immune
to infection is not sufficient to prevent the spread of the virus.

Director insists upon seeing the "protection of the operating system and other
commonly used programs" as the issue.  I do not blame him; if I were in the
business of selling write protection, I suspect that I would see it that way
too.

Nonetheless, I will continue to assert that it is the SPREAD OF THE VIRUS,
rather than the protection of one or more systems, that is the issue.

I must confess to a great deal of disappointment that all of the response to my
review of Director's product has focused on assertions that I have been
extremely cautious not to make and has been totally silent on those that I have
gone to such great pains to make.  I feel much as George Washington must have
felt when writing to the Continental Congress: "Is anybody there?"

William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
2000 National City Center Cleveland, Ohio 44114                          
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840                

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.80.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.82.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-29</DOCNO>
<DOCOLDNO>IA012-000129-B045-439</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.82.html 128.240.150.127 19970217021226 text/html 26453
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:10:52 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 82</TITLE>
<LINK REL="Prev" HREF="/Risks/6.81.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.83.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.81.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.83.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 82</H1>
<H2>  Wednesday 11 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of Research Computing -- Don't ask computers for flavors 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of Single Point Failures -- The Hinsdale Fire    
</A>
<DD>
<A HREF="#subj2.1">
Chuck Weinstock and Patrick A. Townson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Phone system RISKS: Second-order effects 
</A>
<DD>
<A HREF="#subj3.1">
Joel Kirsh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Program Trading Halted 
</A>
<DD>
<A HREF="#subj4.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Law to Regulate VDT Use 
</A>
<DD>
<A HREF="#subj5.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Virus Prose 
</A>
<DD>
<A HREF="#subj6.1">
Vin McLellan and John Norstad
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: "Auftragstaktik" 
</A>
<DD>
<A HREF="#subj7.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of banking -- audio tellers 
</A>
<DD>
<A HREF="#subj8.1">
haynes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Reliability of SDI-related equipment 
</A>
<DD>
<A HREF="#subj9.1">
Andy Behrens
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of Research Computing -- Don't ask computers for flavors
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Wed 11 May 88 09:43:52-PDT
</i><PRE>

A three-alarm fire destroyed the research building at Dreyer's ice cream plant
in Oakland CA.  Computers and files were destroyed -- the entire collection of
"top-secret" formulas known only to the "flavor team" -- along with two
freezers full of ice cream.  The flavor team had recently been ``working
toward updating all our files and materials and getting backups of everything
-- computer disks, formulas, the whole works.  It would [soon] have been
stored in another building.''  (Don Conolly, director of R&amp;D) The company had
whittled down the potential new flavors for 1989 (usually about 7 are chosen
each year) from 100 to about 25, but all of those complex formulas were lost.
[SFChron, 10 May 1988, p.A2]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of Single Point Failures: The Hinsdale Fire [<A HREF="/Risks/6.81.html">RISKS-6.81</A>, Boyle]
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Wed, 11 May 88 10:23:10 EDT
</i><PRE>
From: Chuck Weinstock &lt;weinstoc@SEI.CMU.EDU&gt;

This item points out the risks of not guarding against single point failures.
In my memory this is the worst example of this sort of thing in terms of how
much of the general public was affected.   Chuck

Excerpted from:

TELECOM Digest                           Tuesday, May 10, 1988 10:36PM
Volume 8, Issue 76

                            The Great Fire

 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

From: Patrick_A_Townson@cup.portal.com
Subject: The Great Fire
Date: Mon May  9 23:19:29 1988

In my earlier posting, details were very sparce and I was unable to be
specific in describing the disaster which struck us here over the weekend.
I now have a more detailed accounting for the net --

An extra alarm fire broke out Sunday, May 8 at 5:30 PM in the Illinois Bell
Central Office, 120 North Lincoln Avenue, Hinsdale, Illinois. At the time
of the fire, the Chicago area, and the west suburbs in particular, were
experiencing a very bad electrical storm. There had been a great deal of
lightning; rain was quite heavy, and winds were about 40 miles per hour.

Fire Departments from 15 nearby communities battled the blaze before bringing
it under control at about 8:30 PM. The fire was officially struck at 11:30 PM
Sunday night. Deemed the worst disaster in the history of Illinois Bell, and
one of the worst disasters ever in the telephone industry, the fire virtually
gutted the two story building.

The Hinsdale central office is a *major* switching center for the west
suburban area. In addition to serving ten prefixes covering various
communities including Oak Brook, Westmont, Darien, Hinsdale and others,
the office housed the Directory Assistance Data Base for downstate Illinois;
it served as the communications apex for air traffic control between Ohare,
Midway, and the Aurora, IL aviation center; it was the headquarters for a
majority of the cellular phone service in the greater Chicago area; *and*
it handled long distance calls in and out of most of Dupage County, Will
County and southern Cook County.

        *And the office is now almost gutted*

The reason for the fire has not been detirmined, but fire department officials
have reason to believe the building was struck by a tremendous bolt of
lightning during the worst of the electrical storm which was in progress when
the first fire alarms were called in at 5:30 PM.

The fire caused another problem: the emission of toxic fumes which required
the evacuation of several blocks of homes in the vicinity. These fumes came
from batteries described as 'highly toxic' which were stored in the premises
and a large amount of fiber optic cable. The Hinsdale office was very much
a fiber optic center in the area.

Because of the toxic release, at one point firemen working in the building
had to be called out, in the interest of their own safety, and as firemen
relieved each other working inside in ten to fifteen minute shifts, they
were required to strip to their underwear and be hosed down with a special
solution so that the contamination would not be carried elsewhere.

After the fire was first reported, Illinois Bell employees on duty at the
time followed company procedures by first notifying the Fire Department.
Others then began fighting the fire, and a few began a process known as
an emergency telephone tree, calling other employees and company management
at home to notify them of the circumstances. Each employee thus notified
was responsible for calling a few more employees.

Within about an hour, while the fire was raging at its worst, several dozen
employees had already gathered on location, waiting for a go ahead to begin
clean up and restoration work.

   *But no one dreamed it would be nearly as bad as it was*

Although the fire was struck at 11:30 PM, fire officials would not permit
anyone to enter the building for several more hours, pending exhaustion of
the toxic fumes. Illinois Bell employees were allowed access to the building
beginning at 4:00 AM to survey the damage.

Most of Monday was spent merely bailing out the water and removing the
rubble from the fire. Emergency lighting was installed and cleaning crews
began scrubbing soot from the walls, ceilings and floors. The cleanup was
still in progress late Monday afternoon.

At this writing (12:50 AM Tuesday, May 10), Illinois Bell has not announced
any date that service will be restored. It is estimated that it will be
at least 4-5 days before *emergency* service is restored. Hinsdale, you
see, is also the main center for 911 services in over a dozen west suburban
communities.

Ordinarily in circumstances like this, the phone company will set up special
phones in public areas. They will often times be mobile or cellular type
instruments available for the public to use for emergency calls. But since
Hinsdale *is* the cellular center for Chicago, even this option is not
available.

When the first firemen arrived on the scene, heavy black smoke was pouring
out of all the windows on the first floor. By that time, employees were
evacuating after having given up on their own emergency proceedures.

What we are faced with now is a *major* traffic jam on the network in the
Chicago area. Long distance calls in and out of the area are very sluggish
in getting through. Directory Enquiry in downstate Illinois is only able
to handle about ten percent of the calls they are receiving, those being
requests that are being searched manually through paper directories on hand
in the communities affected.

Hinsdale was the major center for MCI/Sprint long distance also....and those
services are severely crippled in the area. Obviously, data transmission
lines and the like are dead.

About 40,000 subscribers, representing 100,000 residents are without phone
service for the indefinite future. In Hinsdale and the other communities
affected, the Police Departments have stationed patrol cars a few blocks
apart on the street, and residents have been told to go to the nearest
police car to report emergencies.

Illinois Bell has not announced -- as of Monday evening -- any schedule
of priorities for restoration of service. Jim Eibel, vice president of
operations for Illinois Bell said emergency phones would be set up within
a day or two, when crews were able to reroute at least limited traffic
through the LaGrange, IL center. Of equal importance of course is the
restoration of 911 service, and the restoration of long distance service.
Eibel said restoring service to the ten prefixes in the area, which would
return regular phone service to local residents would probably not occur
for 'several' days. Naturally, cellular service also has to be placed in
the table of priorities somewhere. About fifty percent of the cellular
service in the entire Chicago area is out right now due to the fire.

Other Bell companies around the nation have responded by dispatching
emergency crews to come to the aid of Illinois Bell, and these out of
town crews will remain on site for several weeks as needed. In addition,
while the fire was in progress, executives from MCI and Sprint met with
their counterparts from Illinois Bell on location and immediatly offered
their full assistance and cooperation during the period of turmoil we
will be facing for the next several weeks.

For up to the minute announcements during the next several days, it is
recommended that you call a special recorded announcement service for
company employees. Called the 'Illinois Bell Communicator', this recorded
announcement will be updated 4-5 times daily, and can be recieved by
dialing 312-368-8000, a number at IBT Chicago Headquarters Building.

It goes without saying on this forum that everyone is requested to
avoid making all but emergency calls into the Chicago west suburban area
for at least the next several days. And if your call is met with an
'all circuits busy' message, kindly refrain from repeated dialing attempts,
as this simply clogs the network even worse.

A further update will be posted here when I have news available.

The last fire to occur in a telephone center was in Manhattan a few years
ago. You may recall the resulting damage and confusion from that situation.
The last fire *in the Chicago area* occurred in the River Grove, IL central
office in 1946...then an all manual exchange. Unlike that fire, considered
bad at the time, the fire in Hinsdale this past weekend was many times worse,
since Hinsdale is responsible not only for its local calling area but so
many of the overall network services for the Chicago area.

Patrick Townson

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Phone system RISKS: Second-order effects
</A>
</H3>
<address>
Joel Kirsh 
&lt;<A HREF="mailto:KIRSH@NUACC.ACNS.NWU.Edu">
KIRSH@NUACC.ACNS.NWU.Edu
</A>&gt;
</address>
<i>
Tue, 10 May 88 09:36 CDT
</i><PRE>

[...]  It appears (to me, at least) that ATC never expected that a fire in a
switching center could compromise their operations.  Another point is that
efforts to fight the blaze were slowed by toxic fumes from burning insulation.
Perhaps Illinois Bell never expected the fire, either.  [...]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Program Trading Halted
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Wed 11 May 88 09:46:49-PDT
</i><PRE>

In a move intended to restore investor confidence in the stock market, five
large Wall Street firms announced yesterday that they had suspended program
trading for their own accounts.  The action came in the wake of intense
pressure from customers and other member firms who blamed the controversial
practice for many of the recent sharp swings in prices since the stock market
collapse last October.  Four of the firms will continue to execute such trades
for their customers, however.  [SFChron, 11 May 1988, p.C1]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Law to Regulate VDT Use
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>
Wed, 11 May 88 09:21:57 EST
</i><PRE>

MEASURE REGULATES VDT USE

  HAUPPAUGE, N.Y. - A measure regulating the use of computer terminals in the
workplace was passed Tuesday by the county legislative body.
  Described as the first of its kind in the nation, the bill will set
standards for public and private employers in firms that have more than 20
video display terminals.
  Legislator John Foley, the bill's sponsor, said the legislation would
prevent "high-tech sweatshops."  Opponents said it could drive business from
Suffolk County.
  The bill:
  + Requires a 15-minute break every three hours for employees who work at
    the terminals;
  + Will set work station standards, including adjustable desks and chairs
    and detachable video screens; and
  + Mandates that companies pay 80 percent of the cost of annual eye exams
    and eyewear required for an operator.
  A workplace experts [sic] said the bill would serve as a model for other
municipalities or states.
  "Whether this bill will result in legislation elsewhere is unclear, but
it'll rejuvenate a lot of campaigns for VDT standards around the country,"
expert Laura Stock said.
  Companies that would be affected said implementation of the law would be
costly, placing them at a competitive disadvantage in the marketplace.
						- Associated Press

From the Lafayette (IN) Journal &amp; Courier, May 11, 1988, page 1.   --Dave Curry

                             [Among other issues, RISKS-1.6, 1.7, 2.2, 3.9 and
                             4.40 have previously considered VDT safety.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Virus Prose
</A>
</H3>
<address>
"Vin McLellan" 
&lt;<A HREF="mailto:SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Wed 11 May 88 01:01:45-EDT
</i><PRE>

   Ken van Wyk's crisp clear description of the "Lehigh" virus 
in a report to RISKS provided a text outlining a simple DOS virus 
which became a common reference in both professional and public 
discussions of the problem.

   Norstad's explorations into the mysteries of the "Scores" 
virus on the Macintosh have tended to illustrate how complicated 
(even relatively benign) PC viruses can be. He and his associates
have educated a huge community of academics who supervise and guide
student and faculty Mac users; giving an earthy and technical 
overview of the threat, the risk, and options for survival. It has
been a striking display of networked education... or was it medicine?
Another Norstad report, an example of his followup, follows.

    Vin McLellan, The Privacy Guild, Boston
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;

As relayed from:

INFO-MAC Digest         Wednesday, 4 May 1988      Volume 6 : Issue 46
&lt;INFO-MAC@SUMEX-AIM.Stanford.EDU&gt;

 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
  
Date: Mon, 2 May 88 09:52 CDT
From: John Norstad &lt;JLN%nuacc.acns.nwu.edu@forsythe.stanford.edu&gt;
Subject: Scores Virus Report 3
   
This is my third report on the Scores virus.  In my first report I
revealed what Scores did, how to detect it, and how to get rid of
it by hand using ResEdit.  In my second report I reviewed Ferret
1.0 and KillScores, two free disinfectant programs that have
appeared to get rid of Scores.  In this report I describe further
testing of Ferret 1.0, the new Ferret 1.1, and KillScores.
   
IMPORTANT:  Ferret 1.1 has very serious bugs!  Based on my tests I
recommend using KillScores instead.
  
1. Ferret 1.1 does NOT properly delete one of the viral resources
in the system file (INIT 17), at least on my small infected test
system!  I found this unbelievable, so I reran my test several
times, and it failed each time.  Ferret 1.0 does not have this
problem.

2. Ferret 1.1 does NOT properly disinfect files which contain CODE
resources marked "protected".  Some applications are distributed
with protected CODE resources, and Scores can infect them, so this
is another important bug.  Ferret 1.0 also has this bug.  In this
case the supposedly repaired application is left in a seriously
damaged state - it will bomb immediately on launch.

3. Ferret 1.1 does NOT properly disinfect locked files.  This is an
important bug, even though Scores can't infect locked files.  The
file could have been unlocked when it became infected, and then the
user could have locked it later.  Ferret 1.0 also has this bug.
I'd like to thank Rich Holmes for first pointing out this bug.

4. Ferret 1.1 still does NOT always properly report the names of
infected files.  Ferret 1.0 also has this bug.

To make things even worse, Ferret does not give the user any
indication that anything is wrong.  It leaves the user with the
impression that his/her system is clean, when in fact it's still at
least partially infected.

I also did further testing of KillScores.  KillScores had no
problems with the cases above where Ferret failed - it properly
disinfected all the files on my test system.  In the case of locked
files KillScores unlocks the file, disinfects it, and leaves it
unlocked.

In my second report I mentioned that CE Software's Vaccine
effectively prevents infection by Scores, at least on my test
system.  If you are at all worried about viruses, and you should
be, I strongly recommend that you get Vaccine and use it
religiously.  CE Software deserves all of our thanks for developing
and giving away this important tool.  It's not perfect protection,
as the authors freely admit in the documentation, but it is
effective against Scores, and I understand that it's also effective
against most of the other recent Mac viruses.

Once again, I must emphasize that I do not have the facilities or
time to do large scale testing of many infected applications.  All
of my testing is done on a small floppy-only system, with only
MacWrite, TeachText, and ResEdit for infected applications.  So I
can't guarantee that KillScores or any other program is perfect, or
that I haven't made mistakes in these reports.

Also, I should probably mention that all of my statements in all of
my reports reflect my opinions only, and not those of my employer,
Northwestern University.

John Norstad, Academic Computing and Network Services, Northwestern University
Evanston, IL 60208    Bitnet:   JLN@NUACC     Internet: JLN@NUACC.ACNS.NWU.EDU

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: "Auftragstaktik"
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 11 May 88 00:04:54 EDT
</i><PRE>

I agree with most of Gary Chapman's comments, but must correct one error
of fact:  Auftragstaktik was not a World War I invention.  It became formal
doctrine in the 1870s, after the Franco-Prussian War, and had been employed
earlier in the Seven Weeks' War (1866).  A possible reason for the error is
that there were *two* famous German generals named Moltke:  the originator
of Auftragstaktik, and his nephew, the less-successful WWI commander.  The
quote I gave was from the elder Moltke, who died in 1891.

Ironically, the well-known WWII successes of Auftragstaktik came after it
was already in decline, because of Hitler's intolerance for disobedience.
Guderian spent most of the Battle of France making excuses for (and
bending the truth about) how far his units were advancing.

Henry Spencer @ U of Toronto Zoology  {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of banking -- audio tellers (Re: <A HREF="/Risks/6.81.html">RISKS-6.81</A>, (Daniel P Faigin)
</A>
</H3>
<address>
99700000
&lt;<A HREF="mailto:haynes@ucscc.UCSC.EDU ">
haynes@ucscc.UCSC.EDU 
</A>&gt;
</address>
<i>
Tue, 10 May 88 18:46:16 PDT
</i><PRE>
Organization: California State Home for the Weird

I had a similar experience with a commercial system for telephone transfers
between banks some years ago.  I keyed in all the data in response to the
computer voice prompts. At the end it should have said "Data accepted.
Goodbye."  Instead it said "System error. Session terminated."  So I waited a
few hours and tried again with the same results, and tried again the next day
with the same results, having called the help number and been advised by a real
live person to try again.  A few days later I got a call from the bank
complaining that the account I was transferring out of was grossly overdrawn
and what's going on anyway?  So it turns out that the transactions had in fact
gone through before the point where the voice announced an error; and the error
didn't undo the transaction.  Clearly a very bad example of how to write
software.

haynes@ucscc.ucsc.edu   haynes@ucscc.bitnet   ...ucbvax!ucscc!haynes

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Reliability of SDI-related equipment  [More on <A HREF="/Risks/6.81.html">RISKS-6.81</A>, Chapman]
</A>
</H3>
<address>
Andy Behrens
&lt;<A HREF="mailto:burcoat!andyb@dartvax.Dartmouth.EDU ">
burcoat!andyb@dartvax.Dartmouth.EDU 
</A>&gt;
</address>
<i>
Sat, 7 May 88 18:08:53 EDT
</i><PRE>
Organization: Burlington Coat Factory Warehouse

Syndicated columnist Mary McGrory describes what happened when the U.S. House
of Representatives considered an amendment by Reps. Dellums and Boxer.  The
amendment would have reduced SDI funding to the "basic research" level -- only
$1.3 billion.

"The electronic scoreboards on the wall were busy recording the huge numbers of
those in favor of more voodoo in outer space, when all of a sudden they went
wild and starting flashing a sensational victory for Dellums.

"Members gathered around Dellums' elegant figure and congratulated him noisily
as the numbers piled up.  At one point the score for Dellums was 358 to 237,
and the fail-safe technology showed a total of 595 members -- 100 more than
exist.

"There was wild laughter about the wonders of science.  The heretics hailed the
vivid proof that software can go soft and the timely hint that a wayward
microchip could bring Star Wars crashing down.

"The presiding officer announced that the roll would be called in the old way,
by hand.  The laborious reading began, and the hilarity increased.  But the
result was what it was always going to be: 118 in favor of [the amendment], 299
for pressing on amid the wars."
					Andy Behrens        andyb@burlcoat.UUCP

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.81.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.83.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-30</DOCNO>
<DOCOLDNO>IA012-000129-B045-459</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.83.html 128.240.150.127 19970217021240 text/html 22248
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:11:07 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 83</TITLE>
<LINK REL="Prev" HREF="/Risks/6.82.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.84.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.82.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.84.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 83</H1>
<H2>  Thursday 12 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Time-bomb warning: SunOS may have one set to go off TOMORROW!    
</A>
<DD>
<A HREF="#subj1.1">
Dave Platt [2]
</A><br>
<A HREF="#subj1.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  A reminder on listening to the boy who cried wolf! 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Report on the Northwest crash in Detroit 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  CCC informs on `Virus Jerusalem'; valid threat? 
</A>
<DD>
<A HREF="#subj4.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  `Virus Epidemic Center' at Hamburg University 
</A>
<DD>
<A HREF="#subj5.1">
Klaus Brunnstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Risks and Risk Reporting 
</A>
<DD>
<A HREF="#subj6.1">
Elizabeth D. Zwicky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Hawaiian Tel and HISS -- the Hawaiian Islands SysOp Society 
</A>
<DD>
<A HREF="#subj7.1">
Todd South
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Time-bomb warning: SunOS may have one set to go off TOMORROW!
</A>
</H3>
<address>
Dave Platt
&lt;<A HREF="mailto:dplatt@coherent.com ">
dplatt@coherent.com 
</A>&gt;
</address>
<i>
Thu, 12 May 88 14:36:05 PDT
</i><PRE>

Our site administrator has just received notice of what's said to be a
"confirmed rumor" that there is a time-bomb buried in some current versions
of SunOS (the Sun variant of Unix).  This time-bomb is reported to be set to
trigger tomorrow (Friday the 13th).  It was suggested that we should either
shut down our Sun systems tomorrow, or alter the date so that the time-bomb
doesn't go off.  As we don't know whether the bomb is of the "go off on the
13th" or "go off on or after the 13th" variety, it would seem safest to set
the system clocks back rather than forwards.

We have no details at this time about the content of the time-bomb.  The
call to our administrator did not come from Sun, but from one of her
contacts at another Sun customer's site; it was of the "We thought you
should know... more details soon" variety.

It is possible that this rumor, although "confirmed", is actually mistaken
or is a hoax.  So, I apologize in advance to everyone everywhere if this
alert turns out to be a false alarm.

I'll mail updates when and as I receive them.

Dave Platt                                             VOICE: (415) 493-8805
  USNAIL: Coherent Thought Inc.  3350 West Bayshore #205  Palo Alto CA 94303
  UUCP: ...!{ames,sun,uunet}!coherent!dplatt     DOMAIN: dplatt@coherent.com
  INTERNET:   coherent!dplatt@ames.arpa,    ...@sun.com,    ...@uunet.uu.net

</PRE>
<HR><H3><A NAME="subj1.2">
Followup to SunOS time-bomb alert
</A>
</H3>
<address>
Dave Platt
&lt;<A HREF="mailto:dplatt@coherent.com ">
dplatt@coherent.com 
</A>&gt;
</address>
<i>
Thu, 12 May 88 15:25:28 PDT
</i><PRE>

Within the past 20 minutes, I've spoken to two people in Sun's tech-support
department.  They report the following:

-  They have been running extensive experiments on their in-house machines,
   attempting to detect any signs of a "Friday the 13th" time-bomb.  So far,
   there has been "absolutely no sign" of any such time-bomb.

-  They have no information that leads them to believe that any such time-
   bomb exists in the code.

-  They're not sure where the rumor of the time-bomb originated.  It
   appears to have first "broken" at about noon PDT (3 PM EDT), and has
   spread with extreme rapidity.  One of the people to whom I spoke indicated
   that he has spoken with "at least 30" contacts across the country.

-  There have been no reports from Australia or Japan (where it's already
   Friday the 13th) that would indicate the triggering of any time-bombs.

So... at this point, it appears likely that the "Friday the 13th time-bomb"
rumor is just that... a rumor with no facts behind it.

Dave Platt                                             VOICE: (415) 493-8805
  USNAIL: Coherent Thought Inc.  3350 West Bayshore #205  Palo Alto CA 94303
  UUCP: ...!{ames,sun,uunet}!coherent!dplatt     DOMAIN: dplatt@coherent.com
  INTERNET:   coherent!dplatt@ames.arpa,    ...@sun.com,    ...@uunet.uu.net

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Followup to SunOS time-bomb alert
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Thu 12 May 88 17:28:34-PDT
</i><PRE>

Private net communications from &lt;werner@rascal.ics.utexas.edu&gt; Werner Uhrig and
chuq@Sun.COM (Chuq Von Rospach) and spaff@purdue (Gene Spafford) confirm that
as far as any one can tell, the rumor is totally unfounded, but that Sun is
taking this very seriously.  (By the way, I know that several computer
companies routinely run their systems with the clock advanced in an effort to
detect time-bombs in the official products.)  Serious concern about the rumor
is reported within the U.S. government.  No one has yet been able to identify
the source of the rumor, although it could have easily been someone's confusion
with the alleged Israeli time bomb, also scheduled for 13 May but presumably
defused by now.  (Rumors sometimes do have a thread of reality behind them.)
And, after all, as Werner noted, it is Friday the 13th -- which is sort of an
imitation April Fool's Day.

Starting rumors is a commonly used technique to attempt to damage the
competition, or to test public reaction.  It also provides a mask for the
perpetrator of the real thing to hide behind.  [See the next item!]
      
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A reminder on hearing the boy who cried wolf! 
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Thu 12 May 88 13:38:13-PDT
</i><PRE>

Security personnel in the First Interstate Bank tower in Los Angeles
apparently reset the smoke alarms that went off at the beginning of last
Wednesday's fire, believing that this was another in a recent string of false
alarms.  They also sent maintenance engineer Alexander John Handy to
investigate the alarms.  (He died in the elevator.)  At least seven minutes
were lost until three phone calls came in to 911 from outside the bank.

Although this is not computer related, the less on is clear: mere presence of
false alarms must always be considered as a potentially serious system problem.
[SF Chron, 11 May 88, p.A8]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Report on the Northwest crash in Detroit
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Thu 12 May 88 13:35:41-PDT
</i><PRE>

The National Transportation Safety Board officially blamed the crash last
August (killing 156) on pilot error.  They also acknowledged the contribution
of the audible warning system, which did not go off because power to it had
been cut, and which should have alerted the pilots that the flaps were not set
properly.  They were unable to determine whether a circuit had been pulled by
the pilots or maintenance workers, or if the alarm had simply failed.  
[SF Chron, 11 May 1988, p.A5]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 CCC informs on `Virus Jerusalem'; valid threat?  (Re: <A HREF="/Risks/6.80.html">RISKS-6.80</A>)
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>

</i><PRE>

Members of Computer Chaos Club have informed German public authorities that
a version of `Jerusalem Virus' has invaded public PCs. These authorities have
asked some Computer Security experts, but up to now, there is no evidence of
such an epidemic. Can anybody else help to verify or falsify this?

In this context, the following information from a CCC insider may become
interesting: the arrest of CCC leader, Mr.Wernery, who is the virus expert of
his organisation, has heavily upset CCCs members; some younger guys evidently
plan a `revenge action'. Since the chances to invade German public computers
are rather restricted, due to missing links to publicly accessible networks,
they may try to distribute `interesting' programs (games, text processors, DTP,
databanks) infected with a virus with `retarded activation'. According to good
information souces, such activities are discussed but I have no insight that
they have decided and begun action!

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 `Virus Epidemic Center' at Hamburg University (Re: <A HREF="/Risks/6.80.html">RISKS-6.80</A>)
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>

</i><PRE>

As a consequence of growing concern of economic and public organisations in
Fed.Rep.Germany, we are establishing in Hamburg, together with scientific staff
and some 20 students, a `Virus Epidemic Center' aimed at testing any new virus
as well as producin and testing `hygienic software' to detect and eliminate
`infections'. We focus our work on PC (DOS) and PS (OS-2), Amiga, ATARI and
MacIntosh. We plan to establish a formatted description distributed
electronically (and available to RISK FORUM directly or by reference, depending
on PGNs moderation), and to publish a (German) book on "Viruses, and how to
fight them" covering our tests.  We are interested in any exchange of
information and experiences.

Klaus Brunnstein       University of Hamburg      FRG

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Risks and Risk Reporting
</A>
</H3>
<address>
Elizabeth D. Zwicky
&lt;<A HREF="mailto:zwicky@pterodactyl.cis.ohio-state.edu ">
zwicky@pterodactyl.cis.ohio-state.edu 
</A>&gt;
</address>
<i>
Wed, 11 May 88 17:14:27 EDT
</i><PRE>

Risks have been on our minds a lot here recently. We're in a bad security
position as a heavily networked educational site. This quarter we have some 500
students (all in Computer and Information Science) using Sun workstations.
Probably 400 of them know barely enough about UNIX to do the work. Another 90
know enough to fool around, but are basically harmless.  Those last 10 students
are a real problem, though. We implement a little more security every quarter.
We started by making the client Suns unable to touch any of the disk as root.
Then we modified the boot sequence so that it will not simply dump you into
single-user mode if interrupted, but will ask for the password first. This
quarter we modified the programs that allow you to become the superuser so that
they only work for users in specific groups and also log extra attempts.

While we were doing all this, we were of course merrily creating other security
holes we didn't know about. The one that just came to our attention had to do
with a screen saver. The students here run the X window system, and there is a
program that is not advertised to them but is available called "xsecure" which
blanks the screen to black and bounces a little lock around it until you type
your password at it.  Earlier, in one of our less security-minded moments, we
added to xsecure a feature we had come to know and love in the SunView version
of the program, where you can type the root password as well as the user
password to clear the lock. This allowed us to easily and non-destructively
clear locks. Students are not supposed to lock screens for more than a few
minutes, since we are rather short of Suns. As a stick-in-the-mud, I stuck to
my old violent method of just rebooting the Sun. Turns out that this was a good
thing, as a clever student trojan-horsed xsecure. His program looked just like
xsecure, but stored the password. He just set it running and left, sure that an
operator would come by and unlock it eventually - and one did.

Everybody now uses my method.

Then, the CACM got here. Several people asked, on a public newsgroup, whether
we had the mentioned Gnu Emacs bugs. Fact is, we don't. I can't imagine what
posessed them to ask on cis.general, however. Did they think we were going to
say that we did have the bugs? Some security improvement that would be!

Elizabeth Zwicky
                             [I presume you are referring to Cliff 
                             Stoll's article in the May 88 CACM?  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Hawaiian Tel and HISS -- the Hawaiian Islands SysOp Society 
</A>
</H3>
<address>
Todd South
&lt;<A HREF="mailto:tsouth@pro-pac.cts.com ">
tsouth@pro-pac.cts.com 
</A>&gt;
</address>
<i>
Mon, 9 May 88 06:00:26 HST
</i><PRE>

Recently, Hawaiian Tel has gone on the local news and stated that they want to
change the laws so that ALL computer BBS's will have to have business lines and
become actual businesses! This is the result of a recent person in the
community deciding that he would become a universal watchdog for the Hawaiian
area BBS's.  After sending intimidating letters to Hawaiian Tel, the Star
Bulletin newspaper, all local military commanders, and to the sysops of a large
number of local systems, this person finally sparked Hawaiian Tel into action.
The telephone company has been badgering people with claims of false service
and threatening them with federal prosecution if they do not change their lines
to business service RETROACTIVELY to the first day the phone line was
installed!

Their (HTel) basic claim is that even if you have a BBS listing on your system
that does nothing but list the phone numbers of other local area BBS's you
are advertising.  If someone on your system says, "hey I want to sell this
extra CP/M board I have", you (as a sysop) are running a business.

To this effect there have also been claims of tax evasion and other illicit
activities with no founded proof.  But, it is all a bad situation that has
caused a number of us to band together into an association of sysops in Hawaii
so that we may have a large base of people and financial backing in case this
thing comes down to lawyers.  The following is the official notice that is
being published around Hawaiian systems.

                   --------------------------------------

First off, my name is Toni Hinton (aka "avatar") and my husband Stan and I
run The Restaurant... BBS.

I'm not sure how much of the garbage going on you're aware of -- the
letters "reporting" SysOps to HawTel for running "businesses" on residential
lines; letters supposedly sent to local TV stations and newspapers; letters
to the Provost Marshals of military bases and military SysOps' commanding
officers suggesting they be reprimanded for their "illegal and fraudulent
activities"; the anonymous letters of some months ago suggesting that it
was impossible and risky to run a BBS no matter how responsible the SysOp
might be; and other actions whose apparent aim is to cause diffculty (both
personal and legal) and strife in the BBS community here.

I say it has to stop!

I've been approached by several local SysOps who have been told by others
that I have the "straight dope" on the situation. I don't; but from each
person I've spoken to I've learned more, and I know enough now to have a
pretty good grasp of the situation. I also have my suspicions as to who has
been waging this campaign, but nothing I can prove as yet. It's a safe bet
(I think) that it's someone within the BBS community, either a current or
former SysOp.

A lot of ill will, misinformation, and fear has been spread by this person
or persons, and outside forces are also coming into play. You're probably
aware that in many cases the "outside world" considers us all unprincipled,
lawless "hackers" -- stories in the Star-Bulletin recently have only
confirmed this view with their emphasis on BBSes used to further "kiddie
porn" and unlawful access to credit companies, banks, telephone companies,
and classified government information.

It's time for Hawaiian SysOps to band together to communicate with each
other and to begin policing our ranks from internally before someone from
the outside, with little understanding of what it is to be a SysOp, does it
for us.

To this end, the two of us and some other SysOps we are friendly with are
working to organize "HISS" -- the Hawaiian Islands SysOp Society.
Membership in HISS will be open to any Hawaiian SysOp with a BBS currently
active; whether commercial or hobby, public or private. HISS will give a
chance to meet fellow SysOps, talk, get to know each other and hopefully be
able to be prepared if another troublemaker tries his/her tricks. Our best
weapon is our strength as a group and communication in that group, and we
haven't made much of an effort to utilize that weapon. Ironic, isn't it,
when the purpose of BBSes is to facilitate communication?

Right now, HISS is just a handful of us working as a sort of "board of
directors" to get it off the ground. As such, I haven't much to report on
our progress. Our first board meeting will be early this week, and we'll
try to hammer out a few rough guidelines -- meeting dates, times, location,
all the niggling details of getting a large group of people together. We
will do our best to keep you informed of our progress.

To this end, I would appreciate it if you could set up an account on your
system for us to communicate with you. It needs to only have email or
feedback privileges so that we may leave messages to you. Use the account
name of HISS (if a last name is necessary, as it is on our TBBS system,
use a period) with the password of "grumpy". You may also contact us via
The Restaurant at (808) 499-1101 (24 hours, 3-2400 baud), where we have set
up an account for visiting Sysops under the name of "Visiting SysOp", pass-
word "howdy" (all lower case, TBBS considers lower case different from upper
case). Look under the Bulletin Board menu for "The Lounge" which is our
visiting SysOp message base. All updates and details will be posted there.
We may also be contacted voice at (808) 499-3158 between 10am and 10pm.

Thanks for your attention and we hope to see you at the first meeting of
HISS in the very near future.

                        Toni
               ------------------------------------------

To this end, an account has been setup on my site, Pro-pac, to facilitate
mail from the 'net' at large on this subject.  If you have any comments on
this, or would like to learn more about the results of this situation as
they develop, please send mail to hiss@pro-pac.CTS.COM and it will be
forwarded to the appropriate people.  Thanks for the soapbox, and any
support you may provide.
                                          Todd South

UUCP: {nosc, ihnp4, cacilj, sdcsvax, hplabs!hp-sdd, sun!ihnp4}
                           ...!crash!pnet01!pro-simasd!pro-pac!tsouth
ARPA: crash!pnet01!pro-simasd!pro-pac!tsouth@nosc.MIL   
INET: tsouth@pro-pac.CTS.COM - BITNET: pro-pac.UUCP!tsouth@PSUVAX1

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.82.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.84.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-31</DOCNO>
<DOCOLDNO>IA012-000129-B045-482</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.84.html 128.240.150.127 19970217021255 text/html 30052
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:11:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 84</TITLE>
<LINK REL="Prev" HREF="/Risks/6.83.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.85.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.83.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.85.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 84</H1>
<H2>  Monday 16 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Friday the 13th, Part N 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  'Jerusalem Virus' Bet Ends in a Draw; May 13th... 
</A>
<DD>
<A HREF="#subj2.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Risks in timestamps ... 
</A>
<DD>
<A HREF="#subj3.1">
Ken Barr
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Lost homework due to the computer 
</A>
<DD>
<A HREF="#subj4.1">
David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Chicago Phone Fire 
</A>
<DD>
<A HREF="#subj5.1">
PGN
</A><br>
<A HREF="#subj5.2">
 James M. Boyle quoting Christine Winter
</A><br>
<A HREF="#subj5.3">
     Paul Czarnecki
</A><br>
<A HREF="#subj5.4">
 Patrick A. Townson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Friday the 13th, Part N
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Mon 16 May 88 13:34:05-PDT
</i><PRE>

A few comments are in order on Friday the 13th, Part One and Only for 1988.

That this incident was a rumor rather than a real threat is not important.  It
did have some basis in truth -- even if only a faint glimmer.  The rumor might
have had its roots in an actual bug discovered in a test version of a test
version of Sun 4.0 on the Sun 4/110.  That bug had nothing in particular to do
with a time-bomb, and was just a garden-variety bug.  As the rumor spread, the
bug was transmogrified into a virus on all 4.0 machines, and later into a virus
in all releases back to 1.4.  But throughout, it seems there never were was any
real theat of Friday the 13th Sun spot activity, and that there never was a
time bomb.  All in all, it is my impression that Sun behaved admirably
throughout the incident, and took the entire incident with great seriousness.

There are some important lessons to be learned.

 * In our electronic age it is possible for rumors to span the networld
   within an incredibly short time.

 * The risks of such a rumor are enormous.  Entire companies could be
   threatened by a well-placed and partially founded but credible rumor.

 * Computer-network security problems (e.g., Trojan horses and viruses) 
   are intrinsic.  They are not going to go away, although better computer
   systems and networks will help a little.  

 * Simplistic solutions are vulnerable.  They may be even more dangerous
   than NO solutions if they lull people into a false sense of security.

 * Although it was probably very painful for Sun, this was in retrospect a
   valuable exercise, a little like a fire-drill but sufficiently
   indistinguishable from the real thing that people had to react as if it were
   real.  How many times have you heard people saying that they were going to
   keep backups (perhaps even off-site) of everything, but had not yet gotten
   around to it because nothing had ever happened before...  But don't get me
   wrong -- I'm not recommending this kind of fire-drill.

[By the way, recall that the ORIGINAL Friday the 13th ("Jerusalem") virus was
NOT a rumor.  See the next message.]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
'Jerusalem Virus' Bet Ends in a Draw [See <A HREF="/Risks/6.62.html">RISKS-6.62</A>]; May 13th...
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:nsc!taux01!taux01.UUCP!amos@Sun.COM ">
nsc!taux01!taux01.UUCP!amos@Sun.COM 
</A>&gt;
</address>
<i>
13 May 88 12:02:03 GMT
</i><PRE>

A 10,000 shekel (about $6000) bet between Israeli virus hunters ended in a
draw this week. The bet, started during a live TV interview, was between Yuval
Rekhavi of the Hebrew U. of Jerusalem (discoverer of the first
'jerusalem Virus'), and Ofer Akhituv of Iris Software Ltd. (which sells an
innoculation program to that virus).  Mr. Rekhavi claimed to have written a
program that can alert against the presence of any virus on a PC (IBM or
clone), while Mr. Akhituv had bet that such a program is impossible.

The bet was decided this week by two arbitrators, Dr. Israel Spiegler and Mr.
Ran Giladi, of Tel-Aviv University. While it was evident that none of the
viruses provided by Iris Software could evade detection by Mr. Rekhavi's
program, the arbitrators stated that the cycle of improvments in viruses and
detection program is infinite, so detection of all viruses, present and
future, is impossible; therefore they concluded that the bet is a draw.

The original 'Jerusalem Virus' is due to set off today, May 13. I doubt it'll
cause much damage, since it has a bug that causes each infected program to
grow by about 1000 bytes each time it is run. Any disk that has not been
sanitized by now, has probably run out of space.

Amos Shapir, National Semiconductor (Israel)
6 Maskit st. P.O.B. 3007, Herzlia 46104, Israel  Tel. +972 52 522261
amos%taux01@nsc.com  34 48 E / 32 10 N

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re:  Risks in timestamps ...
</A>
</H3>
<address>
Ken Barr
&lt;<A HREF="mailto:calma!barr@ucbvax.Berkeley.EDU ">
calma!barr@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Fri, 13 May 88 10:05:33 pdt
</i><PRE>

In RISKS DIGEST 6.81, 
Subject: Risks in timestamps (postmarks)

&gt;At &lt;major post office&gt; in &lt;major city&gt; where I used to live, it was a
&gt;regular practice to stay open until midnight, April 15 to allow the
&gt;filing of last-minute tax forms.  These forms would be taken by postal
&gt;employees at drive-up booths.  One year, a housemate happened to
&gt;notice that his form, dropped off at ~8 PM was stamped "11:59PM". [...]
&gt;--Alan Wexelblat  UUCP: {harvard, gatech, pyramid, &amp;c.}!sally!im4u!milano!wex

Here's an even better example of posible timestamp abuse, from "Linn's Stamp 
News", May 9. 1988, page 3 (Editor's Choice column, by guest ed Ken Lawrence)

"If you haven't filed your 1987 income tax return yet, it's not too late to
get it postmarked before the April 15 deadline.  That's because the Postal 
Service has granted very generous grace periods for servicing first-day covers
of recent stamps.  All three non-denominated E stamps were released without
prior warning on March 22.  Collectors have until May 21 to submit envelopes
franked with these stamps to receive first day cancels.  [... Other stamps
which may still receive pre-April 15 postmarks deleted ...]  The last possible
date for late-filing taxpayers to get a pre-April 15 postmark is June 11, the
deadline for submitting FDC's of the 8.4c non-profit-rate stamped envelope, 
whose first day was April 11."	

If anyone is interested in the details, please e-mail me directly for info.
Basically, you have to buy the stamps/envelopes from your local Post Office and
mail them to the First Day of Issue city or the USPS headquarters in Virginia.
They will be *delighted* to back-date the cancellations to the FDOI date ...

Disclaimer:  I don't know *what* the IRS can/would do about this pseudo-legal
"timestamping" ... and I don't intend to find out ...

Ken Barr		{ucbvax,sun}!calma!barr	
Calma Company		calma!barr@ucbvax.ARPA

Disclaimer:  Calma lets me use their computers and their mailstops.  Unless 
	     policy has changed, my opinions should not be considered as gospel.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: lost homework due to the computer
</A>
</H3>
<address>
David Sherman
&lt;<A HREF="mailto:lsuc!dave@unix.SRI.COM ">
lsuc!dave@unix.SRI.COM 
</A>&gt;
</address>
<i>
15 May 88 02:03:35 EDT (Sun)
</i><PRE>

I had to use that excuse back in 1976-77, when I was an undergraduate taking
language courses at U of Toronto.  Being a UNIX hacker, I used to typeset my
assignments on a Versatec plotter, using nroff (this was v6, before troff)
and various fonts for French, German and Hebrew.  When the Sanford Fleming
building caught fire in February 1977, I had two assignments due that day
that I hadn't yet run off.  The professors involved accepted my explanation,
and in fact the CRF lab housng the PDP-11/45 wasn't damaged, so I was able
to get the assignments out a few days later.

I'm sure others remember that fire.  My textbooks smelled of smoke for months.

David Sherman

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Chicago Phone Mess Disrupts Businesses Across the Country [<A HREF="/Risks/6.82.html">RISKS-6.82</A>]
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Mon 16 May 88 13:27:30-PDT
</i><PRE>

  Chicago (L.A. Times)
    All day last Friday, bankers trooped to an unmarked car inn a secret
  location in the western suburbs of Chicago to transfer millions of dollars
  over a car phone.  The car contained officials from the Federal Reserve
  Bank of Chicago, and the operation, carried out under the watchful eye of
  local police at the undisclosed suburban city, was just one of the
  resourceful ways people here are coping with a telephone disaster of
  unprecedented proportions.

  ... the impact on businesses has been devastating.  And the scope of the
  problems raises questions about the emergency plans in place in other
  major business centers to handle similar disasters.

  One business that had prepared for disaster was Bekins, the household moving
  company that is based in Glendale, Calif., but has its dispatch operations in
  Hillside, Ill.  [They set up temporary dispatch headquarters in Glendale.]...
  
  For the 80 to 100 banks located in the affected area, ... 300 automated
  teller machines were out of commission...

[FS Chron, 16 May 1988.]

There are important implications of this case for the RISKS community.  Thus
we also include the following messages, despite some duplication...

</PRE>
<HR><H3><A NAME="subj5.2">
More on Chicago Telephone Fire
</A>
</H3>
<address>
&lt;<A HREF="mailto:boyle%antares@anl-mcs.arpa">
boyle%antares@anl-mcs.arpa
</A>&gt;
</address>
<i>
Wed, 11 May 88 13:20:38 CDT
</i><PRE>

The problem with telephone service in the Chicago area was much more serious
than I was aware of at the time of my original posting.  Non-local telephone
service was cut off for customers in an approximately 500 square mile area from
the Wisconsin border to Kankakee, and from Aurora to the Chicago city limits.
Among these was the FAA Air Traffic Control Center in Aurora, which lost all
its land lines to O'Hare and Midway airports [no redundancy there!], causing
delays of an hour or more.  Directory assistance was unavailable over most of
the state.  [James M. Boyle]

    [James sent in a lengthy article, "WHEN HUB IS HIT, EVERYONE IS HURT", 
    by Christine Winter, Chicago Tribune, 11 May 1988, from which I have 
    excerpted even more heavily than he did.  PGN]

"The goal behind running lines from a large number of Illinois Bell central
offices through one major superoffice, called a "hub," is to provide security
and flexibility, especially in times of emergency.  [Well, perhaps they need to
evaluate whether the goal is served by the means! JMB]

"But when an emergency occurs at the hub itself, the repercussions are more
like tidal waves than ripples.  On Sunday night, when a major fire struck
Bell's hub in Hinsdale [Ill.], those tidal waves hit the western suburbs [of
Chicago].

[...Explanation of the "hub" concept.]

"A diagram of the concept would look like a wagon wheel, with the hub office in
the cnter.  Of course, customers know nothing of all this--until the hub burns
down.  [I'll say amen! to that.  From my experience with computer networks, I
had assumed that there were all sorts of alternate paths.  JMB]

"'Normally, we feel really secure with the hub concept, because most of the
problems occur out in the field when somebody digs up a fiber-optic cable,'
said Neal Cox, director of engineering for Ametitech Mobile Communications.
Ameritech Mobile used Hinsdale as its major `link to the world' for its
cellular telephone network.

[...  Explanation of fiber-optic cables.]

"`Under a centralized setup like this, when a fiber-optic cable is damaged,
there is an enormous amount of flexibility, because so many cables come into
the hub that they can just reroute all the traffic,' Cox said.  "But who whould
have guessed the hub would burn down?"  [Ahh..., who indeed! I'm sure a
terrorist would never think of such a thing.  JMB]

[... Paragraphs about the fire damage to equipment.]

"The central processor suffered only minimal damage Sunday, and its software
was largely undamaged, so its computer operations are largely unaffected.
[You've gotta watch that software! It goes quickly in a fire...  JMB]

[... Paragraphs about a second switch in La Grange doing 98% of its operations
through the Hinsdale office, and attempts to reconnect them by microwave.]

"`This is about the worst place a disaster like this could have happened,
except for the downtown [Chicago] office.' Richards said.

"He said it would be `possible, but not practical' to have backup capabilities.
"`It would mean a duplication of all our cabling and all this equipment,' he
said, pointing to the rows and rows of metal frames, many of the first floor
singed and blackened, which hold the electronic circuitry.  [This reasoning
seems specious.  There would be some duplication, but not complete duplication.
Wouldn't distributed function, stealing cycles in many switches, be much, much
more reliable?  Perhaps he means that the economics of high-bandwidth
fiber-optic cables weigh against duplication.  JMB]

"Illinois Bell spokeswoman Pat Montgomery said only that the costs of getting
service restored, while substantial, would not be recovered through rate
increases.  [Hmmm, that's a relief! But I wonder about the lawsuits...  JMB]

</PRE>
<HR><H3><A NAME="subj5.3">
Re: The Great Fire
</A>
</H3>
<address>
Paul Czarnecki
&lt;<A HREF="mailto:ames!ll-xn!munsell!pz@spam.istc.sri.com ">
ames!ll-xn!munsell!pz@spam.istc.sri.com 
</A>&gt;
</address>
<i>
Fri, 13 May 88 10:52:45 EDT
</i><PRE>

&gt; and a few began a process known as an emergency telephone tree,
&gt; calling other employees and company management at home to notify
&gt; them of the circumstances.  Each employee thus notified was
&gt; responsible for calling a few more employees. 

Does anyone else find it suprising that a telephone company's emergency
handling policy includes use of the telephone?  It sounds like you are just
asking for trouble.
         			           pZ

Paul Czarnecki {{harvard,ll-xn}!adelie,{decvax,allegra}!encore}!munsell!pz

    [Telephone systems work fine on batteries during power failures.
    That is a more commonplace "emergency".  PGN]

</PRE>
<HR><H3><A NAME="subj5.4">
Questions We Aren't Supposed To Ask About Hinsdale
</A>
</H3>
<address>
&lt;<A HREF="mailto:portal!cup.portal.com!Patrick_A_Townson@Sun.COM">
portal!cup.portal.com!Patrick_A_Townson@Sun.COM
</A>&gt;
</address>
<i>
Sat May 14 16:20:12 1988
</i><PRE>

First, an update: On Friday, Jim Eibel, Vice President of Operations for
Illinois Bell announced the company was abandoning efforts to save the
water/fire damaged switch at Hinsdale. The old switch was a #1 ESS; the new
one will be a #5 ESS. They estimate 14 days of round the clock work will be
required to bring it up.

For about 21,000 of the 35,000 customers effected, limited service will resume
on May 15, gradually phased in during the evening and overnight hours. Most
network services for the Chicago area have been resumed in part, and will be
largely restored by May 15. The network will remain somewhat crippled for
another 2-3 weeks, pending complete installation of the new switch. Several
more emergency communication centers have been set up in the west suburban
area, bringing the total to eight locations where the public can go to make
calls. Complete rehabilitation is expected by mid-June.

The grim news though, is that Illinois Bell is avoiding discussion of the
'40 to 60 minute delay' in calling the Fire Department, which probably
caused the loss of the switch, and contributed to what is now openly being
called 'the worst disaster in telephone history'.

We now have this timetable of events for Sunday, May 8 --

At 3:50 PM, a technician in a Bell central office in Springfield, IL got a
fire alarm trip signal from Hinsdale. *HE CHOSE TO IGNORE THE ALARM TRIP*.
Within a period of 10 minutes, several more alarms from Hinsdale tripped,
including one for a loss of power.

Shortly after 4:00 PM, the technician called the weekend duty supervisor for
the area to ask what was going on. The duty supervisor agreed to check it
out, and drove to 120 North Lincoln Street in Hinsdale. When asked why a
technician in Springfield had to notify a supervisor for Hinsdale, Jim Eibel
responded that *THE HINSDALE OFFICE IS TOTALLY UNATTENDED ON WEEKENDS*.

This was in direct contradiction to earlier reports from Bell saying that
personnel 'on duty' discovered the fire and tried to extinguish it. *There
were no personnel on duty.*

The duty supervisor checked the building and found the fire. It is unclear
at this point if the supervisor attempted to fight the fire or returned to
a safe area of the building to call the Fire Department. In any event, the
supervisor found all the phones dead. There was no way to call the Fire
Department. Community residents we have talked to believe the phone circuits
in town had *ALREADY CEASED TO OPERATE 10-15 MINUTES EARLIER*.

At this point, now about 4:15 PM, being unable to call the Fire Department
on the phone, the supervisor leaned outside the front door of the building
and asked a passer by to please call the Fire Department. Apparently the
passer by did not call; but let us be generous and assume the person tried
to call from the payphone down the block on Lincoln. Finding that phone dead
also -- and why not? -- the person probably dismissed the matter, was
bewildered and went on about their business. Let's be that generous, anyway.

After about ten minutes, nearing 4:30 PM, when no Fire Department had
arrived, the supervisor flagged a motorist driving past, and urged that
person to go for help. Apparently that person went to the police nearby and
got help on the way. A little past 4:30 PM, the first firefighters were on
the scene. *Earlier reports, for which the media is probably to blame and
not Illinois Bell, say the fire started 'about 5:30 PM'.

So a fire starts sometime in the afternoon, maybe 3:30-3:45. By 3:50 the fire
has becoming sufficiently severe that heat/smoke sensors go off. We don't
really know the *exact minute* it started -- just that depending on the
sensitivity of the alarms, either a minute or two or several minutes passed
before a technician downstate got the message.

There were *NO SPRINKLERS OR OTHER AUTOMATIC FIRE FIGHTING DEVICES IN THE
BUILDING*. According to Jim Eibel, they don't use sprinklers for the same
reason they don't like firemen with water: the switch can be, and was
damaged.

So a fire burns at some degree of intensity or another for around an hour
before firemen even start working on it -- and this comes to light only
when Illinois Bell is pressured by the [Chicago Sun Times] to explain how
the matter could have gotten so far out of control.

Here are some questions for Jim Eibel and others in the hierarchy at Illinois
Bell to answer. I doubt you will hear them discussed or the answers given on
the Illinois Bell Communicator for obvious reasons --

1. Why did the technician in Springfield at first ignore the fire alarm?
   What does a fire alarm mean, if it does not mean a fire is going on?

2. When the person in Springfield finally was moved to call a supervisor
   in the area to see what it was all about, why were no emergency authorites
   notified at that time?

   Why didn't s/he call the Hinsdale Fire Department -- the phones may have
   still been working then! -- or the police, or *some authority in the
   the community * and tell them, 'we [may] have a serious problem. Please
   send the fire department to 120 N. Lincoln. I have a supervisor on the
   way to meet them and let them in the building.' Why? Had the weekend duty
   supervisor and the fire department and their police escorts all landed on
   location somewhere around 4:00 PM, the damage would have been greatly
   minimized.

3. Why no personnel on duty on weekends? Not even a watchman or a single
   clerk? Here sits a multi-million dollar hunk of electronic equipment,
   very sophisticated in nature, and not one person to brouse around from
   time to time in the course of the afternoon?

   It didn't have to be a fire! It could have been vandals. It could have
   been a dissident employee. It could have been a broken water pipe. It
   seems incredible Bell would essentially abandon its property in this
   way, out of some false sense of economy.

4. Was the lack of personnel -- even one person -- part of the same school
   of thought called 'economics in running a central office' which says to
   put all your eggs in one basket? Why was Hinsdale doing all these jobs
   for the area? Anyone should have the foresight to see that now and then
   the bottom falls out of the basket and all the eggs get broken.

    Is it really 'too expensive' to distribute the traffic over a few more
    offices instead of stacking everything in one big center? I'm not
    suggesting a full complement of services/features in every office, but
    a little more judicious distribution in the future. And if nothing else,
    a watchman, technician, clerk *or someone* to be on the premises at all
    times day and night.

    Many's the time such a person would sit and do nothing. Last Sunday I
    dare say they'd have earned their salary many times over. Can you imagine
    the difference it would have made if someone on site around 3:30-3:45 PM
    or whenever it was all that hell came down had been able to grab some
    halon, a celluar phone, walk into the switch and start spraying? And on
    the phone, getting people into the office immediatly?

    I guess that doesn't fit into the economics of running a switch!

5.  Finally, why no fire protection system in place? Admittedly, automatic
    water sprinklers are *not* the thing to use overhead in a central office
    switch. But why not halon piped in?

    Halon *can* be disseminated through overhead plumbing the same as water.
    When the firefighters went in the building, they took halon because they
    knew what they were dealing with. They only gave up on using the halon
    when the fire got so far out of control that halon was no longer effective.

    When that fire alarm tripped in Springfield, why didn't overhead halon
    jets start releasing their gas? It would have made short work of a fire
    at that point in time! And had there been halon extinquishers about the
    premises, a weekend duty *clerk* -- note please! on premises person! --
    could have used them also. But what did Jim Eibel say? Well...it just
    didn't fit into that sacrosanct economy. Neither does the forced purchase
    of a new switch, Mr. Eibel.
6.  Finally, a question for the duty supervisor last Sunday --
    When you found the phones were all dead, why didn't YOU immediatly go
    and get help? Why not jump in your car, drive 90 miles an hour if you
    could, flash your lights, honk your horn, scream and holler at the top
    of your lungs or otherwise find a policeman somewhere, and tell him
    'we need help now, and we need it bad.'

    Admittedly you wanted to stay there and protect the system and do what
    you could on your own, but trained firefighters could have made very
    good use of the ten minutes or so you wasted trying to find someone to
    turn in the alarm.

I began this report thinking I would conclude it by calling for the resignation
or firing of James Eibel and the two or three people directly reporting to him
who could have prevented last Sunday's disaster by proper planning. Now I am
not so sure. Perhaps Mr. Eibel has a very good explanation for how one of
the main switchers for northern Illinois could be left unattended; and a
worker in Springfield could ignore a fire alarm; and an employee responding
locally could have been not properly trained -- all at the same time.

Maybe Mr. Eibel has very good answers, and hopefully it will not take a
bit of arm twisting by the Illinois Commerce Commission and the newspapers
to get his reponse. But if Illinois Bell *even considers* the notion of
recouping their loss on this fire through the rate base -- as opposed to
the stock holders -- then my feeling is Eibel and employees reporting to
him *HAVE GOT TO GO*.

Its not as though a check for twenty five million dollars could be written
today and all would be well tomorrow. And twenty five million is a *very
low estimate* of the cost of the fiasco. The new switch alone is estimated
to cost about sixteen million dollars. Although Eibel refused to discuss
the cost of the switch, purchased on an emergency basis from American
Telephone and Telegraph, we've done some comparative shopping, if you will,
with other vendors/suppliers making similar equipment. The best we could
find was about sixteen million dollars -- for the switch alone. That does
not of course include peripheral equipment, overtime salaries to workers,
the cost of repairing the building or the month of lost revenue from the
thousands of subscribers without service.

And what of hardship to residents and businesses? What of restitution to the
community? Eibel pointed out that the affected subscribers would recieve
'a credit on their bill for the time service was out....but it is not our
corporate policy to go further...'

I have to agree with him there. There is no constitutional right to phone
service. No one should become dependent on it. Still, the fact remains that
eight telemarketing firms are closed for the duration; their employees told
to stay home. Spiegel's Catalog is closed with many employees laid off. A
major insurance claims processing center is without phone service. Numerous
travel agencies are shut. Bank ATM systems are down. Restaurants and
theatres cannot accept reservations. Credit approvals for purchases made
with plastic are jeopardized.

No, we should not have ever come to the place we are *this dependent* on a
pair of wires attached to a microphone and earpiece. But likewise, Bell must
share some of the blame. The 'economy of running a central office' espoused
by Mr. Eibel and associates caused a needless delay in resolving a serious
problem. That 40 minute delay probably cost them their switch and has caused
considerable economic hardship to west suburban Chicago.

If Eibel and his associates have an answer, perhaps they will share it with
us. Many, many dedicated people are working their hearts out to bring back
the service from a disruption that might well have been avoided. Fires cannot
be avoided. 40 minute delays *can be*.

I've been a supporter of Bell and most of its corporate policy for many, many
years. Right now, I am disgusted to think of how slipshod some of its
operations have become.
                                        Patrick Townson

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.83.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.85.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-32</DOCNO>
<DOCOLDNO>IA012-000129-B045-506</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.85.html 128.240.150.127 19970217021311 text/html 27919
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:11:36 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 85</TITLE>
<LINK REL="Prev" HREF="/Risks/6.84.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.86.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.84.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.86.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 85</H1>
<H2>  Monday 16 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Don't always assume the computer is wrong [elevator control] 
</A>
<DD>
<A HREF="#subj1.1">
Greg Kable
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Warning: Trojan turkey program 
</A>
<DD>
<A HREF="#subj2.1">
Doug Fouts via Tim Morgan and Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Program Trading 
</A>
<DD>
<A HREF="#subj3.1">
Vint Cerf
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Metallic Helium Balloons 
</A>
<DD>
<A HREF="#subj4.1">
Steven McBride
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A320 update 
</A>
<DD>
<A HREF="#subj5.1">
Robert Dorsett
</A><br>
<A HREF="#subj5.2">
 Franklin Anthes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Navigation 
</A>
<DD>
<A HREF="#subj6.1">
Robert Dorsett
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Don't always assume the computer is wrong [elevator control computer]
</A>
</H3>
<address>
Greg Kable
&lt;<A HREF="mailto:munnari!ubo.oz.au!gregk@uunet.UU.NET ">
munnari!ubo.oz.au!gregk@uunet.UU.NET 
</A>&gt;
</address>
<i>
Sun, 15 May 88 17:19:58 EST
</i><PRE>

I recently heard of an interesting risk associated with people ignoring
(apparently) invalid results because they assume the computer displaying them
is broken.  The State Bank building in Sydney has lifts (elevators) which
announce (with a North American accent) the current floor and lift direction
each time the door opens.  They also have a strip display above the door
showing the date, time of day, temperature and such.

While travelling to an appointment in this building, a friend noticed that
according to the display the temperature was 63 degrees Celsius (about 145
Fahrenhieit).  He naturally assumed this was some sort of error and ignored it.

However when he went to leave the building fifteen minutes later, he found that
the lifts were out of order due to a fire in the control room.  So if you are
ever in one of these lifts and the temperature display is a bit high, please
notify the building management in case it's on fire.

Greg Kable
Honeywell Bull Australia	ACSnet: gregk@ubo.honeywell.oz
124 Walker St,			UUCP: uunet!munnari!ubo.honeywell.oz.au!gregk
Nth Sydney, NSW, 2060		Phone: (02) 9239549

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Warning: Trojan turkey program
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy%cf13.ics.uci.edu@ICS.UCI.EDU">
nancy%cf13.ics.uci.edu@ICS.UCI.EDU
</A>&gt;
</address>
<i>
Thu, 12 May 88 19:20:43 -0700
</i><PRE>

  To: ICS@ruby-falls.ICS.UCI.EDU
  Subject: Warning!
  Date: Thu, 12 May 88 13:07:21 -0700
  From: Tim Morgan &lt;morgan@ruby-falls.ICS.UCI.EDU&gt;

  Everyone should be aware of the program described in the following
  message.  We don't want to have to restore any files for anyone...

    Date: Tue, 10 May 88 12:48:16 PDT
    From: Doug Fouts &lt;fouts%krypton@hub.ucsb.edu&gt;
    To: jwills@venera.isi.edu
    Subject: EMAIL WARNING

    I have just been informed by a friend of mine here at U.C.S.B. that there
    is a program being passed around via ARPAnet (and also some other computer
    networks) that is called "turkey".  The instructions that are sent with the
    program say that when compiled and run the program will draw a nice picture
    of a turkey.  I have been informed that the program is a (not very funny)
    joke.  It does not draw a turkey, but it does erase all of the unprotected
    files in your directory.  You might want to pass this information along to
    people you know who use the network, as I am doing.
                                                              Doug Fouts

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Program Trading
</A>
</H3>
<address>
&lt;<A HREF="mailto:CERF@A.ISI.EDU">
CERF@A.ISI.EDU
</A>&gt;
</address>
<i>
14 May 1988 06:12-EDT
</i><PRE>

Do RISKS Forum readers have anything to say about the following thought on
program trading:

The stock market is a closed-loop feedback control system. Prices fluctuate
based on the demand for stock or desire to sell it. The introduction of
computer-based trading which makes decisions on a very short time-scale,
introduces into the system a very rapid response time. In other feedback
control systems, it is necessary to introduce damping to avoid wild
oscillations, when you have a very fast response mechanism. The present stock
market automation system, including the program trading facilities, appears to
offer no damping at all. Is it legitimate to conclude that the system is an
example of an undamped feedback control and therefore prone to wildly
oscillatory behavior? Would some form of damping (limits on maximum stock value
excurions as a percentage of stock value, for instance) serve as an adequate
damper?

I am not a control theoretician, so my thought may simply be naive analogical
reasoning - I am prepared to be educated on the point.
                                                                Vint

    [Program trading has been considered in <A HREF="/Risks/5.44.html">RISKS-5.44</A>, 5-52, 5-70, 6.1,
    6.11, and 6.37.   There were some earlier discussions on stable feedback
    loops.  Perhaps someone will venture a definitive response... PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Metallic Helium Balloons
</A>
</H3>
<address>
Steven McBride 
&lt;<A HREF="mailto:shamus@BOEING.COM">
shamus@BOEING.COM
</A>&gt;
</address>
<i>
Wed, 11 May 88 13:05:07 pdt
</i><PRE>

A Boeing Company Renton Division Safety Alert:

SOARING PROBLEM: METALLIC HELIUM BALLOONS CAN CAUSE POWER OUTAGES.

Metallic helium balloons -- popular gifts during holidays, birthdays
and other special events -- are no longer allowed on Boeing sites
because of the severe damage they can cause to electric power lines.

The problem is that the balloons are often coated with one-1,000th of
an inch of aluminum, which makes an excellent conductor of electricity.
When a stray metallic balloon comes in contact with power lines, it can
cause electricity to arc between transformers and sometimes cause live
wires to fall to the ground threatening the safety of bystanders. In
Antioch, California, last year, a balloon caused a 12-hour blackout in
which a power surge fried the wires of microwave ovens, videocassette
recorders and television sets.

A power outage encompassing the entire Renton complex occurred February
9th when a metallic helium balloon touched a 55,000-volt power line
west of the 10-50 building. A similar unscheduled power outage occurred
last year when a metallic balloon came in contact with a power line
north of the 10-50 building.

Because of the serious and costly nature of the problem, no metallic
balloons of any kind will be allowed on a Boeing site for any reason.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
A320 update
</A>
</H3>
<address>
Robert Dorsett
&lt;<A HREF="mailto:mentat@huey.cc.utexas.edu ">
mentat@huey.cc.utexas.edu 
</A>&gt;
</address>
<i>
Sat, 14 May 88 23:19:38 CDT
</i><PRE>

There is a good article on several manufacturers' attitudes toward aircraft
avionics in the April 16 issue of "Flight International."  Airbus currently
feels that the test of fly-by-wire is in maintenance, rather than operational
reliability.  They have multi-level redundancy on many systems, and enforced
strong separation of design teams for the redundant equipment.  They used
different manufacturers for each level of redundancy, and made sure that
there were no common members of the software development teams.  Nonetheless,
Airbus indicated that the airplane would have faced far stiffer certification
without the manual backup on the horizontal stabilizer and rudder (which,
ironically, crews are not being trained to use--despite a complete system
failure during testing).

A rather interesting portion of the article suggests that Boeing, in its
never ending quest to cut equipment weights, is considering getting rid of
many antiquated analog and digital computers--which provide a de facto
high degree of redundancy in a distributed computing environment--and re-
placing many of the systems with a single high-speed computer.  This should
cause interesting problems.  

An earlier reader indicated that there was a lawsuit being conducted in England
to stop the A320 from being utilized by British Airways.  Apparently the
suit failed.  British Airways accepted its first A320 a couple of weeks ago, 
and should be starting route service about now.  BA itself was quite concerned
about the cockpit design, and apparently put the airplane through extensive
testing.  Information that I have suggests they don't really like the air-
plane, but can't get out of their commitments.

On another front, a more recent issue of "Flight International" suggests that
one reason for the A320's popularity with short-haul operators is that
Boeing was sluggish in releasing the 737-400, a large-capacity short-range
transport (with a glass cockpit, but manual controls).  As a consequence, 
Lufthansa is replacing all of its 727's with A320's, and plans on replacing 
its DC-10's with A340's for cockpit commonality.  It is also planning on 
replacing all of its 747-200's with 747-400's, the all-glass, fly-by-wire 747.

Robert Dorsett, University of TX at Austin  Internet: mentat@walt.cc.utexas.edu
UUCP:{ihnp4, allegra,decvax}!ut-emx!walt.cc.utexas.edu!mentat

</PRE>
<HR><H3><A NAME="subj5.2">
Airbus 320 (Re: <A HREF="/Risks/6.76.html">RISKS-6.76</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:mcvax!geocub!anthes@uunet.UU.NET">
mcvax!geocub!anthes@uunet.UU.NET
</A>&gt;
</address>
<i>
Mon, 9 May 88 17:45:48 +0200
</i><PRE>
Organization: Greco de programmation, Bordeaux France

A couple of details on the AirBus A320

Excerpts from an article published in the May issue of "Sciences &amp; Vie Micro"
(translated from the French original)

  When taking the plane [the A320], what is the probability that it will crash
  due to a software error? One chance in a million? Wrong! One chance in a
  billion and that for each hour of flight.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Navigation
</A>
</H3>
<address>
Robert Dorsett
&lt;<A HREF="mailto:mentat@huey.cc.utexas.edu ">
mentat@huey.cc.utexas.edu 
</A>&gt;
</address>
<i>
Sat, 14 May 88 23:21:47 CDT
</i><PRE>

In reference to my earlier post on KAL 007, I should also point out that it has
been suggested (in Hirsh's book, if memory serves) that if the original
airplane waypoint (the start position on the ground, waypoint 0) is entered
incorrectly, the entire course will be translated somewhat.  For this to occur,
the start position would have to be entered in intermix mode (BIG no-no), and
the INS's would have had to have been shut down before the flight.  This is a
very important number, needless to say, and a traditionally high importance has
been assigned to its entry.  It isn't a "casual entry."  Even if it should be
entered in intermix mode, both the captain and first officer should cross-check
it.  There is the possibility, though, that it could be derived from a map,
written down incorrectly, then entered properly--but from bad data.  In this
case, the cross- check wouldn't produce any "errors."  However, I do not
remember any major gripes reported about the KAL flight by ATC or other
authorities, which should have come up if this had happened, since the airplane
would have been off course practically from the minute it started its enroute
climb.

Another reader sent me email asking me to detail manual navigation alternatives
to automation.  That wasn't exactly my point in the post.  There doesn't seem
to be any alternative to computer-augmented systems, both from reliability and
safety standpoints.  Rather, I'm concerned about the way they are supposed to
be used by their human operators.  The current trend is to assign the pilot a
caretaker role, on the assumption that (a) the systems will never fail, and (b)
that the pilot is a manager of systems.  Unfortunately (a) isn't true, and (b)
relegates the human pilot to the role of observer, which can produce operator
errors (largely out of boredom or apathy) or render him incapable to intervene
in the aircraft's welfare if a bona fide emergency should develop (as the China
Airlines flipover three years ago demonstrated).

But to answer the question (which may be of academic interest to the readers),
here are the main navigational aids and techniques which have been developed
over the years:

I.  Techniques:

a.  Dead reckoning.  Assumes the pilot keeps track of airspeed and has some
knowledge of the winds.  The relevant instruments are a magnetic compass,
airspeed indicator, a clock, and accurate weather information.  An altimeter
would also be handy at higher altitudes.  Dead reckoning requires the pilot to
be very much in the aircraft "loop."  It is used with a variety of other
techniques these days.

b.  Pilotage.  In this mode, the pilot flies by reference to the ground.
Traditionally, it's flying by reference to ground features, but the definition
can be extended to incorporate ground-based radio navigation aids.

As one might guess from the rest of this article, we are moving away from
pilotage and back towards dead reckoning as a primary means of flight--with the
exception that it is all automated and the pilot is largely out of the loop.


II.  Airborne systems:

1.  ADF.  Automatic direction finding.  A ground-based navigational aid
(really, any source of electromagnetic radiation) "beams" undirected
electromagnetic radiation.  The instrument on the airplane which interprets the
information appears as a needle with some sort of azimuth reference.  On most
light airplanes, the ADF indicator is a fixed card with markings from 0 to 359
degrees.  The aircraft heading is *always* 0 degrees; the card demonstrates a
relative offset. For example, if the airplane is pointed due south (180
degrees) and has an ADF bearing of 350 degrees, the navaid's magnetic bearing
is 170 degrees.

As technology improved, during the 50's a flux-gate gyro compass was installed
in many larger airplanes.  Essentially, this looked like the fixed ADF card,
except it *moved*, and provided precise compass bearings.  It did not suffer
from the usual gyro precession problems, due to the fact that it automatically
recalibrated itself.  ADF needles were installed on it (usually two) and thus
provided an easy-to-read, precise synopsis of both the airplane's heading and
the exact magnetic bearing of the selected navigational aids.  It removed one
level of computation from the pilot, but this is generally considered a Good
Thing; the old system was rather kludgy.

The ADF/flux-gate gyro compass is commonly called a Radio-Magnetic Indicator, 
or RMI.

ADF systems generally have a limited range, due to the HF frequencies used.
50-75 miles tops, often quite less.  They were also susceptible to atmospheric
problems, such as thunderstorms.

In modern navigation, the ADF equipment is almost exclusively used in executing
approaches in homing onto marker beacons.


2.  VOR.  Variable omnirange.  A VOR is another ground-based aid, but
one which works with aircraft on-board systems to provide an illusion
of a "compass rose" emanating from the station.  For example, if the 
airplane is exactly south of the station, and has a bearing of 0 degrees 
to it, it will be receiving the 180 radial.  But that information pertains 
to the airplane relative to the position to the station, and not the 
airplane attitude itself: the airplane can be pointed in any direction 
whatsoever and still receive the 180 radial.  

VOR range is dependent on the slant range of the airplane to the navaid.  VOR's
use the very high frequency (VHF) band range (108.00 to 119.95 MhZ) and do not
suffer any deterioration in performance due to atmospheric conditions.  An
airplane flying at, say, 39,000 feet would be able to detect a station (with
sufficient broadcasting power) 300 nautical miles away.

VOR's provide the standard method of navigation.  Four methods have been
developed to use this information:

a.  The first was the course deviation indicator (CDI).  This displays
information on how far away the airplane is from an arbitrary selected radial.
The "distance" information is in degrees of arc.  It is neccessary to have some
way of specifying the desired radial.

To clarify this, the system detects which radial the airplane is currently
on, then calculates (mechanically) the offset to the desired radial.  

b.  Next complex is the VOR equivalent of the ADF RMI. This has the same 
moving compass card, the same one or two needles, but instead of pointing 
to VOR bearings, the needles indicate the radial the airplane is on.  The 
tail of each needle indicates the radial, while the head indicates
		(radial + head) mod 360
No additional "selecting" hardware is necessary: the VOR indicator
is totally self-contained.  Apart from selecting the station frequency, the 
pilot need do nothing.

c.  The Horizontal Situation Indicator (HSI) combines the flux-gate compass
with the CDI indicator.  The CDI is mounted in the center of the instrument;
the gyro card moves around it.

The HSI is the central navigation instrument on nearly every jetliner.
It has replaced the CDI entirely.  In addition to basic navigation 
information, the controls which set the CDI can also be used to provide
inputs to the autopilot.  There is a "bug" (pointer) which indicates 
desired heading; this rotates around the compass card.  The desired course 
(the desired radial from/to the VOR station) can also be used to make 
the autopilot fly an intercept.

d.  A broad class of CRT navigational displays have come to replace the HSI on
the newest jets.  For the old-timers' sake, most models can be set to operate
as a simple computer-generated HSI. There is also usually a mode which
incorporates the concept of area navigation.  It displays a variety of
supplemental information, such as airplane track, a mini-map of radio aides,
etc.  These devices often take inputs from flight management computers (such as
an INS).  As one pilot recently remarked in a magazine, "I like it because I
don't have to think; the computer does all the work."  Precisely the attitude
we wish to stimulate in our young pilots.  One problem with the newer "area"
modes is that the display formats are not standardized, which can introduce
training and, later, operational difficulties.


3.  Inertial Navigation Systems (INS's) made their entry in the late
60's and early 70's, first on the 747.  The INS is an on-board system, 
entirely self-contained.  Theoretically, an INS fits the definition
of a dead reckoning aid.  It is networked with most of the other computers 
on board, and derives its own airspeed information, position data, etc., 
and generates a wide variety of information ranging from ground speed to 
wind speed and direction.  It's a neat gadget, and the provided features
are indispensible for trans-oceanic flight.

Common airline practice these days is to fly a flight with the INS.
The waypoints along the flight path are entered prior to departure,
and the INS is used to drive the autopilot.  Pilots are expected to
use the VOR indicators for a fast, convenient verification that it's
working like it's supposed to.  INS waypoints are normally indicated
on high-altitude maps, and it's fairly easy to verify that one is where
one is supposed to be by cross checking.


4.  Distance Measuring Equipment.  DME is sort of like a transponder
system, and provides slant range distance data between the airplane
and a ground station by interacting with the ground station.  Nowadays, 
most DME stations are collocated with VOR stations, either as VORTACs 
(a military concept) or as two distinct units.  


5.  Astral navigation.  On older airplanes, such as the 707 and some 727's, a
port on the cockpit ceiling was used to provide the navigator (a position which
no longer exists) the ability to determine the airplane's latitude from the
stars.  Needless to say, this required a fairly high degree of training and was
somewhat prone to errors.  Not many people mourne the passing of the
navigators; they pretty much disappeared by the mid-70's.  It was cheaper to
buy an INS (or several) to take their place.


6.  Doppler.  Doppler was an airplane-based navigation system intended
to provide a realistic idea of airplane true airspeed and drift while 
flying over water.  This was then used with dead reckoning and astral 
navigation to figure out where the airplane is and get it to its destination 
safely.  This method is not used anymore, either, although the equipment 
is still installed on many airplanes.


7.  LORAN.  Loran was originally a navigation system intended for 
commercial shipping.  The receiver synchronizes very long frequency radio 
emmissions from a handful of transmitting sites to determine an approximate 
idea of its location. Most current units also have additional features.  
Loran is very, very inexpensive, ranging from $600 on up.  LORAN is commonly
installed on light aircraft, or as a backup system on corporate aircraft
or airliners.


8.  Omega.  Omega was a neat idea that never caught on in a big way.
Most Omega units use information from Omega/VLF stations scattered
around the planet to calculate a variety of statistical data, including 
the approximate airplane position.  Most Omega units include the ability 
to conduct area navigation and commonly have a better-defined database
capability than most INS units.  Omega installations are more expensive
than LORAN installations, and are commonly found on business jets or, 
more rarely, as backup systems on airliners.


9.  Flight performance systems.

There are two general classes of flight performance computers available.  Most
of these systems are installed in more recent airliners and incorporate a wide
variety of features.  In general, the distinction is whether they can drive the
autopilot; if they can, it's probable that they have their own inertial
navigation system.

Flight performance systems exist to squeeze the last dollar out of an
airplane's flight; they were developed at a time when fuel was more expensive,
but are retained due to efficiency considerations.  There is, theoretically,
very limited wastage.  Whereas the older INS systems flew an airplane on a
two-dimensional course, FMS's can be used to set a *three-dimensional* flight
path, from right after takeoff to pattern entry (or even landing) at the
destination airport.  When coupled with the autopilot and autothrottle (an
autothrottle is a computer-controlled throttle system; until the A320, there
was a manual override for it), they can fly the airplane more efficiently and
more precisely than the human pilots.

Flight International reports that NASA's Langely Research division is
developing a four-dimensional flight performance computer, capable of
conducting a flight within five seconds of accuracy on 50 n.m.  segments.  As
one might guess, such a system would have to be tied into ATC and available on
most other aircraft to avoid traffic congestion problems.
 
The question now becomes: what're the pilots supposed to be doing?  
The answer?  "Managing."  Not an entirely satisfying one, at that.


Now, you may ask: "What're they using on my next flight?"

707: Probably two INS's.  HSI, ADF and VOR indicators with the RMI cards.
Primitive autopilot.  Maybe a left-over Doppler, but it won't be used on the
flight.

727: Possibly two INS's, probably not.  HSI, primitive autopilot, ADF and VOR
indicators with the RMI cards.  Maybe a leftover Doppler system.

737: No INS's, HSI, ADF and VOR indicators with the RMI cards.  Primitive
autopilot.  On later -200's and -300's, a flight management system.  Perhaps
glass CRT displays, but nothing revolutionary.

747: Three INS's, HSI, ADF and VOR indicators with the RMI cards.  Nicely
designed autopilot.  There may be one flight performance computer.  With the
747-400, the INS's will be merged with the flight performance computers and the
traditional HSI, ADF, and VOR indicators will disappear to be replaced by CRT
displays with an unproven (in terms of human interaction) design.

757, 767: The first generation of airliners with glass cockpits.  Each
pilot's flight director (artificial horizon) and HSI is replaced by 
a CRT screen.  The HSI has the HSI/area navigation mode option.  The 
airspeed, altitude, vertical speed guages bracket the CRT's.  There are
also two engine diagnostic displays on the center panel.

DC-9: Pretty much the same equipment as on the 737.

MD-8X: pretty much the same as the 737-300.

DC-10: more or less the same as the 747.

MD-11: pretty much the same as the 747-400.
 
Robert Dorsett, University of TX at Austin  Internet: mentat@walt.cc.utexas.edu
  UUCP:{ihnp4, allegra,decvax}!ut-emx!walt.cc.utexas.edu!mentat

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.84.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.86.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-33</DOCNO>
<DOCOLDNO>IA012-000129-B046-21</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.86.html 128.240.150.127 19970217021328 text/html 21319
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:11:52 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 86</TITLE>
<LINK REL="Prev" HREF="/Risks/6.85.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.87.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.85.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.87.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 86</H1>
<H2>  Wednesday 18 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
$70 million computer fraud attempt 
</A>
<DD>
<A HREF="#subj1.1">
Werner Uhrig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  DeutschApple Virus Alerts 
</A>
<DD>
<A HREF="#subj2.1">
Otto Stolz via Vin McLellan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Market stability 
</A>
<DD>
<A HREF="#subj3.1">
Martin Ewing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Matching Dormant Accounts 
</A>
<DD>
<A HREF="#subj4.1">
STEYP-MT
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Risky academic software development 
</A>
<DD>
<A HREF="#subj5.1">
Woody
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  AIRBUS 
</A>
<DD>
<A HREF="#subj6.1">
Steve Philipson
</A><br>
<A HREF="#subj6.2">
 Henry Spencer
</A><br>
<A HREF="#subj6.3">
 Mark Mandel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Navigation and KAL 007 
</A>
<DD>
<A HREF="#subj7.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
				 
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
The RISKS Forum is moderated.  Contributions should be relevant, sound, in good
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
taste, objective, coherent, concise, nonrepetitious.  Diversity is welcome. 
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
Contributions to RISKS@CSL.SRI.COM, Requests to RISKS-Request@CSL.SRI.COM.
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  For Vol i issue j, ftp kl.sri.com, get stripe:&lt;risks&gt;risks-i.j ... .
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj13">
  Volume summaries in (i, max j) = (1,46),(2,57),(3,92),(4,97),
</A>
<DD>
<A HREF="#subj13.1">
5
</A><br>
<A HREF="#subj13.2">
85
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
$70 million computer fraud attempt 
</A>
</H3>
<address>
Werner Uhrig 
&lt;<A HREF="mailto:werner@rascal.ics.utexas.edu">
werner@rascal.ics.utexas.edu
</A>&gt;
</address>
<i>
Tue, 17 May 1988 19:35:14 CDT
</i><PRE>

I think it was Dan Rather who in tonight's prime-time news reported on a $70
million embezzlement attempt at First National Bank of Chicago.

An employee used "International Network Computer Links" for a "wire transfer
to a bank in NY".  The system used was "CHIPS" and the matter seems to have
been noticed yesterday when "Merrill Lynch discovered a discrepancy".

    [Apparently there was collusion involving at least four people.
    The amount evidently exceeded a threshold, but they were able to
    control the telephone response that requested overage authorization.    
    They were caught apparently only because the amount blew ML's account!
    Watch your favorite news sources.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
DeutschApple Virus Alerts
</A>
</H3>
<address>
"Vin McLellan" 
&lt;<A HREF="mailto:SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
SIDNEY.G.VIN%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Wed 18 May 88 01:50:24-EDT
</i><PRE>

German Virus Alert: RELAYED FROM VIRUS-L @ Lehigh U.

A Special Warning of Three Infected MAC programs

From: Otto Stolz +49 7531 88 2645 
&lt;RZOTTO%DKNKURZ1.BITNET@MITVMA.MIT.EDU!U&gt;

Hello,

A couple of minutes ago, I run into a letter dated 21th March 1988, that
was circulated by a Software Distributing House in southern Germany to
their customers.  I will not post their name or address to this list; if
somebody really needs it, please drop my a note, privately.

As I don't have access to a MacIntosh, I can't assess the importance the
message might bear to MacIntosh users; so I deemed it best posting it in
this list for anybody who might be concerned.  As none of the programs
below is mentioned in the DIRTY DOZEN, somebody (Ken Van Wyk?) should
forward this note to Eric Newhouse whose BITNET address is unknown to me.

Following is the main part  of this letter (translated into English):

&gt; Subject: MacIntosh Virus!!!
&gt;
&gt; Regrettably, also MacIntosh has been befallen by some virus, meanwhile.
&gt; Please do *not* use any of the following programs:
&gt;      Pre-Release PageMaker 3.0
&gt;      Pre-Release HyperCard German
&gt;      Pre-Release Multifinder German
&gt;
&gt; *Beware:* Virus spreads through networks (e.g. AppleTalk)!!!
&gt;
&gt; Symptoms: Difficulties when using the Hard Disk, even to the amount
&gt;           of completely loosing the Hard Disk.

Best regards
              Otto Stolz

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Market stability
</A>
</H3>
<address>
Martin Ewing
&lt;<A HREF="mailto:msesys@DEImos.Caltech.Edu ">
msesys@DEImos.Caltech.Edu 
</A>&gt;
</address>
<i>
Tue, 17 May 88 13:54:05 PDT
</i><PRE>

In connection with program trading and stock market volatility, Vint at
CERF@A.ISI.EDU asks "Would some form of damping (limits on maximum stock value
excurions as a percentage of stock value, for instance) serve as an adequate
damper?"  Herewith, an inquiring but non-authoritative submission. 

I note that a number of proposals for controlling the market involve setting
limits.  For example, the Brady Commission's "circuit breaker" would stop
various kinds of trading once the marked dropped by N points.  In control
terms, these set constraints on the system, but they are not "damping".
Damping requires a lossy device of some kind, a dashpot. 

One sort of damping would be a transaction tax that is a function of market
rate of change, "tic" figure, or some such.  I.e., if you want to trade in a
crashing market, it will cost you more than on a quiet day.  Another tactic
would be to make delayed trades cheaper than prompt trades; this would
particularly discourage program trading. 

Savings and loan institutions provide another example.  Since the Feds insure
all deposits, a failing S&amp;L will attract many investors with offers of
above-market interest rates - while other banks have trouble obtaining
deposits at prudent rates.  To avoid "financial runaway", we need another
damper.  For example, if I were only insured for the first 80% of my balance,
I'd probably make a better choice of S&amp;L. 

I don't recall ever seeing an "engineering" discussion on stability of
financial markets, can anyone point to one?  (I have, however, talked with
economists who could derive Hamiltonian Equations for the economy.  Mind
your p's and q's.)

Martin Ewing  mse@caltech.edu

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Matching Dormant Accounts
</A>
</H3>
<address>
STEYP-MT Materiel Test Dir 
&lt;<A HREF="mailto:steypmt@yuma.arpa">
steypmt@yuma.arpa
</A>&gt;
</address>
<i>
Tue, 17 May 88 15:35:59 MDT
</i><PRE>

Extracted without comment from:
Federal Register, 53:90 (10 May 1988); p. 16577-8

Defense Logistics Agency

Privacy Act of 1974; Notice of a Proposed New Ongoing Computer Matching Program
Between the Department of Defense and Financial Institutions to Preclude
Escheatment of Individual Accounts Under State Laws

... "Send any comments or inquiries to: Mr. Robert J. Brandewie, Deputy
Director, Defense Manpower Data Center, 550 Camino El Estero, Suite 200,
Monterey, CA 93940-3231.  Commercial phone number: (408) 646-2951; Autovon:
878-2951.

"For further information contact: Mr. Aurelio Nepa, Jr., Staff Director,
Defense Privacy Office, 400 Army Navy Drive, Room 205, Arlington, VA
22202-2803.  Telephone: (202) 694-3027; Autovon: 224-3027.

"The Defense Manpower Data Center... is willing under written agreement to
assist individual financial institutions to be a matching agency for the
purpose of providing up-to-date home or work addresses of persons of record of
abandoned money or other personal property subject to escheatment laws.  The
computer matching will be performed at the Defense Manpower Data Center in
Monterey, CA using records supplied on computer tape by the financial
institutions and the DoD employment records of both military and civilian
personnel, active and retired.  The match will be accomplished using the social
security number.

Matching records will be returned to the financial institution, the activity
responsible for reviewing the matching data and for assuring that the account
owner receives proper notification and due process before any adverse action is
taken on the abandoned property...."

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Risky academic software development
</A>
</H3>
<address>
Woody
&lt;<A HREF="mailto:<WWEAVER%DREW.BITNET@CUNYVM.CUNY.EDU> ">
&lt;WWEAVER%DREW.BITNET@CUNYVM.CUNY.EDU&gt; 
</A>&gt;
</address>
<i>
Tue, 17 May 88 15:22 EDT
</i><PRE>

I think this verges on the RISKy.  In the MARCH/APRIL 1988 issue of _ACADEMIC_
_COMPUTING_ subtitled "Covering Computer Use In Higher Education" there is
an article on page 30 by Dennis J. Moberg of Santa Clara University.  The
article is titled "The Last Hurdle: Some Lessons For Software Developers Who
Plan To Market Their Product With Academic Publishers".  Column 2, paragraph
3 and 4 are

    We decided it was really time for us to put a proposal together, so that's
  what we did.  We got stuck, though, on two scores.  First, we were reluctant
  to send out the prototype of ur product for fear that some reviewer
  somewhere would rip us off.  Perhaps we were cynical about the level of
  ethics in the academic community about software copying, but were worried
  that someone somewhere would copy our disks and immediately start using them
  with their students without permission.  Obviously, every publisher needs
  to have prototypes reviewed, so we found ourselves vulnerable.  Ultimately,
  we decided to plant a worm in the software that allowed reviewers only
  four boots.  That trick gave us the peace of mind to go on.
    Lesson 2.  [in red]  If you are worried about protecting your software
  from being stolen by unscrupulous reviewers, plant a worm in it.  [in bold]

The risks I see here are philosophical ones to the academic community.  My
first reaction was one of outrage: that an academic, writing to the
non-technical community, would suggest that developers "plant a worm" in their
software.  In boldface type, yet.  It reeks of the developer who put a worm in
a business spreadsheet (was it an old version of Lotus?) that if it detected
that its copy protection had been broken destroyed all the data files it could
find.  I don't want anyone intentionally writing trojan programs, especially in
an academic environment.

The second one is the risk we have let turn into a real problem: by condoning
software piracy at the academic level, we have created an atmosphere where
developers do not feel safe about their product.  This means that packages are
not being written because developers don't feel there will be a profit in it.

What can be done about this?  I certainly want to write a letter to Dennis
J. Moberg of Santa Clara University and discuss alternatives to worms.  But
what can the academic community as a whole and the computing community in
particular do to abate this problem?
                                                         woody

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
AIRBUS [<A HREF="/Risks/6.85.html">RISKS-6.85</A>]
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Tue, 17 May 88 11:48:42 PDT
</i><PRE>

RE: Robert Dorsett (mentat@huey.cc.utexas.edu) writes: 	[on the Airbus A-320]
   reliability.  They have multi-level redundancy on many systems, and enforced
   strong separation of design teams for the redundant equipment.  They used
   different manufacturers for each level of redundancy, and made sure that
   there were no common members of the software development teams.  ...

How interesting.  This approach sounds rather like using random algorithms
to generate a sequence of random numbers.  One would think that the best
approach to redundancy would be to design the redundant systems with
detailed knowledge of how the primary system works.  One would endeavor to
make the backup systems as different as possible from the known primary
systems, not use any common assumptions (as much as that's possible), and
not use common software/hardware.  If the approach reported is actually how
the systems were developed, there is no guarantee that the systems do have
common assumptions, algorithms, etc., and thus have common failure modes.

I think I'll try to schedule my flights to avoid the A-320 for awhile.

RE: mcvax!geocub!anthes@uunet.UU.NET writes: ["Sciences &amp; Vie Micro"]

   When taking the plane [the A320], what is the probability that it will crash
   due to a software error? One chance in a million? Wrong! One chance in a
   billion and that for each hour of flight.

One of our defense ministers had a similar comment about a major military
system (can't remember if it was the B1 or SDI).  A reader pointed out that
even an ANVIL doesn't have that high a level of reliability.  Happy flying!

And again, Robert Dorsett (mentat@huey.cc.utexas.edu) makes an excellent
contribution on the various flight navigation systems.  I have a few
"nit picks" that I hope will not detract from this text-book quality summary.

   As one might guess from the rest of this article, we are moving away from
   pilotage and back towards dead reckoning as a primary means of flight--with
   the exception that it is all automated and the pilot is largely out of the 
   loop.

Well, not quite.  Modern systems incorporate inertial navigation equipment
which is far more accurate than simple dead reckoning.  INS systems do
internalize navigation functions to the aircraft, but systems accept external
input for recalibration on a frequent basis. (Robert does mention this later.)

</PRE>
<HR><H3><A NAME="subj6.2">
A320 update
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 18 May 88 14:47:11 EDT
</i><PRE>

&gt; ... British Airways accepted its first A320 a couple of weeks ago...
&gt; Information that I have suggests they don't really like the air-
&gt; plane, but can't get out of their commitments.

This seems unlikely, since Airbus Industrie's A320 order backlog is the
biggest in jet-airliner history, and they would jump at the chance to
take back some early delivery slots from an unhappy customer, in hopes
of using them to hook some happy customers.  Flight International reports
that Airbus told BA so, in so many words, and BA has been much more
positive about the A320 since.  For the piece of glitch-plagued junk that
some people claim the A320 is, it is selling awesomely well.

Henry Spencer @ U of Toronto Zoology   {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<HR><H3><A NAME="subj6.3">
 Airbus 320: risks of translation
</A>
</H3>
<address>
Mark Mandel 
&lt;<A HREF="mailto:Mandel@BCO-MULTICS.ARPA">
Mandel@BCO-MULTICS.ARPA
</A>&gt;
</address>
<i>
Wed, 18 May 88 10:10 EDT
</i><PRE>

RISKS DIGEST 6.85 includes a brief excerpt translated from the
French-language "Sciences &amp; Vie Micro" referring to chances of a crash
due to a software error:
  "One chance in a million?  Wrong!  One chance in a billion and that
   for each hour of flight!"

I haven't seen the original, but note well that the French "billion" =
the USA "trillion" (10**12).  The British, with whom we think we share a
language, also call it a "billion".  Our USA "billion" (10**9) is a
French "milliard".  I suppose this makes an argument for using
scientific notation, rather than words, for all large numbers.

((My employer, Honeywell Bull, Inc., is not responsible for anything I
think, say, do, or eat.))

 [Early RISKS were inundated with milliard canards.  This problem is
 destined to haunt us forever unless we can say thousand million, 
 million million, or use the international standard!   PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Navigation and KAL 007
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Tue, 17 May 88 12:07:18 EDT
</i><PRE>
From: Joe Morris (jcmorris@mitre.arpa)

In RISKS 6:85, Robert Dorsett discounts the possibility of the KAL 007 flight
having been off-course due to an error in the data entry of its initial
airport co-ordinates:

&gt;                                                        However, I do not
&gt; remember any major gripes reported about the KAL flight by ATC or other
&gt; authorities, which should have come up if this had happened, since the
&gt; airplane would have been off course practically from the minute it started
&gt; its enroute climb.

Not really.  I don't have any experience flying in Alaskan territory or the
adjacent international waters, but I would expect that westbound flights
would be routed over the normal radionavigation fixes until there are
no more within usable range, and only then would the flight be cleared for
do-it-yourself navigation.  The INS would not be used until the last station
was passed, so the path which could be seen by ground stations would match
the clearance.  Given the long baseline for the overwater leg where the
INS is used, the error in the course set (incorrectly) by the autopilot
could have been invisible to the long-range radar screens.

If the crew instructed the autopilot to fly to the (far-away and incorrect)
waypoint directly instead of telling it to fly the proper route, it would be
possible for the crew to fail to recognize the problem.  They might have
dismissed the right-of-anticipated-bearing situation as representing a strong
unforcast wind from the north.  If the autopilot had been set to follow
the planned route then the pilot's instruments would have indicated an
extreme left-of-course situation; a fly-to-defined-point command probably
showed an on-course condition since the airplane would be doing exactly
what it was told, and had no reason to display an error warning.

One potential RISK here is in the analysis: the flight followed its planned
path while under radar surveillance, but since we don't know when the
pilot began using the INS and its suspect data we can't say for sure what
part the INS played in the tragedy.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.85.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.87.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-34</DOCNO>
<DOCOLDNO>IA012-000129-B046-54</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.87.html 128.240.150.127 19970217021344 text/html 21830
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:12:09 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 87</TITLE>
<LINK REL="Prev" HREF="/Risks/6.86.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.88.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.86.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.88.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 87</H1>
<H2>  Thursday 19 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Stock Market Damping 
</A>
<DD>
<A HREF="#subj1.1">
Richard A. Cowan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Bankwire fraud 
</A>
<DD>
<A HREF="#subj2.1">
Steve Bellovin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Metallic Balloons 
</A>
<DD>
<A HREF="#subj3.1">
Keith Anderson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  BENEFITS! of RISKS 
</A>
<DD>
<A HREF="#subj4.1">
John Kullmann
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  IRS mismatching and other computing anomalies 
</A>
<DD>
<A HREF="#subj5.1">
John M. Sullivan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Why technicians wait to respond to alarms 
</A>
<DD>
<A HREF="#subj6.1">
Lynn Gazis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Illinois Bell Hinsdale fire 
</A>
<DD>
<A HREF="#subj7.1">
Ted Kekatos
</A><br>
<A HREF="#subj7.2">
 Ed Nilges
</A><br>
<A HREF="#subj7.3">
 David Lesher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of Ignoring Alarms 
</A>
<DD>
<A HREF="#subj8.1">
Daniel P Faigin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Halon environmental impact citation 
</A>
<DD>
<A HREF="#subj9.1">
Anita Gould
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Stock Market Damping
</A>
</H3>
<address>
Richard A. Cowan 
&lt;<A HREF="mailto:COWAN@XX.LCS.MIT.EDU">
COWAN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Wed 18 May 88 20:43:44-EDT
</i><PRE>

  Regarding the recent message about the Stock Market as a feedback system:

  If you think about it, it's easy to devise a damper on the frenzied
  stock market trading system.  If there are too many trades causing
wild swings in the market, caused partly by our ability today to handle
a huge volume of trades because we have computers, all you have to do
is increase the cost of this type of trading.

  Of course, if you aren't rich you don't want to have to pay even
higher commissions.  So you could implement a progressive "tax" on
usage of the market trading system.  But this would be difficult
to enforce without changing the entire structure of the "free
market" system.  Right now, seats on the exchange are purchased
for a flat fee (the going rate is $850,000) and I don't know if
there is any type of usage fee.  In the same way that the law 
has historically treated waterways and land, ownership gives
you the right to use *and* abuse, where polluting the environment
is analogous to overloading trades in the stock market.

  A potentially more enforceable mechanism is to tax short-term
profits (capital gains) at a higher rate than long-term gains.
I'm not sure (someone correct me on this), but I think the recent
tax reform equalized the two rates, which were previously different.
This makes no sense for market stability, as the old system at
least provided some incentive to hold on to stocks for 6 months
or more, or whatever period is considered "long-term."

  An obstacle with either solution is that people who have seats
on the exchange profit greatly from the commissions and other
business activity generated by a high stock market volume.  The
economy as a whole would probably function fine with one-tenth
the stock market volume we have today.  But you have an army
of people fighting to gain that extra 0.01% return on their
investments and they are legally bound to do this (this is the
meaning of "fiduciary responsiblity").

  Any alternative solutions or comments on my solutions?
                                                                  -rich

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Bankwire fraud (Re: <A HREF="/Risks/6.86.html">RISKS-6.86</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:smb@research.att.com">
smb@research.att.com
</A>&gt;
</address>
<i>
Thu, 19 May 88 11:40:09 EDT
</i><PRE>

An unconfirmed report claims that the embezzlement scheme employed tapes of
bank officers reading code words.  Replay attacks!
                                              		  --Steve Bellovin

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Metallic Balloons
</A>
</H3>
<address>
Keith 'Dain Bramaged' Anderson 
&lt;<A HREF="mailto:KANDERSON%HAMPVMS.BITNET@MITVMA.MIT.EDU">
KANDERSON%HAMPVMS.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 17 May 88 11:05 EST
</i><PRE>

        I understand that those metallic ballons also reflect radar, and play
havoc with airport controller's systems.  I believe that it works on the same
principle as chaff, or "window" (I think that was what it was called), the
stuff they dropped over germany during the war to ruin radar.

Keith Anderson  Kanderson@Hampvms

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
BENEFITS! of RISKS
</A>
</H3>
<address>
John Kullmann 
&lt;<A HREF="mailto:jk@Apple.Com">
jk@Apple.Com
</A>&gt;
</address>
<i>
Tue, 17 May 88 14:18:17 PDT
</i><PRE>

Eugene Miya wrote of an episode with an automatic stamp machine. I would like
to relate one I had when I was in high school, about , well, a while ago.

It involved a dollar bill changer similar (at least externally) to the ones
still in use today. I was second in line for it in the 'rathskeller' of our
high school. After the girl in front of me finished I quickly stuck my bill in,
being in a rush to return to my foosball game, and it popped back out because I
had put it in backwards. Then, immediately following it, out came ANOTHER bill!
Being a quick learner I quickly stuck it in backwards again, out it came, but
no second bill followed.  I then got another bill out of my pocket, stuck one
in the right way, out came the change, stuck the second one in backwards, out
it came, and out came the previous bill!! Well, you can imagine the rest of the
story from here. Many trips up to locker with pockets BULGING with change.  Cut
classes until machine was empty of change.  The next day the machine was
restocked with change but I could never get it to happen again. I never did
learn why that happenned. I bet the person servicing the machine was surprized
when he/she opened it up!
                            --John Kullmann, Apple Computer Inc., Cupertino, CA

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
IRS mismatching and other computing anomalies
</A>
</H3>
<address>
John M. Sullivan
&lt;<A HREF="mailto:jmsulliv@phoenix.Princeton.EDU ">
jmsulliv@phoenix.Princeton.EDU 
</A>&gt;
</address>
<i>
Wed, 18 May 88 00:21:35 edt
</i><PRE>

I recently got a notice from the IRS saying I had underreported some taxes
in 1985.  They of course had mismatched items on the return with 1099's,
so I wrote back to tell them this.  Just the other day I received their
reply, which seemed to be mostly a form letter, but had one paragraph in
all caps which was obviously personalized:

WE HAVE ACCEPTED YOUR EXPLANATION HOWEVER, YOU STILL ARE SUBJECT TO SELF
EMPLOYMENT TAX OF $4220.00 TIMES .11 IS $497.00.

Ignoring the strange punctuation, I quickly noticed the strange math.
I tried my head, pencil and paper, a calculator, and 'bc', and 4220*.11
always came out as 464.20, not the higher figure they gave.

I called the IRS and it turns out that the SE tax rate for 1985 is 11.8%.  So
the $497 is correct, and in fact has been truncated down from $497.96.
Evidently, dollar amounts are truncated (not rounded) to the nearest dollar,
then printed with 2 decimal digits.  Other figures are truncated at 2 decimal
digits for printing (but I bet they won't let you figure your tax that way).

John Sullivan   sullivan@fine.princeton.edu

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Why technicians wait to respond to alarms
</A>
</H3>
<address>
Lynn Gazis 
&lt;<A HREF="mailto:SAPPHO@SRI-NIC.ARPA">
SAPPHO@SRI-NIC.ARPA
</A>&gt;
</address>
<i>
Mon, 16 May 88 20:02:23 PDT
</i><PRE>

I have a few words in defense of the nameless technician who waited ten minutes
to report the fire in Hinsdale.  Ten minutes is not a long time to miss an
alarm.  I work as a computer operator.  Ten minutes is a coffee break.  I could
easily go out, grab a cup of coffee, look at the latest cartoons on someone's
door, come in and see a slew of alarms on my console.  (Two ten minute breaks
are required by law.)  Or I could be off backing up someone's PC.  I doubt that
that technician had nothing to do but monitor a site miles away which hadn't
bothered to hire its own weekend shift.  Often more than one thing breaks down
at once.  Many times I have come in to find three independent problems.  That
technician could easily have been off dealing with some minor emergency while a
major one was going unreported.

I don't think you can even necessarily blame the technician for not calling the
fire department; probably he or she called the supervisor, was told "I'll take
care of it," and hung up assuming everything is in hand.  The supervisor, and
not the technician, should be in trouble for not calling the fire department
immediately.  Any company should have emergency procedures, and those should
involve calling the fire department, not running over to look at it yourself.

If your alarm is a message on a console, and your technician is watching
several things at once, then ten minute is a prompt response.  If you want
better response to your alarms, make the most serious ones noisy.  I doubt that
this alarm was noisy, because if it were, even the least attentive technician
would respond right away, if only to get the thing turned off.  Probably they
had a loud alarm in the empty building, and a message on a terminal in
Springfield as a backup.

Lynn Gazis   sappho@sri-nic.arpa

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
questions about Illinois Bell Hinsdale fire
</A>
</H3>
<address>
Kekatos
&lt;<A HREF="mailto:ihuxv!tedk@moss.att.com ">
ihuxv!tedk@moss.att.com 
</A>&gt;
</address>
<i>
13 May 88 20:30:01 GMT
</i><PRE>
Organization: AT&amp;T Bell Laboratories - Naperville, Illinois

The Great Fire.... continued

Most people have heard about the Illinois Bell "Hinsdale" fire by now. It
has been mentioned on network TV news. Alot of people are asking questions.
These are some of the questions that I have heard.

How can one office have such an affect on the phone network?
What ever happen to redundancy in the network?

How come the local news service still thinks only  35,000  people are
affected?  What about the thousands of businesses that are affected. What
about the hundreds of DATA-COMM links?  All over the western suburbs,
hundreds of Automatic Teller Machines are down.  Hundreds of stores can not
perform credit card approvals.

How come it is taking them many days to do some work arounds on the long
distance network?  Why can't they re-route the long distance calls to other
switches?

How come the fire was not detected before it had so seriously damaged the
switching office?  Is the phone company to cheap to install fire detectors?
I would think that there would at least a sprinkler system.

Hundreds of payphones are affected.

One person related their experience.  "Direct dial calls still
seem to be impossible,   but operator-assisted calls
sometimes work.  I was able to make three long distance calls
with my calling card this afternoon.  I got the "all carrier
circuits are busy.." announcement several times, but did  finally
get the bong tone and completed the calls that I needed to
make."


Another person relates their experience:  "There is no  operator,
no 411, no 911, no long distance, though I was able to make one
call at 2:00 a.m. "

There is a sign at my bank that states: "Due to the 
fire at the Illinois Bell Hinsdale Central office, our computers are
not functioning. Please visit our main office at [bank address]." 

----  Ted G. Kekatos

</PRE>
<HR><H3><A NAME="subj7.2">
     Illinois Bell Fire
</A>
</H3>
<address>
Ed Nilges 
&lt;<A HREF="mailto:EGNILGES@PUCC.Princeton.EDU">
EGNILGES@PUCC.Princeton.EDU
</A>&gt;
</address>
<i>
Wed, 18 May 88 16:07:55 EDT
</i><PRE>

...might be compared to the King's Cross subway fire in London last year;
too few maintenance people in both the Hinsdale office and at King's
Cross owing to a false notion of "economy"...

</PRE>
<HR><H3><A NAME="subj7.3">
Chicago Telephone fire (<A HREF="/Risks/6.84.html">RISKS-6.84</A>)
</A>
</H3>
<address>
David Lesher 
&lt;<A HREF="mailto:ames!wb8foz@cucstud">
ames!wb8foz@cucstud
</A>&gt;
</address>
<i>
Thu, 19 May 88 0:02:08 EDT
</i><PRE>
Organization: Columbia Union College; Takoma Park, MD 20912

Regarding sprinklers and computers, I don't think it is realistic to
rationalize away the lack of sprinklers by saying "We don't want to flood
the computer room".  Many computer rooms are sprinkler equipped.  First,
despite the image the public gets from TV and movies, each (sprinkler) head
trips ITSELF ONLY.  The standard heads are fuse style, but most computer
rooms use thermostatic ones that turn off again when the area cools.  If
your CPU is burning, will a little water do any more damage?  Second, the
switch itself is only part of the space in the building. I recall from the
NY switch fire (1970 +/- 3 db) that one reason for the severe delays in
restoration was the fire consumed the cable vault burnt up to the exit of
the building.  As I recall, MA bought the building next door BEFORE the fire
was out (no small trick in the NYC real estate market) in order to install
the new CO and toll switch.  By the way, even 8 years ago, many CO's were
unmanned even during working hours. Only those with test boards were
staffed.  I think the real message of Hinsdale is failure to learn from the
mistakes of the past.

   [I have quoted Henry Petroski here before -- we never learn from our
   successes, but we have an opportunity to learn from our failures.
   (On the other hand, we probably tend to learn less from other people's 
   failures than from our own...)  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of Ignoring Alarms
</A>
</H3>
<address>
Daniel P Faigin
&lt;<A HREF="mailto:faigin@sm.unisys.com ">
faigin@sm.unisys.com 
</A>&gt;
</address>
<i>
Wed, 18 May 88 08:52:32 PDT
</i><PRE>
Organization: Unisys - System Development Group, Santa Monica

In the latest RISKS-FORUM article on the Hinsdale Illinois Bell fire, I read
the following:

&gt;At 3:50 PM, a technician in a Bell central office in Springfield, IL got a
&gt;fire alarm trip signal from Hinsdale. *HE CHOSE TO IGNORE THE ALARM TRIP*.
&gt;Within a period of 10 minutes, several more alarms from Hinsdale tripped,
&gt;including one for a loss of power.

This made me think back to the First Interstate fire that just happened in
L.A., where one person died because *they didn't believe the alarm, and went
to investigate*.

As more and more of these incidents occur, we get more and more warning
devices.  We now have *electronic* smoke detectors in our homes and at work.
We have humidity sensors for our computers, temperature alarms, pressure and
motion sensors. All of them electronic, all of them driven by our transistor
technology.

As with any alarm system, a certain percentage of alarms are false. With more
alarms, the actual number of false alarms grows. Our society begins to view
the alarms in a manner similar to how the people treated the boy who called
"wolf". We don't believe them. We wait for human confirmation that there
actually is a problem. When there isn't a problem, we are relieved. When
there is, it often turns out (as in Hinsdale and LA), that we are actually
worse off.

In certain industries, such as nuclear and chemical manufacturing/research,
all alarms are treated as real emergencies until proved otherwise. This
includes notifying the authorities.  We too often ignore the alarm and wait
until security tells us there is a real problem. In doing this, we lose
valuable evacuation and containment time.

How many of you have had a smoke detector go off in your building?  What did
*you* do about it?

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Halon environmental impact citation
</A>
</H3>
<address>
Anita Gould 
&lt;<A HREF="mailto:FONER.NITA%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU">
FONER.NITA%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 19 May 1988  02:59 EDT
</i><PRE>

In RISKS 6.79, Dave Cornutt asks about the ozone-depletion risks of the
halon used in fire-fighting.  Science News (9 April 1988, Vol. 133, No. 15)
recently ran a cover story on current usage of halocarbons and the search
for ways to reduce it.  Here are some answers taken from there.

The Montreal Protocol, the international agreement currently under
consideration, would freeze production of halon at 1986 levels.

Yes, halon is unfortunately *very* bad for the ozone layer.  Halon
1301 (CF3Br), used primarily in room-flooding systems, is ten times as
destructive as the more common CFCs used in other applications, while
halon 1211 (CF2BrCl), used in hand-held fire extinguishers, is three
times as destructive as the common ones.

However, halons are used in much smaller quantities.  Of the total 1.1
billion kilograms of halocarbons produced worldwide annually, 14.1 million
(just over 1%) are the halons mentioned above, split evenly between the two
types.  (I'm mixing 1985 and 1986 EPA figures.)  I have no idea to what
extent the amount produced reflects the amount released; particularly in the
case of halons, one may hope that new installations, rather than
steady-state use, are responsible for a significant fraction of the total.

There are currently no good substitutes for halon, but according to SN, they
"are released far more frequently during tests than during fires."  Of
course, failure to conduct tests has risks of its own! I'm sure they can be
minimized by designing equipment to be tested under dry run conditions.
Does anyone know if this is actually being done?  This is a solution I
hesitate to propose, since every point where test conditions deviate from
actual ones is a chance for something to go wrong.  RISKS readers are all to
familiar with the canonical horror story in which the system (be it
hardware, software, human, or what-have-you) works fine during tests, but
the tests fail to simulate actual conditions in some unforseen way.  (Any
guesses on what percentage of incidents reported herein fit this paradigm?)
However, weighing the choices, I believe that this is the best solution
currently available, provided that both designers and users of fire-control
systems go into it with their eyes open.
                                                  -Anita Gould

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.86.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.88.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-35</DOCNO>
<DOCOLDNO>IA012-000129-B046-77</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.88.html 128.240.150.127 19970217021358 text/html 19373
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:12:26 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 88</TITLE>
<LINK REL="Prev" HREF="/Risks/6.87.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.89.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.87.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.89.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 88</H1>
<H2>  Thursday 19 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Soviet Space Shuttle software problem 
</A>
<DD>
<A HREF="#subj1.1">
Tim Shimeall via Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Navigation 
</A>
<DD>
<A HREF="#subj2.1">
Charles Brunow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: moral obligations with security exposures 
</A>
<DD>
<A HREF="#subj3.1">
Rob van Hoboken
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Voter registration records and risks to democracy 
</A>
<DD>
<A HREF="#subj4.1">
Philip E. Agre
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Soviet Space Shuttle software problem
</A>
</H3>
<address>
Tim Shimeall 
&lt;<A HREF="mailto:tim%safety.ics.uci.edu@ICS.UCI.EDU">
tim%safety.ics.uci.edu@ICS.UCI.EDU
</A>&gt;
</address>
<i>
Wed, 18 May 88 15:47:03 -0700
</i><PRE>
(Remailed by Nancy Leveson)

From the Internet SPACE Digest, Volume 8, #224, dated 5/18

In a discussion of the Soviet Space shuttle, Glenn Chapman of the MIT Lincoln
Lab made the following comment:

"    Also for what it is worth it appears now that the first Russian
shuttle flight will be manned with two cosmonauts Igor Volk (Soyuz T12,
July 17, 1984) and Anatoly Levchenko (Soyuz TM-4, Dec. 21, 1987).
Pravda actually had a sketch of their shuttle about a week ago.  They
are still talking about a June flight.  It has been known for some time
that the cosmonaut corps were pushing for a manned first shuttle
mission, and had trained for similar missions.  One could speculate that
the final factors pushing for this was two things.  First it has been      &lt;--
confirmed that the failure in the upper stage of Energiya was due to a     &lt;--
software error which reversed the direction vectors of the stage during    &lt;--
firing, not a failure of the engines or other guidance systems.            &lt;--
Secondly the shuttle autolanding system development has been having some
trouble.  So when your robots fail you substitute humans for tasks
humans have shown abilities to do. "

Interesting, No?
			Tim

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Navigation
</A>
</H3>
<address>
Charles Brunow
&lt;<A HREF="mailto:ames!loci!clb@spam.istc.sri.com ">
ames!loci!clb@spam.istc.sri.com 
</A>&gt;
</address>
<i>
19 May 88 03:24:41 UTC (Thu)
</i><PRE>

The recent posting about "Navigation" by Robert Dorsett exposed a related
RISK. Since it was a tangential topic to his subject, I'd like to pick it
up and describe it in more detail.

My subject is celestial navigation, who knows how to do it, and why should
anyone care. It has been an important skill for thousands of years and
it is directly responsible for the geo-political map of todays world. It has
also proven to be the most useful method on the longest voyage ever made.

The method which I will describe is called "St. Hilaire's" by some, the
"Sumner line" or position line by others. A more complete description
can be found in the "Bowditch" navigation text, which should be in most
libraries. To my knowledge, 1975 was the last year of publication.

The RISK involved with celestial navigation (referred to as "Astral" in
the referenced posting) is that it seems to be a lost art. The list of
navigational aids described by Mr. Dorsett was indeed impressive but
two limitations came to mind as I read it: one, all these methods are
reliant on electricity and two, they aren't available for small private
aircraft, boats, and ground transport.

Why should anyone be concerned by relying on electricity? Clearly the
answer is that it can fail, and if it fails what can you do? Suppose
that you are a frequent flyer, you've accumulated enough miles to take
your family on a trip to Hawaii, and off you go. Further, suppose that
as you cruise over the Pacific, there is a total electrical system
failure. Can it happen? You know it can. What could be done? If the
crew is totally reliant on the instrumentation, you may go swimming.

More important is the point that the high-tech methods are eclipsing
traditional methods to the point that the skill is being lost. I have
posed this question to many people: "how do you know where you are and
how do you know what time it is?" The response has been consistent: a
momentary puzzled look as they search for an answer, and then anger for
the foolish feeling they have. When I first asked myself these questions,
I resolved to find the answers. What I found was a facinating history
of exploring the seas and the land masses, and a story of truly
creative thinking.

The method of celestial navigation is similar to the satellite methods:
starting with an approximate observer position based on "dead reckoning",
successive approximations based on observations improve the estimate.
More specifically, the DR position (and time) are used to compute the
"expected" altitude of a celestial object and this value is compared
to the observed altitude. The difference angle is called the intercept
and represents the amount of correction to apply. The direction of the
correction is along a line between the observer and the object (the
azimuth angle), toward it if observed angle is greater, away if the
computed angle is greater. A second observation, at right angles to the
first is required to really fix the location. Note that, in general,
both longitude and latitude are affected, and the method finds both.
Additional sighting can improve the approximation further, for an
ultimate accuracy of a few hundred meters.

The "trick" in celestial navigation is computing the expected position,
compensating for the motions of the Earth and other effects. The fact
that these methods pre-date computers proves that it can be done.
Military teams like the "Green Berets" included a member trained in
communications and navigation based on equipment that could be carried
on their backs. But computers can also be used to great effect in
celestial navigation. The longest voyage ever made, by spacecraft
which have gone to the "gas giant" planets of our solar system, were
guided by computer based celestial navigation systems. And common
desk-top computers can be "taught" everything needed in a matter of
seconds, by loading the appropriate software/database from a floppy.
For example, a program set that I wrote, the Loci StarDB and Loci
3-Space Calculator, perform a sight reduction from an internal star
database. With this tool, a sextant or astrolab, and a chronometer
or WWV receiver, I can find my location on the Earth, for myself.

You may ask, "if my PC can do the navigation, why do I need to under-
stand it?" The reason is that someone must understand it to write the
software when new applications arise (exploration of Mars ?), there
must be people who understand the process to make the required upgrades
to the software. And if the equipment should fail, only a thorough
understanding will allow the operator to pick up where the hardware
left off. This is similar to the car: you can drive a car without
knowing how to repair it or how it works, but you run a RISK, so
don't forget how to walk.

In addition, the future always holds exploration, at sea or in space.
Robot spacecraft will need navigation software, even if manned missions
don't. The same skills transfer to other disciplines such as astronomy,
satellite defense and graphics. Jobs will be open for "navigators"
though the title will be different (mission specialist, staff engineer,
supreme commander, etc.).

Charles Brunow, mission specialist, communications/navigation  clb@loci.uucp

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     Re: moral obligations with security exposures
</A>
</H3>
<address>
Rob van Hoboken 
&lt;<A HREF="mailto:RCOPROB%HDETUD1.BITNET@CUNYVM.CUNY.EDU">
RCOPROB%HDETUD1.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri, 13 May 88 14:16:15 MET
</i><PRE>

I have found many bugs and/or security exposures in MVS and as such have had
to think up a reaction to such finds.  I have done the following:

1. create a proof for submission to the manufacturer,
2. send in a documented error report to the technical rep. and a high ranking
   management type of the manufacturer.

   When after several weeks nothing has happened:
3. send the above mentioned trouble report to &lt;trusted&gt; colleages in other
   computer centers, and have them submit a similar report to the manufacturer.

I have made a policy of never going &lt;public&gt; with such exposures because of the
seriousness of the situation.  Consider a computing center being faced with
an exposure in one of its key software systems (e.g. their transaction system).
What options do they have?

1. They can not remove the software from their systems, that would lose them
   millions of dollars PER DAY.
2. They could try to hack a fix for the exposure.  Estimated time of success
   several weeks of &lt;highly qualified&gt; syspro work.  Risks of malfunction of
   the entire transaction system, no support from supplier.  No dice.
3. Monitor abuse of the exposure.  Difficult.
4. Contact the supplier, explain the predicament and suggest you go looking for
   a replacement of his product.  Usually successful, but it takes about half a
   year for a security fix to arrive.

I think it is immoral towards colleages in your site and other centers to
publicly announce a security leak.  Even discussing it with too many syspro
types is risky, because one of them may be a blabbermouth and spill the news
to an unfriendly hacker or newspaper type.  It happens to be our reality
that you cannot close down a system on account of a security exposure if
that system is earning you money.  Fixing it is risky and difficult, so
waiting for you friendly supplier is the best you can do.

In this respect IBM has the best policy I know of:  each contract contains a
clause that a security exposure shall be dealt with within a specific time.
I've seen it work and I am impressed.  Of course some sites never apply the
fix, so not everybody will be covered, but that is their risk.  Other
suppliers (on the IBM market) do not have a similar policy.  I know of
several instances where an exposure was not even fixed after three years.
In one case I persuaded some of my friends to remove the product from their
systems and terminate the contract with the supplier.

I don't want to sound too gloomy, but the morally acceptable method will not
always yield results.  The (in my view) immoral way &lt;may&gt; yield long term
results, but in the period between public exposure and fix your systems are
extremely vulnarable to practically every hacker with assembler knowledge.
In no way can you guard against that many possible perpetrators.

The only argument I can come up with to defend a security through ignorance
policy, is the small number of attempts that will be made on your system.
I &lt;may&gt; be better to keep relatively inexperienced hackers unaware of exposures
when knowledgable folks can find out.  In the worst case it will save you
unscheduled IPLs.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Voter registration records and risks to democracy
</A>
</H3>
<address>
Philip E. Agre 
&lt;<A HREF="mailto:Agre@AI.AI.MIT.EDU">
Agre@AI.AI.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 19 May 88 07:50 EDT
</i><PRE>

The following paragraph appears in an article by Alfred Stepan of the
Americas Watch committee (New York Review, June 2nd 1988, p 35) on his
recent visit to Chile to report on human rights and on preparations by
opposition political parties and citizens' groups for the plebiscite on
military rule that is expected sometime in the next year:
  
  An official in charge of running the elections, Ignacio Garcia, told
  me and my Americas Watch colleague Stephen Richard that he would
  release a notarized copy of the registration rolls.  [Commander in
  chief of the Chilean air force] General [Fernando] Matthei went
  further, saying that not only would the registration rolls be
  ``absolutely'' available, but that giving the opposition access to the
  master computer disk on which all voters' names were entered was
  ``crucial'' to a fair plebiscite.  I mentioned these statements by
  government officials in a press conference.  The following day,
  Ricardo Lagos appeared at the elections office with a check and
  unsuccessfully tried to purchase a copy of the registration rolls.
  The list has now been made available, and there is a growing demand
  that the disk be released so that the names on the list can be checked
  against it.  Lagos argues that if the disk is not released, the
  government will be vulnerable to a charge of voter fraud.  However, if
  the disk is released, he and the citizens' free elections committees
  believe it could be used to verify the registration process more
  effectively than was possible either in the Korean presidential
  election or in the election called by Marcos.

It used to be that you could hope to verify something by checking paper
files.  File cabinets full of paper are so clumsy and inert that it is
hard for a government to both operate from day to day and also falsify
its own records in a massive and systematic way.  Nowadays, however,
one can use software and printers to generate an infinite amount of
arbitrarily mendacious paper at minimal expense.  Citizens who would
deter systematic mendacity now need access to the computer records.

If the opposition has computers and technical expertise of its own,
having the registration rolls in machine-readable form might make
whatever checking they can do more efficient.  But what does ``access to
the disk'' mean?  Is Sr. Garcia going to dismount the actual medium and
hand it over to the opposition?  Is he going to spin them a tape copy?
Is he going to let opposition programmers sit at the console of the
election commission computer and rummage around?  Is he going to run a
network cable across Santiago to the opposition headquarters?  In any
case, without effectively complete and continual monitoring of the
computer's software and operations, how can the opposition know that
it's getting the actual registration rolls and not simply the bogus
sources that were used to print the paper listing they've already got?

The idea of the Chilean government owning computers at all is pretty
repulsive.  The same article also reports on the government's new, more
sophisticated methods for inhibiting dissent.  Fewer people disappear
these days.  Instead, people who engage in disapproved political
activity receive a graded series of threats whose administration must
require a formidable database facility.  A typical series might run as
follows (p 32):

  For example, before a kidnapping 1) you receive a phone call at work
  noting with displeasure your involvement in a certain activity; 2) an
  unsigned letter at your home follows, using all three of your legal
  names [a footnote here explains that most Chileans never use their
  full names except on official documents; the letter thus suggests that
  its authors have access to official records]; 3) you get a short
  menacing phone call at home conveying information about your children;
  4) in what appears to be an accident you are knocked to the ground on
  a crowded sidewalk; 5) a decapitated animal is placed on your doorstep
  [the juxtaposition of technology and primitive barbarity is weirdly
  unnerving here]; 6) another phone call -- if you have moved it is
  noted that this move has been observed; 7) you hear a shot in the air
  near your home; 8) you hear an explosion or more often you find an
  explosive nearby that has not gone off; 9) people enter your house and
  tell your husband or wife that the activity you are engaged in is
  dangerous to them and to you and that they should convince you to
  stop; 10) you are kidnapped, interrogated, and released in a day; 11)
  you receive a death threat.

This pattern has become sufficiently institutionalized that a vocabulary
has arisen around it.  Having reached your ``tenth gradation'' of threat
is considered very bad news: disappearances have certainly not stopped.

[...There is indeed an intrinsic problem as to whether the released disk
information was the actual information.  Acceptability of computer records
-- even with cryptoseals, authenticators, or any other digital signature --
is always going to be in question.  Essentially anything can be altered,
spoofed, or forged, given appropriate access.  Even "once-writable" optical
media can be overwritten (albeit asymmetrically)!   "No guarantees"...  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.87.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.89.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-36</DOCNO>
<DOCOLDNO>IA012-000129-B046-91</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.89.html 128.240.150.127 19970217021423 text/html 15879
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:12:39 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 89</TITLE>
<LINK REL="Prev" HREF="/Risks/6.88.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.90.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.88.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.90.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 89</H1>
<H2>  Sunday 22 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computer problems in the Connecticut State Lottery 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Worms in evaluation copies of software 
</A>
<DD>
<A HREF="#subj2.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Comments from the "Bell System" on the Hinsdale Fire 
</A>
<DD>
<A HREF="#subj3.1">
Mike Eastman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Illinois Bell Fire 
</A>
<DD>
<A HREF="#subj4.1">
Bradley W. Dolan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Smoke detectors and electrical equipment 
</A>
<DD>
<A HREF="#subj5.1">
John Bruner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Halon environmental impact citation 
</A>
<DD>
<A HREF="#subj6.1">
Jeffrey R Kell
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computer problems in the Connecticut State Lottery
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
20 May 88 07:52:52 PDT (Friday)
</i><PRE>

The following account is slightly edited from a story by Dennis Hevesi in the
New York Times (Thursday, May 12, 1988, p. 12), with the headline CONNECTICUT
SUSPENDS LOTTERY GAMES.  I don't read the NYTimes every day, so I'm not sure
what has happened since.

On Sunday (May 8), the Connecticut State Lottery went on line with its new
computer system.  But yesterday, with the alarm sounded by two ticket sellers
who knew they weren't entitled to $16,500, the entire system was shut down for
24 hours for repairs.  The problems included the printing of tickets with the
previous day's date, duplication of serial numbers, and malfunctions in the
1,853 computer terminals that have been installed so far.

After 8 p.m. Monday, ticket sales are terminated.  At 8:05, lottery officials
announce on television the day's winning numbers.  One pharmacy owner and one
liquor store owner, friends who both sell lottery tickets played a Lotto number
for Tuesday, May 10.  But the sale was recorded as a Monday sale.  They tried
one of Monday's winning numbers,
and it came out with a Monday, May 9 date.  With a few plays, the total amount
of their winnings was $16,500.  They stopped.

On Tuesday morning, they filled out the forms at the lottery office, and were
given their checks for $6,750.30, after tax.  They then said, "These tickets are
a fraud."  But officials kept saying the tickets were legitimate.  Investigators
were called. "I pointed out there's a big problem with the system.  At first,
they could not believe it.  Then they treated us like criminals.  Now they're
apologizing like crazy.  They did give us back the $6 we spent on the tickets."

The big loser, it may turn out, could be General Instruments Corporation of
Hunt Valley, Md., which was installing lottery terminals in the state under a
five-year, $40-million contract.  "We have a liquidated-damages clause in the
contract, which basically says they replace our losses in case of system
downtime," a lottery official said.  "They're looking at big penalties.  A week
could be over $3 million."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Worms in evaluation copies of software (Woody, <A HREF="/Risks/6.86.html">RISKS-6.86</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Thu, 19 May 88 15:50:55 PDT
</i><PRE>

&gt; The risks I see here are philosophical ones to the academic community. 

There is a tremendous difference between putting protective "worms" in your own
software, and putting in destructive worms or trojan horses.  The developer is
justified in protecting his software from unauthorized use.  There is nothing
unethical in using a security measure that only restricts use of the protected
code or makes that software non-functional if misuse is detected.  It is not
reasonable to include code to inflict damage on an unauthorized user as
retribution or revenge.  The later is also poor business practice, as such code
might destroy data belonging to a legitimate user.  This will certainly hurt
sales, and possibly subject the vendor to legal liability.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Comments from the "Bell System"
</A>
</H3>
<address>
Mike Eastman
&lt;<A HREF="mailto:ihuxz!mfe@moss.att.com ">
ihuxz!mfe@moss.att.com 
</A>&gt;
</address>
<i>
18 May 88 23:06:59 GMT
</i><PRE>
Organization: AT&amp;T Bell Laboratories - Naperville, Illinois

"boyle" posted an article in <A HREF="/Risks/6.81.html">RISKS-6.81</A> indicating surprise that the Hinsdale
office did not have alternate trunking or redundancy.
The poster wanted comments from THE BELL SYSTEM.

As of Jan 1, 1984 the Bell System was abolished when the Justice Dept had AT&amp;T
officially divest itself of the local operating companies. At that time, seven
NEW regional independent Bell holding companies began operating.

This was a RISK that was thrust upon the public. That risk being seven
independent local operating companies and many more long distance companies
working together to provide one cohesive telephone network with the same
objectives in mind as before divestiture - guaranteed phone service to the
public.

As to alternate trunking policy, AT&amp;T generally contracts for more than one
access route into each LATA. I believe that BOTH of those were in the same Ill.
Bell cable vault that burned. Notice that AT&amp;T (or any other long distance
company) has little control over what Ill Bell puts in its cable vaults.

I would hope that it is general policy that critical hubs in the local network
have alternate routes. But, with divestiture, this is now something that the
operating companies and the state utility commissions work out. The idea of
divestiture was to set rate structures such that one pays the TRUE cost of
providing each type of service.  Could it be that alternate trunking is just
too expensive to provide the public?  It is obvious that it was too expensive
for the subscribers in the western suburbs of Chicago!

To sum up, I think it is silly to ask a non-existent organization
("the Bell System") to comment on risks.

Mike Eastman    ihnp4!ihuxz!mfe    (312) 979-4111
AT&amp;T Bell Laboratories  Rm. 4C-321  Naperville, IL 60566

            [Perhaps "boyle" was thinking of the "Virtual Bell System"?  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Illinois Bell Fire
</A>
</H3>
<address>
&lt;<A HREF="mailto:Bradley_W_Dolan@cup.portal.com">
Bradley_W_Dolan@cup.portal.com
</A>&gt;
</address>
<i>
Fri May 20 20:39:29 1988
</i><PRE>

Daniel Faigin writes:
&gt; ...in certain industries, such as nuclear ... all alarms are
&gt; treated as real emergencies until proved otherwise.

My experience has been that, at any given time, there may be 20-100 alarms
indicating in a nuclear power plant control room.  New ones come in (on a good
day) every few minutes.  Realistically, they can't all be immediately treated
as valid.  99% will eventually prove to be spurious or trivial.  Alarms serve
to focus attention on a *potential* problem. The reactor operator must judge
the validity of each alarm and decide what response is appropriate.  If no
judgement was needed, the alarm input could as well be hardwired to produce the
desired response.

I suspect that similar conditions prevail in Bell's remote monitoring location.
Fire alarms are notorious for spurious indication.  Hot days, impaired
ventilation, dust, etc. can erroneously activate various types of fire alarms.
The maligned technician probably received several - maybe dozens - of false
alarms per month from different monitored sites. He probably spent the infamous
10 minutes trying to confirm or deny the existence of a real problem (which
would have been simpler had there been a human at the switching office).

&lt;Brad Dolan&gt; sun!portal!cup.portal.com!bdolan@Sun.COM
(Opinions expressed herein are my own... and I only understand
about half of what I know!)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
smoke detectors and electrical equipment
</A>
</H3>
<address>
John Bruner 
&lt;<A HREF="mailto:jdb@mordor.s1.gov">
jdb@mordor.s1.gov
</A>&gt;
</address>
<i>
Fri, 20 May 88 08:27:02 PDT
</i><PRE>

Another risk of automatic alarms is created by the inappropriate
choice of technology.  The VAX and Sun computers for my group at LLNL
are located in two machine rooms.  Each machine room is equipped with
smoke detectors which are checked on a regular basis.  The machine
rooms are often unmanned.

Two years ago someone in an office near one of the machine rooms
reported smelling smoke.  When several of us entered the machine room
the smoke was so thick that we could not see the other side of the
room; however, none of the smoke detectors had sounded an alarm.

The smoke detectors "passed" subsequent tests, including cigarette
smoke.  We finally determined that the smoke came from an insulation
fire in one of the air conditioners.  The insulation smoke didn't
ionize, rendering the detectors ineffective.  (We replaced them with
optically-based detectors.)

I don't know who originally installed the smoke detectors, but after
the initial incorrect decision was made we had no clue that part of
our fire alarm system was useless.  The testing procedure did not
detect the unsuitability of this type of detector for our particular
application.

  John Bruner (Supercomputer R&amp;D, Lawrence Livermore National Laboratory)
  jdb@mordor.s1.gov	...!lll-crg!mordor!jdb		(415) 422-0759

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Halon environmental impact citation (Re: <A HREF="/Risks/6.87.html">RISKS-6.87</A>)
</A>
</H3>
<address>
   Jeffrey R Kell 
&lt;<A HREF="mailto:JEFF%UTCVM.BITNET@CUNYVM.CUNY.EDU">
JEFF%UTCVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri, 20 May 88 09:23:27 EDT
</i><PRE>

  &gt;From: Anita Gould &lt;FONER.NITA%OZ.AI.MIT.EDU@XX.LCS.MIT.EDU&gt;
  &gt;Subject: Halon environmental impact citation
  &gt;
  &gt;There are currently no good substitutes for halon, but according to SN, they
  &gt;"are released far more frequently during tests than during fires."  Of
  &gt;course, failure to conduct tests has risks of its own! I'm sure they can be
  &gt;minimized by designing equipment to be tested under dry run conditions.
  &gt;Does anyone know if this is actually being done?

Our latest system, installed in 1986, was initially tested using small tanks
charged with Freon that were valve-compatible with the Halon tanks (although
much smaller in volume).  As best I can recall the system has *never* been
tested with actual Halon, but this test does verify the operation of the actual
valve assemblies.  [Electronics and solenoids are Pyrotronics, release valves
are Pyr-A-Lon].

The Freon tests are not much better on the ozone layer, but better than dumping
the whole system (and much less expensive).  The added security of the test is
that equipment is left in the room during the dump to measure the Freon
concentration, as a double check of your "dosage" and degree of airseal.

I do not know of tests done with any inert or otherwise harmless gas.  The
reliability of the test could very well be affected (CO2 would generate a small
snowstorm, temperature/pressure variance in the valves with other gases).

Jeffrey R Kell, Dir Tech Services, Admin Computing, 117 Hunter Hall 
Univ of Tennessee at Chattanooga, Chattanooga, TN 37403 (615)-755-4551

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Navigation
</A>
</H3>
<address>
Mike Fischbein
&lt;<A HREF="mailto:msf@tab13.larc.nasa.gov ">
msf@tab13.larc.nasa.gov 
</A>&gt;
</address>
<i>
Fri, 20 May 88 07:20:51 EDT
</i><PRE>

There are reasons besides philosophic satisfaction and independence of
electricity (as mentioned by Mr. Brunow in RISKS Vol 6, Issue 88) to maintain
proficiency in celestial navigation.  US Naval vessels have many redundant
sources of electricity, and are probably not immediately concerned with
navigation if all are gone.  All the electronic methods of navigation require
external devices in predictable and accessible locations; defending these
usually delicate installations would be extremely difficult at best.  (Inertial
systems require external input to prevent drifting off the correct dead
reckoning position) The stars, sun, moon, and planets are available under
nearly all conditions and can give accurate results easily and quickly with
moderate practice.
                                   	mike 
Michael Fischbein     msf@ames-nas.arpa    ...!seismo!decuac!csmunix!icase!msf
                                  
These are my opinions and not necessarily official views of any organization.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.88.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.90.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-37</DOCNO>
<DOCOLDNO>IA012-000129-B046-124</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.90.html 128.240.150.127 19970217021438 text/html 20070
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:13:05 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 90</TITLE>
<LINK REL="Prev" HREF="/Risks/6.89.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.91.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.89.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.91.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 90</H1>
<H2>  Tuesday 24 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Man Charged with 'Infecting' Computers" 
</A>
<DD>
<A HREF="#subj1.1">
Steve Smaha
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Automobile recall notice 
</A>
<DD>
<A HREF="#subj2.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  The Risks of Risks [Second-Order Friday the 13th Effects] 
</A>
<DD>
<A HREF="#subj3.1">
Mike O'Brien
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Cash on the Nail 
</A>
<DD>
<A HREF="#subj4.1">
Betty Smith via Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  "Sciences &amp; Vie Micro":  BILLIONS 
</A>
<DD>
<A HREF="#subj5.1">
Franklin Anthes
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Who watches the watchers? -- Southern Bell outage 
</A>
<DD>
<A HREF="#subj6.1">
Scott Schwartz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  "The Bell System"; aircraft navigation systems 
</A>
<DD>
<A HREF="#subj7.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Hinsdale File 
</A>
<DD>
<A HREF="#subj8.1">
John Haller
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"MAN CHARGED WITH 'INFECTING' COMPUTERS"
</A>
</H3>
<address>
&lt;<A HREF="mailto:Smaha@DOCKMASTER.ARPA">
Smaha@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 24 May 88 09:23 EDT
</i><PRE>

Fort Worth, Texas (AP)  24 May 1988

A 39-year-old computer progammer is being prosecuted on felony charges of
infecting his ex-employer's computers with an electronic "virus", and faces up
to 10 years in prison if convicted.

Donald Gene Burleson faces a charge of "harmful access to a
computer," and is free on a $3,000 bond pending his July 11 trial.

Police described the electronic interference as a "massive deletion"
of more than 168,000 records of sales commissions for employees.

Burleson is thought to be the first person charged under the state law
prohibiting computer sabotage, which took effect Sept. 1, 1985, about three
weeks before the alleged incident, said Davis McCown, chief of the Tarrant
County district attorney's economic crimes division.

[From Steve Smaha, Austin, TX]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Automobile recall notice
</A>
</H3>
<address>
Martin Minow THUNDR::MINOW ML3-5/U26 223-9922
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
24 May 88 19:36
</i><PRE>

Abstracted from a notice that I received yesterday.

"Volvo has determined that a defect which relates to motor vehicle safety
exists in Volvo installed cruise control systems of 1986 and 1987 Volvo
automobiles.

"In laboratory tests, we have been able to induce a malfunction in the
microprocessor of the cruise control unit.  We have found that if the cruise
control switch is left in the "on" position and the car's electrical system
experiences a voltage drop, the cruise control may unexpectedly engage.  We
have also found that the application of the brake pedal and the movement of the
switch to the "off" position cancels the malfunction.  This cannot occur if the
cruise control is in the "off" position.

"We know of know cases where this has happened in normal driving, but we do not
want a malfunction of the cruise control to contribute to an accident.
Accordingly, we will replace the microprocessor of your cruise control at no
charge to you...."

A few observations:

-- I'd really like to know how they discovered this -- was it by some
   programmer staring at the source code, or by testing in a design
   verification test chamber?  The problem itself might make an interesting
   case study for a "software safety" seminar (assuming you can pry the
   details out of the manufacturer).

-- A law (The National Traffic and Motor Vehicle Safety Act) does wonders
   for improving the quality of manufacturered goods.  Would the problem
   have been discovered (and the roms replaced) if it weren't for this act?
   (Note: this is a voluntary recall from a manufacturer who advertises the
   quality of its cars.)

-- "Microprocessor" is now a common English word.

Martin Minow   

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
The Risks of Risks [Second-Order Friday the 13th Effects]
</A>
</H3>
<address>
&lt;<A HREF="mailto:obrien@aerospace.aero.org">
obrien@aerospace.aero.org
</A>&gt;
</address>
<i>
Mon, 23 May 88 09:57:23 -0700
</i><PRE>

	We had what is, in retrospect, a fairly humorous occurrence here
last Friday 13th.

	As most readers are no doubt aware by now, there was a rumor
to the effect that a disgruntled employee of Sun Microsystems had
planted a "logic bomb" (nature unspecified) in Sun's operating system,
set to "detonate" on Friday 13th.   [<A HREF="/Risks/6.83.html">RISKS-6.83</A>-84]

	This rumor hit our site only sometime on Thursday the 12th.
As a precaution, and after some considerable thought, one of our
chief systems team members decided to set all the clocks back so that
the Suns in our network would think that Friday was Thursday.

	Imagine the surprise some of us got when we arrived at work
on Friday morning to discover that the screens on our Suns were blank,
dead, kaput, no response, zippola.  This made us really wonder if perhaps
there were some truth to the rumor.

	Well, no.  Those of us with dead screens were the ones who run
a Sun-supplied program called "screenblank" which turns off the video
signal to the Sun screen after a certain period of inactivity.  This
program, after blanking the tube, goes into a sleep loop, waking every
1/4 second by default to check for keyboard and/or mouse activity.

	What had happened, of course, was that our screenblank programs
were asleep when the date was set back by 24 hours.  Since in UNIX,
time is kept as an absolute quantity, the programs were now waiting
for 24 hours plus 1/4 second before checking for activity.  They
had to be killed off and the video restored manually (running another
"screenblank" did the trick).

	As I say, this is amusing in retrospect: in defending against
a non-existent RISK, we created a real one, though minor.  Risks don't
even have to exist to cause real damage.

Mike O'Brien, The Aerospace Corporation

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Cash on the Nail
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Tue, 24 May 88 21:42:26 +0100
</i><PRE>

&gt;From Betty_Smith@UK.AC.NEWCASTLE Tue May 24 14:39:41 1988

 DAEDALUS
 David Jones
 
      For  years  now,  we  have been told that the cashless society is
 just around the corner.  Every shop will  have  a  computer  terminal;
 simply enter the transaction, validate it with your personal card, and
 the central computer will transfer the sum specified  from  your  bank
 account  to  that  of the shop.  Wonderful!  The reason why it doesn't
 happen is that fraud would be so easy.  Card fraud  is  so  widespread
 already  that the banks daren't risk anything worse.  But Daedalus has
 the  answer.   His  new  cash-card  is  unstealable:  the  user's  own
 thumbnail.
 
      A  nail  has  a  smooth  and  uniform surface, and is transparent
 enough to let through the light from a laser.   A  small  laser  could
 bring  a brief light pulse to a focus in the body of the nail, burning
 a tiny white mark that could easily be read, but  would  be  protected
 from chance abrasion.  A dot-matrix pattern of such marks could easily
 encode a financial transaction.  A nail has no nerves so  the  process
 would  be  quite  painless.   Accordingly,  the  new Dreadco financial
 terminal has, besides a  keyboard  for  entering  the  transaction,  a
 thumb-port to admit the user's thumb.
 
      Every day a nail grows about a tenth of a millimetre.  With laser
 dots about the size of those on a compact disc , this would give space
 for about ten new transactions.  Over time the user will accumulate on
 his  thumbnail  a  running  financial  statement   showing   all   his
 transactions  for the past few months.  Each time he inserts his thumb
 into a terminal, the sytem will check that statement against its file.
 If  everything  matches,  his  identification  is secure; the terminal
 accepts the new transaction and prints it  below  the  previous  ones.
 But  if  there is a discrepancy, it sounds an alarm and clamps down on
 the suspect thumb, trapping the fraudster until the police arrive!
 
      But  suppose  a  bent manicurist manages to photograph a client's
 thumbnail, and uses it to construct a forged thumb?   Even  then,  the
 fraud  is  risky.   By  the time the forged thumb is ready, the victim
 will probably have used the system again.  The forgery will not  carry
 this  latest  transaction:  it  will  be  detected  and trapped by the
 terminal, for the police to study later as evidence.
 
      Daedalus'  new  thumbcard  will  impose financial prudence on its
 users.  The spendthrift who fills his thumb up with wild  transactions
 will  soon  be  choked off by sheer lack of space.  On the other hand,
 should he go down with mumps or measles (which  arrests  nail  growth)
 bankruptcy would rapidly threaten.  And secrecy is not really assured.
 Gigolos with magnifiers may  shrewdly  revive  the  old  gallantry  of
 hand-kissing:  gypsy  palmists  will  read both sides with great care;
 shady financial operators of both sexes may  take  to  wearing  opaque
 nail  varnish.   And  a  death  in  the family will have the sorrowing
 relatives   hastily   erasing   the   deceased's   thumbs    with    a
 laser-scrambler,  before  some unscrupuous undertaker or body-snatcher
 can detach or copy them to filch their encoded legacy.
 
The Guardian
24 May l988

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"Sciences &amp; Vie Micro":  BILLIONS (Re: <A HREF="/Risks/6.86.html">RISKS-6.86</A>)
</A>
</H3>
<address>
Franklin Anthes
&lt;<A HREF="mailto:mcvax!geocub!anthes@uunet.UU.NET ">
mcvax!geocub!anthes@uunet.UU.NET 
</A>&gt;
</address>
<i>
Mon, 23 May 88 21:15:50 +0200
</i><PRE>
Organization: Greco de programmation, Bordeaux France

&gt;RISKS DIGEST 6.85 includes a brief excerpt translated from the
&gt;French-language "Sciences &amp; Vie Micro" referring to chances of a crash
&gt;due to a software error:
&gt;  "One chance in a million?  Wrong!  One chance in a billion and that
&gt;   for each hour of flight!"

 The original was:

   "Je prends l'avion, quelle probabilite ai-je de m'ecraser au sol pour
    une erreur de logiciel? Une chance sur un million? Perdu! Une chance
    sur un milliard et par heure."

So the translation was correct concerning the billion. I Looked in the
dictionary and found out that billion actually has two meanings in French: one
old and one new (talk about a RISK!). The old meaning is 10**9, and the new is
10**12, like you said. Anyway thank you for pointing out the possible
ambiguities.

Frank Anthes-Harper   ....!ucbvax!decvax!uunet!mcvax!inria!geocub!anthes

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
who watches the watchers?  -- Southern Bell outage
</A>
</H3>
<address>
Scott Schwartz 
&lt;<A HREF="mailto:schwartz%thebes%swarthmore.edu@RELAY.CS.NET">
schwartz%thebes%swarthmore.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Tue, 24 May 88 04:46:11 EDT
</i><PRE>

Relying on alarms, even with humans in the loop is sometimes not
enough, it seems.

The following article is from the Philadelphia Inquirer, 23 May '88, pA10.

	"Power Surge Knocks Out Telephone Service in N.C"

	UPI, Charlotte N.C. --  A mysterious power surge that went undetected
	for six hours knocked out telephone service to about one-fifth of 
	North Carolina Saturday (May 21) night and early yesterday, forcing
	hospitals and police to rely on radio communications.	...

	The outage was caused by an apparent power surge of unknown origin that
	struck the central office of Southern Bell in Charlotte at about 11:30
	a.m. Saturday.  A skeleton crew at the office failed to notice alarms
	warning of the problem until the overloaded system failed about six
	hours later.

-- Scott Schwartz	schwartz@swarthmore.edu

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
"The Bell System"; aircraft navigation systems
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@ames-aurora.arpa">
steve@ames-aurora.arpa
</A>&gt;
</address>
<i>
Mon, 23 May 88 11:44:02 PDT
</i><PRE>

In RISKS 6.89, ihuxz!mfe@moss.att.com (Mike Eastman) writes:

&gt;As of Jan 1, 1984 the Bell System was abolished when the Justice Dept had AT&amp;T
&gt;officially divest itself of the local operating companies. ...

It has been three and a half years since divestiture and a lot of operational
changes have occurred in that time.  However, that Ill. Bell cable vault has
probably been around a long time.  Was it put in place and operated by the
"Bell System" BEFORE divestiture?  Did the Bell System originally place the
primary and backup trunks in the same building?  These questions have
significance to RISKS in that we should find the roots of our technical errors
in their design process and not simply lay blame on government decisions that
we don't like.  Has divestiture increased risk, or is it beginning to serve as
a convenient whipping boy when something goes wrong?

It's easier to point fingers at the other guy than to accept responsibility.
We see this all the time in multi-vendor computer systems.  No one want to 
accept blame when they can say it's someone else's problem.  Of course, the 
users just want the system fixed!  (It's not a hardware problem -- it's a
wetware bug!)


One more point on aircraft navigation systems:

The concerns of depending on electrical power for navigation become
insignificant for many new aircraft, as some cannot fly at all if there is
total electrical system failure.  In RISKS we've discussed the new Airbus jets.
The opposite end of the spectrum is the new Mooney PFM.  This single engine
aircraft uses electronic ignition.  It does have dual electrical systems and
batteries, and a very low failure probability, but if total failure does occur,
the pilot will be more concerned with landing his glider than navigating to a
distant destination.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Hinsdale File (Re: RISKS DIGEST 6.89)
</A>
</H3>
<address>
&lt;<A HREF="mailto:jhh@ihlpl.uucp">
jhh@ihlpl.uucp
</A>&gt;
</address>
<i>
Tue, 24 May 88 01:10:16 EDT
</i><PRE>

Last Friday, May 20, there was a Chicago Tonight (1/2 hour show on PBS channel)
that described the Hinsdale fire.  Apparently, the fire alarms go off whenever
there is a power failure.  Since there was an AC power alarm at the same time
as the fire alarm, it was assumed to be the source of the fire alarm.  I
personally would not be surprised if that was actually the case, and that the
AC power went off as a result a short, which caused the fire.  The diesels
started automatically, and then failed within 10 minutes, causing another power
and fire alarm.  At this time, when the alarms were released (a manual
operation), they did not re-occur, indicating only a glitch in the alarm
circuits.

The alarms are detected by a contact closure on the switch itself,
and passed to the SCCS (Switching Control Center System) via a
data link.  Since the alarms were being received, the switch was
obviously working, the prime concern of SCC personnel.

Since the fire, the other three hub switches in Chicago are being
staffed 24 hours a day, because of the vulnerability caused by
Hinsdale not being in full operation.  I can understand some of the
logic behind not staffing offices on off-hours, as there is
a large expense involved, particularly if all offices are to be staffed.
Even assuming a day shift at all offices, another 3 shifts are required
to cover the remainder of the week.  At a typical salary of a
craft person, that would be ~$120,000 per year per office.  To
staff 100 offices, at $12,000,000 per year, it is easy to see
the decision not to staff compared to the cost of a new switch.
Before Hinsdale, public utilities commissions probably would be
likely to disallow those charges, as unnecessary.

I also suspect that Hinsdale grew more by accident than by design into such an
important part of the Chicago network.  There has been tremendous growth in
development in the western suburbs, along with subsequent growth in
telecommunications.  I seriously doubt that anyone in Illinois Bell ever did a
worst case catastrophe analysis of their network.  After all, it could have
been a tornado destroying the entire building, rather than a fire destroying
merely the contents.  I am positive that there has never been a study by
Illinois Bell of the effects of two simultaneous failures.

John Haller, AT&amp;T Bell Laboratories

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.89.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.91.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-38</DOCNO>
<DOCOLDNO>IA012-000129-B046-152</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.91.html 128.240.150.127 19970217021508 text/html 22036
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:13:18 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 91</TITLE>
<LINK REL="Prev" HREF="/Risks/6.90.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.92.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.90.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.92.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 91</H1>
<H2>  Wednesday 25 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computers as a weapon? 
</A>
<DD>
<A HREF="#subj1.1">
Ken De Cruyenaere
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Aircraft computer malfunction incidents 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Federal "smart cards" 
</A>
<DD>
<A HREF="#subj3.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Cash on the Nail 
</A>
<DD>
<A HREF="#subj4.1">
Michael Travers via Andrew Scott Beals
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Style rules - a horror story 
</A>
<DD>
<A HREF="#subj5.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Rebuttal on Hinsdale 
</A>
<DD>
<A HREF="#subj6.1">
Patrick A. Townson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Risk cost recovery -- Hinsdale 
</A>
<DD>
<A HREF="#subj7.1">
Barry C. Nelson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computers as a weapon ?
</A>
</H3>
<address>
&lt;<A HREF="mailto:Ken De Cruyenaere <KDC%UOFMCC.BITNET@CORNELLC.CCS.CORNELL.EDU> ">
Ken De Cruyenaere &lt;KDC%UOFMCC.BITNET@CORNELLC.CCS.CORNELL.EDU&gt; 
</A>&gt;
</address>
<i>
Tue, 24 May 88 12:02 CDT
</i><PRE>

The following story appeared in today's WINNIPEG SUN
(reprinted without permission)
Life must certainly be unpleasant in an "occupied land".

  COMPUTER NETWORK NABS ARABS
 RAMALLAH (AP)  Israel is using computers as weapon in the struggle
to suppress the Palestinian uprising in Israeli occupied Arab lands.
  A computer linkup of the military administration, police and civil
and security service offices allows Israel to monitor almost every aspect
of life in the West Bank and Gaza.
   Arab merchants who obey the calls of the uprising's underground
leaders and refuse to pay taxes are often nabbed in a network of
computerized roadblocks.
  On the road between Jerusalem and the West Bank town of Bethelem,
an AP reporter saw checkpoints where portable computers were used
to track down tax evaders.  Names are taken from identity cards
Arabs are required to carry.  When the names are entered in the
computer, it identifies those who owe taxes.
  The military government demands tax payment in exchange for a
registration of a newborn child or marriage, Palestinians told
told the AP.
  "We are scared.  The tax officials catch you and seize your
   car or impose a huge fine."
  A military government official said about 400 vehicles belonging
to deliquent Arab taxpayers have been seized in the West Bank.
  The computer "is indeed the ultimate instrument of population
control, a carrot-and-stick operation", researcher Meron Benvenisti
wrote in his annual study of the occupied territories.
Benveniti said Israel started to develop a computerized occupied lands
data bank in August, 1985.  The five-year, $8.5-million project
was undertaken by TIM, an Israeli representative of the U.S.
computer company Data General.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Aircraft computer malfunction incidents
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@ICS.UCI.EDU">
nancy@ICS.UCI.EDU
</A>&gt;
</address>
<i>
Tue, 24 May 88 21:12:44 -0700
</i><PRE>

From Air Line Pilot, May 1982.
  
  "Several of ALPA's technical committees and the Assocation's New Aircraft
   Evaluation-Certification Committee are studying improvements that might
   be made to the stretched DC-9 to address such pilot concerns as the
   following:

          Computer Malfunctions

   Unexpected mode changes, complete loss of data, and other anomalies of
   the flight guidance system have been reported during all phases of flight
   in Super 80s; cold soaking of the computer or electrical transients or
   both are believed to have been partial causes.  Reports of flight guidance
   system malfunctions include unexpected switching from the takeoff mode to
   another mode during the takeoff roll and from the desired approach mode to
   the heading mode near decision height (DH).  Autopilot and autothrottle
   disconnects during turbulence have been reported, and switching from takeoff
   mode to climb mode has caused the autothrottle thrust computer to retard
   one throttle to idle.

   Under certain deicing-engine auti-icing bleed configurations and flight
   conditions -- for example, on coupled approaches and when climbing through
   cirrus clouds -- problems with computer system logic for digital thrust
   rating have caused autothrottle disconnects."

[It continues with a listing of problems in non-computer parts of the design.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Federal "smart cards"
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.stanford.edu ">
chapman@csli.stanford.edu 
</A>&gt;
</address>
<i>
Wed, 25 May 88 16:08:06 PDT
</i><PRE>

The recent humorous (I presume) recommendation for a universal "smart
card" on one's thumbnail prompts me to call attention to something a
little more serious.  I was recently a reviewer for an OTA draft report
on computerizing the entire Federal welfare benefits system--food
stamps, Medicare, welfare, etc.  As one official put it to me recently,
people at OTA thought this was sort of a joke when it first came down, but
Congress is serious.  The draft report, which may get elevated to a
full panel study, considers the issuance of "smart cards" to all Federal
welfare beneficiaries, with ATM-like machines at all places where
Federal benefits are exchanged for goods and services.  If you just
stop and think a minute about how many sites this involves--every "Mom
and Pop" grocery store, every Seven-Eleven, any place that takes food
stamps--you get an impression of the expense.  This is a multi-billion 
dollar proposal just to get the system set up and into place.  

Beyond that, say some experts, looms a national identity card for all U.S.
citizens.  Serious proposals for this may not be far off.  So far there has
been no real rationale for Congress to consider this, but the recent
immigration law, which imposes fines on employers for hiring undocumented
workers, will create a nation-wide consitituency pressing for some reliable
form of citizenship identification.  If there is a trend toward "smart card"
disbursement of Federal benefits, this will add to the INS rationale for a
national identity card.  What's disturbing about all this is that Congress
gradually gets used to ideas like these, opposition seems to fade, and the
momentum can appear irresistable.

Gary Chapman, Executive Director, CPSR

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Cash on the Nail
</A>
</H3>
<address>
Andrew Scott Beals
&lt;<A HREF="mailto:well!bandy@lll-crg.llnl.gov ">
well!bandy@lll-crg.llnl.gov 
</A>&gt;
</address>
<i>
Wed, 25 May 88 15:29:15 PDT
</i><PRE>

Date: Wed, 25 May 88 16:07 EDT
From: Michael Travers &lt;mt@media-lab.media.mit.edu&gt;
Subject: Mark O' the Beast update

Subject: Cash on the Nail

 DAEDALUS
 David Jones
 
      For  years  now,  we  have been told that the cashless society is
 just around the corner.  Every shop will  have  a  computer  terminal;
 simply enter the transaction, validate it with your personal card, and
 the central computer will transfer the sum specified  from  your  bank
 account  to  that  of the shop.  Wonderful!  The reason why it doesn't
 happen is that fraud would be so easy.  Card fraud  is  so  widespread
 already  that the banks daren't risk anything worse.  But Daedalus has
 the  answer.   His  new  cash-card  is  unstealable:  the  user's  own
 thumbnail.
 
      A  nail  has  a  smooth  and  uniform surface, and is transparent
 enough to let through the light from a laser.   A  small  laser  could
 bring  a brief light pulse to a focus in the body of the nail, burning
 a tiny white mark that could easily be read, but  would  be  protected
 from chance abrasion.  A dot-matrix pattern of such marks could easily
 encode a financial transaction.  A nail has no nerves so  the  process
 would  be  quite  painless.   Accordingly,  the  new Dreadco financial
 terminal has, besides a  keyboard  for  entering  the  transaction,  a
 thumb-port to admit the user's thumb.
 
      Every day a nail grows about a tenth of a millimetre.  With laser
 dots about the size of those on a compact disc , this would give space
 for about ten new transactions.  Over time the user will accumulate on
 his  thumbnail  a  running  financial  statement   showing   all   his
 transactions  for the past few months.  Each time he inserts his thumb
 into a terminal, the sytem will check that statement against its file.
 If  everything  matches,  his  identification  is secure; the terminal
 accepts the new transaction and prints it  below  the  previous  ones.
 But  if  there is a discrepancy, it sounds an alarm and clamps down on
 the suspect thumb, trapping the fraudster until the police arrive!
 
      But  suppose  a  bent manicurist manages to photograph a client's
 thumbnail, and uses it to construct a forged thumb?   Even  then,  the
 fraud  is  risky.   By  the time the forged thumb is ready, the victim
 will probably have used the system again.  The forgery will not  carry
 this  latest  transaction:  it  will  be  detected  and trapped by the
 terminal, for the police to study later as evidence.
 
      Daedalus'  new  thumbcard  will  impose financial prudence on its
 users.  The spendthrift who fills his thumb up with wild  transactions
 will  soon  be  choked off by sheer lack of space.  On the other hand,
 should he go down with mumps or measles (which  arrests  nail  growth)
 bankruptcy would rapidly threaten.  And secrecy is not really assured.
 Gigolos with magnifiers may  shrewdly  revive  the  old  gallantry  of
 hand-kissing:  gypsy  palmists  will  read both sides with great care;
 shady financial operators of both sexes may  take  to  wearing  opaque
 nail  varnish.   And  a  death  in  the family will have the sorrowing
 relatives   hastily   erasing   the   deceased's   thumbs    with    a
 laser-scrambler,  before  some unscrupuous undertaker or body-snatcher
 can detach or copy them to filch their encoded legacy.
 
The Guardian, 24 May l988

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Style rules - a horror story (forwarded from comp.lang.misc on USENET)
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Wed, 25 May 88 20:33:49 EDT
</i><PRE>

On the topic of corporate rules requiring formal documention for each
procedure in a program, Dick Dunn (uucp: {ncar,cbosgd,nbires}!ico!rcd)
posted the following in comp.lang.misc:
  
  People may not realize just how much trouble it can cause.  A few years
  back, I saw a procedure-heading standard which was so large and ornate that
  it was actually causing people to *avoid* writing procedures!  They were
  working on a project which had deadlines (as opposed to lines-of-code-per-
  day goals:-), but they were absolutely required to build one of these giant
  headers for each function.  As a result, it was often easier to write code
  in-line to perform the identical function in several different places than
  to split it out into a separate procedure.
  
  Write your own moral--something about programmers taking the easiest path
  so style rules should encourage the easiest path to be the same as the
  right one.

Forwarded to Risks by Mark Brader

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Rebuttal on Hinsdale
</A>
</H3>
<address>
&lt;<A HREF="mailto:Patrick_A_Townson@cup.portal.com">
Patrick_A_Townson@cup.portal.com
</A>&gt;
</address>
<i>
Wed May 25 20:40:09 1988
</i><PRE>

John Haller of AT&amp;T Labs (Risks 6.90) discusses the sequence of events which
led to the disasterous fire at Hinsdale on May 8. He quotes from a television
show (Chicago Tonight) which on more than one occassion has been derelict
in getting all its facts straight.

First: The fire alarm and power outage alarm were NOT simultaneous. The fire
alarm was first noted in Springfield, IL at 3:50 PM that Sunday afternoon.
The fire alarm signal continued for nine minutes. It was ignored by an employee
who thought it was going off due to other conditions at the time.

The alarm stopped about 3:59 PM, then started again a few minutes later, and
on its second warning, *then the alarm for loss of power made itself known*.
There was nine minutes wasted, plus the several minutes until it began again.

Second: When the technician finally was moved intellectually to consider that
a fire alarm might actually refer to a fire, a call was made to a weekend
duty supervisor. Not the Hinsdale Fire Department; not the Police Department,
but a person who had to put down what they were doing, go out to their car
and drive to 120 South Lincoln from wherever they were, through Sunday
traffic, the whole bit. Had the tech immediatly called the Hinsdale Fire
Department and the weekend supervisor, and coordinated as best as possible
the arrival of firemen with telco personnel on location, the damages would
have been much less.

Third: The cost of staffing for that office, or any central office on weekends
or off hours is no where near the estimate given by correspondent. He assumes
a full compliment of people on each shift, Sundays, nights, holidays, etc...
and assumes holiday pay, night premiums, etc. None of this is required. One
or two persons *maximum* per office would be fine. A clerk at a terminal with
work to do -- they surely could input work orders, make record corrections,
etc -- and the express duty of touring the building once every hour or so and
immediatly upon reciept of an alarm would be sufficient.

Fourth: A good, comprehensive Halon network, via overhead plumbing just as
in conventional water sprinkler systems, would cost only about a quarter
million dollars per office to install, and much less than that annually to
refresh the holding tanks each year. Hand held halon extinquishers mounted
in strategic locations around the building would cost even less.

Imagine if you will, a clerk on the premises Sunday afternoon. He is only
paid $30,000 a year or so, and an alarm is noted on his console or terminal.
He picks up a hand held cellular phone, walks into the room down the hall,
sees smoke and grabs the Halon cannister from the wall. On the phone he
dials 911 to tell them. He starts spraying the Halon, and likely gets the
fire out before the firemen arrive. Then he calls a couple other numbers on
the phone to key employees to get the word out: get over here fast.

He goes out, meets the firemen and escorts them inside. If the fire is still
going, they also have Halon, and are better trained at this sort of thing
than the $30,000 per year clerk. Within minutes a couple of other employees
are there, and the limited damage is assessed and repairs begin immediatly.

Now how much would this very *non* labor intensive scenario cost in a year?
We would need three such persons per office -- or four perhaps -- allowing
for one at night, one evenings, one weekends and days off for the other two.

Would $200,000 per year per office cover salaries?  If there were 10 very
important central offices in the Chicago area, would $2,000,000 per year
cover salaries? That's quite a bit lower than the $12,000,000 correspondent
suggests would be required. And if the watch-persons had other duties to
do, could their salaries at least in part be charged off in the budgets of
other departments?  In my figures here, I've actually over-budgeted to
include two or three additional watch-persons-at-large, who would travel
from office to office during the night to relieve for lunch breaks,
fill in for sick or vacationing watch-persons, etc.

Correspondent shudders at the idea of $12,000,000 (his figures), and
says its not economical....but the actual damage to date from Hinsdale
has exceeded $50,000,000 and the cash register is still ringing! Talk
about false economies....

I'm sorry, but I think Jim Eibel, Illinois Bell VP of Operations, and
designer of the plans which led to this tragedy was expecting an awful
lot for his money if he figured a person downstate would see the alarm,
know what it was, get help and control a serious problem as well as someone
right on location babysitting the switch would do it.

Finally, they have weekend duty supervisors all over the area anyway. They
are already being paid a salary, so in figuring the cost of staffing an
office at night you have to consider you already have several of the
needed employees in place. Arrange them differently and hire a few more.

I rest my case.

Patrick Townson

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Risk cost recovery
</A>
</H3>
<address>
"Barry C. Nelson" 
&lt;<A HREF="mailto:bnelson@ccb.bbn.com">
bnelson@ccb.bbn.com
</A>&gt;
</address>
<i>
Wed, 25 May 88 09:41:37 EDT
</i><PRE>

John Haller writes about economics of protecting telco switches:

&gt;  At a typical salary of a
&gt;craft person, that would be ~$120,000 per year per office.  To
&gt;staff 100 offices, at $12,000,000 per year, it is easy to see
&gt;the decision not to staff compared to the cost of a new switch.

Okay, so I'm not an 'econ' major, and it isn't very easy for me to see this.

It  does  NOT  take a craft person to watch a switch, it takes a security guard
(and I would guess they would not be  paid  as  well!).   The  CRAFTperson,  if
provided, could be doing otherwise-useful work while guarding the switch.  Such
work could not be fully billable as 'protection', and the TelCo  would  benefit
materially.   

Ten  minutes  out of an hour to do 'rounds' leaves 3/4 time 'working.' Add this
to the demonstrably fallible alarms already installed and they  are  made  much
better since a person on-site can EASILY go LOOK, let alone COPE with a problem
immediately.

Why not just reduce daily staffing so as to normally have productive work to do
during  off-hours.  Even  paying  an EXTRA 1/4, or $30,000 per year per office,
exclusively for added protection, is pretty cheap for guaranteed insurance.

We must also not forget the other costs beyond the actual switch.
[From Patrick Townson's May 14 posting to RISKS:]

&gt; And twenty five million is a *very
&gt;low estimate* of the cost of the fiasco. The new switch alone is estimated
&gt;to cost about sixteen million dollars. ... That does
&gt;not of course include peripheral equipment, overtime salaries to workers,
&gt;the cost of repairing the building or the month of lost revenue from the
&gt;thousands of subscribers without service.

I'll  bet someone with the ACTUAL number of similar offices, over all the years
they've been installed, given the ACTUAL distribution and cost  of  preventable
disasters  during  those  years,  could  come  up with a good business case for
continued protection.  Belt and suspenders, anyone?

Barry C. Nelson

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.90.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.92.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-39</DOCNO>
<DOCOLDNO>IA012-000129-B046-180</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.92.html 128.240.150.127 19970217021519 text/html 13333
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:13:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 92</TITLE>
<LINK REL="Prev" HREF="/Risks/6.91.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.93.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.91.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.93.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 92</H1>
<H2>  Wednesday 25 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Down in the Dumps (a true story) 
</A>
<DD>
<A HREF="#subj1.1">
Peter Rowell via David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  "Providence Journal" virus 
</A>
<DD>
<A HREF="#subj2.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Stock market damping 
</A>
<DD>
<A HREF="#subj3.1">
David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Daedalus and the Thumb Card 
</A>
<DD>
<A HREF="#subj4.1">
Dave Clayton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Hinsdale 
</A>
<DD>
<A HREF="#subj5.1">
John [J.G.] Mainwaring
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Down in the Dumps (a true story) from comp.unix.wizards
</A>
</H3>
<address>
David Sherman
&lt;<A HREF="mailto:lsuc!dave@unix.SRI.COM ">
lsuc!dave@unix.SRI.COM 
</A>&gt;
</address>
<i>
25 May 88 14:36:29 EDT (Wed)
</i><PRE>

From: peter@thirdi.UUCP (Peter Rowell)
Newsgroups: comp.unix.wizards
Subject: Down in the Dumps (a true story)
Date: 19 May 88 22:13:13 GMT
Organization: Third Eye Software, Menlo Park, CA

If the following command does not look Evil to you, then read on....

	dump 0usf /dev/rmt0 /dev/rrf0g

I post this to the net in the hopes it will save someone else from
nailing themselves to the cross like I did.  I am sure that more than
a few people will read this and say.

    "Oh sure, *I* knew that's what would happen.  Why didn't you:
	(a) RTFM (read the friendly manual) (b) be more careful."

Well, actually, I *did* just RTFM and then I made one simple little
error and Murphy stepped all over my file system.

In case you haven't already figured it out, the command in
question (dump 0usf /dev/rmt0 /dev/rrf0g) will wipe out the
file system residing on device /dev/rrf0g! (Yes, it really did...)

The problem is that the "s" flag is looking for a size specification for
the tape (which I accidently left out).  It apparently ate "/dev/rmt0"
and decided that it liked that just fine.  Next, the "f" flag says "Oh
boy! I get to do the dump TO /dev/rrf0g".  Now, it would have been nice
if dump had complained that I had not told it what device to dump FROM,
but Nnnoooooo, the manual says:

     " ... If no arguments are given, the key is assumed to be 9u and a
     default file system is dumped to the default tape.  ..."
     ^^^^^^^^^^^^^^^^^^^
The default on my system (an ISI box running 4.3) is /dev/rsd0g.  Since
this is a valid device on my system, dump promptly started dumping /usr
all over rrf0fg.

I saw right away that I had left the length off and interrupted the dump.
When I started it up again (with the length) it informed me that the
super-block was now caca and that I should run fsck with the -b switch.
I did this with -b 32 and -b 11600 and -b etc. etc. etc. sigh.
(Through no fault of my own, we did have a recent dump to restore from.)

In conclusion:
I *know* that being root is dangerous.  I just never expected that
I could *create* a dead file system by using dump!

I personally would like to see dump modified along these lines:

	1.	Not default *anything* (except, perhaps, dump TO tape).
	2.	Be pickier about what a valid numerical value is.
	3.	Require confirmation for dangerous target devices.
		(Such as mounted file systems or things in /etc/fstab.)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
"Providence Journal" virus
</A>
</H3>
<address>
Martin Minow THUNDR::MINOW ML3-5/U26 223-9922
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
18 May 88 12:18
</i><PRE>

On Tuesday, May 18, The Boston Globe business section included a column
(probably syndicated) called "Your Computer" written by John J. Xenakis
(1610 Worcester Road, Suite 629A, Framingham, MA  01701) that gave a
decent overview of the virus phenomena.

The same issue of the Globe (I think, I can't find it now) had an article
on a virus that attacked the newsroom computers at the Providence (RI) Journal.

This morning, WBUR radio broadcast a story on that virus.  These notes
were scribbled at the time:

  In an instant, a reporter lost weeks of work.  Their systems programmer
  used a special program to look at the disk.  He found "welcome to the
  dungeon -- beware of this virus" and three telephone numbers in Pakistan.
  One of them reached   a person who expressed suprise that the virus had
  gotten that far.

  Fred Cohen at the University of Cincinnati said that the virus reached
  Delaware [University of?] last year.  At least three others are on the
  loose.  The best advice is don't share disks.  Cohen also noted that
  the Macbug virus got into "legitimate distribution channels" so shrink-
  wrapped software might not be safe.  Also "viruses can mutate."

  The Journal's virus was found on disks in their news bureaus and on
  their employees' home computers.  Their systems programmer is afraid
  that, although they've gone through all their disks to elminate it,
  "a copy might be lurking in some desk drawer."

  This particular virus infects IBM PC's and clones.  You might consider
  buying an anti-viral program, but at least one is itself infected.

WBUR local news stories are often picked up by NPR, so you might keep an
ear open to All Things Considered and/or Weekend Edition.

This particular virus isn't new to RISKS readers.  What is interesting,
however, is that the part of the general public that reads the business
section and/or listens to public radio news is getting a reasonable education
in this field.

    [The NY Times of 25 May 1988 has an article in THE MEDIA BUSINESS, p.C18.
    The virus made its appearance when a financial reporter, Froma Joselow,
    saw the message "disk error" on her computer screen after she
    unsuccessfully tried to print out a copy of a news article she had been
    writing.  There was a virus program on her floppy, which caused this
    message on the screen: "Welcome to the Dungeon...  Beware of this VIRUS.
    Contact us for vaccination."  The message included an address and phone
    number of Brain Computer Services...  PGN]

PS: how can virus [programs] mutate?         

                 [Self-mutating, e.g, by adapting to their environments.  PGN]

    

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Stock market damping
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
24 May 88 13:26:14 EDT (Tue)
</i><PRE>
From: lsuc!dave@unix.SRI.COM (David Sherman)

Attempts to influence stock market trading patterns by taxing
short-term gains at higher rates aren't likely to have much effect.
Apart from the remoteness of the tax hit, bear in mind that the
traders who most influence the stock market are those who manage
the huge pension funds, which don't pay any income tax.

David Sherman   dave@lsuc.uucp
(Canadian tax lawyer)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Daedalus and the Thumb Card
</A>
</H3>
<address>
Dave Clayton (401) 792-2501 
&lt;<A HREF="mailto:LCO101%URIMVS.BITNET@MITVMA.MIT.EDU">
LCO101%URIMVS.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 25 May 88 15:42 EDT
</i><PRE>

It is quite frightening to contemplate a financial transaction system that
can be brought down by application of a bandaid to a paper cut on the
thumb--let alone the unthinkableness of losing a thumbnail.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Hinsdale
</A>
</H3>
<address>
John (J.G.) Mainwaring 
&lt;<A HREF="mailto:CRM312A%BNR.BITNET@CORNELLC.CCS.CORNELL.EDU">
CRM312A%BNR.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
25 May 88 11:07:00 EDT
</i><PRE>

There seems to have been a fair amount of high horsemanship in the
correspondance to date on the Hinsdale fire.  Perhaps it shows one of
the biggest potential risks associated with a disaster of this sort,
namely the oversimplified fixes that people not in a position to make
a full appraisal are likely to push on anyone who will listen.

The remark about the lack of operators in a modern central office is a case
in point.  I wonder how many people know the size of the installation
necessary to allow manual operators to handle a large enough fraction of the
traffic offered by tens of thousands of subscribers to make any difference?
In any case, such equipment was typically made of beautifully polished wood,
and would burn at least as well as an electronic switch, although the smoke
might be less toxic.

A good deal of criticism was leveled at cost cutting measures.  The phone
companies have been under intense pressure to cut costs.  The divestiture
decree was meant to cut costs by introducing competition.  As models of
efficiency the phone companies may have been matched only by the federal
government.  Some recent measures may have been misdirected, and much more
improvement remains possible.  However, there was no widespread campaign to
pay more for more reliable phone service.

Hopefully, the hub concept will be revised to provide diverse routing from
end offices to the rest of the network, in spite of the cost and network
management problems involved.  Perhaps cellular phones will be recognized as
a backup to the main network, with base station equipment separately located
and trunking to the land network carried over diverse routes.  Policies of
this sort are only likely to be instituted if the cost is included in the
rate base, and then only if there is widespread public acceptance of the
cost.

Another significant risk which undoubtedly exists in many situations is the
tendency for increases in computing power to decrease modular redundancy.
That which is cost effective is not necessarily cheap in small doses.  The
phone system is highly distributed, but the parts may not function well
independantly.  Each part of the system may strike the casual observer as
large in itself, not a small part of a whole.  In fact, each part is likely
to be duplicated, separately powered, and and redundantly connected to
duplicated sets of other key components.  For performance and logistic
reasons, the duplicated parts are not likely to be geographically dispersed.
In any case, the wires from your phone just go to one switch building, so
the benefits of dispersal of the switch remain academic.

We can all hope for lessons from the high level planning down to the the day
to day operational procedures that allowed the delay in summoning the fire
department.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.91.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.93.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-40</DOCNO>
<DOCOLDNO>IA012-000129-B046-208</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.93.html 128.240.150.127 19970217021539 text/html 29195
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:14:00 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 93</TITLE>
<LINK REL="Prev" HREF="/Risks/6.92.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.94.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.92.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.94.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 93</H1>
<H2>  Monday 30 May 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Westpac disaster revisited? 
</A>
<DD>
<A HREF="#subj1.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Telecommunications redundancy 
</A>
<DD>
<A HREF="#subj2.1">
Chris Maltby
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Plastic cash makes for a 'safe' society 
</A>
<DD>
<A HREF="#subj3.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Daedalus and Cash on Nail 
</A>
<DD>
<A HREF="#subj4.1">
Rudolph R. Zung
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  A Thumbnail Sketch of Daedalus: David E. Jones 
</A>
<DD>
<A HREF="#subj5.1">
John Saponara
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  More on programmed trading 
</A>
<DD>
<A HREF="#subj6.1">
Charles H. Buchholtz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Computers as a weapon ? 
</A>
<DD>
<A HREF="#subj7.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: risks of automatic test acknowledgement 
</A>
<DD>
<A HREF="#subj8.1">
Carl Gutekunst via Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  The Israeli Virus Bet Revisited 
</A>
<DD>
<A HREF="#subj9.1">
Y. Radai
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Westpac disaster revisited?
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 26 May 88 13:46:46 est
</i><PRE>

Readers with long memories will recall the disaster of Westpac Banking
Corporation (Australia) going "live" with an essentially untested system.

The May 23rd issue of Computing Australia has a brief report on their
new system, the Accounts Opening and Customer Information (AOCI) system
about to undergo three weeks of tests in Brisbane and Sydney.  The AOCI
system is part of a $120 million program to build a national, integrated
new-generation computer system [buzz-word generated?] called Core System
90 (CS90) for Westpac.

Strangely enough, the article does not mention the aforesaid disaster,
but one would hope this system will receive a lot more testing than the
last one did...  Stay tuned for further details.

Dave Horsfall (VK2KFU), Alcatel-STC Australia, dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET, ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Telecommunications redundancy
</A>
</H3>
<address>
Chris Maltby
&lt;<A HREF="mailto:munnari!softway.oz.au!chris@uunet.UU.NET ">
munnari!softway.oz.au!chris@uunet.UU.NET 
</A>&gt;
</address>
<i>
29 May 88 19:58:23 [GMT+1000] (Sun)
</i><PRE>
Organization: Softway Pty Ltd, Sydney, Australia

What no-one is talking about in the Chicago exchange fire is whether society
(i.e., the government) has a role in ensuring adequate redundancy in as
important a strategic network as the telephone system. The commercial decision
made by the telephone company to cut staff in exchange for the risk is just
that: a commercial decision. The decision to route all the trunks through the
same building is also a typical commercial decision. The result of a
concentration on getting the price down to compete in the market is a trade off
in services - and that means a much greater exposure to this sort of risk.

There is obviously a higher purpose which is being ignored in all this
commercialism, but just whose function is it to impose decent standards on the
poor old commercial phone companies. Should it be yet another government
regulatory bureaucracy, or should the phone companies be made liable for
damages caused by their failure to provide an essential service? Can we put up
with higher phone bills? Just who is benefitting out of all the phone company
cost cutting anyway?

This is all rather academic to me, as Australia has a centralised
government-owned phone company (which only last week was converted from a
statutory authority into a limited company). I think the issues are just as
important for Australia as well as the US, as we head away from the amorphous
Posts and Telegraphs Department system where the cost of a fully redundant
network was just absorbed, towards the strict focus on the bottom line.

Chris Maltby - Softway Pty Ltd    +61-2-698-2322

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Plastic cash makes for a 'safe' society
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 26 May 88 13:36:25 est
</i><PRE>

From "Computing Australia", 23rd May, 1988:

	"Plastic cash makes for a 'safe' society"

	A cashless society was a safer society, an expert on electronic
	funds transfer told last week's ANZAAS conference in Sydney.

	Marie Keir, from the secretariat of the Australian Science and
	Technology Council in Canberra, said EFT meant shop assistants
	were less vulnerable as they had little money in the cash register.

	"The amount of cash to be handled and transported safely has also
	been a high expense to retailers and banks," Keir said.  "EFTs
	have therefore been promoted as a form of payment to reduce
	handling costs.  The effect of these changes has been a movement
	to a society which is largely cashless; one which deals with
	electronic information instead of notes, cash and cheques.

All very laudable, but I'm concerned that this is one more excuse to
plunge headlong into a system with no standards, where the customer's
rights are ill-defined, and where naturally nothing can possibly go wrong,
go wrong, go wrong, go.....

Dave Horsfall (VK2KFU), Alcatel-STC Australia, dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET, ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Daedalus and Cash on Nail
</A>
</H3>
<address>
"Rudolph R. Zung" 
&lt;<A HREF="mailto:rz02+@andrew.cmu.edu">
rz02+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Thu, 26 May 88 13:28:43 -0400 (EDT)
</i><PRE>

Is this for real? I would hate to have my transactions limited by the
size of my nails. In case you haven't noticed: some people have really
short nails, and others have really long nail. People involved in
manual labor may also have their nails scratched. Oh my.

Anyway, a cashless transaction system is already in place in Singapore.
Interestingly enough, the government subsidised Post Office Savings Bank
(POSB, and somehow related to the Post Office, though I have no idea why
this is so) issues their own brand of ATM cards. Under the direction of the
government, they introduced cashless transactions.  Most of the major stores
in Singapore have a terminal for this service.  The total charges for
purchases and/or services are rung up, and punched into this machine. The
cashier then hands you a keypad (which has high sides to as to prevent
people from peeking at what you're typing in) and the keypad's display shows
you how much has been rung up. It also asks you "Account?" To which you tell
it whether you want to debit from your savings, checking or whatever
account. Having done that, it asks for "PIN?" (Personal Identification
Number). This is the same number that you would use to get money out of an
ATM.  I suppose this remote terminal thingy then calls up the bank and
verifies everything (just like an ATM probably would). It may sometimes
"Transaction Denied" (insufficient balance, cannot contact back's computer,
who knows) or "Transaction Approved", in which case the money is debitted
from your account immediately (again just like and ATM, except no money
comes out physically.) You then get your little receipt and everybody is
happy. Notice that the cashier does not get to find out what account you
paid from, nor your PIN. All the cashier knows is that you're using a bank
card to pay, and how much you paid for the purchase. It's very neat and
handy, and convenient.  I haven't heard of any frauds from using that system
so far, so I would assume that it is safe. (Standard ATM safeguards should
apply.)   ...Rue

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
A Thumbnail Sketch of Daedalus (Eric Haines)
</A>
</H3>
<address>
John Saponara
&lt;<A HREF="mailto:saponara@tcgould.TN.CORNELL.EDU ">
saponara@tcgould.TN.CORNELL.EDU 
</A>&gt;
</address>
<i>
Thu, 26 May 88 14:53:40 EDT
</i><PRE>

Organization: Cornell Theory Center, Cornell University, Ithaca NY

There seems to be a little confusion about whether the Daedalus column about
recording financial transactions on the thumbnail was a joke or not.  It was.

The author is actually David E. Jones, a freelance consultant who brainstorms
for a living.  He also writes the "Daedalus" column for "New Scientist"
magazine in Great Britain.  This column is usually about some strange,
humorous concept that his friend Daedalus is working on at the bustling,
mythical Dreadco research labs (whose motto is probably "A Growing Concern").

What's interesting is that about 17% of his ideas have been seriously studied
as possibilities by various groups.  For example, a method of building
prototypes based on shining UV light into a vat of photopolymer was just
described in the May 1988 issue of "Computer Graphics World".  This idea was
presented back in 1982 through "Daedalus".  Anyway, I highly recommend David
Jones' hilarious, thought provoking book "The Inventions of Daedalus", which
is a collection of these columns.

-- Eric Haines (not John Saponara, no matter what the mail header says)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
More on programmed trading
</A>
</H3>
<address>
Charles H. Buchholtz
&lt;<A HREF="mailto:chip@eniac.seas.upenn.edu ">
chip@eniac.seas.upenn.edu 
</A>&gt;
</address>
<i>
Thu, 26 May 88 03:48:57 edt
</i><PRE>

Since people are still talking about programmed trading, I thought I'd
pass this along.  When I first started reading about programmed
trading in RISKS, I asked a financial analyst friend of mine what she
thought.  She replied that there are (at least) two types of
programmed trading: arbitrage and portfolio insurance.  What follows
is my understanding based upon her comments; I hope that someone more
familiar with finance would correct my inevitable misconceptions.

Arbitrage involves monitoring two or more prices (usually of related
items in different markets), and responding quickly to small
fluctuations.  This acts as a stabilizing force in the market; when
price A drops relative to B, B is sold and A is bought, which acts to
raise the price of A and lower the price of B.  This is a computerized
application of the adage, "Buy low and sell high".

Portfolio insurance attempts to assure a reasonable rate of return on a
portfolio of diverse investments.  The portfolio insurance program sells
when the price drops, and buys when the price rises, in an attempt to get
out of failing markets and into rising ones.  This "Buy high and sell low"
philosophy acts to reinforce market movement.  It works as long as the
volumes traded are small enough not to effect the prices involved.  If too
much of the market is traded according to this system, chaos will result.

---Chip

Disclaimer:  U. of P. doesn't even know I'm writing this, and I'm sure
the folks at Wharton know much more about this than I do.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Computers as a weapon ?
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:nsc!taux01!taux01.UUCP!amos@Sun.COM ">
nsc!taux01!taux01.UUCP!amos@Sun.COM 
</A>&gt;
</address>
<i>
26 May 88 14:18:03 GMT
</i><PRE>

The computerized roadside ambush operation  to catch tax evaders was not
designed especially for  the occupied territories; it  started in Israel
itself a few years  ago. Its main goal is to  catch businesses without a
formal address, such as free-lance taxi drivers, etc.

All the sources of risk presented in  the article as aspects of 'life in
an occupied land' (such as  the connections among government data bases,
and the  requirement to carry an  id card), are also  imposed on Israeli
citizens. Many western democracies use similar methods.

Amos Shapir, National Semiconductor (Israel)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Risks of automatic test acknowledgement
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Wed, 11 May 88 17:50:32 EDT
</i><PRE>
Originally-from: Carl S. Gutekunst

The unmoderated nature of Usenet sometimes leads to people doing silly
and destructive things, but the following, I think, is a new one.

There is a newsgroup "misc.test" on Usenet for test postings, as well as a
variety of local-area or restricted-distribution newsgroups that are used
for the same purpose whenever such distribution will suffice for what is
being tested.  Now, many sites operate automatic acknowledging programs that
attempt to send mail to anyone posting an article in these groups, so that
the poster knows where their test message reached.

With this build-up, you can probably guess what's coming.  The following
article was posted by Carl S. Gutekunst:

&gt;A 2300-line message was posted to misc.test (and cross posted to talk.bizarre)
&gt;by 22116@pyr1.acs.udel.EDU that refers to itself as the "misc.test digest." It
&gt;contains the complete text of all the misc.test messages posted within the
&gt;past month or so, a total of 107 articles. This awesomely stupid menuever was
&gt;topped by pst@comdesign.UUCP reposting the same message to alt.test. 
&gt;
&gt;The posting of two 68 Kbyte messages to test groups is trivial compared to the
&gt;effect of all the echo reflectors out there. Every one is forwarding the damn
&gt;postings back to the sender. Worse, at least one standard reflector script,
&gt;Erik Fair's, echos mail to *EVERY* "Path:" line in the test article. Since the
&gt;article contains 109 Path lines, we mailed the 68K posting to all 109 of them!
&gt;
&gt;We have broken the UUCP link to comdesign, and are trashing every copy of the
&gt;test message that we can find. Unfortunately, nearly all of them already went
&gt;out during the night, and we apologize to all of you who found this monster in
&gt;your inbox this morning. Other sites, especially those running echo reflec-
&gt;tors, should survey their own spool partitions and squash as many of these as
&gt;they can. 

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
    The Israeli Virus Bet Revisited
</A>
</H3>
<address>
Y. Radai 
&lt;<A HREF="mailto:RADAI1%HBUNOS.BITNET@CORNELLC.CCS.CORNELL.EDU">
RADAI1%HBUNOS.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
Mon,  30 May 88 17:32:51 +0300
</i><PRE>

   This is to report on the results of the "virus bet" which was made on an
Israeli television program at the beginning of April (see RISKS 6.62).  Although
the outcome was already announced in RISKS 6.84 by Amos Shapir, the story is
much more involved than what was described there.  (In fact, it was not quite
accurate to describe the outcome as a draw.)  Since I think the details will be
of interest to some readers, I am offering the following more complete report.

   As will be recalled, the bet originated when a pair of students, Yuval Rakavy
and Omri Mann, who had previously written and freely supplied software to de-
tect, prevent, and eradicate the four known viruses which had invaded IBM PCs in
Israel, had now written a program which they claimed could detect infection of a
disk by *any* virus under PC-DOS or MS-DOS.  Interviewed on television on April
4, they were unexpectedly confronted by the director of an established software
house, who challenged the students to a bet on the correctness of their claim,
for an amount equivalent to about $6200.  Since the names of the persons and
companies involved are unlikely to be of much interest to the non-Israeli read-
er, I shall refer to the authors of the program as the "defender" and to the
challenging director as the "attacker".
   In the agreement which was drawn up on April 27 between the two parties it
was stated that the defender "claims that he has a method of detecting the
propagation of any virus", where a virus is "software that reproduces within a
computer and between computers."  The attacker, on the other hand, "claims that
the method which [the defender] presented is not good against every virus."
Both parties were required to submit to the referees by May 4 flowcharts and
written descriptions of their algorithms.  The attacker had also been supplied
on April 10 with a Beta version of the defender's program (in non-disassemble-
able form).
   Unfortunately, certain key points were not spelled out in the agreement.
First, the terms 'method', 'detection', 'propagation' and 'reproduction' were
not defined, and the correctness of the claims could depend on the meanings
assigned to these terms.
   More important, it was not specified in the agreement precisely what would
have to occur in order for the referees to declare that the attacker or the
defender had won the bet.  Presumably it would be agreed that if the defender's
method failed (due to a shortcoming of the method as opposed to a mere bug in
the program) to detect the propagation of one of the attacker's viruses, it
should be concluded that the defender had lost.  On the other hand, even if the
defender's program succeeded in detecting propagation of all viruses submitted
by the attacker, this would not prove that "he has a method of detecting the
propagation of *any* virus".  Taken literally, it would seem that the defender
had no possibility of winning.  Of course, the reasonable position would be to
declare the defender victorious in such a case.
   However, the situation was complicated by the introduction of a theoretical
aspect.  The defender's insistence on the word 'method', rather than 'program'
or 'software', in the agreement was partly in order to express the fact that the
Beta version of his program might contain a bug, and partly in order to justify
submission of a theoretical proof that the method on which his program is based
guarantees detection of the propagation of any virus under certain specified
assumptions.
   Just how submission of this proof affected the criterion for victory is not
spelled out in the agreement.  Did the defender's proof have to be certified as
correct and complete in order for him to win?  Did he have to win on *both* the
empirical and theoretical fronts or on only one of them?  Was it possible that
*both* parties could be declared losers?  I think that if an effort had been
made to obtain agreement on these and all similar questions in advance, the bet
would have been much fairer, and perhaps one of the parties might even have de-
cided that there was no point in continuing with the bet.
   In any case, when the attacker's viruses were tested, their propagation was
detected by the defender's program in every case.  However, the outcome, as
decided by the two referees on May 8, was not only that the attacker had lost,
but so had the defender!  (The referees emphasize that this is *not* the same as
a draw.)  Their arguments were as follows:
   On the one hand, they admitted that under certain conditions users of the
defender's method "indeed gain a defense which makes it difficult for viruses to
penetrate the system" and that the attacker "did not succeed in proving unambi-
guously that the *method* which [the defender] presented is not good against
every virus."
   On the other hand, they contend that the defender's claim is substantiated
"at most in a work environment which is very restricted and limited by heavy
constraints" and that the viruses created by the attacker "were very effective,
and succeeded in penetrating the defense ... in situations in which not all the
(generally impractical) safety rules required for protecting the system were ob-
served."  And what are these impractical rules?  The only clue we get to this is
in the following passage: "... only immediately after booting ..., could a long
series of operations be performed without fear of infection by a virus ...."
   However, rebooting is recommended in the defender's method (in certain situa-
tions) only in order to *prevent* infection, whereas the subject of the bet was
*detection* of infection.  And even if rebooting were necessary for purposes of
detection, while this would certainly be an extremely important *practical* con-
sideration, for purposes of the *bet* it would be entirely irrelevant.  I there-
fore find the referees' mention of this point in their decision to be extremely
peculiar.
   Another passage in the referees' decision which is quite peculiar is as
follows:  "There is, in our humble opinion, at least one method which can breach
the defense ... and due to lack of time and lack of will to create a virus, we
have declined to implement it."  Just what this method is they categorically
refuse to state, not only in their public decision but even privately to the
defender.  (Imagine a trial in which a judge admitted that the prosecution had
produced no valid evidence, but nevertheless found the defendant guilty on the
grounds that the judge claimed to possess evidence of his own which he refused
to reveal!)  Under the circumstances the referees' declaration remains complete-
ly unsubstantiated and can hardly serve as a legitimate basis for a judgment
against the defender.
   A point which apparently influenced the referees strongly was the fact that
after the agreement was signed, the defender modified his program, not only to
fix what were clearly bugs, but also (in the referees' words) to make a change
"in the region between correction of a programming error and updating of the de-
fense method" in order to detect a certain type of virus (one which depends on a
certain peculiarity of DOS which I shall not reveal here); as a result the pro-
gram detected propagation of one of the attacker's viruses that would otherwise
have gone undetected.  The referees state that "this process [of improving the
program each time a new virus goes undetected] is, in our opinion, infinite".
On the other hand, the defender states that he thought of this improvement him-
self and not as a result of the attacker's virus, and he claims that it does not
constitute a change in his *method*.  Whether this is correct or not depends on
what is meant by a 'method'.  In any case, the defender replaced his software on
May 4, the day on which the two parties were required to present their flow-
charts and algorithms and the attacker to present his viruses.  Given this fact,
it seems to me that even if this is construed as a change in method, this should
not have counted against the defender.
   The referees conclude:  "The declaration that it is possible to detect *any*
virus is irresponsible, borders on misleading the public, and stems perhaps from
a naivety according to which the mechanisms of action of a virus must fulfill a
set of assumptions which [the defender] makes, assumptions which were not always
found to be justified."
   Here there is much to comment on.  This is the only place where the referees
(apparently) refer to the defender's proof.  However, they do not point to any
error in any step of that proof.  I would understand if they expressed skepti-
cism concerning the defender's claim that he supplied an airtight proof covering
all possible cases.  However, their complaint is with the assumptions.  But
*which* particular assumptions are "not always justified"?  *Why* are they un-
justified?  On these questions the referees remain as silent as on their myster-
ious method for breaching the defense.  Moreover, it is not at all clear on what
basis it could be decided that a given assumption is not justified, considering
that many of the assumptions are simply part of the defender's method.
   Secondly, the charges of irresponsibility and misleading the public (the
phrase sounds as if such action was deliberate and malicious, and was played up
by the press) are extremely harsh under the circumstances; not only has it not
been demonstrated that the defender's claim is false, but even if this is as-
sumed for sake of argument, the referees themselves admit that the defender's
claim may stem from mere naivety.  Taken together with the previously mentioned
peculiarities, these charges raise a certain suspicion that the referees were
not entirely objective in their decision.  It must be added that they tried to
dissuade the defender from accepting the bet in the first place.  Given their
approach, this was certainly fair on their part.  However, there is reason to
suspect that once the defender declined their advice, the negative verdict was
practically determined in advance.
   Incidentally, I attempted to interview one of the referees, both in order to
obtain an explication of what precisely would have had to occur in order to
decide that the defender had won (if indeed there was any such possibility!) and
also in order to obtain their reactions to the peculiarities mentioned above.
However, he was very uncooperative, refusing to elaborate on anything beyond
what was printed in the official decision.
   In conclusion, I think that there was much injustice in the decision, and
yet much was learned from the challenge, not only in perfecting the defense
against less obvious types of viruses, but also in revealing the RISKS involved
should anyone else feel inclined to take on a challenge of this sort (cf.
Dennis Director's invitation in RISKS 6.79).

Y. Radai, Computation Center, Hebrew Univ. of Jerusalem, RADAI1@HBUNOS.BITNET

P.S. The opinions expressed above on the referees' decision are based on the
evidence available to me at the time of writing.  Moreover, they do not
necessarily reflect those of the Hebrew University or of anyone other than
myself.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.92.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.94.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-41</DOCNO>
<DOCOLDNO>IA012-000129-B046-241</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/6.02.html 128.240.150.127 19970217021553 text/html 18561
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:14:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 6: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/6.01.html">
<LINK REL="Up" HREF="/Risks/index.6.html">
<LINK REL="Next" HREF="/Risks/6.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/6.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 6: Issue 2</H1>
<H2> Monday, 4 January 1987 </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Source Code is Counter to Viruses &amp; Trojan Horses 
</A>
<DD>
<A HREF="#subj1.1">
Hal Guthery
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Viral VAXination? 
</A>
<DD>
<A HREF="#subj2.1">
Bryce Nesbitt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Who is entitled to privacy? 
</A>
<DD>
<A HREF="#subj3.1">
Andy Freeman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  SSN / Passport / IRS ... 
</A>
<DD>
<A HREF="#subj4.1">
Joe Morris
</A><br>
<A HREF="#subj4.2">
 Don Wegeng
</A><br>
<A HREF="#subj4.3">
 Jean Marie Diaz
</A><br>
<A HREF="#subj4.4">
     Martin Minow
</A><br>
<A HREF="#subj4.5">
 Brint Cooper
</A><br>
<A HREF="#subj4.6">
 EAE114
</A><br>
<A HREF="#subj4.7">
 John Pershing
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Source Code is Counter to Viruses &amp; Trojan Horses
</A>
</H3>
<address>
"guthery%asc@sdr.slb.com" 
&lt;<A HREF="mailto:GUTHERY%ASC%sdr.slb.com@RELAY.CS.NET">
GUTHERY%ASC%sdr.slb.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Mon, 4 Jan 88 07:51 EDT
</i><PRE>
To: risks@csl.sri.com

As a little bit of reflection about the fact that almost all computers have
clocks in them will show, there is no protection in trying programs out with 
write-only harddisks or with privileges turned off.  Doing this only sets
the hook deeper.  In fact, anytime you run a program whose complete 
workings you do not and cannot understand you are at the mercy of the author
of the program and you are at risk.

One very good way to counter viruses and trojan horses is to insist on getting
the source code of any program you run.  This is summarized in the following 
pocketsize adage:

		     IF YOU CAN'T READ IT, DON'T RUN IT

There are NO good reasons why software vendors shouldn't give you the source
code of any program they sell you.  The reason they don't currently is because
you could see what a mess the program really is.  In 999 cases out of 1,000
they don't know everything the program does and they certainly don't want you
looking over the code and telling them.

For a moment stop and think of all the execute only software you run on
your system.  Think of all the companies from whom you purchased this
software.  Think of all the pressure you put on them for bug fixes, new
features, and lower prices.  Think about the translation of these pressures
into pressures on programmers.  Suppose one of these programmers decides to
get just a little even ...  an occassional bad number, a lost record once a 
month, a couple pennies moved from here to there just for fun, a scrambled
directory entry once in a blue moon.  If the program does what it purports 
to do, where is the check?  The project leader?  The manager?  The president?
The venture capitalist?  You?  And who is responsible?  You!  And what can 
you do with a bunch of object code?  Turn off the harddisk?  Scan the program
for strings?  Deny privileges?  Piece of cake!

We are marginally able to answer the question "Does this piece of software
do what I want it to do?" but we are absolutely incapable of answering
the much more important question "Does this piece of software NOT do what 
I don't want it to do?"  Through this gaping hole in our capabilities enter 
viruses and trojan horses.  It is historically interesting that I can get a 
handle on the first question without the source code but I can get nowhere 
on the second without it.  As long as we willing to accept programs from 
software suppliers without the source code we, irresponsibly in my view, 
accept undue risk and invite disaster.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Viral VAXination? (Re: RISKS-6.1)
</A>
</H3>
<address>
Bryce Nesbitt
&lt;<A HREF="mailto:bryce%hoser.Berkeley.EDU@ucbvax.Berkeley.EDU ">
bryce%hoser.Berkeley.EDU@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 4 Jan 88 07:52:09 GMT
Organization: The Logic Foundation

&gt;      (Martin Minow THUNDR::MINOW ML3-5/U26 223-9922)  writes:
&gt;
&gt;Could a "harmless"  CHRISTMA-like virus attack a VAX/VMS system?   A
&gt;recent network posting (RISKS?, LINKFAIL?) mentioned the possibility of a
&gt;virus  hidden in SHAR files which are _executed_ as .COM  files to unpack
&gt;them.

I'm surprised nobody has mentioned this:  Around here we don't "execute"
shar files to unpack them.  Instead there is a handly little utility called
"unshar".  I use a version on both Unix and my Amiga microcomputer.  It
internally handles all of the "legitimate" commands that a simple file packing
shar might contain (echo, wc, cat, if, test, #, exit, etc.).

It is much less vulnerable to attack.  To use the example of the poster, unshar
would simple report "unknow command" if a "SET PROC/PRIV=ALL" was quietly 
inserted in the middle of the file.

The comp.sources.unix and comp.sources.misc archives undoubtably have C
source code for the taking.

bryce@hoser.berkeley.EDU -or- ucbvax!hoser!bryce (or try "cogsci")

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Who is entitled to privacy?
</A>
</H3>
<address>
Andy Freeman 
&lt;<A HREF="mailto:ANDY@Sushi.Stanford.EDU">
ANDY@Sushi.Stanford.EDU
</A>&gt;
</address>
<i>
Thu 31 Dec 87 14:36:48-PST
</i><PRE>
To: risks@csl.sri.com

[BTW - What happens if I send mail to risks-list@kl.sri.com?]

The recent controversy over access to financial records of companies
(the companies want to control it and some find this offensive) is
somewhat similar to the continuing furor over records about people,
except that popular opinion in the latter case is that the people
should be able to control information about themselves.

Is there an essential difference here and what is it?  Is the corner
gas station entitled to more privacy than IBM?  Why?  Are all the
corner gas stations entitled to more privacy than IBM?  (The former
group is comparable in size to IBM.)

Note that in the current case, companies collected the information
about themselves while in most privacy invasion cases, the person
doesn't collect the information.  If one is going to argue on property
rights alone, these companies are entitled to control access while
people in the other case aren't.
                                            -andy

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
SSN Required Disclosures
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>

</i><PRE>
Date: Mon, 04 Jan 88 16:27:05 EST
From: Joe Morris (jcmorris@mitre.arpa) &lt;jcmorris@mitre.arpa&gt;

In RISKS 6:1, David Albert reports that a post office clerk claims that the
disclosure of your SSN is no longer "optional" on the passport applications.
I can't say whether or not it is required, but the clerk is out of line in
any case.  The law on disclosure requirements is unusally direct:

  o The law prohibits any Federal, State, or local government entity
    (supposedly including related entities like State-suppported 
    universities) from denying any benefit or service because you
    didn't give your SSN, with certain specified exceptions.  These
    exceptions  are generally (a) where tax matters are involved; 
    (b) for a driver's license, and (c) in  certain cases where there
    was a pre-existing *legislative* requirement for the SSN.

  o Whenever a governmental organization requests the SSN, whether it is
    required or optional, you *must* be given what is called the "Privacy
    Act Notification".  This must tell you:

      (a) whether the request for the SSN is mandatory or optional;
      (b) what will happen if you don't give it;
      (c) under what authority it is being requested; and
      (d) what will be done with the information being requested.

    The Federal income tax forms you just received last week contain
    a good example of a well-constructed, complete Privacy Act Notification.
    (I knew that the IRS had to be good for something!)

  o There are no restrictions placed on the private sector governing the
    request for your SSN.

In other words, the passport application should have included a Privacy Act
notification, regardless of whether the SSN was optional or required.

After writing the above, I called the Department of State to see what they
had to offer.  According to the Passport Office, the SSN *is* required, as
of this morning (1/4/88); supposedly the Privacy Act Notification is on the
back of the application.  The DoS staffer I talked to insisted that
applications prior to today didn't require the SSN to be provided.

I assume that an application without the SSN would merely be returned; I
can't see them fining you for not completing the form.

Incidentally, does anyone in NetLand know of any case law covering the
SSN requests?  In particular, I'm interested in whether there have been
any cases involving state universities.  Although I wasn't involved, a  
friend was told by the legal office of his state university employer that
the law didn't apply to educational institutions, even if they were
funded by the state.  On the other hand, seeing how poorly the legislature
funded that university, maybe the lawyer had a point...
                                                            Joe Morris

</PRE>
<HR><H3><A NAME="subj4.2">
Re: SSN Required Disclosures
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
4 Jan 88 18:37:09 EST (Monday)
</i><PRE>
To: RISKS@KL.SRI.COM
From: Don Wegeng &lt;Wegeng.Henr@Xerox.COM&gt;

I saw a short article on this subject last week in one of the Rochester, NY
newspapers (I can probably find it at home if anyone wants a more specific
reference). As I recall, the article stated that the IRS is having problems
tracking down American citizens living abroad who don't file income tax
returns, so a law was passed which requires passport applicants to give
their SSN. The article didn't mention a fine, but stated that until new
application forms are available applicants who do not give their SSN will
probably be contacted for this information by the IRS.

It appears that the IRS and the INS are going to start sharing information,
undoubtably by connecting their computers in some way. The potential RISKS
in this have been discussed in this forum many times.
                                                              /Don

     [Also noted by Roy Maxion.  The following messages, for those of you who
     haven't already given up on RISKS-6.2, relate further to this topic.  This
     is a very popular subject, and it keeps flaring up spontaneously in RISKS.
     Thus I tend to be tolerant for a while, but then &lt;once again&gt; wish to slow
     it down.  The following flurry of messages is an effort in that direction 
     rather than an encouragement to stimulate it further.  PGN]

</PRE>
<HR><H3><A NAME="subj4.3">
Re: mother's maiden name
</A>
</H3>
<address>
Jean Marie Diaz 
&lt;<A HREF="mailto:ambar@ATHENA.MIT.EDU">
ambar@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Sun, 3 Jan 88 04:04:11 EST
</i><PRE>
Reply-To: ambar@athena.mit.edu
Usnail: 55 Grove St., Somerville, MA  02144
Nynex: (617) 623-6591

Funny, I was opening a checking account today, and noticed that question
for the first time.  When I asked why they asked, I was told that it was
wanted "in case the bank wanted to verify who I was".  (In case of an
accident that cripples my writing hand?  Well, maybe...)

On a related note, someone can call BayBanks and make various inquiries
about my account, and even change the address to which my statements are
mailed, by knowing my account number and the amount &amp; date of my last
deposit.  Sounds tricky enough?  Not for those of us who use Direct
Deposit to handle our paychecks...
                    				AMBAR

</PRE>
<HR><H3><A NAME="subj4.4">
Mother's maiden name?
</A>
</H3>
<address>
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
3 Jan 88 11:47
</i><PRE>

Why does American Express want to know your mother's maiden name?
When my pocket was picked two years ago, and my AmEx card, passport,
cash, and travellers checks stolen, AmEx (Paris) asked the obvious
questions plus my mother's maiden name.  As I understand it, it's
something you generally know, but the thief (who has your name, address,
phone number, SSnumber, and a lot of other information) probably doesn't
know.  AmEx (or whoever) is assuming the risk of giving a new card out
to an unknown person who might not have *any* identification at all,
and they evidently feel that this simple "password" is an authenticator
with a reasonable level of risk.

Incidently, AmEx lived up to its advertisements.  The U.S. embassy in Paris
managed to get me a replacement passport at 1 pm on a Saturday even though I
had absolutely no identification.  The embassy officer even lent me $10 so I
could take a photo and metro to my luggage (and money stash).  If I remember
correctly, they did ask for a mother's maiden name (or similar).
                                                                     Martin

</PRE>
<HR><H3><A NAME="subj4.5">
 [Henry Mensch: American Express security ...]
</A>
</H3>
<address>
Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.ARPA">
abc@BRL.ARPA
</A>&gt;
</address>
<i>
Sun, 3 Jan 88 13:12:06 EST
</i><PRE>

    [Coincidentally, Steve Anthony &lt;Anthony@ALDERAAN.SCRC.Symbolics.COM&gt;
    asked Why are Mother's Maiden Names Required?  PGN]

In registering patients for the first time, the Johns Hopkins Hospital
in Baltimore asks for Mother's maiden name as well.  This and other
information is factored into an algorithm for assigning a patient
identification number.  The hope is that by using such information, the
probability of two patients being assigned the same number is acceptably low.

Why not just assign numbers sequentially?  Inevitably, someone loses
their plate.  JHH wants to be able to retrieve their records by
reconstructing the number, if necessary.  Assigning a second number
would mean that the patient has two incomplete sets of medical records
in the hospital.  Some physicians would know the old number, others the
new.  Imagine what a malpractice lawyer would do with that!

</PRE>
<HR><H3><A NAME="subj4.6">
AM/EX AND MAIDEN NAMES
</A>
</H3>
<address>
&lt;<A HREF="mailto:EAE114%URIMVS.BITNET@CUNYVM.CUNY.EDU">
EAE114%URIMVS.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 04 Jan 88 10:07 EST
</i><PRE>

When you're filling out the forms, it helps if you remember that the
MOTHER's MAIDEN NAME is essentially a password.  
          [and therefore subject to all of the problems of passwords...  PGN]
There is no particular reason why you have tell the truth, as long as you
remember what you DID say.

</PRE>
<HR><H3><A NAME="subj4.7">
  American Express security ...
</A>
</H3>
<address>
John Pershing 
&lt;<A HREF="mailto:PERSHNG@ibm.com">
PERSHNG@ibm.com
</A>&gt;
</address>
<i>
4 Jan 88 08:49:17 EST
</i><PRE>

    From: Henry Mensch &lt;henry@garp.mit.edu&gt;
    Does this mean that anyone who knows a bit about me can get my AmEx
    plate, too?

No, it merely means that anyone who knows a bit about you can get a new
AmEx card mailed to your house.  (Of course, there's nothing preventing
someone who knows your card number from sending AmEx a change of address
notification, and then requesting a new card!  However, this might raise
some eyebrows over at AmEx...)

Remember, too, that AmEx is liable for any fraud that is perpetrated in this
way.  They are taking a calculated risk -- trying to make life as painless
as possible for their cardholders while maintaining a sensible amount of
security.  It has always seemed to me that AmEx strikes an extremely
reasonable balance in this respect.
                                     John A. Pershing Jr., IBM Yorktown Heights

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/6.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.6.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/6.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-42</DOCNO>
<DOCOLDNO>IA012-000129-B046-287</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/8/index.html 128.240.150.127 19970217021617 text/html 80807
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:14:36 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Index to Volume 8</TITLE>
<LINK REL="Pref" HREF="/Risks/7/index.html">
<LINK REL="Next" HREF="/Risks/9/index.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/9/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Index to Volume 8</H1>
<H2> Friday 30 June 1989  </H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------">
<DL>
<DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.1.html">Volume 8 Issue 1 (4 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.1.html#subj1">  A Danish Home Companion (Hugh Miller)</A>
<LI><A HREF="/Risks/8.1.html#subj2">  Tales from the Vincennes tape (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.1.html#subj3">  Suit filed to force FBI to enforce privacy provisions of ECPA (John Gilmore)</A>
<LI><A HREF="/Risks/8.1.html#subj4">  moRe: Armed with a keyboard ... -- Kevin Mitnick (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.1.html#subj5">  Computer Chaos Congress 88 report (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/8.1.html#subj6">  Two steps forward, one step back (Jerry Leichter)</A>
<LI><A HREF="/Risks/8.1.html#subj7">  Clapham Junction train crash (Clive Feather via Mark Brader)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.2.html">Volume 8 Issue 2 (4 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.2.html#subj1">  Christmas 1988 Decnet Worm -- Counteracted (Cliff Stoll)</A>
<LI><A HREF="/Risks/8.2.html#subj2">  Vincennes and the computer (Steve Philipson, Clifford Johnson)</A>
<LI><A HREF="/Risks/8.2.html#subj3">  Viruses and System Security (a story) (by Dave Platt,    submitted to RISKS from rec.humor.funny by Jim Horning and Mark Brader)
</A>
<LI><A HREF="/Risks/8.2.html#subj4">  Stallman, Minsky and Drescher on the Internet Worm (via Martin Minow)</A>
<LI><A HREF="/Risks/8.2.html#subj5">  FAA Orders Computer Card Security Systems at 270 Airports (Henry Mensch)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.3.html">Volume 8 Issue 3 (8 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.3.html#subj1">  Computer-related accidental death (Gegg)</A>
<LI><A HREF="/Risks/8.3.html#subj2">  Re: Danish Home Companion, Kierkegaard, and Feynman (David E. Leasure)</A>
<LI><A HREF="/Risks/8.3.html#subj3">  "NO CARRIER" (Jef Poskanzer via David Sherman)</A>
<LI><A HREF="/Risks/8.3.html#subj4">  Re: Tales from the Vincennes tape (Maj. Doug Hardie)</A>
<LI><A HREF="/Risks/8.3.html#subj5">  "Hand-written" letters (Gary Chapman)</A>
<LI><A HREF="/Risks/8.3.html#subj6">  Dark Side Hacker, an Electronic Terrorist (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.3.html#subj7">  The risks of trusting CBS (Phil Goetz)</A>
<LI><A HREF="/Risks/8.3.html#subj8">  Hackers - pure and simple (Travis Marlatte)</A>
<LI><A HREF="/Risks/8.3.html#subj9">  Viruses of all kinds (Travis Marlatte)</A>
<LI><A HREF="/Risks/8.3.html#subj10">  Henry Cox's "Supercomputer used to `solve' math problem" (John C. Bazigos)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.4.html">Volume 8 Issue 4 (11 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.4.html#subj1">  M1 Plane crash (Nigel Roberts)</A>
<LI><A HREF="/Risks/8.4.html#subj2">  $4.5 M Child Support Computer to be Scrapped in VA (Dave Davis)</A>
<LI><A HREF="/Risks/8.4.html#subj3">  Eelskin wallets erase mag strips? (Jane D. Smith)</A>
<LI><A HREF="/Risks/8.4.html#subj4">  Firearms Arrive in the Electronics Age (Allen)</A>
<LI><A HREF="/Risks/8.4.html#subj5">  Unused city computer system set aside after 4 years, $4M (Stephen W. Thompson)</A>
<LI><A HREF="/Risks/8.4.html#subj6">  Re: Hackers' Conference versus CBS (John Gilmore)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.5.html">Volume 8 Issue 5 (11 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.5.html#subj1">  Digital Photos and the Authenticity of Information (Dave Robbins)</A>
<LI><A HREF="/Risks/8.5.html#subj2">  Medical software (Ivars Peterson via Robert Morris)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.6.html">Volume 8 Issue 6 (12 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.6.html#subj1">  Computers and Civil Liberties, article by Gary Marx (Ronni Rosenberg)</A>
<LI><A HREF="/Risks/8.6.html#subj2">  Losing systems (Vince Manis)</A>
<LI><A HREF="/Risks/8.6.html#subj3">  Our blinders [with respect to RISKS] (Don Alvarez)</A>
<LI><A HREF="/Risks/8.6.html#subj4">  Totally secure MAIL &amp; infallible aeroplane warning systems (Nigel Roberts)</A>
<LI><A HREF="/Risks/8.6.html#subj5">  "Disaster Becomes a Matter of Routine" (Steve Philipson)</A>
<LI><A HREF="/Risks/8.6.html#subj6">  Re: Biased coverage of hacker's convention by CBS (Richard Thomsen)</A>
<LI><A HREF="/Risks/8.6.html#subj7">  SAFECOMP89 (Udo Voges)</A>
<LI><A HREF="/Risks/8.6.html#subj8">  Name this book -- for a box of cookies! (Cliff Stoll)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.7.html">Volume 8 Issue 7 (15 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.7.html#subj1">  Re: Medical Software (Are computer risks different?) (Jon Jacky)</A>
<LI><A HREF="/Risks/8.7.html#subj2">  Ground proximity warning (Bill Standerfer via Mark Brader)</A>
<LI><A HREF="/Risks/8.7.html#subj3">  Aircraft (Dale Worley)</A>
<LI><A HREF="/Risks/8.7.html#subj4">  You don't know what you've got till it's gone.  (Phil Agre)</A>
<LI><A HREF="/Risks/8.7.html#subj5">  Data integrity (Brent Laminack)</A>
<LI><A HREF="/Risks/8.7.html#subj6">  Quality of Evidence (Bill Murray)</A>
<LI><A HREF="/Risks/8.7.html#subj7">  D.Robbins' conclusions (Authenticity of Information) (Allan Pratt)</A>
<LI><A HREF="/Risks/8.7.html#subj8">  Risks of trusting the press (Brad Templeton)</A>
<LI><A HREF="/Risks/8.7.html#subj9">  Risks of Remote Student Registration: Another Interaction Story     (Gary McClelland)
</A>
<LI><A HREF="/Risks/8.7.html#subj10">  Medical information systems (Jerry Harper)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.8.html">Volume 8 Issue 8 (15 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.8.html#subj1">  Re: Losing systems -- and Structured Programming (Bruce Karsh)</A>
<LI><A HREF="/Risks/8.8.html#subj2">  Ethics of the Internet - Request for Comments (Cliff Stoll)</A>
<LI><A HREF="/Risks/8.8.html#subj3">  Chaos Computer Congress 1988 -- Documentation (Klaus Brunnstein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.9.html">Volume 8 Issue 9 (17 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.9.html#subj1">  Re: Structured Programming (Jim Horning, Steve Bellovin, Brian M. Clapper)</A>
<LI><A HREF="/Risks/8.9.html#subj2">  Re: Losing Systems (David Marks)</A>
<LI><A HREF="/Risks/8.9.html#subj3">  A risk averted (Gideon Yuval)</A>
<LI><A HREF="/Risks/8.9.html#subj4">  Re: M1 Crash -- Risks of misunderstood statistics (Jordan Brown)</A>
<LI><A HREF="/Risks/8.9.html#subj5">  Hacker wants to marry his computer (Cliff Stoll)</A>
<LI><A HREF="/Risks/8.9.html#subj6">  Hackers break open US bank networks (Dave Horsfall)</A>
<LI><A HREF="/Risks/8.9.html#subj7">  National Research Network (Brad Blumenthal)</A>
<LI><A HREF="/Risks/8.9.html#subj8">  Once-writable storage (Steve Philipson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.10.html">Volume 8 Issue 10 (18 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.10.html#subj1">  Speak nicely to your air hostess - or be blacklisted... (HCART)</A>
<LI><A HREF="/Risks/8.10.html#subj2">  (Too) Intelligent Network News mailing (Ralph A. Shaw)</A>
<LI><A HREF="/Risks/8.10.html#subj3">  Information protection in Europe (Steve Bellovin)</A>
<LI><A HREF="/Risks/8.10.html#subj4">  Re: Losing systems -- and Structured Programming     (Henry Spencer, Lynn R Grant, Steven C. Den Beste)
</A>
<LI><A HREF="/Risks/8.10.html#subj5">  Re: Ground proximity warning (Henry Spencer)</A>
<LI><A HREF="/Risks/8.10.html#subj6">  WORM storage and archival records (RAMontante)</A>
<LI><A HREF="/Risks/8.10.html#subj7">  Re: 3 vs. 2 engined airplanes (Steve Jay)</A>
<LI><A HREF="/Risks/8.10.html#subj8">  Re: Hackers break open US bank networks (Jan Wolitzky)</A>
<LI><A HREF="/Risks/8.10.html#subj9">  Evidence (Bill Murray)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.11.html">Volume 8 Issue 11 (19 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.11.html#subj1">  Risks of no backup systems for critical applications (Yoram Eisenstadter)</A>
<LI><A HREF="/Risks/8.11.html#subj2">  Computer malfunction downs traffic lights, one killed, one injured    (Scott Campbell)
</A>
<LI><A HREF="/Risks/8.11.html#subj3">  Chaos Theory Predicts Unpredictability (PGN)</A>
<LI><A HREF="/Risks/8.11.html#subj4">  China accused of software piracy (PGN)</A>
<LI><A HREF="/Risks/8.11.html#subj5">  Friday the 13th Again (PGN)</A>
<LI><A HREF="/Risks/8.11.html#subj6">  Computer error locks out politicians (D. Steele)</A>
<LI><A HREF="/Risks/8.11.html#subj7">  Re: Losing Systems (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/8.11.html#subj8">  Technical brilliance v. commercial acumen (Jerry Harper)</A>
<LI><A HREF="/Risks/8.11.html#subj9">  National Credit Information Network (Sidney Marshall)</A>
<LI><A HREF="/Risks/8.11.html#subj10">  Re: Ethics of the Internet (John Gilmore)</A>
<LI><A HREF="/Risks/8.11.html#subj11">  RISKs of reading newspapers: Credit card fraud is not hacking. (Mike Van Pelt)</A>
<LI><A HREF="/Risks/8.11.html#subj12">  Counting engines (Don Alvarez)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.12.html">Volume 8 Issue 12 (20 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.12.html#subj1">  Risk of using your own name (Gary T)</A>
<LI><A HREF="/Risks/8.12.html#subj2">  Risks in NBS time by radio (computer malfunction downs lights) (Clements)</A>
<LI><A HREF="/Risks/8.12.html#subj3">  Computer-related accidents in British chemical industry (Jon Jacky)</A>
<LI><A HREF="/Risks/8.12.html#subj4">  Re: Losing Systems (Henry Spencer, Donald Lindsay, Keane Arase)</A>
<LI><A HREF="/Risks/8.12.html#subj5">  Failure of Software Projects (WHMurray)</A>
<LI><A HREF="/Risks/8.12.html#subj6">  Re: Structured Programming (David Collier-Brown, Jerry Schwarz)</A>
<LI><A HREF="/Risks/8.12.html#subj7">  Discrete probability and airplanes (Mike Olson)</A>
<LI><A HREF="/Risks/8.12.html#subj8">  Re: Chaos theory (Phil Goetz)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.13.html">Volume 8 Issue 13 (22 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.13.html#subj1">  Gigabit superhighway/worms (Vint Cerf)</A>
<LI><A HREF="/Risks/8.13.html#subj2">  IAB Ethics DRAFT (Vint Cerf)</A>
<LI><A HREF="/Risks/8.13.html#subj3">  Space shuttle computer problems, 1981--1985 (Jon Jacky)</A>
<LI><A HREF="/Risks/8.13.html#subj4">  F-16 that can't stall falls from sky (Scot E Wilcoxon)</A>
<LI><A HREF="/Risks/8.13.html#subj5">  Re: China accused of software piracy (Jim Olsen)</A>
<LI><A HREF="/Risks/8.13.html#subj6">  Losing systems (Dale Worley, Chris Lewis)</A>
<LI><A HREF="/Risks/8.13.html#subj7">  Re: Structured Programming (John Mainwaring, Mark Rosenstein, Steve Pozgaj)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.14.html">Volume 8 Issue 14 (24 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.14.html#subj1">  Re: Medical Software -- testing and verification (Dave Parnas)</A>
<LI><A HREF="/Risks/8.14.html#subj2">  NSA and the Internet (Vint Cerf)</A>
<LI><A HREF="/Risks/8.14.html#subj3">  Re: Losing systems (Geoff Lane)</A>
<LI><A HREF="/Risks/8.14.html#subj4">  Computer Emergency Response Team (CERT) (Brian M. Clapper)</A>
<LI><A HREF="/Risks/8.14.html#subj5">  Probability and Product Failure (Geoff Lane)      [lack of independence]</A>
<LI><A HREF="/Risks/8.14.html#subj6">  Probabilities and airplanes (Robert Colwell, Mike Olson, Dale Worley)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.15.html">Volume 8 Issue 15 (25 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.15.html#subj1">  More video piracy (Dave Curry)</A>
<LI><A HREF="/Risks/8.15.html#subj2">  Computerized records of employee informers (Mike Trout)</A>
<LI><A HREF="/Risks/8.15.html#subj3">  Censorship and computers (Anthony Finkelstein)</A>
<LI><A HREF="/Risks/8.15.html#subj4">  Re: Object Oriented Programming (Benjamin Ellsworth)</A>
<LI><A HREF="/Risks/8.15.html#subj5">  Structuring large systems (John Spragge)</A>
<LI><A HREF="/Risks/8.15.html#subj6">  About non-redundant redudant systems (Elizabeth D. Zwicky)</A>
<LI><A HREF="/Risks/8.15.html#subj7">  Engine-count and the Spirit of St. Louis (Michael McClary)</A>
<LI><A HREF="/Risks/8.15.html#subj8">  Counting engines (Jordan Brown)</A>
<LI><A HREF="/Risks/8.15.html#subj9">  Re: Space shuttle computer problems, 1981--1985 (Henry Spencer)</A>
<LI><A HREF="/Risks/8.15.html#subj10">  Revised Computer Ethics Course Proposal (Bob Barger)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.16.html">Volume 8 Issue 16 (26 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.16.html#subj1">  Cable video piracy (anonymous)</A>
<LI><A HREF="/Risks/8.16.html#subj2">  F-111 downed by EMI? (Gordon Davisson)</A>
<LI><A HREF="/Risks/8.16.html#subj3">  F-16 that can't stall falls from sky (Mike Tanner)</A>
<LI><A HREF="/Risks/8.16.html#subj4">  Re: Probability and Product Failure [common mode failures] (Bruce Hamilton)</A>
<LI><A HREF="/Risks/8.16.html#subj5">  Discrete probability and airplanes (Dave Settle)</A>
<LI><A HREF="/Risks/8.16.html#subj6">  Micro-cellular phones (Steven C. Den Beste)</A>
<LI><A HREF="/Risks/8.16.html#subj7">  Looking for Computer Folklore (Karla Jennings via Vernard C. Martin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.17.html">Volume 8 Issue 17 (27 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.17.html#subj1">  ELIZA and Joe Weizenbaum (Bard Bloom)</A>
<LI><A HREF="/Risks/8.17.html#subj2">  Savings, Loans, and Easy Money (PGN)</A>
<LI><A HREF="/Risks/8.17.html#subj3">  Risks of inept management ["Losing Systems"] (John R. Levine)</A>
<LI><A HREF="/Risks/8.17.html#subj4">  MIT Athena Kerberos Authentication System available for FTP     (John Kohl via Jon Rochlis)
</A>
<LI><A HREF="/Risks/8.17.html#subj5">  Single-engine planes (Phil Karn)</A>
<LI><A HREF="/Risks/8.17.html#subj6">  Multi-engine airplanes (Craig Smilovitz)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.18.html">Volume 8 Issue 18 (30 Jan 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.18.html#subj1">  Hong Kong computer horse betting (George Moore)</A>
<LI><A HREF="/Risks/8.18.html#subj2">  Keycard badges vs. anti-shoplift systems (Bruce Hamilton)</A>
<LI><A HREF="/Risks/8.18.html#subj3">  Bank Fraud (Peter Golde)</A>
<LI><A HREF="/Risks/8.18.html#subj4">  Crashing a PDP-11/40 (Computer Folklore) (Jeff Makey)</A>
<LI><A HREF="/Risks/8.18.html#subj5">  Sprint to the Finish? (Steve Philipson)</A>
<LI><A HREF="/Risks/8.18.html#subj6">  Information Security/Computer Crime Statistics (Stan Stahl)</A>
<LI><A HREF="/Risks/8.18.html#subj7">  Re: ELIZA and Joe Weizenbaum (Bernie Cosell, Bob Krovetz)</A>
<LI><A HREF="/Risks/8.18.html#subj8">  Virus conference hosts software swap meet (Robert Lee Wilson Jr)</A>
<LI><A HREF="/Risks/8.18.html#subj9">  Structured Programs, Project Failures (Charles J. Wertz)</A>
<LI><A HREF="/Risks/8.18.html#subj10">  Losing Systems (Mike Albaugh)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.19.html">Volume 8 Issue 19 (1 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.19.html#subj1">  Massachusetts limits disclosure of driver's license database. (Jon Jacky)</A>
<LI><A HREF="/Risks/8.19.html#subj2">  Dead Code Maintenance (Douglas Jones)</A>
<LI><A HREF="/Risks/8.19.html#subj3">  Re: Structured Programming (Eric Roskos)</A>
<LI><A HREF="/Risks/8.19.html#subj4">  Random Thoughts on Redundancy (Earl Boebert)</A>
<LI><A HREF="/Risks/8.19.html#subj5">  One last word about probabilities (Dr Robert Frederking)</A>
<LI><A HREF="/Risks/8.19.html#subj6">  Independence and probabilities (PGN)</A>
<LI><A HREF="/Risks/8.19.html#subj7">  Counting Engines (Mike Bell)</A>
<LI><A HREF="/Risks/8.19.html#subj8">  Talk by Roy Saltman on computerized vote tallying (Charles Youman)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.20.html">Volume 8 Issue 20 (5 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.20.html#subj1">  FAA and flying under pressure in Alaska (PGN)</A>
<LI><A HREF="/Risks/8.20.html#subj2">  New use for Credit Cards (?) (Leslie Chalmers)</A>
<LI><A HREF="/Risks/8.20.html#subj3">  Computer Chaos in Burnaby (Stuart Lynne)</A>
<LI><A HREF="/Risks/8.20.html#subj4">  Swedish fighter plane crash (Otto J. Makela)</A>
<LI><A HREF="/Risks/8.20.html#subj5">  Re: Massachusetts limits disclosure of driver's license database.    (Jerome H Saltzer)
</A>
<LI><A HREF="/Risks/8.20.html#subj6">  "Computer Literacy Education" Report Available (Ronni Rosenberg)</A>
<LI><A HREF="/Risks/8.20.html#subj7">  Engineering vs. Programming (Lynn R Grant)</A>
<LI><A HREF="/Risks/8.20.html#subj8">  Re: Structured Programming (Al Arsenault, Allen Gordon, Dan Franklin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.21.html">Volume 8 Issue 21 (5 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.21.html#subj1">  `User friendliness' tradeoffs can lead to total nonsecurity (Eric S. Raymond)</A>
<LI><A HREF="/Risks/8.21.html#subj2">  Capturing a password (Phil Karn)</A>
<LI><A HREF="/Risks/8.21.html#subj3">  Collisions in DES (Jean-Jac. Quisquater) </A>
<LI><A HREF="/Risks/8.21.html#subj4">  Re: Crashing a PDP-11/40 [static electricity] (Jeffrey Mogul)</A>
<LI><A HREF="/Risks/8.21.html#subj5">  ATM error (Douglas Jones)</A>
<LI><A HREF="/Risks/8.21.html#subj6">  Anecdotes: ping-pong robot; CCC breaks net (Konrad Neuwirth)</A>
<LI><A HREF="/Risks/8.21.html#subj7">  Request for information:  Health Hazards of Office Laser Printers    (Keith Dancey)
</A>
<LI><A HREF="/Risks/8.21.html#subj8">  Re: Structured Programming (Michael J. Chinni)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.22.html">Volume 8 Issue 22 (8 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.22.html#subj1">  B-1B bomber avionics problems (Jon Jacky)</A>
<LI><A HREF="/Risks/8.22.html#subj2">  Risks of public terminal rooms (Roy Smith)</A>
<LI><A HREF="/Risks/8.22.html#subj3">  Using barcodes for road toll payments (Phillip Herring)</A>
<LI><A HREF="/Risks/8.22.html#subj4">  ATM error - in Europe (John O'Connor)</A>
<LI><A HREF="/Risks/8.22.html#subj5">  Computing as a Discipline (Peter J. Denning)</A>
<LI><A HREF="/Risks/8.22.html#subj6">  Cryptic status displays, and GIGO (Mark Brader)</A>
<LI><A HREF="/Risks/8.22.html#subj7">  Re: `User friendliness' and forgotten root passwords     (Shannon Nelson, Ge' Weijers, smv)
</A>
<LI><A HREF="/Risks/8.22.html#subj8">  Health Hazards of Office Laser Printers (Hal Murray, Jeffrey Mogul)</A>
<LI><A HREF="/Risks/8.22.html#subj9">  Re: Keycard badges vs. anti-shoplift systems (Craig Leres)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.23.html">Volume 8 Issue 23 (9 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.23.html#subj1">  Self-Taught Space Craft (Brian Randell)</A>
<LI><A HREF="/Risks/8.23.html#subj2">  Still a few bugs in the system, as they say (Mark Brader)</A>
<LI><A HREF="/Risks/8.23.html#subj3">  Multi-gigabuck information "theft" (Mark Brader)</A>
<LI><A HREF="/Risks/8.23.html#subj4">  Risks of letting key people leave employment? (David A. Curry)</A>
<LI><A HREF="/Risks/8.23.html#subj5">  Phone Risks (Greeny)</A>
<LI><A HREF="/Risks/8.23.html#subj6">  Virus Technical Review (David J. Ferbrache)</A>
<LI><A HREF="/Risks/8.23.html#subj7">  Re: WORM storage and archival records (Curtis Abbott)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.24.html">Volume 8 Issue 24 (13 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.24.html#subj1">  Massive counterfeit ATM card scheme foiled (Rodney Hoffman, PGN)</A>
<LI><A HREF="/Risks/8.24.html#subj2">  Computer blamed for 911 system crash (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.24.html#subj3">  Risks of Selective Service (Rob Elkins)</A>
<LI><A HREF="/Risks/8.24.html#subj4">  Re: Engines and probabilities (Barry Redmond, Robert Frederking)</A>
<LI><A HREF="/Risks/8.24.html#subj5">  Re: Structured programming (Jim Frost)</A>
<LI><A HREF="/Risks/8.24.html#subj6">  Re: Engineering vs. Programming     (John Dykstra, Henry Spencer, Robert English, Shawn Stanley)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.25.html">Volume 8 Issue 25 (14 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.25.html#subj1">  Authenticity in digital media -- electronic time travel (Steve Philipson)</A>
<LI><A HREF="/Risks/8.25.html#subj2">  Bogus Frequent Flyer Scheme (Kenneth R. Jongsma [and Dave Curry])</A>
<LI><A HREF="/Risks/8.25.html#subj3">  Automatic targeting for Maverick missile (Jon Jacky)</A>
<LI><A HREF="/Risks/8.25.html#subj4">  Economics, Engineering and Programming (Jerry Leichter)</A>
<LI><A HREF="/Risks/8.25.html#subj5">  RE: ATM Error in Europe (Udo Voges)</A>
<LI><A HREF="/Risks/8.25.html#subj6">  Another bank error (Hsiu-Teh Hsieh)</A>
<LI><A HREF="/Risks/8.25.html#subj7">  Static Electricity crash (Seth K)</A>
<LI><A HREF="/Risks/8.25.html#subj8">  Legal clamp-down on Australian "hackers" (Neil Crellin)</A>
<LI><A HREF="/Risks/8.25.html#subj9">  MIT virus paper available for anonymous ftp (Jon Rochlis)</A>
<LI><A HREF="/Risks/8.25.html#subj10">  Prospectus for "Computer Viruses" (J Cordani)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.26.html">Volume 8 Issue 26 (15 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.26.html#subj1">  "$15 Million Computer Dud Baffles Udall" (Joseph M. Beckman)</A>
<LI><A HREF="/Risks/8.26.html#subj2">  Re: Computer blamed for 911 system crash (Rodney Hoffman, Paul Blumstein)</A>
<LI><A HREF="/Risks/8.26.html#subj3">  Selling who-called-the-800-number data (Bob Ayers)</A>
<LI><A HREF="/Risks/8.26.html#subj4">  PIN?  Who needs a PIN? (Alan Wexelblat)</A>
<LI><A HREF="/Risks/8.26.html#subj5">  Door Sensors and Kids (Eddie Caplan)</A>
<LI><A HREF="/Risks/8.26.html#subj6">  Risks of misunderstanding probability and statistics (Tom Blinn)</A>
<LI><A HREF="/Risks/8.26.html#subj7">  Why you can't "flip" bits on a WORM disc (Daniel Ford)</A>
<LI><A HREF="/Risks/8.26.html#subj8">  Credit Checker &amp; Nationwide SS# Locate (David Andrew Segal)</A>
<LI><A HREF="/Risks/8.26.html#subj9">  Re: Authenticity in digital media (Pete Schilling)</A>
<LI><A HREF="/Risks/8.26.html#subj10">  Re: multi-gigabuck information "theft" (Jeff Makey)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.27.html">Volume 8 Issue 27 (16 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.27.html#subj1">  FBI NCIC Data Bank (Bob Morris)</A>
<LI><A HREF="/Risks/8.27.html#subj2">  Internet mail forgery (Walter Roberson)</A>
<LI><A HREF="/Risks/8.27.html#subj3">  Re: Dead code maintenance (Clifford Johnson)</A>
<LI><A HREF="/Risks/8.27.html#subj4">  Probabilities and Engines (Steve Philipson, Robert Dorsett, Daniel A. Graifer)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.28.html">Volume 8 Issue 28 (19 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.28.html#subj1">  Continuing problems with WWMCCS command-and-control network (Jon Jacky)</A>
<LI><A HREF="/Risks/8.28.html#subj2">  US missile-warning radar endangers friendly aircraft (Jon Jacky)</A>
<LI><A HREF="/Risks/8.28.html#subj3">  Power failure problems (John Sinteur)</A>
<LI><A HREF="/Risks/8.28.html#subj4">  The Risks of Going on Vacation (Jim Carson)</A>
<LI><A HREF="/Risks/8.28.html#subj5">  Re: Faking Internet mail (Peter Scott)</A>
<LI><A HREF="/Risks/8.28.html#subj6">  Multi-gigabuck value of information theft denied (Mark Brader)</A>
<LI><A HREF="/Risks/8.28.html#subj7">  Re: multi-gigabuck information "theft" (David Chase)</A>
<LI><A HREF="/Risks/8.28.html#subj8">  Re: Authenticity in digital media (Doug Krause)</A>
<LI><A HREF="/Risks/8.28.html#subj9">  Digital doctoring of images (Richard Wiggins)</A>
<LI><A HREF="/Risks/8.28.html#subj10">  PIN?  Who needs a PIN?  (Bill Mahoney)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.29.html">Volume 8 Issue 29 (22 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.29.html#subj1">  Overloaded computer delays (overworked) commuters (Steve Graham)</A>
<LI><A HREF="/Risks/8.29.html#subj2">  Chicago Phone Freak Gets Prison Term (Patrick Townson via Cliff Stoll)</A>
<LI><A HREF="/Risks/8.29.html#subj3">  Computer Confinement (Joseph M. Beckman)</A>
<LI><A HREF="/Risks/8.29.html#subj4">  Police officers sentenced for misuse of PNC (Nigel Roberts)</A>
<LI><A HREF="/Risks/8.29.html#subj5">  The word "virus" causes panic (Nigel Roberts)</A>
<LI><A HREF="/Risks/8.29.html#subj6">  Re: Faking Internet mail (Steve Bellovin, Kevin S. McCurley)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.30.html">Volume 8 Issue 30 (24 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.30.html#subj1">  "Do you know who's reading your medical records?" (PGN)</A>
<LI><A HREF="/Risks/8.30.html#subj2">  Wells Fargo ATM outage (PGN)</A>
<LI><A HREF="/Risks/8.30.html#subj3">  New York 540 Phone Number Scam (John Murray)</A>
<LI><A HREF="/Risks/8.30.html#subj4">  900 "confession" number (Randal L. Schwartz)</A>
<LI><A HREF="/Risks/8.30.html#subj5">  Re: Chicago Phone Freak Gets Prison Term (Rich Salz)</A>
<LI><A HREF="/Risks/8.30.html#subj6">  Reach Out and Spy on Someone (Peter Scott)</A>
<LI><A HREF="/Risks/8.30.html#subj7">  Power failure problems (Jonathan I. Kamens)</A>
<LI><A HREF="/Risks/8.30.html#subj8">  Photographs as evidence (re: digital editing, etc.) (Ernest H. Robl)</A>
<LI><A HREF="/Risks/8.30.html#subj9">  Stanford and rec.humor.funny (Martin Minow)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.31.html">Volume 8 Issue 31 (27 Feb 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.31.html#subj1">  Bank fraud was "easy" (Stephen Page)</A>
<LI><A HREF="/Risks/8.31.html#subj2">  Men accused of `hacker' crime (Michael C Polinske)</A>
<LI><A HREF="/Risks/8.31.html#subj3">  Stanford bboard censorship (Les Earnest, John McCarthy, Jerry Hollombe)</A>
<LI><A HREF="/Risks/8.31.html#subj4">  Computer writing coach / friend (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.31.html#subj5">  British Computer Society policy on safety-critical systems (Martyn Thomas)</A>
<LI><A HREF="/Risks/8.31.html#subj6">  Reach out and spy (gls)</A>
<LI><A HREF="/Risks/8.31.html#subj7">  Risks of Running a Hotel (Chuck Weinstock)</A>
<LI><A HREF="/Risks/8.31.html#subj8">  Singing in the Rain (Kent Borg)</A>
<LI><A HREF="/Risks/8.31.html#subj9">  [RISKS BARFMAIL] (PGN)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.32.html">Volume 8 Issue 32 (1 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.32.html#subj1">  RISKS-LIST: On Risks of Running RISKS (PGN)</A>
<LI><A HREF="/Risks/8.32.html#subj2">  Gripen prototype crash (Dave Newkirk, Kenneth R. Jongsma, Karl Lehenbauer)</A>
<LI><A HREF="/Risks/8.32.html#subj3">  A pilot's account of a multi-engine failure (Karl Lehenbauer)</A>
<LI><A HREF="/Risks/8.32.html#subj4">  Knowing probability just doesn't make a difference (Sumit Dongre)</A>
<LI><A HREF="/Risks/8.32.html#subj5">  A new ATM risk: bureaucracy (Laura Halliday)</A>
<LI><A HREF="/Risks/8.32.html#subj6">  IBM's claims for error-free code (Robert Lee Wilson Jr)</A>
<LI><A HREF="/Risks/8.32.html#subj7">  Re: discussion of computer viruses (Brent Laminack)</A>
<LI><A HREF="/Risks/8.32.html#subj8">  Re: [RISKS BARFMAIL] (Robert J. Reschly Jr.)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.33.html">Volume 8 Issue 33 (2 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.33.html#subj1">  Viruses and the comics (Jack Holleran, Hope Munro)</A>
<LI><A HREF="/Risks/8.33.html#subj2">  Hacking in the movies -- Working Girl (Martin Minow)</A>
<LI><A HREF="/Risks/8.33.html#subj3">  Re: British Computer Society policy statement (Clifford Johnson)</A>
<LI><A HREF="/Risks/8.33.html#subj4">  Hacking and Computer Fraud in the U.K. (Brian Foster)</A>
<LI><A HREF="/Risks/8.33.html#subj5">  Re: Knowing probability just doesn't make a difference... (Henry Spencer)</A>
<LI><A HREF="/Risks/8.33.html#subj6">  Reach Out and Spy on Someone (Pete McVay, Douglas Jones, Emily Lonsford)</A>
<LI><A HREF="/Risks/8.33.html#subj7">  New Sprint Card (Will Martin)</A>
<LI><A HREF="/Risks/8.33.html#subj8">  US missile-warning radar endangers friendly aircraft (Ken Arnold)</A>
<LI><A HREF="/Risks/8.33.html#subj9">  Error free code and ancient systems (Bill Francis)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.34.html">Volume 8 Issue 34 (2 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.34.html#subj1">  German hackers breaking into LOS ALAMOS, NASA,...(Claus Kalle via Mabry Tyson)</A>
<LI><A HREF="/Risks/8.34.html#subj2">  The Gumbel Machine Becomes a Candid Camera (PGN)</A>
<LI><A HREF="/Risks/8.34.html#subj3">  (Un)fairness in European s/w protection (Herman J. Woltring)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.35.html">Volume 8 Issue 35 (6 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.35.html#subj1">  NASA to replace top-level personnel with Expert Systems (Dave Davis)</A>
<LI><A HREF="/Risks/8.35.html#subj2">  A Touching Faith in Technology (Ruaridh Macdonald)</A>
<LI><A HREF="/Risks/8.35.html#subj3">  Computer catches thief (Randall [!] Davis)</A>
<LI><A HREF="/Risks/8.35.html#subj4">  Computer espionage: 3 `Wily Hackers' arrested (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/8.35.html#subj5">  Re: West German Hackers (Dana Kiehl)</A>
<LI><A HREF="/Risks/8.35.html#subj6">  The word "hacking" (Geoffrey Knauth, Rao V. Akella)</A>
<LI><A HREF="/Risks/8.35.html#subj7">  747 Simulators Can't Simulate Flight 811 Failures (Scot E Wilcoxon)</A>
<LI><A HREF="/Risks/8.35.html#subj8">  Viruses in the comics (Peter Merel, Tom Parker, Len Levine, Guy Robinson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.36.html">Volume 8 Issue 36 (7 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.36.html#subj1">  Malicious Hacking (Gene Spafford)</A>
<LI><A HREF="/Risks/8.36.html#subj2">  News from the KGB/Wily Hackers (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/8.36.html#subj3">  The fight to purify the word "hacker" is lost (Steve Bellovin, Brad Templeton)</A>
<LI><A HREF="/Risks/8.36.html#subj4">  Dangers of Spy programs (John ffitch)</A>
<LI><A HREF="/Risks/8.36.html#subj5">  Re: reach out and spy on someone (Vandenberg)</A>
<LI><A HREF="/Risks/8.36.html#subj6">  Social effects of viruses (Don Alvarez)</A>
<LI><A HREF="/Risks/8.36.html#subj7">  Previous message to RISKS misunderstood (John Sinteur)    [Power failure problems]
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.37.html">Volume 8 Issue 37 (11 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.37.html#subj1">  Computer blunders blamed for massive student loan losses (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.37.html#subj2">  Prisoner access to confidential drivers' records (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.37.html#subj3">  Ethics Question (Randall Neff)      </A>
<LI><A HREF="/Risks/8.37.html#subj4">  Risk of congenial machinery (Robert Steven Glickstein)</A>
<LI><A HREF="/Risks/8.37.html#subj5">  Limitless ATM's (Geoff Kuenning)</A>
<LI><A HREF="/Risks/8.37.html#subj6">  Re: Faking internet mail (Stephen Wolff)</A>
<LI><A HREF="/Risks/8.37.html#subj7">  Virus detector goes wrong (Dave Horsfall)</A>
<LI><A HREF="/Risks/8.37.html#subj8">  Re: News from the KGB/Wily Hackers (Hans Huebner = `pengo')</A>
<LI><A HREF="/Risks/8.37.html#subj9">  UK archive service [for European RISKS readers] (Dave Ferbrache)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.38.html">Volume 8 Issue 38 (15 Mar 89 )</A>
<DD><UL>
<LI><A HREF="/Risks/8.38.html#subj1">  Water Bug - Computerization Messing Up Yacht Race (Robert Horvitz)</A>
<LI><A HREF="/Risks/8.38.html#subj2">  Sunspots &amp; Communications (Cliff Stoll, PGN)</A>
<LI><A HREF="/Risks/8.38.html#subj3">  pengo and the Wily hackers (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/8.38.html#subj4">  Toshiba DOS 3.3 Backup deletes files (Fiona M Williams)</A>
<LI><A HREF="/Risks/8.38.html#subj5">  Star Trek computer virus (Kevin Rushforth)</A>
<LI><A HREF="/Risks/8.38.html#subj6">  Re: NASA to replace top-level personnel with Expert Systems (Henry Spencer)</A>
<LI><A HREF="/Risks/8.38.html#subj7">  Pushbutton Banking (Lynn R Grant)</A>
<LI><A HREF="/Risks/8.38.html#subj8">  Risks of telephone access to your bank account (Michael McClary)</A>
<LI><A HREF="/Risks/8.38.html#subj9">  Limitless ATMs (John Murray)</A>
<LI><A HREF="/Risks/8.38.html#subj10">  Re: Prisoner access to confidential drivers' records (Scot E Wilcoxon)</A>
<LI><A HREF="/Risks/8.38.html#subj11">  Risks of Human Emulating Machinery (Jon Loux)</A>
<LI><A HREF="/Risks/8.38.html#subj12">  New Sprint Card (Ken Harrenstien)</A>
<LI><A HREF="/Risks/8.38.html#subj13">  Incoming-call identification (David Albert)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.39.html">Volume 8 Issue 39 (16 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.39.html#subj1">  Solar flares vs. garage door openers (Steve Bellovin, Peter Scott)</A>
<LI><A HREF="/Risks/8.39.html#subj2">  Sunspots and Power Lines (John Coughlin)</A>
<LI><A HREF="/Risks/8.39.html#subj3">  Man-machine interfaces and perception-impaired people (David A. Honig)</A>
<LI><A HREF="/Risks/8.39.html#subj4">  Re: reverse engineering of type fonts (Herman J. Woltring)</A>
<LI><A HREF="/Risks/8.39.html#subj5">  Re: Ethics Question (Marc Mengel)</A>
<LI><A HREF="/Risks/8.39.html#subj6">  Re: Toshiba DOS 3.3 Backup deletes files (Jay Elinsky)</A>
<LI><A HREF="/Risks/8.39.html#subj7">  Re: IBM's claims to omnipotence (Dr Robert Frederking)</A>
<LI><A HREF="/Risks/8.39.html#subj8">  Re: Pushbutton Banking (Tom Coradeschi)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.40.html">Volume 8 Issue 40 (17 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.40.html#subj1">  Re: Sunspots &amp; Communications (Jordan Brown, Gasbarro)</A>
<LI><A HREF="/Risks/8.40.html#subj2">  Ethics of Copying Fonts (Jerry Schwarz)</A>
<LI><A HREF="/Risks/8.40.html#subj3">  Policy Statement Request (Dave Grisham)</A>
<LI><A HREF="/Risks/8.40.html#subj4">  Re: Incoming-call identification (Brint Cooper)</A>
<LI><A HREF="/Risks/8.40.html#subj5">  Risks of telephone access to your bank account (Brint Cooper)</A>
<LI><A HREF="/Risks/8.40.html#subj6">  Limitless ATMs (Emily H. Lonsford)</A>
<LI><A HREF="/Risks/8.40.html#subj7">  Re: A Touching Faith in Technology (Henry Spencer)</A>
<LI><A HREF="/Risks/8.40.html#subj8">  Risks of helpfulness (Henry Spencer)</A>
<LI><A HREF="/Risks/8.40.html#subj9">  Work monitoring survey (Goun)</A>
<LI><A HREF="/Risks/8.40.html#subj10">  Faking Internet mail (Robert C. Lehman)</A>
<LI><A HREF="/Risks/8.40.html#subj11">  Spying on or intercepting UUCP mail (David Sherman)</A>
<LI><A HREF="/Risks/8.40.html#subj12">  Hackers, cartoons, and computers (Doug Claar)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.41.html">Volume 8 Issue 41 (20 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.41.html#subj1">  20+ year, $100+ million Army software project (Jon Jacky)</A>
<LI><A HREF="/Risks/8.41.html#subj2">  Formal methods to be applied in Australian railroad switching (Jon Jacky)</A>
<LI><A HREF="/Risks/8.41.html#subj3">  Error in updating new specifications for call-routing (Pertti Jarvinen)</A>
<LI><A HREF="/Risks/8.41.html#subj4">  Risks of Registering Shareware (A. Lester Buck)</A>
<LI><A HREF="/Risks/8.41.html#subj5">  Risks of helpfulness (Jerome H Saltzer)</A>
<LI><A HREF="/Risks/8.41.html#subj6">  Remote Smart-Cards (Ian W Moor)</A>
<LI><A HREF="/Risks/8.41.html#subj7">  Re: so-called multi-gigabuck theft of information (Mark Brader)</A>
<LI><A HREF="/Risks/8.41.html#subj8">  Re: NASA to replace top-level personnel with Expert Systems (Robert English)</A>
<LI><A HREF="/Risks/8.41.html#subj9">  Meter Readers an Endangered Species? (David K. Black)</A>
<LI><A HREF="/Risks/8.41.html#subj10">  Security of Electronic Mail (Karl Lehenbauer)</A>
<LI><A HREF="/Risks/8.41.html#subj11">  Star Trek computer virus (Colin P.)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.42.html">Volume 8 Issue 42 (20 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.42.html#subj1">  Automatic Caller Identification (Phil R. Karn, Robert Goldman, John Murray,    Bernie Cosell, Karl Lehenbauer, Dean Riddlebarger, Mark Mandel, Phil R.
    Karn again, Benjamin Ellsworth, more or less chronologically)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.43.html">Volume 8 Issue 43 (21 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.43.html#subj1">  Outdated codes made US missiles useless (Henry Cox)</A>
<LI><A HREF="/Risks/8.43.html#subj2">  Risks of dying batteries (Henry Cox)</A>
<LI><A HREF="/Risks/8.43.html#subj3">  Things to do with a computer... (Joe Morris)</A>
<LI><A HREF="/Risks/8.43.html#subj4">  Possible Cancer Risks from Cellular Phones? (Mike Trout)</A>
<LI><A HREF="/Risks/8.43.html#subj5">  Supreme Court and Copyrights (ark)</A>
<LI><A HREF="/Risks/8.43.html#subj6">  Mitnick plea bargain (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.43.html#subj7">  Re: Risks of telephone access to your bank account (Phil R. Karn)</A>
<LI><A HREF="/Risks/8.43.html#subj8">  Internet Security Plans (Vin McLellan)</A>
<LI><A HREF="/Risks/8.43.html#subj9">  Duplicates due to network lossage? (*Hobbit*)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.44.html">Volume 8 Issue 44 (21 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.44.html#subj1">  Computer-Justified Citations (Kevin Driscoll)</A>
<LI><A HREF="/Risks/8.44.html#subj2">  Vehicle ID tags, cont'd (Steve Smaha)</A>
<LI><A HREF="/Risks/8.44.html#subj3">  Ethics question re fonts (Michael Harrison, Elliott S Frank)</A>
<LI><A HREF="/Risks/8.44.html#subj4">  Risks of shirt-pocket size floppy disks (Roy Smith)</A>
<LI><A HREF="/Risks/8.44.html#subj5">  Re: Pushbutton Banking (Robert English)</A>
<LI><A HREF="/Risks/8.44.html#subj6">  Credit card magstripe-encoded pictures (Peter Scott)</A>
<LI><A HREF="/Risks/8.44.html#subj7">  Re: Remote Smart-Cards, English and Welsh soccer (Craig Cockburn, Dick King)</A>
<LI><A HREF="/Risks/8.44.html#subj8">  Re: Risks of Registering Software (Bill Murray)</A>
<LI><A HREF="/Risks/8.44.html#subj9">  Collecting for Shareware (Bill Murray)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.45.html">Volume 8 Issue 45 (25 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.45.html#subj1">  Wells Fargo Deposits Slip (PGN)</A>
<LI><A HREF="/Risks/8.45.html#subj2">  Hospital Viruses (Dennis Steinauer and Joe Morris)</A>
<LI><A HREF="/Risks/8.45.html#subj3">  Optical Scanning of Handwritten Purchase Orders (Hiram Clawson)</A>
<LI><A HREF="/Risks/8.45.html#subj4">  Credit card magstripe-encoded pictures (Mike Trout)</A>
<LI><A HREF="/Risks/8.45.html#subj5">  Cellular phones and health (anonymous, Dale Worley, R. Scott Truesdell)</A>
<LI><A HREF="/Risks/8.45.html#subj6">  New method (risk) of demagnetizing floppies (Douglas B. Robinson)</A>
<LI><A HREF="/Risks/8.45.html#subj7">  Microwave ovens (Don Chiasson)</A>
<LI><A HREF="/Risks/8.45.html#subj8">  Corrections to Internet Security Plans (David M. Balenson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.46.html">Volume 8 Issue 46 (29 Mar 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.46.html#subj1">  B-1B wept-swing swept-wing (PGN)</A>
<LI><A HREF="/Risks/8.46.html#subj2">  Soviets Lose 2nd Mars Probe (PGN)</A>
<LI><A HREF="/Risks/8.46.html#subj3">  Satellite failure due to unremoved lens Cap (PGN)</A>
<LI><A HREF="/Risks/8.46.html#subj4">  Technology strikes again -- Dodge Spirits and Dodge Fever (Matt Fichtenbaum)</A>
<LI><A HREF="/Risks/8.46.html#subj5">  Suing over runaway computer systems (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.46.html#subj6">  Virus Hits Hospital Computers (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.46.html#subj7">  Prank Virus Warning Message (Bruce N. Baker)</A>
<LI><A HREF="/Risks/8.46.html#subj8">  Subversive bulletin boards (Eric Percival)</A>
<LI><A HREF="/Risks/8.46.html#subj9">  UK Computer Threat Research Association (David J. Ferbrache)</A>
<LI><A HREF="/Risks/8.46.html#subj10">  Will the Hubble Space Telescope Compute? (Paul Eggert)</A>
<LI><A HREF="/Risks/8.46.html#subj11">  The Airbus disaster and Ada (Ted Holden via Bob Burch via jpff)</A>
<LI><A HREF="/Risks/8.46.html#subj12">  DIAC-90 -- Call for Papers (Douglas Schuler)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.47.html">Volume 8 Issue 47 (1 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.47.html#subj1">  Summary of recent news briefs on "hacker" activity (Anonymous)</A>
<LI><A HREF="/Risks/8.47.html#subj2">  "Free Fall" -- new book on 1983 Air Canada near-disaster (Rich Wales)</A>
<LI><A HREF="/Risks/8.47.html#subj3">  Farm worker killed by conveyor (Walter Roberson)</A>
<LI><A HREF="/Risks/8.47.html#subj4">  Hackers dictionary in Japanese? (Les Earnest)</A>
<LI><A HREF="/Risks/8.47.html#subj5">  Undetected Monitoring Programs and Privacy Rights (Donald B. Wechsler)</A>
<LI><A HREF="/Risks/8.47.html#subj6">  Re: Ada and Airbus (John Knight via A. Blakemore and Mike Linnig)</A>
<LI><A HREF="/Risks/8.47.html#subj7">  Galactic Hacker Party (Rop Gonggrijp)</A>
<LI><A HREF="/Risks/8.47.html#subj8">  Virus in PKARC software (Bob Kozlarek via Robert Casey via A-N-Onymouse)</A>
<LI><A HREF="/Risks/8.47.html#subj9">  Computer Documentation Course Queries (Stephen W. Thompson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.48.html">Volume 8 Issue 48 (3 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.48.html#subj1">  BMW's DWS system (Brian Randell)</A>
<LI><A HREF="/Risks/8.48.html#subj2">  Risks of insomnia (Roger H. Goun)</A>
<LI><A HREF="/Risks/8.48.html#subj3">  VDT Risks? No, Lead pipe cinch. (F. Baube)</A>
<LI><A HREF="/Risks/8.48.html#subj4">  Aircraft running out of fuel in flight (Dale Worley)</A>
<LI><A HREF="/Risks/8.48.html#subj5">  Yet another round of Airbus A320 discussions (Joe Morris)</A>
<LI><A HREF="/Risks/8.48.html#subj6">  Daylight savings change requires computer shutdown (Walter Roberson)</A>
<LI><A HREF="/Risks/8.48.html#subj7">  Elevator accident kills 13 year old (Walter Roberson)</A>
<LI><A HREF="/Risks/8.48.html#subj8">  Re: "Free Fall" -- new book on 1983 Air Canada near-disaster (Henry Spencer)</A>
<LI><A HREF="/Risks/8.48.html#subj9">  Newspapers' computer access to public records (Wm Randolph Franklin)</A>
<LI><A HREF="/Risks/8.48.html#subj10">  Computers and Property Revaluation: It's Great in Dayton, Ohio (John Karabaic)</A>
<LI><A HREF="/Risks/8.48.html#subj11">  Credit card magstripe-encoded pictures (Brian Randell)</A>
<LI><A HREF="/Risks/8.48.html#subj12">  Using Pre-release Software (David A. Honig)</A>
<LI><A HREF="/Risks/8.48.html#subj13">  Computer say, go to jail (Clifford Johnson)</A>
<LI><A HREF="/Risks/8.48.html#subj14">  Accidental erasure of magnetic media used by the public (Peter Jones)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.49.html">Volume 8 Issue 49 (5 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.49.html#subj1">  An unusual "common mode failure" in B-1B aircraft (PGN)</A>
<LI><A HREF="/Risks/8.49.html#subj2">  Gripen crash caused by flight control software (Mitchell Charity, Mike Nutley)</A>
<LI><A HREF="/Risks/8.49.html#subj3">  Airbus A320 article plus some comments (Nancy Leveson) [long]</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.50.html">Volume 8 Issue 50 (5 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.50.html#subj1">  Mechanical Horse Racing (Mike Trout)</A>
<LI><A HREF="/Risks/8.50.html#subj2">  Elevator death update (Walter Roberson)</A>
<LI><A HREF="/Risks/8.50.html#subj3">  Re: Elevator accident kills 13-year-old (Eric Roskos)</A>
<LI><A HREF="/Risks/8.50.html#subj4">  Federal Pay System botch-up (Tim Shimeall)</A>
<LI><A HREF="/Risks/8.50.html#subj5">  NYTimes business readers shown the future (Mitchell Charity)</A>
<LI><A HREF="/Risks/8.50.html#subj6">  Newspapers and access to public records (J. Eric Townsend)</A>
<LI><A HREF="/Risks/8.50.html#subj7">  High-Tech Locomotives (Mark Brader)</A>
<LI><A HREF="/Risks/8.50.html#subj8">  Military software (Henry Spencer)</A>
<LI><A HREF="/Risks/8.50.html#subj9">  Authenticating Internet mail (Peter Scott)</A>
<LI><A HREF="/Risks/8.50.html#subj10">  Advertising vs the net (Brian Kantor via Skip Montanaro)</A>
<LI><A HREF="/Risks/8.50.html#subj11">  Gorillas in the Missed Identification (Joe Morris, Jay Elinsky, Eddie Caplan)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.51.html">Volume 8 Issue 51 (6 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.51.html#subj1">  Valdez Autopilot (Glenn Lea)</A>
<LI><A HREF="/Risks/8.51.html#subj2">  The National Weather Service automation vs. aviation (Randal L. Schwartz)</A>
<LI><A HREF="/Risks/8.51.html#subj3">  Authenticating Internet mail (Jon Rochlis)</A>
<LI><A HREF="/Risks/8.51.html#subj4">  Mechanical horse racing (Brad Hutchings)</A>
<LI><A HREF="/Risks/8.51.html#subj5">  Re: Airbus A320 article (Dan Swinehart, Robert Dorsett, PGN)</A>
<LI><A HREF="/Risks/8.51.html#subj6">  More on 1983 Air Canada near-disaster (Rich Wales)</A>
<LI><A HREF="/Risks/8.51.html#subj7">  ATM loss - no one believes the customer. (jrl)</A>
<LI><A HREF="/Risks/8.51.html#subj8">  BMW Risks (Peter Kendell)</A>
<LI><A HREF="/Risks/8.51.html#subj9">  BMW Road Warmers (Dennis Vadura)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.52.html">Volume 8 Issue 52 (9 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.52.html#subj1">  Valdez follow-up... (Dean Riddlebarger)</A>
<LI><A HREF="/Risks/8.52.html#subj2">  Phobos (Bob Morris)</A>
<LI><A HREF="/Risks/8.52.html#subj3">  Presumption of innocence -- for computers (Peter da Silva)</A>
<LI><A HREF="/Risks/8.52.html#subj4">  1988 Toronto election (Mark Brader)</A>
<LI><A HREF="/Risks/8.52.html#subj5">  California's anti-fax-ad bill (David M. Gursky)</A>
<LI><A HREF="/Risks/8.52.html#subj6">  Man bytes dog (Charles Youman )</A>
<LI><A HREF="/Risks/8.52.html#subj7">  Re: Elevator accident kills 13-year-old (John Luce via John (J.G.) Mainwaring)</A>
<LI><A HREF="/Risks/8.52.html#subj8">  Need DRAMs? (Mike Raffety)</A>
<LI><A HREF="/Risks/8.52.html#subj9">  Cellular telephones (Steven C. Den Beste)</A>
<LI><A HREF="/Risks/8.52.html#subj10">  CDC operating system has passwords in batch files (Gerard Stafleu)</A>
<LI><A HREF="/Risks/8.52.html#subj11">  Cornell Chronicle coverage of Robert T. Morris (Manny Farber via Dave Farber)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.53.html">Volume 8 Issue 53 (10 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.53.html#subj1">  Product Recalls Due to Software Error (B.J. Herbison)  [Medical]</A>
<LI><A HREF="/Risks/8.53.html#subj2">  Airliners running out of fuel in mid-flight (Jerome H. Saltzer)</A>
<LI><A HREF="/Risks/8.53.html#subj3">  Good press in Flying (Howard Gayle)</A>
<LI><A HREF="/Risks/8.53.html#subj4">  Re: More on 1983 Air Canada near-disaster (Henry Spencer)</A>
<LI><A HREF="/Risks/8.53.html#subj5">  PC causes multiuser host to drop off the network (Patrick Wolfe)</A>
<LI><A HREF="/Risks/8.53.html#subj6">  Auto Risks (Robert Dorsett)</A>
<LI><A HREF="/Risks/8.53.html#subj7">  Risk of Living in Nova Scotia (Matthew Wall)</A>
<LI><A HREF="/Risks/8.53.html#subj8">  Otis elevator software (Eric Roskos)</A>
<LI><A HREF="/Risks/8.53.html#subj9">  Elevator Units (Don Alvarez)</A>
<LI><A HREF="/Risks/8.53.html#subj10">  Nuclear-powered vessels (Steve Bellovin)</A>
<LI><A HREF="/Risks/8.53.html#subj11">  (Deep-seated) Presumption of innocence -- for computers (ephraim)</A>
<LI><A HREF="/Risks/8.53.html#subj12">  Re: Authenticating Internet mail (John Labovitz)</A>
<LI><A HREF="/Risks/8.53.html#subj13">  Passwords in plaintext (Brian McMahon)</A>
<LI><A HREF="/Risks/8.53.html#subj14">  Re: Cellular telephones (Eric Thayer, David Collier-Brown)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.54.html">Volume 8 Issue 54 (11 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.54.html#subj1">  More on Otis 401 elevators (Dave Horsfall)</A>
<LI><A HREF="/Risks/8.54.html#subj2">  PC crashing network: blame the error message (Mark Mandel)</A>
<LI><A HREF="/Risks/8.54.html#subj3">  Election tampering and illegal surveillance (Brad Sherman)</A>
<LI><A HREF="/Risks/8.54.html#subj4">  Computer CAN attempt to defraud you (Peter van der Linden)</A>
<LI><A HREF="/Risks/8.54.html#subj5">  Infallible Computers (Dave Curry)</A>
<LI><A HREF="/Risks/8.54.html#subj6">  Re: Airliners running out of fuel in mid-flight (Alan Marcum)</A>
<LI><A HREF="/Risks/8.54.html#subj7">  Re: More on 1983 Air Canada near-disaster (Alan Marcum)</A>
<LI><A HREF="/Risks/8.54.html#subj8">  Airbus A320 article plus some comments (Greg Rose)</A>
<LI><A HREF="/Risks/8.54.html#subj9">  Re: CDC operating system has passwords in batch files (Steve Lidie)</A>
<LI><A HREF="/Risks/8.54.html#subj10">  NSA and Not Secure Agencies (Curtis Spangler)</A>
<LI><A HREF="/Risks/8.54.html#subj11">  California's anti-fax-ad bill... (Mark Mandel)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.55.html">Volume 8 Issue 55 (12 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.55.html#subj1">  Informing the Public about Risks (Marc Rotenberg)</A>
<LI><A HREF="/Risks/8.55.html#subj2">  Central Locking Systems (J M Hicks)</A>
<LI><A HREF="/Risks/8.55.html#subj3">  Social Security Administration Verifying SSNs (David Gast)</A>
<LI><A HREF="/Risks/8.55.html#subj4">  Not Secure Agencies (Hugh Miller)</A>
<LI><A HREF="/Risks/8.55.html#subj5">  Re: Cellular Telephones (Eric Roskos)</A>
<LI><A HREF="/Risks/8.55.html#subj6">  Risk to Sun 386i users (Mike O'Connor via Alan Wexelblat)</A>
<LI><A HREF="/Risks/8.55.html#subj7">  Infallible Computers and Perry Mason (Brinton Cooper, Ephraim Vishniac)</A>
<LI><A HREF="/Risks/8.55.html#subj8">  Air Canada and fuel-proof gauges (Robert Dorsett, John Hascall)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.56.html">Volume 8 Issue 56 (13 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.56.html#subj1">  Student grants debited instead of credited (John Harper)</A>
<LI><A HREF="/Risks/8.56.html#subj2">  Electronic Truant Officers (Mike McNally)</A>
<LI><A HREF="/Risks/8.56.html#subj3">  "Virus" arrest in New Jersey (A. Michael Berman)</A>
<LI><A HREF="/Risks/8.56.html#subj4">  H.D. Thoreau on Risks of Believing Computations (David A Honig)</A>
<LI><A HREF="/Risks/8.56.html#subj5">  Knowledge and Power (David Guaspari)</A>
<LI><A HREF="/Risks/8.56.html#subj6">  "Malicious" computers? (Clifford Johnson)</A>
<LI><A HREF="/Risks/8.56.html#subj7">  Re: Infallible Computers and Mason (Jack Holleran)</A>
<LI><A HREF="/Risks/8.56.html#subj8">  HP MPE V/E Batch Security (Brown)</A>
<LI><A HREF="/Risks/8.56.html#subj9">  More on the Sun 386i security hole (David C. Kovar via Alan Wexelblat)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.57.html">Volume 8 Issue 57 (15 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.57.html#subj1">  H.D. Thoreau on Risks of Believing Computations (Jim Haynes)</A>
<LI><A HREF="/Risks/8.57.html#subj2">  Airbus 320 (Brian Randell)</A>
<LI><A HREF="/Risks/8.57.html#subj3">  1,000 Pilots Face ban (Dermot Williams)</A>
<LI><A HREF="/Risks/8.57.html#subj4">  RFI and elevators (Robert A. Morris)</A>
<LI><A HREF="/Risks/8.57.html#subj5">  Electronic Truant Officers    (Carolyn M. Kotlas, Michael R. Hoffman, Ed Robertson)
</A>
<LI><A HREF="/Risks/8.57.html#subj6">  Re: Computer CAN attempt to defraud you (Hugh Davies)</A>
<LI><A HREF="/Risks/8.57.html#subj7">  Computer maliciousness (Peter da Silva)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.58.html">Volume 8 Issue 58 (17 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.58.html#subj1">  Cruise Missiles with "Polish" (Ralph Vartabedian via Nancy Leveson)</A>
<LI><A HREF="/Risks/8.58.html#subj2">  Computerized parts supply (Jim Haynes)</A>
<LI><A HREF="/Risks/8.58.html#subj3">  RFI and Elevators (Martin Ewing)</A>
<LI><A HREF="/Risks/8.58.html#subj4">  Aegis the almighty (Henry Spencer)</A>
<LI><A HREF="/Risks/8.58.html#subj5">  Thoreau and Navigation (Eric Roskos)</A>
<LI><A HREF="/Risks/8.58.html#subj6">  Risks of automatic order entry in restaurants (Daniel Klein)</A>
<LI><A HREF="/Risks/8.58.html#subj7">  Re: Most Accurate Clock (Clay Jackson)</A>
<LI><A HREF="/Risks/8.58.html#subj8">  Fuel Management/Mis-management (Mike Brown)</A>
<LI><A HREF="/Risks/8.58.html#subj9">  Companies mask ANI to calm callers (Bob Wallace via GEBM)</A>
<LI><A HREF="/Risks/8.58.html#subj10">  The dangers of electric windows (Martin Cooper)</A>
<LI><A HREF="/Risks/8.58.html#subj11">  Careless tape transfer procedures (Peter Jones)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.59.html">Volume 8 Issue 59 (18 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.59.html#subj1">  More on the British Midlands 737 crash (Robert Dorsett)</A>
<LI><A HREF="/Risks/8.59.html#subj2">  Computers and Food Poisoning [anonymous]</A>
<LI><A HREF="/Risks/8.59.html#subj3">  The dangers of electric seatbelts (was: windows) (Clements)</A>
<LI><A HREF="/Risks/8.59.html#subj4">  Re: The dangers of electric windows (Daniel Klein)</A>
<LI><A HREF="/Risks/8.59.html#subj5">  Newspaper Cartoons and Computer Infallibility (G. McClelland)</A>
<LI><A HREF="/Risks/8.59.html#subj6">  Re: Thoreau and Navigation (David A Honig)</A>
<LI><A HREF="/Risks/8.59.html#subj7">  "Journalist Vigilantes" (Walter Roberson)</A>
<LI><A HREF="/Risks/8.59.html#subj8">  Hazards of RF near electronic controls (Dana Myers)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.60.html">Volume 8 Issue 60 (19 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.60.html#subj1">  Hillsborough: Risks of using Computers at Stadium Turnstiles (Brian Tompsett)</A>
<LI><A HREF="/Risks/8.60.html#subj2">  Risks of plaintext data (Hugh Miller)</A>
<LI><A HREF="/Risks/8.60.html#subj3">  Computer voting at Stanford (Scott Seligman)</A>
<LI><A HREF="/Risks/8.60.html#subj4">  Re: Computerized attendance (Sean Fagan)</A>
<LI><A HREF="/Risks/8.60.html#subj5">  More Auto-Seatbelt Horrors (Thor Simon)</A>
<LI><A HREF="/Risks/8.60.html#subj6">  Mb = 1024? 1000? (Walter Roberson)</A>
<LI><A HREF="/Risks/8.60.html#subj7">  Re: Newspaper Cartoons and Computer Infallibility (Will Martin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.61.html">Volume 8 Issue 61 (20 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.61.html#subj1">  Alleged Computer-aided fraud (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.61.html#subj2">  Black box for automobiles (Anthony Stone)</A>
<LI><A HREF="/Risks/8.61.html#subj3">  References to smoking and computer failure? (David A Rasmussen)</A>
<LI><A HREF="/Risks/8.61.html#subj4">  The danger of testing (re RFI and elevators) (Dave Collier-Brown)</A>
<LI><A HREF="/Risks/8.61.html#subj5">  Reaction to John Luce's letter on electronic elevators (Peter Jones)</A>
<LI><A HREF="/Risks/8.61.html#subj6">  Industry not protecting privacy (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.61.html#subj7">  Sun386i security problem update (Ed DeHart)</A>
<LI><A HREF="/Risks/8.61.html#subj8">  Writing on "write-protected" disks (David M. Zielke and Peter Jones)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.62.html">Volume 8 Issue 62 (24 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.62.html#subj1">  Release SkyDome, Release 0.0 (Mark Brader)</A>
<LI><A HREF="/Risks/8.62.html#subj2">  Risks of plaintext data (II) (Hugh Miller)</A>
<LI><A HREF="/Risks/8.62.html#subj3">  Computer orders for phone books (Mark Brader)</A>
<LI><A HREF="/Risks/8.62.html#subj4">  ATM's used to track accused killer (Al Stangenberger)</A>
<LI><A HREF="/Risks/8.62.html#subj5">  Computer Voting (Chris Davis)</A>
<LI><A HREF="/Risks/8.62.html#subj6">  Re: Most Accurate Clock (David Schachter)</A>
<LI><A HREF="/Risks/8.62.html#subj7">  Writing on write-protected disks (Leigh L. Klotz, Kenneth R. van Wyk,     Phil Goetz, Dimitri Vulis, Henry Spencer, Dave Kemp, Rich Sims)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.63.html">Volume 8 Issue 63 (25 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.63.html#subj1">  More 737 Computer Problems (Brian Randell)</A>
<LI><A HREF="/Risks/8.63.html#subj2">  Cockpit Computers Defy Pilots (Robert Dorsett)</A>
<LI><A HREF="/Risks/8.63.html#subj3">  Common thread in recent postings: People (Ian)</A>
<LI><A HREF="/Risks/8.63.html#subj4">  Smoke vs. disc drives (John Shipman)</A>
<LI><A HREF="/Risks/8.63.html#subj5">  Use of "Standard" on sensitive applications (Terry S. Arnold)</A>
<LI><A HREF="/Risks/8.63.html#subj6">  Computer Threat Research Association (UK) (David J. Ferbrache)</A>
<LI><A HREF="/Risks/8.63.html#subj7">  ATMs used to track accused killer (Steve Bellovin)</A>
<LI><A HREF="/Risks/8.63.html#subj8">  Re: Most Accurate Clock (Don Watrous)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.64.html">Volume 8 Issue 64 (26 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.64.html#subj1">  DARPA studying high-tech surveillance for drug wars (Jon Jacky)</A>
<LI><A HREF="/Risks/8.64.html#subj2">  Re: SKYDOME (Michael Wagner)</A>
<LI><A HREF="/Risks/8.64.html#subj3">  Cursing the Darkness? (Ronald J Bottomly)</A>
<LI><A HREF="/Risks/8.64.html#subj4">  Data Checking at Osco's (Scott Turner)</A>
<LI><A HREF="/Risks/8.64.html#subj5">  Re: Common thread in recent postings: People (Hugh Miller, John Karabaic)</A>
<LI><A HREF="/Risks/8.64.html#subj6">  Re: Use of "Standard" ... (Pete Schilling, Steve Bellovin)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.65.html">Volume 8 Issue 65 (27 Apr 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.65.html#subj1">  Northwest 255 -- Another Disconnected Alarm story? (Jerry Leichter)</A>
<LI><A HREF="/Risks/8.65.html#subj2">  All addressed up with the wrong place to go (Jerry Leichter)</A>
<LI><A HREF="/Risks/8.65.html#subj3">  Jukebox foolishness (Robert J. Reschly Jr.)</A>
<LI><A HREF="/Risks/8.65.html#subj4">  Electronic Seat-Belts (Marc W. Mengel)</A>
<LI><A HREF="/Risks/8.65.html#subj5">  Mitnick plea bargain rejected by judge as too lenient (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.65.html#subj6">  Spider-Man's SSN and computer limitations (Brad Blumenthal)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.66.html">Volume 8 Issue 66 (4 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.66.html#subj1">  Standards == nothing (Rich Neitzel)</A>
<LI><A HREF="/Risks/8.66.html#subj2">  Traffic Alert Collision Avoidance System with "no bugs" (Henry Schaffer)</A>
<LI><A HREF="/Risks/8.66.html#subj3">  Nuclear reactor knocked offline by 2-way radio in control room     (Wm. Randolph Franklin)
</A>
<LI><A HREF="/Risks/8.66.html#subj4">  B-2 builders: Prototype not needed (Long Article)    (Mark Thompson via Stephen W. Thompson)
</A>
<LI><A HREF="/Risks/8.66.html#subj5">  American Express is watching... (Sundar Iyengar)</A>
<LI><A HREF="/Risks/8.66.html#subj6">  Telephone line security (David C. Kovar)</A>
<LI><A HREF="/Risks/8.66.html#subj7">  COMPASS Program (John Cherniavsky)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.67.html">Volume 8 Issue 67 (7 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.67.html#subj1">  Space software problems (Henry Edward Hardy)   [Magellan, Phobos I]</A>
<LI><A HREF="/Risks/8.67.html#subj2">  Self-diagnostics in airplanes (David Robinson)</A>
<LI><A HREF="/Risks/8.67.html#subj3">  B-2 Builders: Prototype not needed (Dave Parnas, Bill Murray, Henry Spencer)</A>
<LI><A HREF="/Risks/8.67.html#subj4">  Standards == Nothing (Dave Parnas, Bob Estell, Henry Spencer)</A>
<LI><A HREF="/Risks/8.67.html#subj5">  Risks to contact lenses wearers from computer ventilators (Periklis Tsahageas)</A>
<LI><A HREF="/Risks/8.67.html#subj6">  Re: Telephone line physical security (William M. Bumgarner, Mike Akre)</A>
<LI><A HREF="/Risks/8.67.html#subj7">  Power lines and computers (George Michaelson)</A>
<LI><A HREF="/Risks/8.67.html#subj8">  Not using computer helps trapping of error (Konrad Neuwirth)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.68.html">Volume 8 Issue 68 (8 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.68.html#subj1">  Low-Probability / High-Consequence Accidents -- and the Midland 737? (PGN)</A>
<LI><A HREF="/Risks/8.68.html#subj2">  "Probing Boeing's crossed Connections" (Werner Uhrig)</A>
<LI><A HREF="/Risks/8.68.html#subj3">  An Atlantis spacecraft computer problem resolved nicely (PGN)</A>
<LI><A HREF="/Risks/8.68.html#subj4">  "Life's Risks: Balancing Fear Against Reality of Statistics"    (Marc Rotenberg, Jerry Leichter)
</A>
<LI><A HREF="/Risks/8.68.html#subj5">  Hear No Evil (Kevin Driscoll)</A>
<LI><A HREF="/Risks/8.68.html#subj6">  Computer Ethics Course/Resource Volunteers Wanted (long)  (Bob Barger)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.69.html">Volume 8 Issue 69 (10 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.69.html#subj1">  Computers and Redistricting (PGN)</A>
<LI><A HREF="/Risks/8.69.html#subj2">  Re: Atlantis spacecraft computer problem resolved nicely (Henry Spencer)</A>
<LI><A HREF="/Risks/8.69.html#subj3">  Computer-generated checks (Art Werschulz)</A>
<LI><A HREF="/Risks/8.69.html#subj4">  Re: Hear No Evil (Clay Jackson)</A>
<LI><A HREF="/Risks/8.69.html#subj5">  Computer Bugs/Recalls/Upgrades (Clay Jackson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.70.html">Volume 8 Issue 70 (12 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.70.html#subj1">  Computers in mathematical proofs (Henry Spencer)</A>
<LI><A HREF="/Risks/8.70.html#subj2">  Re: An Atlantis spacecraft computer problem resolved nicely (Yves Deswarte)</A>
<LI><A HREF="/Risks/8.70.html#subj3">  Company sued for "computerized" firing scheme (Emily H. Lonsford)</A>
<LI><A HREF="/Risks/8.70.html#subj4">  Logged on and Unattended (NOT FROM Jon Orseck)</A>
<LI><A HREF="/Risks/8.70.html#subj5">  Dot Matrix == valid and LaserReceipts (Mike Albaugh)</A>
<LI><A HREF="/Risks/8.70.html#subj6">  Computer generated checks (John McLachlan, Darin McGrew)</A>
<LI><A HREF="/Risks/8.70.html#subj7">  Auto electronics and Radio Transmitters don't mix! (Peter Morgan Lucas)</A>
<LI><A HREF="/Risks/8.70.html#subj8">  Mitnick update (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.70.html#subj9">  TRW &amp; SSA (Michael J. Tighe)</A>
<LI><A HREF="/Risks/8.70.html#subj10">  Centralized Railroad Dispatching (Chuck Weinstock)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.71.html">Volume 8 Issue 71 (17 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.71.html#subj1">  American Airlines' reservation system crash (Dave Curry)</A>
<LI><A HREF="/Risks/8.71.html#subj2">  NCIC information leads to repeat false arrest suit (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.71.html#subj3">  Hacking for a competitive edge (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.71.html#subj4">  Privacy of SSA records (Marc Rotenberg)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.72.html">Volume 8 Issue 72 (21 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.72.html#subj1">  Air Force Bombs Georgia (henry cox)</A>
<LI><A HREF="/Risks/8.72.html#subj2">  The Geomagnetic Storm of 13 March 1989  (Brian Randell)</A>
<LI><A HREF="/Risks/8.72.html#subj3">  Tolerability of Risk (Martyn Thomas)</A>
<LI><A HREF="/Risks/8.72.html#subj4">  More magnetic stripe woes (Joe Morris)</A>
<LI><A HREF="/Risks/8.72.html#subj5">  Dive Computers revisited (Henry Cox)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.73.html">Volume 8 Issue 73 (22 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.73.html#subj1">  State computer system scrapped (Bruce Forstall)</A>
<LI><A HREF="/Risks/8.73.html#subj2">  Fax Attack (Chuck Dunlop)</A>
<LI><A HREF="/Risks/8.73.html#subj3">  Client responsibility for organization's head crash (David A Honig)</A>
<LI><A HREF="/Risks/8.73.html#subj4">  Re: Computers in mathematical proofs    (Robert Lee Wilson Jr, Robert English, Travis Lee Winfrey)
</A>
<LI><A HREF="/Risks/8.73.html#subj5">  Formal Methods -- Call For Papers (Nancy Leveson)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.74.html">Volume 8 Issue 74 (26 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.74.html#subj1">  Aegis, Vincennes, and the Iranian Airbus (PGN interpreting Matt Jaffe)</A>
<LI><A HREF="/Risks/8.74.html#subj2">  Anti-lock brake system failure - fail-safe? (Jay Elinsky)</A>
<LI><A HREF="/Risks/8.74.html#subj3">  Pleasure boat database helps thieves (Howard Gayle)</A>
<LI><A HREF="/Risks/8.74.html#subj4">  SAGE-BOMARC risks (Les Earnest)</A>
<LI><A HREF="/Risks/8.74.html#subj5">  SABRE disaster caused by "core corruption" (Andrew Birner)</A>
<LI><A HREF="/Risks/8.74.html#subj6">  Computer Intrusion Network in Detroit (Dave Curry)</A>
<LI><A HREF="/Risks/8.74.html#subj7">  Robert T. Morris suspended from Cornell (Dave Curry)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.75.html">Volume 8 Issue 75 (30 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.75.html#subj1">  Mariner I -- no holds BARred (PGN)</A>
<LI><A HREF="/Risks/8.75.html#subj2">  Another false incarceration (PGN)</A>
<LI><A HREF="/Risks/8.75.html#subj3">  Perfecting Peopleware (Bob Morris)</A>
<LI><A HREF="/Risks/8.75.html#subj4">  Aegis and the Iranian Airbus shootdown (Steve Philipson)</A>
<LI><A HREF="/Risks/8.75.html#subj5">  Radio Frequency interference (J. Michael Berkley)</A>
<LI><A HREF="/Risks/8.75.html#subj6">  SRI attacked by kamikaze squirrels? (David L. Edwards)</A>
<LI><A HREF="/Risks/8.75.html#subj7">  Computer electrocutes chess player who beat it! (Gene Spafford)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.76.html">Volume 8 Issue 76 (31 May 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.76.html#subj1">  State computer system scrapped (Davis)</A>
<LI><A HREF="/Risks/8.76.html#subj2">  Swedish library loan data to become secret (Howard Gayle)</A>
<LI><A HREF="/Risks/8.76.html#subj3">  SABRE (Bill Murray)</A>
<LI><A HREF="/Risks/8.76.html#subj4">  Strange Customs Service Clock Department (Willis H. Ware)</A>
<LI><A HREF="/Risks/8.76.html#subj5">  No power lunch, just no-power crunch (after the squirrel's over) (PGN)</A>
<LI><A HREF="/Risks/8.76.html#subj6">  Re: Computer electrocutes chess player who beat it! (David Chase)</A>
<LI><A HREF="/Risks/8.76.html#subj7">  Five admit automated teller scam (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.76.html#subj8">  Re: Kevin Mitnick (Kenneth Siani)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.77.html">Volume 8 Issue 77 (8 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.77.html#subj1">  Second elevator death (Walter Roberson)</A>
<LI><A HREF="/Risks/8.77.html#subj2">  Electronic card spots hooligans (Martyn Thomas)</A>
<LI><A HREF="/Risks/8.77.html#subj3">  Big Brother is watching your magnetic card (Amos Shapir)</A>
<LI><A HREF="/Risks/8.77.html#subj4">  May you live in interesting times (High-tech Chinese revolution)(Martin Minow)</A>
<LI><A HREF="/Risks/8.77.html#subj5">  "Core-Walker" that crashed SABRE (Rodney Hoffman)</A>
<LI><A HREF="/Risks/8.77.html#subj6">  Airbus A320 (Brian Randell)</A>
<LI><A HREF="/Risks/8.77.html#subj7">  Re: Power outages (Peter Scott)</A>
<LI><A HREF="/Risks/8.77.html#subj8">  One of Cliff Stoll's `Wily Hacker' dead (suicide?) (Klaus Brunnstein)</A>
<LI><A HREF="/Risks/8.77.html#subj9">  Computer Virus Catalogue (Aims and Scope) (Klaus Brunnstein)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.78.html">Volume 8 Issue 78 (11 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.78.html#subj1">  NY Telephone Freebies (PGN)</A>
<LI><A HREF="/Risks/8.78.html#subj2">  Nielsen Raidings -- A risk? (John Rushby)</A>
<LI><A HREF="/Risks/8.78.html#subj3">  C-17 Overrun (Gary Chapman)</A>
<LI><A HREF="/Risks/8.78.html#subj4">  COMPASS '89 reminder (Al Friend)</A>
<LI><A HREF="/Risks/8.78.html#subj5">  Re: Big Brother is watching your posting in RISKS (Amos Shapir)</A>
<LI><A HREF="/Risks/8.78.html#subj6">  How Rumors Mutate, Lesson 2 (Rich Fritzson)</A>
<LI><A HREF="/Risks/8.78.html#subj7">  The computer didn't commit the crime (Michael Doob)</A>
<LI><A HREF="/Risks/8.78.html#subj8">  An ATM gets it right (Steve Anthony)</A>
<LI><A HREF="/Risks/8.78.html#subj9">  Justice Department wary in Computer Case (Dave Bozak)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.79.html">Volume 8 Issue 79 (14 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.79.html#subj1">  Single point of failure -- Tokyo Stock Exchange (Jerry Carlin)</A>
<LI><A HREF="/Risks/8.79.html#subj2">  Costly Horse Race (Rick Zaccone)</A>
<LI><A HREF="/Risks/8.79.html#subj3">  Commercial Loans in California at a Standstill (PGN)</A>
<LI><A HREF="/Risks/8.79.html#subj4">  Phone Hacking (Brinton Cooper)</A>
<LI><A HREF="/Risks/8.79.html#subj5">  Microcomputers in the operating theatre (Martyn Thomas)</A>
<LI><A HREF="/Risks/8.79.html#subj6">  Inspiration from the past -- Machines Will Take Over (Curtis Galloway)</A>
<LI><A HREF="/Risks/8.79.html#subj7">  "Illuminatus!" (Pete)</A>
<LI><A HREF="/Risks/8.79.html#subj8">  Praise and Blame -- Computers and People (Hugh Miller)</A>
<LI><A HREF="/Risks/8.79.html#subj9">  NORAD Computers: Years Late, Unusably Slow, $207 Million Over Budget    (Karl Lehenbauer)
</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.80.html">Volume 8 Issue 80 (16 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.80.html#subj1">  Disarmament by defect (Gerard Stafleu)</A>
<LI><A HREF="/Risks/8.80.html#subj2">  Even human-in-the-loop isn't foolproof. A test case. (Pete Holzmann)</A>
<LI><A HREF="/Risks/8.80.html#subj3">  Single point of failure? probably not. (Ephraim Vishniac)</A>
<LI><A HREF="/Risks/8.80.html#subj4">  Re: single point of failure -- Tokyo Stock Exchange (Patrick Wolfe)</A>
<LI><A HREF="/Risks/8.80.html#subj5">  Qantas Airliner Mishap (John Murray)</A>
<LI><A HREF="/Risks/8.80.html#subj6">  Theorem Proving by Computers (Tom Thomson)</A>
<LI><A HREF="/Risks/8.80.html#subj7">  Re: Computer electrocutes chess player ... (Dave Horsfall, Joel Kirsh)</A>
<LI><A HREF="/Risks/8.80.html#subj8">  Clerical error spares famed sex-fiend (Mike Albaugh)</A>
<LI><A HREF="/Risks/8.80.html#subj9">  Sabre computer problems revisited (Emily H. Lonsford)</A>
<LI><A HREF="/Risks/8.80.html#subj10">  Protection from Misdirected Radio Control Commands (Robert Horvitz)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.81.html">Volume 8 Issue 81 (17 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.81.html#subj1">  Re: Disarmament by defect (Gary Chapman)</A>
<LI><A HREF="/Risks/8.81.html#subj2">  Medical history-on-a-card? (Ellen Keyne Seebacher)</A>
<LI><A HREF="/Risks/8.81.html#subj3">  No backups -- TOWER of Babel (Sam Cramer)</A>
<LI><A HREF="/Risks/8.81.html#subj4">  'Blip' Blows Computers Back to Paper Age (Mark Osbourne)</A>
<LI><A HREF="/Risks/8.81.html#subj5">  Re: Computer electrocutes chess player who beat it! (O. Crepin-Leblond)</A>
<LI><A HREF="/Risks/8.81.html#subj6">  Re: Hartford Coliseum (Richard S. D'Ippolito)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.82.html">Volume 8 Issue 82 (19 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.82.html#subj1">  Re: Microcomputers in the operating theatre (Ken Howard)</A>
<LI><A HREF="/Risks/8.82.html#subj2">  Risks of missiles (Steve Den Beste)</A>
<LI><A HREF="/Risks/8.82.html#subj3">  Trojan Horse in Comp.Risks? (John C Williams)</A>
<LI><A HREF="/Risks/8.82.html#subj4">  Power glitches scrambling computers --- can it be avoided? (Will Dickson)</A>
<LI><A HREF="/Risks/8.82.html#subj5">  Re: 'Blip' Blows Computers Back to Paper Age (William M. Bumgarner)</A>
<LI><A HREF="/Risks/8.82.html#subj6">  No back-ups:  Ninth Circuit's "computer error" (Clifford Johnson)</A>
<LI><A HREF="/Risks/8.82.html#subj7">  Hillsborough Football -- Another Computer Connection (Charles Lindsey)</A>
<LI><A HREF="/Risks/8.82.html#subj8">  Radio Control Interference (Marco C. Barbarisi)</A>
<LI><A HREF="/Risks/8.82.html#subj9">  New Yorker Article (book serialization?) on radiation risks (Martin Minow)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.83.html">Volume 8 Issue 83 (20 Jun 89 PDT)</A>
<DD><UL>
<LI><A HREF="/Risks/8.83.html#subj1">  Pacemakers, radios (Walter Roberson)</A>
<LI><A HREF="/Risks/8.83.html#subj2">  'Traffic monitoring system used for spying' (Walter Roberson)</A>
<LI><A HREF="/Risks/8.83.html#subj3">  I am not a number... (unique postal codes) (Walter Roberson)</A>
<LI><A HREF="/Risks/8.83.html#subj4">  Medical history-on-a-card? ; Another ATM Risks (Edward A. Ranzenbach)</A>
<LI><A HREF="/Risks/8.83.html#subj5">  Re: Microcomputers in the operating theatre (Donald Lindsay, Keith Emanuel)</A>
<LI><A HREF="/Risks/8.83.html#subj6">  Hartford Civic Center roof crash (Peter Desnoyers)</A>
<LI><A HREF="/Risks/8.83.html#subj7">  Re: Risks of missiles (Jan Wolitzky, Gary Chapman, Bob Ayers)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.84.html">Volume 8 Issue 84 (21 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.84.html#subj1">  The risks of global editing (Martyn Thomas / Richard Tobin / Nick Radcliffe)</A>
<LI><A HREF="/Risks/8.84.html#subj2">  Re: I am not a number -- already in the US (Tom Comeau)</A>
<LI><A HREF="/Risks/8.84.html#subj3">  Re: I am not a number -- more in Canada (Vince Manis))</A>
<LI><A HREF="/Risks/8.84.html#subj4">  Re: Computer electrocutes chess player ... (W. Scott Meeks, Brendan McKay)</A>
<LI><A HREF="/Risks/8.84.html#subj5">  Gigatext Translation Services Inc. scandal (Bhota San)   [long]</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.85.html">Volume 8 Issue 85 (28 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.85.html#subj1">  Air Force satellite positioning system cracked (Dave Curry)</A>
<LI><A HREF="/Risks/8.85.html#subj2">  Loose wire caused Clapham train crash (Jon Jacky)</A>
<LI><A HREF="/Risks/8.85.html#subj3">  London firms reportedly offer amnesty to ``hacker thieves''     (Ken Berkun via Jon Jacky)
</A>
<LI><A HREF="/Risks/8.85.html#subj4">  Re: Microcomputers in the operating theater (Jon Jacky, Diomidis Spinellis)</A>
<LI><A HREF="/Risks/8.85.html#subj5">  Don't celebrate big tax refund too quickly  (David Sherman)</A>
<LI><A HREF="/Risks/8.85.html#subj6">  Reading meters and gauges by robot in nuclear power plants (Robert Cooper)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.86.html">Volume 8 Issue 86 (29 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.86.html#subj1">  SPADOC Modernization Effort (Chris McDonald)</A>
<LI><A HREF="/Risks/8.86.html#subj2">  Are are nuclear weapons useable?  How can one test this?  (Dennis L. Mumaugh)</A>
<LI><A HREF="/Risks/8.86.html#subj3">  NASA tests video system that may lead to windowless cockpits (Karl Lehenbauer)</A>
<LI><A HREF="/Risks/8.86.html#subj4">  Air Force to upgrade missile launch command computers (Jon Jacky)</A>
<LI><A HREF="/Risks/8.86.html#subj5">  Missile launch -- upgrades degrade ? (Clifford Johnson)</A>
<LI><A HREF="/Risks/8.86.html#subj6">  Strategic weapon software development practices (Stan Shebs via Jon Jacky)</A>
<LI><A HREF="/Risks/8.86.html#subj7">  Rotting Landsat data (Jonathan Patrick Leech)</A>
</UL><DT><IMG SRC="/Images/redball.gif" ALT=p"o" WIDTH="14" HEIGHT="14">
<A HREF="/Risks/8.87.html">Volume 8 Issue 87 (29 Jun 89)</A>
<DD><UL>
<LI><A HREF="/Risks/8.87.html#subj1">  ``Student plan marred by computer mistake'' (Matthew Wall)</A>
<LI><A HREF="/Risks/8.87.html#subj2">  Immigration Chief Proposes National Computer Screen (Christopher T. Jewell)</A>
<LI><A HREF="/Risks/8.87.html#subj3">  Big Brother is Hallucinating (Elizabeth D Zwicky)</A>
<LI><A HREF="/Risks/8.87.html#subj4">  Study finds ``pedal misapplication'' to blame for Audi surges (Jon Jacky)</A>
<LI><A HREF="/Risks/8.87.html#subj5">  Computer Crime and Social Risks (Pete McVay)</A>
<LI><A HREF="/Risks/8.87.html#subj6">  Reducing risks of cost overruns/project failures (Pete Lucas)</A>
<LI><A HREF="/Risks/8.87.html#subj7">  Re: New Yorker Article on radiation risks (David Chase)</A>
<LI><A HREF="/Risks/8.87.html#subj8">  Computerized Translations (Will Martin)</A>
</UL></DL>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7/index.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/9/index.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Volume" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-43</DOCNO>
<DOCOLDNO>IA012-000129-B046-326</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.2.html 128.240.150.127 19970217021649 text/html 23436
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:15:17 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 2</TITLE>
<LINK REL="Prev" HREF="/Risks/7.01.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.03.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 2</H1>
<H2>  Thursday 2 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Happenstance and $70 Million 
</A>
<DD>
<A HREF="#subj1.1">
Patrick A. Townson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Optimisers too tacit, perhaps? 
</A>
<DD>
<A HREF="#subj2.1">
Tim McDaniel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Optimisers; Telecommunications Redundancy 
</A>
<DD>
<A HREF="#subj3.1">
Michael Wagner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Major security hole in some sun systems     
</A>
<DD>
<A HREF="#subj4.1">
Pete Cottrell and Steve Miller and Jim Purtilo and Chris Torek
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Happenstance and $70 Million
</A>
</H3>
<address>
&lt;<A HREF="mailto:Patrick_A_Townson@cup.portal.com">
Patrick_A_Townson@cup.portal.com
</A>&gt;
</address>
<i>
Wed Jun  1 23:28:30 1988
</i><PRE>
Reply-Path: sun!portal!cup.portal.com!Patrick_A_Townson ?

On May 13, 1988, the day they allegedly embezzled $70 million from First
National Bank of Chicago, two key players met in the waiting room at the
Chicago &amp; Northwestern Railroad Suburban Station.

Armand Moore, convicted swindler said by prosecutors to have masterminded
the crime, was quick to assure bank employee Gabriel Taylor that the plan
had gone off without a hitch.

"You did fine. Everything went great," Moore told Taylor. "Just sit tight.
I won't forget to give you your share of the loot." Confident that all was
well, Moore and the other co-schemers went out to look at new Jaguars and
Cadillacs the next day.

But by Monday morning, May 16, the scheme had begun to unravel. Gabriel
Taylor decided it best to begin cooperating with the government, and seven
men, including Moore and another employee of First National Bank were
indicted by a federal grand jury in the case two days later.

First National has said it anticipates no loss to itself or its customers
in the case. Although $19.8 million remained at large for several days
following the exposure of the scheme, the bank has now retrieved it after
filing suit against Citibank, which at first had refused to return it.

The effort failed 'only by the merest happenstance. This was a big near-miss,'
according to Robert Edwards, a Hagerstown, MD consultant on money transfer
security.

In the case at hand, about $70 million was sent out of the bank in just 64
minutes by wire transfer that Friday morning. Several trillion dollars per
week is moved around the country by wire transfer, in which funds are moved
from one bank to another by electronic debits and credits to interbank account
at the institutions involved.

First National has been busily telling everyone who would listen that the
attempt was foiled because of 'the effeciency of our system, and the many
controls we use....'.  Cynical insiders at the bank and members of the
financial community in Chicago say that is nonsense. The scheme was a
relatively simple minded one which failed because of the perpetrators'
greed and apparent lack of sophistication.

"It's not the hackers and phreakers who are making trouble in most cases,"
said Edwards. "It's the employees who are working us over. When you have
collusion between an employee and somebody on the outside, it is almost
impossible to prevent fraud like this." He added, "The wire transfer business
is extremely risky at best. This is one of the nightmares you live with."

In the First National case, the plot allegedly centered on Moore, known by
his street name of 'The Chairman'. Moore came from his home in Detroit about
the first of May to meet with his cousin Herschel Bailey of Chicago, one
of those charged in the scheme.

Bailey knew Otis Wilson, who had worked at First National for six years
in the wire room. He was also aquainted with Gabriel Taylor, another wire
room employee. Both Taylor and Moore were low-level employees at First
National. Both were young guys from the south side of Chicago who had gotten
jobs at the bank as older teenagers a few years before.

There were several planning meetings at the downtown Quality Inn hotel,
according to federal prosecutors. To entice the two bank employees, Moore
flashed photographs of Rolls-Royce automobiles and luxury yachts, according
to Assistant United States Attorneys Jeffrey Stone and Scott Mendeloff.

Moore allegedly promised Taylor and Wilson he would give them $28 million of
the loot in exchange for their cooperation. At first, Moore wanted to steal
$232 million, but Taylor convinced him that was just too greedy and risky.

Taylor and Bailey allegedly provided the others with confidential information
regarding wire transfers, including the words and phrases bank employees
would say to one another on the phone. They allegedly provided confidential
information about the accounts of several large corporate customers of First
National. They studied computer printouts to determine which of these various
customers had the highest amount of protection against overdrafts, and which
had the highest volume of transactions in their account, meaning that missing
funds would be difficult to immediatly reconcile. They rejected several of
the accounts they reviewed, including Hilton Hotels Corp., for which the
limits were too low.

The men allegedly selected three companies -- Merrill Lynch &amp; Co,. United
Airlines and Brown-Forman Corp. They called First National, purporting to
be with those companies, requesting wire transfers. Taylor arranged to be
the person who made confirming telephone calls, the government claims.

Under First National's procedures, the employee who receives the customer's
request for a wire transfer cannot also be the employee who makes the
confirming phone call. Furthermore, a third employee is required to actually
operate the electronics involved in passing the money.

Prosecutors said the plan called for Taylor to hang up the phone if he was
the person who received the incoming call. Calls to the wire room are
routed automatically by a call distributor-like system; no one knows who will
get which incoming phone call.

Keeping alert to the incoming calls, which were expected at certain times,
Taylor then managed to get the task of making the callbacks, but instead of
calling the actual companies involved, he called his accomplices at Bailey's
house on the south side. Although the bank keeps a computerized record of
all outgoing calls from phones in the wire room, the log was seldom checked
and in any event was never checked immediately.

The money was transferred to accounts of Austrian banks at Chase Manhattan
Bank and Citibank in New York that Friday morning between 8:30 and 9:34 AM.

Later Friday, Moore and another of his accomplices met with officials of
another Chicago bank to discuss how they could move money from an overseas
account and convert it to cash here in Chicago.

The scheme was derailed early Monday when United Airlines officials noticed
a big overdraft in one of its accounts and immediately called First
National.  Brown-Forman did the same. What the schemers did not realize was
that not only are the dialed digits recorded, *but the conversations are
also*. They also did not realize that due to the size of the Merrill Lynch
account, one employee at First National is assigned full time to handle only
that account and attend to the needs of that very large customer. On coming
to work Monday morning, the first thing that person did was review the
latest printout for the customer. The overdraft was immediately noted, and
since no other employee at the bank is ever authorized to debit or credit
the customer's account or do maintenance on the account, it stood out like
the proverbial sore thumb. A call to the responsible party at Merrill Lynch
confirmed that they had not requested a transfer either.

Bank employees who wish to remain anonymous said it was naive to assume
the large overdrafts would not be noticed in a matter of hours. "It's the
greed that killed them," said one bank executive.

It's not really clear why the money was not moved out of the United States
to the banks in Vienna on Friday rather than waiting for Monday. Although
the bank executive said the schemers were stupid about the whole thing, he
admitted there were flaws in First National's system also. He said Taylor
should not have been able to know for sure that he would be the employee
to make the 'confirming phone call'. The person in the wire room who
handles the confirmation should be selected at random just like the person
who receives the call in the first place. The person actually doing the
transfer should likewise be selected at random. By making it predictable
to either party, a scam is that much easier.

The scheme would have eventually foundered anyway. You don't just withdraw $70
million from a bank in Austria without pretty thorough feedback and checking.

ABOUT THE DEFENDANTS - Gabriel Moore and Otis Wilson apparently had no prior
criminal background. Both have elected to cooperate with the government in the
prosecution of Armand Moore, a several times convicted con man. Both are free
on recognizance bond pending their own trials. While its hard to feel sympathy
for them, I *do* feel a twinge of sympathy. Both were (probably) very poorly
paid clerks. They saw billions of dollars pass through their hands daily. When
an older man, suave and sophisticated, takes them out to dinner, hovers over
them, showers them with attention and offers to help them achieve the kind of
riches they and their families could never legitimately have, it was too much
temptation for them to resist. Wouldn't *you* find it hard? I know I would....
In all probability, based on the sentencing guidelines in federal court here,
when they are tried, based on their pleas of guilt, the court will find them
guilty. The government will make no recommendation as to appropriate
punishment, and they will receive federal probation, probably for two to four
years.

Obviously, they are blackballed from any further employment in banking/credit
card/other financial operations. They face their families and friends as
convicted felons.

If Armand Moore and his other associates -- the people who would have actually
benefitted from the scheme (you don't *really* think they planned to cut those
two kids in on it if they could help it, do you?) -- are convicted, most likely
they will face hard time.

A curious dilemma arose regarding $19.8 million transferred to Citibank that
Friday morning. *Citibank refused at first to give it back*. According to
Citibank, all regulations regarding wire transfers were followed. The proper
things were done, the proper words and phrases uttered, all was in order.
Why, they asked, should *we* have to handle security at First National? They
argued that wire transfers were intended to be immediate credits, and that
if First National was now saying in effect that under some conditions their
word on wires was not good, then why bother with a wire?

First National responded by filing suit the same day, Monday, May 16 in court
in New York City, demanding that their money be returned to them. After some
negotiations between Citibank and First National, *most* of the $19.8 million
was returned. Citibank now says apparently they had better stop accepting wire
transfers from First National altogether, or at least subject them to normal
clearing procedures, for you never know when First National might come back a
few hours -- or a weekend -- later and say it was in error.

Internal controls at First National have been so poor in recent years that in
fact a lot of smaller banks throughout the country have begun holding their
paper for clearance -- even cashier's checks and drafts -- simply because when
'errors' have occurred in the past, First National has taken what is percieved
by many banks as a very uppity attitude toward investigation and restitution.

Mr. Edwards of Hagerstown called it 'sheer happenstance that it failed.' I
think I agree.

Patrick Townson@cup.portal.com, PO Box 1003, Chicago, IL 60690-1003

(ps: Hinsdale seems to be rehabilitated - finally - as of the past few days!
Rumors of terrorist activity/arson at the switch are totally unfounded.)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
   Re: Optimisers too tacit, perhaps?
</A>
</H3>
<address>
Tim McDaniel
&lt;<A HREF="mailto:mcdaniel%uicsrd.csrd.uiuc.edu%uxc.cso.uiuc.edu@uxc.cso.uiuc.edu ">
mcdaniel%uicsrd.csrd.uiuc.edu%uxc.cso.uiuc.edu@uxc.cso.uiuc.edu 
</A>&gt;
</address>
<i>
Wed, 1 Jun 88 12:23:33 CDT
</i><PRE>

&gt;Does anyone wish optimisers were more forthcoming about the changes they make?

In general, I agree with your point.  For example, some source-to-source
parallelizing compilers can simply list their output; the output language is
the input language, and often you can tell what input generated what output.

However, there are two possible pitfalls.  One RISK is that if a compiler
always puts out reams of messages, a user comes to ignore them, and may not
notice the important ones.

Another problem is that super-optimizers super-mangle code.  A change made
by a super-optimizers after many passes may have little or no relation to
the original source, and so a message may be totally inappropriate.

As one (possibly poor) example, consider the job of doing subscript checking
in Pascal.  Suppose that you already have a very good flow-analysis pass in
your compiler.  The straightforward approach would be to change
	var a, b: array [0 .. 10] of integer;
		i: 0 .. 255;
	...
	a[i] := b[i];
into
	if (i &lt; 0 or i &gt; 10) then
		abort(some message about a);
	if (i &lt; 0 or i &gt; 10) then
		abort(some message about b);
	a[i] := b[i];

I say ``straightforward'' because these statements can be generated
mechanically, yet it can be easily improved (if you have the good pass as
above).  A super-optimizer could remove the second ``if'', knowing that
there is no return from abort and hence no path in which i is out-of-bound
can reach the second ``if''.  It could notice that ``i'' is non-negative and
remove ``i &lt; 0 or''.  If the original statement were enclosed in
	for i := 0 to 10 do begin ... end
(a common case for arrays) then it could remove all the subscript-checking code.

The alternative would be to special-case the subscript-checking pass to
insert the checks only when necessary.  That would be far more error-prone
and more specialized.

(There are many other optimizations that introduce dead code; see your local
Dragon book.  In fact, because users rarely write dead code,
dead-code-elimination passes exist to clean up after the compiler itself.)

Alas, designing proper messages controlled by reasonable compiler options is
not an easy task.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Optimisers; Telecommunications Redundancy (Risks 6.94)
</A>
</H3>
<address>
Michael Wagner +49 228 8199645       
&lt;<A HREF="mailto:WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU">
WAGNER%DBNGMD21.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 01 Jun 88 12:20
</i><PRE>

In Risks 6.94, J M Hicks &lt;cudat@CU.WARWICK.AC.UK&gt; asked:
&gt;Does anyone wish optimisers were more forthcoming about the changes they make?

Yes, and for this reason, I've always liked the IBM translators, and
particularly the PL/I optimising compiler.  PL/I told you (as a
warning-level message) when it detected and deleted unreachable code.  PL/I
also gave you a complete attribute and cross-reference list, marking the
difference between reference and assignment.  These are features I really
miss in the C compilers I use now (including the IBM one, strangely).

I have had a number of philosophical discussions with people who feel that
such functionality (a) does not belong in a timesharing or micro environment
(because it produces long 'listings') and (b) does not belong in the
compiler.  While there might be a use for a tool that reads the defined
reference language and produces such information (like LINT and XREF), I
find it very useful when the compiler itself tells me.  Amongst other
things, it is reassuring me that it has the same understanding of the source
code as I (and perhaps the reference language) have.

In the same issue, Klaus Brunnstein wrote:
&gt; When analysing the missing redundancy in the ... `Deutsche
&gt; Bundes-Post', ...
&gt; our DATEX-P network has only one central communications controller
&gt; per area. ... Despite many discussions and arguments ...  the Post
&gt; office managers argue that today, redundancy does not pay

To make this a little more concrete, here in Bonn, the central switch is in
a little building on the banks of the Rhine.  For a variety of reasons, the
Rhine floods every year.  The last two years have been particularly bad.
Both Datex-P traffic and voice traffic in Bonn was badly hampered for days
this year because of minimal redundancy.  Nothing was done after last years
flood, and I sincerely doubt that anything is being done about it now.

Michael

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Major security hole in some sun systems
</A>
</H3>
<address>
Jim Purtilo
&lt;<A HREF="mailto:purtilo@flubber.cs.umd.edu ">
purtilo@flubber.cs.umd.edu 
</A>&gt;
</address>
<i>
Wed, 1 Jun 88 13:07:19 EDT
</i><PRE>

We at UMCP have just discovered (the hard way) that there is a major
security hole in a program called "rpc.rexd" on sun workstations.  This
program is intended to facilitate a form of remote execution between
appropriate workstations; the front-end program which is used to request the
remote execution is called simply "on".  Unfortunately, "rpc.rexd" fails
(miserably) in its check of whether the requesters should have the
permission to do what they ask for.

Because of the way on/rexd works, anyone who wishes can, given root access
to his own machine, become any uid he wants on any other machine running rex
*anywhere on the Internet*.  (Luckily, root appears to be the only exception
to this rule, if that is some small consolation.)  The authentication test
in the Sun3.2 rex daemon appears to proceed as:

	get the remote user id out of Unix-flavored authentication
	if it's zero, then deny access
	if getpwuid(remoteuid) is not NULL
		then grant access
		else deny access

In other words, any non-zero user identifier which happens to correspond to
a valid user on the target machine can be used to gain the privileges of
that user.  There is no check to see whether that user has granted "trusted"
status to the originating user and host (normally done via a file called
".rhosts" in many networked Unix systems), nor is there any check to see
whether a system administrator has generically granted such a trusted status
to the originating machine.

If you're running rexd and you're connected to a network, and if there are
people or places on your net whom you don't trust, then we suggest not
running rexd.  To see if you are running it now, look in your /etc/servers
table.  If the "rpc.rexd" line is missing or commented out, you're OK.  Sun
does not enable this daemon in the /etc/servers you read off the
installation tapes.

There are several ways that this problem seems relevent to the risks forum.
The most obvious is the risk of blindly trusting a vendor to ship you
software that performs at least `reasonable' security checks.  We will not
belabor that point here.  Instead, we provide yet another testimony to how
closely we must all watch what goes on our machines:  innocent intentions
can still lead to big headaches.  Most of the Suns in our network ran
version 3.0 of the Sun OS, served by a large central fileserver.  Rex
daemons were not readily available for this version, and there was no hole.
However, many individual research groups have suns of their own.  One day, a
guru running one of these individual Suns decided to be the first on his
block to upgrade to release 3.2.  He was not a staff member in our
department, but was in fact trusted with superuser access to the fileserver.
A well-intentioned chap, as he upgraded his owner's machine, he also
installed the new, cute looking goodies from the distribution on the
department fileserver so that all might benefit from his efforts.  Hence,
the normal scrutiny we would subject a new piece of software to was
bypassed.  Whether or not we would have found the hole when doing our normal
installation of this software is unclear, to be sure, but we would at least
liked to have had a shot at finding it.  You can only speculate at where we
have hidden the body of the late, otherwise well-intentioned, guru who
installed the rex daemon.

	Pete Cottrell, 	Steve Miller,	Jim Purtilo,	Chris Torek

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.01.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.03.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-44</DOCNO>
<DOCOLDNO>IA012-000129-B046-350</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.3.html 128.240.150.127 19970217021706 text/html 16446
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:15:33 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 3</TITLE>
<LINK REL="Prev" HREF="/Risks/7.02.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.04.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 3</H1>
<H2>  Friday 3 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
OTA Report: Science, Technology, and the First Amendment 
</A>
<DD>
<A HREF="#subj1.1">
Jan Wolitzky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Disasters and computer facilities 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Running as root; Hinsdale redundacy; Daedelus 
</A>
<DD>
<A HREF="#subj3.1">
David Herron
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Optimizing PL/I 
</A>
<DD>
<A HREF="#subj4.1">
Bard Bloom
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: Auckland cable cars 
</A>
<DD>
<A HREF="#subj5.1">
Richard A. O'Keefe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  My experience with metal balloons 
</A>
<DD>
<A HREF="#subj6.1">
David J. Edgerton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Halon 
</A>
<DD>
<A HREF="#subj7.1">
Romain Kang
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Virus collection 
</A>
<DD>
<A HREF="#subj8.1">
Robert Slade
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
OTA Report: Science, Technology, and the First Amendment
</A>
</H3>
<address>
&lt;<A HREF="mailto:research!wolit@research.att.com">
research!wolit@research.att.com
</A>&gt;
</address>
<i>
Thu, 2 Jun 88 08:02 EDT
</i><PRE>

The U.S. Congress's Office of Technology Assessment (OTA) recently issued a
special report that may be of interest to readers of the RISKS Digest.  It
is entitled, "Science, Technology, and the First Amendment," (OTA-CIT-369,
Washington, DC: U.S. Government Printing Office, January, 1988, 73 pp.,
$3.50).  The table of contents follows:

I. Freedom of the Press in the Information Age
	1. New Technologies for Gathering News and Information
		Newsgathering
		Computer Databases
		Media Satellites
		Implications for Privacy
		Implications for National Security
	2. New Technologies for Editing and Selecting News and
	     Information
		Electronic Publishing
		Editorial Control and Liability
		Global Networks and the International Press
	3. New Technologies for Publishing and Disseminating News
	     and Information
		The Convergence of the Media
		Cable Television
		Information Services Delivered Over Telephone Lines
II. Scientific Communications and the First Amendment
	4. National Security and Scientific Communications
		Science, Free Speech and National Security
		The Executive Branch and Classification of Documents
		Export Controls
	5. The 1980s: Converging Restrictions on Scientific
	     Communications
		Contractual Restrictions on Communications
		Restrictions on Informal Communications
		Self-Restraint
		National Security Directives and the Role of the
		  National Security Agency
	6. Constitutional Issues: An Overview

Jan Wolitzky, AT&amp;T Bell Labs, Murray Hill, NJ; 201 582-2998; mhuxd!wolit
(Affiliation given for identification purposes only)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Disasters and computer facilities
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
2 Jun 88 11:56:13 PDT (Thursday)
</i><PRE>

The 'Wall Street Journal' for Tuesday, May 31 features a story by Wendy L. Wall
headlined "FEW FIRMS PLAN WELL FOR MISHAPS THAT DISABLE COMPUTER FACILITIES"
(page 25 -- front page of Section 2).  The lead sentence says, "Welcome to the
era of the electronic disaster."

Starting with a review of the Hinsdale fire and its effects, the story discusses
"accidents that disable the concentrated computer and telecommunications
networks on which companies depend increasingly for basic tasks.... In a recent
University of Texas study, 75% of businesses surveyed said they would have a
'critical or total loss of functioning' within 14 days if they lost their
computer support.... Serious disruptions ... are becoming more common as
computers spread...."

"Most businesses are ill-prepared to cope with electronic disasters, computer
and communications specialists say....  Many top executives 'don't realize that
the value of the information  (in the computer) could very easily be worth
several times the value of their hardware, software and building,' says Steven
Christensen, a researcher at UT.  In addition, the cost of insurance or backup
computer systems can be high...."

Besides dividing operations between several sites, the other major precaution
taken by a growing number of companies is buying disaster insurance to use
backup computer centers and networks:  "The two largest disaster-recovery
companies ... have nearly 1500 clients...."

The major example used in the story is that of wholesaler United Staioners,
which has spent nearly $1 million a year on emergency preparations which served
them well in the present Hinsdale fire:  "Within hours, they dispatched a 31-man
team, with backup data tapes, to an insurer's computer facility in New
Jersey.... By the next day, they had reconstituted their entire computer
network.... Although all this cost some $600,000 over two weeks, including a
$40,000 fee for the insurer and travel costs for the 31 people sent to New
Jersey, it probably saved the company at least $30 million in sales during that
time, says United Staioners' CEO.  Even more important, he adds, was the boost
to customer confidence."

                                   [Stationers?  Stainers?  Stallioniers?  P.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
A few points from recent risks
</A>
</H3>
<address>
David Herron 
&lt;<A HREF="mailto:david@ms.uky.edu">
david@ms.uky.edu
</A>&gt;
</address>
<i>
2 Jun 88 16:36:56 GMT
</i><PRE>
Organization: U of Ky, Math. Sciences, Lexington KY

Running as root bad:

Someone from CMU berated the fella who'd messed up his disks for doing dumps as
root and suggested instead running as "sys".  hmm.  My first thought was "what
about files that people have protected against global reading?  You'd need root
to be able to read them".  But dump reads directly from the device... no
problem.  I'd suggest a small change -- make the permissions "400" rather than
"444" to prevent "everyone" from being able to read the disk.

In general however I've found it very good to engrave some of the more mystical
and hard to remember incantations into shell scripts and the like.  One of the
first projects I did here was to come up with a backup procedure for our
systems.  I of course used shell scripts for the whole thing...  I also put a
sticker on the console giving the format of the backup command for those times
when I was typing it directly, and relied on that sticker to jog my memory.

Multiple routes aren't multiple routes if they're the same physical route:

About the Hinsdale stuff.  There were a number of trunks heading into the same
building using the same exact physical route, right?  And the claim was that
the trunks were going over different routes.  Well, this just isn't a very good
assumption -- obviously.  One only needs to remember the arpanet outage a year
or so ago where a backhoe dug up some cables.  All of New England's ARPANET
traffic was ultimately routed through the cables that were in that one trench,
yet they were separate cables going over different "routes".
    
sigh                                                     [See <A HREF="/Risks/4.30.html">RISKS-4.30</A>.  PGN]

I think that we (as telecommunications customers) should have the ability to
demand proper seperate routes (physical routes) for backup communications ...

Daedelus thumb stuff:

Um, joke or no I'm surprised nobody got scared over the same thing I was
immediately scared over.  That there's all these financial transactions sitting
on my thumbnail and every time I purchase something I'm potentially telling the
store all of my financial dealings for the past N months.  That's a disclosure
of information they have no need or right to know.  Weell... they have a "need"
in that it would give them a better idea of who they're dealing with, but I
certainly don't want to be giving them such detailed information.

David Herron

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Optimizing PL/I
</A>
</H3>
<address>
Bard Bloom 
&lt;<A HREF="mailto:bard@THEORY.LCS.MIT.EDU">
bard@THEORY.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 2 Jun 88 23:22:40 edt
</i><PRE>

&gt; Yes, and for this reason, I've always liked the IBM translators, and
&gt; particularly the PL/I optimising compiler.  PL/I told you (as a
&gt; warning-level message) when it detected and deleted unreachable code.  

The last time I used an IBM PL/I optimizing compiler (some years ago), I had
a procedure which took two 32-bit integer arguments.  I called it with the
constant arguments 1 and 1.  It produces some cosmically weird results.
Eventually I put a print statement after the procedure entry; when the 1's
got passed to the procedure, they were somehow transformed into 65536's.

Somehow the compiler was interpreting the 1's as 16-bit numbers and putting
them in the wrong half of the 32-bit arguments.  I immediately switched to
non-IBM PASCAL.
                                        -- Bard Bloom

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Auckland cable cars (Willis Ware, RISKS-7.1)
</A>
</H3>
<address>
Richard A. O'Keefe
&lt;<A HREF="mailto:quintus!ok@Sun.COM ">
quintus!ok@Sun.COM 
</A>&gt;
</address>
<i>
2 Jun 88 07:38:09 GMT
</i><PRE>
Organization: Quintus Computer Systems, Mountain View, CA

It's about a year since I was last home, but Auckland didn't have any
cable cars then, and I very much doubt that they've got any now.  (The
Museum of Transport and Technology has a small tram system, but those
are old trams and have no computers.)  There's a cable car in Wellington
such as Willis describes, but then, Wellington is only the capital, can't
expect people to get _that_ right.  If the paper was the Sun, I've heard
that it's typeset by computer, perhaps that is the risk story?

    [Willis noted he read an Auckland newspaper.  We'll assume the cable 
    cars were really in Wellington, unless someone else contradicts it...  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
My experience with metal balloons
</A>
</H3>
<address>
&lt;<A HREF="mailto:edgerton%csdpie.DEC@decwrl.dec.com">
edgerton%csdpie.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
Thu, 2 Jun 88 14:26:20 PDT
</i><PRE>

About 2 years ago (Summer of 86) I bought a metallic balloon for my 2-year old
daughter.  It had a metal "string" about six feet long.  When we were getting
into the car, she let go of it, and it flew up into the corner of the parking
lot and tangled up in the power transformer there.  It shorted out the
transformer and killed power for half the town.

After my initial surprise at the damage, and feeling lucky that I didn't have
to pay for the damage, several thoughts crossed my mind.

  1. That metal string should never have been used.  Some powerline droop
     fairly low.

  2. I jokingly told some friends that you could really "take out" the power of
     a town fairly easily.  I was not aware how fragile our power system was.

  3. The potential for mischief and vandalism implied by #2.
                                                              David J. Edgerton

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Halon
</A>
</H3>
<address>
Romain Kang
&lt;<A HREF="mailto:pyrnj!romain@rutgers.edu ">
pyrnj!romain@rutgers.edu 
</A>&gt;
</address>
<i>
2 Jun 88 19:26:02 GMT
</i><PRE>

In RISKS 6.87, Anita Gould asks about dry-run tests of halon equipment.
Here is a fortunate experience from such a dry-run:

To test that the equipment had been installed properly in a computer
room, a gas other than halon was put in the tanks.  The alarm was then
triggered manually, and the room was evacuated.  

Normally, the operator would have manually shutdown the system (Operating
System, not power down), and then left the room.  Since this was only a
drill, the operator left immediately.

When we returned to the room, one of the 'dispersers' from the tank
had shot itself across the room and was embedded in the wall.  These 
'dispersers' are cork-screw shaped metal objects, and have quite a point.
In line with the trajectory of the disperser was the operator's chair at
the console.

If the operator had actually stayed too long in the room to insure an orderly
shutdown of the system, his own shutdown would have instead occured.

The tank was then turned to aim elsewhere, but the dispersers are normally
not supposed to leave the tank.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Virus collection
</A>
</H3>
<address>
&lt;<A HREF="mailto:Robert_Slade@mtsg.ubc.ca">
Robert_Slade@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Thu, 2 Jun 88 07:15:54 PDT
</i><PRE>

Re: my offer of the collected virus messages:  please note that American
postage is no longer acceptable.  Send a 5 1/4" double sided, double density
MS-DOS 2.xx or 3.x formatted 360K floppy diskette, with a self addressed
*Canadian* stamped mailer to: Robert Slade, 3118 Baird Road, North Vancouver,
B. C.   V7K 2G6

Thanks to all of those who have followed the proper form.  I hope the American
stamped packages have not suffered too greatly at the hands of customs.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.02.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.04.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-45</DOCNO>
<DOCOLDNO>IA012-000129-B046-386</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.4.html 128.240.150.127 19970217021721 text/html 25504
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:15:47 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 4</TITLE>
<LINK REL="Prev" HREF="/Risks/7.03.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.05.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 4</H1>
<H2>  Monday 6 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Review article on privacy/civil liberties risks in CACM 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  RISKS of wrong numbers and tigers 
</A>
<DD>
<A HREF="#subj2.1">
Steve Nuchia
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Academic Assignment of Viruses 
</A>
<DD>
<A HREF="#subj3.1">
Bill Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Peter J. Denning on Terminology 
</A>
<DD>
<A HREF="#subj4.1">
Bill Kinnersley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  COMPASS '88 PROGRAM 
</A>
<DD>
<A HREF="#subj5.1">
Frank Houston
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Halon agreement and the ozone models 
</A>
<DD>
<A HREF="#subj6.1">
Rob Horn
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Review article on privacy/civil liberties risks in CACM
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Sun, 05 Jun 88 17:32:33 PDT
</i><PRE>

Many readers of this digest will be interested in the article, "Information
technology and dataveillance," Roger A. Clarke, Communications of the ACM,
31(5): 498 - 512, May 1988.  This is a long review with 78 references.

The author defines "dataveillance" to mean the systematic use of computing
technology in the investigation or monitoring of the actions or 
communications of one or more persons.  He distinguishes betwen "personal
surveillance" - surveillance of an identified person, where there is a
specific reason for the investigation, and "mass surveillance" - surveillance
of large groups of people in order to identify individuals who might be of
interest to investigators.  The author concludes that computing technology
is making it much easier to perform both kinds, a lot of it is going on 
and more can be expected.  

The author says he does not argue that surveillance
is intrinsically evil or that it should be ruled out altogether, but 
argues that much of what is in fact now going on is in general a bad thing,
especially the mass surveillance.  He concludes that privacy and civil
liberties protections in place in most countries are inadequate to protect
against these new surveillance techniques.  The author says that he feels
people working in computing, due to their special knowledge, have some 
special responsibility to consider privacy implications of their work,
evaluate safeguards, and lobby for effective ones.

- Jon Jacky, University of Washington

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
RISKS of wrong numbers and tigers
</A>
</H3>
<address>
Steve Nuchia
&lt;<A HREF="mailto:nuchat!steve@uunet.UU.NET ">
nuchat!steve@uunet.UU.NET 
</A>&gt;
</address>
<i>
4 Jun 88 18:32:45 GMT
</i><PRE>
Organization: Public Access - Houston, Tx

(Paraphrased from The Houston Post, 29 April)

A local newscast carried a story on a Herpes research project under way at
Baylor College of Medicine, and displayed a phone number for volunteers to call
- with appropriate assurances of confidentiality.

Not only was it the wrong number, it was the number for the "back door" to the
public address system at Baylor (No indication of how large an area was covered
- it is a big place.)

The callers, hearing a pick up but no answer "assumed it was an answering
machine" and "gave their names, phone numbers, everything."

I believe this points up an important "human factor."  People are a lot less
cautious when they initiate a contact than when they are contacted.  This
explains the easy success of the typical "service spoof" attacks - password
harvesters and "night deposit box out of order" scams.  I don't have a magic
answer for designers of services - it is very hard to design a service that is
at all hard to spoof if the clients aren't at least a little bit cautious.


Second item:

One of the tigers went through a window in a door and killed an employee.  It
was at night and the public would not have been in immediate danger even in the
daytime, but the incident nevertheless caused quite a ruckus.

The firm that designed the enclosure stated that the door design, including the
window pane used, was "standard" for that kind of application.  The tiger had
no trouble going through it, and there was no indication that it was defective,
nor that any other tiger would have had any trouble going through any other
door of like design.

(Zoo officials have the big cats in holding cages while the window materials
used in the (relatively new) cat facility are tested - by swinging miniature
wrecking balls into them.  The cat facility is a modern close-contact one - you
can routinely find one of the lionesses sleeping against a window with the
public on the other side - in a tunnel.)

Apparently quite a few nominally professional people in the world think that
standards excuse them from thinking.  Perhaps that explains the popularity of
standards?

Applicability to computers?  Gee, there aren't any people clamoring for
standards in the computer industry, are there?

Steve Nuchia  uunet!nuchat!steve  (713) 334 6720

  [Yes, but we've always had tiger teams trying to break system security.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Academic Assignment of Viruses
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Sun, 5 Jun 88 10:25 EDT
</i><PRE>

A society that depends upon any mechanism for its own proper functioning,
cannot tolerate, much less encourage, any tampering with the intended
operation of that mechanism.

Therefore, one is tempted to rise up in indignation at the idea of a qualified
academic assigning a virus to his students.  The next thing you know, they will
be assigning plagiarism.  How about the forgery of academic credentials?
Perhaps we should offer a course in how to falsify research results.  Or,
perhaps, on how to trash another's experiments, notes or reports.

Perhaps it is a sign of immaturity that we are unable to recognize the moral
equivalency.  I will leave open the question of whether the immaturity is in
the technology, the society, or academia.

I thought that we put this issue to bed several years ago when we stopped
assigning the breaking of security.  It seems that we did not.

For an academic to be unable to recognize that assignments, and the recognition
that goes with their successful completion, encourages the behavior assigned,
demonstrates a lack of understanding of the activity in which he is engaged.
If he understands it, and still makes such an assignment, he demonstrates a
lack of understanding of where his real interest rests.

Such irresponsible behavior may account, in part, for the anti-academic bias in
our society and for the manifest distrust of the scientific establishment.  It
is of little wonder that the citizens of Cambridge, Massachusetts are reluctant
to trust the likes of these with genetic engineering.

If there is any lesson that we should have learned from the computer, it is
that understanding the effects of what we intend for it to do is a daunting
task.  Even getting it to do what we intend is not trivial.  It seems to me,
that there is plenty of material here for assignments; we need not look to
assignments which are at best trivial, and at worst, dangerous.

William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
2000 National City Center Cleveland, Ohio 44114                          
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840                

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
  Peter J. Denning on Terminology
</A>
</H3>
<address>
Bill Kinnersley 
&lt;<A HREF="mailto:iphwk%MTSUNIX1.BITNET@CUNYVM.CUNY.EDU">
iphwk%MTSUNIX1.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 6 Jun 88 12:02:13 mdt
</i><PRE>

        Subscribers to this list may be interested in the recent article
"Computer Viruses" by Peter J. Denning in the American Scientist, vol 76
page 236.  In particular, he discusses terminology.  Paraphrasing his
definitions:

1) Worm - a program that invades a workstation and disables it.
        &lt;one copy per machine, RAM resident, self propagation via network&gt;

2) Trojan horse - a program that performs some apparently useful
        function, but containing hidden code that performs an
        unwanted malicious function.
        &lt;file resident, propagation by unwitting human beings&gt;

3) Bacterium - a program that replicates itself wthout bound,
        thereby preempting the resources of the host system.
        &lt;many copies per machine, RAM resident, self propagating&gt;

4) Virus - a program that incorporates copies of itself into the
        machine code of other programs, and when those programs
        are invoked, performs a malicious function.
        &lt;two phase life cycle - RAM form with self propagation,
                                file form with human propagation&gt;

        Denning points out that these types often occur in combination.
A Trojan Horse is the most common means of originally introducing a
virus into a system.  For example, a Trojan Horse compiler can attach
a copy of the virus code to its output.

Defence against computer viruses comes out sounding like a message
from the Surgeon General.  Practice digital hygiene yourself.  Don't
exchange programs with anyone whose computer habits are not up to
your own standards.  Refuse to use software if the manufacturer's
seal has been broken!

        Maybe we need a "Centers for Computer Disease Control".

                          [No comments on the last sentence, please.  Recent 
                          issues of RISKS have beaten that idea to death.  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
COMPASS '88 PROGRAM
</A>
</H3>
<address>
Frank Houston
&lt;<A HREF="mailto:houston@nrl-csr.arpa ">
houston@nrl-csr.arpa 
</A>&gt;
</address>
<i>
Thu, 2 Jun 88 12:46:15 edt
</i><PRE>

            *****************************************
            *                                       *
            *            COMPASS '88                *
            *     JUNE 27th - July 1st, 1988        *
            *                                       *
            *     NATIONAL BUREAU OF STANDARDS      *
            *         Gaithersburg, MD              *
            *                                       *
            *           ADVANCE PROGRAM             *
            *                                       *
            *****************************************

* MONDAY,  27 JUNE 1988 *

Meeting of the Tri-services Software Safety Working Group

* TUESDAY, 28 JUNE 1988 *

0730    REGISTRATION
0900    CALL TO ORDER
        General Chair---CDR Mike Gehl, Office of Naval Research
0910    OPENING REMARKS
        Honorary Chair---Helen Wood, Deputy Director, Institute for 
	Computer Sciences and Technology, National Bureau of Standards
0930    PROGRAM OVERVIEW
        Program Chair---Janet Dunham, Research Triangle Institute
0940    INTRODUCTION OF KEYNOTE SPEAKER AND PANEL
        Chair, COMPASS Board---H.O. Lubbes, Space and Naval Warfare 
        Systems Command
0950	KEYNOTE ADDRESS
        Chair, Keynote Panel---Dr. Roger McCarthy, Failure Analysis, Inc.
        "THE PRESENT AND FUTURE SAFETY CHALLENGES OF COMPUTER CONTROL"
1100    COFFEE BREAK
1130    KEYNOTE DISCUSSION
        PANEL:	 Herb Hecht, SoHAR, Inc.
       	         Peter Neumann, SRI International
                 Jim Treacy, Federal Aviation Administration
       	         Andres Zellweger, Computer Technology Associates
       	         William J. Rodda, DELCO Electronics Corp.
1300    LUNCH BREAK
1430    RISKS AND BENEFITS
        Chair---Janet Dunham, Research Triangle Institute
        * "The Computer Related Risk of the Year:  Computer Abuse"
       	         Peter Neumann, SRI International.
        * "Alzheimer's Patient Monitoring System"
       	         Doris Rouse, Research Triangle Institute
        * "Advance Computations into the Third Millenium"
       	         James P. Farell
1530    COFFEE BREAK
1600   	WHAT IS SOFTWARE SYSTEMS SAFETY?
        Chair---Al Friend, Space and Naval Warfare Systems Command
        * "Software Systems Safety and Human Error Avoidance"
       	         Mike Brown, Naval Surface Warfare Center
        * "A Definition of Process Security"
       	         John McDermott, Naval Research Laboratory
        * "Definitions and Requirements for Distributed Real-Time Systems"
       	         Christina Berggren, IBM System Integration Division
        * "An Approach to Software Safety Analysis in a Distributed 
        Real-Time System"
       	         Sang H. Son and Chun-Hyon Chang, University of Virginia 
       	         and Paul V. Shebalin, ORI
1730    ADJOURN
1900    BANQUET 
        * "Stalking the Wily Hacker"
       	         Cliff Stoll, Lawrence Berkeley Laboratories

* WEDNESDAY, 29 JUNE 1988 *

0900    RELIABILITY AND SECURITY OF VOTE COUNTING SYSTEMS:
        Chair---Lance Hoffman, George Washington University
        Panel:   Roy Saltman, National Bureau of Standards
       	         Emmett Fremaux, Jr., District Board of Elections and Ethics
		 Peter Neumann, SRI International
1000    ENGINEERING ERROR FREE SPECIFICATIONS
        Chair---Sam DiNitto, RADC
        * "Overview: Complementary Completeness"
       	         Sam DiNitto, RADC
        * "Early Detection of Requirements Specification Errors"
       	         Paul C. Jorgensen, Arizona State University
        * "Reliable Software Specification"
       	         John McLean, Naval Research Laboratory
        * "An Investigation of the Reliability of a Software 
        Specification"
       	         Janet Dunham, Research Triangle Institute
1100    COFFEE BREAK
1130    DESIGNING SAFETY CRITICAL SYSTEMS
        Chair --- Peter Neumann, SRI International
        * "Designing Safety Critical Systems: The Viper Microprocessor"
       	         Dr. John Cullyer, Royal Signals and Radar Establishment
        * Question and Answer Session
1300    LUNCH BREAK
1430    SOFTWARE PRODUCT ASSURANCE: TECHNIQUES FOR REDUCING SOFTWARE RISK
        Chair---Dolores Wallace, National Bureau of Standards
        * "Software Product Assurance:  Reducing Software Risks in 
        Critical Systems"
       	         William Bryan and Stanley Siegel, Grumman Corporation
        "FIPS 132/IEEE 1012 SVV Plans Standard"
       	         Dolores Wallace, National Bureau of Standards
1600    COFFEE BREAK
1630    VERIFICATION, TESTING, AND ANALYSIS
        Chair---Michael Brown, Naval Surface Warfare Center
        * "Predicting Computer Behavior"
       	         Don Good, Computational Logic, Inc.
        * "On Back to Back Testing"
       	         Mladen Vouk, North Carolina State University 
        * "A Static Scheduler for the Computer Aided Prototyping System"
       	         Dorothy Janson and Prof. Luqi, Naval Post Graduate School
        * "The IBM Software Quality and Productivity Program"
       	         Anne Martt, IBM Houston
1800    ADJOURN


* THURSDAY, 30 JUNE 1988 *

0900    SOFTWARE SAFETY MODELING AND MEASUREMENT 
        Chair---Herb Hecht, SoHaR
        Panel:  Jerry Mauck, Nuclear Regulatory Commission
                Douglas R. Miller, George Washington University
       	        Dev Raheja, Technology Management, Inc.
1015    USE OF MODELING TOOLS: A VARIED APPROACH
        Chair---Don Lee, Aerospace Corporation
        Panel:  Sal Bavuso, NASA-Langley Research Center
     	        Nancy Leveson, University of California-Irvine
1100    COFFEE BREAK
1130    PANEL DISCUSSION:  SAFETY REVIEW PROGRAMS
        Chair---George Finelli, NASA-Langley Research Center
        Panel:	Mike Brown, Naval Surface Warfare Center 
       	        Frank Houston, Food and Drug Administration 
       	        Mike Dewalt, Federal Aviation Administration
1300    LUNCH BREAK
1430    CASE STUDIES: OPERATIONAL SAFETY AND PROCESS SECURITY CONSIDERATIONS 
        Chair---Dan Strub, U.S. Air Force
        * "On Software Safety Management"
       	         Jim Dobbins, Verilog
        * "A Methodology for Analyzing Avionics Software Safety"
       	         Bob De Santo, LOGICON, Inc.
        * "A Case Study of System Integrity for Alcohol Taxation"
       	         T. F. Buckley, P.W. Garratt, and T.G. Gough, Leeds Univ., U.K.
        * "Update on the Safety Verification of the B1 Bomber"
       	         Joe Cantu, Boeing Military Airplane Company
        * "The Centaur Project"
       	         Helen De Mao, Corporation for Studies and Analysis
1600    BREAK

1630    CASE STUDIES: ASSURING MEDICAL SOFTWARE
        Chair---Frank Houston, Food and Drug Administration
        * "A Methodology for Assuring Medical Software"
       	         Roger Fujii, LOGICON
        * "Formal Safety Analysis and the Software Engineering Process in 
        the Pacemaker Industry"
       	         D. Santel, C. Trautman, and W. Liu, Medtronic, Inc
        * Discussion/Question and Answer 
1800    ADJOURN

* FRIDAY, 1 JULY 1988 TUTORIALS *

0900    Software Safety and Process Security in the Ada Reusable Software 
        Environment
       	         E.V. Berard, EVB Software Engineering, Inc.
0900    Verification and Validation
       	         Dolores Wallace, National Bureau of Standards
       	         and Roger Fujii, LOGICON, Inc.
1200    ADJOURN


REGISTRATION--Preregistration closes 17 June 1988.  On-Site registration 
will begin on 28 June 1988 from 0730 to 0900 in the NBS Administration 
Building.  Persons attending the Tri-Service Software Systems Safety 
Working Group may register there on 27 June 1988 between 1530 and 1730.

PARKING--Parking is available in the NBS Visitors Parking Lot adjacent to
the Administration Building.

TRANSPORTATION--For those attendees who will be driving, the National 
Bureau of Standards is located on Clopper Road near the I-270 interchange 
approximately 12 miles north of I-495 (marked "National Bureau of 
Standards/ Clopper Road" for northbound travelers; or "National Bureau of 
Standards/Route 124 Darnestown" for southbound travelers).  For attendees 
who do not wish to drive, the conference hotels are accessible from Dulles, 
National and BWI airports by regular limosine service with no reservation 
required.  Also, NBS provides shuttle service to and from the Shady Grove 
Metrorail Station (on the Red Line) on the quarter and three-quarter hour 
(0815, 0845, ... 1715) from the West side KISS AND RIDE lot.  COMPASS will 
provide a shuttle morning and evening between NBS and the conference 
hotels.

MEALS--The registration fee includes lunches on Tuesday, Wednesday, and 
Thursday, and Dinner on Tuesday evening.  Refreshments will be available at 
all breaks.



FOR ON-LINE or hard-copy REGISTRATION FORMS, PLEASE CONTACT FRANK HOUSTON
 houston@nrl-csr.arpa .

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Halon agreement and the ozone models
</A>
</H3>
<address>
Rob Horn
&lt;<A HREF="mailto:harvard!ulowell!infinet!rhorn@husc6.harvard.edu ">
harvard!ulowell!infinet!rhorn@husc6.harvard.edu 
</A>&gt;
</address>
<i>
Thu, 2 Jun 88 19:31:50 edt
</i><PRE>

The real risk with the freon-halon-ozone controversy is best
understood when you realize that the Third World countries were
major opponents to the production freeze.  The major uses of
freons are:
 1) Refrigeration
 2) Manufacturing
 3) Fire Protection (only about 10%)
Freons have been shown to be much cheaper and much safer than the
alternative technologies.  Only recently have there been
indications that equally safe refrigeration technologies can be
practical, and these will be many times more expensive.

In the Third World refrigeration means much more than a cool car. 
It can mean the difference between life and death.  In food
production, refrigeration allows produce to reach markets, to be
stored safely.  Without it (and most underdeveloped countries
lack adequate refrigeration) food spoils, farm incomes drop
dramatically, people go hungry, people starve.  In medicine,
refrigeration means medicines that don't spoil and blood
transfusions.  Lack of refrigeration means death.  So the Third
World countries opposed the removal of freons.  Why agree to many
thousands of deaths just to keep the Americans happy?  The future
environmental destruction is a good reason, but with so much at
stake the evidence must be persuasive.  Even with the new
technologies, they must weigh the huge increase in costs against
their limited incomes.

The evidence from the computer models is weaker than the press
reports indicate.  The measurements of world ozone show an
*increase* of about 5% from 1960 to 1975 followed by a much
larger and faster decrease of about 15% since then.  The computer
models do not predict or explain that increase.  Their
predictions of what altitudes would have how much of a decrease
do not match the observed decreases.  The models did not predict
the Antarctic `hole', although this has a tentative explanation. 

I believe that the real deciding factor was the intuitive
decision by the negotiators that while the models were pretty
inaccurate, the measurement data was accurate enough to make the
trend very worrisome.  The rapid action following confirmation of
the satellite data calibration is consistent with this.  It also
is evidence of a cautious approach towards computer models.  The
research level was dramatically increased, both into the
atmosphere and into freon substitutes, after the initial modeling
results were published.  Freon uses with easy substitutions
(spray propellent) were eliminated in the US.  Oddly, the
Europeans did not follow suit.  The drastic changes were studied,
but no action taken until there was much more information.

The Montreal agreement also places real emphasis on more data gathering and
analysis following the agreed freeze and reduction in production.  The
reduction goal can be met with changes in refrigeration and manufacturing
without any change in fire protection uses.  The United States may move
internally for much larger reductions.  The large chemical companies may decide
to switch production entirely when suitable substitutes are found.  Dow has
announced its intention to completely phase out freon production.  The
international agreement is to reduce somewhat, then wait for more evidence from
measurements.
				Rob  Horn

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.03.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.05.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-46</DOCNO>
<DOCOLDNO>IA012-000129-B046-420</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.5.html 128.240.150.127 19970217021737 text/html 27316
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:16:01 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 5</TITLE>
<LINK REL="Prev" HREF="/Risks/7.04.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.06.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 5</H1>
<H2>  Tuesday 7 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Auckland cable cars (in Wellington) 
</A>
<DD>
<A HREF="#subj1.1">
Mark Davies
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Perfect computers 
</A>
<DD>
<A HREF="#subj2.1">
Hugh Cartwright
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Assigning viruses 
</A>
<DD>
<A HREF="#subj3.1">
Ian G Batten
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Programmer sabotage 
</A>
<DD>
<A HREF="#subj4.1">
Bob Devine
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  First Interstate disaster planning and the L.A. fire 
</A>
<DD>
<A HREF="#subj5.1">
Jeff Lindorff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Telecommunications redundancy 
</A>
<DD>
<A HREF="#subj6.1">
Joel Kirsh
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Look and Feel Copyright Issue 
</A>
<DD>
<A HREF="#subj7.1">
Karl A. Nyberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of root typos 
</A>
<DD>
<A HREF="#subj8.1">
Tim Pointing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Access to DEC VMS 5.0 technical seminar 
</A>
<DD>
<A HREF="#subj9.1">
Claude Barbe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Risks of bank ATM cards 
</A>
<DD>
<A HREF="#subj10.1">
Karl Denninger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Re: Australia Card 
</A>
<DD>
<A HREF="#subj11.1">
Greg Bond
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Auckland cable cars (in Wellington) (Richard A. O'Keefe)
</A>
</H3>
<address>
Mark Davies 
&lt;<A HREF="mailto:ames!comp.vuw.ac.nz!mark@uunet">
ames!comp.vuw.ac.nz!mark@uunet
</A>&gt;
</address>
<i>
Sun, 5 Jun 88 14:00:01 +1200
</i><PRE>
Organization: Comp Sci, Victoria Univ, Wellington, New Zealand

The cable car was in Wellington (in fact a guy in an office down the hall
was waiting to catch it at the time and watched it go right past the stop
and into the buffers at the end of the line).  I had intended to post
something at the time but the newspaper reports were pretty vague.

The cable car had only recently come back in service after its major yearly
maintenance which apparently included a rewrite of its controlling
software.  The braking system failed to engage, and several people suffered
minor injuries.  The current status (several weeks after the accident) is
that the cable car is still not running and samples of the code have been
sent to the manufacturer, a European (Swedish?) firm.

This is from memory, more details when/if they become available.    mark

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Perfect computers
</A>
</H3>
<address>
&lt;<A HREF="mailto:HCART%VAX.OXFORD.AC.UK@CUNYVM.CUNY.EDU">
HCART%VAX.OXFORD.AC.UK@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
7-JUN-1988 09:32:02 GMT
</i><PRE>

The Sunday Times in the U.K. has produced, and is offering for sale, videos on
microcomputing, because ''...there is clear evidence that British management
has not yet appreciated the benefits of the microcomputer revolution.''

One of the benefits the Sunday Times has identified (June 5) is new to
most of us reading the RISKS forum, I suspect:

    ''In the computerised office information, once entered, is always
available....It is impossible to introduce an error, because the
transaction is entered once only.''

The discovery by the Sunday Times of computers that can prevent entry
of faulty data (provided, evidently, the entry is attempted once only),
must be of interest to us all.

But what of those reading the article who might believe it ?

Hugh Cartwright, Oxford University.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Assigning viruses (RISKS-7.4)
</A>
</H3>
<address>
Ian G Batten 
&lt;<A HREF="mailto:BattenIG%uk.ac.bham.cs@CUNYVM.CUNY.EDU">
BattenIG%uk.ac.bham.cs@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 07 Jun 88 17:46:49 BST
</i><PRE>

Talking of teaching virus-writing, WHMurray@DOCKMASTER.ARPA writes "The
next thing you know, they will be assigning plagiarism.  How about the
forgery of academic credentials?"

One of the UK Polytechnics (virtual Universities) assigned a student
exercise that was to break into some system (I seem to recall it was an
11/44 running V7) and assign yourself an "appropriate" mark.  There was
quite a row about it at the time (about two or three years ago).  I'm
afraid I can't recall any details beyond its being a London poly.

ian    University of Birmingham Computer Science Department

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Programmer sabotage
</A>
</H3>
<address>
Bob Devine
&lt;<A HREF="mailto:devine%cookie.DEC@decwrl.dec.com ">
devine%cookie.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
Tue, 7 Jun 88 10:50:46 PDT
</i><PRE>

This is not really a "risk" but is yet-another case of increased legal
definition of programming.                                  Bob Devine

    A programmer was found guilty under a Colorado law when he destroyed a
  program.  A legal research company hired him to write a personal computer
  application that would permit a lawyer to search for relevant case law.
  
    When a deadline was approaching and a leave request was refused, the
  programmer resigned, telling the company that they would never have the
  program.  When the program could not be found on the system after he left,
  the company had to start over.

    The programmer was found guilty of theft and computer crime.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
First Interstate disaster planning and the L.A. fire (RISKS-7.3)
</A>
</H3>
<address>
Jeff Lindorff
&lt;<A HREF="mailto:jeffl@sequent.UUCP ">
jeffl@sequent.UUCP 
</A>&gt;
</address>
<i>
6 Jun 88 21:09:37 GMT
</i><PRE>

The following is excerpted from an Associated Press article by George Garties.
I can attest to the effectiveness of the measures described within as a 
customer of First Interstate Bank. Not once, in my experience, has a banking
problem at my local branch been blamed on the Los Angeles fire.


AFTER THE TOWERING INFERNO, FIRST INTERSTATE DOSEN'T MISS A BEAT

Cole Emerson has known for two years that when the big earthquake hits
California, it will be his job to get First Interstate Bank back into business.

When the city's worst high-rise fire swept the bank's headquarters last month,
Emerson saw his disaster plans put to the test, and by all accounts, they passed. 

[The May 4 fire gutted 4 1/2 floors of the 62-story building, killing a
maintenance man and closing the building for an indefinite period of time.]

But by the start of banking hours the next day, the vital business of First
Interstate Bankcorp, the nation's 9th-largest bank holding company, was
proceeding. And only one of the company's 320 California branches was closed.
The one on the building's ground floor.

Emerson, 42, is in charge of contingency planning and computer security. He is
assigned to First Interstate Bank of California, although in the headquarters
fire, his plan and staff also helped restart the parent company, which owns
banks in 13 states and franchises in 10 others.

He recalled that shortly after the fire broke out, his five-member "business
resumption group" and a parallel group that deals with staff safety opened the
bank's new emergency center in a computer operations building seven blocks
from the downtown headquarters.

As damage reports came in, Emerson's group orchestrated moves for the vital
groups that work in the headquarters.

They saw the securities trading department dispersed, with traders flying to
company offices in Hong Kong and New York, as well as taking borrowed space in
Los Angeles. They were prepared, since the disaster plan calls for traders and
other key employees to carry home diskettes bearing vital records from their
personal computers.

The main computers handling the bank's daily rush of consumer and business
transactions weren't in the headquarters, but if they had been knocked out,
they would have been backed up in Northern California.

The disaster plan was developed to deal with a great earthquake. The state
Office of Emergency Services says odds are better than 50% that such a quake
will hit the region in the next 25 years.

"An earthquake is real, and it's catastrophic, and it's going to happen,"
Emerson said. "There's nobody in my position in any of the banks who's going
to say 'if.' It's always 'when it's going to happen.' I feel even more 
confident right now that we're well on the way to being prepared for that."

Jeff

(Not employed by Sequent Computer Systems, Beaverton, OR., so don't blame them.)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Telecommunications redundancy
</A>
</H3>
<address>
Joel Kirsh 
&lt;<A HREF="mailto:KIRSH@NUACC.ACNS.NWU.Edu">
KIRSH@NUACC.ACNS.NWU.Edu
</A>&gt;
</address>
<i>
Wed, 1 Jun 88 10:34 CDT
</i><PRE>

    The mention of government involvement in assuring robustness of
telecommunications jogged my memory.  I recall reading of a particular
U.S. government agency, which is solely responsible for taking control
of telecomm services in the country in the event of a national emergency,
to insure that the government's communications abilities are maintained.
    The article went on to describe that the agency's control center was
located within the blast radius of several primary nuclear targets, and
no plans had been made to build redundant control centers.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Look and Feel Copyright Issue
</A>
</H3>
<address>
Karl A. Nyberg
&lt;<A HREF="mailto:karl@grebyn.com ">
karl@grebyn.com 
</A>&gt;
</address>
<i>
Tue, 7 Jun 88 14:11:57 edt
</i><PRE>

Text of an article in the Wall Street Journal this morning.  (I claim USC 17
in reproduction of this article for fair use, or whatever the appropriate
legal term is...)

This could have a chilling effect on the future development of software if
the ruling is applied very broadly.  I'm trying to get an actual copy of the
specific ruling.

-- Karl, Grebyn Corporation, 703-281-2194  --

U. S. Agency Rules Software Copyrights Protect Displays on Computer Screens
By Bob Davis,  WSJ, Tuesday June 7, 1988, p. 4.

WASHINGTON - The Copyright Office, in a boost to software publishers, ruled
that software copyrights protect displays on computer screens from
infringement.

Protecting software, either by patents or by copyrights, has been a muddled
field of law in recent years.  In a major case this year, Apple Computer,
Inc. sued Microsoft Corp. and Hewlett-Packard Co. in March for copying
certain graphical display features that Apple popularized in its Macintosh
personal computers.  An Apple spokeswoman, however, said yesterday's ruling
doesn't directly affect that case.

Besides Apple, Lotus Development Corp. has tried to protect innovative
computer displays by bringing copyright-infringement cases against
competitors.  But in cases of this type, it hasn't been clear whether
copyright protection extends to instances in which companies, using
different computer codes, generate displays that look like those of popular
programs.

The Copyright Office, a part of the Library of Congress, rules that when a
software company copyrights a program, it automatically copyrights the
graphic and textual displays produced by the program.  At the same time, the
Copyright Office said publishers don't need to register any display or
textual screen separately.

"We think the screen will be protected, no matter what the code" used to
create it, said Richard Glasgow, the Copyright Office's assistant general
counsel.

As an example, Mr. Glasgow said that if Apple copyrights its Macintosh
software, the copyright "probably" protects the trash-basket symbol Apple
uses to tell users how to discard files.  Apple would only need to prove it
has "an original drawing" of the trash basket to be covered by the
copyright, he said.

... stock information ...

Decisions of the Copyright Office, which sets rules governing copyrights,
are influential in federal courts that interpret those rules.  Copyright
protection lasts for 50 years after the death of an author or for 75 years if
a company commissions the work and retains the copyright.

Jason Mirabito, a Boston copyright attorney, said the copyright decision
gives "greater protection and certainty" to software publishers.  Had the
Copyright Office required publishers to register every computer screen, he
said, judges would likely have interpreted the protection narrowly to cover
only exact copies of the disputed display screens.

But Mr. Mirabito said the broader copyright protection would likely
encourage judges to rule that software publishers can protect their programs
from competitors that merely "look and feel" like popular programs, but
aren't exact copies.

However, computer veterans worry that if protection is extended too broadly,
it may harm consumers and retard innovation, because it will slow the
development of standardized displays.  With such displays, computer users
wouldn't have to learn a new set of commands with every new software
program.

Moreover, "look and feel" cases are especially murky.  If Shakespeare were
alive, Mr. Mirabito speculated, he could have a copyright infringement case
against "West Side Story" because it's very similar to "Romeo and Juliet."

The Apple spokeswoman said the ruling doesn't affect the suit against
Microsoft and Hewlett-Packard, filed in San Jose, Calif., because Apple had
filed separate copyright applications covering both the "literary and
audio-visual" aspects of the display features it wanted to protect.

In its suit, Apple also accused Microsoft of exceeding the limits of
licenses granted to it by Apple to use certain display features.  At the
time, computer industry analysts and intellectual property experts
interpreted the suit as Apple's attempt to preserve a technological edge
just as rivals were starting to close the gap.

    [This case never ceases to amaze me, particularly in that much of
    the innovation came from Doug Engelbart's Augmentation Research Center
    at SRI in the 60's and 70's, and thence from Xerox PARC.  PGN]

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of root typos
</A>
</H3>
<address>
Tim Pointing
&lt;<A HREF="mailto:tim%dretor@uunet.UU.NET ">
tim%dretor@uunet.UU.NET 
</A>&gt;
</address>
<i>
Fri, 3 Jun 88 11:42:32 EDT
</i><PRE>

In Risks v6n92, Dave Sherman &lt;dave@lsuc.uucp&gt; writes...
about accidental mis-use of dump wiping out a filesystem. The same sort of
incident happened here earlier this year when somebody (who shall remain
nameless to protect the horribly guilty [not me]) was running fsck on a
PDP 11/70 running V7. This person's only mistake was leaving out a space.
Instead of typing
	"fsck -t tempfile /dev/rroot"
s/he typed
	"fsck -ttempfile /dev/rroot"

(for those not familiar with the old fsck, the "-t" flag specified
a temporary file for holding tables that grew too big for small address
space machines). Unfortunately, this fsck came from well before the time
that "getopt" existed and manually parsed the arguments. It expected the
temp filename as the argument after the "-t", not glued to it.  The
result was that fsck used the root filesystem device for its temporary
storage (to ensure that the damage was severe, fsck starts by zero'ing
the temporary file :-) and started checking a default filesystem. In the
blink of an eye, the first 400 blocks of the filesytem were gone. Combine
this typo with a flakey emergency system which, for reasons we have yet
to determine, restored files incorrectly, and you can see that we had some
*real* fun getting the system back on-line.

Tim Pointing, DCIEM

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Access to DEC VMS 5.0 technical seminar
</A>
</H3>
<address>
"Claude Barbe - SDR - (203) 431 5524" 
&lt;<A HREF="mailto:BARBE%sdr.slb.com@RELAY.CS.NET">
BARBE%sdr.slb.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Fri, 3 Jun 88 10:03 EDT
</i><PRE>

Working in the US under a 3 year L1 visa, I first could not enroll in
the DEC VMS 5.0 technical seminar since I was not a US citizen nor holding
a "green card". What surprised me is 1) the regulation that forces DEC to
inquire about citizenship (the IRS is not that picky...) and 2) the menu
system to accept my application could not handle L1 visa numbers...

Claude Barbe - Schlumberger-Doll Research, Ridgefield, CT

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Risks of bank ATM cards (more) (<A HREF="/Risks/6.94.html">RISKS-6.94</A>)
</A>
</H3>
<address>
Karl Denninger
&lt;<A HREF="mailto:mordor!lll-crg!lll-winken!ddsw1!karl@rutgers.edu ">
mordor!lll-crg!lll-winken!ddsw1!karl@rutgers.edu 
</A>&gt;
</address>
<i>
Thu Jun  2 16:08:19 1988
</i><PRE>
Organization: Macro Computer Solutions, Inc., Mundelein, IL

Here's another risk in the use of the ATM cards:

At New Century Bank in Mundelein, IL there is an ATM terminal.  About a
month ago I used this terminal to make a sequence of transactions.  The
final transaction, a withdrawal of $20.00 was denied with a message "Cannot
complete, try later".  The card was ejected, with *no receipt* indicating
failure.  Thinking nothing of it, I went to another bank and obtained my cash.

About three weeks later the *same* thing occurred.  Suspecting something funny
was going on, I reinserted the card, and discovered to my horror that the ATM
had indeed debited my account, yet not dispensed any cash -- AND NO RECEIPT.

This time I got a little peeved.  The bank with the terminal (New Century) was
unable to help at the time of the incident -- they claimed they had to wait for
the "proof" from the machine the next day.  My bank said the same thing.

The next day, my bank said that yes, indeed, there was a transaction
recorded, and to their knowledge *it was paid by the machine*.  They put in
a charge-back request to New Century.

Upon more stringent questioning, they admitted that the charge-back might be
refused by New Century Bank, and that since I had no receipt to prove that
the transaction failed, I could be out the amount of the transaction in
question!   (the card agreement clearly states that receipts from the
machines are considered "official" evidence of a transaction or failure
thereof, and that they are the *only* evidence which the bank will accept!)

I placed a call to "Cash Station, Inc" (the regional company handling the 
ATMs in this area) in an attempt to discover why the machines had been 
programmed to not issue receipts on failed transactions.   Reaching someone 
with authority there took two days (!), and when I finally did get through 
the end result was that no change would be made.

New Century did eventually own up to having a problem -- in fact, they said
that after investigation I was not the only one who had been "hosed".  My
questions were (and still are):

o Why was this not caught when the machine was balanced?  It would seem as
  though if the machine recorded a debit of $20.00, and didn't issue the
  cash, that the machine would be out of balance by $20.00....

o After discovering that the machine was out of balance, why did New Century
  not attempt to rectify the problem themselves, or place the machine out of
  service until it was working properly?  WHY DID THEY POCKET MY CASH?

o Why was a decision made to not issue receipts on denied transactions,
  and why does Cash Station, Inc. refuse to *require* that institutions
  issue these receipts?  

o While I was on the phone with Cash Station, Inc. I inquired as to 
  the display of balances (this was another "sticking" point with me; they
  were often off by hundreds of dollars).  Their reply was that the network
  which interconnects the ATMs "cooks" your balance (!) depending on what
  you do at the terminal.  In other words, the balance shown by the terminal
  MAY NOT BE YOUR TRUE BALANCE.  When I asked as to why there was no
  indication anywhere that these numbers were "finagled" they indicated that
  the response time of the member bank's computers was insufficient to get a
  real balance.... sounded (and still sounds) fishy to me.  Isn't this
  *literally* fraud, as they claim that number on the screen to be your 
  BALANCE? (along this line, the machines do not dispense receipts on
  balance inquiries either -- perhaps to prevent you using these as
  "evidence".)

It would appear that someone (or many someone's) have been making out like
bandits on these "failures" -- I was hit twice within 30 days, at the same
terminal.  How many others (who don't balance their checkbooks and thus
never catch this kind of error) have also been taken for a ride?  

What is most disturbing is that there was no indication that the problems
would be resolved -- that is, no one was willing to state that they would
begin (now or any time in the future) to provide receipts on all
transactions in order to facilitate proof of what had occurred.

I have decided to boycott all ATMs in the Chicago area until I receive some
satisfactory answers to these questions.  So far no one has been able to
provide them.  I suggest that others who are concerned for the safety of
their funds also boycott the ATMs.  Go to a Jewel (food store), where you 
can still use the card, yet you deal with a *human* who hands you your money.

Karl Denninger, Macro Computer Solutions, Inc.    ...ihnp4!ddsw1!karl

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Re: Australia Card [RISKS DIGEST 6.94]
</A>
</H3>
<address>
Greg Bond
&lt;<A HREF="mailto:munnari!vertical.oz.au!greg@uunet.UU.NET ">
munnari!vertical.oz.au!greg@uunet.UU.NET 
</A>&gt;
</address>
<i>
Thu, 2 Jun 88 12:32:50 EST
</i><PRE>
Organization: Vertical Software, Melbourne, Australia

This card was intended as a plastic card. I never saw any intention of
a smart-card system. The initial idea came from the HEALTH department,
as all eligible residents carry a "Medicare" card for the national
health system. The Australia Card was to replace the Medicare card for
the health system, and was also to be used for taxation, social
security and other financial transactions. (For example, to open bank
accounts, or start jobs, or employ brokers/agents, so any taxable
transaction could be followed.) As the idea evolved, more and more
departments and uses were included. I think over a dozen departments
and 25+ "systems" were to have access to (part of) the database.

With 15M people, that is one ENORMOUS database.

The benefits the Govt. were flogging (and quite hard too) was savings
on social security and tax fraud. (Numbers like $1b/year - about 2-3%
of the Govt. budget).

There was to be a "Data Protection Agency" that was to monitor and
control access to the sections of the database. No-one really believed
it would work.

The idea was killed after the largest, loudest and longest public
campaign I have seen. Many groups joined in, from the looney left to
the radical right, including most professional Computing and
Engineering bodies, as well as the obvoius civil liberties groups.

The RISKs? This proposal took on an awesome momentum, and grew
frighteningly fast. I'm glad it was killed off before it started
as unwinding or even slowing the increase would be enormously 
difficult. And governments aren't known for taking tough decisions.

One of the arguments in favour of the card was that with one centralised
database, and legislative controls over access, we as citizens would
actually be better off as far as protection and privacy were concerned.

Comments?

Gregory Bond,  Vertical Software, Melbourne, Australia
Internet: greg@vertical.oz.au	(or greg%vertical.oz.au@uunet.uu.net)
Bang: {uunet,mcvax,pyramid,mnetor,ukc,ucb-vision,...}!munnari!vertical.oz!greg
struct responsible for(these_opinions) { return me &amp;&amp; !my_employer; }

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.04.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.06.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-47</DOCNO>
<DOCOLDNO>IA012-000129-B047-16</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.6.html 128.240.150.127 19970217021751 text/html 16365
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:16:19 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 6</TITLE>
<LINK REL="Prev" HREF="/Risks/7.05.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.07.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 6</H1>
<H2>  Wednesday 8 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Buggy ATC Software 
</A>
<DD>
<A HREF="#subj1.1">
Paul Fuqua
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  The Challenger and visionary software architects 
</A>
<DD>
<A HREF="#subj2.1">
Kent Stork
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  How To Stop A War 
</A>
<DD>
<A HREF="#subj3.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  UK Poly; another root typo 
</A>
<DD>
<A HREF="#subj4.1">
Matt Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Re: The Australia Card 
</A>
<DD>
<A HREF="#subj5.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Risks of bank ATM cards 
</A>
<DD>
<A HREF="#subj6.1">
John Pershing
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  ATM risks - the figures in UK 
</A>
<DD>
<A HREF="#subj7.1">
Alasdair Rawsthorne
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Buggy ATC Software
</A>
</H3>
<address>
Paul Fuqua 
&lt;<A HREF="mailto:pf@ti-csl.csc.ti.com">
pf@ti-csl.csc.ti.com
</A>&gt;
</address>
<i>
Tue, 7 Jun 88  18:12:18 CDT
</i><PRE>

From the Dallas Morning News, June 7, 1988, without permission:

     "Glitches" in a new computer program used by air traffic
controllers at Dallas/Fort Worth International Airport can temporarily
obliterate information on altitude, airspeed, ... types of aircraft in
the area ... the call signs [,] and intended destinations of aircraft.
     The same program is used at airports in Houston, Los Angeles, and
Atlanta.
     "When the program is running and it detects a glitch in the system
... it will remove the alphanumerics on the screen for a period of 20
seconds or less," said Lawrence Parrent, assistant air traffic manager
at the D/FW Terminal Radar Approach Control center, or TRACON.
     ....
     An audible alert is sounded when the data blocks are about to
disappear, and FAA officials say the controllers have up to five seconds
to either write down the information or memorize it.
     Parrent said FAA officials do not believe the glitch constitutes a
safety hazard.  "The radar has not failed," he said.  "The primary
target is still there."  The radar image and a four-digit number
assigned to each aircraft remain on the screen.
     ....
     Parrent said that the new program offers many features that improve
the margin of safety in air traffic operations ...
     [Discussion of potential problems if the "glitch" occurs during
holding patterns or handoff from en-route controllers to approach
controllers.]
     FAA officials say controllers are able to determine the altitude of
aircraft just as they did before the software was developed -- by asking
the pilots.
     [Comments from Parrent about controller uneasiness.]
     [Testing began in January, increased to 24-hour-a-day use after
April.]
     "The reason we are testing with live traffic is that we do not have
the capability to simulate the number of targets in off-line
conditions," Parrent said.  "We have to test under actual conditions.
     "It's like other aviation-type equipment -- just like an airplane.
You put it in a wind tunnel and it looks great, but you still have to go
out there and put a test pilot in it and fly the darn thing."

End of article.

Comments:

The system itself is obviously aware of a problem, or it wouldn't be
able to sound a warning.  Wouldn't it be better to leave the information
on the screen, even if updates are frozen until the 20-second problem is
over?  Even if the only benefit is to avoid disturbing the controllers?
And "up to five seconds" to record information on "up to ten" aircraft?
(The number's in the article, I just omitted it.)  Did anyone ask the
controllers what *they* would like to see in the new program?

The FAA apparently considers this a minor problem because when it fails
it's just equivalent to the old system.  What about (a) becoming
dependent on the new features and (b) the "startle factor" when the
warning sounds?  Did the problem show up before the peak-period testing?
If so, how come it hasn't been fixed in five months, and if not, isn't
that an extra worry?

Since I'm working on simulations and simulators at the moment, I can
sympathise with the inadequacy of off-line testing, but I'd rather the
field-test were on something less important than an air-traffic control
system.  Sounds like a good argument for better simulation technology and
more computing power to use what's already there.

Paul Fuqua, Texas Instruments Computer Science Center, Dallas, Texas

-------------------------------

Date: Tue, 7 Jun 88 12:37:37 HST
From: stork@humu.nosc.mil (Kent Stork)
Subject: The Challenger and visionary software architects

The May issue of Defense Science validates something that many computer
scientists have probably suspected: ultimately, the failure of the Challenger
and the death of the astronauts was due to a control loop software design
oversight - just another bug.

To what extent must software architects be visionaries? Certainly the
requirements are proportional to the power of the system the software controls.
Do such visionaries exist to design our Challengers and our other more
aggresive weapons?

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
How To Stop A War (Dunningan and Martel)
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 8 Jun 88 00:45:16 EDT
</i><PRE>

Of some small relevance to Risks, and of possible interest to readers, is
a recent book:  "How To Stop A War", James F. Dunnigan and William Martel,
Doubleday 1987.  The authors are military analysts, not peace marchers.
A good look at the realities of why wars start or don't.  (Sample:  "As
long as there have been technically complex weapons, there have been
accidents.  For example, one sixth of the losses of modern battleships
were due to accidental explosions.  If such a formidable ship can
accidentally demolish itself, it's no wonder users are fearful about
the safety of current systems...  During the 1986 Air Force raid on
Libya, two F-111 aircraft were needed for every one that got through
in working order to drop its bombs.")

Henry Spencer @ U of Toronto Zoology  {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
UK Poly; another root typo (RISKS-7.5)
</A>
</H3>
<address>
Matt Bishop
&lt;<A HREF="mailto:bishop@bear ">
bishop@bear 
</A>&gt;
</address>
<i>
Wed, 8 Jun 88 08:02:36 EDT
</i><PRE>

   The UK Polytechnic that Ian Batten was talking about is described as
case 78.066 in the book "Computer Insecurity" by Adrian Norman (Chapman
and Hall, New York, c. 1983, p. 191.)  This book, incidentally, is an
excellent collection of incidents involving computer security (or lack
thereof) and even does some analysis to show some things that lead to
security problems.  (The computer was a DEC10 system, not a PDP-11/44;
other than that, though, the details are exactly the same.)

   Yet another root typo story: a certain person who had superuser privileges
once accidentally typed "exit" rather than "halt" to leave superuser
mode.  The former does just that; the latter halts the CPU ... 
                                                                   Matt

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: The Australia Card [RISKS DIGEST 7.5]
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:nsc!taux01!taux01.UUCP!amos@Sun.COM ">
nsc!taux01!taux01.UUCP!amos@Sun.COM 
</A>&gt;
</address>
<i>
8 Jun 88 05:32:25 GMT
</i><PRE>

Israel  does implement  a system  of  a national  ID card,  used by  all
government  agencies,  banks, hospitals,  employers,  etc.  There is  no
central database (yet!) but information cross-over is relatively easy.

Last month  a man  requested for  a loan  from a  bank; his  request was
denied because (the bank claimed) he  had just applied for the same type
of loan  two years  ago. Checking it  out, the poor  guy found  out that
there was another man  with a similar name, who had  the same ID number,
and what's more, the other guy was a criminal wanted by the police.

It  seems that  the criminal  had  lost his  ID  card a  few years  ago,
requested a new one,  and the Ministry of the Interior  had issued him a
new one - with the other man's  number! They claim that since the system
has been computerized by now, such a mistake cannot happen again...

Amos Shapir, National Semiconductor (Israel)
6 Maskit st. P.O.B. 3007, Herzlia 46104, Israel  Tel. +972 52 522261

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Risks of bank ATM cards (more) (<A HREF="/Risks/6.94.html">RISKS-6.94</A>)
</A>
</H3>
<address>
John Pershing 
&lt;<A HREF="mailto:PERSHNG@ibm.com">
PERSHNG@ibm.com
</A>&gt;
</address>
<i>
8 Jun 88 08:32:35 EDT
</i><PRE>

In reply to Karl Denninger's posting...

I don't see any risks in his story that can be attributed specifically to
the use of ATMs, as opposed to the more general use of a Bank.  If
anything, the risk is assuming that a transaction that is "untouched by
human hands" will be less likely to go wrong when, in fact, it is more
likely to have something go wrong.

Specific points:

  -  The error undoubtedly *was* caught when the machine was counted out
     at the end of the day (assuming that your bank follows accepted
     accounting procedures).

  -  They didn't know it was "your cash".  The machine ended up the day
     with too much money, which means that one (or more) of the 500
     people who used the machine that day got short-changed.  Undoubtedly
     people were assigned to look into the problem if it has happening
     on a regular basis (probably a mechanic was sent out to clean and
     oil the ATM).

  -  I have never gotten a receipt for a failed transaction.  Requiring a
     receipt for a failed transaction sounds sort-of bogus to me, as one
     of the (dozens of) failures that can happen is that the receipt
     printer breaks or runs out of paper.

  -  There is no such thing as a "true balance" from the bank's point of
     view, as you undoubtedly have a bunch of "paper" (checks, credit
     charges, etc.) floating around that they haven't seen yet.  Also,
     contrary to popular opinion, electronic funds transfers are seldom
     posted against the "bank of record" in real-time -- rather, they go
     onto a tape somewhere and get fed in at night.  So, any "balance"
     that your bank would report is necessarily flakey.

     Indeed, there are response-time requirements placed on banks that
     are wired in to ATM networks (typically a few seconds).  Since the
     "real" records are on a tape in the back room, the "front-end"
     computer only has your balance as of last night (or, maybe the night
     before) plus the electronic transactions that it has seen go by.  It
     may have missed some electronic transactions, e.g., due to crashing
     and/or a network failure.  It hasn't seen any of the day's paper.
     The electronic transactions that it has seen haven't been verified yet.

Electronic banking systems are incredibly complicated.  It is impossible to
even imagine the number of things that can go wrong, or the number of ways that
clever consumers can subvert the system.  Of course, this is nothing new with
ATMs -- financial fraud has been around as long as banks.  It is quite sensible
for an ATM's programming to "lean" in the bank's direction is there is
something amiss, because the consumer will always go complaining to a bank
officer.  When was the last time that you got *over*-changed and actually
reported it?

Go ahead and boycott the machines if you want.  However, if you want them
to improve, then you have to exercise the system so that the bugs will be
found and fixed.  If your bank is not responsive to your bug reports, then
find another bank.

John Pershing, IBM Research, Yorktown Heights

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
ATM risks - the figures in UK
</A>
</H3>
<address>
Alasdair Rawsthorne 
&lt;<A HREF="mailto:alasdair%unix.cs.man.ac.uk@NSS.Cs.Ucl.AC.UK">
alasdair%unix.cs.man.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Wed Jun  8 14:19:19 1988
</i><PRE>

I have always refused to possess an ATM card, on the grounds that the
individual is not well protected against the banks' errors, particularly
since bank employees perceptions of the possibility of malfunctions differ
from mine.

My feeling has been strengthened in the past by one or two highly
publicised cases of the banks' intransigence in the face of complaints of
``phantom'' withdrawals from ATMs.

I've not seen a case of this type now for a few years, and was beginning to
succumb to the idea that the safeguards have improved, when I came upon an
article describing the UK Banking Ombudsman.  He is the arbiter of last
resort for customer complaints, and will only accept cases that have
exhausted the relevant bank's internal complaints procedure (usually at
general manager level).

According to Money Management(June '88), the Banking Ombudsman received 198
complaints in March 1988.  The category with the highest number of
complaints was.....

``Cashcards - unauthorised withdrawal'' with 17 (~9%) complaints.

Are there any figures for other countries banking systems?

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.05.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.07.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-48</DOCNO>
<DOCOLDNO>IA012-000129-B047-44</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.7.html 128.240.150.127 19970217021803 text/html 21833
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:16:31 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 7</TITLE>
<LINK REL="Prev" HREF="/Risks/7.06.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.08.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 7</H1>
<H2>  Friday 10 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Accidental breach of software security 
</A>
<DD>
<A HREF="#subj1.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  "Sewage flows into river; Computer Failure Blamed" 
</A>
<DD>
<A HREF="#subj2.1">
Randal L. Schwartz
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Canadian Public Service warned against SINing 
</A>
<DD>
<A HREF="#subj3.1">
John Coughlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Betting network crash in Australia 
</A>
<DD>
<A HREF="#subj4.1">
George Michaelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  John Pershing on ATMs  
</A>
<DD>
<A HREF="#subj5.1">
David Thomasson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  A typo in "UK Poly; another root typo" 
</A>
<DD>
<A HREF="#subj6.1">
Matt Bishop
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: The Challenger and visionary software architects 
</A>
<DD>
<A HREF="#subj7.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  COMPASS '88 CONTACT 
</A>
<DD>
<A HREF="#subj8.1">
Frank Houston
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Accidental breach of software security
</A>
</H3>
<address>
Martin Minow THUNDR::MINOW ML3-5/U26 223-9922
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
9 Jun 88 16:08
</i><PRE>

From Electronic Engineering Times, June 6, 1988, condensed and abstracted.

	Unauthorized access to software cited
	       Shuttle security lapse
		 by Richard Doherty

An accidental breach of software security at Rockwell International Corp.
gave unauthorized engineers and programmers access to raw code being prepared
for the space shuttle Discovery's return to space, now slated for Aug. 22.
The six-month lapse in security resulted from "an unintentional keyboard
error," Last November, the most recent embodiment of "Operational Increment"
shuttle software (revision OI8-A) was somehow stripped of its normal RCAF
[Resource Access Control Facility] protection... [IBM] Engineers discovered
on Nov. 22, 1987, that they were able to modify the code while in the
supposedly restrictive "browse" mode.  An IBM supervisor then immediately
notified NASA, and by afternoon's end, a weekend-long bit-by-bit comparison
was initiated.

NASA says that in all, 16 changes were made.  The agency still does not know by
whom or when.  Because multiple copies of the OI8-A software existed at that
time, NASA said there is no chance the security breach could endanger the
mission.

NASA conducted a six-month long inquiry into how the event happened.
As a result, the agency said it now knows the normal protection was
somehow stripped off during a change in editing modes (between integer
and block) and who the operator was at the time.

But NASA said it still doesn't know how many accesses were made and by
whom over a six-month period.  Nor has it discovered why it took six
months to notice the code was open to editing.

Shuttlegate?

The acknowledgement by NASA and Rockwell engineers came in the wake of
a $5.2 million lawsuit field by shuttle engineers who were dismissed
after expressing concern about overall OI8-A software vulnerability,
among many other problems, to Rockwell management last fall.

The engineers, Sylvia Robins and Ria Solomon, first took their concerns
to the company's ombudsman, then to the NASA Inspector General and,
eventually, to the White House.

Finally, seeing no action taken on their concerns regarding accelerated
software verification audits and a steady lack of secure data access,
Robins and Solomon took action by filing a lawsuit here [Houston] against
Rockwell and its prime software contractor, Unisys, last fall.  That action
triggered widespread denial by Rockwell of the lawsuit's many safety concerns,
including the charge of lax shuttle programming security that was finally
acknowledged last month.

[There's more, but this is getting long.  Any idea what "between integer
and block" modes mean?]                           Martin

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
"Sewage flows into river; Computer Failure Blamed"
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Tue, 07 Jun 88 10:34:13 PDT
</i><PRE>
From: Randal L. Schwartz &lt;mipos3!merlyn%intelob.Berkeley.EDU@ucbvax.Berkeley.EDU&gt;

Page one (below the fold) of the 6/7/88 morning edition of The
Oregonian (Portland, Oregon) reports:

[BEGINNING OF ARTICLE]
"Sewage flows into river; computer failure blamed"

* The five-hour spill from the Sullivan Pump Station poured about 5.4
million gallons into the Willamette River downtown

A computer failure caused about 5.4 million gallons of raw sewage to
spill into the Willamette River in downtown Portland early Monday,
prompting state officials to warn against recreational use of the river
through Tuesday morning.

"That's a major spill," said Shirley Kengla, spokeswoman for the Oregon
Department of Environmental Quality.

[What a quote!  We Oregonians now know what a major spill is...
sheesh.]

The spill began about 3 a.m. when a computer failure at the Sullivan
Pump station caused sewage to flow directly into the river [...]. The
spill was stopped by 8 a.m. [...].

Peterson [operations director] said the computer failure was caused by
a loss of electrical power, shutting down the pumps at the pump
station.

He said the computer system was designed so that the operators could
override computer commands at the station, but they discovered Monday
they could only do that when the computer had electrical power [!!!].
Monday's loss of power prevented that.

[... more stuff about volume and repair efforts ...]

Kengla said the DEQ is investigating the spill.

"Because it was a computer failure, it was an accident [!!!] and for
that reason, we're just looking toward making sure it doesn't happen
again," she said.

[... more stuff about location of spill ...]

Contact with the water could cause sickness with severe flu-like
symptoms.

In June 1985, another computer failure caused the dumping of more
than 3 million gallons of raw sewage into the Willamette from the
same pump station.  Kengla said that state and city officials had
been working to prevent a recurrence of the problem.

"We thought we had done enough, but obviously we hadn't," she said.
[Brilliant quotes!]

[... stuff about another tiny spill last year, not computer-related...]
[END OF ARTICLE]

(1) Why did they have a computer-controlled system that depended on
    electrical power to operate with no backups?

(2) Given that they already had a failure before, how could they have
    failed to design a failsafe system?

(3) The statements made by the spokeswoman, like "because it was a computer
    failure, it was an accident..." make me wonder.  Why should an accident
    be so obviously required to happen after a computer failure?  Why
    should we not *plan* for the system to break?  These guys obviously
    didn't.

Sheesh.  And during Rose Festival too!

-- Randal L. Schwartz, Stonehenge Consulting Services (503)626-6907
on contract to Intel Technical Publications: merlyn@omepd.intel.com (for now)

      [Moderator's note: This article was also reported by  
      Andrew Klossner &lt;andrew%frip.gwd.tek.com@RELAY.CS.NET&gt; and by
      Richared {?} England, Mentor Graphics Corp., Customer Services, 
        Technical Support, Beaverton, Oregon, pdx.MENTOR!rengland@uiucdcs.
      The abridged version from Randal was chosen for brevity, but the
      following comments from R. England are also worth including:

          [This case] points out, once again, the need for total design
          consideration.  A truly fail-safe system would include manual
          overrides instead of requiring all control signals to originate
          from the automatic control system.  Conversation with the writer
          lead me to believe that there was a wide-spread power loss which
          may have precluded operation of the pumps as well, in which case
          nothing would have helped.  Note, however, that the computer gets
          the blame.   [R. England]
          
</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Canadian Public Service warned against SINing
</A>
</H3>
<address>
John Coughlin 
&lt;<A HREF="mailto:JC%CARLETON.BITNET@CORNELLC.CCS.CORNELL.EDU">
JC%CARLETON.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
10 Jun 88 10:25:00 EDT
</i><PRE>

   The  following article appeared in the Ottawa Citizen,  Friday June  10,
and is reproduced without permission.

===========================================================================

PS warned against SINing

By Iain Hunter
Citizen staff writer

   Treasury Board President Pat Carney has ordered bureaucrats who run hundreds
of federal programs to SIN no more.  And Justice Minister Ray Hnatyshyn has
warned that the government may bring in laws to regulate the collection and use
of the social insurance number if other levels of government and the private
sector don't follow the federal example.

   Carney announced Thursday that the use of the individual identity number
will be phased out over five years in several institutions to reduce the risks
of invasion of [...] privacy.  Carney said the use of the SIN will be
restricted mainly to the administration of tax, pension and social benefit
programs.  Any new collection or use of the SIN beyond those covered under the
new policy will have to be approved by Parliament.

   A Treasury Board spokesman said "hundreds" of programs in which the number
is now used will be affected by the new restrictions.  The cost of phasing out
the use of SIN is estimated at $16 million.

   Privacy Commissioner John Grace called Carney's announcement heartwarming
and said it puts the federal government "in a much stronger moral position to
preach controls on the use of SIN to other governments and the private sector."

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Betting network crash in Australia
</A>
</H3>
<address>
George Michaelson 
&lt;<A HREF="mailto:munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET">
munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 09 Jun 88 09:40:23 +1000
</i><PRE>

Earlier this week (Monday) the T.A.B suffered a major loss of a
computerised betting control system which caused much anguish to punters
across the state of Victora.  I phoned their computer manager &amp; got a
loose description of the problem, he was understandably reticent since
the network manages many millions of dollars of bets daily, and there
are public relations issues aside from the security ones.

	Brief Description of TAB &amp; Gambling:
	++++++++++++++++++++++++++++++++++++

Gambling, the 4th most ancient vice after programming sex, religion and
politics is endemic in Australia.  It is also very tightly controlled by
the state, concentrating in several HUGE casinos with banks of "pokeys"
or one-armed bandits, and of course the ponies. [remember phar lap anyone?]

Apart from pre-computed instant win cards and lotterys the only [legal]
form of betting off the racetrack in Australia is run by the T.A.B.  or
Totalizer Agency Board.

They run a "totalizer" scheme, where the pool of cash placed in any
given race is split into the dividend, so that the winnings are more
"socially" adjusted, and also not simply calculated from starting price
("SP" bookmakers thrive in the better drinking establishments and police
stations, according to popular myth &amp; corruption tribunals) however
there is an element of feedback, in that offered "odds" are obviously
adjusted according to the poolsize as well as traditional form, much as
in normal betting.  the "divi" depends on the size of the pool and is
post-close-of-betting calculated, although a running total could be
available (I don't know for sure, I'm not a gambling man you
understand...)

Each state has a transaction processing network which underpins this
exercise, so that the pool/dividend holds across the entire state for
each race.

	The Problem:
	++++++++++++

The Victorian T.A.B.  uses a tightly coupled "cluster" of 5 nodes
handling the incoming transactions, and a central node that acts as a
controller and calculates the divi.  Some form of shared memory is used
to do all this.

At some stage in the day the central node noticed an inconsistency in 2
separate pools, across two of the nodes.  They were disconnected,
possibly automatically.  Afterwards, the entire network was taken down
and the betting calculated manually to prevent any data inconsistency
being propagated out into the real world.  -From the "feedback"-y nature
of the tote algorithm it's plausible that had this not been done, many
many thousands of punters would have been rooked of their winnings..
actually perhaps they would have made too much money as well!

-The problem was verbally ascribed to software, but no details are
available.  According to radio reports over $1M was lost due to the much
less efficient manual methods.  Punters were furious.


I wanted to end with some pun about shutting the sTABle door after the
horse has bolted, but I can't think of a good punchline.

        George Michaelson, CSIRO Division of Information Technology

ACSnet: G.Michaelson@ditmela.oz                      Phone: +61 3 347 8644
Postal: CSIRO, 55 Barry St, Carlton, Vic 3053 Oz       Fax: +61 3 347 8987

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     John Pershing on ATMs 
</A>
</H3>
<address>
        David Thomasson 
&lt;<A HREF="mailto:ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU">
ST401405%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 09 Jun 88 09:38:27 EDT
</i><PRE>

A tip of the hat to John Pershing (pershing@ibm.com) for his reply
concerning risks of ATM's (RISKS 7.6). This piece is truly a standout in
that it is (a) not anecdotal and (b) not hysterical in tone. I commend it to
others as a model for crafting their arguments and replies.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
A typo in "UK Poly; another root typo" (Re: RISKS-7.6)
</A>
</H3>
<address>
Matt Bishop
&lt;<A HREF="mailto:bishop@bear.Dartmouth.EDU ">
bishop@bear.Dartmouth.EDU 
</A>&gt;
</address>
<i>
Thu, 9 Jun 88 09:01:57 EDT
</i><PRE>

   Error in my last letter: he typed "halt", not "exit"; "halt" halts the CPU
and "exit" takes you out of superuser mode.  Sorry for the boo-boo.    Matt

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: The Challenger and visionary software architects 
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@amelia.nas.nasa.gov">
eugene@amelia.nas.nasa.gov
</A>&gt;
</address>
<i>
Thu, 09 Jun 88 16:16:29 PDT
</i><PRE>

&gt;From: stork@humu.nosc.mil (Kent Stork)
&gt;The May issue of Defense Science validates something that many computer
&gt;scientists have probably suspected: ultimately, the failure of the Challenger
&gt;and the death of the astronauts was due to a control loop software design
&gt;oversight - just another bug.

I have grabbed the May issue of Defense Science (an oxymoron):

%A Yale Jay Lubkin
%T The Challenger Disaster
%J Defense Science
%V 7
%N 5
%D May 1988
%P 13-18 (actually only 3 pages)

This article neither validates nor mentions software, bugs, or computers.
There are two sets of problems 1) Kent's comment, and 2) the article itself.
The article is basically a summary of different causal hypotheses: the
cold joint and the AW&amp;ST puncture (Abu-Taha) hypotheses.  There is a good
tone of conspiracy in the paper, but I am not in a position to side in
defense of Washington bureaucrats or Lubkin.

The closest comment to "control loop software design" is:
	"It was not the leak that killed the astronauts.  It was the
	attempt to correct the sidethrust, which sent the Challenger
	into violent oscillations.
There are probably some difficulties in asserting "cause."  Further:
	"If the Challenger had been permited to go off course,
	without attempting the major correction, the side booster would
	not have broken out, the booster would have burnt out with the
	Callenger still intact, and the crew could have ejected, off
	course but aslive."
This latter is probably false, but we will not really know.  I don't usually
trust words like "ultimately."

Researching this article did have a positive side benefit while in the library,
I found a good 5 page obit to Richard Feynman in Engineering and Science
[Caltech's Alumni magazine].

There is a very "hardware must fly" orientation in NASA, and you should
understand software is not well understood in the Agency.  
This was documented by internal reports [Sagan et al. 1980].
Any disaster will have underlying PHYSICAL causes sought.

&gt;To what extent must software architects be visionaries? Certainly the
&gt;requirements are proportional to the power of the system the software controls.
&gt;Do such visionaries exist to design our Challengers and our other more
&gt;aggresive weapons?

I take some offense at you calling the Challenger a weapon, and I know
several thousand others who would, too.  I would not call any of the software
people working on the Shuttle "visionaries," there is a degree of
salesmanship, however.  Your codes have to withstand many walk throughs
(or walk overs depending on your prespective 8-). Don't think the control
problem scales linearly, it doesn't, typically O(n^2) and greater.

--eugene miya
  NASA Ames (not speaking directly for the Agency)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
COMPASS '88 CONTACT
</A>
</H3>
<address>
Frank Houston
&lt;<A HREF="mailto:houston@nrl-csr.arpa ">
houston@nrl-csr.arpa 
</A>&gt;
</address>
<i>
Fri, 10 Jun 88 16:51:28 edt
</i><PRE>

Regarding the COMPASS '88 advance program and registration info.

Some people have had trouble contacting me by email and I, in turn, have
had some difficulty getting the nrl-csr mailer to recognize return addresses.
I recommend including a surface mail address with requests for registration
info.  For those who could not reach me by net, my telephone number is
(301)443-5020.  Registration is still open.

Frank Houston (I really exist @nrl-csr.arpa)


    [Note, not on the foregoing, but on the following: 
    I have had a request to add the issue number on the standard trailer,
    as you see I have done.  That seems like a fine idea for people who tend
    to string RISKS issues together.  However, this may defeat the 
    UNDIGESTIFIER programs if they look for the precise trailer.  Please
    let me know if this causes any troubles.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.06.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.08.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-49</DOCNO>
<DOCOLDNO>IA012-000129-B047-65</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.8.html 128.240.150.127 19970217021818 text/html 25581
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:16:45 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 8</TITLE>
<LINK REL="Prev" HREF="/Risks/7.07.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.09.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 8</H1>
<H2> Thursday 16 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
New Jersey wants computer audit trails disabled 
</A>
<DD>
<A HREF="#subj1.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Bunkers 
</A>
<DD>
<A HREF="#subj2.1">
C H Longmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  More on Blackhawk helicopter 
</A>
<DD>
<A HREF="#subj3.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Root typos 
</A>
<DD>
<A HREF="#subj4.1">
Ken Yap
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Costs/risks of impregnable telephone booths 
</A>
<DD>
<A HREF="#subj5.1">
Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Science, Journalism, and Whistle-Blowing 
</A>
<DD>
<A HREF="#subj6.1">
HENRY SPENCER
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Shrink Wrap 
</A>
<DD>
<A HREF="#subj7.1">
BILL MURRAY
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Hard-disk risks from vendors 
</A>
<DD>
<A HREF="#subj8.1">
Jerry Harper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  An old CTSS virus 
</A>
<DD>
<A HREF="#subj9.1">
Tom Van Vleck
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
New Jersey wants computer audit trails disabled
</A>
</H3>
<address>
Joe Morris (jcmorris@mitre.arpa) 
&lt;<A HREF="mailto:jcmorris@mitre.arpa">
jcmorris@mitre.arpa
</A>&gt;
</address>
<i>

</i><PRE>

From _Computerworld_, 13 June 1988, p. 4 (without permission, of course):

   CASINOS FIGHT PLAN FOR COMPUTER ACCESS

   Atlantic City -- In a major dispute over government access to corporate
   computers, 11 Atlantic City casinos are fighting a proposal by the New
   Jersey Division of Gaming Enforcement (DGE) to obtain direct access to
   casino computers for investigations.

   Unfettered computer access is necessary to fully investigate and regulate
   casino operations, DGE officials say.[...]

   The casinos have been joined in their battle by privacy experts, who say the
   proposal would set a dangerous precedent by allowing government agents to
   go on secret "fishing expeditions" through business computers.  Public
   comments on the proposal are due this week.

   [discussion of parallel paper-and-electronic records, due process
   requirements, etc...]

   The proposed regulation, published last month and pending before the state's
   Casino Control commission, would require the licensed casinos to provide DGE
   investigator with inquiry-only access to ALL [emphasis supplied] computer
   records.

   The requirement would have the following conditions:

   * The New Jersey casinos must provide the DGE with an on-site terminal and
     the capability to make printouts.

   * DGE personnnel must be given "reasonable privacy in which to conduct such
     inquiries."

   * Casinos may not track or monitor the DGE inquiries, and casino computers
     must be programmed to preclude any such tracking.

   * Casinos may request a log of DGE inquiries that shows the general category
     of information examined and the time of the inquiry.

   * Each casino must train DGE personnel in the use of its computer system.

   [The DGE tried to get this done four years ago but was blocked by a court
   order requiring extensive hearings.  DGE changed the procedures under which
   the demands were made, prompting] an April 7 filing by 11 of the 12 Atlantic
   City casinos [which] raised numerous objections and argued that the new
   proceeding defies the 1985 court order.

   [discussion of the loss of audit trail info for inquiries, which would make
   it impossible for anyone to know if compromised information had been leaked
   by a DGE employee or someone else.]

Wow.  Regardless of one's stand on how deeply the Mob owns the casinos,
you've got to wonder just who if anyone at DGE knows how to spell "Computer
Security".  After we've been careful to build security audit capability into
systems (and screaming about how dumb designers of the older systems were
for not doing so), now comes DGE with orders to shut them down.  Anyone want
to give some odds on some other part of DGE filing charges against the casinos
for failing to maintain an audit trail of access to the detailed profiles they
keep of the high rollers?

Disclaimer: the odds are very high that you won't be able to show any link
between yours truly and any casino or the DGE, mainly because there isn't
any.  Of course, we all know how easily computer records can be changed...

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Bunkers
</A>
</H3>
<address>
C H Longmore 
&lt;<A HREF="mailto:CCAse7-16%UK.AC.BIRMINGHAM@CUNYVM.CUNY.EDU">
CCAse7-16%UK.AC.BIRMINGHAM@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 15 Jun 88 19:23+0100
</i><PRE>

The following is from The Independent of 15th June 1988, reproduced without
permission.

                                   * * * *

                 COUNCIL WAR BUNKERS HIT BY COMPUTER PROBLEMS

The Home Office has suspended installation of a critical part of the
Government's wartime communications network, a multi-million pound
computerised link-up for local authority bunkers.

A national programme for the installation of the County Message Switch system
was halted at the end of March because of "Software Problems"

The Home Office confirmed yesterday that the software was still being tested.

One county emergency planning officer has privately described the situation as
"an absolute botch-up".

Bunkers in Lancashire, North Yorkshire, Cornwall and Somerset have been
affected by the delay following extensive teething problems encountered during
a pilot installation in Bedfordshire.

It is understood that the system's memory specifications are so limited that
district computers can only take about eight messages before previous files
are automatically deleted.

One source said yesterday that the Home Office had suggested that punctuation
and spaces should be left out of messages in an attempt to avoid overloading
the system. But there have been complaints that this would make messages more
difficult to decipher.

There are also complaints that because of a lack of back-up batteries, a power
cut would result in the computer system's entire memory being automatically
wiped out. [Note: bunkers have their own generators, but EMP from a nuclear
airburst could easily disrupt the supply]

                                   * * * *

[Note: In the UK, the Civil Defence plans in time of war are to keep the
population in the towns and cities where they live, and devolve power to
Emergency Regional Seats of Government if central Government is
incapacitated.]

One of the thoughts that occurred to me was this:

Why upgrade from teletypes to a new [?] computer system. After all, the
message capacity of a teletype in that of the roll of paper attached, and they
don't need rebooting after a power failure. You can also read them in the dark
by using a torch. If you were getting really technical you could use an
incoming teletype, and outgoing terminal/teletype.

And another one was:

Upgrading this sort of computer system is very dangerous. The more complex the
technology involved (ICs, DRAMS, Magnetic Media etc) the more prone it is to
damage from ElectroMagnetic Pulse from Nuclear Weapons, fluctuations in the
generator supply and other adverse operating conditions. A simple teletype is
less technologically advanced and therefore probably *more reliable* in these
conditions.

And finally:

Is this going to end up as another Nimrod fiasco, where the UK government
spends millions of pounds on a system, and then scraps it and buys from the US
instead?

                                   -- -- --

              C H Longmore: CCAse7-16%bham.ac.uk@cunyvm.cuny.edu

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
More on Blackhawk helicopter
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 10 Jun 88 16:42:13 est
</i><PRE>

From "The Australian" 31st May 1988:

	"German incident sours Blackhawk shield plan

 The United States Army says it will speed up plans to shield the UH-60
 Blackhawk helicopter from radio-wave interference following an incident
 in West Germany earlier this month [May].  On May 11, a Blackhawk flying
 near a large group of powerful antennae banked into a right-hand turn for
 five seconds without any pilot commands.

 [...] An Army spokesman, Major Phil Soucy, said on Friday that tests had
 shown the problem of electromagnetic interference did not jeopardise
 flight safety.  ``We certainly are not going to ground the (Blackhawk)
 fleet because there's no reason to'' Major Soucy said.  He said the Army
 had begun talks with the helicopter's manufacturer, Sikorsky Aircraft,
 on shielding a number of electronic components.

 [Details on Knight-Ridder report of 5 accidents and 22 deaths, since 1982]

 The Army and Sikorsky, a subsidiary of United Technologies Corp of
 Hartford, Connecticut, disputed that report, saying there was no
 evidence that electromagnetic interference had caused any crashes."

-- 
Dave Horsfall (VK2KFU), Alcatel-STC Australia, dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET, ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
root typos
</A>
</H3>
<address>
Ken Yap 
&lt;<A HREF="mailto:ken@cs.rochester.edu">
ken@cs.rochester.edu
</A>&gt;
</address>
<i>
Fri, 10 Jun 88 17:55:24 -0400
</i><PRE>
X-Uucp: ..!rochester!ken Internet: ken@cs.rochester.edu

You don't even have to be root to wreak havoc. I have the escape
character in rlogin set to ^P because I want to keep ~ for my own use.
One day I was using the console on a Vax to make a backup tape and
logged in to another machine to read my mail while waiting. When I
decided to escape back to the Vax to check how the backup was going, I
got:

	&gt;&gt;&gt;

(For those not familiar with Vaxes, this is the bootstrap prompt.)
Fortunately I realized that I had halted the machine and typed C
&lt;return&gt; immediately.

These days I do one of the following:

(1) Ensure the console switch is on LOCK.
(2) Avoid using the console.

	Ken

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
costs/risks of impregnable telephone booths.
</A>
</H3>
<address>
Geoff Goodfellow
&lt;<A HREF="mailto:geoff@fernwood.mpk.ca.us ">
geoff@fernwood.mpk.ca.us 
</A>&gt;
</address>
<i>
Mon, 13 Jun 88 11:56:59 PDT
</i><PRE>

The following was passed to me from David Kucharczyk &lt;ssr@cos.com&gt;:  Taken
from the Sydney Morning Herald and the May 22, 1988 issue of Awake magazine.

In an effort to outwit phonebooth thieves, Telecom, Australia's government-
owned telephone company, has fitted the susceptible booths with Kirk safes.
Named after the worker who invented them, the safe has so far proved 100-
percent effective. As mentioned in the Sydney Morning Herald, it has with-
stood 'oxy torches, ramset guns, angle-grinders, hydraulic jacks, pulley
clamps, centre-punches and bricks.' Ironically, the new safes appear to have
led to an increase in vandalism, as theives frustrated by the tough safes
vent their anger on the booths. Telecom reports that the current rate of
smashed glass and ruined handsets and cords is at a new high of 3,000 cases
per month.

[note by Geoff:  reminds me of the time my car was broken into in an 
unsucessful attempt to steal the stero/casette player.  the shattered glass
everywhere, the mangled radio face plate, storage of the car in a secure
location until i could obtain an appointment at the fix-it shop, the overhead
of taking the car in / pick-up, etc -- all besides the expense/insurance
deductable.  quite a hassle, for which i would have given the radio away to
have avoided!]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Science, Journalism, and Whistle-Blowing
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 10 Jun 88 18:05:34 EDT
</i><PRE>

The following is the editorial by Daniel E. Koshland Jr. in the 29 April
1988 issue of Science; it has relevance beyond the scientific community.
[Reprinted (sigh) without permission.]

  "Discussion of fraud in science is becoming a cottage industry in need of an
  environmental impact report.  Fraud is devastating to science; it undermines
  the basic respect for the literature on which the rapidity of scientific
  advance depends.  It must be rooted out wherever and whenever it is
  discovered.  That makes it all the more imperative that charges of fraud be
  made responsibly and that the performance record of whistle-blowers be
  scrutinized as well as those of the scientists they criticize.  In recent
  times we have been exposed to excesses in whistle-blowing and journalism
  that come close to the evils they wish to eradicate.  We see, for example,
  the charge that there is widespread fraud, followed by a text defining fraud
  as a broad concept including "misconduct".  Misconduct is then interpreted
  to include such items as poor proofreading or incomplete references.  In a
  recent congressional hearing, misconduct was further broadened to include
  a difference in interpretation of complex data.  Crying wolf tends to lose
  effectiveness when the wolf is redefined as a vicious mouse and then it is
  further conceded that the viciousness is a matter of opinion.

  "The slowness of institutions in conducting investigations is viewed by some
  as evidence of an "old boy" conspiracy.  But there are good reasons to be
  slow to accuse a colleague.  A student works in close cooperation with a
  professor for months or years and finally solves a problem.  A statement
  by the professor that "we can't publish until the result is checked" might
  eliminate a few cases of fraud, but it would forever damage the relation
  between student and professor.  Institutions that are quick to accuse
  distinguished faculty members of misconduct or worse on the basis of gossip
  or flimsy data will not long have a distinguished faculty.  The fate of
  whistle-blowers who have lost their jobs or failed to continue in science
  is often recounted as evidence of retaliation, but the quality of the
  whistle-blowers' work is relevant to this conclusion.  The idea that
  scientists may cut corners to achieve fame, but whistle-blowers never do,
  is nonsense.  Past track records are not always a guide to future conduct --
  some distinguished scientists err, some erratic whistle-blowers are right
  on occasion -- but scientists, like ordinary citizens, are innocent until
  proven guilty.  Investigation of their integrity should require substance.
  It is not a cover-up for an institution to refuse to initiate an inquiry
  if the only evidence is the accusation by an unreliable source.

  "The scientific apparatus cannot afford to disregard accusations of fraud,
  and competent whistle-blowers help science.  Investigations should be
  pursued meticulously, but the final report should strongly state the
  outcome:  If the accusation is correct the miscreant should be punished
  and the whistle-blower commended.  If, however, the accusation is incorrect,
  in addition to the usual bland announcement of exoneration there should be
  a denunciation of the false charges and a documentation of the time,
  anguish, and delay that has been occasioned.  Science cannot tolerate
  fraud, but it should not be at the mercy of headline-happy journalists
  or incompetent whistle-blowers.

  "Journalists must distinguish between fraud, sloppiness, and differences of
  opinion.  When an accusation of fraud is made, if the evidence appears
  weak or the charge exaggerated a careful journalist should be alerted to
  probe more deeply.  Opinions of noninvolved experts on the likelihood of
  error and the track record of the accuser should be documented early on,
  even in the initial story.  The original story may have to state the facts
  of an accusation before all the background is obtained, but in most cases
  the story can be delayed, and in all cases pertinent doubts should be
  expressed.  The final outcome should be publicized appropriately.  Finally,
  the setting in which a story is reported must be considered by a journalist.
  A story involving a prominent scientist in an inquiry on fraud is bound to
  make headlines, even if the story is only a question of judgement.  The late
  Senator Joseph McCarthy was particularly clever at manipulating journalists
  in this way; the techniques should be familiar by now.

  "Scientists respect integrity, scholarship, and good judgement as much as
  they abhor fraud, sloppiness, and poor judgement, but these are very
  different phenomena.  Those who mix them together in uncritical ways may
  decrease our chances of eliminating true fraud, may damage reputations
  unfairly, and may diminish enthusiasm for healthy differences of opinion at
  the cutting edge of science."

				Henry Spencer @ U of Toronto Zoology
				{ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Shrink Wrap
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Wed, 15 Jun 88 09:41 EDT
</i><PRE>

Yesterday I received an unsolicited package in the mail.  From the
source and the marking "magnetic media," I conclude that the package
contains a program sent to me for evaluation and review.

I am usually cautious about unsolicited mail.  However, this one came
with its own warning.  It was sealed with a sticker with the following
warning:  "The program on the enclosed disk is licensed to the user.  By
opening this package, you indicate your acceptance of the ENCLOSED
(emphasis mine) license agreement."  

Goodness!  What might I be agreeing to?  The fantasies are simply endless.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Hard-disk risks from vendors
</A>
</H3>
<address>
Jerry Harper 
&lt;<A HREF="mailto:mcvax!euroies!jharper@uunet.UU.NET">
mcvax!euroies!jharper@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 15 Jun 88 15:41:59 GMT
</i><PRE>

We use a number of 286 machines (American Research Corporation -made in
Taiwan) for some development work before uploading the code to an MVS/XA
environment.  REcently, one of the machines has given considerable trouble
and, indirectly, an insight into the obligations of the vendor we dealt
with.  The system unit emits quite a noticeable vibration which transmits
itself forcibly to the keyboard and desk - that problem has been there
from its purchase.  On several occasions the vendor has checked the unit
to ascertain the source of the vibration but to no avail.  Almost from
the start I mentioned that the vibration was bound to cause some damage
to the hard-disk in the long run (increased oscillation of the heads,etc).
In the last month one of the crimped connections to the hard-disk
controller board fell out with the result that drives C and D were not
recognised and some 30mb, it appeared were either lost or inaccessible.
I took the shroud off the unit and pushed home the connector - we lost two
recent files (yes, we have floppy backups).  A week later the same occured only 
but this time I couldn't locate any loose connections, so I rang the
vendor.  Firstly, he said he was too "busy" to come out, and then he
told me in a matter of fact manner that the hard-disk was probably corrupt
and all the data was lost.  We have had this machine *four* months.
He then proceeded to give a telephone analysis of what might have
happened.  Eventually, I was tiring and demanded that someone appear
quickly.  Two days later a technician came and once again it turned out
that a power connection to the the hard-disk had worked itself loose.
At this point, I decided that we should have a replacement machine.
No dice.  I was assured that the machine was in fine form.  A week later
the CMOS went sick and the hard-disk was inaccessible.  Once again 
a telephone analysis was conducted and I reconfigured the system.
I know this is getting long-winded but the point is that at no stage
in any of the exchanges did the vendor admit any liability, nor did
he seriously offer a replacement. This is of some concern to a number of
companies here in Ireland as quite a number of vendors have suffered
financial difficulties leaving their customers with pitiful after
sales support.  Are too many people getting into the VAR market by
the seat of their pants?
Jerry Harper : Merrion Gates Software (Logic Programming)
             : 89 Booterstown Avenue, Blackrock, Co Dublin, IRELAND.
Phone-net : 353-1-88 52 51
email : jharper@euroies.uucp


</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 An old CTSS virus
</A>
</H3>
<address>
&lt;<A HREF="mailto:garyt@cup.portal.com">
garyt@cup.portal.com
</A>&gt;
</address>
<i>
Mon Jun 13 11:42:06 1988
</i><PRE>
Really-from Tom Van Vleck

   SENT: 88-06-11  19:00
   FROM:2 VANVLECK_TOM @PRUNE

This may qualify as one of the oldest viruses: Just before the July 4th
holiday in 1966, two undergraduate CTSS users decided to write a RUNCOM (like
a shell script) which would invoke itself.  They knew that this would create a
new SAVED file on each invocation and eventually use all the disk space on the
Project MAC CTSS system, but they thought this would just lead to a documented
error return.  Unfortunately, there was a bug in the system and CTSS crashed.
Noel Morris and I spent a long time repairing the system disk tables by hand.
Well, was this a virus? The program launched a new copy of itself, and this
proliferation led to the death of the host.

(Note the early fascination with self-reference.  The other well-known way to
crash CTSS was to issue the XEC * instruction, which said "execute the
instruction at the location where this instruction is."  The 7094 CPU looped
taking I cycles only and couldn't be interrupted.  Bill Matthews once did this
deliberately to stop the system when an unwary system administrator
accidentally put the password file in the "message of the day."  Once again,
at 5PM Friday.)

The most important lesson is "don't get clever at 5PM Friday."

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.07.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.09.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-50</DOCNO>
<DOCOLDNO>IA012-000129-B047-87</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.9.html 128.240.150.127 19970217021830 text/html 15691
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:16:58 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 9</TITLE>
<LINK REL="Prev" HREF="/Risks/7.08.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.10.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 9</H1>
<H2>  Wednesday 22 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of ATM manufacturers 
</A>
<DD>
<A HREF="#subj1.1">
Philip E. Agre
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of bank ATMs 
</A>
<DD>
<A HREF="#subj2.1">
Mary-Anne Wolf
</A><br>
<A HREF="#subj2.2">
 Larry E. Kollar
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Yet more on the Blackhawk helicopter Jan Wolitzky)
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: root typos 
</A>
<DD>
<A HREF="#subj4.1">
Dave Curry
</A><br>
<A HREF="#subj4.2">
 nyssa
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Notice to the OTA mailing list 
</A>
<DD>
<A HREF="#subj5.1">
Eric Roberts
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Challenger Payoff? 
</A>
<DD>
<A HREF="#subj6.1">
Richard Outerbridge
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Risks of ATM manufacturers
</A>
</H3>
<address>
"Philip E. Agre" 
&lt;<A HREF="mailto:AGRE@AI.AI.MIT.EDU">
AGRE@AI.AI.MIT.EDU
</A>&gt;
</address>
<i>
Thu,  9 Jun 88 02:05:54 EDT
</i><PRE>

In reading Risks over the last couple years, I've noticed that responses to
attempts to complain about uncorrected technical problems tend to take
certain recurring forms.  John Pershing's message about ATMs illustrates a
remarkable number of these forms of argument, all of which will be familiar
from previous Risks discussions of related topics, such as privacy
violations and whistle-blowing at NASA.

What has happened?  Someone, in this case a customer though in other
cases it has often been an employee, complains that something is badly
amiss with some system, receives no redress, and finds that their
reports are ignored.  So they make noise about it.  The response?

1. Misplaced accusations of uncooperativeness.  `You have to exercise
the system so that the bugs will be found and fixed.'  The person
*has* exercised the system and discovered and reported difficulties
with it, but the organization in question ignored the reports and thus
(we must presume) neither found nor fixed any bugs.

2. Condescending lectures about how `incredibly complicated' the
systems in question are and how hard it is to anticipate all possible
problems.  Nobody has demanded that all problems be anticipated, only
that attempts be made to repair detected problems, especially ones
that cause unnecessary loss or injury.

3. Misplaced appeals to the market.  `If your bank is not responsive
to your bug reports, then find another bank.'  The ATM didn't just
have a bug, it stole this person's money.  And presumably it is
stealing other people's money.  Why doesn't the knowingly misdesigned
software constitute a company policy to defraud its customers?  And
don't ATMs, as a legal matter, fall under some version of the notion
of implied warranties of merchantability?

4. Casting misdesign as an irremediable act of God.  `It is quite
sensible for an ATM's programming to "lean" in the bank's direction is
there is something amiss ... .'  Wouldn't the really sensible thing be
to make a record, whether on a paper receipt or in a computer file,
and preferably both, that something was amiss in this particular
transaction?

5. Diagnosing the system is the victim's job.  `... the consumer will
always go complaining to a bank officer.  When was the last time that
you got *over*-changed and actually reported it?'  It is even more
sensible to "lean" in the customer's direction, because the bank will
always be motivated to fix problems that cost it money.  When was the
last time a bank discovered it had over-changed you and actually let
you keep the money?

6. This-is-nothing-new.  `I don't see any risks in his story that can
be attributed specifically to the use of ATMs, as opposed to the more
general use of a Bank.'  Such a statement requires that we define the
problem far too abstractly.  The story concerned a particular
misdesign.  Taking it as an abstract attack on ATMs misses the point.

7. Blaming the victim.  `It is impossible to even imagine ... the
number of ways that clever consumers can subvert the system.  Of
course, this is nothing new with ATMs -- financial fraud has been
around as long as banks.'  A customer gets defrauded, yet somehow the
issue has gotten twisted around into customers committing fraud.  Note
the irony of the last bit: banks have committed financial fraud as
long as there have been banks.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Risks of bank ATMs
</A>
</H3>
<address>
Mary-Anne Wolf 
&lt;<A HREF="mailto:MWolf@BCO-MULTICS.ARPA">
MWolf@BCO-MULTICS.ARPA
</A>&gt;
</address>
<i>
Thu, 9 Jun 88 11:38 EDT
</i><PRE>

The ATM itself is not all that you need.  Baybanks in (Eastern) Massachusetts
has a dial-less telephone next to their ATMs, which reaches an office staffed
24 hours a day.  I have only used this phone for information, but I assume
that, if anything went wrong, it would be possible to inform someone and check
the state of the machine immediately.  If the bank decided to wait until
business hours to check the machine, they could still have a record of who
claimed to be short-changed.  These ATMs also have a camera behind glass
pointing at the customer, and although I never know when it's running, it seems
unlikely that someone would fake a complaint.  One pays for this convenience
with relatively high minimum balances and relatively low interest, but, as long
as I have the money, it's worth it.  (When I didn't have the money, I got a
better deal at a bank with only 2 branches that didn't offer ATMs at all, and a
check-cashing card in a 24-hour supermarket for emergencies.)

I suspect that the problem is less the machine than the attitude of the bank.
A bank should probably rather risk losing a little money than a lot of
customers, and I would boycott banks rather than ATMs if I boycotted at all.

Mary-Anne Wolf, MWolf -at BCO-Multics.ARPA, Honeywell Bull, Billerica MA
These opinions are my own, and my only connection with any bank is as a customer.

</PRE>
<HR><H3><A NAME="subj2.2">
Re: Risks of bank ATM cards
</A>
</H3>
<address>
Larry E. Kollar
&lt;<A HREF="mailto:dcatla!mclek@gatech.edu ">
dcatla!mclek@gatech.edu 
</A>&gt;
</address>
<i>
Fri, 10 Jun 88 16:43:31 EDT
</i><PRE>
Organization: DCA Inc., Alpharetta, GA

&gt;From: John Pershing &lt;PERSHNG@ibm.com&gt;
&gt;
&gt;  -  I have never gotten a receipt for a failed transaction.  Requiring a
&gt;     receipt for a failed transaction sounds sort-of bogus to me, as one
&gt;     of the (dozens of) failures that can happen is that the receipt
&gt;     printer breaks or runs out of paper.

The ATMs around Atlanta always give you a receipt, whether or not your
request went through.  Usually they have a code on the front, with a list
of codes and what they mean on the back.

As for the printer breaking or running out of paper, it's not a hard thing
for an ATM to detect the lack of paper flow and put itself out of service.
Whether or not ATMs do that is yet another question.

Earlier, Karl Denninger relates that the bank told him "no receipt, no fix."
ATMs keep an internal printout of account numbers, as an audit trail.  It came
in handy for us a couple of years back when my wife deposited $400 in cash,
threw the receipt away, and the ATM crashed that evening and forgot to transmit
the transaction.  We didn't know what had happened until checks started
bouncing on us.  This safeguard must be on all machines; Georgia isn't much of
a consumer-oriented state to require that kind of special modification.

	Larry Kollar	...!gatech!dcatla!mclek

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Yet more on the Blackhawk helicopter
</A>
</H3>
<address>
&lt;<A HREF="mailto:wolit@research.att.com">
wolit@research.att.com
</A>&gt;
</address>
<i>
Fri, 17 Jun 88 10:15 EDT
</i><PRE>

Additional details on the incident Dave Horsfall reported in RISKS DIGEST
7.8, from 'Aviation Week &amp; Space Technology,' June 13, p. 31:

  The most recent tests were conducted near a dense antenna field of nearly 1
  sq.  mi. that radiates on a broad range of frequencies with a power level
 
  potential well above 400 MW, according to Army officials.  During the tests,
  the aircraft experienced uncommanded rudder pedal movements that caused the
  UH-60 [Blackhawk] to begin turning, stiffness in the rudder pedals and
  illumination of caution and advisory lights in the cockpit.

  Specifically, the test UH-60 experienced a simultaneous loss of hydraulic
  pressure to both tail rotor servos for approximately 5 sec. and a jamming of
  the tail rotor control pedals.  Both malfunctions were attributed to the
  susceptibility of the hydraulic logic module to the high energy levels.  As a
  result, the service has decided to accelerate the hardening of the module for
  both production and retrofit as the first priority under the modified ECP
  [Engineering Change Proposal 384].

Jan Wolitzky, AT&amp;T Bell Labs, Murray Hill, NJ; 201 582-2998; mhuxd!wolit
(Affiliation given for identification purposes only)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: root typos
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>
Thu, 16 Jun 88 12:49:07 EST
</i><PRE>

Ken Yap relates his problems with ^P and the Vax console.  Fortunately,
^P is not the standard rlogin escape.

Here's a better (worse?) one:  the console escape character on the CCI Power
6/32 ("tahoe") is the tilde.  And, so is the escape character for Berkeley
mail.  You guessed it... log in on the console, send some mail, and do a "~h"
to see the headers.... ooops, the machine just halted.

CCI also cleverly placed the "reboot" switch, an up/down toggle, on the
front of the cabinet, not recessed, and at knee level.  Fortunately,
UNIX seems to ignore the switch.

--Dave Curry

P.S. - Don't get me wrong; the tahoe is a really *nice* machine, regardless
       of the above demonstrations of poor design judgement.

</PRE>
<HR><H3><A NAME="subj4.2">
Another Root typo
</A>
</H3>
<address>
&lt;<A HREF="mailto:nyssa@terminus.att.com">
nyssa@terminus.att.com
</A>&gt;
</address>
<i>
Fri, 10 Jun 88 13:59 EDT
</i><PRE>

This has taken on an almost urban legendary status in our group:

Four summers ago, we were doing a beta test at a customer site.
Our field support person had to remove some files in a directory, so
he had to use the "su" command.  This he did, followed by an rm -rf *

The problem was that he typed "su -" which moved him to the root
directory.  Not even a series of messages like "/bin/rm: Cannot remove,
file busy" detered him, until the machine was wiped out...

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
A catch for coughin'
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 18 Jun 88 15:57:42 est
</i><PRE>

From "Computing Australia" 13 June 1988:

"System slip leads to danger dosage

 An error in instructions given to a pharmaceutical manufacturer's computer
 has resulted in the production of two dangerous batches of cough mixture.

 A spokesman for South Australian Hamilton Laboratories, which makes the
 Neo-Diophen Elixir, said during preparation of the master batch documents
 for the computer, a decimal placing was typed incorrectly [another decimal
 point error?].

 Some of the mixture was found to contain 10 times the normal level of a
 certain chemical, he said.  He said about 6,400 bottles of the mixture
 had left the laboratory, but less than half had reached retail outlets.

 The Federal Community Services and Health Department issued an instant
 recall on the batches and last week department inspectors were investigating
 the mistake."


So it's not the cough that carries you off, but the coffin they'll carry
you off in...

Dave Horsfall (VK2KFU), Alcatel-STC Australia, dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET, ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Challenger Payoff?
</A>
</H3>
<address>
Richard Outerbridge 
&lt;<A HREF="mailto:csri.toronto.edu!outer@uunet">
csri.toronto.edu!outer@uunet
</A>&gt;
</address>
<i>
Sun, 12 Jun 88 21:44:18 EDT
</i><PRE>

Recently I heard a litigation lawyer speak on the connection between insurance
premiums and corporate motivation.  He claimed that despite the shuttle disaster
Morton Thiokol still received a $65 Million dollar "early completion" bonus
on the contract that included the Challenger launch.  Is this true?  'Twere
scandalous 'twere so, but stranger (and sorrier) things have been known true.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.08.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.10.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-51</DOCNO>
<DOCOLDNO>IA012-000129-B047-110</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.10.html 128.240.150.127 19970217021842 text/html 18839
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:17:10 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 10</TITLE>
<LINK REL="Prev" HREF="/Risks/7.09.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.11.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 10</H1>
<H2>  Monday 27 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Four killed as Airbus crashes 
</A>
<DD>
<A HREF="#subj1.1">
Duncan Baillie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Laziness as an excuse 
</A>
<DD>
<A HREF="#subj2.1">
Matthew P Wiener
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Privacy vs. Security 
</A>
<DD>
<A HREF="#subj3.1">
Larry Hunter
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re-using government databases 
</A>
<DD>
<A HREF="#subj4.1">
Amos Shapir
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Root Bloopers 
</A>
<DD>
<A HREF="#subj5.1">
Doug Krause
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Problems with VARs 
</A>
<DD>
<A HREF="#subj6.1">
Hal Norman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Fail-safe ATMs 
</A>
<DD>
<A HREF="#subj7.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Malicious Code Reports 
</A>
<DD>
<A HREF="#subj8.1">
Joseph M. Beckman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Four killed as Airbus crashes
</A>
</H3>
<address>
Duncan Baillie 
&lt;<A HREF="mailto:dmb%lfcs.edinburgh.ac.uk@NSS.Cs.Ucl.AC.UK">
dmb%lfcs.edinburgh.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
27 Jun 1988 0953-WET (Monday)
</i><PRE>

This is how the Airbus crash in France was reported on the front page of the
Guardian. Unfortunately it is rather short on facts but no doubt these will
follow. 

From The Guardian, June 27 1988 (copied without permission).
by Paul Webster, Michael Smith, Peter Murtagh.

At least four people were killed and at least 30 more unaccounted for last
night after a European Airbus using a controversial computer controlled flying
system crashed into a forest during a demonstration flight at an airshow in
eastern France.

British Airways and Air France suspended further flights of the plane, the
A-320 which is Europe's most advanced passenger aircraft and is built by a
French, British, West German and Spanish consortium. British Airways has had
two A-320s in service since the spring and orders for a further eight.

The future of the aircraft, in which British Aerospace has a 20 per cent stake
worth 450 million pounds, and builds the wings and tailpiece, will be placed in
doubt after yesterday afternoon's crash, the first disaster to hit the new
generation of European Airbuses.

The plane, carrying 127 guests, airshow joyriders and journalists, was flying
low over the small airport at Habsheim, about 10 kilometres from Mulhouse in
southern Alsace when the pilot let down the undercarriage and made two passes
over the local aeroclub buildings. As he turned the plane the wheels caught the
tops of the pine trees and plunged into the forest.

It burst into flames shortly afterwards but many of those on board appeared to
have escaped. Reports of people trapped inside could not be confirmed but the
French authorities said that about 100 passenegers had been injured, two of
them seriously.

A policeman among the first on the scene said "The plane did not go into a
nose-dive. It belly flopped onto the trees." The pilot who had minor head
injuries, told a rescuer: "I tried to accelerate but the plane did not
respond." 

A photographer among the passengers said the aircraft was turning when there
was "a noise as if we were travelling along a bumpy road". He saw the tops of
the trees and the plane caught fire near the cockpit when it came to a
standstill.

He said: "There was no panic and I only saw one woman passenger who seemed
seriously hurt. She was quite badly burned," he added.

The narrow bodied plane, designed for short to medium-range flight, went into
service only last Thursday with Air Inter, the internal French airline, where
pilots have been protesting for more than three years about its safety. In
spite of warnings that the plane's two-man cockpit, without room for a flight
engineer, was potentially dangerous, 21 airlines have ordered 522 of the
planes. 

The crash could not have come at a worse time for the Aitbus whose reputation
has been built on an impressive safety record since its first model went into
production 18 years ago.

The A-320 is the first civilian aircraft to use a computer-controlled flying
system known as "fly-by-wire". This replaces the conventional stick and rudder
control with three computers and miles of electronic cables, leaving the pilot
with a "sidestick" like the control arm on a video game.

The pilot uses it to direct the computers but they direct most of the
instruments. However, if the pilot makes an error or unreasonable demands on
the engine, the computer can over-rule his command.

Last night Professor Bev Littlewood, of the software engineering department at
the City of London University, questioned the system's safety.

He said: "We have gone so far along the rocky road of computer control, it is
now hard to ask fundamental questions about critical safety areas."

Last year, the A-320 system was criticised by Mr Brian Perry, head of Avionics
and Electrical Systems for the Civil Aviation Authority. He said: "It's true we
are unable to establish a fully verifiable level that the A-320 software has no
errors. It's not satisfactory but it's a fact of life".

An Airbus spokesman said: "Airbus planes have flown over 5 million hours. In
all cases the aircraft was not to blame". There have been three crashes
involving Airbuses but none had caused casualties, he said.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Laziness as an excuse
</A>
</H3>
<address>
Matthew P Wiener
&lt;<A HREF="mailto:weemba%garnet.Berkeley.EDU@violet.berkeley.edu ">
weemba%garnet.Berkeley.EDU@violet.berkeley.edu 
</A>&gt;
</address>
<i>
Sat, 25 Jun 88 08:38:59 pdt
</i><PRE>

This is forwarded from Robert L Park's "What's New" in the physics
group, dated 24 June 88:

3.  RESTRICTIONS ON ACCESS TO UNCLASSIFIED DOE TECHNICAL REPORTS
came to light when the DOE's Office of Science and Technology
Information offered "some limited reports" to university
libraries if they would agree to grant access only to government
agencies and principal investigators on DOE contracts.  Most
libraries refused on principle, but they wanted to know what they
weren't getting.  In response to a Freedom of Information request
from the National Security Archive, however, DOE refused even to
provide a list of titles, claiming the information was stored in
a computer and thus could be retrieved only by writing a new
program!  The Office of Hearings and Appeals last week overruled
DOE, pointing out that agencies would otherwise be allowed to
conceal information simply by putting it in computerized form.

ucbvax!garnet!weemba	Matthew P Wiener/Brahms Gang/Berkeley CA 94720

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Privacy vs. Security
</A>
</H3>
<address>
Larry Hunter 
&lt;<A HREF="mailto:hunter-larry@YALE.ARPA">
hunter-larry@YALE.ARPA
</A>&gt;
</address>
<i>
Thu, 23 Jun 88 11:52:00 EDT
</i><PRE>

I recently applied for a job that would require a security (Q) clearance.
I was handed a form for "pre-employment screening" that any job offer
would be contingent upon.  I was surprised by the invasiveness of the
form I was being asked to sign:
  
  "I hereby authorize the [employer] and its agents to inspect, copy or 
  photostat any or all documents pertaining to my financial records, my
  education records, my personal references, my employment records, and 
  local law enforcement records as they pertain to me. `Documents' shall    
  be construed in its broadest sense including any original, reproduction,
  or copy of any kind of written, printed, recorded, documentary material 
  (or drafts thereof), or graphic matter regardless of the medium on which
  it is produced, reproduced, or stored, including, but not limited to,
  correspondence, memoranda, inter or intra-office communications, notes,
  diaries, calendars, contract documents, publications, calculations,   
  estimates, vouchers, minutes of meetings, invoices, reports, studies,
  computer tapes, computer cards, photographs, negatives, slides, dictation
  belts, voice tapes, telegrams, notes of telephone conversations, and notes
  of any oral communications."

Note that there is no time limit on this authorization, and that this
is merely pre-employment screening, not yet an application for a clearance.

Have all of you folks with clearances agreed to something similar?  Is
national security incompatible with the personal privacy of those who
are aware of security matters?
                                         Larry Hunter, hunter@yale.edu

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re-using government databases
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:nsc!taux01!taux01.UUCP!amos@Sun.COM ">
nsc!taux01!taux01.UUCP!amos@Sun.COM 
</A>&gt;
</address>
<i>
17 Jun 88 12:13:14 GMT
</i><PRE>

The Israel Broadcasting Authority is a semi-independed agency, funded in
part by a tax on radio and  TV sets (called, for historical reasons, 'TV
license fee'). Anyone  owning a TV or renting one  should inform the IBA
of  this fact,  so they  know where  to send  the bill.  Naturally, many
people evade the tax by not informing the IBA when they move.

This week, the IBA used a computerized database to send all people older
than 26 and listed as living  with their parents, letters informing them
that the law requires that any change of address be reported to the IBA.

The assumption  is that most of  these people no longer  live with their
parents, have  their own untaxed  TV sets,  and that their  parents will
forward the message. I don't know  what database they have used, since I
also got  such a letter,  but have not been  living with my  parents for
years.
	                            Amos Shapir

National Semiconductor (Israel), 6 Maskit st. P.O.B. 3007, Herzlia 46104,
Israel Tel. +972 52 522261   amos%taux01@nsc.com

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Root Bloopers
</A>
</H3>
<address>
Doug Krause 
&lt;<A HREF="mailto:dkrause@orion.cf.uci.edu">
dkrause@orion.cf.uci.edu
</A>&gt;
</address>
<i>
Thu, 23 Jun 88 03:43:09 -0700
</i><PRE>

Try typing 'kill 1' when you really mean 'kill %1'.

Douglas Krause, University of California, Irvine

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Problems with VARs
</A>
</H3>
<address>
Hal Norman
&lt;<A HREF="mailto:norman@devvax.Jpl.Nasa.Gov ">
norman@devvax.Jpl.Nasa.Gov 
</A>&gt;
</address>
<i>
Fri, 17 Jun 88 9:07:43 PDT
</i><PRE>

In response to Jerry Harper's troubles with a VAR, I have had (am currently
having) a similar problem.  I bought a XT clone for my home use from a
"reliable" VAR.  It came with a 1 year warranty.  About 4 months after I bought
it, it started making horrible noises.  I opened it up and it was the fan on
the power supply(PS) that was making the noise.  I called my VAR and was told
to return either the whole unit and they would replace the PS or just bring in
the PS and get a new one.  So I removed the PS and took it in for replacement.
The owner was not there at the time and an employee exchanged it for me.  I
made the mistake of not getting a receipt showing the serial numbers of both
power supplies (the bad one and the replacement).  About a week later I got a
call from the owner claiming that I had foisted a bogus PS off on him.  He was
quite irate, claiming he had never ever carried the brand of PS I had returned
and wanted me to pay him $60 for the replacement.  I copied my original receipt
(with the PS serial number) and sent him a copy, but he claims it doesn't match
the one I returned and still demands $60.  Meanwhile, the replacement PS
developed the same fan problem as the original and had to be replaced.  I took
it in and he replaced it, but is still irate and wants $60.  I told him to send
me a bill, and as soon I get the bill that I would file in small claims court
and we could let the Judge sort it all out and decide how much if any I owed
him.  I have not yet gotten the bill.  The point is, when you buy something as
complex as a computer, make sure you get a receipt signed by the VAR specifying
ALL the serial numbers of ALL the components and verify that the list is
correct.  Then, if you should have to take it back for warranty repair, make
sure you get a receipt for any swapouts indicating BOTH the serial number of
the new unit AND the serial number of the bad unit.

Hal Norman -
Disclaimer: These are my personal opinions and are NOT to be
construed as those of my employer.  
 
</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 Fail-safe ATMs (RISKS-7.9)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Wed, 22 Jun 88 15:46:31 PDT
</i><PRE>

  In RISKS 7.9 dcatla!mclek@gatech.edu (Larry E. Kollar) writes:

&gt; The ATMs around Atlanta always give you a receipt, whether or not ...

   In California, Security Pacific's ATMs (part of the STAR System) issue
a message that the machine is out of receipts, and ask if you want to
proceed.  You can still make transactions, but as we have seen, there 
is a higher degree of risk.  Many ATM transactions don't generate a 
receipt.  Account balances, for example, are displayed only on the 
electronic display and no receipt is given.  

   There is no way that receipts can cover all contingencies.  A machine
that will not operate if it is out of receipts reduces the magnitude of
the problem, but what happens when the receipt producing mechanism fails,
either by the print mechanism, feed mechanism, or receipt quantity
sensor failing?  A good design should try to minimize abnormal transaction
termination, but it must also have provisions for unanticipated failure
modes to be handled gracefully -- soft failures instead of hard failures.
Audit trails sometimes get screwed up, too.

   It seems that in order for all parties to get maximal protection from
errors, there should be multiple independent levels of redundancy and 
record keeping.  Independent video tapes of the customer AND display
screens would provide a mechanism for resolving discrepancies, but I know
of no systems that use this technique.  Many ATMs look like they have 
cameras to monitor customer (ab)use, but often it's just a dummy camera 
to discourage vandalism.

   Even telephone systems to report problems won't catch everything.
Failed transactions may not make it clear that a problem needing 
correction occurred, so there would be reason to report it.

   We're a long way from making automated systems foolproof.  Thus we
must monitor such systems and not let the service providers call all
the shots.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Malicious Code Reports
</A>
</H3>
<address>
"Joseph M. Beckman" 
&lt;<A HREF="mailto:Beckman@DOCKMASTER.ARPA">
Beckman@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 23 Jun 88 15:40 EDT
</i><PRE>

As a member of the National Computer Security Center, I am asking for
direct contributions of reports on malicious software.  Please report
computer viruses, trojan horses, or other forms of offensive software.
I and the Center will use this information to track attacks, gain an
understanding of system vulnerabilities, and develop defenses.  Please
send your reports to:

SOFTWARE @ DOCKMASTER.ARPA.

Joseph

P.S. If the information is proprietary or not-to-be-shared, please indicate on
the report. The NCSC shares some information with NBS.  I will try to release
summaries or abstracts to RISKS (of the non proprietary/secret variety);
although it may formally come through NBS.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.09.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.11.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-52</DOCNO>
<DOCOLDNO>IA012-000129-B047-132</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.11.html 128.240.150.127 19970217021920 text/html 19753
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:17:37 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 11</TITLE>
<LINK REL="Prev" HREF="/Risks/7.10.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.12.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 11</H1>
<H2>  Wednesday 29 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Risks of answering machines 
</A>
<DD>
<A HREF="#subj1.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Airline reservation crash 
</A>
<DD>
<A HREF="#subj2.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Updates on Airbus crash 
</A>
<DD>
<A HREF="#subj3.1">
Duncan Baillie
</A><br>
<A HREF="#subj3.2">
 Klaus Brunnstein
</A><br>
<A HREF="#subj3.3">
 Laura Halliday
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  root typos 
</A>
<DD>
<A HREF="#subj4.1">
Joe Eykholt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  "large-scale" disasters (Hinsdale, Ill.)  
</A>
<DD>
<A HREF="#subj5.1">
Tom Perrine
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Risks of answering machines
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 25 Jun 88 16:19:31 est
</i><PRE>

From the Sydney Morning Herald, 13 June 1988:

``Careless talk: it's a message machine

  Alan wasn't at home when his girlfriend Donna called him yesterday
  morning.  Nor could he take his father's call.  Or a call from his other
  girlfriend, Jenny.  I know this because Alan owns an answering machine
  just like mine.  It is so similar, in fact, that my remote control unit
  _lets_me_listen_to_his_messages_ [emphasis mine!].

  The machine in question is a Tandy, but the 'Herald' has discovered
  that anyone can listen to messages left on most of thre many thousands
  of answering machines already in people's homes.  This is because most
  remote-control answering machines have primitive codes, and many have
  none at all.  [ ... 14,000 like this sold in a three-week sale ... ]

  [ ... how the remote tone coders work - just one of four tones ]

  [ ... Tandy had sold "tens and tens of thousands" of this model - the
  TAD-212 - and similar machines in 2 years ... ]

  Dick Smith Stores [a consumer electronics chain] also sell answering
  machines which are activated by voice pattern.  [The product manager]
  said the group had sold more than 20,000 such machines.  By talking for
  a set period of time, keeping quiet for a set period of time, and then
  talking again, the machines can be activated.  He said every machine
  responded to the same voice code.  "You would not recommend that
  anybody leave vital information on an answering machine," he said.

  Ms.  Phillipa Smith of the Consumers' Association said the privacy and
  security problems associated with these machines were "quite obvious".
  "I think most consumers would assume there was a built-in personal-
  identification system," she said.  "This really is an area where
  technology has outstipped the law."

Dave Horsfall (VK2KFU), Alcatel-STC Australia, dave@stcns3.stc.oz

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Airline reservation crash (A new definition of "virus" ?)
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 25 Jun 88 14:33:39 est
</i><PRE>

The following appeared in "Computing Australia" (affectionately known
as "Confusing Australia") 20 June 1988 and appears to define a new
form of virus:

``Virus shoots down flight reservations

  Hundreds of travel agents in two states went offline after a virus
  caused a system crash.  Staffs of Travel Industry Automated Systems
  (TIAS) last week told of their "organised panic" as the virus spread
  through the Multi Access Airline Reservation System (MAARS), which
  covers agents in New South Wales and Queensland.

  TIAS technical manager Michel Radecki said the virus appeared in the
  form of corupted statistical data on June 9 soon after software
  changes.  Software supplier Memorex Telex said an onsite power
  interruption on the night of June 8 was believed to have caused the
  problem.  The company's manager of airline applications and support,
  Alan Sitters, said data was not disk-converted [?] during the
  interruption, resulting in incomplete information entry into the
  network.  He said the cause was external and the MAARS software was not
  at fault.

  Radecki said about 450 users were offline for several hours over two
  days as Memorex Telex trouble-shooters joined inhouse staff to fix the
  problem.  TIAS staff had staff shut the 275-user queuing system to
  pinpoint the fault, but the virus quickly spread to the reservation
  system and information database, he said.

  [...]

  He said the software changes had been made about one week before the
  crash to test the integration of American Airlines [!] into the
  system.  The TIAS network already had access to 35 airlines'
  reservation systems.''

So, a power failure causes corruption of input data, and with no
apparent sanity-checking, goes on to corrupt other data.  Is this a
virus?  If it looks like a crow, and sounds like a crow...

-- Dave Horsfall (VK2KFU), Alcatel-STC Australia, dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET, ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Update on Airbus crash
</A>
</H3>
<address>
Duncan Baillie 
&lt;<A HREF="mailto:dmb%lfcs.edinburgh.ac.uk@NSS.Cs.Ucl.AC.UK">
dmb%lfcs.edinburgh.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
29 Jun 1988 0950-WET (Wednesday)
</i><PRE>

The airbus story seems to have been dropped from today's news, probably being
overshadowed by the Paris Train crash (which killed 57). There were some more
details yesterday, but I don't have them to hand. It seems however that the
blame for the crash is being placed squarely on pilot error. Apparently the
pilot had TURNED OFF the computer for the demonstration flight and was flying
the aircraft at 30 feet, 70 feet below the minimum safety level. The pilot has
said that he requested more power from the engines but it arrived to late (from
film of the accident you can hear the power coming on just when the plane
clipped the top of the trees). I believe that manslaughter proceedings may be
brought against the pilot.

British Airways have stated that they are satisfied the cause of the crash was
not any design fault in the aircraft and have resumed service with their own
A-320s.

It is amazing that more lives were not lost in the crash as there was a large
explosion a few seconds after the planes came down. The only recognizable
features in the burnt out wreckage are the tailfin and part of the left wing.
The planes automatic escape chutes, which opened as soon as the plane crashed,
seem to have been the reason that so many people were able to leave the plane
so quickly. Many people clearly have their lives to thank for this safety
feature. 

In accidents such as this there are usually some other contributory factors
but for the moment pilot (and co-pilot) error is the main source of blame. The
risks: perhaps the major risk was the lack of faith the pilot had in the
computer (French pilots have been voicing concerns for some time about the
aircraft's safety) so the major question is why was the computer turned off?

</PRE>
<HR><H3><A NAME="subj3.2">
Re: Airbus A 320 crash - risk of `Fly by Wire'?
</A>
</H3>
<address>
Klaus Brunnstein 
&lt;<A HREF="mailto:brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET">
brunnstein%rz.informatik.uni-hamburg.dbp.de@RELAY.CS.NET
</A>&gt;
</address>
<i>

</i><PRE>

West German newsmedia began to report about possible risks of the
Fly-by-wire technology of the Airbus A-320 only after a spokesman of
Cockpit, an international pilots association, said that his organisation had
severe doubt about the `official' version (as having been published by the
responsible French minister a few hours after the accident) that the pilot
made severe mistakes. In the meantime, public authorities in France, UK and
Germany as well as Airbus Industries (through the chairman of the board, MP
Strauss from Bavaria) interprete video-films showing the `demonstration
flight' including the final phase with the following arguments:

   1. `demonstration flights' aimed at demonstrating the
      aerodynamic limits (e.g. low height, low velocity)
      are only allowed without passengers, with small
      amount of kerosene and only with specially educated
      test pilots; since Mulhouse airport is only a very
      small airport, a demonstration flight would have
      never been allowed by the French authorities; the
      two French pilots, though Air France's most experienced
      Airbus pilots, were not properly educated;

   2. the pilots have (against rules) switched to `manual
      control'; as can been seen in the videos, the plane
      was as low as 30 feet at a velocity of only 140 Knots;
      the trees shortly after the end of the runway were about
      40 feet tall, but the pilots could not see the tree-tops 
      because of the elevation of the plane's nose in the
      simulated landing procedure;

   3. while the pilots say, that the engines didnot follow
      their signal `speed-up', the officials say, that this 
      signal was given too late; assuming that the simulated
      approach was done under `running idle' conditions, the
      engines need 8-10 seconds to accelerate to max. RPM;
      from the moment where the engines really began to
      accelerate, until the moment where the plane reached at
      top of the first trees, only 5-6 seconds were past.

Despite the official version (which allowed the French, UK and
German Airbus A-320 planes to be in the air again after 1 day
of flight prohibition), several questions are un-answered:

   a. Did the pilots fly under `manual control'(as the
      officials argue, while some experts said that such
      a mode doesnot exist for simulated landing)?

   b. If under manual control, did the pilots fly (contrary to
      experienced behaviour) with the engines running idle (then
      needing 8-10 seconds to accelerate the engines), or did they
      run with `drag gas' (German: Schleppgas) after which the
      engines need only 2-4 seconds for maximum RPM? In both cases,
      why did the engines only react on gas-giving with retardation?

      (Cockpit officials say, that experienced pilots fly such
      manoevers with drag gas: this reaction time would have
      allowed to avoid the accident when all other technical
      conditions are in good orfer; they trust their colleagues
      statement that the engines didnot react instantaneously,
      and they continue to speek of a technical problem)

   c. Was the demonstration flight authorized? The Airbus was
      transferred to Air France only 2 days before, and evidently
      this was its public maiden flight.

The very fast reaction of government and industry is not surprising:
Airbus Industries hopes to build and sell more than 500 Airbus
A-320 models in the next 10 years. Though the governments of France,
UK and FRG are responsible for airtraffic safety, they have also 
invested more than 10 Billion Dollars into the diverse models, and
they are interested in minimizing the risks from prize guarantees
which they have overtaken also for A-320. It seems rather doubtful
whether guaranteed security was the reason that the responsible
French minister excluded any technical risk before technical
investigations could have given enough evidence.

Though severe problems with computerized equipment in military
aircraft have recently drawn public interest to safety in airtraffic,
the A-320 accident for the first time draws public attention to 
risks of overreliance on computers. Officials as well as technicians
argue that the technical system is much safer than any other plane
before or even today; if there is any risk, than it is `only the
risk of the human operators'. If you leave the `holistic approach'
aside (according to which the security of a system consisting of 
humans and machine is not greater than the least secure component),
there remain also design considerations to be analysed:

    If a pilot cannot see, in the typical approach configuration
    `nose up', the ground several 100 meters before his nose,
    is it responsible to have a `manual landing mode' at all?
    (In this case, the demonstration of slow, low flight would
    have been impossible, but also no victims!)

    As pilots control involves human errors, automatic control
    also involves human decisions, namely those of designers and
    programmers; even if they were flight experts, they cannot
    foresee (not only in todays limitations, gut generally) all
    situations of the `real application situation'. A totally
    computerized system like the A-320 where no mechanical aid
    helps to correct electronic shortcomings is by its very
    design principles less adaptible to unforeseen real world
    events.

Unfortunately, it is not so unprobable that several more accidents
may falsify the official optimism which describes this plane as
`the most secure plane ever built'; but fortunately, public media
begin (at least in FRG) to wake up from such dreams.

Klaus Brunnstein    Univ.Hamburg       FRG
    
</PRE>
<HR><H3><A NAME="subj3.3">
re: Four killed as Airbus crashes  [Actually Three?]
</A>
</H3>
<address>
&lt;<A HREF="mailto:Laura_Halliday@mtsg.ubc.ca">
Laura_Halliday@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Mon, 27 Jun 88 09:48:58 PDT
</i><PRE>

In an interview on the BBC World Service this morning, an aviation expert
commented that some pilot errors cannot be easily remedied by computer. In
particular, once the landing gear is down, the on-board computers assume that
the pilot intends to fly the plane down to ground level, otherwise the A320
could not land until it ran out of fuel.
 
This implies the existence of elaborate lockouts - what if the
pilot intends to make a wheels-up landing (for whatever reason)?
 
Laura Halliday                     laura_halliday@mtsg.ubc.ca

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
root typos (could happen to anyone)
</A>
</H3>
<address>
Joe Eykholt
&lt;<A HREF="mailto:jre@Sun.COM ">
jre@Sun.COM 
</A>&gt;
</address>
<i>
Tue, 28 Jun 88 17:38:51 PDT
</i><PRE>

How about "rm *&gt;o"  instead of  "rm *.o"  this can be caused on many
keyboards by holding the shift key down a little bit too long.

Don Sterk at Amdahl pointed this one out to me, after it happened to him once.
The shell creates the file "o" then rm removes it and everything else.

	Joe Eykholt

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"large-scale" disasters (Hinsdale, Ill.)
</A>
</H3>
<address>
Tom Perrine
&lt;<A HREF="mailto:hamachi!tots!helix!tep@nosc.mil ">
hamachi!tots!helix!tep@nosc.mil 
</A>&gt;
</address>
<i>
Tue, 28 Jun 88 14:16:18 PDT
</i><PRE>

A few questions and comments about disaster planning and the recent
Illinois Bell central-office (C)) fire in Hinsdale Ill.

This seems to be the first time that such a relatively small fire has
destroyed so much communications capability. The Hinsdale CO was
apparently carrying most (if not all) of the communications traffic
for lots of large, information-intensive businesses.
***Is this CO typical of others around the country?

Many (or most) of the companies involved had placed the probability of
interruption of the carrier's service as fairly low.
***Is this typical of companies that depend on communications common-carriers?

According to interviews in "Network World," many of the network managers
of the affected companies were "shocked" at the lack of a fire-control
system. This has led to threats of litigation.
*** Any comments?

Even though this was a communications failure, and no customer's equipment was
damaged, several companies were forced into their full-scale disaster plans,
because they either had not addressed loss of communications separately or
these "mini-disaster-plans" were not workable (e.g. the backup phone lines also
went through the same CO).  This is *much* more expensive than just restoring
communications would have been (United Stationers, Inc. spent nearly $600,000
to move to its backup data center).  
*** How many companies would be in the same situation if this happened to them?

Has anyone (or any organization) announced plans to try to conduct a
large-scale multi-company post-mortem examination of the incident?  This would
appear to be a golden opportunity to examine a wide range of disaster plans,
produced by many different organizations and determine which features of each
plan were most or least useful. This could lead to better overall disaster
planning for the industry as a whole.

Tom Perrine    hamachi!tots!tep@NOSC.MIL (last resort:Perrine@DOCKMASTER.ARPA)
Logicon(Tactical and Training Systems Division)	San Diego CA (619) 455-1330

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.10.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.12.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-53</DOCNO>
<DOCOLDNO>IA012-000129-B047-153</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.12.html 128.240.150.127 19970217021934 text/html 19989
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:18:01 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 12</TITLE>
<LINK REL="Prev" HREF="/Risks/7.11.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.13.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 12</H1>
<H2>  Thursday 30 June 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Airbus 320 
</A>
<DD>
<A HREF="#subj1.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Background on the A-320 incident 
</A>
<DD>
<A HREF="#subj2.1">
Willis Ware
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Fly-By-Wire 
</A>
<DD>
<A HREF="#subj3.1">
John O. Rutemiller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Airbus 320 
</A>
<DD>
<A HREF="#subj4.1">
H.Ludwig Hausen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  $40 million Pentagon computer system failure 
</A>
<DD>
<A HREF="#subj5.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Another "silent fault tolerance" example: DWIM 
</A>
<DD>
<A HREF="#subj6.1">
Tim Budd via Mark Brader
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Airbus 320 (<A HREF="/Risks/7.11.html">RISKS-7.11</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Thu, 30 Jun 88 13:18:20 PDT
</i><PRE>
 
Here are some comments on the A-320 crash, official reports, and 
unofficial speculation.

   It is truly amazing that official sources attributed the accident
to pilot error virtually before the investigation began.  A decision 
seems to have been made to protect Airbus and blame the flight crew
no matter what the facts.  It was grossly irresponsible to exonerate
the aircraft before the flight data recorders were examined, or experts 
had time to analyse the video tapes and other data.  

   There are several questions that many people have not asked that are
critical to an understanding of this accident.  If the aircraft was
indeed only at 30 feet of altitude, why was it that low?  Did the pilot
intend to descend to that height?  What was the minimum altitude authorized
for the low pass?  What was the actual airspeed, the pilot-commanded/desired
airspeed, and the minimum authorized airspeed?  

   Observers claimed that they heard the engines spool-up too late.  The 
conclusion is that the pilots did not allow for the spool-up delay.  Such 
a delay is NOT specific to the A-320 but is rather a characteristic of all 
turbo-jet engines.  Why would an experienced crew have delayed adding power, 
or even throttle back to low idle, when a high-speed idle would have made 
engine response much quicker.  When did the crew command a power-increase?  
Was it several seconds BEFORE witnesses heard the engines START to spool-up?

   Some maintain that the "computer was turned off".  This is an interesting
concept for an aircraft that flies completely by electronic controls.  There
are no direct manual controls of the primary flight surfaces or engine
controls.  Some auto-matic features may have been de-selected. It is of 
great interest which these were and how the selected systems operated.

&gt; The planes automatic escape chutes, which opened as soon as the plane crashed,

   That's an interesting report.  As far as I know, there is no automatic
door opening / escape slide deployment mechanism.  Slides inflate auto-
matically once doors are opened manually.  The likely reason that so few
lives were lost is that the aircraft contacted the trees in wings level,
controlled flight, with the nose up.  The lower fuselage structure and wings
absorbed much of the impact, and as trees were destroyed they relatively
gradually slowed the aircraft.  

&gt; I believe that manslaughter proceedings may be brought against the pilot.

   What will be the outcome if we find that an aircraft system was at 
fault? Do we bring charges against Airbus management, engineers, or 
software programmers?  

   It is interesting that British Airways is satisfied that the aircraft 
was not at fault.  How could they have made that decision before any data on
the accident was released?  Every day that their airplanes sit on the ground
costs a lot of money in lost revenue, and is negative publicity for their
shinny new airplanes.  The airlines thus have a proprietary interest in
keeping them flying.


   Officials blame a flight crew that was chosen for its experience and
abilities.  This crew was extensively trained and passed certification
exams on systems and flight of this aircraft.  That such a crew could be
involved in an accident like this indicates that the aircraft is not
immune to accidents, even with it's advanced technology.

   The A-320 may have been designed to be more safe than older technology 
craft, but this does not mean that it is.  Only operational experience 
will establish the actual risk.  A major concern of systems analysts and
pilots is that automated systems may actually increase risk as the pilot 
is not "in the loop", at the least not to the extent he is in other 
aircraft.  Operational experience has shown us that automation introduces
new problems as it addresses some old ones.  As of yet, we have no data
to show that the highly automated A-320 will be as safe, less safe, or 
more safe than older aircraft.  We may learn a lot about the aircraft
from an analysis of this accident.  We will certainly not know why the
accident occurred or if anyone is to blame until the investigation is
complete.

						Steve Philipson

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Background on the A-320 incident
</A>
</H3>
<address>
&lt;<A HREF="mailto:willis@rand-unix.ARPA">
willis@rand-unix.ARPA
</A>&gt;
</address>
<i>
Thu, 30 Jun 88 10:14:10 PDT
</i><PRE>

Given the extensive commenting on the A-320, perhaps these observations
will be useful.  They're based on my personal knowledge of avionics as it
is implemented and practiced in USAF aircraft and in the 757/767.

Incidentally Klaus Brunstein quotes the investment in the A-320 as $10
Billion.  I wonder whose "billion" he's using; if it's the English
billion, that's an investment of $ 10*13 -- lotsa bucks.

The USAF F-16 tactical fighter is a fly-by-wire and implements flight
control with a quad-redundant analog (YES - analog) computer in the belly
of the plane.  It is a microcircuit analog implementation to be sure, but
nonetheless avoids the software problem in flight control.  There are no
cables from the cockpit to the control surfaces except for trim tabs.  If
the quad-redundant machines are lost, the pilot can try to land the plane
by manipulating trim tabs.  Needless to say, one of the earliest changes
to the aircraft was to put protective armor around the flight controllers.

There is a separate 65K (as I recall) computer that integrates aircraft
functions, delivers signals to the flight control analog system, receives
signals from it, talks to the software-controlled heads-up-display, receives
digital inputs from the inertial navigator and from manual pilot inputs,
manages the radios, receives signals from and sends control signals to the
software-controlled radar, transmits pilot inputs to the digital
weapons-control subsystem and receives status information from it, receives
and logs all fault indications from the entire aircraft and runs diagnostic
tests on itself and on other subsystems, AND manages cockpit instrumentation
and display.  The sytem also monitors for some danger conditions, e.g.,
wheels up but ground clearance approaching zero.  Everything communicates
with everything else on a 1 Megabit/sec digital redundant MUX bus.

As I recall, pilot intentions (originating by a non-moving pressure-
senstive side stick) are communicated directly to the flight control
system which then relays them to the digital systems.  Thus the pilot
could fly the airplane IF the master digital system failed, although he
might have no instrumentation (at one time there was a debate about
leaving a few "round instruments" in the cockpit as fallback).

USAF has experimented with and test flown a digital fly-by-wire system,
but I don't know whether it's been implemented in more recent aircraft, or
even in the upgraded F-16.  Odds are that newer fighters (e.g., F-18s and
F-20s) are all-digital.  Almost surely the ATF will be all-digital.

Even though the analog system actually flys the F-16, it gets inputs and
control from the digital systems.  In particular, the acclerometers of the
inertial nav system report dynamic acceleration and if it's too high, the
intent of the pilot is overriden by the software controls to avoid tearing
the wings off the plane and blacking out the pilot.  In fact pilots have
complained about this because they would be willing to risk aircraft
damage and/or blackout to escape a pursuer or perform some maneuver.

In US commercial aircraft that have "glass cockpits" (as the CRT displays
are called), flight control has continued to be traditional direct cable
linkage for the most part although hydraulic boost is almost always
needed.  There are aircraft in which the stick motions control only a
hydraulic system which is the only linkage to the surfaces.

There usually is an all-digital system called by some such name as "Flight
Director" that does or helps with navigation (especially on inertial-nav
equipped aircraft), controls the aircraft trajectory in conjunction with
an autopilot or other nav inputs, might support fuel management, might
handle the aircraft through Cat III (blind-landing) procedures, controls
the descent from flight altitude to minimize fuel consumption, handles the
throttles to conserve fuel consumption, etc.

Without a lot of technical details, one cannot know how the A-320
designers implemented their software and distributed the functionality
across one or more computers.  Odds are that the flight control is in a
separate and redundant set of machines for safety.  If the designers were
astute, the redundant machines are powered from separate power sources and
through individual circuit breakers. [There is a recorded instance in a
commercial aircraft of the pilot losing an important instrument because it
was powered through a circuit breaker that also happened to control some
inconsequential other thing -- such as lighting.]

So any comment about "shutting off the computer" (in the A-320) must refer
to the flight management system, not to flight control.  Airlines are
forever interested in optimizing cost of operation, and who knows what
flight-profile or flight-maneuvers may have been incorporated into the
A-320 systems?  Who knows what combination of danger situations have been
programmed in -- and the flight crew blundered into?  Who knows whether
the aerodynamically possible and economically desired flight envelope
has been built into the software -- and the flight crew accidentally
violated?

One can easily imagine a software requirement that says something like:

   IF   engines throttled back AND wheels down AND altitude less
	than ..... AND rate of descent equal to .... AND speed less
	than .....

   THEN aircraft is landing and adjust angle of attack to .....;
	also check for proper fuel-flow conditions for landing, check
	flap position, ......

In spite of what has been said, I personally am not yet ready to conclude
that a software anomaly lurks in the A-320.  Personal opinion of course,
but it sounds suspicious to me.

There is one other observation about glass cockpits that my friends in the
business have told me.  Round instruments not only indicate some parameter
but they also convey rate-of-change information.  Glass instruments
evidently have been implemented to convey only the parameter value, not
the derivative of the parameter.  If true, one can imagine that in some
circumstances the flight crew is denied helpful and possibly critical
information about events.

					Willis Ware

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Fly-By-Wire
</A>
</H3>
<address>
"John O. Rutemiller" 
&lt;<A HREF="mailto:Rutemiller@DOCKMASTER.ARPA">
Rutemiller@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 30 Jun 88 09:12 EDT
</i><PRE>

When considering the safety of a fly-by-wire system compared to a "normal"
system, you must consider whether the overall safety of the system is improved.
Granted there are failure modes in fly-by-wire that would not otherwise
exist, but there are also a lot of things you can do with fly-by-wire that
you would not be able to do with a "normal" system.  If the overall safety
of the system is improved, then it is a better system.

   [But don't forget that if the aircraft is designed to be aerodynamically
   unstable (i.e., without the computer) -- as are some high-performance planes
   -- overall safety can be nonexistent under certain conditions.  At the
   IEEE COMPASS '88 this week, John Cullyer noted that in a fully
   fly-by-wire plane such as the planned Eurofighter, the pilot will
   have at most two seconds in which to decide whether to eject, after
   which it may generally be too late.  (The Experimental Aircraft Project
   is developing a plane that will be -12% (un)stable.  John described the
   VIPER effort, which is being subjected to extensive formal proofs, and
   which is being designed for the EAP.)  PGN]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Airbus 320 (Re: <A HREF="/Risks/7.10.html">RISKS-7.10</A>)
</A>
</H3>
<address>
"H.Ludwig Hausen +49-2241142426"            
&lt;<A HREF="mailto:HAUSEN%DBNGMD21.BITNET@CUNYVM.CUNY.EDU">
HAUSEN%DBNGMD21.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Thu, 30 Jun 88 09:54
</i><PRE>

 There was a video on German TV Newsshows (ARD, ZDF, SAT1)
indicating that the Airbus plane
1. was 10 meters above the ground
2. in a position making the pilot unable to see the trees at the
   end of the runway (which was too short for landing an Airbus)
3. engines got power far to late to get back into secure hights.

Seeing the video one will get the impression that the whole thing
(going to a small, badly equipped airfield and doing demonstrations)
was a very risky PR manoeuver.  There might be some serious
problems with this Airbus plane (see B. Littlewoods comments) but
I guess this time it was the pilot's fault.  H.L. Hausen

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
$40 million Pentagon computer system failure
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
30 Jun 88 07:45:04 PDT (Thursday)
</i><PRE>

From the Los Angeles Times, June 29, 1988:

   PENTAGON COMPUTER SYSTEM CALLED A $40-MILLION FAILURE

The Pentagon's latest effort to unscramble its tangled foreign military sales
accounts has been a $40-million failure, the House Government Operations
Committee said Tuesday.  It said a costly new computer system for straightening
out the botched program was two years behind schedule, had thousands of
unresolved problems and ultimately could cost $75 million without performing
well.

As a result, the committee said, the Defense Department cannot say why there is
an unreconciled $1-billion difference between cash on hand in a special trust
fund and total payments by foreign countries that purchase U.S. military
equipment through the foreign military sales program.  "The [foreign military
sales] trust fund system is in shambles," Committee Chairman Jack Brooks
(D-Tex.) said.... 

The new accounting system, developed by the SAGE firm of Rockville, Md., for the
military, was supposed to be ready in October, 1986.  Now the completion date
has been postponed until next October, or two years behind schedule.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Another "silent fault tolerance" example: DWIM
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Mon, 27 Jun 88 16:11:44 EDT
</i><PRE>

Path: sq!utfyzx!utgpu!utzoo!attcan!uunet!husc6!bloom-beacon!tut.cis.ohio-state.edu!rutgers!orstcs!mist!budd
From: budd@mist.cs.orst.edu (Tim Budd)
Newsgroups: comp.lang.misc
Subject: Re: What makes a language "easy" to program in?
Date: 17 Jun 88 20:31:42 GMT
Organization: Oregon State Universtiy - CS - Corvallis, Oregon

No, I'm not sure you want a ``do what I want'' command.

The following story is true, I've just forgotten some of the less important
details.  There was a Lisp system once that had something called DWIM (do
what I mean).  If you typed an expression, if it didn't make sense, it would
try various techniques to see if something close to it made sense, and do
that.  Now a friend of mine was using this system and kept having amazingly
slow programs.  It turned out he was saying things like (CAR ...) when the
system wanted (car ...).  It would not recognize CAR, go through some
analyzing, discover that a probable meaning was car, then do it.  Problem
was there was no feedback - no indication he was doing anything wrong, it
produced the right answer, just slowly.  So there are dangers in ``do what I
want'' systems even when (and this is a big if) they can exactly figure out
what it is that you want.

[Forwarded to Risks by Mark Brader] 
     [That was Warren Teitelman's INTERLISP environment.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.11.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.13.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-54</DOCNO>
<DOCOLDNO>IA012-000129-B047-185</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.13.html 128.240.150.127 19970217021948 text/html 25737
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:18:15 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 13</TITLE>
<LINK REL="Prev" HREF="/Risks/7.12.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.14.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 13</H1>
<H2>  Friday 1 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Scratch-and-win"?  Try "X-ray-and-win"! 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  SDIO computers stolen 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Did DWIM DWYW (Do what you wanted)? 
</A>
<DD>
<A HREF="#subj3.1">
Stephen D. Crocker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Directions and Implications of Advanced Computing - DIAC-88 
</A>
<DD>
<A HREF="#subj4.1">
Douglas Schuler
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Grocery Store Barcodes: Another game you don't win 
</A>
<DD>
<A HREF="#subj5.1">
David A. Pearlman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  ATM "receipts" 
</A>
<DD>
<A HREF="#subj6.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Risks of bank ATM cards 
</A>
<DD>
<A HREF="#subj7.1">
Dan Franklin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Risks of ATMs and the people who unload them 
</A>
<DD>
<A HREF="#subj8.1">
Rob Austein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  More problems with VARs 
</A>
<DD>
<A HREF="#subj9.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Hard-disk risks from vendors 
</A>
<DD>
<A HREF="#subj10.1">
George Pajari
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Scratch-and-win"?  Try "X-ray-and-win"!
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Fri 1 Jul 88 07:53:07-PDT
</i><PRE>

The Ontario Lottery Corp in Canada has removed all Money Match and Double
Dollar tickets from sales (about $8M Canadian [per week?]) because tests have
shown that the numbers under the latex patches on the $2 tickets could be read
with 100% accuracy using x-ray equipment -- albeit at some expense.  Lottery
Corp's president Norman Morris said, "There's always somebody working to beat
the system, and we're constantly working against them to improve the system."
He added that the withdrawn tickets were much better than those made five or
six years ago [but still not good enough!].  [Source: The Globe and Mail, 15
June 1988, front page article by Mary Gooderham]

This is another example of the continual escalation resulting from more
sophisticated attacks responding to more sophisticated technology.  Past RISKS
cases have included microprocessor-controlled slot machines, computer system
breakins, internal frauds, and of course -- over many years -- phone phreaking.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
SDIO computers stolen         [old story not previously noted here]
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Fri 1 Jul 88 07:32:02-PDT
</i><PRE>

Two computers were stolen from the Pentagon's Strategic Defense Initiative
Office on consecutive nights (9 and 10 April 1988).  The thieves entered by
sabotaging the (physical) security system.  "Videotape cameras did not record
the theft because they had not been loaded," according to TV station WJLA.
"The station, attributing its information to unidentified Pentagon
investigators, said this lapse was a common one at the agency's offices."
[Source: AP, Washington DC, 24 June, in NY Times, 26 June 1988, p. 18, on the
same page with "Bishops Raise Morality Issue on `Star Wars'"...]

    [One wonders whether the motive was theft of stored information,
    or merely theft of the equipment for its own sake!]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Did DWIM DWYW (Do what you wanted)?
</A>
</H3>
<address>
Stephen D. Crocker
&lt;<A HREF="mailto:crocker@tis-w.arpa ">
crocker@tis-w.arpa 
</A>&gt;
</address>
<i>
Thu, 30 Jun 88 21:10:57 PDT
</i><PRE>

In <A HREF="/Risks/7.12.html">RISKS-7.12</A>, Tim Budd relays a story about the Do What I Mean (DWIM) facility
in Interlisp.  For example, if "CAR" was misspelled "car", the Interlisp
interpreter would trap to the DWIM facility, which would notice a probable case
error, make a replacement and proceed.  This facility took a lot of time if it
was called repeatedly.  Budd says the DWIM facility did not say what it was
doing, so the poor user did not know why his program was running so slowly.

The true story about DWIM is more complex.  MANY others, including, of course,
the designer Warren Teitelman, can comment usefully on DWIM.  Let me outline
a few of the important points.

o DWIM was a collection of facilities, some intended to fix errors and some
  intended to facilitate programming.  Various forms of spelling correction
  were included, as were numerous other useful error correctors.  Each of
  these facilities could be turned on or off, and various levels of feedback
  were possible.  It was certainly possible to disable all DWIM facilities,
  and it was certainly possible to insist that the user be notified and/or
  queried before making any corrections.

o DWIM was fundamentally an experimental system that enjoyed quite extensive
  use.  No strong claims were made that DWIM was fail-safe, although it was
  well thought out and as solid as any production code I've ever dealt with.

o DWIM was COMPLETELY documented.  A relatively large fraction of the daunting
  Interlisp manual was devoted to the DWIM system.

Some risks are endemic in any such system:

o If a new user is given access to Interlisp with DWIM enabled, he may not
  know how it will operate or what it will do for him.  It was not uncommon
  for a novice user to be set up with an environment that reflected the
  preferences and KNOWLEDGE of an experienced user.

o The amount of documentation was daunting.  Very few users could absorb
  the documentation at first exposure.

o DWIM relied on various models of probable errors.  Case errors are easy
  to understand, but some others were more subtle.  DWIM would attempt
  to correct parenthesization errors by checking for stray 9's and 0's.
  If DWIM's model of probable errors did not match the user's actual error
  pattern, the results would range from wasting time to miscorrection.

DWIM stimulated strong feelings, both pro and con, in the Lisp community.
As might be guessed, I liked it a lot, particularly because it represented
the most complete collection of ideas on program error detection and
correction and hence was a living laboratory.  People who attempted to do
research in this area and who did not have exposure to Interlisp had no
idea what they were missing, and I saw some number of PhD dissertations
completely wasted on poor imitations.  What I never saw, however, was
a serious study of how to introduce such facilities to new users and control
the facilities in a way that would minimize the risks.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Directions and Implications of Advanced Computing - DIAC-88
</A>
</H3>
<address>
Douglas Schuler
&lt;<A HREF="mailto:bcsaic!douglas@june.cs.washington.edu ">
bcsaic!douglas@june.cs.washington.edu 
</A>&gt;
</address>
<i>
30 Jun 88 18:48:08 GMT
</i><PRE>

              DIRECTIONS AND IMPLICATIONS OF ADVANCED COMPUTING

             DIAC-88   Twin Cities, Minnesota   August 21, 1988

      Earle Browne Continuing Education Center, University of Minnesota

Computing technology in public and  private  institutions  poses  challenging
technical,  political,  and social dilemmas. Programmers, analysts, students,
and professors will face these dilemmas, either actively or unwittingly. Both
within  the  computing  profession  and  in the relation of our profession to
other institutions, we have much to consider.

The second annual  symposium  on  Directions  and  Implications  of  Advanced
Computing will be held at the University of Minnesota campus on Sunday August
21, 1988, the day before the American Association for Artificial Intelligence
(AAAI) conference.

Douglas Engelbart, the DIAC-88 plenary speaker, will share his perspective on
using  the  computer  to  address  global  problems.   Since the late 1950's,
Engelbart has worked with systems that augment the human intellect  including
his  NLS/Augment  system,  a  hypertext system that pioneered "windows" and a
"mouse."  The driving force behind Engelbart's professional career  has  been
his  recognition  of  social  impacts  of  computing technology.  The plenary
session  will  be followed by presentations of research papers  and  a  panel  
discussion.  The panel, John Ladd (Brown University), Deborah Johnson  (Rens-
salaer Polytechnic), Claire McInerney (College of St. Catherine)  and  Glenda  
Eoyang (Excel  Instruction)  will address  the question, "How  Should Ethical 
Values be Imparted  and  Sustained in the Computing Community?"

		         Presented Papers

  Computer Literacy: A Study of Primary and Secondary Schools, Ronni 
    Rosenberg

  Dependence Upon  Expert  Systems:   The  Dangers  of  the  Computer  as  
    an Intellectual Crutch, Jo Ann Oravec

  Computerized Voting, Eric Nilsson

  Computerization and Women's Knowledge, Lucy Suchman and Brigitte Jordan

  Some Prospects for Computer Aided Negotiation, Douglas Schuler

  Computer Accessibility for Disabled Workers: It's the Law (invited paper)
    Richard E. Ladner

Send symposium registration to: DIAC-88, CPSR/Los Angeles,  P.O.   Box  66038
Los  Angeles,  CA   90066-0038.   Enclose  check payable to CPSR/DIAC-88 with
registration.  For additional information, call David Pogoff, 612-933-6431.

  NAME ___________________________________________________
  ADDRESS _________________________________________________
  ________________________________________________________
  ________________________________________________________
  Phone (home) _____________________ (work) ______________________

  Please check one:
  Symposium Registration           Regular             O $50
  (Includes Proceedings and Lunch) CPSR Member         O $35
                                   Student/Low Income  O $25

  I cannot attend, but want the symposium proceedings  O $15

There  will  a  reception  following  the  symposium.   Proceedings  will  be
distributed  to  registrants  at  the  symposium.  Non-attendees will receive
proceedings by October 15, 1988.

   ** MY VIEWS MAY NOT BE IDENTICAL TO THOSE OF THE BOEING COMPANY **
	Doug Schuler     (206) 865-3226
[allegra,ihnp4,decvax]uw-beaver!uw-june!bcsaic!douglas 	douglas@boeing.com

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Grocery Store Barcodes: Another game you don't win
</A>
</H3>
<address>
David A. Pearlman
&lt;<A HREF="mailto:dap@cgl.ucsf.EDU ">
dap@cgl.ucsf.EDU 
</A>&gt;
</address>
<i>
Mon, 27 Jun 88 17:01:28 PDT
</i><PRE>

All this talk about how ATM's don't make mistakes in the customer's
favor reminds me of one of my pet peeves: When the price on the food
shelf is not the same as the price scanned at the cash register.

It seems I run into this problem at least once a month at Safeway (and
I've had this problem every *week* for the last month). When I catch
it, the store will correct the mistake for me, but they don't offer
any other sort of fix (no additional discount; no free goods). What
this means is that a lot of people (who don't pay any attention) get
ripped off. Those, like me, who pay attention, get the goods at the
shelf price. Quite a good deal for the store, I'd say.

David A. (DAP) Pearlman   BITNET: dap@ucsfcgl.BITNET   UUCP: ucbvax!ucsfcgl!dap

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
ATM "receipts"
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Mon, 27 Jun 88 10:13:29 EDT
</i><PRE>

&gt; From: dcatla!mclek@gatech.edu (Larry E. Kollar)
&gt; The ATMs around Atlanta always give you a receipt, whether or not your
&gt; request went through.

I'd be very surprised if there are any ATMs anywhere that give a *receipt*
for a deposit transaction.  The ones I use are careful to refer to it as a
*transaction record*.  The distinction, of course, is that a receipt would
constitute an agreement that you actually deposited the amount you claimed.

For a withdrawal transaction, "receipt" doesn't even make sense.  *You* would
have to give *them* a receipt, if anybody did.

Despite the above, I have in earlier days seen ATMs that referred to their
transaction records as receipts.  I suspect the original messages were
written by programmers and not bankers...

Mark Brader, Toronto		   utzoo!sq!msb, msb@sq.com

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Risks of bank ATM cards
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Mon, 27 Jun 88 23:34:47 -0400
</i><PRE>
From: dan@WILMA.BBN.COM

&gt;From: dcatla!mclek@gatech.edu (Larry E. Kollar) [...]
&gt;As for the printer breaking or running out of paper, it's not a hard thing
&gt;for an ATM to detect the lack of paper flow and put itself out of service.
&gt;Whether or not ATMs do that is yet another question.

At least some of them do.  The ATMs I use (BayBanks, in Massachusetts) can tell
you as soon as you begin using them if they are out of paper and cannot print a
receipt; they then ask if you still want to use them.  (They unfortunately
can't tell when their ribbon renders the receipt almost unreadable.  Oh well.)
They also tell you about cancelled transactions.

Someone else mentioned the phones near BayBanks machines.  I was extremely
grateful for that phone a couple of weeks ago, the night before I was leaving
on a trip.  I had inserted my card, told the ATM I wanted $250 cash, and
listened to the mechanism start whirring when it suddenly went catatonic.  The
display was still lit, but there were no sounds or any other sign of activity.
Pressing CANCEL did nothing.  It still had my card hostage, so I couldn't just
go to another machine.  Also, I was worried about the possibility that it had
actually dished out some money in the still-locked cash drawer which might end
up going to the next person to use the machine.  I picked up the phone and
spoke to a woman who told me, after a moment, that the teller's communication
line to the mainframe didn't seem to be working.  She did something and my card
popped out.  (I guess there was more than one line from the ATM to the great
world outside.)  She told me to try another machine, but not too close, as it
might be using the same line.  I suggested a possible other machine and she
confirmed that it was on a different line; I went there and got my money.  I
have no idea what I would have done without the phone.

From the stories of other people, it sounds like BayBanks may do a better job
than some other banks with their ATMs.
                                        	Dan Franklin

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Risks of ATMs and the people who unload them
</A>
</H3>
<address>
Rob Austein 
&lt;<A HREF="mailto:SRA@XX.LCS.MIT.EDU">
SRA@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 28 Jun 1988  13:18 EDT
</i><PRE>

Here's another ATM horror story.  It's really a people horror story,
the ATM just made things more interesting.

I have both my checking account and my MasterCard at a bank with a bad
reputation for customer service but an extensive network of ATMs, which is
usually ok because I use ATMs every week and talk to human tellers maybe twice
a year.  Last fall I had occasion to attempt to use an ATM to make a prepayment
to my MasterCard from a travel advance via my checking account, because I knew
that the upcoming trip would exceed my credit limit.  To make a long story
short, I'd forgotten whether the MasterCard had a password (PIN) associated
with it, never having used it in an ATM before, so I followed what turned out
to be bad instructions from the person who answered the 24-hour customer
service phone, to wit, I used my normal ATM card to start the ATM session, then
punched all the right buttons for a credit card deposit (which were distinct
from any normal kind of deposit) and gave the machine the money in an envelope
that clearly indicated that this was a payment to credit card #x.  Then off I
went to California.

When I got to California and checked into the hotel, the hotel clerk told me
that my MasterCard wouldn't take the estimated charge, so I made temporary
arrangements and called the bank.  The bank said that the fine print gave them
to right to still be sitting on the payment, but that this right would expire
before the day I was planning on checking out, so if I just sat tight
everything would be fine.  As the reader has no doubt guessed, things were not
fine at checkout time, the MasterCard still wouldn't take the charge.  I called
the bank again and this time they had no record whatsoever of the payment, but
neither were they willing to take steps over the phone such that the check
would not be deposited if it were found (not in time to be useful to me,
anyway).  So here I was, on the other side of the country, I couldn't use the
MasterCard because the bank had lost the payment, and I couldn't write the
hotel a check because the bank might FIND the payment.  Fortunately I also had
an American Express Card for just such emergencies, so I was able to square
things with the hotel and fly home to yell at the bank.

When the dust settled, here's what they told me.  It seems it doesn't matter
what buttons you push on the ATM if you put the wrong card in, the human who
unloads the ATM processes it "appropriately" for the card you used.  I.e., the
effect was as if I'd deposited a check into the checking account it was drawn
on.  Since this is obviously a nonsense transaction, it isn't recorded anywhere
(amazing logic), and I would have eventually found out what had happened when I
received the UNCANCELLED check with my monthly statement and called up the bank
to ask what the hieroglyphics meant.

Now, I don't know if the ATM is simply asking for more information than it's
giving to the teller who unloads it in the morning (probably, I know that these
ATMs only look at the first four digits of a PIN no matter what you type) or if
this was an amazingly stupid teller.  Maybe both.  I did take the bank to task
for not having at least kept track of what the ATM/teller pair had done, at
which point they said that they'd had this problem before.  They had also had
the problem of the customer service people giving bad instructions on the phone
in this situation before.

The bank did make good on all the little expenses (except time) that I had
incurred during this fiasco.  I think they were embarrassed about the American
Express Card....
                                        --Rob

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
More problems with VARs
</A>
</H3>
<address>
jcmorris@mitre.arpa
&lt;<A HREF="mailto:Joe Morris ">
Joe Morris 
</A>&gt;
</address>
<i>
Mon, 27 Jun 88 16:59:48 EDT
</i><PRE>

In <A HREF="/Risks/7.10.html">RISKS-7.10</A> Hal Norman of JPL commented on problems of a VAR who claims
that the power supply he (Hal) is trying to return as defective wasn't part
of the system the VAR sold.  There's a flip side to this: soon after the 
first customer ship of the original IBM PC, several dealers were found to
be playing a game with the customers by buying a stripped PC (16K, no disk
drives) and installing their own memory chips and some el cheapo disks.
They would then sell the unit at the IBM list price, making much more than
if they had paid IBM's dealer price for the unit.  IBM was burned repeatedly
by units that failed and were returned for warranty repair; the customers
thought they had bought an IBM box and weren't happy when IBM declined to
give warranty service to non-IBM parts.

That's why the disk drive front panels suddenly acquired the IBM logo, so
that the non-IBM drives could be more easily identified.

I don't know why the AT's (and probably PS/2's) don't sport the IBM logo.
It may be that the drives themselves have the IBM part numbers or whatever
on the chassis so that they can be identified; the drives on the older
units have no IBM markings I can find.

Something to do on a rainy day: look at the ads in _Computer_Shopper_ and
try to guess the pedigree of the major subassemblies used in some of the
more aggressively-marketed clones.  The number of vendors who supply that
data is depressingly small.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Hard-disk risks from vendors (RISKS-7.8)
</A>
</H3>
<address>
George Pajari 
&lt;<A HREF="mailto:pajari%grads.cs.ubc.ca@RELAY.CS.NET">
pajari%grads.cs.ubc.ca@RELAY.CS.NET
</A>&gt;
</address>
<i>
Fri, 17 Jun 88 14:06:19 PDT
</i><PRE>
Organization: UBC Department of Computer Science, Vancouver, B.C., Canada

&gt;From: Jerry Harper &lt;mcvax!euroies!jharper@uunet.UU.NET&gt;
&gt;Subject:  Hard-disk risks from vendors
&gt;We use a number of 286 machines (American Research Corporation -made in Taiwan)
&gt; ...[details of various hardware problems]...
&gt; ... he said he was too "busy" to come out ...[more problems]...
&gt; ...[never] did the vendor admit any liability, nor did
&gt; he seriously offer a replacement. This is of some concern to a number of
&gt; Are too many people getting into the VAR market by the seat of their pants?

I get very upset with comments such as the above.  

Why do consumers in the computer market (especially PCs and other low-end
systems) assume that they can get more than they pay for?

Jerry as much as admits that they bought a cheap Asian clone to save
money then seems not to understand why the support is non-existent?

Unfortunately your hardware supplier has to eat also and the narrow margin on
his sales doesn't permit much support.  Why does he charge so little?  Because
if he included enough mark-up to pay for reasonable support people like Jerry
would buy from someone else! So it is the market (of which Jerry is a part)
which supports and even encourages such vendors.

Don't complain about support unless you are willing to pay for it.

George Pajari        sometime grad-student and full-time consultant
(no...I don't sell hardware...just get frustrated with clients who
expect the same level of service from low-margin clone vendors as from
full-price outlets)
These opinions are those of my company.  I own it, dammit.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.12.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.14.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-55</DOCNO>
<DOCOLDNO>IA012-000129-B047-212</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.14.html 128.240.150.127 19970217022001 text/html 20268
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:18:29 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 14</TITLE>
<LINK REL="Prev" HREF="/Risks/7.13.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.15.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 14</H1>
<H2>  Friday 1 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Eyes Have It (unique driver's license numbers) 
</A>
<DD>
<A HREF="#subj1.1">
Woody
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  New UK Virus 
</A>
<DD>
<A HREF="#subj2.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Australia Card - more details 
</A>
<DD>
<A HREF="#subj3.1">
Chris Maltby
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: The Challenger and visionary software architects 
</A>
<DD>
<A HREF="#subj4.1">
Jerry Hollombe
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Academic Assignment of Viruses 
</A>
<DD>
<A HREF="#subj5.1">
John Gregor
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 The Eyes Have It
</A>
</H3>
<address>
Woody
&lt;<A HREF="mailto:    <WWEAVER%DREW.BITNET@CUNYVM.CUNY.EDU> ">
    &lt;WWEAVER%DREW.BITNET@CUNYVM.CUNY.EDU&gt; 
</A>&gt;
</address>
<i>
Fri, 1 Jul 88 13:50 EDT
</i><PRE>

From _The_Star_Ledger_, Thursday, June 30, 1988 page 35, a New Jersey paper
published in Newark.

THE EYES HAVE IT

MV acts to 'separate' drivers with the same name, birth date

  At least 14,000 New Jersey motorists share the same names, birth dates,
and eye colors, the Division of Motor Vehicles has discovered in its
efforts to straighten out its licensing records.

  The DMV will be sending out letters to the motorists next week asking
them once again to reveal their true eye color.  The agency was forced to
delete the information from its computer system and use a substitute code
number in order to avoid issuing the same drivers's license number ot
different mororists, DMV Director Glenn Paulsen said yesterday.

  When issuing driver's licenses, the DMV computer system assigns a number
consisting of a letter followed by 14 digits.  The letter and first nine
digits represent the driver's name, the next four digits reflect the month
and year of birth and the final digits is a code representing eye color.

  In 14,000 cases, the DMV discovered, different motorists shared the same
names, birth dates, and eye colors and had to be issued special driver's
license numbers that substituted the number 7, 8, or 9 for the digits used
to represent eye color.

  "This effectively altered the driver license number to overcome any
possible duplication with an already existing number," Paulsen said.
"However, it also eliminated the individual's true eye color from the record."

  Paulsen said the system has been reprogrammed so that driver's license
numbers can be altered to avoid duplication, but still retain information
regarding eye color.  In addition, the DMV plans to change the format of
its driver's license documents later this year to include the eye color
information on the face of the license.

  The numbers 7, 8, or 9 will still be used on licenses in place of the eye
color code numbers in cases of potential duplication, but the eye color
information will remain on file in the DMV's records, under the new system.

  The eye color code numbers are 1 for black, 2 for brown, 3 for grey, 4
for blue, 5 for hazel, and 6 for green.

    [In light of all of the stories we have had in the past involving 
    name confusion and overzealous computer matching, this one is an
    attempt to do things a little more sanely -- at least to recognize the
    problem.  But it does not seem likely that, with 14,000 data collisions,  
    the codes 7, 8, and 9 are adequate to disambiguate on into the future,
    especially if new collisions arise.  How about using "9" as an escape
    for "other" and then tack on a unique disambiguator including color.
    What about albinos? People with non-matching eyes?  glass-eyes?  tinted
    contacts?  Lots of risks in computer matching here...  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 New UK Virus
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Fri, 1 Jul 88 10:36:42 CDT
</i><PRE>

The following is a complete item from the FEDERAL BYTES column (p. 42) of the
June 27, 1988, issue of Federal Computer Week, which just arrived in today's
mail (July 1):

Oh, No - Not Maggy!

Sources of reasonable reliability within the British Ministry of Defense (MoD)
report that a computer virus has broken out. It seems that MoD uses a number
of Macs, largely for graphics but some of them for word processing.

Whenever anyone writes "Margaret Thatcher" or "prime minister", the screen
[image] vanishes, along with whatever was on it. In the place of the missing
document appears a picture of Maggy, with a Union Jack behind her.

MoD, say our sources, has not found a cure.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Australia Card - more details
</A>
</H3>
<address>
Chris Maltby
&lt;<A HREF="mailto:munnari!softway.oz.au!chris@uunet.UU.NET ">
munnari!softway.oz.au!chris@uunet.UU.NET 
</A>&gt;
</address>
<i>
16 Jun 88 20:02:07 +1000 (Thu)
</i><PRE>
Organization: Softway Pty Ltd, Sydney, Australia

The Australia Card was not planned to be anything in particular.
The design was still in the tendering stage when the whole project
was canned due to a legislative technicality. Strictly speaking,
the government was given a mandate by means of a dissolution and
new election of both the Senate and the House of Reps which is
possible only when the Senate is viewed to be obstructing legislation.
The obstructed legislation was the Australia Card bill. For those
unclear about the Australian Parliamentary system, the government is
formed by the party which controls the House of Reps. The Senate has
been/is and is likely to remain without any absolute majorities. When
the new parliament was convened, a joint sitting of both houses was
held to pass the bill, and it may even have been gazetted into real
law, when it was discovered by a clever person that a regulation bill
was required to activate the Card. The Senate indicated it wouldn't be
passed so rather than face another election (and a certain loss) the
Australia Card was dumped. It's ready to go, just waiting...

Suggestions or requirements for the card itself were:

    A digitised image of the person possibly on the card itself or
    accessible to the counter operator when the card was scanned.

    A digitised signature (or thumbprint) and a digitising pad
    which could validate the user on presentation.

    The card was supposed to be made from secure materials and
    with secure printing etc etc.

No-one had really resolved how forgery was to be prevented. An
accomplice behind the registration desk would have laid the whole
system open. How many forged cards would you like sir...

Now we are to have an "upgraded tax-file-number" (unspecified)
if the Government can get it through the Senate. Of course, the
next election will be in early 1990 so they'll have to hurry...

Meanwhile, the tax commissioner and the courts have started to
interpret tax law much more strictly, and cuts in the rates have
probably done as much as the card would to prevent avoidance.
Social Security fraud seems to have retreated as an issue;
it's the cutbacks to it which are capturing the public mind.

Chris Maltby - Softway Pty Ltd	(chris@softway.oz)

PHONE:	+61-2-698-2322		UUCP:		uunet!softway.oz!chris
FAX:	+61-2-699-9174		INTERNET:	chris@softway.oz.au

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: The Challenger and visionary software architects (RISKS-7.7)
</A>
</H3>
<address>
The Polymath
&lt;<A HREF="mailto:hollombe@ttidca.TTI.COM ">
hollombe@ttidca.TTI.COM 
</A>&gt;
</address>
<i>
13 Jun 88 21:13:42 GMT
</i><PRE>

}Date: Thu, 09 Jun 88 16:16:29 PDT
}From: Eugene Miya &lt;eugene@amelia.nas.nasa.gov&gt;
}Subject: Re: The Challenger and visionary software architects\
}
}&gt;From: stork@humu.nosc.mil (Kent Stork)
}&gt;The May issue of Defense Science validates something that many computer
}&gt;scientists have probably suspected: ultimately, the failure of the Challenger
}&gt;and the death of the astronauts was due to a control loop software design
}&gt;oversight - just another bug.
}
}The closest comment to "control loop software design" is:
}	"It was not the leak that killed the astronauts.  It was the
}	attempt to correct the sidethrust, which sent the Challenger
}	into violent oscillations.

This smacks of semantic quibbling.  Had there been no leak there would
have been no need to correct for it.  In any case, the boost phase of the
shuttle's flight is extremely critical with respect to forces on the
assembled shuttle, tank and boosters.  The shuttle's control surfaces are
put through a very precise series of moves at this time to minimize stress
all around.  Any drastic deviation from expected conditions would be bound
to have severe consequences.

}	"If the Challenger had been permited to go off course,
}	without attempting the major correction, the side booster would
}	not have broken out, the booster would have burnt out with the
}	Challenger still intact, and the crew could have ejected, off
}	course but alive."   [spelling corrected]

Not true.  There were no facilities for crew ejection on board the
Challenger. (A more feasible scenario would have been an attempt to fly
the Shuttle to a landing after the boost phase had burned out).  If the
off-course shuttle had headed for a populated area the Range Safety
Officer would have been in the unenviable position of having to destroy
it _and its crew_ anyway.  Fortunately for his peace of mind, he only had
to destroy the boosters.

There are many RISKS associated with flying the Shuttle.  While much effort is
devoted to minimizing them, some of them simply have to be lived with.

The Polymath (aka: Jerry Hollombe, hollombe@TTI.COM)   
Citicorp(+)TTI, 3100 Ocean Park Blvd.   (213) 452-9191, x2483
Santa Monica, CA  90405 {csun|philabs|psivax|trwrb}!ttidca!hollombe

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
 Academic Assignment of Viruses (RISKS-7.4)
</A>
</H3>
<address>
John Gregor
&lt;<A HREF="mailto:unido!ecrcvax!johng@uunet.UU.NET ">
unido!ecrcvax!johng@uunet.UU.NET 
</A>&gt;
</address>
<i>
13 Jun 88 21:09:43 GMT
</i><PRE>
Organization: ECRC, Munich 81, West Germany

-&gt; Date:  Sun, 5 Jun 88 10:25 EDT 
-&gt; From: WHMurray@DOCKMASTER.ARPA 
-&gt; Subject: Academic Assignment of Viruses

-&gt; A society that depends upon any mechanism for its own proper
-&gt; functioning, cannot tolerate, much less encourage, any tampering with
-&gt; the intended operation of that mechanism.

Do you really believe that?  Are you saying that any possible activity
that could cause a deviation from the status quo is a danger and should
be 'discouraged' (a euphamism for destroyed)?  Unless you claim that
the system is perfect (completely without flaw), how can you claim that
an attempt to make change cannot be tolerated.  Even if you feel
perfection has been reached, who appointed you to be the conscience for
the rest of the race?  There no difference between your statement and
worst actions attributed to "The Red Menace," in that they destroy the
individual to maintain the purity of the state.  Such closed mindedness
never leads to an orderly society.  It leads to the mindless
destruction of all (both valid and fringe) criticism and methods of
checks and balances.  It leads to an ever tightening spiral of
repressions that is only broken by revolution and chaos (not something
I consider beneficial).  Your statement is the antithesis of the ideals
of personal liberty and social change that this (I'm a temporarily
relocated US citizen, so I mean the US) country is founded upon.

-&gt; Therefore, one is tempted to rise up in indignation at the idea of a
-&gt; qualified academic assigning a virus to his students.  

It's one thing to assign a project that specifically violates US or
State laws.  It is quite another to use an exercise to demonstrate the
fallacies of system security, system design flaws, and the ingenuity
and persistence of the dedicated.  The assumed goal of the exercise was
to give the students an insight into the problems of system security
and design.  A lesson they will take with them into industry to
integrate into the next generation of computing systems.  Then you and
those like you will be praising the same people for their ability to
seal up the leaks that plagued today's systems.

-&gt; The next thing you know, they will be assigning plagiarism.  How about
-&gt; the forgery of academic credentials?  Perhaps we should offer a course
-&gt; in how to falsify research results.  Or, perhaps, on how to trash
-&gt; another's experiments, notes or reports.

This is in no way implied by the original project.  It is only an
emotional appeal to create some sort of "mob-scene" reaction.  It is in
bad style.  The sad part is that mob psycology works (mobs aren't very
bright).  This means that some external entity must apply force to the
majority to protect the rights of the stampeding minority.  From your
posting and your ARPA location, I assume you are a part of some such
entity.  Unfortunately, the types that wind up ensuring the rights of
the minority are also the most likely to mindlessly follow the state
dogma and use their ability to use force to destroy the balances they
were there to protect.  It's a positive feedback situation.  It's an
auto-immune reation gone crazy.  It's fatal.  It's the biggest RISK of
all.

-&gt; Perhaps it is a sign of immaturity that we are unable to recognize the
-&gt; moral equivalency.  I will leave open the question of whether the
-&gt; immaturity is in the technology, the society, or academia.

I sugest it is in those who fear any and all challenges to their dogma
and supersticion.  Especially those who fear ideas and use force to
destroy them.  Actually, I guess I'm no better.  The basic philosophy
your posting supports and what history has shown to be the results of
that philosophy are the only cause I can imagine risking my life to
help destroy.  Our only difference is that I am able to live my life
knowing that there are those who don't believe as I.  While many of
them won't rest until all of the heretics, perverts, and risks to their
social order have been neutralized.  Yes, this is a war.  It's not one
I would have.  It's one that is caused by those who feel they MUST
destroy all dissent and won't let the rest alone.  I only hope I and the
ones I love never have to fight.

-&gt; I thought that we put this issue to bed several years ago when we
-&gt; stopped assigning the breaking of security.  It seems that we did not.

It's still common practice to stress test a system (computer, program,
physics theory, etc.) by trying to break it.  It's the only way to be
sure.  Why should a political theory or social order be sacrosanct?
If you fail to test, unless you are perfect, the system will fail in
a way that could have prevented if only the attitude of the powers-that-be 
didn't equate questioning as heresy.  Our shuttle is a good example of where
that attitude goes.

-&gt; For an academic to be unable to recognize that assignments, and the
-&gt; recognition that goes with their successful completion, encourages the
-&gt; behavior assigned, demonstrates a lack of understanding of the activity
-&gt; in which he is engaged.  If he understands it, and still makes such an
-&gt; assignment, he demonstrates a lack of understanding of where his real
-&gt; interest rests.

-&gt; Such irresponsible behavior may account, in part, for the anti-academic
-&gt; bias in our society and for the manifest distrust of the scientific
-&gt; establishment.  

I believe that your perceptions of an anti-academic bias and distrust
of academia stem from that fact that they can't be controlled.  They
can come up with facts independently from your personal belief system.
Your views are no better than the worst of the Soviet and Nazi system,
where only state-backed results were released and non-conforming
results were destroyed and the people involved "reeducated."  Academia
should have to bow to your (or anyone's) fears, superstitions, or idea
of what the answers should be.  Reality is not going to change, no
matter how much you or anyone (creationists, flat earthers, etc) want.

-&gt; It is of little wonder that the citizens of Cambridge, Massachusetts
-&gt; are reluctant to trust the likes of these with genetic engineering.

An analogous project might be to create viruses and other biological
agents that target "flaws" in the human system.  I don't think you need
to worry about the universities.  The US military is quite advanced in
this madness.  The difference between the two projects is that 

  1. The computers are the property of the university and theirs to do with as
they wish.  Humans aren't.  

  2. An electrically and logically separate computer environment is easier
to create/maintain and guarantees isolation.  Biological systems aren't so
simple or as easy to play with.  

  3. The worst case scenario for the computer project is: Brand X computers
fall over until booted from a clean tape and some data is lost.  For a
biological scenario:  Extinction of the human species or of all life on
Earth.  So why does the DoD continue Biowarfare?  Or is is it ok because
it's done by the state?

If I ever try to get a security clearance and this doesn't come back to
me, I'll be disappointed.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.13.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.15.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-56</DOCNO>
<DOCOLDNO>IA012-000129-B047-244</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.15.html 128.240.150.127 19970217022015 text/html 24541
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:18:42 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 15</TITLE>
<LINK REL="Prev" HREF="/Risks/7.14.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.16.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 15</H1>
<H2>  Tuesday 5 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"The target is destroyed." (Iranian Airbus) 
</A>
<DD>
<A HREF="#subj1.1">
Hugh Miller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Clarifications on the A320 Design 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Virus aimed at EDS gets NASA instead 
</A>
<DD>
<A HREF="#subj3.1">
Dave Curry
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
     "The target is destroyed."
</A>
</H3>
<address>
Hugh Miller 
&lt;<A HREF="mailto:HUGH%UTORONTO.BITNET@CORNELLC.CCS.CORNELL.EDU">
HUGH%UTORONTO.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
Mon, 04 Jul 88 11:15:52 EDT
</i><PRE>

        There will be a board of inquiry, and congressional committees, and
endless hearings, and in the end "operator mistakes" or "human error" will be
found to have been the cause of the downing of the Iranian passenger airliner.
A system as big and expensive as the Aegis cannot be allowed to fail, as the
scandal about its testing revealed.  The "failures" will be explained away.
        The irony of this situation is, of course, that "human error" gets
blamed for the disasters, to take the heat off the (more-infallible-than-the-
pope) technology/-ists; but, in a skewed and entirely unfunny way the blame is
well-placed.  I imagine that every commander sitting in one of those high-tech
bathtubs in the Gulf took one look at poor Captain Brindel of the Stark -- who
took the fall and the forced retirement and the reduced pension when all along
it was his buggy EW gear at fault, not he or his crew -- and said to himself,
"OK, the writing's on the wall.  If anything hits me and holes the ship &amp;
kills American sailors the pols will throw me to the sharks rather than admit
that some whiz-bang from Rockwell or Unisys or whoever didn't do its zillion
dollar job.  So from now on it's hair-trigger 24 hours a day, and since I
can't be sure my BOZO QZ999 Battlesys can knock down a missile once it's fired
my only recourse is to knock the launchers down before they fire.  They're
bigger &amp; slower &amp; better targets anyway.  Shoot first and ask questions later.
The hell if I'm gonna be the next one to lose his Florida retirement condo to
keep Marconi's rep clean."  I can't find it in my heart to blame the man,
either.  Who wants to be the fall guy for a gigabuck defense contractor and a
desperate, freebooting White House in an election year?  So along comes a
jumbo jet, 25,000 feet, 430 mph, radar cross-section size of a football field.
Software library in the EW battle computers says it's an F-14, kind that
dinged the Stark.  Hell, we ought to know our own aircrafts' profiles, right?
You may fire when ready, Gridley.
        So, in a way, it _was_ a "human" "error".  A human, all-too-human
error.

        (Lest I be accused of imputing less-than-noble motives to valiant,
dedicated career military men from my safe armchair half a world away, I
advance for your consideration a hypothesis similar to the one Henry Spencer
proposed, here or over in ARMS-D, I forget, last year.  Never attribute to
malice what can be accounted for by plain stupidity, he urged; I concur.
Similarly, I would propose that one should not impute noble motives where base
ones will do the trick, human nature being what it is.  Remember, we live in a
society where the most revered moral maxim is "Look out for Number One,"
followed closely by "Cover your ass" and "Nice guys finish last."  Naivete,
especially willful naivete, is not a necessary condition of lucidity in
thinking about techno-political matters.  And, today, all technological
matters are political and vice versa.)

        Which brings me, Mr. Speaker, to my questions.  They are not original,
but since they have never been answered and still seem crucial I will put them
again.

1:      Surely one of the greatest risks at which we are held by technology is
    the result of its completely self-contained, hermetic world-view?  In that
    view, all nature, human and otherwise, is a machine, science the search
    for the control levers, and technology the pulling thereof.  We are guided
    in how we want to pull them by our "values," whatever they are.  (What are
    they, by the way, in the Persian Gulf?  I suppose the usual "national
    interest," whatever that is.)  Just as we don't stop using our PC because
    the disk drive breaks -- Quick! Get the drive repaired! --technological
    thinking will not countenance any stint of its advance.  Greenhouse
    effect?  Engineer hardier crops.  (I heard _that_ one at the Toronto
    atmospheric conference the other day.)  290 dead civilian airline
    passengers, including 66 children?  Patch the software library, piece of
    cake.  Six months from now, when we shoot down a couple of our own
    fighters returning from a sortie because of an unforeseen bug in the
    Flight 655 patch, we patch the patch, no problem.  Nothing fazes the true
    believer, except the suggestion that we deep-six his favorite toy.

2:      Technology creates risks, vigorously.  Since politics and technology
    are today joined in unholy matrimony, technology creates political risks.
    Techno-freaks don't like to think about this, preferring to pretend to be
    "apolitical" so no one will disturb their tidy world, but it is no less
    true or all that.  Since World War II especially the military has been the
    hot spot for the interpenetration of politics and technology.  Only the
    can-do technoptimism of the postwar armed forces can explain such patently
    politically imprudent and hazardous ventures as the Persian Gulf
    filibuster or the "600 Ship Navy"'s aggressive forward basing strategy, to
    say nothing of CBW or, haha, the Strategic Defense Initiative.  The bigger
    and more optimistic the technology, the bigger the risks.  Soviet SSBN's
    off Virginia and Pershing II's in Europe?  An 8-minute LUA decision
    window.  This is not, _pace_ Charles Perrow, a matter of "normal
    accidents" arising out of the increasing complexity of systems.  It is a
    _positive drive_ coeval with technology itself, to which the
    complexification problem is only an adjunct.  As Oppenheimer once told us,
    "If the experiment is sweet, you have to run it." If there's no going
    back, are we prepared for the increasingly wild lurches politics will take
    in the nearer and nearer future?


Hugh Miller, University of Toronto,(416)536-4441 

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Clarifications on the A320 Design
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Sun, 03 Jul 88 19:00:12 -0700
</i><PRE>
From: Nancy Leveson &lt;nancy@commerce.ICS.UCI.EDU&gt;

There has been a great deal of speculation about the design of the A320 
computing system in Risks.  I would like to clear up a few things.  First, the 
A320 is not designed like the F-16 or Boeing 757/767.  The information below
is taken from a paper by J.C. Rouquet and P.J. Traverse entitled "Safe and
Reliable Computing on Board the Airbus and ATR Aircraft," which was
published in the Proceedings of Safecomp '86 (Safety of Computer Control
Systems 1986), edited by W.J. Quirk, published by Pergamon Press, and
copyrighted in 1986 by IFAC (International Federation of Automatic Control).
The authors work for Aerospatiale, the firm responsible for designing most
of the computing systems on board Airbus aircraft.  I quote from some of
the relevant parts; sorry I could not include the figures. Instead of trying 
to correct the English in the paper (which was obviously not edited before
printing), I have left it as is for accuracy; I have tried to proof read this 
typewritten message carefully to make sure that I have not introduced errors.  
I apologize if I have.

... "The A320 is the first civil aircraft designed as fly-by-wire.  It is also
the only aircraft with such an ultra high reliability requirement (failure
rate of 10^-9/H) for a computing system." ... 

"Safety-only requirements can be specified as not computerized back-up exits.
Let us take the roll control of the AIRBUS 300-600 and 310 as an example.
The aircraft is controlled on the roll axis using a pair of ailerons and
5 pairs of spoilers.  The aircraft is controlled either in manual mode, or
in an automatic one.  The automatic flight control system is composed of
two "Flight Control Computer".  Only one of them is active at a time, the
other one being a spare.  If both computers are lost, the aircraft is 
manually controlled.  Therefore, the loss of the automatic flight control
system is not dangerous for the aircraft (except during a short period of
an automatic landing in bad weather conditions)."

"Computers are involved in the manual control mode.  Two "Electrical Flight
Control Unit" are used to control the spoilers.  If both computers are lost,
the pilot can still control the aircraft using the ailerons, with a reduced
authority, as the spoilers are no more available."

"The basic building block is a duplex computer.  Each high safety computer
is composed of two computation channels.  Each channel is monitoring the
other.  If one channel fails, the other one shuts the whole computer down
in a safe way.  This scheme can be impaired by a latent error of the 
monitoring.  Therefore, a self-test program is run each time the computer
is powered up."

"Other precautions are that each channel contains watchdog, that exception 
testing and acceptance testing on the channels output are done, and that
if a computing channel contains two processors, they partially cross-check
themselves."

"Input to the computer are also tested prior to use.  It has to be noted
that safety is not affected, even if a Byzantine general strikes.  Indeed,
if a sensor sends different information to the two computation channels
the consequence is only the shut-down of the computer."

"As a basic precaution, computers are shielded and loosely synchronised.
Most of the transient are coming through power supply.  Therefore, the power
supply is filtered, but also monitored.  A power loss is thus detected, a
few data stored in a protected memory.  If the power loss is sufficiently
short, a "hot start" is possible.  Else, the computer can anyway reset
itself, and restart."

"Equipment on board are divided into two subsets.  These two subsets are often
referred the 2 sides of the aircraft.  Typically, one side is controlled by
the pilot, the other by the copilot."

"The main characteristics are as follow:
  -- only one side is needed to flight [sic] without almost any limitation
  -- an error cannot propagate from one side to the other
  -- a fault cannot be common to both sides
The main task is to verify that the two sides are sufficiently segregated to 
limit error propagation and common point failure."

"High quality software is obtained using a quality plan, as defined in (DO178A).
[I discuss this standard, and my qualms about it and the n-version programming
used to justify the high reliability numbers, in a previous Risks. It was 
reprinted in SEN. NGL]  This document is agreed as a basis for certification.  
Its recommendations are used during the software design phase, and each time 
software must be recertified because of modifications."

"This (and any) rigorous design and testing methodology is not acknowledged as
a fault free software warrant."

"Therefore, each computers uses two different programs, one in each channel.
The dissymetry (diversity) between the two programs is obtained using:
  -- different software design teams,
  -- different languages,
and, depending on the computer, different algorithms, functions, etc.."...

"A major concern is about maintenance faults.  Their effects are limited,
thanks to the power-up self tests, and the computer aided maintenance system.
The pilots are generating input to the computers, and it is recognized that
in most of the accidents, at one time, a pilot takes a wrong option.  This
error may not be an important one, and it has to be noted that in these cases,
the pilot is generally in very bad working conditions.  Anyway, pilot errors
are a major concern.  Two ways to cope with these are:
  -- a computer aided decision (in case of emergency) system (Airbus 300-600,
     310, 320)
  -- a limitation of the authority of the pilot (A320)."

"The first system called Electronic Centralized Aircraft Monitoring displays 
adequate procedures on a screen....  More, on the A320, the pilot cannot drive 
the aircraft outside the flight envelope.  [Wasn't this what the manufacturers 
claimed happened in the recent accident? NGL]  Ziegler and Durandeau (1984) have
discussed further this point. "  [Citation to a paper entitled  "Flight control
system on model civil Aircraft, Proc. of the International council of the 
Aeronautical Sciences (ICAS '84), Toulouse, France, Sept. 1984.]

"The flight control of the A320 is ensured by a computing system, with a
limited mechanical backup.  The design objective is for the computing system
to be sufficiently reliable in order not to use the mechanical back-up.  This
back-up is on board to ease the certification of the aircraft and to help
people to be confident in the aircraft."  

"The safety requirement still exists for the computers.  Therefore, they are
built following the rules defined above (two channels computer, different
programs, high segregation ...)."

"Reliability is gained using five computers.  All of them participate in the
control of the aircraft on the roll axis, four of them on the pitch axis.  At
each time, each surface is controlled by one computer, the other being hot
back-up.  Two types of computers are used.  One is called 'ELAC' (Elevator
and Aileron Computer) is manufactured by THOMSON-CSF, around microprocessors
of the 68000 type.  The other is built by SFENA and AEROSPATIALE with 80186
type processors, and is called 'SEC' (Spoiler and Elevator Computer)."

"Each computer has two different programs.  Therefore, two types of computer
have been designed and four programs.  The repartition of the computers is
shown on Table  1."

                PITCH     ROLL   'SIDE'
    ELAC 1       x         x       1
    ELAC 2       x         x       2
    SEC 1        x         x       1
    SEC 2        x         x       2
    SEC 3        -         x       2
      TABLE 1 - Repartition of the computers

"With this architecture, the aircraft can tolerate:
   -- multiple hardware failures
   -- a complete loss of one 'side' of the aircraft
   -- at least a software error, or a hardware design error, event if it
      shuts down one type of computer
   -- combinations of the above."

"More details about the Electronic Flight Control System of the A320 can be
found in a paper by Ziegler and Durandeau (1984)."  [Cited above]

"When an equipment fails, two problems appear.  First, to find it, and second
to replace it.  On the A320, the localization is done at two levels: each
equipment records failure indication, and at the aircraft level, a computer
collects all the information and correlates them.  It is thus possible to
have at a terminal the list of all the failed computers, through the
'Centralized Fault Display System.'"

"Spare parts are not available in all the airports.  In order not to ground 
an aircraft, it is needed to have spares on board, or for the aircraft to
be able to take off with failed equipment.  The second way is taken and
computing systems are generally designed to reach their the [sic] reliability
requirements, even if one of the computer is down.  For example electrical
flight control system of the A320 is composed of five computers, but, provided
some limitations of the flight envelope, it will be allowed, and safe, to
take-off with only four computers up."

... "The demonstration [of the assigned reliability] is based on ground or 
flight test (to measure the effect of a failure), on probability numbers, and 
on a software design quality plan in accordance with (DO 178A).  No number is 
assigned to a software, even if measures have been done by Troy and Baluteau 
(1985)."  [Reference to a paper in the proceedings of FTCS-15, June 1985,
pp. 438-443].

"The 'Zonal Safety Assessment Document' analyzses the effect of such things
as an engine burst, waste liquids, ..."

"We rely also on ground and flight tests.  For example, the equipment of the
A320 are tested on ground in an 'iron bird' for one year prior to the first
flight.  During the year between the first flight and the certification, both
ground and flight tests will be performed.  The ground tests include power
supply transients, electrical environment hazard."

[There is a section on accrued experience] ... "Our record is satisfactory.
No aircraft crashed, and even came close to this situation.  Design errors
have been found in operation, both in computer specification, and in programs.
We plan to examine all of them, but at first glance, none of them is dangerous.
The use of design diversity is successful, as no error has been found in both
versions of a software." 

NGL:  The argument in Britain about the A320, led by Mike Hennell and 
Bev Littlewood, has focused on the lack of proof of the claims by the 
manufacturers of the Airbus A320 that they have the safest plane flying 
because of the ultra-high reliability of the computer systems.  Despite the 
claim of 10^-9/H, there was an incident where the A320 computers all failed 
in test.  The manufacturers explain this as a "teething problem" that will 
disappear after test.  They also stress that the test pilot was able to safely 
land the plane on the back-up system.  

I have been concerned about claims that the use of n-version programming 
(aka "design diversity") will provide ultra-high reliability.  John Knight
and I have written several papers describing experiments with this technique.  
Tim Shimeall and I have also just completed another experiment that compares 
n-version programming and more traditional reliability techniques.  I will 
send anyone copies of these papers upon request.   

Let me add to the voices suggesting that we wait for the final data before 
judging the latest accident.  In almost all accidents, the manufacturers of
the equipment involved immediately claim that it was a result of operator error
(for very good reasons which are usually of a liability and monetary nature).
It did not seem like the pieces had all stopped smoking before the cause of
the A320 accident was announced.  Unfortunately, with the immense amount of
money involved, it is not clear that the truth will ever be known.  If it truly
is a technical problem, it may require multiple accidents and deaths before 
this is admitted.  This, by the way, is what happened with the Therac 25.
It now appears that some early accidents involving the Therac 25 were the
result of software error even though hardware was blamed in the official 
accident reports.  After several such accidents, it was no longer possible to 
continue to blame the operators and the mechanical systems, and the software 
errors responsible were finally found.  The Three Mile Island accident is often 
attributed to operator error although four separate hardware failures occurred 
before the operators even got into the act.  Most accidents are not attributable
to a single cause -- they are a result of the interaction of several factors.  
It is always possible to blame the operator for not taking the correct steps to
"save the day" after the accident scenario has already been started; accidents 
in complex systems are usually not a matter of operator error alone.  At the 
least, why was the system involved designed to be unsafe on a single point 
failure like an operator error? If it is, then the limiting reliability is 
that of operator error, which is usually counted as 10^-5 in risk assessments.  
Note that according to the paper cited above, the A320 contains a computer-aided
decision system and a limitation of the authority of the pilot.  The pilot also 
cannot drive the aircraft outside the flight envelope.  If this is true, it 
seems odd to blame the recent accident solely on the pilot driving the aircraft
outside the flight envelope, as reported by the press.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Virus aimed at EDS gets NASA instead
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>
Mon, 04 Jul 88 11:18:37 EST
</i><PRE>

Taken from The Lafayette Journal &amp; Courier, 7/4/88, Page A2.

Destructive computer program sabotages government data

  NEW YORK (AP) - A computer program designed to sabotage a Texas computer
company destroyed information stored on personal computers at NASA and other
government agencies, according to _The_New_York_Times_.
  It was not known whether the program had been deliberately introduced at
the agencies or brought in accidentally, but NASA officials have asked the
FBI to enter the case.
  Damage to government data was limited, but files were destroyed, projects
delayed and hundreds of hours spent tracking the electronic culprit.
  The rogue program destroyed files over a five-month period beginning in
January at the National Aeronautics and Space Administration, the
Environmental Protection Agency, the National Oceanic and Atmospheric
Administration and the U.S. Sentencing Commission, the _Times_ reported.
  The program, or virus, infected close to 100 computers at NASA facilities
in Washington, Maryland and Florida.
  The virus was designed to sabotage computer programs at Electronic Data
Systems, a private company in Dallas, Bill Wright, a company spokesman,
said.  The program did little damage, he said.

--Dave Curry
Purdue University

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.14.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.16.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-57</DOCNO>
<DOCOLDNO>IA012-000129-B047-265</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.16.html 128.240.150.127 19970217022028 text/html 29245
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:18:57 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 16</TITLE>
<LINK REL="Prev" HREF="/Risks/7.15.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.17.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 16</H1>
<H2>  Wednesday 6 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Air France Airbus A320 Crash Story In Aviation Week 
</A>
<DD>
<A HREF="#subj1.1">
Karl Lehenbauer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Common failure path in A320 
</A>
<DD>
<A HREF="#subj2.1">
Lee Naish
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Reply to Hugh Miller about Iran Flight 655 
</A>
<DD>
<A HREF="#subj3.1">
Michael Mauldin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The Iranian airliner tragedy 
</A>
<DD>
<A HREF="#subj4.1">
Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Aegis and the Iran Airbus 
</A>
<DD>
<A HREF="#subj5.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  The "F-14" attacking the Vincennes... But the F-14 is for air defense       
</A>
<DD>
<A HREF="#subj6.1">
Jonathan Crone
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  It's easy to make decisions if you don't have the facts 
</A>
<DD>
<A HREF="#subj7.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: A300 using F14 transponder 
</A>
<DD>
<A HREF="#subj8.1">
Bruce O'Neel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Iran Flight 655 and the Vincennes 
</A>
<DD>
<A HREF="#subj9.1">
James P. Anderson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Lockpicking 
</A>
<DD>
<A HREF="#subj10.1">
Randy D. Miller
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Re: The Eyes Have It 
</A>
<DD>
<A HREF="#subj11.1">
Tracey Baker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  RISK of PIN's - PNB calling card 
</A>
<DD>
<A HREF="#subj12.1">
Scott Peterson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Air France Airbus A320 Crash Story In Aviation Week
</A>
</H3>
<address>
Karl Lehenbauer
&lt;<A HREF="mailto:sugar!karl@uunet.UU.NET  ">
sugar!karl@uunet.UU.NET  
</A>&gt;
</address>
<i>
6 Jul 88 01:19:18 GMT
</i><PRE>

(quoted without permission from the July 4, 1988 issue of Aviation Week)

"The investigation into the June 26 crash of an Air France Airbus Industrie
A320 is focusing on the pilots' judgment in performing a slow-speed air show
flyby with a fully loaded transport that they allowed to descend well below
their filed minimum altitude."

[background information on the crash deleted for brevity]

"Video images of the accident showed that the A320 was stabilized in a nose-
high attitude throughout the flyby, and that the mid/aft section of the
aircraft struck the outermost row of trees at the perimeter of the airport.
The aircraft then settled into the wooded area and burned.

The pilots said they thought the aircraft was at an altitude of 100 ft. based
on the flight instruments, and stated that the A320's two CFM International
CFM56 turbofan engines did not respond correctly when they moved the throttles
forward for full power."

[The article goes on to quote the French Transport Minister Louis Mermaz
and later the Director of the Direction Generale de l'Aviation Civile (DGAC)
as saying that the aircraft's 30-ft. flyby altitude and its reduced airspeed
"were confirmed by both the cockpit voice recorder and the cockpit data
recorder."]

"'When the pilot advanced the throttles, the thrust was increase was normal,
but it [the power increase] apparently was made too late,' Tenenbaum said.
'This is important because the pilot reported after the accident that the
engines did not respond.  ... According to the data, the thrust increase
to the full available power should have occured within 8 sec., and we
saw it in approximately 5 sec.,', he said."

[The article then describes the renewal of a long debate in France over
the minimum crew requirements for the A320.]

"'Based on the cockpit conversations we heard [on the cockpit voice recorder],
the crew was perfectly aware of what was going on,' Tenenbaum said.  'They
were perfectly lucid, they knew what altitued they were at because there
were [computer-generated] voice callouts from the radar altimiter during
the low pass, including an audible callout of 30 ft.'"

[The article proceeds to describe the orientation of the aircraft during
its low pass and as it struck the trees (nose-high level flight), the 
history of Air France's operations of the aircraft, that Air France has 
decided to suspend all further demonstration flights and that British
Airways and Air France substituted other aircraft for their scheduled
A320 flights for two days after the accident.]

"Officials at British Airways said the airline had experienced no significant
mechanical or electronic problems with the aircraft since they entered
service earlier this year.

Several European test and company pilots questioned the crew's reasoning
in attempting to perform an air show-type low, slow flyby without apparent
advanced training and with a passenger payload."

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Common failure path in 320
</A>
</H3>
<address>
Lee Naish
&lt;<A HREF="mailto:munnari!mulga.oz.au!lee@uunet.UU.NET ">
munnari!mulga.oz.au!lee@uunet.UU.NET 
</A>&gt;
</address>
<i>
Wed, 6 Jul 88 19:00:14 EST
</i><PRE>

Though the A320 Airbus has redundant computer systems, they all use the
same air conditioning system.  Does anyone know what the expected
failure rate of that system is, or how critical a failure would be?

	Lee Naish

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Reply to Hugh Miller about Iran Flight 655
</A>
</H3>
<address>
&lt;<A HREF="mailto:Michael.Mauldin@NL.CS.CMU.EDU">
Michael.Mauldin@NL.CS.CMU.EDU
</A>&gt;
</address>
<i>
Tue, 5 Jul 1988 22:38-EDT
</i><PRE>

I can't match Mr Miller's polemic, but I can point out that he got just
about every fact wrong about flight 655.  All of the information below
is from the Pittsburgh Post Gazette, Monday July 4.  Their text comes
from an article by Stephen Engelberg of the New York Times News Service.

&gt;           So from now on it's hair-trigger 24 hours a day, and since I can't
&gt; be sure my BOZO QZ999 Battlesys can knock down a missile once it's fired
&gt; my only recourse is to knock the launchers down before they fire.  They're
&gt; bigger &amp; slower &amp; better targets anyway.

	Do you have a problem with that?  You criticize "the system" for
	overreliance on technology and then fault the captain for his
	caution?

&gt; Shoot first and ask questions later.

	3 warnings were radioed on civilian distress frequencies
	4 warnings were radioed on military frequencies
	A nearby Italian vessel reported hearing at least 4 of these warnings

	All of the discussion I've heard said that he should have fired
	2 minutes earlier, and would have been justified in doing so,
	given the information available.  Captain Rogers was very
	forgiving to have waited as long as he did.

&gt; The hell if I'm gonna be the next one to lose his Florida retirement condo to
&gt; keep Marconi's rep clean."  I can't find it in my heart to blame the man,
&gt; either.  Who wants to be the fall guy for a gigabuck defense contractor and a
&gt; desperate, freebooting White House in an election year? 

	How about a more likely line of reasoning:
	
	"Gee whiz, just after we sank two of those gunboats this plane
	takes off from a nearby civilian/military air base and is
	closing directly on my ship.  It has no transponder and won't
	answer my radio challenge.  Maybe I should shoot it down to save
	my ship and the men in my command."

&gt; So along comes a jumbo jet, 25,000 feet, 430 mph

	An A300 is much smaller than a jumbo jet.
	It was flying at 9,000 feet and descending.  It was shot down
	  at an altitude of 7,500 according to Iranian press releases.
	It was traveling 450 knots (518 mph) and gaining speed.

&gt; radar cross-section size of a football field.

	The wingspan of an A300 is 147 feet, less than half the size of a
	football field.  That's a little more than twice the 64 foot wingspan
	of an F-14.  In any event the bottom line is that you can't reliably
	identify planes from a head-on cross section.  No one has ever said
	they could.

&gt; Software library in the EW battle computers says it's an F-14, kind that
&gt; dinged the Stark.

	The plane was tentatively identified as an F-14 not from radar
	but from five other facts:
	
	1. There were reports of 10 F-14's operating out of Bandar Abbas.
	2. The flight took off from Bandar Abbas immediately after the
	   Vincennes fired on the three gunboats.
	3. It had no transponder (a requirement for all civil aviation).
	4. It was 4 miles outside of the commercial air corridor and
	   14,000 feet lower than a commercial plane should have been.
	5. The plane was broadcasting on a military "mode 2" (I'm not
	   sure whether that's a radar or a radio).  These were the
	   "electronic indications" the Admiral Crowe spoke of in his
	   press conference. (This comes from CNN news Tuesday, July 5).

	Also, Flight 655 took off about an hour after it's scheduled
	departure time; the captain had requested information about
	scheduled commercial flights, but this search was not completed
	before the decision to fire was made.  Even if they'd had the
	time, all they would have found was that it was the wrong time
	to be a commercial flight. (Also from CNN News).

   It may well be true that the Iranian pilot thought our technology
was so good that we could identify him properly despite the fact that he
was in the wrong place at the wrong altitude at the wrong time ignoring
(or unable to hear) frequencies he was required to monitor.  To that
extent there may well have been an over-reliance on our technology.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
the Iranian airliner tragedy
</A>
</H3>
<address>
"FIDLER::ESTELL" 
&lt;<A HREF="mailto:estell%fidler.decnet@nwc.arpa">
estell%fidler.decnet@nwc.arpa
</A>&gt;
</address>
<i>
6 Jul 88 08:21:00 PDT
</i><PRE>

The "target is destroyed" note in RISKS 7.15 of 5 Jul 88 was not pleasing to
MY tastes; whether it was in good taste or not is a question that I won't
raise; tastes are far too personal for rational debate.  I know our
moderator personally, and I trust his judgment.

But I also know CAPT Will Chapel Rogers III; we had two years together 
at Baylor a long time ago.  The traits that made Will a friend and
a good student are ones that the Navy seeks in recruits, and develops
in officers; I cannot believe that the goodness has been trained out him.

I also know a thing or two about Aegis radar systems, F-14's, C3 systems
used in Navy combatants.  I know for instance that the "radar signature" of
a "loaded fighter-bomber" [or other medium aircraft, carrying missiles] can
look as large as a jet liner, for much the same reasons that a sequined
bikini will reflect as much footlight as a white satin gown.  And I learned
Tues 5 Jul p.m. that the Iranian airliner was identifying itself as an F-14.
The Vincennes fired for much the same reasons that the police in many cities
fire at apparently armed assailants almost every day: self defense.  When it
sometimes happens that afterwards the attacker turns out to be relatively
innocent [e.g., kid with a water gun], that's a "tragedy."

One of the RISKS of using computers is that we sit in our cubicles and deal
with machines - that feel no pain, leave no widows nor orphans; we come to
think of human loss as statistics, which we compute so easily.  The loss of
one life is tragic; 290 at a stroke only serves to awaken our dulled senses!

Tragedy is one thing; justification is another.  I happen to believe in self-
defense, an adequate army [and navy], and capital punishment.  But I repeat,
the loss of human life is tragic.  Let's not rush to judgment just because the
statistics get our attention.  Instead, let us resolve [in Lincoln's words]
that these 290 will not have died in vain: Let us rethink both our
[computerized] weapons systems designs, AND their use.

Bob
p.s. The opinions herein, as always, are personal; NO conclusions
  can be drawn about my employer's concurrence or lack thereof.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
It's easy to make decisions if you don't have the facts
</A>
</H3>
<address>
Martin Minow THUNDR::MINOW ML3-5/U26 223-9922
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
6 Jul 88 13:34
</i><PRE>

Idle speculation:  sometimes it's more interesting to listen to what wasn't
said.  In the recent attack on the Iranian airliner, why do I get the feeling
that nobody on the Vincennes was monitoring tower-plane radio communications.
(And the vague suspicion that there wasn't anyone on the ship fluent in Farsi.)

Martin Minow  

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
     Re: A300 using F14 transponder
</A>
</H3>
<address>
Bruce O'Neel 
&lt;<A HREF="mailto:XRBEO%VPFVM.BITNET@CUNYVM.CUNY.EDU">
XRBEO%VPFVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Wed, 06 Jul 88 08:09:10 EDT
</i><PRE>

                              [Referring to the Mode 2 / Mode 3 
                              confusion, and belief in the transponder:]
Seems it might be a good idea in a war to equip all the fighters with
transponders saying that they are say 767s?

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Aegis and the Iran Airbus
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Wed, 6 Jul 88 10:40:16 PDT
</i><PRE>

An article in this morning's San Francisco Chronicle (p. A-12) is titled

   "Electronic Errors 
    -----------------
    Star Wars Planners' Lesson in the Gulf", by David Perlman

[...] The cruiser's Aegis system linking its radar with a battery of advanced
comptuers and missile launchers, had been hailed as "Star Wars at Sea" by the
Navy.  But David L. Parnas [...] held a different view.  "It is obvious," he
said in an interview, "that if you can't discriminate at close range between
an Airbus and an F-14 fighter, it would surely be even more difficult if not
impossible to discriminate between a Soviet warhead and a decoy baloon flying
on the same ballistic trajectory in outer space." ... "The Aegis system was
always presented to me in briefings as a defensive system only against
high-speed, low-flying missiles," Parnas said.  "But, while I have no reason
to believe that it was the Aegis computer system that failed on Sunday, the
fact is that discriminating targets is vital for any defense."

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
The "F-14" attacking the Vincennes... But the F-14 is for air defense
</A>
</H3>
<address>
Jonathan Crone 
&lt;<A HREF="mailto:CRONEJP%UREGINA1.BITNET@CORNELLC.CCS.CORNELL.EDU">
CRONEJP%UREGINA1.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
Wed, 06 Jul 88 10:30:47 CST
</i><PRE>

I basically have a comment to make about the supposed response about
the Vincennes defending itself against an attack from an inbound F-14.

Were the F-14's that were sold to Iran during the 1970's stock F-14's
or were they supplied with upgraded avionics and attack systems.

The reason I'm questioning this, is because Grumman designed the F-14 to
support the Navy's requirement for a powerful Air Defense Fighter.

This explains the F-14's exceptional ""capabilities"" in this area...  (such
as the supposed ability to maintain lock on 24 inbound targets and to attack 6
of those targets using a mix of Phoenix Sparrow/AMRAAM, and Sidewinder
missiles.)

However, and I recall this from reading material published during the late
seventies when Canada was looking to purchase a new all purpose fighter for
the Canadian Airforce, the F-14 has very limited Air to Ground capabilities...
its radar and attack systems aren't really designed to do it. (thats why
Canada purchased F-18s instead, because it had multipurpose radars to deal
with both modes of combat.)  (The Canadian Air Force required a single type of
aircraft that would be capable of dealing both with the close ground support
environment of NATO commitments, as well as the long ranging Air Defence
requirements over North America)

Presumably the crew of the Vincennes would know about this wouldn't they???
(from news reports, Iran, is still using F-14's as Air to Air units, and
not as ground attack birds.)

If I were the Commander of the Vincennes, I would be worried if the Aegis was
saying that the inbound aircraft was a Mirage or a Super Etenard (a Mirage is
the aircraft that launched the two Exocet missiles that holed the Stark).

So perhaps the big question is, why are they saying that they
were worried about the possibility of an attack from an F-14?

Jonathan P. Crone

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
 Iran Flight 655 and the Vincennes
</A>
</H3>
<address>
&lt;<A HREF="mailto: JPAnderson@DOCKMASTER.ARPA">
 JPAnderson@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 5 Jul 88 23:03 EDT
</i><PRE>

The Captain of the Vincennes did the correct thing. If he can be faulted for
anything, it is that he waited so long before acting.  All the breast-beating
in world and appeals to castigate the military notwithstanding, the correct
action was taken.  If a human failure took place, it was in the Iranian
decision to fly a commercial aircraft over an area where a fire-fight was in
progress, and in not responding to the reported 7 (repeat seven) attempts to
raise the aircraft and have it identify itself.  The loss of life was indeed
tragic. The attempt to picture the U.S.  Navy or U.S. policy as irresponsible
is even more tragic.

Mr. Miller seems genuinely confused over what is 'national interest'.  I would
submit 'national interest' is Canada selling its wheat to anyone it chooses
regardless of what other nations; ostensible allies and maybe even friends,
think. It is also an assertion that a tin-horn dictator, operating under the
guise of religious leader cannot prevent free ship movement in the Gulf area.
It is possibly also a belief that the rest of the world, maybe even Canada
might suffer if oil does not move freely from the Middle East. [I guess the
view of 'national interest' is crystal clear from the lofty towers of academe.]

Let's get the forum back to technical risks and off of the political beat.  Jim

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Lockpicking
</A>
</H3>
<address>
Randy D. Miller
&lt;<A HREF="mailto:sun!sunburn!gtx!randy@ucbvax.Berkeley.EDU ">
sun!sunburn!gtx!randy@ucbvax.Berkeley.EDU 
</A>&gt;
</address>
<i>
Tue, 5 Jul 88 09:44:06 MST
</i><PRE>
Organization: GTX Corporation, Phoenix, Arizona

     I never imagined that picking locks could be so easy.  A couple months
ago, I went to the Phoenix Public Library (!) and checked out a few books on
locksmithing.  Surprise!  The books all had chapters on how to pick locks for
fun and profit.  One book explained how to make homemade lockpicks by
grinding down hacksaw blades.  Using $0.99 hacksaw blades and a Dremel Tool
grinder, I made an assortment of lockpicks.  K-Mart supplied me with an
assortment of locks to practice on and disassemble.

     After a few days of practice, I found that I could pick open any disk
tumbler lock that I could find - these are the cheap locks found on desk
drawers, cabinet locks, window locks, and a few cheap padlocks and old door
locks.  Most disk tumber locks take me less than 10 seconds to get open.
I've also picked open every pin tumber lock that I've tried, but they're
harder; most of them take about two minutes to get open.  These are the locks
found on most doorlocks.  The most difficult lock I've tried is the expensive
Master brand pin-tumbler padlock, which required about twenty minutes of
delicate work to pick open.  (I disassembled it to see why it was so hard.
Master uses smaller pins than usual, made to very tight tolerances, without
the bevelled ends found on most pins.)  There are such things as pick
resistant locks, but they are pretty rare.  It seems that 99 per cent of the
locks in my life are pickable disk tumbler or pin tumbler locks.  (I haven't
yet begun practicing on automobile locks;  from the diagrams in the books,
they seem to have extra features that may make them harder to pick.)

     I called some city and state offices, and one local locksmith, to see
if there are any laws regulating the possession and use of lockpicks in
Arizona.  No one I talked to seemed to know anything about any regulations!

     If it's so easy to pick open locks, why do burglars resort to harder and
messier ways of entering buildings, desks, cabinets, etc.?  Are most burglars
incapable of learning such a skill, or does it just not occur to them?
Should I spend a fortune replacing the locks on my house, or are the risks
low that a burglar will pick the locks?

Randy D. Miller             (602) 870-1696
GTX Corp., 8836 N. 23rd Ave., Phoenix, AZ 85021
{cbosgd,decvax,hplabs,amdahl,nsc}!sun!sunburn!gtx!randy

     [One of the imperative themes in the RISKS Forum is that protection
     measures are inherently compromisable.  The myth of technology as a
     panacea continues to haunt us.  Most car-door locks are TRIVIAL to 
     break.  Skeleton keys for house locks are simple to fabricate.  Cyclic
     redundancy checks and crypto seals are simple to break if the underlying
     system is not adequately secure.  Thus using a complicated mechanism
     on top of a flawed mechanism invites compromise.  The more sophisticated
     the lock mechanism, the more challenges for the sophisticated attacker.
     But the belief in technology as a magic wand is perhaps the most
     dangerous of all -- whether it is locks or automated defense systems. PGN]

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Re: The Eyes Have It (RISKS DIGEST 7.14)
</A>
</H3>
<address>
&lt;<A HREF="mailto:tab@mhuxu.att.com">
tab@mhuxu.att.com
</A>&gt;
</address>
<i>
Tue, 5 Jul 88 17:32 EDT
</i><PRE>
Organization: AT&amp;T Bell Laboratories, Murray Hill 

  I had to laugh at "The Eyes Have It".  The last five digits of my NJ
driver's license number are 61664.  This is supposed to represent my
date of birth and eye color.  I was born on 11-22-66, and the last time
I checked my calendar, we didn't even have 61 months!

  This made me think about PGN's comment about three extra "eye color"
values not being enough to prevent data collisions.  Since it is
obviously possible to have the first "DOB" digit not match the actual
DOB, why not use 2-9 in that field?  That, combined with the extra eye
color values, would leave room for almost eight times as many "identical"
people ("almost" because Jan-Nov and Feb-Dec birth dates would have to
share the extra numbers).  They could still retain the DOB information
if 2-5 in the first digit = 0 and 6-9 = 1.

  It also makes me wonder about the NJ DMV.  I know they've had many
problems with their computer system (and their offices, and their
personnel, and ... :-), but this is ridiculous - not only do the two DOB
fields not match (they did get it right in the DOB space on the license),
but one of them isn't even a valid date!

(If the NJ DMV already uses different DOB #'s for data collisions, I apologize
 for this entire article.  I've *never* heard of anyone else with something
 other than the DOB in those 4 digits.  In fact, everything I have heard
 makes my nuber look like a unique case.  If there were a reliable way to
 get information from the DMV I'd ask them, but they can't even tell me
 what forms I need to register my car, so I'm afraid there's not much hope
 of getting a correct answer to a question like this.)

Tracey Baker  {att, rutgers!moss}!mhuxu!tab or tab@mhuxu.att.com  (201)582-5357
Rm. 2F-211,  AT&amp;T Bell Laboratories, 600 Mountain Ave., Murray Hill NJ 07974

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
RISK of PIN's - PNB calling card
</A>
</H3>
<address>
&lt;<A HREF="mailto:littlei!foobar!sdp!sdp@uunet.UU.NET">
littlei!foobar!sdp!sdp@uunet.UU.NET
</A>&gt;
</address>
<i>
Tue Jul  5 20:46:53 1988
</i><PRE>

After noting charges on my last phone bill for calls made from places I've
never been, I called Pacific Northwest Bell (PNB) and changed the PIN on my
calling card.  (I decided to pay the $3 in long distance charges since I had
given my PIN to an old girlfriend about a year ago.)

I was mildly surprised to find that the procedure for changing my PIN was to
tell the PNB representative on the phone what I wanted my new PIN to be.  I
already (have to) trust the phone company, so this risk was acceptable to
me.

I was REALLY surprised by what I found out when I received a new calling
card in the mail today.  (Probably sent automatically because I changed my
PIN.) Here are some of the "features" of my new calling card as explained in
the letter sent along with it:


                  "Exclusive extra security

     When you look at your Card, you'll notice that your four-digit security
     number is not shown.  That means _extra security for you_, because only
     you know the Security Code.


                  Maximum convenience

     Turn your card over.  The magnetic stripe on the back lets you use many
     of the new Card Reader phones.  _You don't need to enter your card
     number or your security code_.  Just slide your Card through the
     special slot and dial!  ...  "


Identifying the problem with this is left as an exercise for the reader.

I think I'll just hit my card with a bulk tape eraser, and forget about
using card reader phones until PNB straightens this out.


Scott Peterson, OMSO Software Engineering, Intel,  Hillsboro OR
sdp@sdp.hf.intel.com     uunet!littlei!foobar!sdp!sdp

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.15.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.17.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-58</DOCNO>
<DOCOLDNO>IA012-000129-B047-291</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.17.html 128.240.150.127 19970217022041 text/html 26942
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:19:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 17</TITLE>
<LINK REL="Prev" HREF="/Risks/7.16.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.18.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 17</H1>
<H2>  Friday 8 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Politics and Risk 
</A>
<DD>
<A HREF="#subj1.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Iranian Airbus ([mis]quotation from the SFO Chronicle) 
</A>
<DD>
<A HREF="#subj2.1">
David Parnas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Iranian Airbus and the "facts" 
</A>
<DD>
<A HREF="#subj3.1">
Sue McPherson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Threshold probability for declaring a radar blip "hostile" 
</A>
<DD>
<A HREF="#subj4.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Iran Airline Incident and meaningful real-time data 
</A>
<DD>
<A HREF="#subj5.1">
Chris McDonald
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  A320 Airbus: Air conditioning; monitoring traffic control; F-14s    
</A>
<DD>
<A HREF="#subj6.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Iranian Airbus Blame? 
</A>
<DD>
<A HREF="#subj7.1">
Chaz Heritage
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: "The target is destroyed." 
</A>
<DD>
<A HREF="#subj8.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  An epilogue to this issue 
</A>
<DD>
<A HREF="#subj9.1">
PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Politics and Risk
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.stanford.edu ">
chapman@csli.stanford.edu 
</A>&gt;
</address>
<i>
Thu, 7 Jul 88 16:27:06 PDT
</i><PRE>

I would like to respond to the contributors who suggested that we "leave
politics out of" this forum, and stick to "technical" subjects.  These comments
were in response to a contribution from someone from the University of Toronto,
who was highly critical of the use of computer-based electronic systems like
the one that was involved in the Iranian airliner tragedy. I for one found his
first RISKS posting on that subject very cogent and appropriate. 

If this forum is to address the risks of technical systems, it seems highly
artificial and misleading to eliminate consideration of the political
environment the potentially risky system may be in.  RISKS readers should
certainly be spared pure political harangues or ideological tirades, but there
is no reason why we cannot consider a technical system's political environment
part of the mix of ingredients that may make it risky.  Indeed, for some
systems it is almost exclusively the combination of the technical character of
the system and the political environment within which it is meant to work that
constitutes the risk.  The Strategic Defense Initiative would pose considerably
less risk, perhaps even close to zero, if it did not have to cope with hostile
nuclear warheads (and of course the entire raison d'etre of this system is
bound up with politics).  The technical reliability of Navy shipboard radars
and other sensors is of paramount importance precisely because they are
operating in a combat zone.  If the system's reliability, or unreliability, has
large and grave implications for the political environment in which it is
working, it should be within the purview of engineers and technologists to
question the wisdom and prudence of introducing the system into such a
political context.  This is simply analogous to a matchmaker suggesting that
his product not be used around gasoline or dynamite without due caution.

Extrapolating from that, it is certainly part of a comprehensive assessment of
risk to ask questions about why we want whole classes of technical systems,
such as increasingly automated weapons, weapons that destroy things faster or
more thoroughly, etc., when these technical capabilities entail not only risk
in the conventional sense of malfunction, but "social risk" in helping to usher
in a nightmarish world that our children will probably regret.  It is
legitimate consideration of this "social risk" that many engineers and
technologists avoid like the plague--it is labelled "emotional," "irrational,"
"not technical," etc.  It is astonishing that this is so widespread among
technical professionals when the "social risk" of so many technologies is so
readily apparent in our age, and appears to be getting generally worse instead
of better.

During the war in Vietnam, the United States Air Force had virtually
unchallenged air superiority, and we dropped three times more bomb tonnage on
Southeast Asia than was used by all the powers in all the theaters of World War
II.  This almost unimaginable destruction didn't do much of anything in terms
of winning the war or even furthering short-term American military objectives.
The North Vietnamese still won the war, despite devastation the contemplation
of which would make many people permanently catatonic (for a description of
this madness, read James William Gibson, *The Perfect War:  TechnoWar in
Vietnam*, Atlantic Monthly Press, 1986, Part III, "Death From Above").  The
Pentagon Papers revealed that the Air Force knew the saturation bombing was
having no effect on the level of resistance of the enemy.  The Air Force knew
this, and yet recommended *escalation* of the bombing throughout the remainder
of the war.

Was this a technical problem of not hitting the right targets, or not working
out the right pattern of bombing sorties?  Was this the "correct" decision by
Air Force commanders who were given a job to do with a certain tool?  As the
saying goes, "if the only tool you have is a hammer, all problems begin to look
like nails."  If we give Air Force commanders lots of big B-52s and lots and
lots of 500 and 1,000 pound bombs, should we blame them for attempting to turn
most of Southeast Asia into a parking lot?

Or was this a "social risk" of the technology, an atrocity in which all people
are implicated, technologists and "end users" alike?  Can the technology itself
have a role in creating the political context in which the technology itself
rockets risk over any scale we had previously imagined?  This is what happened
with nuclear weapons, and now it's happening with a whole spectrum of
technologies that are becoming increasingly refined and increasingly deadly.

It's pointless and even distasteful to address these issues in purely technical
terms.  To address risk in that fashion is to limit oneself to "tweaking"
systems that may be fundamentally wrongheaded to begin with, technological
systems that, at their core, are bad--not just risky--for humanity.  Some may
think that this adds up to an "emotional" appeal, but there's nothing
inherently wrong with that.  It takes people with emotion, and not just a
facility for algorithms, to recognize risk and to do something effective about
it.

Gary Chapman, Executive Director
Computer Professionals for Social Responsibility      chapman@csli.stanford.edu

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Iranian Airbus ([mis]quotation from the SFO Chronicle)
</A>
</H3>
<address>
&lt;<A HREF="mailto:parnas%QUCIS.BITNET@CORNELLC.CCS.CORNELL.EDU">
parnas%QUCIS.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
Thu, 7 Jul 88 12:42:50 EDT
</i><PRE>

One of the pleasures of not reading all the major U.S. papers is that I don't
usually see articles that misquote me.  The text by David Perlman that you cite
is quite inaccurate.  The first statement is a paraphrase of my words, not my
words but my thoughts.  I said that it was ludicrous to see people who are
unable to tell a U.S.  made F-14 from a French made Airbus, claiming that they
will be able to write trustworthy software that will discriminate between
Soviet warheads and Soviet decoys designed to look like warheads.  The final
quote in the article is not even an accurate paraphrase.  I said that a system
designed primarily as a defense against low flying high speed missiles should
not be expected to discriminate between different kinds of aircraft.  If the
crew used a system in that way, i.e.  if they assumed that the warning "threat"
meant that the system "knew" it was tracking a military aircraft, then the
crew made an error.  I also told that reporter that we had far too little
information to make any judgement on the failure of such systems.  We do not
know which data were used by the crew in making their decision.  The Aegis
missile defense software might not even have been involved.

Dave

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Iranian Airbus (<A HREF="/Risks/7.16.html">RISKS-7.16</A>) and the "facts"
</A>
</H3>
<address>
Sue McPherson
&lt;<A HREF="mailto:munnari!murdu.oz.au!sue@uunet.UU.NET ">
munnari!murdu.oz.au!sue@uunet.UU.NET 
</A>&gt;
</address>
<i>
Fri, 8 Jul 88 15:14:23 EST
</i><PRE>
Organization: Software Contracts Group, University of Melbourne, Australia

Over the last few days we've had a lot of emotional discussion about the
shooting down of the Iranian Passenger Plane. All in all it has been about as
informative as the discussions last year on KAL007 - that is - not very.

On the one had we have Hugh Miller who believes that the papers have told him 
that technology has fouled up again. On the other we have Michael Mauldin 
who thinks that the Captain made an understandable mistake and it was the 
Iranian's fault. Then there is Bob Estell who thinks his old buddy is one of 
the good guys so it must be the Iranians fault. But I can't help thinking that 
the Navy doesn't have such a good reputation these days for employing honest
and reliable people. Finally we have Jim Anderson who thinks we should 
nuke the lot of them - er sorry, I mean shoot anyone within range.

Each of these people seems to be quite sure that they have the "facts" yet
they seem to be quite contradictory. Just how trustworthy is the "Pittsburg
Post" ? (who got it from the "New York Times" who got it from .....) It seems
that we are very reliant on the media (newspapers &amp; TV) yet we have no way of
authenticating the information presented or even penalising them when they
make a mistake. Interpretation of the "facts" is another risky area, a good
example is the reported "fact" that the 707 has a cruising speed of 325 knots,
while this may be the truth it is not the "whole truth" as there are other
factors (such as wind speed) which could enable to the plane to travel at a
much greater ground speed (i.e., the speed that would be observed by the US
ship).

Both the "shootdown" and the ensuing discussions both prove the point that 
the biggest RISK we take, is in believing what we are told - whether the
information comes from the latest/biggest/most expensive radar system or the
"Pittsburg Post" there are no 100% guarantees that it is correct or even
complete.

Sue McPherson                    sue@murdu.mu.oz

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Threshold probability for declaring a radar blip "hostile"
</A>
</H3>
<address>
Clifford Johnson 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Thu,  7 Jul 88 00:54:41 PDT
</i><PRE>

I have a couple of observations re the Iran shootdown, and the
big question, did Captain Will Rogers have sufficient cause to
order it, as JCS Chairman Crowe loyally contends?

My first observation is that this claim seems premature, since no-one knows
what information Will Rogers based his so-called decision (or should it be
called computer-prompted reflex?) upon, as yet.  Suffice it to say that if, as
is reported, he did not bother to monitor to the air field control tower; and
if, as is reported, Mode C (civilian) transponder returns were received by the
ship; and if, as reported, the plane was flying at the speed of a commercial
flight; and if, as reported, an F-14 is in any case no real threat to his
ship; then on its face he was taking an unnecessary 50-50-ish gamble (not
unreasonably characterized as a "panic") as to whether the radar blip was
really hostile or innocent.  Also, was it not negligent to not monitor the
control tower, as is reportedly standard practice for non-U.S. ships in the
Gulf?

But the question I really want to raise is, at what perceived "odds" -- 50-50,
60-40, 90-10 ? -- does a commander have "sufficient cause" to "declare" a
radar blip, that might be hostile or might be a commercial flight, officially
"hostile," so as to shoot it down?  Judging by Admiral Crowe's immediate
approbation, it seems he thinks that almost *any possibility* that a flight
might be hostile is sufficient to order a shootdown, by virtue of the
commander's "heavy obligation" to protect his "personnel and equipment."
Judging by Will Rogers' simple explanation that he thought it was a hostile
F-14, vague odds above 50-50 seem to be enough.

I would have thought that moral considerations would lead the military to
value civilian lives above their own (isn't that what they are supposed to be
guardians of?), and so the chances would have to be way *over* 50-50 to be
sufficient to order a shootdown?  Does anyone on the net think that odds of
51-49 or less are sufficient?  A natural follow-on question is this:  given
the shortness of the response time, what could be the best odds attainable in
a realistic attack scenario, even assuming the best computer technology the
United States could field?  Perhaps the degree of certainty simply cannot be
high enough to justify a shootdown in any circumstances?

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Iran Airline Incident and meaningful real-time data
</A>
</H3>
<address>
Chris McDonald  STEWS-SD 678-2814 
&lt;<A HREF="mailto:cmcdonal@wsmr10.ARPA">
cmcdonal@wsmr10.ARPA
</A>&gt;
</address>
<i>
Thu, 7 Jul 88  8:01:15 MDT
</i><PRE>

It seems to me that Martin Minow's comments on the danger of drawing
conclusions in the absence of facts hits the mark.  If I might pursue that line
a little farther, I wonder if the Commander of the US ship was not forced to
make a decision because he ultimately did not receive the most accurate or
meaningful data.  For example, neither the news media nor any official
commentator has mentioned what data the AWACCS planes, which stage out of
Saudia Arabia, did or did not see regarding the Iranian aircraft.  From all
published reports and publicity releases it seems likely--assuming that an
AWACCS was airborne at the time of the incident--that the AWACCS detected the
takeoff of the aircraft and may also have monitored signal communications
between the aircraft and ground controllers.  It also seems likely given the
intelligence collection capabilities of several countries in the Gulf that
other sources would have recorded the same information.  

If these sources were available, then it seems logical to ask why one cannot
discriminate between a fighter aircraft and a commercial airliner?

If these sources were not available, then it seems reasonable to ask why not?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 A320 Airbus: Air conditioning; monitoring traffic control; F-14s
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Wed, 6 Jul 88 21:00:43 PDT
</i><PRE>

Munnari!mulga.oz.au!lee@uunet.UU.NET (Lee Naish) asks:

&gt; Though the A320 Airbus has redundant computer systems, they all use the
&gt; same air conditioning system.  Does anyone know what the expected
&gt; failure rate of that system is, or how critical a failure would be?

   Jet aircraft air conditioning is derived from the jet turbine's high
pressure bleed air system and/or auxilary power unit.  Air conditioning is
thus available whenever an engine is running.  If both engines fail, they may
be able to use the APU in flight (some aircraft can only operate the APU on
the ground), but this is probably not significant vis-a-vis instrument
overheating, as the aircraft probably won't be flying long enough for the
equipment to overheat.  Computer system fans can fail, but there are usually
several of these per machine and are not highly critical items.


minow%thundr.DEC@decwrl.dec.com (Martin Minow THUNDR::MINOW ML3-5/U26 223-9922)
writes:

&gt; that nobody on the Vincennes was monitoring tower-plane radio communications.
&gt;(And the vague suspicion that there wasn't anyone on the ship fluent in Farsi.)

   You don't really propose that every ship monitor every aviation and
marine frequency within strike distance, do you?  That would be at least
dozens and perhaps hundreds of frequencies.  Also it is very unlikely that 
tower transmissions would reach 20 miles away on the surface.  

   One should note the international language for air traffic control is
English.


Jonathan Crone &lt;CRONEJP%UREGINA1.BITNET@CORNELLC.CCS.CORNELL.EDU&gt; writes:

&gt;    ...  Grumman designed the F-14 to
&gt; support the Navy's requirement for a powerful Air Defense Fighter.

&gt; ... the F-14 has very limited Air to Ground capabilities...

&gt; So perhaps the big question is, why are they saying that they
&gt; were worried about the possibility of an attack from an F-14?

   Iran wasn't supposed to have Silkworm missiles either.  It must have
really surprised the first few captains whose vessels were hit by them.
Although the Iranians aren't exactly technical whizzards, it is possible
that they could have configured an F-14 for air-to-surface operations.
Would you risk your crew to save one belligerent opponent who has 
equipment of unknown capabilities?

   Fred Arnold, a WWII P-38 pilot and author, noted that he always 
gave wide berth to Allied ships, as policy was that it was better 
to shoot down one friendly aircraft by mistake than to lose a ship.  
It seems that the policy is still in force today.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Iranian Airbus Blame? 
</A>
</H3>
<address>
&lt;<A HREF="mailto:"chaz_heritage.WGC1RX"@Xerox.COM">
"chaz_heritage.WGC1RX"@Xerox.COM
</A>&gt;
</address>
<i>
7 Jul 88 09:31:26 PDT (Thursday)
</i><PRE>

RISKS Digest 7.16 consists almost entirely of speculation and expressions of
personal view about the shooting down of an Iranian civil airliner by the USS
Vincennes.

Where are the hard facts? Where are the Flight Data Recorders? Where is the
Cockpit Voice Recorder? Where is the data logger tape of the activity of the
Aegis system aboard USS Vincennes at the time of the incident? When will the Log
of the USS Vincennes be produced? Who will make known the Rules of Engagement
under which the USS Vincennes engaged its target? Who drafted those Rules of
Engagement? Which authority in Iran is reponsible for permitting the aircraft to
fly through the area from a military base during a period of military action?
Who in Iran is prepared to deny that the incident, tragic though it may be in
human terms, is politically extremely convenient for Iran? Who in Iran is
prepared to deny that fundamentalist Islam might well regard the 'martyrdom' of
the Airbus passengers justified if it facilitates political victory over 'the
Great Satan'? 

It must be entirely unjust to assign blame to any party (or system) in the
absence of admissible evidence. The fact that the unfortunate Captain of the USS
Vincennes felt it necessary to make an immediate personal statement accepting
full responsibility for the incident strongly suggests to me that he does not
expect such evidence to be forthcoming. It is shameful that this officer, who
has clearly done nothing but his duty, should have been placed in such an
invidious position so soon after the incident in question.

Still more shameful is the clearly preprogrammed response of the broadcast
media. We now have another addition to the 'Us and Them' Glossary:

USSR shoots down airliner = 'massacre'
USA shoots down airliner = 'tragedy'

Under such circumstances further Iranian political gain seems inevitable.

Chaz Heritage

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: "The target is destroyed."
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 7 Jul 88 15:14:11 EDT
</i><PRE>

&gt; "...So from now on it's hair-trigger 24 hours a day...  Shoot first and
&gt; ask questions later.  The hell if I'm gonna be the next one to lose his 
&gt; Florida retirement condo to keep Marconi's rep clean."  I can't find it in
&gt; my heart to blame the man, either...

Nor can I, for a different reason.  We're seeing yet another manifestation
of the everything-should-be-absolutely-safe-and-if-it's-not-then-somebody-
has-been-negligent syndrome.  For heaven's sake, has everyone forgotten that
(ignoring the political hairsplitting and sticking to the pragmatic facts
of the situation) there is a *WAR* underway in that airspace?!?

In a war zone, a bias toward shooting first and asking questions later is
normal for anybody with any desire to survive.  Wars are confused.  The
"to shoot or not to shoot" decision often has to be made with inadequate
information.   A "wait and see" decision is *very* hazardous to your health.
"Own goals" -- shooting down your friends -- are  normal in a war; the most
one can do is try to reduce the frequency.

The fact is, when you take an airline flight through an area where a
missile war is in progress, nobody in his right mind is going to expect
that flight to be risk-free.  You won't find me in an airliner anywhere
near the Persian Gulf without an awfully good reason.  Anyone who got on
that flight as if it were a normal peacetime flight was either misinformed
or crazy.  Trying to be an innocent bystander to a war while standing in
the middle of it is a damned risky project.  The Stark incident evidently
made the US warship captains aware of this.  It's too bad the Iranian
airline passengers had to learn the facts of life the hard way, but the
people who fired those missiles cannot really be blamed for it.

Henry Spencer @ U of Toronto Zoology   {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
An epilogue to this issue
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Fri, 8 Jul 88 15:42:11 PDT
</i><PRE>

For those of you who have waded through the past three issues of RISKS, I
received MANY MORE contributions on this subject that have not been included
here.  This subject has generated a high level of interest, despite the lack
of hard facts -- or perhaps precisely because of that lack.  Yes, we should
try to avoid rampant speculation, although it is important that we try to
understand the conflicting factors in the absence of any definitive reports.
(Several messages with rather wild rumors and speculations are omitted.)
But the awaited ``definitive reports'' often turn out to be less than
satisfactorily definitive (as in the case of the KAL 007).  Difficult
situations are in general not black and white, and the evidence is often not
very precise -- if present at all.

I make no claims of infallibility.  I sometimes err on the side of openness
by including questionable material in RISKS.  I prefer that to cloture.
However, I think Gary's point at the top of this issue is very significant
-- on the inherent difficulties in decoupling politics and technology, and
indeed the dangers in trying to do so.  

I sometimes also err by rejecting a contribution that deserves to be heard,
but then I usually succumb to appeal.  The Iranian Airbus incident has
overwhelmed me with highly overlapping and speculative material.  If one of
your contributions overlaps one that is here, but still makes an important
point still unsaid, please excerpt, rewrite, and resubmit.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.16.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.18.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-59</DOCNO>
<DOCOLDNO>IA012-000129-B047-310</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.18.html 128.240.150.127 19970217022052 text/html 23051
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:19:22 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 18</TITLE>
<LINK REL="Prev" HREF="/Risks/7.17.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.19.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 18</H1>
<H2>  Friday 8 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
N-Version Programming 
</A>
<DD>
<A HREF="#subj1.1">
Jim Valerio
</A><br>
<A HREF="#subj1.2">
 Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Physical hazards 
</A>
<DD>
<A HREF="#subj2.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Accu-Scan inaccuracies 
</A>
<DD>
<A HREF="#subj3.1">
Robert Steven Glickstein
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The Eyes Have It 
</A>
<DD>
<A HREF="#subj4.1">
Don Watrous
</A><br>
<A HREF="#subj4.2">
 Evelyn C. Leeper
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Lockpicking 
</A>
<DD>
<A HREF="#subj5.1">
Geoff Kuenning
</A><br>
<A HREF="#subj5.2">
 Henry Schaffer
</A><br>
<A HREF="#subj5.3">
 Lee Hounshell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Another "silent fault tolerance" example: DWIM 
</A>
<DD>
<A HREF="#subj6.1">
Mike O'Brien
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  ATM receipts 
</A>
<DD>
<A HREF="#subj7.1">
Joe Beckenbach
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
N-Version Programming
</A>
</H3>
<address>
&lt;<A HREF="mailto:jimv%omepd.intel.com@RELAY.CS.NET">
jimv%omepd.intel.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Thu, 07 Jul 88 18:04:34 PDT
</i><PRE>
Organization: Radix MicroSystems, Beaverton

Nancy, your mention of n-version programming in "Clarifications on the A320
Design" (recent RISKS) reminds me of an n-version failure I experienced last
year.

In the design of the Intel's 80960 microprocessor, we generated two simulators
for the instruction set.  The first emulated the programs at the instruction
level, and the second emulated programs at the logic/register-transfer level.
These two simulators were developed independently from a detailed architecture
specification.  A third group wrote an automatic test generator, used for
validating the hardware and simulators, which created self-checking programs
with "interesting" random operands and results.

All three implementations, both simulators and test generator, made the
same mistake with the modulo instruction.  The remainder instruction was
implemented correctly, but the modulo instruction did an extra subtraction
when the dividend and divisor had opposite signs and the dividend was an
exact multiple of the divisor.  (For example, 4 mod -4 returned 4, not 0.)
The test generator tested for these cases, but wrongly computed the
expected result in such a way that both the hardware logic and the test
generator produced exactly the same results.

This mistake was discovered well after a year of software development on
the processor by a user who was debugging an "impossible" condition.

Although this is the only explicit n-version failure we had, and even
though the n-version approach found on the order of ten thousand design
errors (estimated) over the course of the 5 year effort, this one failure
was a striking experience.  There were several more bugs that the
n-version programming probably didn't find, but they're more forgivable
because there even any tests generated for those sets of conditions.

For me, n-version programming is a valuable tool, but I wouldn't want
to rely entirely on it.

Jim Valerio	jimv%radix@omepd.intel.com, {verdix,omepd}!radix!jimv

</PRE>
<HR><H3><A NAME="subj1.2">
Re: N-Version Programming  [response to Jim Valerio]
</A>
</H3>
<address>
Nancy Leveson 
&lt;<A HREF="mailto:nancy@commerce.ICS.UCI.EDU">
nancy@commerce.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Fri, 08 Jul 88 06:07:20 -0700
</i><PRE>

That is very interesting.  It would, of course, also be interesting to
determine whether the number of mistakes found by a different type of testing
technique would have been less, as, or more effective.  It is also possible
that more "common mode" failures exist, but that noone has discovered them yet
(the one you speak of was discovered, it sounds, by accident).

My student, Tim Shimeall, is just completing a dissertation in which one of the
topics is a comparison of back-to-back testing (n-version testing) vs. regular
testing.  Eight versions of a specification were written independently and then
the programs subjected to both back-to-back testing and regular testing.  Even
though the testers were undergraduate students and unskilled at testing (not
something usually taught to undergrads), the back-to-back testing was not
terribly effective in comparison to the other test methods used (structured
walkthroughs, automated static analysis, functional testing).  The problem is
that voting is not a very good test oracle -- even on the same test cases,
voting did not find the same errors as standard testing techniques.  One of the
reasons is that voting could compare final results only and not look at
intermediate computations.  Often, the testing methods that could thoroughly
instrument a program detected errors that did not, for those particular input
cases, actually result in wrong answers.  Voting on intermediate results would
not have solved the problem.  The errors did not exist at the abstract function
level, but at a much finer level of granularity.  Any attempts to vote at this
level would have required that the specification include the exact algorithms
and variables to be used, thus defeating the whole purpose of writing multiple
versions and just moving the errors to the common specification.

We did find that the back-to-back testing detected errors that were not
detected by testing.  However, we cannot conclude much here because of the
inexperience of the students doing the standard testing.  We gave them a little
instruction, but none had ever used these test methods before.  This same type
of comparison should perhaps be done with more experienced testers.

Almost all n-version experiments are either done in isolation (without
comparing it to the alternatives in a controlled fashion) or have so many other
methods applied to the programs in conjunction with the n-version programming
that it is not possible to separate the effect of one method from the others.
The important question is not whether one method of detecting errors finds
some, but whether the alternatives that could have been used would have been
better, the same, or worse at finding errors and whether they find the same
errors or different ones (i.e., are alternative or complementary techniques).
There are obviously costs associated with all these error-detection techniques
and almost always a finite and limited amount of resources and time to apply
them.  The real question is how should these limited resources be spent.

No one has yet (including us) compared formal verification techniques with
some of these other approaches.  I just heard John Cullyer speak on the
VIPER development and proof and was very impressed.  My bias is to believe 
that formal techniques would be superior to many of these other techniques, 
but this needs to be confirmed using carefully controlled experimental 
comparison.  In lieu of this, it will be interesting to see if the VIPER 
turns out to have fewer design and other errors than similar microprocessors 
developed using non-formal techniques.

The only small piece of evidence that I know of was obtained during an 
experiment by Brunelle and Eckhardt in which they had two more versions
of the SIFT operating system (written at SRI using formal specification and
verification techniques although not, in the end, completely verified to
the code level) written by graduate students.  When the three versions
were run together as an n-version voting system, no errors were found in
SIFT but there were instances of the two unverified versions outvoting the
correct SIFT version.  The programmers may, however, have had vastly different
backgrounds and experience from the SRI programmer, so no real conclusions 
can be reached here.  But it is interesting.  Harlan Mills is also claiming
very substantial gains from the use of formal development procedures on real
projects at IBM.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Physical hazards
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 6 Jul 88 16:32:02 EDT
</i><PRE>

&gt; CCI also cleverly placed the "reboot" switch, an up/down toggle, on the
&gt; front of the cabinet, not recessed, and at knee level...

Some years ago, when I was with CSRI here, we had an analogous problem.
The machine room was relatively long and narrow, and we had two multi-
rack systems facing each other with consoles in the space in between.
The beat-up old swivel chair that we used as a console chair had a rubber
bumper strip high on its back so it wouldn't mar a wall (or whatever) if
you leaned back against one.  Turned out that the bumper was at exactly the
height of the control switches on one of the RK05 disk drives.  Oops...
We changed console chairs.

Henry Spencer @ U of Toronto Zoology  {ihnp4,decvax,uunet!mnetor}!utzoo!henry

                       [This was not a case of "Chair and chair alike."  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Accu-Scan inaccuracies
</A>
</H3>
<address>
Robert Steven Glickstein 
&lt;<A HREF="mailto:bobg+@andrew.cmu.edu">
bobg+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Fri, 24 Jun 88 14:52:23 -0400 (EDT)
</i><PRE>

I once bought a little container of Minced Garlic at the Food Gallery on
Centre Ave., Shadyside.  The shelf price was something like $1.89, I don't
really know.  The scanned price, however, was $5287.44.

I was with a bunch of my friends, all of whom were very very amused by this.
Unfortunately, the checkout clerk and the manager were both fairly humorless,
and didn't appreciate our comments.

  "Bad garlic crop this year?"
  "Gee, I better really enjoy this garlic bread tonight."
  "Do you take the American Express Gold Card?"
  "Only fifty-two hundred?  I'll take two."
  "Reaganomics."
  "Do you have change for a ten thousand?"
  "Hmm.  Garlic bread tonight, or a new car?"

-Bob Glickstein

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: The Eyes Have It (RISKS DIGEST 7.16)
</A>
</H3>
<address>
Don Watrous
&lt;<A HREF="mailto:watrous@aramis.rutgers.edu ">
watrous@aramis.rutgers.edu 
</A>&gt;
</address>
<i>
Wed, 6 Jul 88 21:04:52 EDT
</i><PRE>

All the original information for the last 5 digits of the NJ Drivers License
is correct (MMYYE) except for the omitted fact that 50 is added to the month
(MM) field for female drivers.  I used to think that this was to make it a
less recognizable date (for women, who tend to conceal their age sometimes),
but now guess it's just adding in a coding for sex also.

I can confirm that all the Watrouses I know have the same initial letter and
4 digits.  I'm curious as to how the middle 5 digits are arrived at.

Don

</PRE>
<HR><H3><A NAME="subj4.2">
 The Eyes Have It (Re: <A HREF="/Risks/7.14.html">RISKS-7.14</A>)
</A>
</H3>
<address>
Evelyn C. Leeper
&lt;<A HREF="mailto:ecl@mtgzy.att.com ">
ecl@mtgzy.att.com 
</A>&gt;
</address>
<i>
6 Jul 88 13:34:45 GMT
</i><PRE>
Organization: AT&amp;T Information Systems, Middletown NJ

    [... also noted the +50 encoding... ]

Even with all this, I have a driver's license that lists me as male!  (Well,
Mark and I both filed for a change of address on our licenses and I requested a
change of name to add my middle initial, and they apparently added all the
stuff together and sent me a temporary license with Mark's decsription!)

Evelyn C. Leeper  201-957-2070  UUCP:	att!mtgzy!ecl or ecl@mtgzy.att.com

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Lockpicking, The Eyes Have It (<A HREF="/Risks/7.16.html">RISKS-7.16</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:ames!desint!geoff@uunet">
ames!desint!geoff@uunet
</A>&gt;
</address>
<i>
Fri, 8 Jul 88 04:23:00 EDT
</i><PRE>
Organization: Interrupt Technology Corp., Manhattan Beach, CA

Randy D. Miller writes:

&gt;      If it's so easy to pick open locks, why do burglars resort to harder and
&gt; messier ways of entering buildings, desks, cabinets, etc.?  Are most burglars
&gt; incapable of learning such a skill, or does it just not occur to them?

In the first place, the great majority of burglars are low-ambition,
low-intelligence people.  In general, they are looking for a quick, easy hit
-- if they were interested in learning in a new skill, they'd most likely
get a safer, higher-paying job.  In the second place, why pick a lock when
you can kick a door in, smash a window, or try the neighbor's house with the
unlocked door?  

In the same digest, Tracey Baker writes:

&gt;   It also makes me wonder about the NJ DMV...

I have a pretty low opinion of ANY organization that generates a
supposedly-unique identification number from non-unique personal
characteristics.  What's wrong with assignments from a sequence, as
with license plates and Social Security Numbers?  The whole purpose is
disambiguation;  the current NJ system is, in a pithy analogy I heard
yesterday, playing Russian Roulette using a clip-loading gun.

	Geoff Kuenning   geoff@ITcorp.com   {uunet,trwrb}!desint!geoff

     [Please let's not reiterate the many previous discussions on the
     use of an SSN.  PGN]

</PRE>
<HR><H3><A NAME="subj5.2">
re: lockpicking
</A>
</H3>
<address>
Henry Schaffer 
&lt;<A HREF="mailto:hes@uncecs.edu">
hes@uncecs.edu
</A>&gt;
</address>
<i>
Thu, 7 Jul 88 15:55:09 edt
</i><PRE>

  Randy Miller discussed the delights of lockpicking, and then raised some
questions.  He raised his chances of success by using inexpensive new locks.
The lower the precision of the lock, the less the chance of quick picking.
The BEST (brand) of locks is of standard construction (with regard to the
pins and cylinder) but is very well made, and is quite difficult to pick.
Then there are locks with specially designed pins (the Medeco brand is
particularly well known) which make sucessful picking unlikely.
Old/corroded locks are often difficult to work with.

  Most of his questions also apply to physical security of computing
facilities, and the concepts are even more general.

  Most locks (e.g., in homes) are not extremely pick resistant, and there
are perfectly good reasons why they are not.  It is a principle of security
that you should reinforce the weaknesses - and not waste time strengthening
the already strong areas.  (This also applies to computer security.)  Since
most (wood frame) doors, windows, desks, etc. are less resistant to force
than their locks are to picking, it would be a waste of money to buy better
quality locks.  (This principle also applies to computer security.)

&gt;     I called some city and state offices, and one local locksmith, to see
&gt;if there are any laws regulating the possession and use of lockpicks in
&gt;Arizona.  No one I talked to seemed to know anything about any regulations!

  There is a "risk" of asking the wrong question! Ask again about possession
of "burglar's tools"! (Yes, the definition of "burglar's tools" is context
dependent.)  It is not a good idea to have a lock pick in your pocket when
you are in or around someplace which has been burglarized!

&gt;     If it's so easy to pick open locks, why do burglars resort to harder and
&gt;messier ways of entering buildings, desks, cabinets, etc.?  Are most burglars
&gt;incapable of learning such a skill, or does it just not occur to them?

  It isn't so easy (you, a technical person, spent quite a bit of time
learning/practicing this.)  A 2' crowbar or strong screwdriver will usually
work faster, and with less practice needed - and who cares about "messier"?

&gt;Should I spend a fortune replacing the locks on my house, or are the risks
&gt;low that a burglar will pick the locks?

  If the easiest way to get into your house is by picking the lock(s), then
you probably should replace them.  Spring latch locks can also be defeated
by use of a piece of flexible plastic or metal - do you have dead bolts?

--henry schaffer  n c state univ

</PRE>
<HR><H3><A NAME="subj5.3">
Lockpicking (Re: <A HREF="/Risks/7.16.html">RISKS-7.16</A>)
</A>
</H3>
<address>
Lee Hounshell
&lt;<A HREF="mailto:tlh@pbhyf.PacBell.COM ">
tlh@pbhyf.PacBell.COM 
</A>&gt;
</address>
<i>

</i><PRE>
Date: 7 Jul 88 16:33:13 GMT

&gt;[Randy D. Miller writes..
&gt;     If it's so easy to pick open locks, why do burglars resort to harder and
&gt;messier ways of entering buildings, desks, cabinets, etc.?  Are most burglars
&gt;incapable of learning such a skill, or does it just not occur to them?
&gt;Should I spend a fortune replacing the locks on my house, or are the risks
&gt;low that a burglar will pick the locks?]

Picking a lock takes time, and sometimes even locksmiths can't do it quickly.
I remember being locked out of a condo at Lake Tahoe last year, and the
locksmith who was called out to open the place up spent 2 hours trying to
pick the lock.  Finally, he gave up and took out a hammer and chisel.  Just
two hits on the deadbolt were all that was needed to completely demolish it.
The door was open in about 10 seconds.  What really amazed me was how quickly
*anyone* can get into someone's home, just with a hammer and chisel.  Locks
only keep out honest people.

Lee Hounshell

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Another "silent fault tolerance" example: DWIM
</A>
</H3>
<address>
&lt;<A HREF="mailto:">

</A>&gt;
</address>
<i>
Fri, 01 Jul 88 12:50:43 -0700
</i><PRE>
From: obrien@aerospace.aero.org

	I can provide a more modern example of "too silent" error
recovery.  A couple of years ago I was programming in Berkeley Smalltalk:
the implementation of Smalltalk on a Sun.  I was surprised at how slow
the graphics of the system was, and went in to tweak the virtual machine.
First, I "batched" the bitmap operations.

	Nothing happened.

	I put in a few print statements to see what was going on in there.

	Nothing happened.

	In desperation I put print statements all over the place.

	Finally, something happened - but not much.  The virtual machine
operation was returning an error immediately (this was "drawLoopXY" for
the curious).  Interpreted Smalltalk code was then taking control and
doing the drawing using more primitive calls.  In all its history,
Berkeley Smalltalk virtual machine had never actually drawn any lines!
The Smalltalk code was silently doing it all, at far less speed.

	I had thought this experience unique, until I saw the message
about DWIM.  I wonder how many of our "high-level programming environments"
are running much, much more slowly than they need to?

Mike O'Brien
The Aerospace Corporation

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
ATM receipts
</A>
</H3>
<address>
Joe Beckenbach
&lt;<A HREF="mailto:beckenba@csvax.caltech.edu ">
beckenba@csvax.caltech.edu 
</A>&gt;
</address>
<i>
Tue, 5 Jul 88 23:23:15 PDT
</i><PRE>

	One of the RISKS readers wrote in to register his surprise at the
concept of receipts for withdrawals and also for deposits, taking the more
traditional legal "exchange money for receipt" view.
	The ATMs here in Los Angelos give "receipts" for deposits,
withdrawals, transfers, and user-selected balance checks. The receipt for
deposits is the traditional legal-style notice that money has been received.
The "receipt" for the other transactions are hard-copy of the transaction,
and therefore not a receipt in the strictest sense. For instance, I find it
very worthwhile keepng the withdrawal 'receipts' from my checking account
ATM withdrawals: balanced checkbooks are happy checkbooks. Hardcopy balance
statements are handy for trying to figure out when checks cleared to contest
a bounced check, and an ATM transfer of funds needs a record just as much as
any other deposit does.
	And a deposit accepted without a receipt is a donation. No joking.
Even most organized charities give receipts for donations accepted.

	Rather "receipts" than mute ATMs!	Joe Beckenbach

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.17.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.19.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-60</DOCNO>
<DOCOLDNO>IA012-000129-B047-328</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.19.html 128.240.150.127 19970217022122 text/html 23774
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:19:34 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 19</TITLE>
<LINK REL="Prev" HREF="/Risks/7.18.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.20.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 19</H1>
<H2>  Sunday 10 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Iranian Airbus discussion 
</A>
<DD>
<A HREF="#subj1.1">
Philip E. Agre
</A><br>
<A HREF="#subj1.2">
 Tracy Tims
</A><br>
<A HREF="#subj1.3">
 Hugh Miller
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Iranian Airbus discussion
</A>
</H3>
<address>
Philip E. Agre 
&lt;<A HREF="mailto:Agre@WHEATIES.AI.MIT.EDU">
Agre@WHEATIES.AI.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 9 Jul 88 18:24 EDT
</i><PRE>

An interesting analogy connects a number of the disagreements over topics
like the shooting of the Iranian airliner.  Some people want to stick to
the technical details and leave politics out of it; others reply that the
distinction is untenable since politics is part of the reality in which
products of technology operate.  Likewise, some people want to discuss
the conduct of war as if it occurred in a reality free of politics.  The
latter was once possible but now it isn't.  But why?  Roughly speaking,
because the world is a smaller place.  For one thing, the efficiency of
modern communications media make it possible to conduct a `political
war'.  For another thing, great increases in the velocities and ranges of
both weapons and civilian transportation make it much harder for civilian
activities to stay out of the way of `war zones'.  Yet the model of `pure
war' continues to inform the design of most computerized weapons systems.
All of the doctrines, indeed all the vocabulary, of Western warfare were
developed in the context of such well-defined, all-out wars as the major
modern European wars.  These wars started and ended at definite times,
opposed clearly defined alliances in which all relevant parties felt the
need of choosing sides, and were conducted by militaries whose only
political constraint was the necessity of winning.  Everyone understood
that civilian life simply came to a complete halt during these wars.
These episodes serve as our prototypes of a `war', a category about which
one makes generalizations by consulting a historiography of warfare,
written by modern Westerners, that concentrates on episodes that fit this
pattern.  The concept of `civilian' is simply the flip side of the
concept of `war'.  This concept of warfare is just as much a part of the
models implemented by the computers on the Vincennes as the concepts of
physics used to describe signals, trajectories, and explosions.  As we
well know, when the models underlying a computer system are wrong, the
computer will make mistakes.  Most of the systematic organized violent
conflicts in the world today are not `pure wars' but rather drawn-out
low-level conflicts in which the smallest details of military operations
are political actions organized by political considerations.  The
inappropriateness of the `pure war' model explains many recurring themes
in interviews, long before the Iran Air incident, with the military
people running the US operations in the Gulf, both the sailors on the
ships and the admirals back in Washington.  They complain bitterly, for
example, of having to ``fight a war in a lake'' and of the narrow margins
placed on their decisions by the presence of non-military planes and
boats, many of which (especially the boats) do not own or competently
operate the radio systems that permit ready discrimination in peacetime
traffic control.  Thus the naval battle that was occurring at the precise
moment when the Air Iran plane approached the `war zone' was not at all a
prerequisite for such an incident.  The ultimate questions are: As
warfare and politics blur, what should be call what's happening in the
Gulf (and two dozen other places in the world) if not a `war'?  And then,
as technical practice and politics blur, what should we call what happens
in laboratories and factories if not `technology'?

</PRE>
<HR><H3><A NAME="subj1.2">
Responsibility (Iranian Airbus)
</A>
</H3>
<address>
Tracy Tims 
&lt;<A HREF="mailto:ttims%watdcsu.waterloo.edu@RELAY.CS.NET">
ttims%watdcsu.waterloo.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Sat, 9 Jul 88 18:52:39 EDT
</i><PRE>

It is true (as Henry Spencer points out) that you would have to be "misinformed
or crazy" get on that flight as if it were a normal peacetime flight.  On the
other hand, the fact that we do not judge such people wise should not affect
the way we judge those who caused their deaths.

If a woman takes a risk (say, walking home from work through a suspect
neighborhood) that leads to her being raped, we may question her judgement
in taking the risk, but we in no way reduce the burden of responsibility on
the man who actually did the raping.  We may suggest that she avoid walking
in the area, but we know that it is not right to expect women to limit their
lives because of a danger some criminals have decided to threaten them with.
The desired situation (in fact the moral situation) would be no risk to women
of rape.  There would have been no risk of rape (and no rape) had not some man
decided to create one.  One must not fall into the trap of transferring
responsibility from the perpetrator onto the victim.

Likewise, there would be no real risk of an airliner being shot down by a
missile had not some group of people decided to create that risk.  Yes, we can
question the judgement of a group of people who decide to expose themselves to
that risk, but we cannot lessen the moral responsibility of the people who
created the risk and who performed the action.

By having a shoot-first-ask-questions-later policy, in a zone where both
military and peacetime activities co-exist (and, as I'm sure we all agree,
where only peacetime activities should be), a military that is executing policy
places the risk of executing that policy squarely on the shoulders of
potentially innocent people.  Given the fact the the U.S. chose to conduct
military operations where there were innocent bystanders I feel strongly that
they should also be willing to accept any attendant risks.  Anything less than
that amounts to sticking other people with the bad results of their decisions.
The Navy has a moral obligation to decide whether or not a blip on their screen
is an attacking aircraft and not an airliner, if there is a significant chance
that it could be an airliner.  If they cannot, they should not place the risk
of misidentification on some innocent passengers. I feel this especially in
this case, where the U.S. Navy is not fighting a war for U.S. survival against
unprovoked attack, but is implementing a peacetime foreign policy decision.

	It's too bad the Iranian airline passengers had to learn the facts of
	life the hard way, but the people who fired those missiles cannot
	really be blamed for it.
		- Henry Spencer

I think this statement has a profound lack of empathy, but I find the last part
of it, "the people who fired those missiles cannot really be blamed for it," to
be completely absurd and dangerous.  Any atrocity can be justified using very
similar words: "it's too bad she had to learn the facts of life the hard way,
but the man who raped her cannot really be blamed for it."  (After all, she
really caused the crime, by placing herself in the position where it could
happen, right?)

The people who died in the airliner did not kill themselves.  Captain Rogers
killed them.  A sidereal examination of the facts of the incident shows this
clearly.  At most, the passengers are guilty of stupidity, optimism and bad
judgement.  Captain Rogers is guilty of their deaths.

The problem with man-made risks in general is not so much detecting them, but
trying to find someone or some group to actually be responsible for them.  If
the responsibility for a risk (and its consequences) is diffuse, or state
sanctioned, or complicated by the fact that the victims apparently chose to
accept the risk; then people are all to quick to deny any blame.  This is
a moral failing.  Many technological risks (from the design of user interfaces
to the existence of nuclear weapons) are orphans in this sense.

Tracy William Lewis Tims

</PRE>
<HR><H3><A NAME="subj1.3">
The Iranian Airbus and following discussion
</A>
</H3>
<address>
Hugh Miller 
&lt;<A HREF="mailto:HUGH%UTORONTO.BITNET@CORNELLC.CCS.CORNELL.EDU">
HUGH%UTORONTO.BITNET@CORNELLC.CCS.CORNELL.EDU
</A>&gt;
</address>
<i>
Sun, 10 Jul 88 09:56:53 EDT
</i><PRE>

        I've had _numerous_ private messages &amp; some RISKS postings responding
to my submission to RISKS 7.15 ("The target is destroyed").  A few warranted
replies, so I have tried to draw up same here.  (I have not responded to Gary
Chapman's posting in RISKS 7.17, since I agree emphatically with everything he
says.)

(1)      Michael Mauldin (RISKS 7.15) taxes me with getting the facts wrong.
         I plead guilty.  If you note the header of my message you will see
         that it was -- well, 'fired off' I guess is the right phrase -- at
         11:15 on Mon 04 July, at which time even the most elementary facts
         were in dispute.  For that matter, several of the 'facts' Mr Mauldin
         and others report have since been, uh, revised.  My main points,
         however, rely (I hope) less on facts than on possibilities.  I would
         be tempted to call them 'philosophical' did that not open them to the
         usual (and deserved) snorts of derision 'hard science' types reserve
         for contemporary so-called 'philosophy.'
                Similarly, Sue McPherson charges from Down Under "that the
         papers have told him that technology has fouled up again." I can
         assure her that I never believe what the papers tell me.  I grew up
         in Louisiana.  As for technology doing what it ought in this case,
         well, 290 dead civilians indicates otherwise to ME.  Her words
         radiate the confidence of technolatry: if we can get the facts
         straight &amp; keep the media &amp; the pols out of the control room we can
         fix this sucker right now so it'll never happen again.  But whether,
         in this instance, Capt Rogers made the 'right' call or not, whether
         the EW gear 'worked' or not, we still have to ask some very
         fundamental questions about technology.
                 Let's not be under any illusions about whether we will ever
         get the "real facts," the nitty-gritty technical details, of the
         Flight 655 tragedy.  (Perhaps 12 months from now one of you reading
         this will get hired by the Pentagon to write some code for the AEGIS
         system to prevent such-and-such a, purely hypothetical you
         understand, 'problem' from occurring.  I would like to think you
         would do the right thing and tell us, but doubtless you will be sworn
         to infinite secrecy.)  In Montreal, where I used to live, complaints
         against the Police de la Communaute Urbaine de Montreal were
         investigated by -- the Police de la Communaute Urbaine de Montreal.
         Needless to say, such complaints were unexceptionally dismissed as
         groundless.  With the stakes stupendously higher, what reason have we
         to believe that the US government (to say nothing of our lickspittle
         press) will behave in any less self-serving a fashion?  290 dead
         innocent airline passengers, 66 children among them, is, to put it
         crudely, one hell of a spin-control problem.

(2)      Bob Estell (RISKS 7.15) knew Capt Will Rogers before the Navy &amp; finds
         it hard to believe he (Rogers) would have behaved in any other way
         save the honorable.  Given the alternative, I hope for Capt Rogers's
         sake he is right.  But military training of any sort changes a
         person, in my thin experience in the matter; it is intended to; and
         the results are for the 'good' only when that 'good' is evalued from
         the standpoint of the profession of arms.  At any rate, Capt Rogers
         either made a bad judgment on the basis of good evidence, a good
         judgment on the basis of bad evidence, or a bad judgment on the basis
         of bad evidence.  I cannot bring myself to believe Capt Rogers, any
         more than Capt Brindel before him, was capable of the first, and I
         hope none of us can.  (That may not keep him from being scapegoated.)
         If versions 2 or 3 are correct, then the particular technology, to
         quote George Bush, is "in deep doodoo."  And in any event technology
         in the broadest sense is what gave us the "Roger-willco" attitude
         that got us embroiled in this hellacious war in the first place.

(3)      Jim Anderson (RISKS 7.16) faults Iran Air for its imprudence, at
         best, in sending a commercial airliner over a combat-engaged US AEGIS
         cruiser.  IF indeed the facts are as my government represents them (I
         am, by the way, a native-born US citizen and a landed immigrant in
         Canada), then I might fault the people at Iran Air for poor judgment;
         perhaps I might even go so far as to hold them technically liable at
         law for criminal negligence indirectly causing death.  As to the true
         facts of the engagement, well, as of today (9 July) the US has, ahem,
         changed its story a few times.  As a highly interested party its
         account will always be suspect.  But even if the facts are as we
         represent them, since the US is not officially at war with Iran (at
         least as far as Congress, which under the Constitution has the
         exclusive power to declare war, is concerned) we had and have no
         right to be where we are in the first place, under strict
         interpretation of international law and maritime convention, to say
         nothing of good old practical political reasoning.  (Henry Spencer,
         RISKS 7.17, please take note.  This is not 'our' war.)  Let me pose
         the following 'scenario', as the gamers say: suppose you are a
         citizen of, say, France, in the year 2000.  Margaret Thatcher, now in
         her 18th term of office, declares war on your country.  The USSR, for
         10 years thanks to _perestroika_ engorged on Western high technology
         and a big consumer of oil from the North Sea, decides to protect its
         supply by sending in a huge naval tactical group, some of which stays
         outside the North Sea &amp; English Channel, but much of which goes in to
         reflag tankers with the Soviet standard &amp; generally harass &amp; fire on
         French vessels while ignoring English ships.  In short order their EW
         technology, still at US 1988 levels, leads them to shoot down an
         Airbus A920.  The Soviets say the French were to blame; some Russians
         claim fanatical French deconstructionists had sent the airliner on a
         deliberate kamikaze mission, or had tucked a MiG-99 behind it, or AT
         BEST just should have known better than to tempt the wrath of the
         Bear.  Describe your feelings, as a French citizen.  (For fun,
         imagine what the Pentagon would be thinking.)  This was my point: we
         are in the the Gulf only partly because of greed and the normal,
         predictable imperialist tendencies we have exhibited for over a
         century.  REAL prudence would counsel us not to be there, and
         statesmen of an earlier day would probably have heeded that counsel.
         But the Mephistopheles of technology, to whom we have sold our soul,
         remember, whispers: "We _can_ do it.  If we _can_ do it, we _should_
         do it.  If we _should_ do it, we _must_ do it."  Technology is much
         more than just a tool.  It is a world, a universe of discourse, a
         mythology (as PGN put it elsewhere in the issue), a devil of a
         weirdly affectless sort, but persuasive as any tempter.  He has
         entered into us like the demon into the Gadarene swine, and driven us
         headlong, not this time into the Sea of Galilee, but into the Persian
         Gulf.
                Mr Anderson's final point is thus the most disturbing, the
         more so for its offhanded, sensible flavor.  "Let's get the forum
         back to technical risks," he urges, "and off of the political beat."
         Again, this is my point: the two are as inseparable as the faces of
         Janus.  The flashpoint of their union is the armed forces of the US
         and NATO, and to a much lesser extent those of the Soviet Union, the
         Warsaw Pact, and other nations.  Technology, or rather its
         apologists, dissembles this; part of the hoodwink consists in its
         claiming to be just a means, completely separate from any
         consideration of ends.  We are more than happy to go along, to let
         ourselves be deceived, for the sake of the lovely, tangible, short-
         term amenities and conveniences it supplies.  (Anyone who has doubts
         about America's capacity for self-deception must have been on Mars
         for the past 8 years.)  Technology is, rather, for us, an end in
         itself as well as the means thereto, THE end-in-itself _par
         excellence_.  (The end, PERIOD, I'm tempted to say.)  This, to my
         mind, is where a more fundamental consideration of the "RISKS" posed
         by technology must begin.
                Such a reconsideration, it seems to me, would have to go far
         beyond the received wisdom.  It would have to question what we take
         completely for granted, and when one does this one always runs the
         risk of being deemed insane, reactionary, or Luddite, no matter how
         much one loves one's children &amp; the future.  Is, for instance, the
         entire modern project of unlimited progress through the conquest of
         nature, of which technology is the articulation, the Unqualified Good
         we assume it to be?  The project of the conquest of nature seems
         itself founded upon still deeper assumptions, such as the mechanical
         character of human and nonhuman nature, the total freedom of human
         cognition and valuation, the denial of transcendence, etc.  But the
         most important such assumption seems to be that compassion for the
         lot of one's suffering fellow human beings must override all other
         practical and theoretical considerations.  In Feuerbach's words,
         "compassion must precede thought."  Are we prepared, in the light of
         the chaos into which our 'compassionate' and 'thoughtful' technology
         is about to precipitate us, to rethink even these assumptions?
                Turning back to bits and bytes (permanently) is tuning out to
         the deeper issues.  I can play with the details as well as anybody, I
         suppose, but just as in a corporation you'll never get promoted to
         CEO if all you want to do is sit at a terminal all day and code, so
         we cannot be free men and women, "The People" to whom our
         Constitution makes constant reference, if we do not undertake to
         THINK about What Gives Here Anyway?

       If I may be permitted a personal point, at the risk of making this
sound like some maudlin Lance Morrow "Time Essay": Someone may object, "Well,
for an anti-technologist you seem to have no problems with the computer, the
pre-eminent technology."  All right.  But with me the issue of technology is
much more painful to think through than whether or not I am prepared to go
back to the typewriter or even the quill pen.  My adorable one-year-old
recently underwent a balloon valvoplasty for a blocked heart valve.  Without
the operation the prognosis was death by heart attack or congestive heart
failure by six months of age.  Today he is well and will lead an utterly
normal life, provided he does not fly on an Iranian airliner near an AEGIS
ship.  For me, to think about technology at a fundamental level means to come
face to face with the bitter possibility of my own son's certain death.
Unless we are prepared to think at that level we will go on killing, puzzled,
wishing we didn't have to, but hopelessly going on and on.  The great English
poet Stevie Smith, writing about theology in her poem "How Do You See?" has
words that the priests and priestesses of the new religion of technology would
do well to heed:

        I do not think we shall be able to bear much longer the dishonesty
        Of clinging for comfort to beliefs we do not believe in,
        For comfort, and to be comfortably free of the fear
        Of diminishing good, as if truth were a convenience.
        I think if we do not learn quickly, and learn to teach children,
        To be good without enchantment, without the help
        Of beautiful painted fairy stories pretending to be true,
        Then I think it will be too much for us, the dishonesty,
        And, armed as we are now, we shall kill everybody,
        It will be too much for us, we shall kill everybody.

        Questioning technology as profoundly as we must is so painful and
vertiginous I doubt we can do it.  I hope we can; but I doubt it.
        That's all for now.

Hugh Miller  University of Toronto   (416)536-4441   &lt;HUGH@UTORONTO.BITNET&gt; 

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.18.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.20.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-61</DOCNO>
<DOCOLDNO>IA012-000129-B047-361</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.20.html 128.240.150.127 19970217022143 text/html 23821
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:20:09 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 20</TITLE>
<LINK REL="Prev" HREF="/Risks/7.19.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.21.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 20</H1>
<H2>  Monday 11 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Computers may be at root of jet downing" 
</A>
<DD>
<A HREF="#subj1.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Iran Airbus tragedy 
</A>
<DD>
<A HREF="#subj2.1">
Chris Moss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Shooting down Flight 655 
</A>
<DD>
<A HREF="#subj3.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Ignoring the wolf 
</A>
<DD>
<A HREF="#subj4.1">
Andy Freeman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Air France Airbus crash 
</A>
<DD>
<A HREF="#subj5.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: Physical hazards - poorly designed switches 
</A>
<DD>
<A HREF="#subj6.1">
John Robert LoVerso
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  PIN on PNB calling card 
</A>
<DD>
<A HREF="#subj7.1">
Mark Mandel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Lockpicking 
</A>
<DD>
<A HREF="#subj8.1">
Henry Spencer
</A><br>
<A HREF="#subj8.2">
 Robert Mathiesen
</A><br>
<A HREF="#subj8.3">
 Doug Faunt
</A><br>
<A HREF="#subj8.4">
 Chaz Heritage
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Computers may be at root of jet downing"
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Mon 11 Jul 88 10:34:52-PDT
</i><PRE>

From the Washington Post, on the front page of the San Jose Mercury News,
11 July 1988:

WASHINGTON -- Computer-generated mistakes abourd the USS Vincennes may lie at
the root oooof the downing of Iran Air Flight 655 last week, according to
senior military officials being briefed on the disaster.  
  If this is the case, it raises the possibility that the 290 Iranian
passwngers and crew may have been the first known victims of "artificial
intelligence," the technique of letting machines go beyond monitoring to
actually making deductions and recommendations to humans.  
  The cruiser's high-tech radar system, receivers and computers -- known as
the Aegis battle management system -- not only can tell the skipper what is
out there in the sky or water beyond his eyesight but also can deduce for him
whether the unseen object is friend or foe and say so in words displayed on a
console.
  This time, said the military officials, the computers' programming could
not deal with the ambiguities of the airliner flight and made the wrong
deduction, reached the wrong conclusion and recommended the wrong solution to
the skipper of the Vincennes, Capt. Will Rogers III.
  The officials said Rogers believed the machines -- which wrongly identified
the approaching plane as hostile -- and fired two missiles at the passenger
plane, knocking it out of the sky over the Strait of Hormuz.  [...]

System `flawed' in tests

  On the question of the Vincennes' performance, Rep. Denny Smith, R-Ore.,
a longtime critic of the Aegis program, said Sunday on the ABC News program
"This Week With David Brinkley" that the type of phased-array radar system
carried on the Vincennes has proved "flawed almost every time" in a recent
series of Navy tests. [...]
  Military officers with combat experience stopped short of criticizing
Rogers for firing but said a skipper who relied more on human intelligence
than artificial intelligence might have doubted that the approaching plane
was an Iranian F-14 intent on attacking his ship for these reasons:
  / The approaching plane had not focused either its search or fire-control
radar system on the Vincennes and had identified itself at least once
electronically as an airliner as well as an F-14, an air-to-air fighter that
Iran has not used against ships.
  / The plane was descending from a high altitude, between 9,000 and 12,000
feet, making it vulnerable to the Vincennes' missiles and guns.  Rogers had
about four minutes -- enough time to handle a single threat -- to shoot the
Airbus down after it came within sight but before a hostile plane could use
its cannons or drop unguided bombs accurately.
  (The Iranian F-14 is not wired for anti-ship missiles, which would be
dropped during a different flight profile than the Airbus was flying, and has
not shown the ability to use laser-guided bombs in such a single-airplane
attack.
  / A single plane would be unlikely to attempt a kamikaze attack against
such a heavily armed and highly maneuverable ship as the Vincennes.

Newspaper disputes account

  The Pentagon's account of the incident came under fire from a new 
direction Sunday when the Sunday Times of London reported that the British
Government Communications Headquarters had determined from electronic
eavesdropping that the Iranian Airbus left Bandar Abbas only three minutes
behind schedule, was flying in the correct flight path south over the Strait
of Hormuz toward Dubai in the United Arab Emirates and was climbing when the
Vincennes shot it down.
  Adm. William J. Crowe Jr., chairman of the Joint Chiefs of Staff, said
July 3 that the Airbus was outside the commercial corridor, an assertion the 
Pentagon stepped away from Thursday, and was descending toward the ship in an
attack mode.  The Pentagon has said the airliner was 27 minutes late taking
off. 
  The newspaper said that the communications headquarters report was
"severely critical" of the U.S. Navy for shooting down the Airbus and
suggests that the initial confrontation between the Vincennes and three
Iranian gunboats may have been provoked by U.S. helicopters flying into
Iranian airspace.  The Pentagon has said a helicopter from the Vincennes was
fired on by the gunboats, triggering return fire from the cruiser.  Pentagon
officials declined to comment on the Times report.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
   Iran Airbus tragedy
</A>
</H3>
<address>
&lt;<A HREF="mailto:      cdsm%DOC.IC.AC.UK@CUNYVM.CUNY.EDU">
      cdsm%DOC.IC.AC.UK@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 11 Jul 88 15:22:43 BST
</i><PRE>

[...]  Some people writing in the US may not realise that Dubai airport, to
which the flight was heading, is the busiest transit point in the region.
It would change a LOT of schedules if it were closed.

Chris Moss

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Shooting down Flight 655
</A>
</H3>
<address>
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 11 Jul 1988  00:47 EDT
</i><PRE>

I've just read the last few issues of commentary about this subject,
and I find the debate sadly misdirected.  The one really relevant
comment came from Gary Chapman, who says we should not look at just
the technical issues.

The point is not to learn why the Vincennes was unable to identify a
civilian airliner as such.  The US military has known for 20 years
that the IFF problem (Identification Friend or Foe) is a VERY tough
problem, and no good solutions exist as yet, other than visual
identification.   If you send ships into areas in which weapons will
be fired at other things in the area, sooner or later an innocent
target will be destroyed.  We can argue till the cows come home the
precise nature of this particular error, but in the larger scheme of
things, it really doesn't matter.  Whatever this reason is, the next
time it will be some other reason.

The real issue -- if you are determined to save innocent lives -- is
why the US Navy is in the Gulf at all.  The only sure way to make sure
you don't -- at some point -- have innocent blood on your hands is to
not send your weapons of war into an area where they could be used.
The technology doesn't matter; the policy does.

On the other hand, maybe RISKS isn't the right place for a strictly
policy debate.  Try ARMS-D for that, maybe?

Herb (ARMS-D moderator)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Ignoring the wolf
</A>
</H3>
<address>
Andy Freeman 
&lt;<A HREF="mailto:andy@polya.Stanford.EDU">
andy@polya.Stanford.EDU
</A>&gt;
</address>
<i>
Fri, 8 Jul 88 23:03:45 PDT
</i><PRE>

The July 8 issue of the San Francisco Chronicle had an article by
Karen DeYoung of the Washington Post.  She reported on a news
conference by Brigadier General Mansour Satary, "the chief of Iran's
Air Force."  The last paragraph of the article was:

"Asked why the airbus failed to respond to what the Pentagon has said
were 12 separate radio queries, on both military and civilian
frequencies, to identify itself, Satary said that such communications
from the American ships in the gulf were so frequent that Iranian
pilots usually ignored them."

-andy

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Air France Airbus crash
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sun, 10 Jul 88 21:57:41 EDT
</i><PRE>

&gt; Does the Airbus model in question display altitude in feet or meters?
    [Question raised regarding whether the Air France Airbus was at 30
    feet or 30 meters...]

Unless I am greatly mistaken, in feet.  Altitudes and airspeeds are not
quite the same situation as fuel volumes.  The latter are a matter for
individual aircraft; the former are of vital interest to air traffic
control and other aircraft, and units are internationally standardized
(altitude in feet, airspeed in knots).  I wouldn't even expect readouts
in both units, because altitude and airspeed are safety-critical items
and even the slightest confusion about which number is which is unacceptable.

It's kind of unfortunate that aviation standardized on units that are now
obsolete, but this is one of those cases where the actual units are not
very important so long as they're standard.  For navigation one needs to
turn airspeed into map distance, and for the initial phase of takeoff and
the final phase of landing the absolute altitude is significant, but
otherwise comparisons are usually relative and the units of measurement
don't matter much.  For example, what matters about airspeed is not its
absolute value, but its value relative to safe limits, optimal values
for the particular phase of flight, and the value requested by traffic
control.  Even near-ground altitudes are relative to some degree:  50 feet
of altitude is a good takeoff-obstacle clearance for a Cessna, a dangerously
small one for a 747 (which can't do a hard turn without sticking a wing
down farther than that), and a routine operating altitude for military
aircraft in wartime.
				  Henry Spencer at U of Toronto Zoology
				uunet!mnetor!utzoo! henry @zoo.toronto.edu

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: Physical hazards - poorly designed switches
</A>
</H3>
<address>
John Robert LoVerso 
&lt;<A HREF="mailto:loverso%encore@multimax.ARPA">
loverso%encore@multimax.ARPA
</A>&gt;
</address>
<i>
Mon, 11 Jul 88 16:01:50 EDT
</i><PRE>

Dave Curry relates of some problems with a CCI Power 6/32:
&gt; CCI also cleverly placed the "reboot" switch, an up/down toggle, on the
&gt; front of the cabinet, not recessed, and at knee level.  Fortunately,
&gt; UNIX seems to ignore the switch.

At SUNY/Buffalo, the Sperry 7000/40 there that I had running 4.3BSD-tahoe
beta did respond to that switch (I remember leaning over the front of the
processor once, only to end up rebooting it).

That machine suffered my worst abuse.  To the left of the front reboot switch
was the key switch for local/locked/off.  I once knocked into it, only to break
the end off of the key.

CCI also used a clever placement strategy with the "emergency shutoff"
switch, a large red push button.  This was on the back of the cabinet,
extending out 1" at waist level.  Pressing this would trip the main breaker
for the CPU and disks.  It was easy to lean on this button and then suddenly
notice the quiet in your end of the machine room.  Unfortunately, this
machine was far from the VAXen in the room, and behind it was one of the
quieter locales in the machine room, so I frequently stood in that area
while talking to people.  And, more than once, I accidentally hit that switch.

One day, I was imparting upon the field service tech how poorly designed
this switch was (and he was telling me how it was required by law to have
an easily accessible emergency cutoff?!) when I (accidentally) leaned on
darned thing again.

The very next day I took the mounting bracket apart and replaced it in such
a way that the switch was recessed 1" into the cabinet.  Never again did I
hit it accidentally.

Henry Spencer tells of a chair that liked RK05s.  I was told a story about
CU/Boulder, where they used to use munchkins (12 year olds) to do dumps.
They had the familiar RA81/TU80 combinations common to VAX 11/750s, where
the RA81 controls are about 18" from the ground.  One particular short
munchkin had the problem of repeatedly off-lining the drive while mounting
the tape to dump it.  As with Henry's chair, he was replaced by someone taller.

John R LoVerso, Encore Computer Corp

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 PIN on PNB calling card
</A>
</H3>
<address>
Mark Mandel 
&lt;<A HREF="mailto:Mandel@BCO-MULTICS.ARPA">
Mandel@BCO-MULTICS.ARPA
</A>&gt;
</address>
<i>
Mon, 11 Jul 88 09:26 EDT
</i><PRE>

Scott Peterson's reaction to Pacific Northwest Bell's encoding his
calling card PIN in the magstripe is simply to "hit [his] card with a
bulk tape eraser, and forget about using card reader phones until PNB
straightens this out".  Scott, have *you* called PNB's attention to this
monumental piece of stupidity?  Has anyone?  Or do you trust the same
crew that implemented this un-security measure to realize their mistake
unaided and take the initiative to correct it?  "Marketing sez the
customers want the convenience, and they haven't gotten any complaints,
so if it ain't broke [i.e., not causing us any grief] don't fix it."

                                        -- Mark Mandel

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Lockpicking
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Sat, 9 Jul 88 23:45:42 EDT
</i><PRE>

&gt; Should I spend a fortune replacing the locks on my house, or are the risks
&gt; low that a burglar will pick the locks?

A local insurance outfit might be able to tell you what the incidence of
such things is locally.  Do beware of one complication:  since picking
leaves no major physical traces, it is a convenient scapegoat for cases
where the *real* problem was the owner's carelessness.  Orthodox wisdom
is that most "burglar picked the lock" cases are really "burglar had a key"
or "door was not locked".

My understanding is that picking is perceived as difficult and possession
of lockpicks (aka "burglary tools") is perceived as too likely to be
incriminating.  I would be surprised if Arizona didn't have a possession-
of-burglary-tools law; before spending a fortune on locks, spend a
little asking a lawyer about this.  (Local officials are notorious for
being uninformed about the laws they are supposed to enforce, so I wouldn't
put too much faith in the negative results you got by asking them.)

Henry Spencer @ U of Toronto Zoology  {ihnp4,decvax,uunet!mnetor}!utzoo!henry

</PRE>
<HR><H3><A NAME="subj8.2">
     lockpicking
</A>
</H3>
<address>
Robert Mathiesen 
&lt;<A HREF="mailto:SL500000%BROWNVM.BITNET@MITVMA.MIT.EDU">
SL500000%BROWNVM.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 11 Jul 88 08:37:45 EDT
</i><PRE>

Apropos of Randy D. Miller's surprise that information on lockpicking is so
readily available, I cannot resist quoting Charles Tomlinson's Rudimentary
Treatise on the Construction of Locks, published about 140 years ago.  His
words are also relevant to much of the discussion on computer security which
has gone on in this Forum.

"A commercial, and in some respects a social, doubt has been started within the
 last year or two, whether or not it is right to discuss so openly the security
 or insecurity of locks.  Many well-meaning persons suppose that the discus-
 sion respecting the means for baffling the supposed safety of locks offers a
 premium for dishonesty, by showing others how to be dishonest.  This is a fal-
 lacy.  Rogues are very keen in their profession, and already know much more
 than we can teach them respecting their several kinds of roguery.  Rogues knew
 a good deal about lockpicking long before locksmiths discussed it among them-
 selves, as they have lately done.  If a lock -- let it have been made in what-
 ever country, or by whatever maker -- is not so inviolable as it has hitherto
 been deemed to be, surely it is in the interest of *honest* persons to know
 this fact, because the *dishonest* are tolerably certain to be the first to
 apply the knowledge practically; and the spread of knowledge is necessary to
 give fair play to those who might suffer by ignorance.  It cannot be too ear-
 nestly urged, that an acquaintance with real facts will, in the end, be better
 for all parties.  Some time ago, when the reading public was alarmed at being
 told how London milk is adulterated, timid persons deprecated the exposure, on
 the plea that it would give istructions in the art of adulterating milk; a
 vain fear -- milkmen knew all about it before, whether they practised it or
 not; and the exposure only taught purchasers the necessity of a little
 scrutiny and caution, leaving them to obey this necessity or not, as they
 pleased.  .....  The unscrupulous have the command of much of this kind of
 knowledge without our aid; and there is moral and commercial justice in plac-
 ing on their guard those who might possibly suffer therefrom.  We employ
 these stray expressions concerning adulteration, debasement, roguery, and so
 forth, simply as a mode of illustrating a principle -- the advantage of pub-
 licity.  In respect to lock-making, there can scarcely be such a thing as dis-
 honesty of intention: the inventor produces a lock which he honestly thinks
 will possess such and such qualities; and he declares his belief to the world.
 If others differ from him in opinion concerning those qualities, it is open
 to them to say so; and the discussion, truthfully conducted, must lead to
 public advantage: the discussion stimulates curiosity, and curiosity stimu-
 lates invention.  Nothing but a partial and limited view of the question
 could lead to the opinion that harm can result: if there be harm, it will be
 much more than counterbalanced by good."

The subsequent development of lockmaking in the course of the next 140 years
has long since demonstrated the correctness of  Tomlinson's argument in his
own field.  I do not doubt that it is equally applicable in the area of com-
puter security.

</PRE>
<HR><H3><A NAME="subj8.3">
re: lockpicking and burglars
</A>
</H3>
<address>
Doug Faunt (phone (415) 496-4727) 
&lt;<A HREF="mailto:faunt@spar.slb.com">
faunt@spar.slb.com
</A>&gt;
</address>
<i>
Fri, 8 Jul 88 22:44:02 PDT
</i><PRE>

I would like to point out that it might be worthwhile to improve your
locks to some degree, since an intruder who picked the lock probably
wouldn't leave any evidence of the intrusion, and at least one of my
insurance policies DOES NOT cover, "mysterious disappearance".  You may
not be able to keep them out, but you can make sure there's a record.
This has obvious applicability to computer security measures.

        ...{amdahl|decwrl|hplabs}!spar!faunt    faunt@spar.slb.com

</PRE>
<HR><H3><A NAME="subj8.4">
Lockpicking 
</A>
</H3>
<address>
&lt;<A HREF="mailto:"chaz_heritage.WGC1RX"@Xerox.COM">
"chaz_heritage.WGC1RX"@Xerox.COM
</A>&gt;
</address>
<i>
7 Jul 88 09:31:26 PDT (Thursday)
</i><PRE>

In his Tue, 5 Jul 88 09:44:06 MST Randy D. Miller writes:

&gt;I called some city and state offices, and one local locksmith, to see
if there are any laws regulating the possession and use of lockpicks in
Arizona.  No one I talked to seemed to know anything about any regulations!&lt;

I feel that I ought to ask the Phoenix, Arizona Police Department how they would
feel about searching Mr. Miller's home for &gt;$0.99 hacksaw blades and a Dremel
Tool grinder&lt;.

Exactly this 'ban it all' attitude is very prevalent in UK. If someone is
murdered with a knife, the media howl for all knives to be 'banned'. What they
should howl about is that someone is motivated to murder - not that someone who
was so motivated chose a particular instrument.

Or perhaps Mr. Miller would be happy to live under a law that prohibited
possession of lockpicks - or the means to make them - or the knowledge of how to
make them........

Chaz Heritage

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.19.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.21.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-62</DOCNO>
<DOCOLDNO>IA012-000129-B047-385</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.21.html 128.240.150.127 19970217022156 text/html 25894
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:20:24 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 21</TITLE>
<LINK REL="Prev" HREF="/Risks/7.20.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.22.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 21</H1>
<H2>  Tuesday 12 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
$54.1 million embezzlement foiled 
</A>
<DD>
<A HREF="#subj1.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Aegis 
</A>
<DD>
<A HREF="#subj2.1">
DAve Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Iran Air Incident 
</A>
<DD>
<A HREF="#subj3.1">
Bob McKay
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "Binary thinking" misses a lot 
</A>
<DD>
<A HREF="#subj4.1">
Bob Estell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Automatic Air Traffic Control 
</A>
<DD>
<A HREF="#subj5.1">
Eldred
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Aviation units of measure 
</A>
<DD>
<A HREF="#subj6.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Mouse trap 
</A>
<DD>
<A HREF="#subj7.1">
James H. Coombs
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Threshold probability for declaring a radar blip "hostile"    
</A>
<DD>
<A HREF="#subj8.1">
Mike Wellman
</A><br>
<A HREF="#subj8.2">
 Clifford Johnson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
$54.1 million embezzlement foiled
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>
Tue, 12 Jul 88 11:22:11 EST
</i><PRE>

System Crash Fails Swiss Bank Theft     (Information Week, July 11, 1988)

   Only a chance system crash prevented an attempted computer crime from
becoming Britain's, and possibly Europe's, largest recorded theft.  A
manager at the London branch of the Union Bank of Switzerland issued an
instruction to transfer 82 million Swiss francs ($54.1 million) to a branch
of Credit Suisse in Lyon, a small town near Lausanne.  The payment
instruction was sent via the Swift international interbank network, which
handles nearly a million payment messages per day.
   A computer breakdown at the Swiss end apparently forced the bank staff to
make manual checks of payment instructions that would normally be processed
automatically.  Suspicions were aroused, and Swiss police were waiting to
pounce on the man who arrived to collect the cash.  Two men have been
arrested in Switzerland, in addition to the London-based, British employee
of UBS.
   Swift officials in Brussels emphasized that the security of the network
had not been compromised, and that what happened was not strictly a computer
crime.  Genuine computer crimes, in which a secure operating system is
breached by an outsider to effect fraudulent transactions, are thought to be
rare.  [sounds like a rather "convenient" definition to me... -Dave]
   More common, and more worrisome to large financial service companies, are
cases in which fraudulent transaction instructions received on paper are
entered into systems as if they were genuine.  The Swift network then has no
way of knowing it is carrying a fraudulent transaction.
   Protection against these crimes relies on the fact that each transaction
is supposed to be ratified by a number of people in different locations.
Collusion among several managers would be required for these frauds to
succeed.  In this case, however, it appears that security at UBS was
inadequate: It should not have been possible for one man to enter a
fraudulent transaction of such high value [meaning that he should have
been able to enter one of lesser value? -Dave] into the Swift network even if
it appeared to have come from a genuine telegram ordering payment.

					- Philip Hunter, London

--Dave Curry, Purdue University

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Aegis 
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>
Tue, 12 Jul 88 11:22:11 EST
</i><PRE>

Aegis System At The Heart Of Vincennes Investigation
(Information Week, July 11, 1988)

   Unanswered questions about the Persian Gulf engagement in which the U.S.
Navy cruiser Vincennes shot down an Iranian jetliner have focused attention
on the Navy's Aegis automated weapon system.  Aegis is widely considered one
of the most sophisticated uses of automation in the armed forces.  Vice
Admiral Joseph Metcalf III, Deputy Chief of Naval Operations, has referred
to it as "Star Wars at sea."
   Part of Aegis' uniqueness is that, like SDI, Aegis is more a concept than
a specific weapon system.  It was developed by RCA's Missile and Surface
Radar unit under a contract to synthesize a weapon system capable of
fighting air, surface, and submarine threats simultaneously.
   Aegis combines input from four phased-array radars (which employ hundreds
of tiny radar beams to scan the entire horizon without causing the gaps in
surveillance created by rotating dish radars) - using UYK-7 computers
manufactured by Unisys - to create a graphic display of all air, surface,
and subsurface targets on video screens in the ship's combat information
center (CIC), including information on the target's speeds and direction.
The radars scan an area that reaches out in all directions from the ship in
the shape of a bowl or shield, hence the name Aegis.
   The ship's sensors also track whether the target is friend or foe,
neutral, or assumed friend or foe, based on visual identification or
encrypted electronic signals.  All of this information - tracks, data,
displays - and almost all communications in or out of the ship's CIC is
automatically recorded in Aegis' computer.
   This is the data Navy investigators will examine when they attempt to
discover what went wrong on the Vincennes.  Although Secretary of the Navy
John Lehman has referred to Aegis as "the most carefully tested combat
system ever built," the system was deliberately designed for human input -
VISUAL IDENTIFICATION OF TARGETS, OPERATOR ASSIGNED FRIEND-OR-FOE STATUS
[emphasis mine], and operator selected targets - and is, thus, subject to
human error.
					- Christpher Hord

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Iran Air Incident
</A>
</H3>
<address>
Bob McKay
&lt;<A HREF="mailto:munnari!cs.adfa.oz.au!rim@uunet.UU.NET ">
munnari!cs.adfa.oz.au!rim@uunet.UU.NET 
</A>&gt;
</address>
<i>
Tue, 12 Jul 88 13:25:50 EST
</i><PRE>

Much of the commentary on this incident treats it as 'a land far away in a time
long ago'; it's not - it's an immediate question not just for Iran, but the
whole of SE Asia and Australasia: ALL the traffic between here and Europe
overflies the Gulf, much of it staging through Bahrein or Dubai. Until now that
hasn't worried me much - a 747 at 25,000 plus feet ought to be safe, so I
thought.  But now I wonder - could a DC10 on its final descent into Dubai on an
unpredicted track - perhaps avoiding a storm - look like an attack on US
vessels? What if an Iranian Mirage had accidentally crossed its track earlier?
Even scarier, what if that Mirage deliberately followed it in? Seems like a
reasonable way to get closer to the task force vessels. Improbable? So is the
present story on mistaking an airbus for an F14.  The point is, this was not
just an unlucky worst case event; it was actually one of the better possible
scenarios from the US point of view - imagine if it had been an Air India or
Qantas jet that was downed.  The US forces in the Gulf seem to be in a
virtually impossible situation.  They cannot afford to assume the best - that a
target is innocuous until proven otherwise; they also cannot afford to assume
the worst - that a target should be blasted unless proven friendly. On the
other hand, the airlines involved don't have much alternative either as there
are no other corridors available. Further disasters don't seem unlikely from
here.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
"Binary thinking" misses a lot
</A>
</H3>
<address>
"FIDLER::ESTELL" 
&lt;<A HREF="mailto:estell%fidler.decnet@nwc.arpa">
estell%fidler.decnet@nwc.arpa
</A>&gt;
</address>
<i>
12 Jul 88 08:04:00 PDT
</i><PRE>

I believe we've previously discussed the "RISKS of 'binary' thinking" in
this forum; i.e., recognizing only dichotomies - one/zero, right/wrong ...  
Our computer thinking - which we sometimes use to debug code - 
encourages that; ditto our legal system.

In defense of CAPT Will Rogers, I spoke of tragedy; I'd bet that Will
agrees with that conclusion.  I'd also guess that he would agree with
George Will ["This Week with David Brinkley", ABC, Sunday 10 Jul 88]
that his actions were "... morally defensible under the circumstances;"
BUT that he would not dispute Sam Donaldson's point [ibid.] that the
outcome was NOT morally desirable.

Some readers of this journal did not see me blame the USN, so they assumed
that I found the "fault" with the Iranians.  In fact, I found no fault;
if I had, I think I would have suggested we debate the methods [at least,
and perhaps motives, too] of those who put USN warships in "harm's way"
without bothering to declare war.  If others want to pursue that debate,
then I suggest we move it to ARMS-D.  [arms-d@xx.lcs.mit.edu]

In RISKS, I suggest we have a hard look at the generic problem of doing systems
- offensive, defensive, process monitoring, banking ... that ordinarily have,
historically, used "binary logic" when indeed they probably ought to evolve
into "expert systems" that use NOT ONLY classical logic [e.g., Boolean] BUT
ALSO [occasionally] "fuzzy logic."  This discussion might quickly spread to
include "neural network" kinds of logic, in which the failure of several bits
[gates] has only slight impact on the outcome, perhaps not even noticeable.

Bob

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Automatic Air Traffic Control
</A>
</H3>
<address>
&lt;<A HREF="mailto:eldred@apollo">
eldred@apollo
</A>&gt;
</address>
<i>
Mon, 11 Jul 88 20:52:37 EDT
</i><PRE>

Considering the discussion about the Iranian A300 incident, I wondered about
the implications of current efforts to automate air traffic control.  Perhaps
if the Iranian ATC and the US Navy Aegis system were fully automated then
the chances of an unfortunate incident happening might have been different?
This article tells of current US plans in that area:
                                                                          
FAA BEGINS PLAN TO FULLY AUTOMATE ATC FUNCTIONS
[ from Aviation Week &amp; Space Technology, June 27, 1988, p 73 ]
[ used without permission ]

SALT LAKE CITY--FAA Administrator Allan McArtor has begun a three-phase plan
to progressively automate air traffic control functions that eventually
would automate most functions and limit human controllers to supervisory and
emergency functions.

In a speech here dedicating the last of the FAA's 20 Host ATC computer
systems, McArtor said the automated network would rely on computers and
satellite tracking to choose the best, safest and most fuel- and
time-efficient routes for aircraft.  It would also space them more
efficiently than human controllers can.

The agency already is working on Phase 1 of the automated en route air
traffic control system (AERA) plan, McArtor said.  When functional, this
computer software upgrade will allow controllers to evaluate routes
requested by pilots for potential conflicts with other aircraft, prohibited
airspace and flow control restrictions.

The second phase, scheduled to be operational by the late 1990s, would give
controllers several solutions to traffic problems.  Any route chosen by the
controller would be communicated automatically to the aircraft by digital
data link.

The final part of the AERA plan--and admittedly the most ambitious, McArtor
said--would upgrade air traffic control software to allow totally automatic
air traffic operations.  Computers would detect and resolve traffic control
problems, make decisions, and offer clearances to aircraft without human
intervention.  However, air traffic still would be supervised by humans, 
McArtor said....

Satellite tracking and communications technology will be key to the AERA
effort and future ATC system modernization, McArtor said

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Aviation units of measure
</A>
</H3>
<address>
Joe Morris (jcmorris@mitre.arpa) 
&lt;<A HREF="mailto:jcmorris@mitre.arpa">
jcmorris@mitre.arpa
</A>&gt;
</address>
<i>
Mon, 11 Jul 88 21:32:15 EDT
</i><PRE>

Discussing the question of the altimeter display in the Airbus involved in the
flyby crash in France in RISKS 7:20, Henry Spencer comments:

&gt;&gt; Does the Airbus model in question display altitude in feet or meters?
&gt;    [Question raised regarding whether the Air France Airbus was at 30
&gt;    feet or 30 meters...]
&gt;
&gt;Unless I am greatly mistaken, in feet.  ...

At the risk of a case of foot-in-mouth disease (since I have no experience
flying as a crewmember in Europe), my Jeppesen manuals (flying charts)
seem to contradict Henry's comment.  The following is extracted from the
Jeppesen J-Aid, "Tables and Codes" section, pp. 27-30 (dated 26 February 88):

UNITS OF MEASUREMENTS TO BE USED IN AIR AND GROUND OPERATIONS

So that there would be no misunderstanding as to what units of measure (as
mitres or feet) were used in each country, the International Civil Aviation
Organization (ICAO) provided a recommended table from which countries could
choose either the table labeled "ICAO" or the table labeled "Blue".

In 1979, ICAO revised Annex 5 and replaced the "ICAO or Blue" choice with
"International Standard" (SI) and non-SI.  
[...]
[excerpts from the definition matrix:]

  Measurement of:           ICAO             Blue                SI      non-SI
  ---------------           ----             ----                --      ------

  Distances used in         Nautical miles   Nautical miles      km       nm
  navigation reports        and tenths       and tenths
 
  Relatively short          metres           metres              m
  distances

  Altitudes, elevations     metres           feet                m        ft
  and heights

[...]
Dimensional units to be used in air/ground communications applicable for
the following countries or FIRS: [excerpts]

France:         ICAO (8) (60)
Switzerland:    SI/non-SI
United Kingdom: Blue (63)
United States:  Blue (33)

[Relevant footnotes:]

(8)  Altitudes and heights on IAL charts in feet
(33) Relatively short distances in feet [...]
(60) [...]
(63) [...]

There are presently 69 footnotes explaining non-standardized measurements.
The international aviation community, in other words, doesn't have the
universal system of measurements which would be nice for everybody, and it's
not at all unlikely that some pilots could become mixed up over a readout.

On the other hand, anyone who would fly a transport with passengers aboard
on a low pass without significant experience at the controls of that 
make-and-model...

Joe Morris (jcmorris@mitre.arpa)

-----------------------------

Date:         Tue, 12 Jul 88 14:19:49 EDT
From: "James H. Coombs" &lt;JAZBO%BROWNVM.BITNET@MITVMA.MIT.EDU&gt;
Subject:      Mouse trap

A user posted this notice on our bulletin board:

    Subject:  Mouse Injury
    Category:  Computer hazard
    Text:  Add another to the list of computer-induced medical problems.
    In frantic, last 8 days before publication haste I used the mouse
    madly in formatting the handbook for employees, and managed to
    inflame the joint of my index finger so thoroughly that I'm now in a
    splint and taking nasty pills.  Had I known this could cause a
    problem, I'd have used keyboard commands whenever possible, as I
    normally do.  [...]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Threshold probability for declaring a radar blip "hostile"
</A>
</H3>
<address>
Mike Wellman 
&lt;<A HREF="mailto:MPW@ZERMATT.LCS.MIT.EDU">
MPW@ZERMATT.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 9 Jul 88 12:05 EDT
</i><PRE>

Clifford Johnson asks,

    ...at what perceived "odds" -- 50-50, 60-40, 90-10 ? -- does a
    commander have "sufficient cause" to "declare" a radar blip, that
    might be hostile or might be a commercial flight, officially
    "hostile," so as to shoot it down?

The short answer is that there is no such threshold probability.  The
question presumes the the commander faces a one-shot shoot/no-shoot
decision to be taken on the basis of information assessed at an instant
in time.  More realistically, the commander's options at any instant t
are (1) shoot, and (2) wait an increment delta-t and decide again at
t + delta-t.  During that interval, the ship is either attacked or it
gains further information about the blip (the mere absence of an attack
counts as information).  The "shooting threshold" depends on the time t,
the likelihood of attack during the next delta-t, and the prospects for
collecting further information in the subsequent time intervals.  In the
general case, the threshold can behave arbitrarily over time.

If we insist on framing this as a one-shot decision, the commander has
two options and there are two basic states of nature distinguished by
whether the blip is an F14 or a civilian aircraft.  Thus, there are four
possible consequences: 

C1 - (shoot, F14)
C2 - (shoot, civilian)
C3 - (no shoot, F14)
C4 - (no shoot, civilian)

I suspect that even ranking these consequences by desirability will be
controversial, except that C1 and C4 are obviously preferred to C2 and
C3.  Let du(F14) be the difference in utility between the better and
worse actions given the blip is an F14.  That is, 

  du(F14) = u(C1) - u(C3), and similarly let
  du(civ) = u(C4) - u(C2).

The one-shot decision recommended by this simple model is to shoot iff
the probability that the blip is an F14 is greater than p*, where

  p* = du(civ) / [ du(civ) + du(F14) ].

Note that p* = 1/2 exactly if du(civ) = du(F14), that is if the
differences between the "wrong" and "right" actions are the same for
both possible states.  The threshold is greater or less than 1/2 as the
civilian or F14 consequences are considered relatively more or less
significant.  It should also be emphasized that these terms are not
simply "the value of civilian versus military lives."

Again, this model is outrageously simplistic because it entirely ignores
the dynamic nature of the actual decision and the important role of
prospective information.

Johnson's second question is

    given the shortness of the response time, what could be the best
    odds attainable in a realistic attack scenario, even assuming the
    best computer technology the United States could field?

There are no general limits to the extremity of the posterior odds,
regardless of technology, simply because the priors can be arbitrarily
extreme.  In particular situations, however, limitations of the sensing
technology do bound the final assessment.

--Mike Wellman.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Threshold probability for declaring radar blip "hostile" 
</A>
</H3>
<address>
Clifford Johnson 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Sun, 10 Jul 88 13:44:59 PDT
</i><PRE>

&gt;      ...at what perceived "odds" -- 50-50, 60-40, 90-10 ? -- does a
&gt;  The short answer is that there is no such threshold probability...

Yes and no, mostly no.  Time passes, and in all circumstances what you say
holds true only until a "use them or don't use them" decision deadline dictated
by the particular threat perceived.  After this time, the intended defense is
ineffective.  Curiously, in the Iran shootdown it has been reported that the
decision came a little late, which perhaps suggests that the Captain panicked
just when the flight turned towards its center corridoor, which happened to be
in the direction of the ship.  This would mean that the flight was shot down
*because it responded* to the strident warnings.  If the threat of missile
attack had been usual (supposing arguendo that F-14's could deliver missiles),
the plane would have been hit after it had released its missiles.

I don't contest your game theory -- such utilities are increasingly being
incorporated into online military battle managers.  In the envisaged naval
battle management system, the decision would presumably be recommended in such
utilitarian terms to the Captain or remote Admiral.  This means that such
values as we have speculated about really are being written into military
hardware that actually or virtually executes its own Rules of Engagement.  I
shudder.

&gt;      given the shortness of the response time, what could be the best
&gt;      odds attainable in a realistic attack scenario, ...
&gt;  There are no general limits to the extremity of the posterior odds, ...
&gt;  In particular situations, however, limitations of the sensing technology
&gt;  do bound the final assessment.

The final point counts, I agree, but an uncontrolled risk-amplification may in
general occur in real-time guestimation of the background or a priori
probabilities of a threat.  Calling an alert, or issuance of a strategic
warning, which is what the Gulf forces got over the July weekend, does exactly
that, it vastly distorts a priori probabilities.  And I say "distort" with
academic rigor, for it is a well-proven tenet of war that a strategic warning
is highly unreliable but easy to believe.  Just like a sale isn't final until a
check is signed, or rather, until the computers say so, so hostilities may not
occur until a first shot is fired, or rather, until the computers say so.  Then
the firing of the first shot then places a priori odds beyond reason,
permitting a commander to see threats even from directions that shots have not
been fired from.

Clearly, it is in everyone's interests that a priori probabilities of conflict
are not unreasonably figured.  Without questioning good military intentions, I
am concerned that the likelihood of civilian deaths features insufficiently in
the U.S.  Rules of Engagement.  Witness the destruction of a mental hospital in
Grenada, of many civilians in the Libyan raid, and now of a civilian jet -- and
so far, the military has not been faulted for any of these mishaps, on the
basic grounds that civilian deaths were due to tragic technical glitches
tolerable in the circumstances.

I am most concerned that the nuclear SIOP implicitly contains a priori
estimates of threat probabilities which are unreasonably boosted to protect the
Air Force and the defense establishment.  This in effect devalues civilian
consequences, and heigthens the danger.  And yet the nuclear hair-trigger is so
unopposed that the Strategic Air Command is *celebrating* 1988 as "The Year of
the SAC Alert Force," in commemoration of the 30-year-old alert called for
SAC's bombers on October 1, 1957.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.20.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.22.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-63</DOCNO>
<DOCOLDNO>IA012-000129-B047-403</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.22.html 128.240.150.127 19970217022205 text/html 23396
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:20:37 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 22</TITLE>
<LINK REL="Prev" HREF="/Risks/7.21.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.23.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 22</H1>
<H2>  Thursday 14 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A-320 Airbus Crash Inquiry 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  User interface problem in the Aegis system? 
</A>
<DD>
<A HREF="#subj2.1">
Kee Hinckley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Radar cross sections, Flt. 655, and F-14s 
</A>
<DD>
<A HREF="#subj3.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  GM Blames Computer for Smelly Vans 
</A>
<DD>
<A HREF="#subj4.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Lockpicking at Los Alamos 
</A>
<DD>
<A HREF="#subj5.1">
Gary McClelland
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Supposedly-unique id. no. from non-unique personal characteristics    
</A>
<DD>
<A HREF="#subj6.1">
Larry Margolis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  NJ Driver's license number coding 
</A>
<DD>
<A HREF="#subj7.1">
Scott Robbins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Colwich Junction, England, 1986 
</A>
<DD>
<A HREF="#subj8.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Shades of Fantasy in Real-Life -- group games 
</A>
<DD>
<A HREF="#subj9.1">
acwf?
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  IQ measurement by machine? 
</A>
<DD>
<A HREF="#subj10.1">
Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Aviation units 
</A>
<DD>
<A HREF="#subj11.1">
Richard S. D'Ippolito
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  RISKS and PGN Saturation! 
</A>
<DD>
<A HREF="#subj12.1">
PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A-320 Airbus Crash Inquiry
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Tue, 12 Jul 88 21:31:25 +0100
</i><PRE>

Today's Guardian carried a story with a new and alarming slant. It
is reprinted here in toto, without permission.

AIRBUS INQUIRY OBSTACLES FUEL COVER-UP FEARS

[By] Paul Webster in Paris

An attempt to stop an examining magistrate investigating the cause of the
A-320 airbus crash in eastern France last month has raised doubts over
official claims made immediately after the crash that pilot error was the only 
cause.

Mr Germain Sengelin, the senior examining magistrate at Mulhouse, defied
a Justice Ministry order yesterday to drop a judicial inquiry and said that
he could understand that there was official concern that "the search for
truth was being placed above other interests."

The magistrate was told to hand over the inquiry to a judge but continued
questioning witnesses. He was concerned that the Airbus's two flight
recorders were taken away after the crash by Transport Ministry officials.
He said the recorders had not been sealed to "guarantee their authenticity
and integrity."

He was also angry that the local public prosecutor, who is responsible to 
the Justice Ministry, had already decided that pilot error was the cause
of the crash which killed three passengers during an aero-club joyride
flight. More than 130 other people escaped when the low-flying Air France
chartered jet crashed into a wood.

Air crew trade unions have also stepped up their protest over the plane's
dependence on a revolutionary computer fly-by-wire system operated by a
two-man crew. The air crews, who believe a flight engineer is needed to
oversee the ultra-modern equipment which is supposed to correct pilot
error, said there was a moral question involved. The policy of a two-man
flight crew was putting passenger lives in danger. Pilots on France's
domestic airline, Air Inter, began a new strike last night as part of a
three-year campaign over Airbus safety.

With the judicial and Transport Ministry inquiries, there are three
investigations being made into the accident, the third being by Air France.

But before any investigating team was able to give a point of view, the flight
recorders had been analysed by civil aviation officials and the main finding
revealed by the Transport Minister at the time, Mr Louis Mermaz.

He ruled out any possible fault in the plane's design and blamed the pilot.
As the Airbus is Europe's main challenger to US civil aviation supremacy,
Mr Mermaz was concerned that doubts over the computer system could affect
orders from more than 50 airline companies for about 500 A-320s which
sell for about (pounds)20 million.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
User interface problem in the Aegis system?
</A>
</H3>
<address>
Kee Hinckley 
&lt;<A HREF="mailto:nazgul@apollo.com">
nazgul@apollo.com
</A>&gt;
</address>
<i>
Wed, 13 Jul 88 10:47:46 EDT
</i><PRE>

Something mentioned briefly in newsweek's analysis of what happened is that the
display system does not show the actual radar blip, but rather an icon which
indicates information about the object (under/on/above water and
friendly/unknown/ enemy).  Although at the 20 mile range there would be no
difference in blip size, they asserted that a dumber radar system might have
seen a difference at the distance at which missles were fired.  If this is true
it is a good example of an instance where switching to a symbolic display
resulted in a loss of potentially critical information.

(Of course the blip size is still not a good indication of aircraft type, given
reflectivity differences, but any bit of information can help.)

Kee Hinckley, User Environment, Apollo Computer Inc.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Radar cross sections, Flt. 655, and F-14s
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@amelia.nas.nasa.gov">
eugene@amelia.nas.nasa.gov
</A>&gt;
</address>
<i>
Thu, 7 Jul 88 20:06:23 PDT
</i><PRE>

Please do not mistake the visual cross-section of a target to equal a radar
cross-section.  Radar is a less than exact science, all cross-sections are
determined empirically with a anechoic chamber.

A good example to understand this is the B-52, which comes with a drone called
a Quail.  The Quail is a tiny fraction of the B-52's size but is designed to
give an identical signature (not quite).  Several radar references include a
recent Spectrum article on radar cross-sections (the IEEE will now probably do
A320 and 655 article as they did they award winning Stark article).  There is
also Skolnick's book on radar.

Current thinking is also based on active transponders, not on cross-section.

--eugene miya,   NASA Ames

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
GM Blames Computer for Smelly Vans
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Thu 14 Jul 88 11:29:44-PDT
</i><PRE>

(UPI) Detroit
  Owners of some General Motors vans have been advised not to blame a
rotten-egg smell on their companions but rather on the vehicles' computer.
  GM has discovered that under certain conditions, 1987 Chevrolet Astro and
GMC Safari vans with 4.3 liter engines and overdrive transmissions spew an
exhaust with the unmistakable smell of rotten eggs.
  The company has issued a bulletin to dealers with instructions on how to fix
the problem.  Among the remedies is replacement of the computer, which
monitors the engine's fuels mix.
  The computer in question is used only in vans with overdrive transmission,
the Detroit News was told by a GM service technician.  An improper fuel mix
results in the buildup of a sulfur and hydrogen mixture, causing the odor, the
technician said.  [San Francisco Chronicle, 14 July 1988, p. A11]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Lockpicking at Los Alamos
</A>
</H3>
<address>
Gary McClelland 
&lt;<A HREF="mailto:MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU">
MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU
</A>&gt;
</address>
<i>
Tue, 12 Jul 88 09:08 MDT
</i><PRE>

   Anyone interested in the recent discussion of lockpicking and security
would enjoy reading Richard Feynman's hilarious chapter on his
lockpicking adventures at Los Alamos during the bomb building days.  The
chapter is in his collection of autobiographical stories entitled "Surely
You Must be Joking, Mr. Feynman.  Reproducing excerpts here would spoil
the fun.  If the locks to the atomic secrets were so easy to pick it is
hard to imagine what system would be required to guarantee no burglars get
in the house.  Just keep the insurance premiums paid and make it look like
your house would be a bit more troublesome than the neighbor's.
   Gary McClelland (Univ of Colorado)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
supposedly-unique id. no. from non-unique personal characteristics
</A>
</H3>
<address>
Larry Margolis 
&lt;<A HREF="mailto:MARGOLI@ibm.com">
MARGOLI@ibm.com
</A>&gt;
</address>
<i>
12 Jul 88 12:31:37 EDT
</i><PRE>

New York State also encodes the driver's sex and date of birth in the
driver's license number.  The reason for this is that a police officer can
do a quick check to tell if the license is invalid.  (No guarantee that it's
valid, of course, but if the DOB on the license doesn't match the encoded
version, or the sex isn't encoded properly, you know that it's invalid.)

Larry Margolis

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
 NJ Driver's license number coding
</A>
</H3>
<address>

&lt;<A HREF="mailto:SROBBINS%DREW.BITNET@CUNYVM.CUNY.EDU">
SROBBINS%DREW.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Mon, 11 Jul 88 16:41 EDT
</i><PRE>

tab@mhuxu.att.com writes:
&gt;  I had to laugh at "The Eyes Have It".  The last five digits of my NJ
&gt;driver's license number are 61664.  This is supposed to represent my
&gt;date of birth and eye color.  I was born on 11-22-66, and the last time
&gt;I checked my calendar, we didn't even have 61 months!

On NJ driver licenses, the first 4 of the last 5 digits are always the month
and date you were born.  If you were born in October, November, or December,
the first '1' is replaced by a '6' , hence 6166 for those four digits on
your license.  I *think* this is always the case for people born in those
three months; other numbers might be used in place of the '1'.  My mother
was born in October, and the numbers on her license are 60422 for the last
five digits.  The last number on your license is your eye color; if you have
a picture license, the codes for numbers and eye colors are on the back of
the license card.  You might also note that of the second group of 5 digits,
the first two should be '66' in your case, because you were born in 1966.
The reason for doing all of this is because NJ picture driver's licenses are
very easy to alter for ID purposes (to buy alcohol, etc.) - so the DMV
figured they'd get smart and build the birthdate into the DL number.  Except
now everyone knows the secret and it's pretty useless.  I believe all the
numbers on a license mean something --&gt; another thing they try to protect
against is people replacing the picture with another (also very easy on a NJ
picture license).

Scott Robbins   SROBBINS@DREW.BITNET

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Colwich Junction, England, 1986
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Wed, 13 Jul 88 18:20:35 EDT
</i><PRE>

The official report on a train collision* at Colwich Junction, England,
on September 19, 1986, has been released and is written up in the June
issue of Modern Railways magazine.  There are two RISKS-related points.

 *Both trains had electric lomocotives, which collided.  The northbound train
  was supposed to stop; the southbound one was running at 95 to 100 mph.  Of
  "nearly 900" passengers on the two trains, 75 were injured, 32 requiring
  hospitalization, but the only fatality was the southbound train's driver.

The basic cause was driver error.  The error related to "approach-controlled"
signals, where a restrictive aspect is used merely to force the train to
slow down, rather than its original meaning of "prepare to stop".  In some
cases new flashing aspects are used to indicate approach control, but the
exact meaning varies (it would take too long for me to go into detail here).
The driver assumed that a particular red signal was going to clear as
he approached, when it was actually telling him to stop, hence the accident.

The magazine editorially blasted the present inconsistent system, saying
that approach control, which is supposed to stop trains from taking
junctions too fast, "is now a lethal menace because it does different
things in different places and is bound to lead drivers into confusion".
They call for a system with the desired speed explicitly displayed.

There was a further contributing cause.  The northbound train was equipped
with wheelslip protection, i.e., antilock braking, which a witness heard
in operation.  (Why do trains need antilock braking when they don't have
to steer?  Because if the wheels slide, flat spots are worn onto them,
causing bad riding and premature wear.)

The driver had no way to turn the wheelslip protection off.  If he had had,
the accident might have been avoided; experiments to test this were incon-
clusive, it being too difficult to reproduce the exact conditions.

But an override would certainly have reduced the stopping distance, and
the report recommended that wheelslip protection be automatically turned
off when the driver selects emergency braking.

Mark Brader	"What can be more palpably absurd than the prospect held out
utzoo!sq!msb	 of locomotives travelling twice as fast as stagecoaches?"
msb@sq.com		 -- The Quarterly Review (England), March 1825

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Shades of Fantasy in Real-Life -- group games
</A>
</H3>
<address>
&lt;<A HREF="mailto:mcvax!doc.ic.ac.uk!acwf@uunet.UU.NET">
mcvax!doc.ic.ac.uk!acwf@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 14 Jul 88 14:23:36 BST
</i><PRE>

I noticed the following article in UK Micro Mart magazine and
thought it might indicate some hitherto unforeseen risks of computer use!

Melanie Weaver and Jez Thorpe, both avid users of Telemap Groups Shades game,
have become the first couple to marry after meeting in a multi-user computer
game.  The newly-weds met in Shades, where players exist in a fantasy world of
castles, wizards and buried treasure. Their characters married in the game;
then they were engaged for real a month later, and married recently at a church
in Cornwall.  Melanie, who works in the travel business said: ``When I started
playing the last thing on my mind was that I would meet my future husband
through a computer game. But I soon discovered that one of the best things
about Shades is that it allows you to meet lots of interesting people.''

Shades is a multi-user adventure set in a fantasy world where players attempt
to rise from the rank of novice to wizard by collecting treasure and scoring as
many points as they can. With up to 128 players taking part the characters you
encounter -maybe in the on line pub, The Talking Shoppe - could be using a
computer anywhere in the world.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
IQ measurement by machine?
</A>
</H3>
<address>
Mark Brader
&lt;<A HREF="mailto:msb@sq.com ">
msb@sq.com 
</A>&gt;
</address>
<i>
Thu, 14 Jul 88 13:42:42 EDT
</i><PRE>

The following article by Bob Gray of Edinburgh University appeared in
sci.misc as an outgrowth of an exchange about the high-IQ society Mensa.

The risks associated with these machines would seem to be of the same type as
those associated with the use of polygraph machines as if they were lie
detectors.

Mark Brader, SoftQuad Inc., Toronto

(Forwarded text follows.  The quoted paragraph is from an earlier article
by Chris Long in the same newsgroup.)

&gt; Binet originally designed his tests to detect mental deficiency, which
&gt; they do, up to a point.  Alas, things did not stay there.  Goddard,
&gt; Terman, and Thorndike took things to where they are now.

Just to add some more napalm to the postings...

A company in Guildford, Surrey, UK announced last week that
they are to market a device to directly measure the early
signs of diseases affecting the brain. Alzheimer's disease
and senile dementia were mentioned.

Electrodes are attached to the scalp and the electrical
activity of the brain in response to computer controlled
stimulus is measured.

The device is also claimed to be able to measure IQ.

The report then went on to mention that some companies have already expressed
an interest in the device for selecting people with low intelligence to do
boring and repetitive jobs.

This device may be an application of some research here at the University of
Edinburgh which showed a correlation of greater than 0.6 between scores on IQ
tests and direct EEG measuremernts of the speed at which the sensory areas of
the brain can process information.
                                        	Bob

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Aviation units
</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard.S.D'Ippolito@sei.cmu.edu">
Richard.S.D'Ippolito@sei.cmu.edu
</A>&gt;
</address>
<i>
Thursday, 14 July 1988 11:17:32 EDT
</i><PRE>

It's curious how errors creep in everywhere. In Joe Morris's discussion of
aviation units, he reproduces a segment of a table from Jeppesen showing SI
units of distance as "km", where the correct unit is "Km". Would an SI
person also interpret the non-SI column entry "nm" as "nanometers" and
reject the chart?

A manual purporting to set a "official standard" for safety purposes, assuming
that the error wasn't a copy error, has an incorrect symbol used for a unit
modifier -- kilo is ALWAYS uppercase as are all SI prefixes that multiply as
opposed to those representing fractional parts, which are lowercase. (E.g., 
m = milli = 10^-3 and M = mega = 10^6.) "kg" is NOT an SI unit, but Kg is!
Imagine drugs if mg could be milligrams, micrograms, or megagrams, or radiation
if mCu were hastily written for microcuries. Some of the folks in my particular
field, the electronic, still mark capacitors with mF for microfarads and mmF
for micro-microfarads when they should be uF (greek letter micro) and pF (pico
= 10^-12).

Yes, we in our leisure know what is meant, but why should the burden be on
the reader to interpret, especially in a critical situation? And why the
mixed units? All units in a table should be consistent, defined, or spelled
out, so that nm, n.m., na. mi., are OBVIOUSLY nautical miles, and not
nanometers. To have adjacent lines of a table showing kg and nm (mixed
units with one incorrectly spelled) is irresponsible and, well, risky.

And all those footnotes? They tell me that there is no standard.

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
RISKS and PGN Saturation!
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Wed, 13 Jul 88 17:54:20 PDT
</i><PRE>

The RISKS backlog is up to 50 unfielded messages just in the past week.  Many
of the pending messages are marginal, and will probably not surface.  Many are
purely speculative, and those have to be very carefully written in order to be
worthy.  Others are interesting, but drifting further and further afield -- as
seems to happen whenever a subject develops.  Others continue to dwell on
topics that have already been covered.  I realize some of you are receiving
RISKS only after long delays (days, in some cases even weeks), which makes it
very hard for you not to avoid duplication of messages that you have not even
seen yet!  But bear with me as I continue to wrestle with the balance between
an open forum and a manageably readable, interesting forum.  Thanks.  Peter

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.21.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.23.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-64</DOCNO>
<DOCOLDNO>IA012-000129-B047-423</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.23.html 128.240.150.127 19970217022219 text/html 22525
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:20:47 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 23</TITLE>
<LINK REL="Prev" HREF="/Risks/7.22.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.24.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 23</H1>
<H2>  Saturday 16 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Policy Chief Indicted in Computer Misuse 
</A>
<DD>
<A HREF="#subj1.1">
Owen Blevins
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Data for Iran airliner discussion 
</A>
<DD>
<A HREF="#subj2.1">
Dave Fiske
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Data "viruses" 
</A>
<DD>
<A HREF="#subj3.1">
Peter J. Denning
</A><br>
<A HREF="#subj3.2">
 PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Invitation to visit Disaster Research Center 
</A>
<DD>
<A HREF="#subj4.1">
DRC
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Passwords on networked systems 
</A>
<DD>
<A HREF="#subj5.1">
Steve Oualline
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Other ways to manage risks 
</A>
<DD>
<A HREF="#subj6.1">
Dave Fiske
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Colwich Junction, England, 1986 
</A>
<DD>
<A HREF="#subj7.1">
Blair P. Houghton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Oops -- risks of writing -- SI prefixes 
</A>
<DD>
<A HREF="#subj8.1">
Richard S D'Ippolito
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Policy Chief Indicted in Computer Misuse
</A>
</H3>
<address>
owen blevins 
&lt;<A HREF="mailto:blevinso@silver.bacs.indiana.edu">
blevinso@silver.bacs.indiana.edu
</A>&gt;
</address>
<i>
Fri, 15 Jul 88 20:25:50 est
</i><PRE>

From New York Times Friday., July 15, 1988:

Metro-North Police Chief Indicted in Computer Misuse

The police chief of the Metro-North Commuter Railroad was indicted yesterday on
charges that he improperly used a New York State polic computer system to
investigate job applicants, their relatives and people who were suing the
railroad.

The indictment against the chief, John V. Esposito, includes allegations of
"computer trespass."  Authorities said he is believed to be the first police
official to be prosecuted under a 1986 law restricting the use of confidential
criminal justice records compiled in computers.

After pleading not guilty in a courtroom in Manhattan, Mr. Esposito, who was
released without bail, said his use of the computer system "is standard
operating procedure" by police chiefs throughout the state as part of routine
background examinations of prospective employees.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Data for Iran airliner discussion
</A>
</H3>
<address>
Dave Fiske
&lt;<A HREF="mailto:davef@brspyr1.brs.com ">
davef@brspyr1.brs.com 
</A>&gt;
</address>
<i>
14 Jul 88 21:28:21 GMT
</i><PRE>

I know this is the net, but I hope I can be forgiven for doing a bit of actual
research! Here are a few excerpts from some books I happen to have at home.
Shows that with just a little effort, we could be having discussions based
loosely on fact, rather than vague memories and opinions.

First of all, despite Reagan's statement, the AEGIS system is a bit more than
your average radar unit.  The following excerpt indicates that it does some
interpretation of the data it obtains, and even performs limited
decision-making.

  "The AEGIS Combat System was developed to counter the saturation missile
  attacks which could be expected to form the basis of Soviet anti-carrier
  tactics during the 1980s.  Conventional rotating radars are limited both in
  data rate and in number of target tracks they can handle, whereas saturation
  missile attacks require sensors which can react immediately and have a
  virtually unlimited tracking capacity.  The solution adopted in the AEGIS
  system is to mount four fixed planar antennae each covering a sector of 45
  degrees on the superstructures of the ship.  Each SPY-1 array has more than
  4000 radiating elements that shape and direct multiple beams.  Targets
  satisfying predetermined criteria are evaluated, arranged in sequence of
  threat and engaged, either automatically or with manual override, by a
  variety of defensive systems."

  John Jordan, "An Illustrated Guide to the Modern U.S. Navy", 1986,
  Prentice Hall.

Several people have maintained in comp.risks that the F-14 would not be
much of a threat to surface ships.  However:

  "The twin-jet F-14 is indeed some airplane.  It was designed to range
  farther, fly faster, climb higher and pack more wallop than any interceptor
  ever built.  While it possesses some of the features of a fighter, fighter
  pilots certainly would prefer to call it an interceptor.  Its long suit is
  its fire control system and its missiles.  With his AWG-9 radar and
  infrared-sensor-computer system, the backseat Missile Control Officer (MCO)
  of the Tomcat can track twenty-four separate targets, from sea level to one
  hundred thousand feet, up to one hundred miles distant."

  James W. Canan, "The Superwarriors", 1975, Weybright and Talley.


  "Possibly the most complete fighter in the world today, the Grumman F-14
  Tomcat first entered service in 1975.  Armament consists of M61A1 20-mm
  rotary cannon plus AIM-9 Sidewinder short-range, AIM-7 Sparrow medium-range
  and AIM-54 Phoenix long-range air-to-air missiles.  A combination of all
  these missiles can be carried at one time, making the F-14 capable of
  shooting down any flying intruder at any range up to 200 km (125 miles).  The
  Phoenix missiles are operated in conjunction with the Tomcat's AWG-9 radar,
  and can hit targets at any altitude from ground level to over 2400 m (78,740
  ft)."

  "Modern Combat Aircraft", Crescent Books

According to The Military Balance, 1984-85, published by the International
Institute for Strategic Studies, Iran still has 10 F-14As (in 1975 they had
15--some undoubtedly have become inoperative since then), and does have
Sidewinders, Sparrows, and Phoenixes. 
                                        Dave Fiske  (davef@brspyr1.BRS.COM) 

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Data "viruses" (<A HREF="/Risks/7.11.html">RISKS-7.11</A>)
</A>
</H3>
<address>
Peter J. Denning 
&lt;<A HREF="mailto:pjd@riacs.edu">
pjd@riacs.edu
</A>&gt;
</address>
<i>
Fri, 15 Jul 88 14:47:45 pdt
</i><PRE>

Dave Horstall inquired about whether the propagation of corrupted data through
a system can be considered a new form of virus.  No.

The propagation of corrupted data is an old problem that systems designers
interested in fault tolerance must face.  It is a difficult problem and many
systems do not include appropriate data consistency checks to prevent or
mitigate it.

The virus is a program designed to infect other programs with copies of itself
and to perform unwanted actions in the manner of a Trojan horse.
   
Peter Denning

</PRE>
<HR><H3><A NAME="subj3.2">
Program viruses vs "data viruses"
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Sat, 16 Jul 88 10:29:19 PDT
</i><PRE>

On viruses versus data propagated effects of contaminated data:

Yes, the propagation of corrupted data is an old problem, although it is
generally considered within the scope of a single program or a single process.
My favorite example of more global propagation is provided by the ARPANET
collapse (mentioned in RISKS occasionally, but newer readers should dig up Eric
Rosen's enlightening article, "Vulnerabilities of network control protocols",
in ACM Software Engineering Notes, vol 6 no 1, January 1981).  This was caused
by a status word being propagated along with two corrupted versions of itself
-- as a result of hardware malfunctions.  The consequence was that those two
corrupted versions (yes, propagated by the normal node programs, which were
unaltered) contaminated every node in the network -- because the flawed garbage
collection algorithm broke down.  True, there was no program virus.  However,
the two bogus status words effectively contaminated the entire network! This
case is interesting not because a piece of data was altered, but because three
different versions of the SAME piece of data were able to bring the entire
network to its knees -- despite the belief that distributed control was safe.
That kind of contamination deserves some sort of explicit identity such as
"data bacterium" or "data microbe" or whatever, although it has some of the
characteristics of a (data or nonprogram) virus...  PGN

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
     Invitation to visit Disaster Research Center (DRC)
</A>
</H3>
<address>
Disaster Research Center 
&lt;<A HREF="mailto:ACJ00984%UDACSVM.BITNET@CUNYVM.CUNY.EDU">
ACJ00984%UDACSVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri, 15 Jul 88 20:24:21 EDT
</i><PRE>

An Introduction to the Disaster Research Center for RISKS
Readers.    Come to our open house in August !

The Disaster Research Center, the first of its kind and the only one in the
United States, was established at the Ohio State University in 1963 and moved
to the University of Delaware in 1985.  The Center engages in a variety of
sociological and social science research on group and organizational
preparations for, responses to, and recovery from community-wide emergencies,
particularly natural and technological disasters.  Since the Center's
inception, there have been over 496 different field studies.  Teams have gone
to earthquakes in Japan, Chile, Yugoslavia, Italy, Iran, El Salvador, Greece,
California, and Alaska; hurricanes in the southern and eastern United States,
as well as Japan; floods in Italy, Canada, and more than a dozen states; and
tornadoes and hazardous chemical incidents in Canada, Mexico, and the United
States.  A dozen cities struck by major disasters have been restudied several
years after the initial research.  For purposes of comparison, Center personnel
have also examined organizational responses to civil disturbances and riots.

The Center has a number of professionals on its staff plus supporting clerical
and secretarial personnel.  It is directed by Professor E.L. Quarantelli, with
the assistance of Professors Dennis E. Wenger and Russell R. Dynes, all of the
Department of Sociology at the University.

Recent studies have focused on:  Social and organizational aspects of the
delivery of mental health services and of emergency medical services in mass
emergencies; and socio-behavioral responses to acute chemical hazards and the
problems involved in mass evacuation and sheltering.  Research underway
includes the ways in which information relating to disaster is processed
through news organizations, the organizational and public response to the
Mexico City earthquake, and the role of local emergency response agencies.
Center personnel have examined legal aspects of governmental responses in
disasters, the emergence and operation of rumor control centers, mass media
reporting of community crises, the functioning of relief and welfare groups in
stress situations, and the handling of the dead in catastrophes.

The research provides basic knowledge about group behavior and social life in
large scale community crises as well as information which can be applied to
develop more effective plans for future disasters.  Besides storing its own
data collected through in-depth interviewing, participant observations, and
document gathering, the Center serves as a repository for materials collected
by other agencies and researchers.  The Center's specialized library, which
contains the world's most complete collection --over 20,000 items-- on the
social and behavioral aspects of disasters, is open to all interested scholars
and public and private agencies involved in emergency planning.  With over 400
publications, the Center has its own book, monograph, and report series.  There
are close relations with Canadian, Mexican, Australian, Swedish, Japanese, and
West German disaster researchers, a number of whom have been visiting research
associates at the Center for periods of up to a year, and collaborative field
research is currently underway with groups in Japan and Mexico.  An exchange
program and very close ties with Italian researchers, especially the Mass
Emergency Program of the Institute of International Sociology in Gorizia,
Italy.

Center activities have been supported by diverse sources including the Health
Resources Administration; the Center for Applied Social Problems, National
Institute of Mental Health; the Defense Civil Preparedness Agency; the Water
Resource Research Program, Department of the Interior; the State of Ohio
Department of Mental Health; but major funding has been from the National
Science Foundation, and the Federal Emergency Management Agency.

If you would like more information concerning the Disaster Research Center or
desire an updated Publications List, write to Margie Simmons, Office
Coordinator, Disaster Research Center, University of Delaware, Newark,
Delaware, 19716, United States of America.

** Special note to Risks Digest Readers **

     Anniversary Celebration Announcement

The Disaster Research Center was formed in August, 1963.
Thus, it will be 25 years old next month.

To mark the occasion, an open house will be held at the Center's
present location on the third floor of 102 East Main St., Newark,
Delaware (U.S.A.).

Time: Monday, August 22, 1988
               1 - 5 p.m.

We hope you can take some time to visit us.

    - E.L. Quarantelli, Director
    - Russell R. Dynes
    - Dennis E. Wenger

(Information forwarded by Bruce D. Crawford, Computer Services
   Coordinator, Disaster Research Center).

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Passwords on networked systems
</A>
</H3>
<address>
Steve Oualline
&lt;<A HREF="mailto:horizon!sdo@seismo.CSS.GOV ">
horizon!sdo@seismo.CSS.GOV 
</A>&gt;
</address>
<i>
15 Jul 88 22:31:51 GMT
</i><PRE>

Although RISKs seems to be primarily oriented toward major problems with the
cutting edge of technology, I wish to offer an example of a small problem that
can be solved by a little common sense.

At our site we have several UNIX systems running on a network.  For convenience
of the administrator, me, all the root passwords are the same.  I discovered
the hard way that this is not a good idea.  I wanted to reboot "zabbar" a small
system that no one was using, so I walked over to its console and type su root,
/etc/halt.

This shut down the system -- the problem was that I had done rlogin horizon
(horizon is our main system), and had shut it down by mistake.  If the root
passwords had been different for each machine, then horizon would have rejected
the root password for zabbar causing me to discover which system I was really
on.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Other ways to manage risks (Re: <A HREF="/Risks/7.20.html">RISKS-7.20</A>)
</A>
</H3>
<address>
Dave Fiske
&lt;<A HREF="mailto:davef@brspyr1.brs.com ">
davef@brspyr1.brs.com 
</A>&gt;
</address>
<i>
15 Jul 88 18:58:58 GMT
</i><PRE>

&gt; From: Doug Faunt (phone (415) 496-4727) &lt;faunt@spar.slb.com&gt;
&gt; Subject: re: lockpicking and burglars
&gt; I would like to point out that it might be worthwhile to improve your
&gt; locks to some degree, ...
&gt; ...  You may not be able to keep them out, but you can make sure there's a
&gt; record.

I'm surprised that comp.risks readers are primarily fixating only on PREVENTION
for managing risks.  Prevention is only one way to deal with them.

Nearly all homeowners therefore have insurance to cover the theft of
contents, as well as locks on the doors.  Some have burglar alarms as
well.  The prevalence of insurance and burglar alarms is an indication
that unwanted entries cannot be 100% eradicated.  Locks are only one
aspect in the management of the risk of theft.

The existence of law enforcement agencies is another deterrent--a
burglar has to (well, at least he should) consider the possibility that
he will get caught.  The consequences of entering a locked home
("burglary", or "breaking and entering") are more severe than entering
one which is not locked ("illegal entry"), and is also more easily
proved due to physical evidence.

In addition to helping to deter entry, locks help to provide evidence
to facilitate getting an insurance settlement, or to capture the
culprit and achieve return of the goods.

Similarly, a computer system can probably never be made totally secure,
since it's always possible (granted, very unlikely) that an
unauthorized user could happen to guess a correct password on the very
first try, etc.  However, log files are kept and checked, means of
disciplining system abusers are maintained, backup tapes are made, etc.
as further means of reducing the consequences of tampering.

Dave Fiske  (davef@brspyr1.BRS.COM) 

    [But don't forget that in many systems it is easy to turn off auditing
     altogether, or to bypass it, or to modify the audit trail later.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Colwich Junction, England, 1986 (Re: Mark Brader, <A HREF="/Risks/7.22.html">RISKS-7.22</A>)
</A>
</H3>
<address>
Blair P. Houghton
&lt;<A HREF="mailto:bph%buengc.bu.edu@bu-it.BU.EDU ">
bph%buengc.bu.edu@bu-it.BU.EDU 
</A>&gt;
</address>
<i>
Fri, 15 Jul 88 17:50:38 edt
</i><PRE>

Mark's message points out a common misconception: that skidding provides more
stopping force than does rolling with the brakes on.

The truth is that the coefficient of friction is lowered drastically once the
surfaces involved begin to slide.  That is, the kinetic coefficient of friction
is lower than the static coefficient of friction.

Hence, a rolling wheel, which indeed has a nonsliding portion of its surface in
contact with the rail, can apply more force to the rail, thus slowing the train
faster; once the wheel locks up and begins to slide, the force decreases in a
virtual discontinuity, and the train slows slower, meaning that the stopping
distance is larger (usually much larger).

If the wheelslip protection overcompensated for impending slippage by lowering
the braking force below even the skidding-friction force, then it is utterly at
fault for an extended stopping distance, and the above mentioned report's
conclusion is correct.

However, if the wheelslip protection was properly designed, it should have
operated in the region between skidding-friction force (kinetic coefficient in
effect) and onset-of-skidding force (static coefficient in effect), then the
report is dangerously wrong and has made a suggestion that will aggravate
future accident situations.

While the "flattening" argument for wheelslip protection is good economy, the
increased stopping power is the primary reason that antilock braking was
invented, since saving lives is the best economy.
                                                       Blair P. Houghton

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Oops -- risks of writing -- SI prefixes
</A>
</H3>
<address>
&lt;<A HREF="mailto:Richard.S.D'Ippolito@sei.cmu.edu">
Richard.S.D'Ippolito@sei.cmu.edu
</A>&gt;
</address>
<i>
Friday, 15 July 1988 09:29:09 EDT
</i><PRE>

I blew it. The SI prefixes for kilo (10^3), hecto (10^2), and deca (10^1)
are abbreviated with lower case letters. Those above kilo are abbreviated
with capital letters. All those below (10^-1 to 10^-18) are lowercase.  I've
seen too many KVs and KWs in the electrical industry.  I'm sorry -- next
time I'll look it up first.
                                             Rich

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.22.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.24.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-65</DOCNO>
<DOCOLDNO>IA012-000129-B047-439</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.24.html 128.240.150.127 19970217022228 text/html 13339
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:21:00 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 24</TITLE>
<LINK REL="Prev" HREF="/Risks/7.23.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.25.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 24</H1>
<H2>  Monday 18 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The IRS Illinois Experiment 
</A>
<DD>
<A HREF="#subj1.1">
Patrick A. Townson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Aegis testing data withheld from Congress 
</A>
<DD>
<A HREF="#subj2.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Man in the loop" 
</A>
<DD>
<A HREF="#subj3.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Aegis 
</A>
<DD>
<A HREF="#subj4.1">
Charles Daffinger
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Lightning strikes... (again?) 
</A>
<DD>
<A HREF="#subj5.1">
Don Mac Phee
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The IRS Illinois Experiment
</A>
</H3>
<address>
&lt;<A HREF="mailto:sun!portal!cup.portal.com!Patrick_A_Townson@unix.SRI.COM">
sun!portal!cup.portal.com!Patrick_A_Townson@unix.SRI.COM
</A>&gt;
</address>
<i>
Sun Jul 17 14:01:44 1988
</i><PRE>

The Internal Revenue Service says it wants to make it faster and easier for
taxpayers to get their refunds in the future, so it is experimenting with
a new approach in Illinois during the 1989 tax paying season.

As a resident of Illinois, you will be able to file your tax return
electronically, by hooking into the IRS computer to complete your tax return
and provide the necessary information on your income, taxes withheld, etc.

The IRS says if this experiment goes as planned, it will speed processing of
tax returns by fifty percent, allowing refunds to be paid within three weeks
instead of the usual five or six weeks. As to be expected, it is not all
altruism on the part of the Internal Revenue Service.

A return sent to the IRS electronically costs about $9 to process. A paper
return mailed to the agency costs $72.50. The reduced labor costs will save
the revenuers about $200 million over the next ten years, primarily through
reduced labor costs, filing space and paper work.

The agency will still have some paper mail to process, since even the returns
filed electronically will require a signature form to be mailed in along with
W-2 forms, but the work will be cut down drastically from the current system.

The IRS believes the lure of a faster refund, which can be deposited directly
into a financial institution, will motivate taxpayers to file earlier. If
their theory is correct, and if the "Illinois Experiment" works out as planned,
the electronic filing program will be expanded nationwide over the next 2-3
years.

Taking advantage of the electronic option will cost taxpayers in other ways,
however. The computer link will only be available through tax preparation
services. The IRS believes that offering access to their computers to all
personal computer users would cause them 'some concerns about hackers and
phreakers getting after us, making trouble for us..', coordinator of the
new program in the Chicago IRS offices, Regina Nixon said.

She said the agency is looking at ways to allow personal computer users to
plug directly into the system while at the same time keeping the system
secure, but nothing has been decided yet. She said one possibility will be
that terminals will be provided in IRS offices where the public can come
in, sit down and work, under the 'guidance' (watchful eye, perhaps?) of
IRS employees.

Linda Jordan, of H&amp;R Block, the national tax preparation service based in
Kansas City said they will probably charge an additional fee of $18-30
per electronic filing to cover their own costs for the program. She noted
that the popularity of the program at first would depend in large part on
the amount of the refund and how quickly the taxpayer was interested in
getting it.

The new electronic filing program will only be for people with refunds
coming. Those folks who owe money will still have to pay the old-fashioned
way, by writing a check which is enclosed with a paper return. Taxpayers
in Illinois can begin using this new option later this year as they begin
the process of reporting their 1988 income. The new electronic system is
expected to receive its biggest workout during the first quarter of 1989,
and the results of that test will detirmine to what extent it should be
promoted nationally.

Dixon, of the IRS office, said they had not yet figured out a way to induce
people to file early when they had to pay additional money; but one thing
under consideration is to combine the electronic filing approach with a
slight discount to the taxpayer who authorizes an automatic draft from their
bank account to pay the taxes due.

Now dear Risks Readers: Can't you *just see* and *just imagine* the several
possibilities for corruption here on the part of the tax preparation services
and others? The theory that it will be more efficient sounds great, but oh
what havoc it will cause if the 'wrong people' start diddling the computers!!

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Aegis testing data withheld from Congress
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.stanford.edu ">
chapman@csli.stanford.edu 
</A>&gt;
</address>
<i>
Mon, 18 Jul 88 09:35:15 PDT
</i><PRE>

Defense Week reports that an unclassified report of the General Accounting
Office (GAO) reveals that the Navy withheld testing problems of the Aegis
air defense system from the Congress.  "Personnel and Aegis equipment were
not subjected to targets or tactics that would be found in combat," and the
reports sent to the Congress by the Navy omitted "unfavorable test results."
The GAO said that the favorable assessment of the Aegis system by John
Krings, the head of testing for the Pentagon, "was not supported by the
evidence."  The Navy report to the Congress, says the GAO, "potentially led
Congress to fund weapons systems whose true operational effectiveness and
suitability are unknown."

Gary Chapman, Executive Director, 
Computer Professionals for Social Responsibility

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
"Man in the loop"
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
18 Jul 88 09:08:10 PDT (Monday)
</i><PRE>

The July 18 Los Angeles Times carries an op-ed piece by Peter D. Zimmerman, a
physicist who is a senior associate at the Carnegie Endowment for International
Peace and director of its Project on SDI Technology and Policy:

        MAN IN LOOP CAN ONLY BE AS FLAWLESS AS COMPUTERS.

  [In the Iranian Airbus shootdown,] the computers aboard ship use 
  artificial intelligence programs to unscramble the torrent of infor-
  mation  pouring from the phased array radars.  These computers decided 
  that the incoming Airbus was most probably a hostile aircraft, told 
  the skipper, and he ordered his defenses to blast the bogey (target) 
  out of the sky.  The machine did what it was supposed to, given the 
  programs in its memory.  The captain simply accepted the machine's 
  judgment, and acted on it....
  
  Despite the fact that the Aegis system has been exhaustively tested at 
  the RCA lab in New Jersey and has been at sea for years, it still failed 
  to make the right decision the first time an occasion to fire a live 
  round arose.  The consequences of a similar failure in a "Star Wars"
  situation could lead to the destruction of much of the civilized world.
  [Descriptions of reasonable scenarios ....]
  
  The advocates of strategic defense can argue, perhaps plausibly, that 
  we have now learned our lesson.  The computers must be more sophisticated,
  they will say.  More simulations must be run and more cases studied so 
  that the artificial intelligence guidelines are more precise.
  
  But the real lesson from the tragedy in the Persian Gulf is that 
  computers, no matter how smart, are fallible.  Sensors, no matter how 
  good, will often transmit conflicting information.  The danger is not 
  that we will fail to prepare the machines to cope with expected situa-
  tions.  It is the absolute certainty that crucial events will be ones 
  we have not anticipated.
  
  Congress thought we could prevent a strategic tragedy by insisting that 
  all architectures for strategic defense have the man in the loop.  We 
  now know the bitter truth that the man will be captive to the computer,
  unable to exercise independent judgment because he will have no indepen-
  dent information, he will have to rely upon the recommendations of his
  computer adviser.  It is another reason why strategic defense systems 
  will increase instability, pushing the world closer to holocaust -- 
  not further away.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Aegis
</A>
</H3>
<address>
Charles Daffinger 
&lt;<A HREF="mailto:cdaf@iuvax.cs.indiana.edu">
cdaf@iuvax.cs.indiana.edu
</A>&gt;
</address>
<i>
Sat, 16 Jul 88 17:08:02 EST
</i><PRE>

For a good overview of AEGIS, you may wish to check out:

Adam, John A.  _Pinning Defense Hopes on Aegis_,  IEEE Spectrum, 25:6,
pp 24-27, June 1988.

-charles

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Lightning strikes... (again?)
</A>
</H3>
<address>
Don Mac Phee 
&lt;<A HREF="mailto:NKK101%URIMVS.BITNET@MITVMA.MIT.EDU">
NKK101%URIMVS.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 18 Jul 88 09:51 EDT
</i><PRE>

  I recently discovered the RISKS of an insufficiently grounded
building the hard way. Lightning struck!

  For several years the VAX systems that have existed in this hall
at the University of Rhode Island, have been plagued with an unusual
number of system crashes. All of these crashes coincided with
electrical storms. Unfortunately, no one bothered to research the
problem, until now. A simple system could have saved up to thousands
of dollars in equipment.

  The campus sprawls down the side of one of the higher hills in the
area. The building is a four story building, which resides at the top
of the hill. The VAX resides on the third floor of this four story
building. But there are no lightning rods on the top of this building
to dissipate the force of a lightning strike! So the VAX has acted as
the perfect lightning rod, generating a positive electrical field
sufficient enough to attract lightning.

  Thousands of dollars have gone to solve a problem that a four dollar
rod, and 20 dollars worth of wire could have solved.

Don Mac Phee

p.s. All standard and some non-standard disclaimers apply. I do not
represent the University. I just comment on it.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.23.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.25.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-66</DOCNO>
<DOCOLDNO>IA012-000129-B047-462</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.25.html 128.240.150.127 19970217022239 text/html 17721
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:21:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 25</TITLE>
<LINK REL="Prev" HREF="/Risks/7.24.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.26.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 25</H1>
<H2>  Wednesday 20 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Possible reason for unexpected Audi 100 acceleration 
</A>
<DD>
<A HREF="#subj1.1">
Lars Lindwall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Bell blames computer error as $4 calls are billed for $400 
</A>
<DD>
<A HREF="#subj2.1">
David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Programming BART (Bay Area Rapid Transit) 
</A>
<DD>
<A HREF="#subj3.1">
Eugene Miya
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: The IRS Illinois Experiment 
</A>
<DD>
<A HREF="#subj4.1">
Michael L. McLean
</A><br>
<A HREF="#subj4.2">
 Lars J Poulsen
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Error rates in barcode data 
</A>
<DD>
<A HREF="#subj5.1">
John Colville
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  PIN on PNB calling card 
</A>
<DD>
<A HREF="#subj6.1">
Nathan K. Meyers
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Risks of bank ATM cards 
</A>
<DD>
<A HREF="#subj7.1">
George H. Feil
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 Possible reason for unexpected Audi 100 acceleration
</A>
</H3>
<address>
LARS LINDWALL LIDAC
&lt;<A HREF="mailto:<L_LINDWA%SELIUC51.BITNET@CUNYVM.CUNY.EDU> ">
&lt;L_LINDWA%SELIUC51.BITNET@CUNYVM.CUNY.EDU&gt; 
</A>&gt;
</address>
<i>
Tue, 19 Jul 88 18:00 N
</i><PRE>

The following is what I can recall from a news story in the Swedish
Broadcasting Corporation's "News for Consumers" ("Konsumentekot") today,
Tuesday July 19th, 1988.

A researcher at the Swedish National Defense Research Institute (FOA) claims
that he has found a possible cause for the well known Audi 100 involuntary
acceleration phenomena. The researcher, Mats Gunnerhed, active in the field of
reliability of technical systems, says that the automatic speed control
probably is to blame for many of the accidents. By manipulating just one of the
connections on the electronic board that is part of the cruise control
function, he has been able to reproduce the unexpected applying of full
throttle. It is not necessary for the cruise control to be activated for the
acceleration to happen. It is enough that the main power switch for the
automatic speed control is in the "on" position.

Gunnerhed says that the construction as described on the drawings seems good
and reliable. A double electronic fault would be required for the involuntary
acceleration. However, when the construction was implemented on a physical
electronic board a mistake was made that makes it possible for one single
electronic fault to cause the unexpected acceleration.

A representative of the cruise control manufacturer, the West German company of
HELLA, says that double security is still present since the human error of not
applying the brakes is also required for an accident to happen (sic!).

Lars Lindwall, University of Linkoping Computer Center, Sweden.
(LLL@SELIUC51.BITNET)

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Bell blames computer error as $4 calls are billed for $400
</A>
</H3>
<address>
David Sherman
&lt;<A HREF="mailto:lsuc!dave@uunet.UU.NET ">
lsuc!dave@uunet.UU.NET 
</A>&gt;
</address>
<i>
19 Jul 88 16:21:46 EDT (Tue)
</i><PRE>

Toronto Star, July 14, 1988:

OTTAWA (CP) -- Thanks to a computer error, massive long-distance bills have
been charged to people in Ottawa who phoned Toronto between May 26 and June 10.
Customers were billed the maximum 999 minutes -- or 16 hours, 39 minutes -- for
all calls because the computer did not register the signal given when a phone
is hung up, Bell says.  As a result, a 10-minute call that should have cost $4
would be billed at a whopping $400.

One business, among 83 customers who have already complained, was charged a
total of more than $13,000.  The average overcharge was $2,450, said Bell
spokesman Mary McGregor.  Some customers received notices warning that their
phone would be disconnected in three days unless they paid up.  More complaints
are expected when subscribers receive their next bill, McGregor says.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Programming BART (Bay Area Rapid Transit)
</A>
</H3>
<address>
Eugene Miya 
&lt;<A HREF="mailto:eugene@amelia.nas.nasa.gov">
eugene@amelia.nas.nasa.gov
</A>&gt;
</address>
<i>
Tue, 19 Jul 88 18:25:19 PDT
</i><PRE>

On a recent climbing trip, the subject of RISKs (this newsgroup) was brought up
in discussion with a partner who heads the programming for BART.  I passed on
the reference to Perrow's "Normal Accidents," which he had read and really
enjoyed [and I also told him of various discussions on programming railway
systems, note: Bob is English].  Anyway he brought up some interesting points:
the current system is only programmed for a maximum of 45 trains (future
extensions may require complete reprogramming); BART is a real-time system with
3,000 independent inputs; they use a Yourdon Design Methodology for
programming, etc.  Oh, yes, he has some interesting stories (like the BART
switching yard is not part of BART control, so this nearly led to several
accidents), so we can get some interesting antecdotes if RISKs wants them.
Anyways, since Bob is heading back to England this fall and the fact that BART
is isolated from any networks (Bob being interested in RISKS), I will agree to
act as intermediary for questions about the real-time programming of BART.  I
will next be seeing Bob in about 2 weeks, so I can batch questions together
forward them and an answer if possible.  So, if you are interested, and
patient, and don't ask things which are too sensitive (security is a concern),
I will collect questions.  Send them to eugene@amelia.nas.nasa.gov for this
purpose (as opposed to my other mail boxes).
                                                 eugene miya, NASA Ames

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: The IRS Illinois Experiment
</A>
</H3>
<address>
Michael L. McLean
&lt;<A HREF="mailto:uiucdcs!pur-ee!mlm@uunet.UU.NET ">
uiucdcs!pur-ee!mlm@uunet.UU.NET 
</A>&gt;
</address>
<i>
Tue, 19 Jul 88 11:55:37 EST
</i><PRE>

&gt; From: Patrick_A_Townson@unix.SRI.COM
&gt; Subject: The IRS Illinois Experiment
&gt; 
&gt; The Internal Revenue Service says it wants to make it faster and easier for
&gt; taxpayers to get their refunds in the future, so it is experimenting with
&gt; a new approach in Illinois during the 1989 tax paying season.

Are you sure about your data?  For my 1988 tax return, I went to an H&amp;R block
here in Indiana, gave them my signed tax return and $20 ..  They sent the
return in electronically with the paper backup and my refund arrived in the
mail 21 days later.  (There was also a 28 day guarantee, if it didn't arrive
H&amp;R block returned the $20 fee -- They must put quite a bit of trust in the
government system for that one)

The paper backup involved the H&amp;R block person copying the vital numbers from
my return onto a different form and sending in my signed return.  The
possibilities for errors are enormous.  I can just see it now the IRS could get
three different tax returns from me: my original, the paper backup with a
number copied wrong, and the electronic version with a typo.

For an additional cost (don't remember - didn't use this) they had a bank in
Maryland loan you your refund and the loan contract explicitly stated that the
IRS check is payment.  That allows you to get your refund within seven days
instead of 28.  This also allows the $20+X fee to be automatically deducted
from your refund.

Having used this system once, I would use it for refunds again.  However after
reading risks (and the stupid clerk stories in rec.humor) for awhile I would
never authorize the IRS to extract money from my checking account.

I think that a system using PC's would be great, IFF they can make it
secure from hackers.  The cost to design it properly would be very
high, and even then I don't think we can get a safe system developed
through the government. 

</PRE>
<HR><H3><A NAME="subj4.2">
Re: The IRS Illinois Experiment
</A>
</H3>
<address>
Lars J Poulsen
&lt;<A HREF="mailto:lars@ACC-SB-UNIX.ARPA ">
lars@ACC-SB-UNIX.ARPA 
</A>&gt;
</address>
<i>
Wed, 20 Jul 88 08:45:59 PDT
</i><PRE>

Patrick Towson's note about the IRS experiment is very interesting.
The projected savings are impressive, but could they be exaggerated ?

The biggest problem is obviously that the email-submitted tax return doesn't
have a signature, and thus it could be hard to prosecute people who file
fraudulent returns in order to obtain a refund to which they are not entitled.
The proposed workaround is to allow filing only through certified tax
preparers, who have something to lose if they are caught assisting with such
fraud.

The note projects that the IRS would save $63.50 for each electronically filed
return, and that the tax preparers would charge $60-$80 on top of their
preparation fee. This seems like a lot of money for what would seem like a
10-minute data entry task. I thought data entry jobs paid about $10-$15/hour;
double that for G&amp;A overheads, and I get $5/return.  Network costs may be
another $5, but while these would be a cost to the tax preparers, the IRS would
incur them.

Frankly, the whole idea sounds like a P.R. scheme. "Let's get high tech".
I have no doubt that it saves cost to put data on the machine as early in
the process as possible, but I thought IRS already did this. Where do
these savings come from ?
                                                  / Lars Poulsen

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Error rates in barcode data
</A>
</H3>
<address>
John Colville
&lt;<A HREF="mailto:munnari!nswitgould.oz.au!colville@uunet.UU.NET ">
munnari!nswitgould.oz.au!colville@uunet.UU.NET 
</A>&gt;
</address>
<i>
Wed, 20 Jul 88 11:32:57 EST
</i><PRE>

On Monday 18 July, on the ABC's Sydney radio station, 2BL, Margaret Throsby
interviewed a representative of a retail organisation about errors in using
barcode systems.  (Sorry, I don't remember his name or organisation).

The rep. quoted experiments in Adelaide which showed that using barcoding
reduced error rates to 5%, compared with earlier experiments in Western
Australia where the error rate when individual items were priced was 15%.

He also defined errors in terms of differences between the price charged and
the price shown on the shelves. Most of the errors he ascribed to failure
of changes to be propagated completely through to the barcode readers
i.e. updates not yet done to tapes, tapes not run through, etc.

There is something rather screwy here. I know that we have inflation in
Australia of, say 7%, and there are *some* specials from week to week.
Even if we assume that the barcode info. is only updated weekly,
it seems to me that 5% error rates are way too high.

[If half the errors are `my' way and half are in the store's favour,
should I buy &lt;&lt; 40 items every time to avoid errors? :) ]

John Colville

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 PIN on PNB calling card
</A>
</H3>
<address>
Nathan K. Meyers 
&lt;<A HREF="mailto:nathanm%hpcvlx@hplabs.HP.COM">
nathanm%hpcvlx@hplabs.HP.COM
</A>&gt;
</address>
<i>
Mon, 18 Jul 88 17:36:45 pdt
</i><PRE>

What exactly is so irresponsible about Pacific Northwest Bell's encoding
charge information into their calling card?  It's a credit card -- like
all credit cards, it relies on physical security.  If someone steals it,
or your Visa or Mastercard, he has access to your money.  Magnetic
stripes on credit cards are pretty common these days -- many of the
charge-type phones that accept your calling card will also accept your
Visa card.

Your calling card does offer a few security advantages over other credit
cards:

  1) Nobody can steal your PIN by looking over your shoulder.  In other
     words, no need to "tear the carbons".

  2) You can cut your card to ribbons and throw it away, while still
     enjoying its advantages at almost any telephone in the world.
     Forget the bulk eraser -- deploy your kitchen shears.

Nathan Meyers, nathanm@hp-pcd.hp.com

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Risks of bank ATM cards (more) (<A HREF="/Risks/6.94.html">RISKS-6.94</A>)
</A>
</H3>
<address>
"George H. Feil" 
&lt;<A HREF="mailto:gf08+@andrew.cmu.edu">
gf08+@andrew.cmu.edu
</A>&gt;
</address>
<i>
Tue, 19 Jul 88 11:08:24 -0400 (EDT)
</i><PRE>

mordor!lll-crg!lll-winken!ddsw1!karl@rutgers.edu (Karl Denninger) writes:
&gt; o While I was on the phone with Cash Station, Inc. I inquired as to 
&gt;   the display of balances (this was another "sticking" point with me; they
&gt;   were often off by hundreds of dollars).  Their reply was that the network
&gt;   which interconnects the ATMs "cooks" your balance (!) depending on what
&gt;   you do at the terminal.  In other words, the balance shown by the terminal
&gt;   MAY NOT BE YOUR TRUE BALANCE.  When I asked as to why there was no
&gt;   indication anywhere that these numbers were "finagled" they indicated that
&gt;   the response time of the member bank's computers was insufficient to get a
&gt;   real balance.... sounded (and still sounds) fishy to me.  Isn't this
&gt;   *literally* fraud, as they claim that number on the screen to be your 
&gt;   BALANCE? (along this line, the machines do not dispense receipts on
&gt;   balance inquiries either -- perhaps to prevent you using these as
&gt;   "evidence".)

I've been screwed by having bogus balances given by ATM's before.
When I had an account with Mellon Bank (which, in my opinion, is run
by a bunch of weasels for many reasons), the balances which appeared
on my receipts were often as much as 48 hours behind transactions
that already occurred.  So, in thinking that I had plenty in my
account, I would make a withdrawal, only to have the bank charge me
$20 for overdrafting my account.  They admitted that the balances
weren't always accurrate, and cannot be trusted.   Of course, they
don't tell you that when you apply for the card...

Another possiblity is when the bank's computer is down.  Sometimes,
the network simply refuses to allow me access to my funds.  But at
other times, I was allowed to make a withdrawal, but my account
balance was "unavailable".

It makes me wonder how much banks have made by suckering customers
into believing that they have more funds in their account then they
actually have, and having them unknowingly overdraw on their
accounts?

From now on, I always keep the receipts, and balance the account on my own.  My
suggestion:  never trust the balance figure that the ATM prints out.

George H. Feil (HAL) 

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.24.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.26.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-67</DOCNO>
<DOCOLDNO>IA012-000129-B047-492</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.26.html 128.240.150.127 19970217022256 text/html 23476
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:21:20 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 26</TITLE>
<LINK REL="Prev" HREF="/Risks/7.25.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.27.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 26</H1>
<H2>  Saturday 23 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Misuse of the UK Data Protection Act 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Risks of not running new software in parallel with old 
</A>
<DD>
<A HREF="#subj2.1">
Jon Reeves
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer Error causes bills to be mailed to wrong address 
</A>
<DD>
<A HREF="#subj3.1">
Todd Medlin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Penetrating the Phone System 
</A>
<DD>
<A HREF="#subj4.1">
John Markoff via Geoff Goodfellow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Electronic IQ Testing 
</A>
<DD>
<A HREF="#subj5.1">
Stephen Colwill
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: IRS and Electronic Filing 
</A>
<DD>
<A HREF="#subj6.1">
Bill Bohrer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: The IRS Illinois Experiment 
</A>
<DD>
<A HREF="#subj7.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: "Man in the loop" 
</A>
<DD>
<A HREF="#subj8.1">
Will Martin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Misuse of the UK Data Protection Act
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Thu, 21 Jul 88 11:29:20 WET DST
</i><PRE>

RISKS readers are all too used to learning of new ways in which the power of
computers has been creatively misused. This posting, however, concerns misuse
of a law which was itself in part intended to prevent computer misuse!

One of the provisions of the UK Data Protection Act, which is now in force,
enables individuals to have the right to obtain copies of information held
about them in computers (excepting by the security organisations, etc.). An
article in the 21 July 1988 issue of Computing reveals that the Act is being
abused by employers who are using it to check up on prospective employee's
backgrounds. It quotes the fourth report of the Data Protection Registrar as
complaining that:
 
  "Employers are using the Act as a back door for getting an individual's
  record, and this is wrong... To use the Act to force individuals to find and
  reveal information about themselves is contrary to the objectives of data
  protection and should be stopped."

The article explains that this misuse is most common by local authorities
checking up on taxi drivers prior to granting trading licenses, It quotes the
Assistant data protection registrar:

  "Individuals are in a difficult position as they want the job and are not too
  keen to stand up for their rights ... the problem is that minor offences,
  which under the Rehabilitation of Offenders Act no longer count against an
  individual, still appear on police records."

Apparently it will take a change in the law to make it illegal for someone to
be forced to exercise his rights under the Data Protection Act.

Brian Randell, Computing Laboratory, University of Newcastle upon Tyne

JANET =	Brian_Randell@uk.ac.newcastle 
UUCP  =	...!ukc!newcastle.ac.uk!Brian_Randell           PHONE =	+44 91 232 9233

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Risks of not running new software in parallel with old
</A>
</H3>
<address>
Jon Reeves
&lt;<A HREF="mailto:reevesdecvax.dec.com ">
reevesdecvax.dec.com 
</A>&gt;
</address>
<i>
Wed, 20 Jul 88 21:05:42 EDT
</i><PRE>

Regular readers have probably heard stories like this before, but it's worth
repeating.

The Bill's in the Mail  [Corporate Report Minnesota, July 1988; by Lee Schafer]

Mona, Meyer &amp; McGrath, the Bloomington [Minnesota] public relations firm that
placed 470 on the 1987 Inc. [magazine] 500 list of fastest growing companies,
is still feeling the effects of a no-growth course of action that it
unwittingly adopted late last year and early this year.

It all started last summer when Mona, Meyer decided that it had outgrown its
accounting and billing system, which, according to partner Scott Meyer, was
suited to a company with $1 million in annual revenue, rather than the $5
million company Mona, Meyer had become. ... The partners ... decided to hire a
Dallas firm, Data Directions Inc., to create a custom system.

In October 1987, the software firm figured the necessary work was completed,
but advised Mona, Meyer to continue to run the old system--just in case.  This
advice was ignored.  "We decided to pull the plug on the old system and flip
the switch on the new one," Meyer says.  The intent was to save some staff time
by running a single system.  "Well, we flipped the switch and it didn't work."

October, November, and December billings went uncompleted while Mona, Meyer
scrambled for solutions.  October and November bills were finally mailed in
January, but they were prepared by hand.  Only by mid-March did the system work
well enough to allow a combined January and February billing to be mailed.

As one might expect with ceased income but continued outgo, Mona, Meyer faced a
cash-flow crunch by mid-January. ... Meyer says bank loans carried the firm
until the billing situation was straightened out.  Although phones weren't
ringing off the hook with clients wondering about their bills, a few customers
were unhappy with the situation because they had to pay for 1987 services out
of 1988 budgets.
                                          Jon Reeves

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer Error causes bills to be mailed to wrong address
</A>
</H3>
<address>
Todd Medlin
&lt;<A HREF="mailto:medlin@csclea ">
medlin@csclea 
</A>&gt;
</address>
<i>
Thu, 21 Jul 88 18:23:07 edt
</i><PRE>

Local radio stations (in the Research Triangle Park, NC area) carried a story
this morning concerning incorrect billing to students at NC State. 
It seems that the program used to generate bills would correctly 
generate a student's bill, but, then address it to the wrong student.
The problem was discovered only after 6000 bills were mailed to 
the wrong students.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Penetrating the Phone System
</A>
</H3>
<address>
the tty of Geoff Goodfellow
&lt;<A HREF="mailto:geoff@Fernwood.MPK.CA.US ">
geoff@Fernwood.MPK.CA.US 
</A>&gt;
</address>
<i>
Fri, 22 Jul 88 09:39:16 PST
</i><PRE>

PERSONAL COMPUTER USERS PENETRATING NATION`S TELEPHONE SYSTEM
By JOHN MARKOFF with ANDREW POLLACK (c.1988 N.Y. Times News Service)

  NEW YORK - Sophisticated personal computer users are becoming increasingly
adept at penetrating the nation's telephone system, raising questions about the
security and privacy of the phone system, industry experts and law enforcement
offiials say.  The vulnerability of the phone system to such tampering has
grown significantly in the past decade or so as telephone companies have
largely replaced electro-mechanical call-routing equipment with
computer-controlled switches.
  As a result, people with the expertise can illegally connect their personal
computers to the phone network. With the proper commands, these intruders can
do such things as eavesdrop, add calls to someone's bill, alter or destroy
data, have all calls to a particular number automatically forwarded to another
number or keep someone's line permanently busy, it was disclosed in an internal
memorandum written by a manager of electronic security operations at the San
Francisco-based Pacific Bell Telephone Co. and in interviews with company
officials.
  Peter Neumann, a computer security consultant at SRI International Inc. in
Menlo Park, Calif., said telephone companies are only beginning to awaken to
the security problems created by the increasing computerization of the
telephone network.  ``As far as our vulnerability, we all have our heads in the
sand,'' he said. ``We have to redefine our notions of what we entrust to
computers and to communication networks.''
  Some personal computer enthusiasts, often called ``hackers,'' view the task
of breaking into the telephone system as a test of their skills and only
infrequently inflict damage, industry officials and consultants say. But others
act with criminal intent.
  In his memo, the Pacific Bell security manager also warned that an electronic
intruder could essentially disable an entire central switching office for
routing calls, disrupting telephone service to entire neighborhoods.
Furthermore, he said, organized-crime groups or terrorists might use such
technology to their own advantage.
  The integrity of customer bills could also be compromised, he said. Customers
might rightfully or wrongfully dispute expensive calls, claiming the calls were
placed on their bills by computer hackers.
  Earlier this month, a teen-age computer enthusiast who requested anonymity
provided The New York Times with the Pacific Bell memo, which was written a
year ago. He said it had been obtained by a fellow hacker who illicitly
eavesdropped on a facsimile transmission between Pacific Bell offices in San
Francisco.  The memo, which Pacific Bell verified as authentic, concluded that
``the number of individuals capable of entering Pacific Bell operating systems
is growing'' and that ``computer hackers are becoming more sophisticated in
their attacks.''
  In one of two cases cited in the memo, a group of teen-age computer hobbyists
were able to do such things as ``monitor each other's lines for fun'' and
``seize another person's dial tone and make calls appear on their bill,'' the
memo said. One of the hackers used his knowledge to disconnect and tie up the
telephone services of people he did not like. In addition, ``he would add
several custom-calling features to their lines to create larger bills,'' the
memo said.
  In the second case, police searched the Southern California home of a man
thought to be breaking into the computers of a Santa Cruz, Calif., software
company. They discovered the man could also gain access to all of Pacific
Bell's Southern California switching computers.  wFiles were found containing
codes and employee passwords for connecting with -- or ``logging on to'' -- the
Pacific Bell switching systems and related computers. The man also had commands
for controlling the equipment.
  In another case involving tampering with telephone company switching
equipment, local police and the FBI in the San Francisco area are investigating
Kevin Poulsen, a former programmer at Sun Microsystems, said Joseph Burton, an
assistant U.S. attorney in San Jose, and John Glang, a deputy district attorney
for San Mateo County.
  Authorities searched Poulsen's apartment in Menlo Park in February as well as
the residence of a suspected accomplice in San Francisco, the officials said.
Poulsen was said to be in Southern California and was unavailable for comment.
  Burton said he could not discuss a current investigation. Glang would say
only that the case had been taken over by the federal government because
``there are some potential national security overtones.''  But a security
expert familiar with the case, who requested anonymity, said that Poulsen
``pretty clearly demonstrated you can get in and romp around inside a Bell
operating system.''  ``What it pointed out,'' he said, ``was the serious
vulnerability.''
  Security consultants said other phone companies are equally vulnerable to
such breaches. They noted that most phone service in the nation is provided by
companies that were part of the Bell System until it was broken up in 1984 and
still use similar equipment and procedures.
  Michigan Bell officials said they had caught an intruder who tampered with
the company's switching equipment last year. A spokesman declined to give
details of the incident but said no arrest was made. ``We have been able to
tighten our security arrangements,'' said Phil Jones, a company spokesman.
``There were lessons to be learned here.''
  Jack Hancock, vice president for information systems at Pacific Bell, said
his company had also taken steps to make it tougher to penetrate its systems.
He said, however, that the company had to strike a balance between security and
cost considerations so the phone system would still be widely affordable and
easy to maintain.
  ``We could secure the telephone system totally, but the cost would be
enormous,'' he said. ``A public service will probably always have certain
insecurities in it.''
  Though Pacific Bell refused to disclose the security measures it had taken,
the company said it had restricted the ability to dial into its computers from
remote points.
  As computerized communications become more sophisticated, companies will be
able to improve security at a reasonable cost, said Barry K. Schwartz, a
systems planning manager at Bell Communications Research, which does research
for the seven Bell operating companies.  It will be increasingly possible to
program a computer so it will only answer a call from an authorized phone, he
said. Another new technology on the horizon, he said, is electronic voice
verification. A security system using this technology would be able to
recognize those authorized to gain access to a computer by their voice
patterns.
  Telephone companies have long had to worry about electronic abuse of their
networks.  For several decades individuals have used electronic equipment to
make long-distance phone calls for free. Some have used devices that generate a
series of tones that provides access to long-distance lines. Telephone
companies have installed equipment on their lines to detect and thwart such
abuse.  In other instances, people have used personal computers to find
long-distance access codes belonging to other users. They do this by
programming computers to keep trying various numbers until they hit upon one
that works.  But while costly, these kinds of abuse are not much of a threat to
the integrity of the system because they do not affect the system itself.
  The new problems involving network tampering are arising, experts say,
because the switches that route calls are now mostly electronic, meaning they
are essentially big computers. If a customer wants an option like call
forwarding or call waiting added to his or her telephone service, that is done
by typing commands into a computer, not by moving wires and switches.
  Pacific Bell said 79 percent of its customers are now served by computerized
switching systems.  Experts say these electronic networks are especially
vulnerable to tampering because it is possible to dial up the computers
controlling the switches from the outside. Phone companies designed their
systems this way to make it easier for them to change the system and diagnose
problems.  For example, a technician in the field trying to diagnose problems
on a line needs to be able to dial certain test circuits in the central office.
But such a dial-up capability can also be used by outsiders with personal
computers and modems who know the proper numbers to call and the proper
procedures to get on the system.
  The ability to eavesdrop on telephone calls is included in the system to
allow an operator to check to see whether a line that is busy for a long time
is being used or whether the phone is off the hook or the line is broken.
  One security consultant who requested anonymity said this capability had also
made it much easier for law enforcement officials to wiretap a line. When the
police receive court permission to conduct a wiretap, they can have the phone
company dial up the switch serving the line so conversations can be monitored
from a remote location.  Obtaining the information needed to break into the
phone system can be difficult, but intruders often do it by impersonating phone
company employees -- a practice that hackers call ``social engineering.''
  A teen-ager interviewed by Pacific Bell officials after his arrest told
investigators that he had entered a number of Pacific Bell facilities in the
San Francisco area disguised as a Federal Express delivery man in order to
search for manuals and other documents, according to the company memo. The
youth also said he had impersonated telephone security officials to obtain
passwords and other information.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Electronic IQ Testing
</A>
</H3>
<address>
Stephen Colwill 
&lt;<A HREF="mailto:mcvax!praxis!steve@uunet.UU.NET">
mcvax!praxis!steve@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 21 Jul 88 9:58:09 BST
</i><PRE>

People interested in scenarios arising from the possibility of mechanised IQ
testing might like to read `Player Piano' by Kurt Vonnegut. I say no more!

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: IRS and Electronic Filing
</A>
</H3>
<address>
ASTROBOY 
&lt;<A HREF="mailto:LI.BOHRER@A20.CC.UTEXAS.EDU">
LI.BOHRER@A20.CC.UTEXAS.EDU
</A>&gt;
</address>
<i>
Fri 22 Jul 88 00:59:28-CDT
</i><PRE>

Lars Poulson writes (regarding the IRS Tax return proposal):

&gt;The note projects that the IRS would save $63.50 for each electronically filed
&gt;return, and that the tax preparers would charge $60-$80 on top of their
&gt;preparation fee. This seems like a lot of money for what would seem like a
&gt;10-minute data entry task. I thought data entry jobs paid about $10-$15/hour;
&gt;double that for G&amp;A overheads, and I get $5/return.  Network costs may be
&gt;another $5, but while these would be a cost to the tax preparers, the IRS woul
&gt;incur them.

I don't know where you got your information about what data-entry pays, but,
at least in the Austin TX job market, you're off by as much as 300%.  Data
entry clerks (the key word here is `clerks') at the IRS facility here start
at $4.65/hr and all you need is a high school diploma.  This salary is true
of the market in general. (I have checked.)  Wendy's starts at $4.25/hr, for
crying out loud, and you don't even need a *brain* to work there.

The biggest advantage in having a tax preparer file your return
electronically is that you will circumvent the underpaid, overworked,
slightly addled civil servant and can be reasonably sure that the numbers
were correctly entered.  If you send in your paper from, and the
caffeine-crazed/caffeine-depleted drone enters the numbers incorrectly, you
then have to deal with the Tax Examiner.  They are paid the premium salary
of $5.50/hr, and need a college degree for that.  Needless to say, these
jobs do not garner the nation's best.

Bill Bohrer

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: The IRS Illinois Experiment
</A>
</H3>
<address>
&lt;<A HREF="mailto:mnetor!utzoo!henry@uunet.UU.NET">
mnetor!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 22 Jul 88 20:31:58 EDT
</i><PRE>

&gt;...  Where do these savings come from ?

The key point is that money that used to come out of the IRS budget now will
come out of yours.  This is why the IRS is big on the idea.  The question is
whether they can make it attractive enough to sell it.

Henry Spencer @ U of Toronto Zoology

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Re:  "Man in the loop"
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Tue, 19 Jul 88 15:51:22 CDT
</i><PRE>

&gt; The July 18 Los Angeles Times carries an op-ed piece by Peter D. Zimmerman
&gt;  ... But the real lesson from the tragedy in the Persian Gulf is that 
&gt;  computers, no matter how smart, are fallible.  Sensors, no matter how 
&gt;  good, will often transmit conflicting information.  The danger is not 
&gt;  that we will fail to prepare the machines to cope with expected situa-
&gt;  tions.  It is the absolute certainty that crucial events will be ones 
&gt;  we have not anticipated.

I would have a lot more respect for Mr. Zimmerman if he had added the line,

   " -- and that people, too, no matter how smart, are fallible."

to the first sentence above.  GIGO applies not only to computers but to humans,
except that we are complex enough computing devices to often perform
unconscious "sanity checks" that we probably would fail to implement in
software.

After all, there WAS a "man in the loop" on the Vincennes -- the computers did
not automatically fire the missiles without human intervention.

Will Martin

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.25.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.27.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-68</DOCNO>
<DOCOLDNO>IA012-000129-B047-513</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.27.html 128.240.150.127 19970217022307 text/html 18499
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:21:37 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 27</TITLE>
<LINK REL="Prev" HREF="/Risks/7.26.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.28.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 27</H1>
<H2>  Monday 25 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
A Fishy Story 
</A>
<DD>
<A HREF="#subj1.1">
John Colville
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Inconsistent Data Taxes Vancouver Woman 
</A>
<DD>
<A HREF="#subj2.1">
Don Chiasson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer Viruses and RETROVIRUSES 
</A>
<DD>
<A HREF="#subj3.1">
Peter J. Denning
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Hacking central office switches - too easy? 
</A>
<DD>
<A HREF="#subj4.1">
John T. Powers Jr.
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  "Man in the Loop" 
</A>
<DD>
<A HREF="#subj5.1">
Bill Murray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  AEGIS 
</A>
<DD>
<A HREF="#subj6.1">
Herb Lin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Journal of Computing and Society 
</A>
<DD>
<A HREF="#subj7.1">
Gary Chapman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Barcodes 
</A>
<DD>
<A HREF="#subj8.1">
Jerome H. Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  The IRS Illinois Experiment 
</A>
<DD>
<A HREF="#subj9.1">
Lenoil
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  "Scratch-and-win"? Try "X-ray-and-win"! 
</A>
<DD>
<A HREF="#subj10.1">
Fred Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  PIN on PNB calling card 
</A>
<DD>
<A HREF="#subj11.1">
Mark Mandel
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
A Fishy Story
</A>
</H3>
<address>
John Colville
&lt;<A HREF="mailto:munnari!nswitgould.oz.au!colville@uunet.UU.NET ">
munnari!nswitgould.oz.au!colville@uunet.UU.NET 
</A>&gt;
</address>
<i>
Mon, 25 Jul 88 16:23:31 EST
</i><PRE>

From "The Sydney Morning Herald", 23 July 1988  (Reprinted without permission)

The new restaurant at the Opera House seems to be having a few technical
troubles. Three people lunching there yesterday ordered river trout.  Some
minutes later, an embarrassed waiter told them: "Sorry, we put the trout
through the cash register, and it came out in the kitchen as octopus."  The
diners settled for octopus anyway.
                                                  John Colville

  [Obviously the wrong "menu" popped up on the screen!  Or were they pulling
   somebody's leg (not the octopus') and using the computer as an excuse?  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Inconsistent Data Taxes Vancouver Woman
</A>
</H3>
<address>
Don Chiasson 
&lt;<A HREF="mailto:G.CHIASSON@DREA-XX.ARPA">
G.CHIASSON@DREA-XX.ARPA
</A>&gt;
</address>
<i>
Mon, 25 Jul 88 16:44:30 ADT
</i><PRE>

     From the Toronto Globe and Mail, page 3, July 25, 1988 (Canadian
Press), as usual without permission:

          BC Woman Alive And Well Despite What Taxman Says

     Judi Sommer insists she is alive and well and living in Vancouver. 
But the 40 year old has trouble convincing the taxman of that. 
     "They say their computer has me down as officially dead but gainfully
employed," she said during the weekend. 
     Ms Sommer said the dilemma is preventing her from collecting the
$1,200 she expects back from Revenue Canada. 
     "What do I have to do to prove I'm alive?" the teacher asked. 
     Her troubles started in 1986 when her mother, Mollie, died.  A mixup in
her lawyer's office led to the placing of Ms Sommer's social insurance number
on her mother's death certificate.
     She said that, when she asked a Revenue Canada official last year if her
tax forms had been received, he told her the social insurance number she gave
belonged to a dead person.
     It took three months for her to sort out the problem and get her 1986 tax
refund ...  But she said she is now facing the same problem with her 1987
return.
     Revenue Canada spokesman Harm Dhillon acknowledged that mistakes are made
occasionally, but added that he has never heard of someone being both dead and
gainfully employed at the same time in his 11 years with the tax office.
     Ottawa has promised to straighten out the mistake and forward Ms
Sommer her refund. 

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer Viruses and RETROVIRUSES (Re: <A HREF="/Risks/7.23.html">RISKS-7.23</A>)
</A>
</H3>
<address>
Peter J. Denning 
&lt;<A HREF="mailto:pjd@riacs.edu">
pjd@riacs.edu
</A>&gt;
</address>
<i>
Sat, 23 Jul 88 14:10:53 pdt
</i><PRE>

Peter Neumann asked what terminology could be applied to the corrupted data
that propagated through a system or network.  The closest biological analogy
is the retrovirus.  A retrovirus (such as the HIV, or human immunodeficiency
virus, or AIDS) incorporates itself into the genetic material of the cell
that it attacks, causing the cell to alter its function; the reproductive
processes of the cell spawn new copies of the retrovirus.  The retrovirus is
not capable of self-reproduction.  So Neumann's ARPANET node "data virus" is
analogous to a retrovirus.

But let's be careful about the analogies with biology.  They are intriguing
metaphors that give the appearance that our machines have lives of their own,
and absolve us of the responsibilities for their behavior.

Peter Denning

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Hacking central office switches - too easy?  [See also <A HREF="/Risks/7.26.html">RISKS-7.26</A>]
</A>
</H3>
<address>
"John T. Powers Jr. (Jac"  
&lt;<A HREF="mailto:POWERS@ibm.com">
POWERS@ibm.com
</A>&gt;
</address>
<i>
23 Jul 88 00:08:58 PDT
</i><PRE>

I read a New York Times article in the San Jose Mercury-News for Friday,
7/22/88 which spoiled my day.  The title was fairly routine: "Computer users
break privacy, security of phones".  Being mildly interested in security, I
read it anyway.

If this article is correct, crackers have been playing games with Pacific Bell
central office switches up to no less than a year ago, maybe even now.  It
appears that open modems were left on what I would call "console" ports,
allowing crackers access to operator-class commands after guessing or otherwise
obtaining passwords.  Once logged on, "visitors" could reportedly disconnect a
line, assign it to another account ("steal dial tone"), and who knows what
other mischief.

It would have been easy for them to make this kind of activity much harder than
it evidently was.  A simple callback system (something I introduced at IBM
about 10 years ago, and common now) would, if used correctly, make it *much*
harder to gain unauthorized access to a CO switch.  In addition, it would
probably warn of interest by unauthorized persons.  Today, much more
sophisticated security systems are not only available but cheap.

It amazes me that a phone company, of all possible victims, would omit such a
simple and effective barrier to mischief.  It would have cost them almost
nothing.  I've toured a number of Pacific Bell COs, and their physical security
looks pretty good to me.  It's almost *inconceivable* to me that that they
would leave a back door open via, of all things, the bleeping *telephone*.

Anyone know how accurate this report is, and what PacBell did about it, if
true?

Does this remind you of another recent security horror story?

Disclaimer: These are my views only... and even I might disclaim them later.
Jack Powers    IBM Almaden Research Lab   powers@ibm.com
Flames at 1200bps or less to 408/779-7472. Voice: 408/927-1495. Share water.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
"Man in the Loop"
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 19 Jul 88 09:31 EDT
</i><PRE>

Rodney Hoffman offers:

  &gt;Despite the fact that the Aegis system has been exhaustively tested at the
  &gt;RCA lab in New Jersey and has been at sea for years, it still failed to make
  &gt;the right decision the first time an occasion to fire a live round arose.

It is clear that the first time that it hit a target, it was a friendly
target.  What evidence is that this is the first opportunity, or even
the first round?  [I also question "exhaustively."  One of the problems
of this class of system is that they do not permit of exhaustive testing.]

[As did Will Martin (<A HREF="/Risks/6.26.html">RISKS-6.26</A>), Bill noted that "People are fallible".  PGN]
Still, they are less fallible in an anticipatory mode than they are in a life
and death crisis situation.
                                            Bill Murray

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
AEGIS
</A>
</H3>
<address>
Herb Lin 
&lt;<A HREF="mailto:LIN@XX.LCS.MIT.EDU">
LIN@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Sun, 24 Jul 1988  07:26 EDT
</i><PRE>

For more commentary on AEGIS and SDI, you might find an article in Scientific
American interesting -- December 1985, on computer software and SDI.  It
contains a description of the early operational testing of AEGIS (including
defects in the testing), and draws comparisons to SDI.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Journal of Computing and Society
</A>
</H3>
<address>
Gary Chapman
&lt;<A HREF="mailto:chapman@csli.stanford.edu ">
chapman@csli.stanford.edu 
</A>&gt;
</address>
<i>
Sun, 17 Jul 88 10:59:33 PDT
</i><PRE>

CALL FOR PAPERS   for   THE JOURNAL OF COMPUTING AND SOCIETY

P.O. Box 717, Palo Alto, CA  94301, (415) 322-3778

The Journal of Computing and Society will begin publishing in late 1988.  It
will be a quarterly journal of material on the social implications of computing
technology and computerization.  The journal is soliciting articles on
computers and privacy, computers and war, computers and power relations,
computers and gender, computers and politics, computers and social theory, and
similar subjects.

The deadline for the Spring 1989 issue is September 15, 1988.  

The emphasis in this journal will be on high quality writing and provocative
ideas.  Original research is welcome, but the journal will try to avoid
conventional academic writing in favor of well-crafted essays.  The journal is
intended to appeal to a general audience as well as the profession of computer
science.  Preference in publication will be given to material showing
originality, creativity, relevance to substantive problems in society, and
readability.  There will be no political or philosophical prejudice--all
viewpoints are welcome.

The Journal of Computing and Society is edited by Gary Chapman, executive
director of Computer Professionals for Social Responsibility.  Questions
regarding manuscripts should be directed to him at the address above.  

Manuscripts should be submitted in quadruplicate, typed or laser-printed, on 8
1/2" x 11" paper with one-inch margins all around.  The Journal's style will be
the same as that of The Chicago Manual of Style and The Communications of the
ACM.

The editorial board of the Journal of Computing and Society consists of the
following people:  Jerry Berman; Margaret Boden; David Burnham; Hubert Dreyfus;
Jean-Louis Gassee; Calvin Gotlieb; Douglas Hofstadter; Deborah Johnson; Rob
Kling; John Ladd; Abbe Mowshowitz; Peter G. Neumann; Susan Nycum; Kristen
Nygaard; Paul Saffo; Mike Sharples; Lenny Siegel; Luca Simoncini; Brian Smith;
Lucy Suchman; Zhisong Tang; Joseph Weizenbaum; Alan F. Westin; Langdon Winner;
and Terry Winograd.

Subscription rates for The Journal of Computing and Society have not yet been
determined, but there will be a personal subscription rate for individuals.

The Journal of Computing and Society will be published by Ablex Publishing
Corporation of Norwood, New Jersey.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Barcodes (re: <A HREF="/Risks/7.13.html">RISKS-7.13</A> )
</A>
</H3>
<address>
Jerome H. Saltzer 
&lt;<A HREF="mailto:Saltzer@ATHENA.MIT.EDU">
Saltzer@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Fri, 22 Jul 88 14:37:04 EDT
</i><PRE>

&gt; From: dap@cgl.ucsf.EDU (David A. Pearlman)
&gt; Subject: Grocery Store Barcodes: Another game you don't win
&gt; All this talk about how ATM's don't make mistakes in the customer's
&gt; favor reminds me of one of my pet peeves: When the price on the food
&gt; shelf is not the same as the price scanned at the cash register.

This is a case in which a combination of technology and store policy can
make a big difference.  The last Albertson's store in which I shopped had a
voice synthesizer that announced the price of every item scanned, and a big
sign saying that if the price scanned isn't identical to the price on the
shelf you get the item for free.

					Jerry Saltzer

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
The IRS Illinois Experiment
</A>
</H3>
<address>
&lt;<A HREF="mailto:LENOIL@XX.LCS.MIT.EDU">
LENOIL@XX.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 25 Jul 1988  14:19 EDT
</i><PRE>

One way to partially automate the filing process without granting online
access to IRS computers to the masses would be to supply a tax filing program
to taxpayers and allow them to file on floppy disk.  The cost would be more
than direct electronic filing, but should be less than a paper return.

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
"Scratch-and-win"? Try "X-ray-and-win"! [<A HREF="/Risks/7.13.html">RISKS-7.13</A>]
</A>
</H3>
<address>
Fred Baube 
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Fri, 01 Jul 88 14:40:53 -0400
</i><PRE>

Even if they make instant-win lottery cards immune to non-
destructive testing by X-ray, aren't there small CAT scanners
or NMR imagers out there that can determine the location of ink
molecules, providing the same winner/no-winner information ?

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
 PIN on PNB calling card
</A>
</H3>
<address>
Mark Mandel 
&lt;<A HREF="mailto:Mandel@BCO-MULTICS.ARPA">
Mandel@BCO-MULTICS.ARPA
</A>&gt;
</address>
<i>
Thu, 21 Jul 88 16:48 EDT
</i><PRE>

Agreed, the calling card with magnetically-encoded PIN is similar to a
credit card, though a credit card still provides a security barrier of
sorts in the signature.  But according to the description we were given,
PNB doesn't tell you so.  What started this discussion was someone's
report of PNB's form letter accompanying the mailed card, in which they
said,
  a:  For security, don't write your PIN on your card or keep it
      in the wallet, and
  b:  You don't even need to remember your PIN because the card
      encodes it!

We who read this digest recognize the contradiction here, but we're not
typical consumers.  The PINheads who set up that arrangement and wrote
the letter don't seem to see that (a) is no protection in light of (b).
How can Jane and Joe Average be expected to see it?  Pacific Northwest
Bell's irresponsibity lies not so much in mag-encoding the PIN, per se,
as in failing to inform the card's users of the resulting risk, and in
actually disguising this risk by warning them to keep the PIN separate
from the card.
                                        -- Mark Mandel

 * My employer is not responsible for anything I say, think, do, or eat.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.26.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.28.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-69</DOCNO>
<DOCOLDNO>IA012-000129-B048-13</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.28.html 128.240.150.127 19970217022320 text/html 19569
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:21:49 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 28</TITLE>
<LINK REL="Prev" HREF="/Risks/7.27.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.29.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 28</H1>
<H2>  Tuesday 26 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Pentagon testing 
</A>
<DD>
<A HREF="#subj1.1">
Mike Trout
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: "Man in the Loop" 
</A>
<DD>
<A HREF="#subj2.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  NOVA on risks of fighter technology 
</A>
<DD>
<A HREF="#subj3.1">
Dave Curry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Hacking central office switches 
</A>
<DD>
<A HREF="#subj4.1">
Laura Halliday
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Law student sues micro sysop under ECPA 
</A>
<DD>
<A HREF="#subj5.1">
John Gilmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Scanning instant-win lottery cards 
</A>
<DD>
<A HREF="#subj6.1">
Rich Kulawiec
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Wanted: Info on Ergonometrics 
</A>
<DD>
<A HREF="#subj7.1">
Emily S. Bryant for Michael Whitman
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Pentagon testing (an oxymoron)  (Re: <A HREF="/Risks/7.24.html">RISKS-7.24</A>)
</A>
</H3>
<address>
Mike Trout
&lt;<A HREF="mailto:miket@brspyr1.brs.com ">
miket@brspyr1.brs.com 
</A>&gt;
</address>
<i>
25 Jul 88 21:21:13 GMT
</i><PRE>

In article &lt;12415398632.18.NEUMANN@KL.SRI.COM&gt;, Gary Chapman writes:

&gt; Subject: Aegis testing data withheld from Congress
&gt; Defense Week reports that an unclassified report of the General Accounting
&gt; Office (GAO) reveals that the Navy withheld testing problems of the Aegis
&gt; air defense system from the Congress.  "Personnel and Aegis equipment were
&gt; not subjected to targets or tactics that would be found in combat," ...

This is typical of Pentagon testing, and seems to be particularly prevalent in
the Aegis system.  An interesting parallel concerns the testing for the Phalanx
close-in shipboard missile defense system, which of course is included as part
of the Aegis umbrella.  The Navy's final results of the testing conducted for
Phalanx reported that the system had achieved greater than 80% "success."  But
what was the definition of "success?"  Pentagon watchdog groups did a little
digging with the Freedom of Information Act, and determined that "success" had
been interpreted as "destruction of the incoming missile."  Well, that seemed
okay, so most investigations were dropped.  But some whistle-blowers in the
Pentagon produced some disconcerting information.  While it was true that
simulated incoming missiles had indeed been "hit" and "destroyed," it had been
determined that the debris and rocket fuel of the destroyed missile would
continue onward and hit the ship, causing tremendous impact and an inevitable
fire.  It was estimated that this would be enough to destroy or knock out
nearly any vessel.  But since the simulated missiles had been "destroyed," the
Navy proudly announced that Phalanx had passed the test.  Empirical evidence
from the Falklands war makes the Phalanx testing look even less realistic.
Only one of the Exocets hitting Royal Navy ships exploded, yet the dud Exocets
still did hellish damage, including sinking two ships.  It also appears that
the missile that hit the USS _Stark_ did not go off.

Another example uncovered by the Dina Rasor group:  A mobility/breakdown test
was conducted for the new M-1 Abrams tank.  The tank failed the test.  The test
was run again, with identical results.  The Aberdeen Proving Grounds was
instructed to just keep running the test until the tank passed.  On the 161st
try, the tank passed the test.  The testing information provided to Congress
included only that which pertained to the 161st test; the previous 160 tests
were not even mentioned.

Rasor has also uncovered suspicious changes in the testing for both ALCM and
GLCM (Air- and Ground- Launched Cruise Missiles).  Recent stories of doctored
test results for the Rockwell B-1B are similar.  

In any system in which hardware or software is to undergo a realistic test, it
is critical that ALL test results be released, unaltered.  Any other course of
action changes the test from a realistic simulation to a public relations
gimmick.  In the case of software written for a computer game, the results of
doctored testing may be comical.  In the case of a military weapon, the results
may be disastrous. 

Michael Trout (miket@brspyr1) =-=-=-=-=-=-= UUCP:brspyr1!miket
BRS Information Technologies, 1200 Rt. 7, Latham, N.Y. 12110  (518) 783-1161

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: "Man in the Loop"
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
26 Jul 88 07:38:52 PDT (Tuesday)
</i><PRE>

I recently posted excerpts from Peter Zimmerman's article about AEGIS and Star
Wars and the "man in the loop".  Just in case it wasn't clear, all but the lead
introductory sentence of that was from Peter Zimmerman, not directly from me.
Anyone wishing a copy of his complete article may contact me.

I completely agree with Will Martin and Bill Murray when they each insisted on
adding to Zimmerman's piece a stronger statement about HUMAN fallibility.  

In my initial posting, I thought I would let Zimmerman speak for himself.  In
light of the responses, I probably should have appended my own reactions.  In
particular, I believe many lessons implicit in Zimmerman's piece (and familiar
to all RISKS readers) are well-taken.  Among them:

  * The blind faith many people place in computer analysis is rarely
    justified.  (This of course includes the hype the promoters use to
    sell systems to military buyers, to politicians, and to voters.)

  * Congress's "man in the loop" mandate is an unthinking palliative,
    not worth much, and it shouldn't lull people into thinking the problem
    is fixed.

  * To have a hope of being effective, "people in the loop" need additional
    information and training and options.

  * Life-critical computer systems need stringent testing by disinterested
    parties (including operational testing whenever feasible).

  * Many, perhaps most, real combat situations cannot be anticipated.

  * The hazards at risk in Star Wars should rule out its development.

Rodney Hoffman 

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
NOVA on risks of fighter technology
</A>
</H3>
<address>
Dave Curry
&lt;<A HREF="mailto:davy@intrepid.ecn.purdue.edu ">
davy@intrepid.ecn.purdue.edu 
</A>&gt;
</address>
<i>
Mon, 25 Jul 88 16:59:49 EST
</i><PRE>

WTTW (Channel 11), the Chicago PBS station, showed a commercial last night
for a NOVA episode on the risks of fighter plane technology.  The preview
blurb mentioned questions like is there too much data for the pilot to keep
track of, are G's too great, etc.

I would assume other PBS stations will have this episode at some point also
(I'm not a regular watcher of PBS or NOVA, so I don't know how they work).
WTTW is showing it on Tuesday 7/26/88 at (I believe) 9pm EDT.

--Dave Curry, Purdue University

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
re: Hacking central office switches
</A>
</H3>
<address>
&lt;<A HREF="mailto:Laura_Halliday@mtsg.ubc.ca">
Laura_Halliday@mtsg.ubc.ca
</A>&gt;
</address>
<i>
Mon, 25 Jul 88 14:30:38 PDT
</i><PRE>

John T. Powers Jr. writes (Risks 7.27):
 
&gt; It would have been easy for them to make this kind of activity much harder 
&gt; than it evidently was. ...

When I worked for BCTel, we had an even simpler solution: remote access to
the console was over dedicated lines. Grossly unsophisticated, but effective.
 
laura halliday            laura_halliday%mtsg.ubc.ca@um.cc.umich.edu

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Law student sues micro sysop under ECPA
</A>
</H3>
<address>
John Gilmore
&lt;<A HREF="mailto:hoptoad.UUCP!gnu@cgl.ucsf.EDU ">
hoptoad.UUCP!gnu@cgl.ucsf.EDU 
</A>&gt;
</address>
<i>
Mon, 25 Jul 88 22:09:35 PDT
</i><PRE>

This appeared in a recent FidoNews (comp.org.fidonet on Usenet).
The FidoNet is a few thousand IBM PC's all calling each other over
dialup lines; similar to Usenet; less flexible; evolving faster.

     Copyright 1988 by  the  International  FidoNet  Association.  All
     rights  reserved.  Duplication  and/or distribution permitted for
     noncommercial purposes only.  For  use  in  other  circumstances,
     please contact IFNA at (314) 576-4067. IFNA may also be contacted
     at PO Box 41143, St. Louis, MO 63141.

     FidoNews 5-30                Page 3                   25 Jul 1988

     Jonathan D. Wallace, Esq.
     1:107/801


             SYSOP LIABILITY FOR DISCLOSING PRIVATE MESSAGES

     In what appears to be the first case of its kind, an Indiana law
     student and BBS user has sued a local sysop, Bob Predaina, in
     federal court, claiming that he intentionally disclosed her
     private electronic mail to others without her permission.

     The lawsuit, which is in the early stages and has not reached
     trial, relies upon the Electronic Communications Privacy Act of
     1986 (the "ECPA"), which makes disclosure of private electronic
     mail without consent either of the sender or the recipient a
     federal crime.

     The ECPA does not obligate sysops to offer private mail on their
     systems.  However, if a sysop promises private mail, that promise
     must be kept and the contents of private messages may not be
     disclosed without consent.

     The ECPA provides limited exceptions to the general rule of no
     disclosure.  A sysop may voluntarily disclose to law enforcement
     authorities the contents of a message pertaining to the
     commission of a crime, if read inadvertently by him or if it is
     read pursuant to the exercise of his duties as a sysop.

     Until the courts clarify these rules, sysops who read private
     mail on their systems and disclose it may be playing with fire.
     Prior court cases involving telephone operators have established
     some useful guidelines: an operator may disclose information she
     overheard while checking the line at the user's request, but may
     not disclose information overheard while eavesdropping out of
     curiosity.  Sysops, like phone operators, will not be considered
     to have a blanket authorization to intercept and disclose private
     messages.

               Systems  such  as  Fido 11w which  routinely  make  all
     private mail visible to the sysop are therefore problematic.  BBS
     programmers  should consider making private mail truly  private--
     while allowing sysops to turn the private mail option off if they
     do not want it.

               In the meantime, sysops should reconsider whether it is
     worth  having private mail on their systems and should make clear
     to users in no uncertain terms,  through bulletins and  messages,
     the degree of privacy which can be expected, if any.

               Note:  a copy of the complaint filed in the Thompson v.
     Predaina  case  is  available  on  the  LLM  BBS,   Fido  107/801
     (212)766-3788) in file area 5 under the name "Indiana".

          *                     *                          *

     JONATHAN D. WALLACE, ESQ. is an attorney in New York
     City specializing in computer law. With Rees Morrison, he is the
     author of the Sysop's Legal Manual, published this year by LLM Press.
     He can be reached at (212) 766-3785 (voice) or at the LLM BBS,
     given above.

     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 

The same issue of FidoNews also contains a relevant ad:

                      SYSOP LEGAL MANUAL FOR SALE

     SYSLAW, the Sysop's Legal Manual,
         by Jonathan D. Wallace Esq. and Rees Morrison Esq.

     This 130 page book, newly published by LLM Press, includes
     chapters on the Electronic Communication Privacy Act, sysop
     liability for illegal uploads such as pirated software and stolen
     credit card codes, libel and state computer crime laws.  The book
     is $21.00 (includes postage and handling) from LLM Press, 150
     Broadway Suite 610, New York, New York 10038.  New York residents
     include 8.25 percent sales tax.

         [This item is included in RISKS because the book might just answer
         questions that have been raised here repeatedly.  This notice
         represents no endorsement of the book, and is for your information
         only.  On one hand, much of the cited information is publically 
         available.  On the other hand, its compilation and interpretation in 
         one place might be useful -- assuming the book is accurate.  If this 
         redistribution in RISKS can in any way be deemed in violation of the 
         FidoNet banner above, then perhaps FidoNet itself was in violation of
         its own noncommercial dictum.  By the way, RISKS is unquestionably a 
         noncommercial effort, in case you hadn't noticed.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Scanning instant-win lottery cards (Re: <A HREF="/Risks/7.27.html">RISKS-7.27</A>)
</A>
</H3>
<address>
Rich Kulawiec
&lt;<A HREF="mailto:rsk@payton.cc.purdue.edu ">
rsk@payton.cc.purdue.edu 
</A>&gt;
</address>
<i>
Tue, 26 Jul 88 01:43:27 EST
</i><PRE>

	Fred Baube &lt;fbaube@note.nsf.gov&gt; writes:

	"Even if they make instant-win lottery cards immune to non-
	destructive testing by X-ray, aren't there small CAT scanners
	or NMR imagers out there that can determine the location of ink
	molecules, providing the same winner/no-winner information ?"

CAT scanners also use X-rays to produce an image, so a card immune
to "peeping" by a conventional X-ray machine is very likely to be immune
to a CAT scanner as well.  (All that is necessary for this is that the
inked area have the same absorption cross-section as the non-inked area.)
A similar comment applies to ultrasonic imaging techniques.  NMR imaging
might reveal the hidden print, if the ink molecules are distinguishable
from those non-ink molecules around them.  My (very casual) guess is
that using an area that's written in two shades of ink with slightly
differing formulations might defeat this approach; i.e. if both areas
consist of a substance with nearly the same chemical composition and
structure, they may be indistinguishable via NMR.

Rich Kulawiec

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Wanted: Info on Ergonometrics
</A>
</H3>
<address>
Emily S. Bryant
&lt;<A HREF="mailto:dartvax!eleazar!emilyb.UUCP@seismo.css.gov ">
dartvax!eleazar!emilyb.UUCP@seismo.css.gov 
</A>&gt;
</address>
<i>
25 Jul 88 18:42:52 GMT
</i><PRE>

I am posting the following for a colleague; please send responses by mail to:

  michael.whitman@dartmouth.edu  or  ...{decvax, ihnp4}!dartvax!michael.whitman
 
and NOT to me!  Thanks.  Emily Bryant.


  WANTED: Information on how to set up a computer workstation's screen,
  keyboard, and seating to minimize eyestrain and physical fatigue.

  I am interested in any research results which pertain primarily to
  eye- and backstrain, but am not looking for information on possible
  effects of video display terminals on pregnant operators.

  I am looking for recommendations on
  
  1) Worker's height : chair in inches;
  
  2) Distance from eyes to computer screen;
  
  3) Angle from eye level to center of screen;
  
  4) Height of keyboard above lap level;
  
  Also,
  
  5) Do higher screen resolution and refresh-rate reduce eyestrain?
  
  6) Is it personal preference or documentable fact that black letters
  on "white" background (Macintosh), green on black, amber on black, or
  some other combination, are easier on daylong viewers' eyes?
  
  8) What kind of ceiling fluorescent bulbs help reduce eyestrain?
  
  9) What kind of chairs help minimize backstrain?
  
  Finally, how about common sense suggestions in addition to these:
  
  10) Workers should look away periodically from their screens and
  focus on objects in the distance;
  
  11) Use a screen font which is large enough to be read easily;
  
  12) Use eyeglasses when computing for long hours, with a
  prescription specifically for one's actual eye-to-screen distance.
  
  
  I am researching a feature article for a publication at Dartmouth 
  College.  Since I have been able to find no recent articles on this
  except a NY Times 6/23/88 article, I hope suggestions for
  information sources will be sent.
  
  Michael Whitman
  Dartmouth College

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.27.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.29.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-70</DOCNO>
<DOCOLDNO>IA012-000129-B048-30</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.29.html 128.240.150.127 19970217022347 text/html 19236
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:22:14 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 29</TITLE>
<LINK REL="Prev" HREF="/Risks/7.28.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.30.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 29</H1>
<H2>  Wednesday 27 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Comparison of hazards 
</A>
<DD>
<A HREF="#subj1.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  NASTRAN and the order-of-magnitude bug 
</A>
<DD>
<A HREF="#subj2.1">
David E. Bakken
</A><br>
<A HREF="#subj2.2">
 via Mark Brader
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Person In The Loop" 
</A>
<DD>
<A HREF="#subj3.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  "Person In The Loop" -- A BarCode example 
</A>
<DD>
<A HREF="#subj4.1">
David A. Honig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Security vs. Cost of Breakin 
</A>
<DD>
<A HREF="#subj5.1">
David A. Honig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Hacking central office switches - too easy? 
</A>
<DD>
<A HREF="#subj6.1">
Skip Montanaro
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: PIN on PNB calling card 
</A>
<DD>
<A HREF="#subj7.1">
Roy Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: IRS Illinois Experiment 
</A>
<DD>
<A HREF="#subj8.1">
Allan Pratt
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Comparison of hazards
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 27 Jul 88 14:04:40 EDT
</i><PRE>

&gt;  * The hazards at risk in Star Wars should rule out its development.

Grace Hopper gave a talk here some years back in which she made a point that
is relevant to this discussion, and more generally as well.  I forget the
details, but she was in some bureaucratic situation where she was required
to take correspondence courses in *something*, and most of the possibilities
were ruled out because she was ineligible or had already taken them... so
she ended up taking War College courses, intended for training admirals and
such.  One of the exercises was to plan an invasion of an island, given some
details on overall situation, available manpower, etc.  Actually, that was
just the first part of the exercise.  The second part was "What would be the
consequences if your plan failed?".  The third, and most relevant, part was
"What would be the consequences of not attempting this plan?".  (Her
comment was that she'd seen many plans for information systems, very few
of which attempted to answer either of these questions.)

Comparisons of hazards should always be made against the real alternatives, not
against some hypothetical absolute standard (especially if the standard is the
mythical "absolute safety").  For example, using a jet fighter's ejection seat
is a dangerous act, with spinal injury not uncommon (ejection is a very violent
process), but it is usually preferable to the alternative of riding a crippled
aircraft down.  On the other hand, if the aircraft is near the ground and
upside down, it is safer to stay with the aircraft unless you have a very
modern ejection seat.  A realistic evaluation of the hazards of SDI must
compare them against realistic alternatives, rather than just saying "they are
too great".  Much of the popular support for SDI comes from the perception that
the alternative is a continuation of the current situation, which is perceived
to be unacceptably dangerous.  I don't think this an appropriate forum for
discussion of the accuracy of these perceptions, but one should not forget that
the alternative to risk often involves risks of its own.

Henry Spencer @ U of Toronto Zoology                  henry@zoo.toronto.edu

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
NASTRAN and the order-of-magnitude bug
</A>
</H3>
<address>
David E. Bakken
&lt;<A HREF="mailto:bakken@hrsw2.UUCP ">
bakken@hrsw2.UUCP 
</A>&gt;
</address>
<i>
Sat, 23 Jul 88 16:05:44 EDT
</i><PRE>
Date: 19 Jul 88 21:23:43 GMT
Remailed-by: msb@sq.com (Mark Brader)

I can't stand it anymore.

I was assigned the task of performing stress analysis on some roof bolts. I was
supposed to do the NASTRAN run on the UNIX machine because it has some special
math hardware, but I was in the middle of a game of rogue, so I used the IBM-PC
on my desk.  Unfortunately it was one of the really old ones, and it had the
divide by 10 bug. As a result, my caculations were off, and I'm afraid a
terrible thing happened.  As a result, effective Friday, I'm leaving Boeing, to
go work in a position where I can't hurt anybody.  Monday I start my new
position with Suzuki Motors Inc., in the suspension department.

Dave Bakken   Ex-Boeing Commercial Airplanes		(206) 277-2571

   [Assessment of which planes NOT to fly deleted by your moderator.  PGN]

</PRE>
<HR><H3><A NAME="subj2.2">
"Person In The Loop" (Clifford Johnson)
</A>
</H3>
<address>
Clifford Johnson 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Tue, 26 Jul 88 13:43:05 PDT
</i><PRE>

&gt;  I completely agree with Will Martin and Bill Murray when
&gt;  they each insisted on adding to Zimmerman's piece a stronger
&gt;  statement about HUMAN fallibility.

I completely disagree.  It's meaningless to construe the ignorance of a human
to know an unknowable fact as a human "failure."  Captain Will Rogers did not
fail - he made his guess, as was required.  Whether such a computer-ordered
guess should ever be required is the the real issue, and if human fallibility
is a factor, it lies in the stupidity of those who mandated this
computer-driven gamble in advance of its execution.

&gt;  there WAS a man in the loop on the Vincennes -- the computers
&gt;  did not automatically fire the missiles without human
&gt;  intervention.

This seemingly logical statement is wrongheaded and very dangerous since it is
a conception shared by congressional armed services committees and military
alike.  A Person-in-The-Loop (PTL) is as a matter of logic no more than a
random number generator when, because of the shortness of time, computers
provide essentially all of the information upon which an immediate "decision"
is *required* from that person.  In such a case, the real role that a person in
the loop plays is to gamble whether an attack warning is real.  To pretend that
the human element means any more than this is the stuff of fairy-tales -- and
whether a President, military commander, or computer operators make the guess
is beside the point.

It is strictly incorrect to label such a response as NOT automatic.  The
response IS automatic.  True, it is *randomized* by the human element, but it
is certainly not made *discretionary* by the token interjection of a guess.
The definition of "automatic" (in my Oxford American dictionary) is "working of
itself without direct human control, done without thought, done from habit or
routine."  If time is insufficient for proper thought, it is improper to class
a procedure as not automatic.  True, routine participation of humans makes a
response "not mechanized", but this is different from "not automatic".  As
General Ellis stated with regard to nuclear launch on warning drills, which are
of the same computer-governed nature, "the purpose of that conference is to get
a decision" - i.e. automatically, procedures force a guess in time to act.

Captain Will Rogers did no more than perform the function of adding an element
of randomization to the Vincennes response, because he could not exercise
proper judgment in that time frame.  His response was inherently automatic.
The gamble was not sanctified because it was made by a Captain.  Rather, the
Captain's role was debased by his being required to gamble.

&gt;  Congress's "man in the loop" mandate is an unthinking
&gt;  palliative, not worth much, and it shouldn't lull people into
&gt;  thinking the problem is fixed.

This portrayal is far too sangine.  The so-called "PTL amendment" is positively
nauseating -- it states that 100% mechanical lethality for Star Wars is A-OK as
long as someone somewhere sometime switches it on.  Herb Lin informed me that
he lobbied to make a CINC responsible for switching on the auto-boost phase SDI
defense -- and failed.  The amendment is a dumb green-light to automation,
masquerading as a restriction.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Person in the Loop
</A>
</H3>
<address>
"David A. Honig" 
&lt;<A HREF="mailto:honig@bonnie.ICS.UCI.EDU">
honig@bonnie.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Tue, 26 Jul 88 17:01:09 -0700
</i><PRE>

Will Martin in RISKS 7.26 mentions how the popular media does not explain
the risks of using computers and the costs and benefits of including
humans in the control loop.  Here is a (true) homey anecdote illustrating
this principle that perhaps the press ought to be aware of:

I went to a supermarket and separated a soft drink from a package of them.
When the UPC label is scanned, a price of $2.00 shows up.  At one store, the
checkout woman didn't believe me when I interrupted her and said that the price
was wrong and sent someone to check; if I had bought a lot of groceries at the
time I probably wouldn't have noticed.  At another store, the checkout person
did notice the unusual price (ie, sanity checking) and automatically corrected
it --her vigilance was probably due to the fact that I again wasn't buying many
items and she was in the express lane where the throughput is lower.

The important point is, the "human in the loop" issue is NOT esoteric or
complex: the PROBLEM is that the popular press either does not understand this
or will not communicate it to the mobs; thus, the layman continues to
misunderstand and mystify computers.

And when an operator fails to interact with a computer correctly, no-one in the
public wonders whether the computer programmer knew anything about man-machine
interfacing and human factors engineering.

Another example: the term "computer virus" is a valid analogy but most laymen
don't understand viruses enough to see the similarity.  Why can't the press use
"self-copying program" or some other informative term?  (Because it makes less
exciting headlines!)
 
</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Security vs. Cost of Breakin
</A>
</H3>
<address>
"David A. Honig" 
&lt;<A HREF="mailto:honig@bonnie.ICS.UCI.EDU">
honig@bonnie.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Tue, 26 Jul 88 17:01:09 -0700
</i><PRE>

There is no such thing as absolute security; one tries to make a
break-in as expensive as possible, more costly than the benefits of
success.  Relevant to recent RISKS issues, notice:

Encoding a bank-card PIN on the card magnetically IS secure for your
average person and your average wallet thief.  (Of course, a card
reader is a pretty simple device; also, a thief could go to a
bankcard-reading house (do they exist?), just like thieves go to pawn
shops that sell stolen goods and car thieves go to junkyards that sell
stolen parts.  But that's a lot of effort for limited (eg, $300/day)
returns, and besides, the owner will stop the card quickly yielding no return.)

Since NMR and CAT machines cost hundreds of thousands (and there are
no small versions of them, and they are expensive to run) it doesn't
matter if they can detect winning lottery cards.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Hacking central office switches - too easy?
</A>
</H3>
<address>
Skip Montanaro
&lt;<A HREF="mailto:steinmetz!vdsvax!montnaro@uunet.UU.NET ">
steinmetz!vdsvax!montnaro@uunet.UU.NET 
</A>&gt;
</address>
<i>
27 Jul 88 16:57:32 GMT
</i><PRE>

John T. Powers wrote concerning the problems Pac Bell was having with
crackers accessing their switches:

    A simple callback system (something I introduced at IBM about 10 years
    ago, and common now) would, if used correctly, make it *much* harder to
    gain unauthorized access to a CO switch.  In addition, it would probably
    warn of interest by unauthorized persons.  Today, much more
    sophisticated security systems are not only available but cheap.

The problem, as I understand it from the article that was posted in Risks,
is that the Pac Bell repair people need to dial in from wherever problems
exist, in order to set parameters, run tests, etc. Callback modems are only
useful if the party wishing access always calls from the same (or at most a
few) location(s). User A dials in, says "I'm user A", and hangs up. The
callback modem then calls the phone number associated with user A. A Pac
Bell repair person won't have a fixed location at which s/he can be called.

Skip Montanaro, GE Corporate Research &amp; Development (montanaro@ge-crd.arpa)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: PIN on PNB calling card
</A>
</H3>
<address>
Roy Smith
&lt;<A HREF="mailto:roy@phri ">
roy@phri 
</A>&gt;
</address>
<i>
26 Jul 88 14:10:46 GMT
</i><PRE>

In RISKS, Volume 7 : Issue 27, Mark Mandel &lt;Mandel@BCO-MULTICS.ARPA&gt; said:
&gt; a credit card still provides a security barrier of sorts in the signature.

	Don't be fooled into thinking that signatures are any kind of
security barrier.  I had my AmEx card stolen once (well, actually, I think
I forget it on the table in a restaurant when I left, but that's another
RISK).  You would not believe the charges that came through (with AmEx you
get back one of the copies of the charge slip so you can see exactly what
is what).  Some charges came through with signatures which don't resemble
mine in the least.  Some came through with no signature at all.  One even
came through with "signature on file" hand-printed on the signature line.

Roy Smith, System Administrator
Public Health Research Institute, NY NY

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: IRS Illinois Experiment
</A>
</H3>
<address>
Allan Pratt
&lt;<A HREF="mailto:atari!apratt@ames.arc.nasa.gov ">
atari!apratt@ames.arc.nasa.gov 
</A>&gt;
</address>
<i>
Tue, 26 Jul 88 12:06:23 pdt
</i><PRE>

&gt; [ Discussion of security issues in filling out tax forms online. ]

Forgive me if I'm wrong, but I thought the whole problem with computer
security was keeping unauthorized people out of sensitive information
and places where they can do damage.  On a computer where there IS NO
WAY to get access like that, what's the problem?

Set up a front end which fills out forms from the remote users.  Then dump a
day's forms to magtape, carry the tape to the processing computer, and
process it! The magtape is probably not necessary: any data channel will do.
The point is to leave no "trapdoor to the OS" commands on the front end...
There is no security door, just a blank wall!

The reason a system like UNIX is insecure, I thought, is that there are
trusted users (esp.  root) and non-trusted users, and ways for anybody to
masquerade as a trusty by guessing the password or otherwise violating
security AND GAINING PRIVILEGED ACCESS.  If there is NO SUCH THING as
privileged access, where can you go wrong?

The only hole I can see is using a bogus SSN to screw up somebody else's
taxes, but you can do that no matter how you get into the system or how
secure the actual access is.  I could do that on paper, too, until they
match the signatures.  How much flak would come down on the poor slob
before they figured that out?

If there is a fundamental flaw in my reasoning, please enlighten me.

Opinions expressed above do not necessarily	-- Allan Pratt, Atari Corp.
reflect those of Atari Corp. or anyone else.	  ...ames!atari!apratt

    [Let me suggest a few problems.  Suppose it runs on a nonsecure system.
    You can now browse through the other returns stored on the system and
    not yet dumped to magtape.  Or, you might install Trojan horses that record
    other people's data even after dumped to tape, or delete some of their
    income or claim phony deductions if you wanted to cause them grief. 
    Or, you might change the program to accept State Disability deductions when
    the IRS had claimed they were nondeductible.  Or, suppose the program was 
    proprietary; you might purloin it and set up your own value-added-service.
    Also, see the comment in the previous note on eyeballing signatures.   
    Top-of-the-head stuff, but you get the idea...  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.28.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.30.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-71</DOCNO>
<DOCOLDNO>IA012-000129-B048-49</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.30.html 128.240.150.127 19970217022359 text/html 17470
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:22:29 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 30</TITLE>
<LINK REL="Prev" HREF="/Risks/7.29.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.31.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 30</H1>
<H2>  Friday 29 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
NASTRAN and ship steel 
</A>
<DD>
<A HREF="#subj1.1">
Lindsay F. Marshall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Is vibration a known A300 problem? 
</A>
<DD>
<A HREF="#subj2.1">
Eric Roskos
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Business Week article on computer security 
</A>
<DD>
<A HREF="#subj3.1">
Woody Weaver
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computers can increase privacy, too! 
</A>
<DD>
<A HREF="#subj4.1">
Robert Weiss
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Viruses - a medical view 
</A>
<DD>
<A HREF="#subj5.1">
John Pettitt
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Apple viruses -- don't go through the ZLINK    
</A>
<DD>
<A HREF="#subj6.1">
Practor Fime
</A><br>
<A HREF="#subj6.2">
 Dr. Logic
</A><br>
<A HREF="#subj6.3">
 The Byter -- via Greg Prevost via Eric Haines
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  On IRS direct computer access 
</A>
<DD>
<A HREF="#subj7.1">
Steven C. Den Beste
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: doing away with privileged users 
</A>
<DD>
<A HREF="#subj8.1">
Alan Silverstein
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
NASTRAN and ship steel
</A>
</H3>
<address>
"Lindsay F. Marshall" 
&lt;<A HREF="mailto:Lindsay_Marshall%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Lindsay_Marshall%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Thu, 28 Jul 88 10:03:46 WET DST
</i><PRE>

Talking of NASTRAN reminds me of something that happened when I worked for a
company involved in shipbuilding. The steel ordered for a ship that was almost
completed turned out to be too thin so some extra reinforcerment was needed. In
order to find the best places for this they ran the whole ship through NASTRAN.
This job ran for 17 hours and filled several Gbytes of disc with temporary
files. The machine crashed when there was no more available disc space. It
turned out that the run involved 32000 degrees of freedom, but nobody had done
the back of an envelope calculations to see if it was practical...
                                                                      Lindsay
JANET: Lindsay_Marshall@uk.ac.newcastle 
UUCP:  ...!ukc!newcastle.ac.uk!Lindsay_Marshall

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Is vibration a known A300 problem?
</A>
</H3>
<address>
Eric Roskos
&lt;<A HREF="mailto:csed-1!csed-47!roskos@daitc.ARPA ">
csed-1!csed-47!roskos@daitc.ARPA 
</A>&gt;
</address>
<i>
Thu, 28 Jul 88 13:13:34 EDT
</i><PRE>

&gt; Pilots on France's domestic airline, Air Inter, began a new strike last
&gt; night as part of a three-year campaign over Airbus safety. 

Are there safety concerns other than fly-by-wire involving the Airbus?
Or is this "three-year campaign" just about fly-by-wire?  The above
suggests there may be other safety issues; due to 3 experiences with
A300s, I have suspected for several years that there might be some
problem with resonance of the body to engine vibrations during takeoff.
However, I have no evidence other than firsthand observation as a
passenger on A300s to back this up.

Eric Roskos (csed-1!roskos)

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Business Week article on computer security
</A>
</H3>
<address>
Woody
&lt;<A HREF="mailto:    <WWEAVER%DREW.BITNET@CUNYVM.CUNY.EDU> ">
    &lt;WWEAVER%DREW.BITNET@CUNYVM.CUNY.EDU&gt; 
</A>&gt;
</address>
<i>
Fri, 29 Jul 88 16:21 EDT
</i><PRE>

  The August 1, 1988 issue of BusinessWeek contained as cover article, "Is
Your Computer Secure?  Hackers, Viruses, and Other Threats".  The article,
pages 64-72, is reasonably well written, without inflammatory text, and has
few errors or misleading statements.  The article is in essence examining
the risk to the public and private sectors of computer usage and loss; and
covers employee attacks (Gene Burleson's assault on the Fort Worth security
firm USPA &amp; IRA Co., and arrest for "harmful access to a computer"), physical
security in light of accident (the Hinsdale disaster), child 'phrackers' and
Ma Bell, adult hackers (the Chaos Computer Club and the Deutsche Bundespost)
viruses, and the like.

  It's a glossy article, but is filled with interesting bits of data, such as
US expenditures on computer systems over the last four years versus estimated
sales of computer protection goods and services.  They have photographs of
Richard Brandow and the programmer who created the McMag virus, Pierre Zovile'
(err -- if I ever meet them in a dark alley...) and so on.  Its nice to see
some responsible journalism coverage in a general purpose magazine.  Or
perhaps this is just a measure of how important the private sector rates
computer security...

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Computers can increase privacy, too!
</A>
</H3>
<address>
"Robert Weiss" 
&lt;<A HREF="mailto:weiss@umnstat.stat.umn.edu">
weiss@umnstat.stat.umn.edu
</A>&gt;
</address>
<i>
Thu, 28 Jul 88 20:26:10 CDT
</i><PRE>

I regularly get reports from my congressperson on his activities, and a comment
in one of the articles grabbed my attention before I could toss the mailing:

	"Technology provides the students with privacy ..."

A different sentiment than we usually read about in RISKS.  This is from an
article on a computer-aided adult literacy teaching project in St. Paul.  PC's
placed in individual booths provide both privacy and flexibility.  If I was 30
years old and unable to read at a 4th grade level, the privacy issue would be
important to me.

This made me realize that while large computers and networks may in general be
detrimental to privacy, there _are_ possibilities for computers to increase
privacy.

Robert Weiss 

    [But probably not if untrustworthy people have authorized access to the
    system or to the data, or if people without authorized access masquerade.
    The biggest problem with putting really sensitive data about an individual
    that might be of interest to someone else (for revenge, blackmail,
    curiosity, leaking, etc.) may be that the temptation level has escalated.
    PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Viruses - a medical view
</A>
</H3>
<address>
John Pettitt
&lt;<A HREF="mailto:jpp@slxsys.specialix.co.uk ">
jpp@slxsys.specialix.co.uk 
</A>&gt;
</address>
<i>
Wed Jul 27 19:00:35 1988
</i><PRE>

Taken without permission from the Independent (which seems to have
gotten it from the British Medical Journal):

VIRUSES could invade hospitals throught their computer systems,
so new software used by doctors is being quarantined before it is
allowed contact with patients' data, Oliver Gillie writes.

The Royal Infirmary in Glasgow isolated a computer virus in its
laboratory among software destined for the cardiac intensive care
unit.  The virus was found by a technician who destroyed it before it
was able to multiply.

Dr Gavin Kenny, an anaesthetist at the Royal Infirmary, said the virus
was not malignant, but "as soon as it was found, we made a complete sweep
to look for others and now we do regular checks".

"A virus can wipe out the memory on an entire disk - that would 
cause a lot of trouble although it would not put patients' lives
in danger," he added. "But some viruses are benign. There is one which
just comes out on Tuesdays.  It says it is Tuesday and then it goes away
again."

[ stuff about what a virus is and the christmas tree deleted - jpp]

Dr John Asbury, another Glasgow anaesthetist, says a virus got
into an intensive care unit in the city where it corrupted data
and caused files to be lost.  Dr Asbury writes about computer
virus disease in the latest issue of the British Medical Journal.

John Pettitt, Specialix, Giggs Hill Rd, Thames Ditton, Surrey, U.K., KT7 0TR
{backbone}!mcvax!ukc!pyrltd!slxsys!jpp            jpp@slxsys.specialix.co.uk

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Apple viruses
</A>
</H3>
<address>
John Saponara
&lt;<A HREF="mailto:saponara@tcgould.tn.cornell.edu ">
saponara@tcgould.tn.cornell.edu 
</A>&gt;
</address>
<i>
Fri, 29 Jul 88 13:06:44 EDT
</i><PRE>

From batcomputer!cornell!mailrus!uwmcsd1!ig!agate!ucbvax!pro-carolina.cts.COM!gregp Fri Jul 29 11:52:17 EDT 1988
Article 7320 of comp.sys.apple:
Path: batcomputer!cornell!mailrus!uwmcsd1!ig!agate!ucbvax!pro-carolina.cts.COM!gregp
&gt;From: gregp@pro-carolina.cts.COM (Greg Prevost)
Newsgroups: comp.sys.apple
Subject: Virus Information
Date: 26 Jul 88 21:54:43 GMT
Reply-To: pnet01!pro-simasd!pro-carolina!gregp@nosc.mil
Organization: The Internet

Ok folks, in the past few days I have seen some major stuff going on.  There
are at least two different viruses running around.  One is called Cyberaids
and the other is made by some group called Festering Hate.  Here is some of
the info I have picked up on it in the last few days.

 - = - = - = - = - = - =

50/50: Warning Apple users
Name: Practor Fime #13 @4
Date: Sat Jul 16 17:16:14 1988

CAUTION:

        ZLink+, ZLink.PBH, ZLink are all viruses, if you run ZLink then you
now are the happy parent to a rodent virus. It seem Zlink has some sort of
virus that attaches to files and stuff.  My friend has it on his HD and it
creates some file entry in the ROOT directory that is hidden from every utility
EXCEPT APW or ORCA.  Every time you boot the prodos with the virus it will do
and ON-LINE vol check (even if you specifiy the exact pathname) and install the
virus on systems files such as, Mr Fixit, Basic.system,Copy II+ etc....

 - = - = - = - = - = - =

(92 of 100)
Titled : &lt;*** W A R N I N G ***&gt;
Author : Dr. Logic/Bill of [None]
Stamped: July 13, 1988 at 12:07 AM

There is a file going around (currently on the Hard Drive) called Z.LINK.PLUS.
It is supposed to be a terminal program somewhat like ProTERM.  It is a decent
program but the main reason I posted this is when you boot it up, it GOES TO
EVERY ON-LINE DRIVE AND MODIFIES &gt;BASIC.SYSTEM&lt;!!!

At bootup, it looks like it's doing an On-Line call and checks every drive.
Then it goes back to some and starts doing some modifications (especially
noticeable on floppy drives).  The program modified copies of BASIC.SYSTEM,
FILER, BACKUP.SYSTEM and PROSEL (don't ask me how it chooses, it usually just
attacks BASIC.SYSTEM).

After installing itself into BASIC.SYSTEM, everytime you boot a disk with that
BASIC.SYSTEM on it, it will do another on-line check and continue to add itself
to other copies of BASIC.SYSTEM.

One of the tell-tale signs of this is it will leave behind tracks such as the
modification date of the files it altered (that's how I found out).  BE
CAREFUL!!!  I do not know if this is a virus as my HD is still operable and
I've replaced all infected files with backups.  Either way, I don't like
something that spreads itself around, especially doing an on-line call after
every bootup.


Please spread the word around.  I don't know what kind of file this is but it
sounds like bad news to me.  I encourage those of you who are more
knowledgeable about machine language to d/l the disk and examine the contents
of the files.  I don't trust it but you have been warned.

WARNING: This is a FOR REAL virus not a trojan, if interested I will pack the
         Infected Basic System and U/L it if you want to make a detoxin for it

-Jon

 - = - = - = - = - = - =

                                    Virus
                                    ~~~~~
        The first verified virus of the ProDOS operating system is out and
around.  The first identified carrier of this virus was a terminal program
called "ZLINK.PLUS", which was discovered about one week ago.  Today, our board
was struck by the same virus, which was hidden inside another file,
"MR.FIXIT.3.7", and since I have found it to inhabit "SQUIRT.1.5" as well.  Be
careful.  The most telltale sign of this virus is the fact that when you
execute a system file which is a carrier, it will scan all of your online
prodos devices, and will then occasionally write to one of them.  Check your
directories carefully, look at the modification date on your system files.  If
it is recent, you may have an infected program.  Files in subdirectories are
NOT safe.  I have not found it to copy itself into any file other than
BASIC.SYSTEM, but I hear that other people have had it copy onto other SYS-type
files.

The Byter

(This is the Byter who runs Cabal of the Lexicon in 213.)

</PRE>
<HR><H3><A NAME="subj6.2">
On IRS direct computer access
</A>
</H3>
<address>
&lt;<A HREF="mailto:denbeste@OAKLAND.BBN.COM">
denbeste@OAKLAND.BBN.COM
</A>&gt;
</address>
<i>
Fri, 29 Jul 88 09:09:58 -0400
</i><PRE>

I think this is going to fail. High school students all over the state will
spend their evenings making up social security numbers and entering phony
returns. Perhaps one time in thirty or so they'll hit pay dirt (a real social
security number!).

The only way to prevent this is to have the machine know the names of the
people who own the SSN - and reject any return which isn't right.

Only, having done that, what happens if the legitimate owner of the SSN doesn't
enter their own name is quite the same way it is held in the database?

Perhaps the right answer is for the computer to categorize the returns into one
of two groups: "Those where the name was correct" and "those which a human
being will check for validity".

Steven C. Den Beste,   Bolt Beranek &amp; Newman, Cambridge MA
denbeste@bbn.com(ARPA/CSNET/UUCP)    harvard!bbn.com!denbeste(UUCP)

</PRE>
<HR><H3><A NAME="subj6.3">
Re: doing away with privileged users
</A>
</H3>
<address>
Alan Silverstein 
&lt;<A HREF="mailto:ajs%hpfcajs@hplabs.HP.COM">
ajs%hpfcajs@hplabs.HP.COM
</A>&gt;
</address>
<i>
Thu, 28 Jul 88 18:31:41 mdt
</i><PRE>

In 7.29, Allan Pratt said:

&gt; If there is NO SUCH THING as privileged access, where can you go wrong?

Alas, there is NO SUCH THING as "NO SUCH THING as privileged access".

Why?  Because computers aren't as smart as people and as trustworthy as
their administrators.  Situations inevitably arise which require ad hoc
human intervention -- by privileged users.

What if there were no distinction of "privilege"?  If any user could
handle the interventions?  There'd also be precious little protection of
users's data from other users.  Even cooperating users need protection
from each other's mistakes.

Alan Silverstein, Hewlett-Packard HP-UX DCE Lab, Fort Collins, Colorado

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.29.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.31.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-72</DOCNO>
<DOCOLDNO>IA012-000129-B048-83</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.31.html 128.240.150.127 19970217022417 text/html 24681
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:22:42 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 31</TITLE>
<LINK REL="Prev" HREF="/Risks/7.30.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.32.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 31</H1>
<H2>  Monday 8 August 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Software failures cost Britain $900M per year, study claims 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Lightning strikes (twice) 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Computer failure delays flights at Logan Airport 
</A>
<DD>
<A HREF="#subj3.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  A320 &amp; A300 safety, risks of so-called experts 
</A>
<DD>
<A HREF="#subj4.1">
Michael Pilling
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RISKS of Electronic Cash-registers 
</A>
<DD>
<A HREF="#subj5.1">
Robin Kirkham
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Computer terminals and dermatology 
</A>
<DD>
<A HREF="#subj6.1">
richard welty
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Computer System Vulnerabilities 
</A>
<DD>
<A HREF="#subj7.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Disaster Exposition 
</A>
<DD>
<A HREF="#subj8.1">
Cliff Stoll
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Software failures cost Britain $900M per year, study claims
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Fri, 05 Aug 88 09:29:58 PDT
</i><PRE>

This article appeared quite a while ago in ELECTRONICS ENGINEERING TIMES
(June 13, 1988, p. 19):

BRITAIN SCRUTINIZES SOFTWARE QUALITY by Roger Woolnough

...(Two) studies were commissioned last year from Price Waterhouse and 
Logica plc by the Department of Trade and Industry (DTI), the government
department concerned with virtually the whole of British industry.  The 
Price Waterhouse study sought to establish the costs and benefits of 
applying quality-management standards to software. The parallel study by
Logica exmained the possibility of harmonizing the civil and military 
quality management standards.

The failure costs are expensive.  For British industry, the report estimates
them conservatively at $900 million a year, and that includes only software
produced domestically and sold on the open market.  If imported and in-house
software were included, the failure costs would be much higher.  And on top
of that there are substantial indirect costs, which Price-Waterhouse could
not quantify.

Price Waterhouse estimated that implementing a quality system would mean
additional costs for a typical supplier with 50 to 100 employees of between
$360,000 and $450,000 a year.  Initial setup costs could be between $180,000
and $270,000, with no difference between large and small companies.

The study was unable to estimate the reduction in failure costs that would 
result from wider use of quality systems but did work out the savings
required to justify them - a 10 to 15 percent reduction in total failure
costs over the life of a system.

"If we consider costs and benefits to suppliers only," says the report, 
"a reduction in failure costs of 35 to 40 percent would be required to
sustain the investment in a quality system.  ... An improvement of this size
is possible, but far from certain.  Therefore it is possible that software 
suppliers could incur net costs as a result of introduction of a quality
system.  The evidence suggests that most users are not prepared to pay higher
prices for software simply because a quality system was used by the
supplier."

(The Logica study compared various standards for software quality assurance,
namely NATO's AQAP documents, used by the British Ministry of Defence, and
international ISO9001.  Logica found little difference in substance and
recommended standardizing on ISO9001).

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Lightning strikes (twice)
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Mon 8 Aug 88 14:33:09-PDT
</i><PRE>

On 31 July 1988 lightning struck the drawbridge between Vineyard Haven and Oak
Bluffs on Martha's Vineyard MA, paralyzing the three-phase controls and then
ricocheting into the elevated transformer.  As a result the Lagoon Pond access
for 40 sailboats and tall powerboats was sealed off for almost three days.
(This was the same weekend that the ferry Islander ripped a hole in its belly
when it ran aground, backlogging 500 cars.  And your moderator was there,
finally getting a little vacation so that you all could get a little vacation
from RISKS.)  The previous lightning strike, only three weeks before, had
closed the bridge for 24 hours.  [Source: Martha's Vineyard Times, 4 August
1988, p. 1.]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Computer failure delays flights at Logan Airport in Boston
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Mon 8 Aug 88 14:40:33-PDT
</i><PRE>

On 5 August 1988, air traffic was delayed because a new software tape
designed to relay departure information to air traffic controllers
sent data to the wrong controllers.  It took an hour to replace the
software.  The delays at Logan lasted for about 6 hours, tapering off
slowly from one-hour delays.  Delays also propagated to nearby airports.
[Source: Boston Globe, 6 August 1988]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
A320 &amp; A300 safety, risks of so-called experts 
</A>
</H3>
<address>
Dr Chocberry)
&lt;<A HREF="mailto:munnari!banana.cs.uq.oz.au!bigm@uunet.UU.NET (Michael Pilling ">
munnari!banana.cs.uq.oz.au!bigm@uunet.UU.NET (Michael Pilling 
</A>&gt;
</address>
<i>
Thu, 4 Aug 88 15:39:47 EST
</i><PRE>

This is from an article in the "Australian" 2-Aug-88 retyped and
abbreviated without permission:

	Two pilots blamed for air crash

	Following an official report to the French transport minister
    last week, responsibility for the crash of an Airbus A320 into trees
    at an airshow in eastern France has been blamed on pilot Michel
    Asseline &amp; co-pilot Pierre Mazieres. The A320 gets a clean bill of
    health.
	Cockpit talk recordings from the black box revealed startling
    over-confidence on the part of both men. Mr Asseline told Mr Mazieres on
    the ground he would not use the aircraft's sophisticated alpha-floor
    computer system, which automatically boosts the fuel supply to the
    engines when its speed, altitude and incline indicate a danger of stalling.
	He also disconnected a secondary system to boost power so he
    would have maximum manual control, boasting that he would fly the
    aircraft at 30m at low speed, with just enough power to keep the plane
    at maximum incline without losing height.
	Mr Asseline would then put on full throttle to climb away at a
    steep angle, he said.
	"You want to show off, huh?", the co-pilot said.
	Several times before the critical manoeuvre the crew
    contemptuously dismissed visual and aural wornings emitted by the
    onboard computers.
	The pilot responded to one by saying: "Knock that one off,
    it's getting on my nerves."
	Just before the fly past the co-pilot said:" `Right, you're
    coming down to 100 feet, do it, do it."
 	"Right, I'm going for it, disconnect the fuel boost system."
	"Watch out for the pylons ahead, eh? You've seen them, yeah?"
	"Yeah, yeah, don't worry."
	The co-pilot then told the pilot to put on full throttle. As
    the aircraft failed to gain height the pilot was heard to curse.
	Neither pilot has been formally accused of causing the crash,
    although the transport ministry said a judicial investigation could
    still bring charges.

	Soon after the crash I saw an american TV report on the crash
which featured a so called "COMPUTER EXPERT" (the caption on the
screen, no mention of his field or qualification was made) stating
that "if it's pilot error it must be systems failure", without knowing
anything of the architecture of the software. Obviously there is a
risk in trusting experts in a field you know nothing of, because you
(in this case the NEWS service) are inclined to believe them.

Eric Roskos (Risks 7.30) asks, is vibration a common problem in A300's. I have
often experienced the throbbing you refer to, and have noticed that the wings
virtually beat on take off.  I think this intended or at least seen as an
acceptable side effect of the wing geometry during take off. In general, I
suspect aircraft maintenance in the US is taken far less seriously than here
and this may be partly to blame.

Michael Pilling (bigm@banana.cs.uq.oz)

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
RISKS of Electronic Cash-registers
</A>
</H3>
<address>
&lt;<A HREF="mailto:munnari!mimir.dmt.oz.au!rjk@magni">
munnari!mimir.dmt.oz.au!rjk@magni
</A>&gt;
</address>
<i>
08 Aug 88 15:37:14 EST (Mon)
</i><PRE>

Years ago when cash-registers could only add, it was safe. Nowadays they can
subtract as well, and so cash-register operators can't, and so you lose your
change. It's been happening to me more and more often over the past couple of
years. I explain:

Formerly, the cash-register would add up all the prices of the things you
bought, and at the end the operator would hit the `Total' button, and the till
would pop open. You would proffer your money, and your change would be made up
by counting out coins, then notes, adding to the total price and working up
to the tendered value. Then you got the docket.

But now, at the end of the sale, the operator punches in your tendered amount,
and the cash register calculates the change, which is then counted out into
your hand in the reverse order -- big notes first, then little ones, then the 
coins get balanced delicately on top. 

Then you get the docket shoved at you. The coins slide off the notes in you 
hand, fall and roll under the checkout counter. Gone forever. Can't give you
any more change, till won't balance. Your own mistake. Get out of the way, 
your holding up the other customers.

Australia has recently been inflicted with a $2 coin, and the old $2 note has
benn withdrawn. The Treasury, in its infinite wisdom, made the coin smaller
than most of the other coins and out of an exceptionally light aluminium
alloy, which made the problem even worse.

I once asked a checkout girl why they had reversed the order of counting out
the change. She said they were told to do it that way, since they "made less
mistakes" and it was "easier". Actually, I expect the reason was so that the
supermarket could sweep under the counters and collect all the dropped change.

Robin Kirkham	CSIRO/DMT	rjk@mimir.dmt.oz	(My opinions, only)

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Computer terminals and dermatology
</A>
</H3>
<address>
richard welty
&lt;<A HREF="mailto:steinmetz!welty@uunet.UU.NET ">
steinmetz!welty@uunet.UU.NET 
</A>&gt;
</address>
<i>
Fri, 5 Aug 88 17:19:22 edt
</i><PRE>

The following short article recently appeared in Cutis, a journal
of dermatology (I don't know the exact issue.)  A note indicates
that the authors are with the Department of Dermatology, University
of Maryland School of Medicine.  Reprints are available from:

Dr. Burnett
Division of Dermatology
University of Maryland Hospital
22 South Greene Street
Baltimore Maryland 21201

This article is reprinted without permission.
Figure 1 (omitted) is merely a picture of a user and an IBM PC.
---

``Dermatologic Manifestations in Users of Video Display Terminals''

Marline L. Cormier-Parry, MD
Gary V. Karakashian, MD
Joseph W. Burnett, MD

  It is not surprising that with new technological advances, new dermatologic
entities also appear.  Rosacea is a cutaneous reaction pattern thought to be
provoked by many factors including foods, alcohol, heat, and cold.  Recent
reports have implicated exposure to video display terminals (VDT) as another
causative factor (Figure 1).  Since the first reports from northern Europe
in 1982, when VDT exposure was related to the excerbation of rosacea, acne,
seborrheic dermatitis, and poikiloderma of Civatte, more recent reports
have appeared (references 1-3).

The symptoms and dermatitis associated with VDT use are usually paresthesia or
pruritus of the upper cheeks or perioral area with either solitary papules or
a fine erythematous papular eruption.  The typical features of most cases of
VDT-associated dermatitis were onset of the eruptions two to three hours after
daily use of the VDT, improvement of the dermatitis on days the unit was not
used, and, low ambient relativie humidity at the time of the exposure.

VDTs produce several types of electromagnetic radiation.  The cathode ray tube
emits low-energy x-rays.  The phosphor material of the screen emits
ultraviolet, visible, and infrared radiation.  The electronic circuits
produce radiofrequency and very-low-frequency radiation.  Most electrical
and electronic equipment can generate ``electrical noise,'' a low-level,
broad-spectrum electromagnetic radiation.  To date, no adverse biological
effects in humans have been documented from these electromagnetic fields
and the level of radiation emitted is far below the occupational standards
set by federal authorities (references 2-4).

The electrostatic fields, however, are more likely to be the causitive
agent of VDT dermatitis.  Electronic fields are noted around most VDTs at low
humidity and tend to disappear at higher humidity (reference 5).  Most cases
of VDT dermatitis have occured in northern Europe and during the winter
months, when the relative humidity is less than 40 percent.  Further
evidence for this hypothesis comes from obserrvations that when the
electrostatic fields were reduced, operators' dermatitis and other symptoms
were also reduced.  Whether this is a direct effect of the field itself or
an irritant dermatitis from airborne particles is unknown.  Several female
operators have reported the deposition of their makeup on the VDT screens at
the end of a working day.  However, the deposition of volatile and
particulate air pollution on the skin can be induced by electrostatic field
charge (reference 2).  Furthermore, there have been several reports of
patients who were able to prevent the dermatitis by the use of physical
blocking agents, such as titanium dioxide or Duoderm.

Recently, computer manufacturers have introduced VDTs that have no static
electric fields as a means of preventing dermatitis.  Electrostatic shields
are also available and widely used in northern Europe.  The shield, which is
placed in front of the VDT screen, becomes conductive at relatively low
humidity and thus eliminates the static field.  Improvement with these
shields, however, is usually temporary since their conductivity diminishes
with time.  In the United States, the use of a skin-colored ``sun-block''
cream containing 2 percent titanium dioxide with iron oxides was recommended.
It showed some success in preventing VDT symptoms and the associated
dermatitis (reference 4).  Improvement in some Norwegian cases was noted
after the substitution of antistatic floor carpeting in the work area
(reference 3).

References

1. Liden C, Wahlberg JE: Work iwth video display terminals among office
employees.  _Scand J Work Environ Health_ 11: 489-493, 1985.

2. Berg M, Liden S: Skin problems in video display terminal users.  _J Am
Acad Dermatol_ 17: 682-684, 1987.

3. Nilsen A: Facial rash in visual display unit operators.  _Contact 
Dermatitis_ 8: 25-28, 1982.

4. Fisher A: ``Terminal'' dermatitis due to computers (video display units).
Cutis 38: 153-154, 1986.

5. Berg M, Langlet I: Defective video displays, shields, and skin problems.
_Lancet_ 1(4): 800, 1987.
-- 
richard welty  518-387-6346  GE R&amp;D, K1-5C39, Niskayuna, New York
   welty@ge-crd.ARPA  {uunet,philabs,rochester}!steinmetz!welty

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Computer System Vulnerabilities
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
2 Aug 88 08:43:51 PDT (Tuesday)
</i><PRE>

RISKS Moderator Peter Neumann has an op-ed piece in the August 2 Los Angeles
Times with the headline 

                       A GLITCH IN OUR COMPUTER THINKING
	     We Create Powerful Systems With Pervasive Vulnerabilities.  

Although they are overly-familiar topics to RISKS readers, I trust the moderator
will permit a few quotes:

   Our civilization seems to have developed an inherent craving for easy 
   answers, especially regarding technology.  In particular, we tend to
   anthropomorphize computers and endow them with human intelligence -- 
   while at the same time we deify them and endow them with infalli-
   bility....

   One of the most serious problems in computer-related systems is the 
   inadequate protection of such valuable resources against unintended 
   or malevolent misbehavior by authorized as well as unauthorized 
   computer users -- and against malfunctions of the computer systems....
   
   [Brief mentions of computer-related problems at Pacific Bell, NASA,
   banks, the Vincennes, false arrests....]

   Computers and their communications are frequently vulnerable, but they 
   are also limited by the intelligence and wisdom of their developers,
   administrators and users.

   It is a common myth that the complexity of such systems deters mal-
   feasants.  In fact, the attackers may understand the system better 
   than many of the defenders.  Digital technology is inherently finite 
   -- there are only certain possible cases.  The number may be large, 
   but often there are shortcuts that eliminate the need to search 
   exhaustively for a needed clue -- password, design flaw or code bug....

   There are no guaranteed complete solutions that can prevent computer-
   system malfunctions, intrusions and both accidental and malevolent 
   misuse.  But there are prudent measures that can be taken to reduce 
   the risks.  [Better design and implementation, better laws, ...] 
   Above all, we must have a computer-literate populace -- better 
   educated, better motivated and more socially conscious.

   Computer security vulnerabilities are pervasive, but they are not 
   usually evident to the general public.  Depending on flawed computer 
   systems will lead only to bigger disasters.  Overall, we must work 
   much harder to understand and openly consider the true risks of 
   using computers.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
 Disaster Exposition
</A>
</H3>
<address>
Cliff Stoll
&lt;<A HREF="mailto:cliff@Csa4.LBL.Gov ">
cliff@Csa4.LBL.Gov 
</A>&gt;
</address>
<i>
Wed, 3 Aug 88 21:59:02 PDT
</i><PRE>

Hi Riskees!

Last month's Computer Assurance conference -- COMPASS '88 was a gas --
really good talks on electronic voting systems, computer assisted automotive
problems, fly-by-wire risks, and averting computer domino effects.  Our
illustrious hero, Peter Neumann, gave a couple outstanding talks.  For those
of you who haven't met him, he's just as quick with puns behind the podium
as when moderating our forum.

COMPASS dealt with averting disasters.  On the flip side is the
1988 International Disaster Congress, Nov 9-11, in Chicago.
Sounds weird to me:   
   "How was your meeting?"   "Complete disaster."

It sounds neat, but I can't afford $675 admission, 
so if any of you Riskee's are going, could you post your notes to Risks?  

Keynote Speaker:
    Edward Teller (inventor of the H Bomb, promoter of Star Wars)
    "Gaining a Global Perspective of Disaster Control"

Some session titles:
Prior Planning for "Acts of God"
Foreseeing Deliberate Acts of Violence
Anticipation of Technology's Catastrophes
Identifying Beforehand the Impact of Epidemics
Success Stories of Disaster Preparedness
Implemented Programs for Minimizing Natural Disaster Impact
Preventive Approaches to Controlling Deliberate Violence
Ventures for Mitigating Technological Accidents
Restraining Threats of Mass Disease
Sustaining Corporate Morale in Midst of Nature's Attack
Allocating Resources while under Siege
Damage Control at Accident Scenes
Minimizing the Spread of Current Epidemics
Cleanup Following Natural Disaster
Recovery from Violence Induced Calamity
Post Exposure Measures for Restoring Health
Timely Action following International Incidents
Eliminating All Effects of Sustained Disaster
Replacing Resources Destroyed by Natural Catastrophe
Restoring Order from Chaos of Deliberate Violence
Total Recuperation from Epidemic
Recovery Through Repossession and Reparations

Speakers are from:
Bay Area Earthquake Preparedness Project, 
Univ. Rome, Univ. Delaware
Emergency Preparedness Council of Canada
Int'l Assoc of Fire Chiefs
Cincinnati Hazardous Materials Task Force
Maryland Institute for Emergency Medical Services
Disaster Services for American Red Cross
National Governor's Association
California National Guard
Association of American Railroads
Armed Forces Institute of Pathology
Israeli National Police
Association of Contingency Planners, American Savings/Loan
Federal Insurance Administration

Also, there'll be a Disaster Exposition, "A showing of products for 
anticipating, coping with, and recovering from disaster."  
Yikes -- what do you think they sell to recover from
one of Teller's thermonuclear bombs?

Registration/Details: 
Kotch &amp; Poliak, 708 3rd Ave, NYC, 10017   212 557 6950


Cheers,  Cliff Stoll   Cliff@lbl.gov 

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.30.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.32.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-73</DOCNO>
<DOCOLDNO>IA012-000129-B048-103</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.32.html 128.240.150.127 19970217022435 text/html 25409
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:22:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 32</TITLE>
<LINK REL="Prev" HREF="/Risks/7.31.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.33.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 32</H1>
<H2>  Tuesday 9 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Privacy in computer age (no place to hide) 
</A>
<DD>
<A HREF="#subj1.1">
Sayed Banawan
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Follow-up to legal hypothetical 
</A>
<DD>
<A HREF="#subj2.1">
CEReuben
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Preliminary A320 Inquiry Results 
</A>
<DD>
<A HREF="#subj3.1">
Martin Harriman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Computer terminals and dermatology 
</A>
<DD>
<A HREF="#subj4.1">
Steve Philipson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Privacy in computer age (no place to hide)
</A>
</H3>
<address>
Sayed Banawan
&lt;<A HREF="mailto:banawan@sun1.cs.uh.edu ">
banawan@sun1.cs.uh.edu 
</A>&gt;
</address>
<i>
Wed, 3 Aug 88 11:26:44 CDT
</i><PRE>

From Houston Chronicle (August 2,1988) without any permission:

No Place To Hide Your Privacy In Computer Age
by Albert E. Denny (Denny is a free-lance writer in Baltimore. MD)

IN case you haven't noticed, your privacy is being invaded and eroded at an
unprecedented pace nowadays, thanks to advances in communications technology
growing out of proliferation of computers. No matter who are you or where you
live, information concerning your personal life and lives of family members
is being pumped into databases at a scary rate.

Even your own computer may be watching you. The congressional Office of 
Technology Assessment reported that computers are being used to keep tabs on
as many as 6 million workers, from government employees to bank tellers.
In some cases, employers monitor the productivity by programming the machines
to record how many keystrokes users make per hour.

Computerized phone systems track how many calls workers make or operators
handle. They can also be rigged to listen in on conversations. "It's Big
Brother at its worst." says U.S Rep. Don Edwards, D-Calif. "Just because 
you get a job doesn't mean you lose your constitutional rights."

No clear legal definition of privacy exists, but experts agree on a few 
basics: It means the right to keep personal affairs to yourself and to know
how information about you is being used. The issue has big implications on
information companies.

"I think the industry feels that individuals must sacrifice a certain amount
of privacy in the information age," says Peter A. Marx, an attorney specialized
in computer law. The public disagrees. A 1984 Harris Poll found 75 percent
or respondents "very" or "somewhat" concerned about threats to privacy.

There is no place to hide. If you are a living, breathing person moving about
in society. making purchases and paying bills, a growing file of information
exists on your personal life and habits that is little short of mind-boggling.
Such information is compiled in diverse ways.

If I buy a toaster made by a major appliance company, what right does it 
have to include with warranty (to be filled by me) a battery of questions
relating to my age, sex, occupation, hobbies, marital status, etc.? The obvious
reason such information is is being compiled is so it can be fed into a
computer and the resulting data used for misleading (and unauthorized) 
purposes such as the sale of mailing lists to specialized companies for money.

When I buy common stock or subscribe to a financial publication, the subsequent
barrage of solicitations from financially related companies interested in
selling me a product or service can only be traced to the sale of such 
confidential information to those seeking to profit from it. That is a gross
misuse to privileged information and I resent ti.

We are all at the mercy of computers which spew out massive amounts of 
information  on individuals that can be collected, cross-matched and 
manipulated to generate much more detailed profiles of U.S. citizens than ever
before - sometimes in a matter of seconds. This information can affect 
everything from credit ratings to welfare eligibility to your chances of 
renting an apartment or landing a job.

consider the following major sources of data that feed into computers, giving
the most intimate details of your personal life:
  The Internal Revenue Service  exchanges data with state and local tax
authorities to check the accuracy of tax returns.
  Your Social Security number, the code that third parties need to tap into
computerized information on you, is available to at least 125 government
and private agencies.
  About 40 states sell direct-mail companies the information you provide when
registering a vehicle or applying for a license. That reveals you age, sex,
Social Security number - even, through deduction, your income range.
  The FBI's National Crime Information Center has more than 10 million
centrally stored recoreds of criminal histories - all available to state and
local authorities.
  The five largest credit reporting companies control records on more than
150 million individuals.
  Some states are computerizing their court documents, making it easier to
monitor everything from eviction to criminal proceedings.
  Most banks are allowed by law to give out information on customers' accounts
and credit histories to state government investigators.
  Life insurance companies, by tapping a central data base run by a company 
called  the Medical Information Bureau, can find out details about your medical
history from claims information provided by insurers.
  Direct-mail companies, hungry fro your business, comb through some of the
above records and other information, churning out lists of specific individuals
whom salesmen or political campaign may want to contact.

Get used to those increasingly more personal letters and the chummy phone
calls from salespeople who want to sell you something. They know everything
about you, and the best defense may be to sign up for a course in sales
resistance.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Follow-up to legal hypothetical (<A HREF="/Risks/6.42.html">RISKS-6.42</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:CEREUBEN%AMHERST.BITNET@MITVMA.MIT.EDU">
CEREUBEN%AMHERST.BITNET@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 8 Aug 88 08:26 EDT
</i><PRE>

     In March of this year I posted a hypothetical in RISKS Digest,
volume 6 issue 42, concerning the proper allocation of rights in
software between programmers and their employers.  At the time, I was
writing a law school paper on this issue, and was curious to see how well
the legal standards I was uncovering lined up with your perceptions of
the basic equities.   Here is the promised follow-up on that posting.

I.  THUMBNAIL LEGAL ANALYSIS OF THE HYPOTHETICAL **

    ** What follows is not practical legal advice, but merely a brief
theoretical analysis.

    Briefly, The hypothetical  dealt with a programmer named John Allan, who is
hired to design and implement a touch-sensitive help utility for use in his
employer Medicomp's medical database, MEDSTORE.  Allan later uses this same
utility in the development of a tax expert system, TAXELF, and is sued by his
former employer Medicomp.  The posting asked for your thoughts on the extent to
which Medicomp, by contract or law, should be able to limit Allan's later use
of code and ideas developed during his employment with them.

    The current law's treatment of such a situation is at best complex and at
worst completely unsettled.  Principles of copyright, patent, trade secret,
unfair competition and contract law all potentially apply.  In each of these
areas, there are relatively few statutes and written judicial opinions which
deal directly with computer software.  New cases are constantly being brought;
however, most of these are settled out of court.

    Therefore, I can't possibly provide you with a definitive "answer" to the
John Allan problem.  What follows is merely the OPINION of a recent law school
graduate as to how this particular hypothetical MIGHT be approached by a court
today.  Bear in mind that the law is in a state of flux.  Also note that I have
NOT yet been admitted to the bar, and that in any event, this should NOT be
taken as practical legal advice.

    As many of you correctly noted, Allan would most likely be covered by a
carefully drafted employment ageement, assigning to Medicomp the ownership of
any copyright or patent in the original program.  Even if the contract did not
speak to ownership issues (which would be unusual these days), Medicomp would
probably by seen by a court as owning the copyright.  The program was written
by "an employee" and "within the scope of his employment," and would therefore
qualify as a "work for hire" under the Federal Copyright Act.

    As owner of the copyright, Medicomp could prevent Allan from using the
actual code in his tax system, both through direct copying or rewriting from
memory.  While de minimus copying of insignificant or nonunique modules would
probably be allowed, Allan's wholesale appropriation of the entire help utility
would likely be seen as a copyright violation.

    Less settled is the extent to which Allan could use the non-code elements
of the program.  A number of courts would extend Medicomp's copyright
protection to the program's structure and organization.  Few, however, would
bar Allan from the use of touch sensitive help in general.

    The important thing to note is that, for the purposes of copyright law,
Allan's status as creator does not give him any greater right to use the
software than members of the general public.

    As an ex-employee, however, Allan is bound by a duty not to use or disclose
the "trade secrets" or "confidential information" of his employer. This duty is
inferred at common law, but would likely be specifically stated in Allan's
employment contract as well.  The precise definition of "trade secret" and
"confidential information" varies greatly from state to state.  Moreover, as
Medicomp would likely be seeking equitable relief, i.e., to enjoin Allan from
further use of the software, the court would be free to engage in a more
open-ended balancing of the equities than would be permissible if purely
monetary relief were sought.

    Given the flexible nature of current trade secret doctrine, a court could
really go either way on this issue. The touch sensitive utility at issue here
does seem to fall within the generally accepted range of protected information:
Allan's solution to implementing touch sensitive help would probably be
considered sufficiently "novel" by a court, the utility was likely "held out as
secret" by Medicomp, and the product has obvious commercial "value."  On the
other hand, a court would also consider the extent to which the program was
developed prior to employment, the fact that the TAXELF and MEDSTORE do not
compete, and, in a minority of jurisdictions, the extent to which Medicomp
contributed in the development process apart from salary.

    More generally, though the court may undertake the analysis from a number
of different angles (trade secret, copyright, contract, etc.) the following
general factors would likely emerge as relevant:

      1)  The nature of the employment relationship and the language
          of the employment agreement.
      2)  Protection of employee's interests in intellectual property
          predating the employment relationship, and in job mobility
      3)  Protection of employer incentives to invest
      4)  The nature of what was taken - intangible ideas vs. tangible
          code.  Unfortunately, this arguably reduces to the question
          of whether Allan can change the code enough to make the
          second utility seem like an independent creation.


II.  SURVEY RESULTS

    I received close to 200 responses from programmers, employers, students and
professors involved in various aspects of computer technology.  Unfortunately,
despite my specific instructions to the contrary, many of the responses seemed
to be an account of what the writer felt the law was, rather than how she would
like it to be. Therefore, it would be misleading to draw any conclusions along
the lines of "90% of those surveyed thought Allan should not be able to reuse
specific code."

    However, I can draw some general conclusions.  The responses seemed to line
up surprisingly well with the treatment under the current law as summarized
above.  Again, it is not clear whether this is an indication that the law
tracks what is considered reasonable in the industry, or that RISKS readers are
well-informed of their legal rights.  The responses also reflected the highly
controversial nature of the allocation question and the range of issues
considered relevant.  Issues discussed included:

     1)  The importance of information-sharing to program
     development.  Many of the responses mentioned that
     programmers are most efficient in an environment where
     information is freely shared.  None of the cases or
     statutes I read seemed to even contemplate the importance
     of information-sharing in the development of an appropriate
     software protection scheme.

     2)  The importance of protecting the employer's investment
     through ownership rights.  There was almost universal
     agreement that the employer investor should own the
     software.  The responses differed, however, on how broadly
     ownership rights should be defined.

     3)  An employee's right to her general programming skill.  There
     was, however, substantial disagreement as to exactly what
     constitutes "general skill".  There was general agreement that
     it does not include actual code, but the responses diverged greatly
     as to whether general skill includes code written from memory,
     program structure and functionality.

     4)  The importance of competitive harm.  Lack of competitive
     harm was often seen as a factor in favor of allowing a
     departing employee to make use of software owned by his
     employer.

     5)  The nature of the software in question.  A few of the
     responses suggested that some kinds of programs should be
     singled out as being more worthy of protection than others.
     (For example, an employer arguably should not be able to sue
     an employee who recycles a standard sort program.)

     6)  The affect of pre-employment assignment agreements on
     inventive behavior.  While most people seemed to feel such
     agreements are valid and enforceable, many noted that
     incentives to invent, and in particular, to reveal those
     inventions to one's employer, would be greatly reduced.

     7)  Problems in policing ownership rights in software.  Many
     of the responses noted the difficulties inherent in proving
     misappropriation, particularly where the defendant
     originally wrote the code.

     8)  The team-programming problem.  Some of the responses opted
     for employer ownership simply because it would be next to
     impossible to determine which employees were primarily responsible
     for the develpment of a product, and impractical to give
     ownership rights to low-level programmers only marginally involved.

     9)  Software Tools.  A minority of the responses suggested that
     denying an employee access to actual code she wrote for a prior
     employer could greatly undermine her effectiveness and marketability.


     Thank you all for your responses.  They were a great help
to me in analyzing and critiquing the current law's allocation scheme.

     Again, I'm not in a position to give practical advice, but I would
like to say this much:  the law in this area is extremely muddled.  There are
no clear cut answers, and the few emerging standards are subject to change. So,
don't take anything for granted.  Also, after reading hundreds of cases,
statutes, articles, etc., I am convinced that there is a GREAT need for more
input from the technical community.  Many judges, laywers, legislators and
commentators, even those of us with some background in computer science, do not
have a firm grasp of all the intricacies and unique needs of the software
develpment industry.  If the law is to serve its function of promoting the
development and accessibility of software products, the legal and technical
community must work hand in hand.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Preliminary A320 Inquiry Results
</A>
</H3>
<address>
martin@bashful   
&lt;<A HREF="mailto:@RELAY.CS.NET:martin@bashful">
@RELAY.CS.NET:martin@bashful
</A>&gt;
</address>
<i>
Mon, 8 Aug 88 20:01:59 PDT
</i><PRE>

Aviation Week and Space Technology, August 8, 1988 has a paraphrase of the
preliminary report; if you want more details than my paraphrase of a
paraphrase contains, I refer you there (I'm too lazy to type in any
substantial extract).

The major points of interest to RISKS readers would seem to be:

* The CFM56 engines and the engine controls responded properly to control
  inputs; the throttles were advanced 5 seconds before impact, and the
  engines had spooled up to 83% N1 speed by impact.  This was not enough
  to produce any useful change in aircraft attitude or speed (indeed, the
  aircraft's airspeed would seem to have continued to decrease during
  this time).

* The pilot and copilot (apparently informally) planned to fly at 100 ft.
  AGL for the flyby, with no planned airspeed (oops).  They ignored
  three radar altimeter callouts below this altitude (the radar altimeter
  gave six callouts in the 25 seconds between 100 ft. and impact, three
  after the throttles were advanced).

* The pilot intentionally disabled the alpha floor protection mode in the
  autothrust system; this mode is intended to provide protection against
  windshear accidents.  Alpha floor refers to the symbol used for angle of
  attack--alpha floor would normally apply takeoff/go-around thrust if
  the angle of attack were to exceed 15 degrees.  As you can see from
  following the altitude/speed profile of this flight, large aircraft
  don't accelerate and climb very well (that is to say, at all) at low
  speeds and high angles of attack.  It takes a long time to spool up
  large high-bypass engines, and it takes even longer before that energy
  input has any effect on the aircraft.

At any rate, Aviation Week says the investigation is now trying to
determine why the pilot and copilot were unaware of their situation (that
is, why they were apparently unaware that they were lower than they
intended, and presumably why they were unaware that they were in deep
trouble with energy (= airspeed) management:  airspeed dropped from
151 kt. at 25 seconds before impact to 112 kt. one second before impact).

In unrelated French (un)safety news, SNCF is investigating two changes to
brakes on its trains, following the second major accident in Paris:  they
are considering replacing the conventional vent-all-the-air-and-eeeeeek
emergency brakes with an intercom to the driver, and they are considering
removing the disconnect valves which enable train crews to disable the
brakes on an individual carriage.  (The source for this fine item is
New Scientist; the British railway-isms may give that away.)

  --Martin Harriman
    martin@cadev4.sc.intel.com

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Computer terminals and dermatology (Re: <A HREF="/Risks/7.31.html">RISKS-7.31</A>)
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Mon, 8 Aug 88 21:18:54 PDT
</i><PRE>

   I found the article posted by steinmetz!welty@uunet.UU.NET (richard 
welty) on "Computer terminals and dermatology" very interesting.  There 
were several statements in the article that directly contradict several
studies I've read.  For example:

  VDTs produce several types of electromagnetic radiation.  The cathode ray 
  tube emits low-energy x-rays.  The phosphor material of the screen emits
  ultraviolet, visible, and infrared radiation.  The electronic circuits
  produce radiofrequency and very-low-frequency radiation.  Most electrical
  and electronic equipment can generate ``electrical noise,'' a low-level,
  broad-spectrum electromagnetic radiation.  To date, no adverse biological
  effects in humans have been documented from these electromagnetic fields
  and the level of radiation emitted is far below the occupational standards
  set by federal authorities (references 2-4).

   Current design VDT's (within the last 10 years) emit essentially no
detectable x-rays.  Light, from the u/v through i/r range, is of low
intensity, less than from typical office incandescent and flourescent
bulbs.  RF intensities are generally lower than the ambient intensities
from local radio and TV stations.  The article does point out that no
known adverse effects have been linked to these sources at these levels,
so the earlier statements aren't really significant.  

   The article notes onset of dermatitis during conditions of "low ambient 
relative humidity at the time of the exposure", and that "The electro-
static fields, however, are more likely to be the causitive agent of VDT 
dermatitis."  These observations are consistent, as low humidity increases
the tendency of electrostatic devices to precipitate out charged airborne
particles.   However, causality is not observed: " Whether this is a direct 
effect of the field itself or an irritant dermatitis from airborne 
particles is unknown."  

   About three or four years ago, a panel at the ACM SIGCHI conference 
discused the issue of VDT hazards to health.  Dermatitis was observed
in several case studies.  It was discovered that the effected operators
had the habit of touching the screen and later touching their faces.
This action served to transfer particulates that had precipitated out
of the air from the screen onto the faces of the operators.  The 
industrial "fix" to the problem was to institute a procedure of cleaning
the screens of all VDT's at the beginning and end of each work shift.

   Blocking agents would be expected to help as they would not only 
reduce skin contact with the precipitated material, but also reduce
the incidence of operators touching the screen, as this action would
coat the screen with blocking agents transferred by the fingers.

   The conclusion of the SIGCHI panel was that the greatest danger
to VDT users was through poorly designed workstations that contribute
to poor posture, increased back and muscle strain, and visual problems
causing eye strain, headaches, and even seizures.

   Straighten up out there, and clean those screens regularly!

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.31.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.33.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-74</DOCNO>
<DOCOLDNO>IA012-000129-B048-130</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.33.html 128.240.150.127 19970217022452 text/html 24169
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:23:16 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 33</TITLE>
<LINK REL="Prev" HREF="/Risks/7.32.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.34.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 33</H1>
<H2>  Wednesday 9 July 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Cascaded Inference and the Vincennes affair 
</A>
<DD>
<A HREF="#subj1.1">
CFEEHRER
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  "Virus" Bill 
</A>
<DD>
<A HREF="#subj2.1">
Joseph M. Beckman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  More RISKy ATM's 
</A>
<DD>
<A HREF="#subj3.1">
Dave Horsfall
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Keeping Autos and Drivers in Suspense 
</A>
<DD>
<A HREF="#subj4.1">
Joseph M. Beckman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Airbus Cockpit Alarms 
</A>
<DD>
<A HREF="#subj5.1">
Fred Baube
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  A-320 investigation 
</A>
<DD>
<A HREF="#subj6.1">
Steve Philipson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Federal charges brought against accused teen-age hacker 
</A>
<DD>
<A HREF="#subj7.1">
Mike Linnig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Orbit 100,000 self-guided "brilliant" weapons, Reagan advised 
</A>
<DD>
<A HREF="#subj8.1">
Jon Jacky
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Cascaded Inference and the Vincennes affair
</A>
</H3>
<address>
&lt;<A HREF="mailto:CFEEHRER@G.BBN.COM">
CFEEHRER@G.BBN.COM
</A>&gt;
</address>
<i>
2 Aug 1988 20:28-EDT
</i><PRE>

  I have become interested in the dialog lately re: Vincennes and the question
of thresholds for declaring radar blips hostile (see, for example, Wellman, 9
July; Johnson, 10 July; Estell, 12 July) and would enjoy some comments in
regard to the following proposition: "There's nothing wrong, in principle, with
"binary thinking/decision making" if ALL of the information available for a
choice among competing hypothesis is employed in the computation of posterior
odds."  What may have gone wrong in the Vincennes case is that not all of the
information that was available came to be used.  Most notably, perhaps, the
diagnostic value associated with target aspect ratio, which the press tells us
was more-or-less head-on and at short range relative to the design envelope of
Aegis, did not enter into the decision in a formal way.  It is interesting to
me that difficulties with interpreting an image formed under such circumstances
was one of the first explanatory notes to surface during coverage of the
encounter.  Thereon hangs the story below.


I'm suggesting that, however, accurate the Aegis sensor and signal processing
systems may be, the information presented to the human decisionmaker is
apparently equivocal ("unreliable") at certain combinations of range and aspect
and provides the basis for a very complex judgment even when a good estimate of
the priors can be made.  It seems to me that the situation, corresponds closely
to what has been called "cascaded inference" in behavioral decision theory.  In
prescriptive approaches to decision making in this kind of situation, there are
two sets of conditional probabilities: the probability of a datum conditional
upon an hypothesis, and the probability of a REPORT (verbally, electronically
or otherwise delivered) conditional jointly upon an hypothesis and a datum.  If
the components of these are known or can be estimated, then the probability of
a report conditional upon an hypothesis can be easily calculated.  In effect,
the decision maker is required first to adjust the nominal diagnosticity of the
report to reflect the reliability of the source -- "interpretability of the
image" is a better term here -- and then to apply this adjusted datum to the
hypotheses under evaluation using Bayes' rule.  In the scenario I'm conjuring,
the first task would have been to make a (cognitive) adjustment of the
diagnosticity of the displayed image (i) given the hypotheses, "(a)ttack",
"(n)o attack", and then to compute the posterior odds (p(a:i)/p(n:i) given
p(i:a) and p(i:n).  (Note that at optimal ranges/aspects, the diagnosticity
would be assumed to be nearly perfect, while at non-optimal ranges/aspects, it
would be considerably less than perfect -- a little circular but OK for now!
The point is that, while the electronics remain the same, the intrinsic value
of the image, its utility, for purposes of deciding between two (or more)
mutually exclusive hypotheses varies.)

When one compares the posterior odds achieved with an adjusted datum with those
achieved with an unadjusted datum, the results can be startlingly different!
(This is not a good forum for lengthy equations, so I'll simply ask you to
believe that assertion! I'd be happy to send along some references and a short
demonstration to anybody who's interested.  For a quick perspective, consider
that a likelihood ratio of 9:1 falls to approximately 4.3:1 when one reduces
the reliability of the reporting system from 1.0 to 0.9.  That can lead to
quite a different decision with the same set of priors.)

Research in decision making in medical, military command, process control/QC,
and trouble-shooting contexts regularly demonstrates two phenomena: (1)
Decision makers are typically not trained to make decisions "by the numbers",
even when that is possible -- it's not a skill that comes naturally; (2) The
few decision makers who are familiar with quantitative decision aids have
rarely been taught means for coping with unreliable data.  The sad thing is
that virtually ALL data, whether delivered through eyes and ears or complex
sensor systems are unreliable from time to time and/or for certain purposes.
So, is it surprising that, in situations characterized by high stakes and great
stress, wrong hypothesis are occasionally supported and correct ones
discarded?! (There is an interesting literature associated with attempts to
create descriptive models of what decision makers actually do which suggests
that optimal procedures for discounting equivocal information are rarely
intuited, but that they can be trained.  References on request.)


The "story" above is clearly a house of cards -- plausible maybe but
unverifiable at best.  Who knows if ANY quantitative reasoning went on at all
-- but I do want to suggest that binary decision frameworks may not be as
limiting as they may seem at first if they are properly implemented.  I'm a
strong supporter of neural net/fuzzy set approaches, but only if simpler
algorithms are found wanting and their alternatives are not.       cef

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 "Virus" Bill
</A>
</H3>
<address>
"Joseph M. Beckman" 
&lt;<A HREF="mailto:Beckman@DOCKMASTER.ARPA">
Beckman@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 5 Aug 88 10:36 EDT
</i><PRE>

"Computer Virus Eradication Act of 1988"

(a) Whoever knowingly --
 
          (1) inserts into a program for a computer information or commands,
knowing or having reason to believe that such information or commands will
cause loss to users of a computer on which such program is run or to those who
rely on information processed on such computer; and

          (2) provides such program to others in circumstances in which those
others do not know of the insertion or its effects;
 
or attempts to do so, shall, if any of such conduct affects interstate or
foreign commerce, be fined under this title or imprisoned not more than
10 years, or both.

Entered July 14th 1988 by Mr. Herger (congressman from CA) for himself and
Mr. Carr; referred to Committee on the Judiciary, to amend title 18.

Joseph                        [You can lead a Trojan horse to Waterloo, 
                              but you can't make his legislator think.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
More RISKy ATM's
</A>
</H3>
<address>
Dave Horsfall 
&lt;<A HREF="mailto:munnari!stcns3.stc.oz.au!dave@uunet.UU.NET">
munnari!stcns3.stc.oz.au!dave@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 4 Aug 88 14:39:34 est
</i><PRE>

From Neville Angove's column in "Computerworld", 29th July:

``According to a number of sources in the systems programmer community,
the recent media noise concerning ATM fraud/failures indicates a number
of severe problems being faced by financial institutions with ATM
networks.  As the size and usage of these networks have increased, so
have the security risks, due to the fact that the knowledge of ATM
characteristics and network limitations have become more widespread.
The most serious rumour is that one bank has evidence that someone has
discovered a means to decode the PIN encrypted on to the magnetic strip
of stolen ATM and credit cards.  [It is not generally well-known that in
Australia at least, that strip encodes your PIN!] 

Another factor causing concern, especially to the more knowledgable
members of the public, is the increasing use of lower-cost -- and
probably lower-quality as a result -- ATMs by the smaller banks which
want to provide a competitive service but cannot justify the cost of
higher-quality equipment.  A model of the ATM favoured by one bank is so
lacking in "intelligence" that it can only run in on-host mode [?], and
circumvents the problems of storing transaction details by printing them
as they occur on to a paper cash register roll (an ironic solution,
since the manufacturer originally made its name as the giant of the cash
register business).  [Well, perhaps they need to use up a warehouse full
of rolls!] 

The increasing number of instances in which ATM networks have not
functioned as claimed, or where stolen cards have been used to milk the
victim's account in apparently impossible circumstances, is evidence
enough of some fundamental design faults or deficiencies in a number of
-- but not necessarily all -- ATM networks.  Public claims by the banks
that their networks are secure do not agree with concerns they have
expressed privately, but it is unlikely that the community will see any
improvement until the problems with ATM networks are brought to light
through the legal system.'' 

Dave Horsfall (VK2KFU), Alcatel-STC Australia, dave@stcns3.stc.oz
dave%stcns3.stc.OZ.AU@uunet.UU.NET, ...munnari!stcns3.stc.OZ.AU!dave

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Keeping Autos and Drivers in Suspense
</A>
</H3>
<address>
"Joseph M. Beckman" 
&lt;<A HREF="mailto:Beckman@DOCKMASTER.ARPA">
Beckman@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Tue, 9 Aug 88 10:25 EDT
</i><PRE>

From "The History and Future of Automobile Suspension" by Rick Castelli in
CORRIDOR TODAY July 29 1988 p9 (No copyright or reprint directions on page)

"As a result of Japanese competition, all of the major American and German
automakers are racing to provide their own versions of 'smart' suspensions as
soon as possible...Both Lotus and Volvo's systems have eliminated the use of
springs, shocks, and antiroll bars, as well as other components.  Instead,
hydraulic cylinder devices are incorporated that detect various lateral and
vertical wheel motions.  Sensors are also used to detect other factors and
forces upon the car.  All of this data is fed into a computer which
subsequently inputs instructions to the hydraulic cylinder devices to adjust
wheel deflection and angle.  What results is that the wheels never leave
contact with the road, and the body of the car automatically leans precisely
into turns, thus maintaining a stable flatness, even through emergency
maneuvers.  This is a phenomenal advantage! In a sense, it makes the car feel
as if it's floating independently above the road.
          Likewise, this could be one disadvantage -- among others.
Drivers will lose that inner sense of knowing when a car is at its
limits of handling, and might get too confident for their own welfare."


The last point reminds me of some study done years ago.  Some researcher, S.
Peltzman, found that the mandatory use of seat belts would not save (net)
lives.  The reason given was that drivers feel 'invincible' (or more so) when
wearing them.  Consequently, they became less attentive to driving, increasing
the number of accidents.  Although they did a good job of protecting the
driver, many accidents killed pedestrians; more than the number of drivers and
passengers they saved.                                               Joseph

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Airbus Cockpit Alarms
</A>
</H3>
<address>
Fred Baube 
&lt;<A HREF="mailto:fbaube@note.nsf.gov">
fbaube@note.nsf.gov
</A>&gt;
</address>
<i>
Tue, 09 Aug 88 13:24:58 -0400
</i><PRE>

munnari!banana.cs.uq.oz.au!bigm@uunet.UU.NET 
(Michael Pilling (Dr Chocberry)):

	Several times before the critical manoeuvre the crew
    contemptuously dismissed visual and aural wornings emitted by the
    onboard computers.
	The pilot responded to one by saying: "Knock that one off,
    it's getting on my nerves."

Pardon my naivete, but ..

This sounds like the Amtrak crash.  Any irritating+persistent
alarm that "cries wolf" gets defeated with whatever tools are at
hand.  If the condition causing the alarm is an everyday event
(Amtrak), or an event that was out of the ordinary but nonethe-
less intended (e.g. fancy airshow maneuver), and the same alarm
is to be used for a REAL problem, then the alarm won't be there
when it's needed.

Don't these guys that design alarms consider a "cry wolf" factor? 
Would they want to be trying to fly an airliner with an unneces-
sary racket disturbing their concentration ?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
A-320 investigation
</A>
</H3>
<address>
Steve Philipson 
&lt;<A HREF="mailto:steve@aurora.arc.nasa.gov">
steve@aurora.arc.nasa.gov
</A>&gt;
</address>
<i>
Tue, 9 Aug 88 12:26:56 PDT
</i><PRE>

Re: martin@bashful   &lt;@RELAY.CS.NET:martin@bashful&gt; posting on "Preliminary 
A320 Inquiry Results".

&gt;* The pilot and copilot (apparently informally) planned to fly at 100 ft.
&gt;  AGL for the flyby, with no planned airspeed (oops).  They ignored
&gt;  three radar altimeter callouts below this altitude (the radar altimeter
&gt;  gave six callouts in the 25 seconds between 100 ft. and impact, three
&gt;  after the throttles were advanced).

   The warnings would have been expected, and the crew would have planned
to ignore them.  The whole point of this maneuver was a low altitude
fly-by.  Ground proximity warning systems would call the altitude, so
there would be no reason to be alerted to a "problem" that was part of
the intended flight path.

&gt;* The pilot intentionally disabled the alpha floor protection mode in the
&gt;  autothrust system; this mode is intended to provide protection against
&gt;  windshear accidents.  ...

   This also seems reasonable for the flight path desired.  Manual control
of engines and AOA was desired, so again, this intentional disabling of
automatic systems seems reasonable.

&gt;                         ...                           large aircraft
&gt;  don't accelerate and climb very well (that is to say, at all) at low
&gt;  speeds and high angles of attack.  It takes a long time to spool up
&gt;  large high-bypass engines, and it takes even longer before that energy
&gt;  input has any effect on the aircraft.

   This is not quite true.  Jetliners attain close to maximum climb
performance at high angles of attack, but with maximum thrust.  The
recommended windshear escape maneuver is to raise the nose to just
below stall AOA and hold maximum power.  The problem IS in spool-up
time of the engines.  What I'm most interested in is how two highly
experienced pilots allowed RPM to decrease below reasonable values
for this type of maneuver.  

   One of the first things you learn when flying jets is that you must 
keep RPM up if you will need a rapid application of power.  Did the 
engine control system retard power below the intended setting?  Did 
the combination of enabled and disabled systems cause the engine settings 
to go below what the pilots had intended?  

   The investigations into why the crew was unaware of their situation 
is critical to assesments of the safety of the A-320.  The unusual 
manuever and crew selected configuration may have had much to do with 
the cause of this accident.  We know that conditions not accounted for
in the design of complex systems are often the root of system failure.
Many of us are very concerned about digital control systems for just
this reason.  We will not know if this crash was really "pilot error"
until those elements of this accident are thoroughly explored.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Federal charges brought against accused teen-age hacker
</A>
</H3>
<address>
Mike Linnig
&lt;<A HREF="mailto:linnig@skacsl.csc.ti.com ">
linnig@skacsl.csc.ti.com 
</A>&gt;
</address>
<i>
Tue, 9 Aug 88 22:28:52 CDT
</i><PRE>

  CHICAGO (AP) -- A teen-age high school dropout is charged with using his
personal computer to break into AT&amp;T and government computers and steal more
than $1 million worth of software.
  "This is not malicious mischief," U.S. Attorney Anton Valukas said in
announcing the federal charges Monday. "It's a felony."
  Herbert Zinn Jr., 18, also is accused of advertising on a computer bulletin
board how to electronically break into AT&amp;T's computers.
  The charges against Zinn mark the start of "an aggressive position toward
computer crimes," Valukas said.
  Zinn allegedly committed the crimes when he was a juvenile, and could be sent
to prison until his 21st birthday in August 1991.
  Federal agents raided Zinn's home last year and confiscated three computers
and software allegedly stolen during the electronic break-ins.
  The telephone at Zinn's North Side residence went unanswered this morning.
  Zinn was quoted in today's editions of the Chicago Sun-Times as saying that
since the raid on his home, he had not pursued his computer techniques "with
quite the same vim and vigor."
  He said he nonetheless hoped eventually to resume his schooling and become an
electonics engineer, the newspaper said. Zinn would not discuss details of the
case, it said.
  The federal charges were brought after Zinn had been arrested several times,
including for alleged computer break-ins at the Keller Graduate School of
Management and at Commodity Perspective Inc., both in Chicago.
  "Before and after the computer break-ins (at Keller and Commodity
Perspective), Zinn was, by his own admission, breaking into AT&amp;T computers,"
Valukas said.
  Court documents said Zinn broke into an AT&amp;T computer at the North Atlantic
Treaty Organization's Maintenance and Supply Headquarters in Burlington, N.C.,
and an AT&amp;T computer at Robins Air Force Base, Ga.
  Valukas said the software taken from NATO and the Air Force base were "low
level in terms of sensitivity."
  Agents raided Zinn's home after an AT&amp;T security officer logged onto the
so-called Phreak Class-2600 computer bulletin board and spotted messages signed
by "Shadow Hawk," a code name the goverment said the teen-ager used.
  In the messages, Shadow Hawk bragged that he had gained access to AT&amp;T
computer files. In a similar message, Shadow Hawk made the mistake of including
his telephone number, which the security officer spotted, the government said.
  The purpose of the Texas-based Phreak Class-2600 is "to educate computer
enthusiasts . . . to penetrate industrial and government sector computer
systems," said William J. Cook, an assistant U.S. attorney.
  The government said Zinn also tried to electonically break into computers at
the Washington Post's accounts payable department, a hospital in South Bend,
Ind.; and computers in Columbus, Ohio; Rye, N.Y. and Pipe Creek, Texas. 

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Orbit 100,000 self-guided "brilliant" weapons, Reagan advised
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Wed, 10 Aug 88 08:53:39 PDT
</i><PRE>

The following story appeared in THE SEATTLE TIMES, Aug 9 1988, p. A3:

SDI OFFICIALS URGE 'PEBBLES' OVER 'ROCKS' by Dan Stober, Knight-Ridder News

A dozen high-ranking "Star Wars" officials met privately with President Reagan
two weeks ago to gain his backing for a new weapons idea: swarms of five-pound
rockets, known as "brilliant pebbles," that would orbit Earth and decide on 
their own to attack Soviet missiles.

The rockets, once launched, would not require a command from the ground to
attack.

"It's effectively a shield over the planet, consisting of these things, and if
anything pierces the shield that doesn't come from an allowed launch point
... it gets knocked off," said Bruce McWilliams, who headed a lab team that 
developed the optical sensors for "brilliant pebbles."

It would take 100,000 such rockets to defend against the next generation of
Soviet missiles, a Livermore study concluded.

...(the idea) was advanced by the Lawrence Livermore National Laboratory...
the classified White House briefing was given by Livermore physicist Lowell
Wood, a protege of the controverial Edward Teller.

- Jonathan Jacky, University of Washington

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.32.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.34.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-75</DOCNO>
<DOCOLDNO>IA012-000129-B048-152</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.34.html 128.240.150.127 19970217022510 text/html 22484
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:23:37 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 34</TITLE>
<LINK REL="Prev" HREF="/Risks/7.33.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.35.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 34</H1>
<H2>  Friday 12 August 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Eye focusing found to be VDT hazard."  
</A>
<DD>
<A HREF="#subj1.1">
Denis Haskin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Privacy (Again) 
</A>
<DD>
<A HREF="#subj2.1">
Willis Ware
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  "Virus" Bill 
</A>
<DD>
<A HREF="#subj3.1">
Jerome H. Saltzer
</A><br>
<A HREF="#subj3.2">
 Steven C. Den Beste
</A><br>
<A HREF="#subj3.3">
 Steve Kovner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  A Visit To the Clinic 
</A>
<DD>
<A HREF="#subj4.1">
Brian Ellis
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Aegis beaten by binoculars? (Trusting computers and/or people?)    
</A>
<DD>
<A HREF="#subj5.1">
Andy Coupland via Martyn Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Airbus 
</A>
<DD>
<A HREF="#subj6.1">
George Michaelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  SDI rationalizations 
</A>
<DD>
<A HREF="#subj7.1">
Steve Summit
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Misidentification of persons as criminal by computers 
</A>
<DD>
<A HREF="#subj8.1">
Haynes
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Eye focusing found to be VDT hazard."
</A>
</H3>
<address>
Denis Haskin 
&lt;<A HREF="mailto:denis%wellesley.edu@RELAY.CS.NET">
denis%wellesley.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Wed, 10 Aug 88 18:03:29 edt
</i><PRE>

  From the Boston Globe, Wednesday, Aug 10, 1988

    BERKELEY, Calif. - Regular work in front of a VDT screen may cause a
  premature loss in the eye's ability to focus, according to preliminary
  research by a University of California optometrist.  A deterioration in eye
  focusing among people in their 20s and 30s was the No. 1 problem found in
  153 patients treated at the university's Video Display Terminal Eye Clinic,
  said researcher James Sheedy.  The study, prepared for a symposium in Ohio,
  was the first clinical report of eye-focusing problems in VDT users.

They may be right.  I've been working with display screens for about the last
five years, and lately (last three years) usually most of a working day.  Until
recently I had no need of glasses but on my last exam the doctor recommended
some; they aren't very strong, but I have noticed a difference.  My eyes are
much less tired after a full day at a terminal now.

Denis W. Haskin, Technical Analyst, Digital Review, Boston, MA

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Privacy (Again) (Re: <A HREF="/Risks/7.32.html">RISKS-7.32</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:willis@rand-unix.ARPA">
willis@rand-unix.ARPA
</A>&gt;
</address>
<i>
Wed, 10 Aug 88 15:23:36 PDT
</i><PRE>

Denny's article is a rehash of old points and old concerns but updated with a
few contemporary examples.  He fails to raise and comment on a central point.

He asks (to paraphrase the point) what right a manufacturer has to ask all
manner of personal questions on the warranty form.  He should note (but did
not) that he nor anyone else is under no obligation to answer all manner of
questions in such a situation.  The warranty in no way will be affected if he
declines to answer.

My best bottom line on personal privacy is this:

        1.  Information intrusion and its consequences is just another one
of those risks of living in this world.

        2.  Each of us better be well informed of when we are legally
obligated to answer questions and give personal information, and when we
are not.

        3.  Each of us will have to understand that like other risks of
living in our world, privacy will require us to take care of ourselves,
using whatever mechanisms society and/or governments have provided and
whatever innovations we can indvidually create.

        4.  To the extent that people behave like information-sheep and
mindlessly answer every question put before them by any inquiring agent,
then privacy will be eroded more and more and self-protection will become
all the more difficult.

Trying saying NO when asked for personal information; you'll be surprised
at how often it won't make any difference.
           					     Willis H. Ware

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 "Virus" Bill (<A HREF="/Risks/7.33.html">RISKS-7.33</A>)
</A>
</H3>
<address>
Jerome H. Saltzer 
&lt;<A HREF="mailto:Saltzer@ATHENA.MIT.EDU">
Saltzer@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 11 Aug 88 00:27:31 EDT
</i><PRE>

&gt; (a) Whoever knowingly --
&gt;       (1) inserts into a program for a computer information or commands,...
&gt;       (2) provides such program to others in circumstances in which ...

Wonderfully put.  As I read that language, installing Sun NFS 3.0 in your
favorite operating system and then running it at your site would be a felony.
Perhaps this bill is not such a bad idea as it seems at first.

(Not to pick on Sun . . . there are dozens of other good examples.  Installing
your vendor's newest system release without alerting all your users would
probably become a felony, too.)
					       Jerry

</PRE>
<HR><H3><A NAME="subj3.2">
Re: "Virus" Bill
</A>
</H3>
<address>
&lt;<A HREF="mailto:denbeste@OAKLAND.BBN.COM">
denbeste@OAKLAND.BBN.COM
</A>&gt;
</address>
<i>
Thu, 11 Aug 88 12:06:50 -0400
</i><PRE>

It has been long known among law enforcement experts that severity of
punishment is less of a deterrent than certainty of punishment.

If a given crime has the death penalty, but only one change in a thousand of
being caught, convicted and punished, then there is no deterrence. If the
penalty is light but the chance of punishment is high, there is deterrence.
(Which is why no-one throws rocks through the windows of the Police station or
paints graffitti on its wall.)

So it is with this bill. The penalty is as stiff as the constitution allows,
but the chance of being caught is vanishingly small. The only virus-authors I
have heard have been identified were boasting about it. If they'd kept their
mouths shut, they wouldn't have been found.

But just finding them, hard as it is, is the easy part. How do you prove that
they are the author? JURY-prove, I mean.

Even without this bill, there were potential penalties. A large corporation who
was hurt by a virus could have sued the virus author, if they knew who it was
and could prove it. But the search usually would have cost more than the
damages.

What this bill DOES do is give the FBI grounds for a serious search for virus
authors. But what if the author is overseas? The current most common virus for
the Amiga was written in Switzerland.

Steven C. Den Beste,   Bolt Beranek &amp; Newman, Cambridge MA
denbeste@bbn.com(ARPA/CSNET/UUCP)    harvard!bbn.com!denbeste(UUCP)

</PRE>
<HR><H3><A NAME="subj3.3">
RE: "Virus" bill
</A>
</H3>
<address>
&lt;<A HREF="mailto:kovner%vsg1.DEC@decwrl.dec.com">
kovner%vsg1.DEC@decwrl.dec.com
</A>&gt;
</address>
<i>
Fri, 12 Aug 88 10:27:52 PDT
</i><PRE>

    While I doubt the entire anti-virus bill was published in Risks Digest
    7.33, the following excerpt seems to have problems:

&gt; (a) Whoever knowingly --
&gt;           (1) inserts into a program for a computer information or commands,
&gt; knowing or having reason to believe that such information or commands will
&gt; cause loss to users of a computer on which such program is run or to those who
&gt; rely on information processed on such computer; and

    This sounds like it makes the DELETE ( or rm ) commands illegal! Even
    more, what would it mean for operations people who have (and supply)
    command files to clean up disk areas? (e.g. PURGE on VMS or deleting
    *.tmp) UNIX(r) systems should have NOCLOBBER always set, and remove
    the &gt;! construct. Gear up disk drive production if this takes effect.

    I hope there is something in the bill which excludes commands
    necessary to the normal functioning of the system, and those which
    allow the user to lose things himself. This should be written to cover
    only those "information of commands" which are surreptitiously
    inserted, or exist in programs which are not expected to erase data.

    Steve Kovner,     Digital Equipment Corporation

    (The opinions expressed above do not necessarily represent the
    opinions of my employer.)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
A Visit To the Clinic
</A>
</H3>
<address>
&lt;<A HREF="mailto:ssc-vax!ssc-bee!ellisb@beaver.cs.washington.edu">
ssc-vax!ssc-bee!ellisb@beaver.cs.washington.edu
</A>&gt;
</address>
<i>
Wed, 10 Aug 88 09:45:24 pdt
</i><PRE>

I went to a local medical clinic yesterday for the first time. After a few
minutes I wondered if I had come to the right place. The first clue that 
something was wrong was the complaint of the couple in front of me in line at
the front desk. They had received a bill in the mail for over 1,000 which was
surprising to them since they had prepaid provider insurance. (Prepaid
provider insurance allows the doctors office to bill the insurance company 
without the patient having to submit insurance claims). Furthermore
their account number for insurance was also scrambled and didn't match the 
credit card that is usually provided with prepaid insurance. The receptionist
explained that the computer had been broken and that they should ignore
the bill since they should not have gotten it in the first place.

When I went up to the desk upstairs someone was having to pay cash because
"the computer is messed up and cannot bill your insurance directly".  Of course
I was depending on *my* prepaid provider plan to pay and had maybe 5 dollars
to my name so I was a little concerned.  I had also noticed that there were
several assistants stashed in corners hand sorting what appeared to be
bills.

After the doctor found out I worked with computers he told me what had
happened.  The clinic had recently replaced their computer system with a
new one and disposed of the old one.  The new computer took the current
balance * number of patients in family and produced bills for all the
patients that had been in the clinic including people with prepaid provider 
type of insurance.  A nurse who had worked at the clinic received a bill for
over 4,000 dollars.  Apparently it had taken her bill of approximately 80
dollars and multiplied it by both her immediate family, and her grandchildren. 
I hope they keep their medical information on a separate computer! Take
3000 aspirins and call me in the morning :-)

It seems to me that using the new system that the clinic or the installer 
should have performed some kind of check before they converted over to the
new system or at least run the two systems in parallel until they verified
the operation of the new system. At least I would attempt to verify the new
system before I mailed out bills to hundreds of angry customers. I guess I
will have to wait till the end of the month and see how my bill comes back
but since there is only one of me at least they should be able to calculate 
it correctly. At least my back is feeling better. It does make me a little
angry that "the computer is always to blame" when it appears that the real fault
lies with the humans that install, program, and feed the computer. 

I think I understand now why we test software and look at the results.
I have seen more than one instance where the end user of a computer product
trusted the computer so much that they stopped checking the results even when
the were obviously wrong. Maybe we need to educate end users to not put
blind faith in the computer and as software producers to test our software
and make it as idiot proof as possible. Even a simple spot check of some of the
bills at the clinic could have prevented an expensive and embarrassing mistake.

Brian Ellis, Boeing Aerospace,Seattle, WA 98124-2499   (206) 773-2599
My boss has both opinions and humor but the views expressed here are mine.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Aegis beaten by binoculars? (Trusting computers and/or people?)
</A>
</H3>
<address>
Martyn Thomas 
&lt;<A HREF="mailto:mcvax!praxis!mct@uunet.UU.NET">
mcvax!praxis!mct@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 11 Aug 88 10:11:55 BST
</i><PRE>

The following letter appears in Flight International, 6 August 1988.  Copied
without consent.

"When I was a kid I was intrigued by an advertisement for a pair of
binoculars with which I would be able to see 'the craters of the moon' and
'France as if it was only a mile away'.  I saved up and bought them, and
when they arrived they were, in fact, a rather nice pair of wide-angle
10*50s.  I never saw France, but I certainly saw the craters on the moon.

The other day, from a vantage point on the South Downs, I thought I'd put
the old 10*50s to the test again.  Visibility was okay, but there was a lot
of wind and fairly low cloud around.  I looked in the general direction of
Gatwick Airport and after only a minute I saw the unmistakable profile of a
One-Eleven climbing out, smoking visibly.  Then a slightly larger aircraft -
almost certainly a 737, a -200 I'd say, the engines were not big enough to
be a -300. These are some binoculars, I thought: even if France doesn't look
a mile away, at least Reigate Hill does.

Only a few minutes passed before a relatively huge shape climbed into the
air - an ex-BCal DC-10, the overall design of the livery clearly to be seen.
Not only was this a DC-10, and not a TriStar, but it was an ex-BCal '10.  It
turned north soon after take-off, and flew away from home a while, and even
from this aspect it was definitely a '10.  I watched it climb and turn,
disappearing into cloud and then reappearing again.  Good sport this, I
thought, give me a clear day and I could follow a widebody all the way from,
er ... well ... Bandar Abbas?

Just a moment! What's going on? Am I really distiguishing between
near-identical wide-body aircraft from all aspects at almost *three times*
the slant range at which the captain of the USS Vincennes launched two
Standard missiles and destroyed an A300?

In disbelief I double-checked the scale of the map in the AA Book of the
Road.  No doubt about it, these aircraft are well over 20 miles away, and
that '10 must have been 30 miles out when I lost sight of him.  The Airbus
was only nine miles out, at 7500 feet on a clear day when the missiles were
fired. Okay, the A300 was motoring, but tell me which direction he was
coming from and with my 10*50s I reckon I'd have narrowed the field to a
757, 767 or an A300 before you could say 'F-14' - and certainly before he
got within nine miles.

I've never seen an RCA Aegis system advertised in Exchange and Mart but,
even if I do, I don't think I'll buy one.

[signed]
ANDY COUPLAND, 20 Holmcroft, Crawley, Surrey, RH10, 6TW		"

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Airbus
</A>
</H3>
<address>
George Michaelson 
&lt;<A HREF="mailto:munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET">
munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 12 Aug 88 11:25:31 +1000
</i><PRE>

Old news is no news but reflective journalism improves with age.

The developments in the airbus crash mirror the situation of the late 19th C
when warning devices began to be installed in Railway Engine cabs &amp; signal
boxes.  Getting highly trained "elites" to accept a machine warning is hard.
If they can switch it off, many of them will, until they crash themselves into
extinction. Does history ALWAYS repeats itself?

For me, the key point is NOT to let this stand as a reason to take a human
out of the system. The system worked, the pilot failed, but PLEASE leave
them in there.

Aegis, is almost but not quite an opposite situation. Both the System AND
its users failed. Some [me?] would argue aegis 'failed by design' since
attempting to 'predict' with &lt;100% accuracy something you cannot really 'see'
is not the same thing as 'identifying' with &lt;high-enough&gt; accuracy something
you might need to destroy. The failure was inevitable.

Congressman Smith seems to show that the process of procurement for the DoD
is sufficiently flawed as to make ANY complex system inherently doubtful.

        George Michaelson, CSIRO Division of Information Technology

ACSnet: G.Michaelson@ditmela.oz                      Phone: +61 3 347 8644
Postal: CSIRO, 55 Barry St, Carlton, Vic 3053 Oz       Fax: +61 3 347 8987

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
SDI rationalizations
</A>
</H3>
<address>
Steve Summit 
&lt;<A HREF="mailto:scs%adam.pika.mit.edu@RELAY.CS.NET">
scs%adam.pika.mit.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Tue, 2 Aug 88 22:23:47 EDT
</i><PRE>

There's an article in the August Issue of Reader's Digest by Tom
Clancy (author of The Hunt for Red October), entitled "Common Sense
About Strategic Defense."  Given RD's editorial stance, I was
surprised to see this title until reading the article revealed that
"Common Sense" entails that SDI is an appropriate, nay, desirable
response to Mutual Assured Destruction (MAD).  Most of the article is
fairly predictable, relying on things like blind acceptance of the SDI
"research" "results" reported so far, but the paragraph on software
really made me laugh (or cry):

	Some opponents have questioned whether we could program
	computers with the millions of calculations necessary to
	fight a battle against ICBMs.  I don't doubt we can.
	In the 12 years since supercomputers were introduced,
	these devices have moved from doing millions of
	calculations per second to billions, and are now about
	to exceed ten billion calculations per second.  Those
	who believe our computing capabilities are not up to the
	challenge ignore the fact that a computer that once
	filled a building would now fit on their wrists.  These
	people just haven't been paying attention.

Steve Summit, scs@adam.pika.mit.edu

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Misidentification of persons as criminal by computers
</A>
</H3>
<address>
99700000
&lt;<A HREF="mailto:haynes@ucscc.UCSC.EDU ">
haynes@ucscc.UCSC.EDU 
</A>&gt;
</address>
<i>
Wed, 10 Aug 88 22:03:04 PDT
</i><PRE>

We have had discussions of cases in which computer data bases wrongly
identified innocent people as criminals.  I just read an interesting counter-
case, in a Bob Greene column in an Esquire magazine from a few months ago.

Briefly, a man killed his live-in fiance, disposed of her body, and then
reported her as missing and mounted an effort to find her so as to establish an
alibi for himself.  A police officer on the case suspected the man, for some
reason, and tried to look him up in a computer database, presumably NCIC.  He
got nothing, so he tried variant spellings of the man's name and turned up the
identity of a fugitive from justice with almost the same social security number
and birth date as his suspect.  Confronted with this, the man confessed to
being the fugitive and waived extradition to be tried for the earlier crime.
With further grilling he confessed to the murder.

Greene also noted that while the Chicago police were looking for the missing
woman, her unidentifiable body was found in Indiana where the murderer had
taken it.  But there was no communication between the two police agencies in
this matter instance.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.33.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.35.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-76</DOCNO>
<DOCOLDNO>IA012-000129-B048-182</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.35.html 128.240.150.127 19970217022526 text/html 18643
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:23:52 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 35</TITLE>
<LINK REL="Prev" HREF="/Risks/7.34.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.36.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 35</H1>
<H2>  Monday 15 August 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: Privacy (difficulty of witholding "private" information) 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: Keeping Autos and Drivers in Suspense 
</A>
<DD>
<A HREF="#subj2.1">
Win Treese
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Cascaded inference 
</A>
<DD>
<A HREF="#subj3.1">
G.L.Sicherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: "Eye focusing found to be VDT hazard."     
</A>
<DD>
<A HREF="#subj4.1">
Brint Cooper
</A><br>
<A HREF="#subj4.2">
 Anthony G. Atkielski
</A><br>
<A HREF="#subj4.3">
 Jeremy Grodberg
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Can current CAD/simulation methods handle long-term fatigue analysis?    
</A>
<DD>
<A HREF="#subj5.1">
John R. Galloway
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  ATMs and PIN protection: twice silly victims in Boulder 
</A>
<DD>
<A HREF="#subj6.1">
Gary McClelland
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Orbit 100,000 self-guided "brilliant" weapons ... 
</A>
<DD>
<A HREF="#subj7.1">
Amos Shapir
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: Privacy (difficulty of witholding "private" information)
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Mon, 15 Aug 88 09:15:05 PDT
</i><PRE>

&gt; (In RISKS 7(34) Willis H. Ware recommends (in response to a posting
&gt; about nosy questions on warranty cards): (people are) under no obligation
&gt; to answer all manner of questions in such a situation - (try) saying NO
&gt; when asked for personal information...

This is good advice.  However, the implication of this posting, that
individuals can significantly control information about their activities that
is collected by firms they do business with, is not true in general.

Information about you that firms learn in the course of doing business
with you is their property, not yours.  It has significant commercial value
which some firms exploit aggressively.   Much of the commercial value derives
from the ability to process this information by computer.  Some of the firms
that do this are utilities, so you do not have the choice of "saying NO."

For example, the local telephone operating company in the Seattle area
has offered a service in which it makes its directory listing information
available to other marketing firms in machine readable form.  Salespeople have
always been able to work through the telephone book of course, but the
value that the computer adds is that the listings can be processed in 
various ways.  Most obviously, the marketer can ask for just the phone numbers
in a given set of zip codes to focus on particular neighborhoods.  Having
the data in machine readable form makes it easy to match against other 
databases the marketer may have.  Note that this is a product that the
phone company sells, just like it sells local telephone service.  
There was a bill introduced into the Washington State legislature that would
have prohibited utilities from reselling information about any customer
without that customer's written permission.  It was killed in committee
due to lobbying efforts by utilities.

&gt; (Willis Ware says) Information intrusion and its consequences is just
&gt; another one of those risks of living in this world.

I believe this takes a much too passive view of the situation.  Information
about individuals (the real stuff of which privacy is an abstraction), like
many other commodities of value, is being struggled over by different parties
that have competing and somewhat incompatible interests.  Who eventually 
ends up with what will result from a combination of laws, regulations,
legal proceedings, and market activity.  The exact contents of these
remain to be seen, but participants who take a passive view of this 
struggle are likely to wind up with very little.

- Jon Jacky, University of Washington

    [By the way, the Sunday New York Times of 31 July had a nice article by
    John Markoff on this general subject, including mention of the American
    Express practice of selling off selective mailing lists (e.g., rich tennis
    players who frequent resort hotels).  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Re: Keeping Autos and Drivers in Suspense
</A>
</H3>
<address>
&lt;<A HREF="mailto:treese@ATHENA.MIT.EDU">
treese@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Sat, 13 Aug 88 18:56:28 EDT
</i><PRE>

In RISKS 7.33, Joseph Beckman describes Sam Peltzman's studies on seatbelt
usage leading to no net decrease in auto accident fatalities.  It is worth
noting that Peltzman's studies were highly controversial and the methodology
was somewhat questionable.  Later studies did not show the same results.
Unfortunately, I do not have any references available now, but there was a
time when I researched the literature on this quite extensively.

The bottom line is still that wearing seatbelts is a good idea.

	Win Treese, Digital Equipment Corporation/MIT Project Athena
        Affiliation given for identification purposes only.

   [Aggressive drivers who feel safer because they are belted up are more 
   likely to be hazardous.  The computer analog relates to overly endowing
   your system -- the results are more likely to be hazardous.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Cascaded inference (in <A HREF="/Risks/7.33.html">RISKS-7.33</A>)
</A>
</H3>
<address>
g.l.sicherman
&lt;<A HREF="mailto:ihnp4!odyssey!gls ">
ihnp4!odyssey!gls 
</A>&gt;
</address>
<i>
13 Aug 88 22:18:31 GMT
</i><PRE>

In Risks Digest 7.33, cfeehrer@BBN writes:
&gt; 
&gt; ... What may have gone wrong in the Vincennes case is that not all of the
&gt; information that was available came to be used.  Most notably, perhaps,
&gt; the diagnostic value associated with target aspect ratio, which the
&gt; press tells us was more-or-less head-on and at short range relative to
&gt; the design envelope of Aegis, did not enter into the decision in a
&gt; formal way. ...

Cfeehrer goes on to discuss the use of a-priori probabilities and
Bayes's rule, and describes how "cascaded inference" can go badly
wrong.  I agree completely, and would like to extend the discussion.

For many years the A.I. research community has been divided over
which is more important in an intelligent system: a big knowledge
base or clever inference methods.  In the field, a majority of
researchers seem to prefer clever inference methods, mainly because
knowledge is hard to come by and harder to encode.

Meanwhile, the probability and statistics research community is
divided into Bayesians and non-Bayesians. (There are other
important philosophical controversies in probability and
statistics, but I won't go into them here.)  In brief, the
Bayesians hold that to get useful probabilities by calcu-
lation, you must calculate them from known a-priori probabilities.
The non-Bayesians hold that you can get useful probabilites even
without knowing enough a-priori probabilities to let you apply
Bayes's rule.  The non-Bayesians accept Bayes's rule--and seek to
augment it.

A non-Bayesian theory prominent in A.I. research is that of A. P.
Dempster, as formalized by his student G. Shafer.  This theory seems
to be popular because (1) its formulas can be computed routinely,
and (2) being non-Bayesian, it can dispense with some a-priori
probabilities that Bayesians would regard as necessary.  Whether
the Dempster-Shafer theory is a valuable contribution to probability
theory or a worthless and misleading exercise is yet to be established.
It falls in roughly the same grey area as Fuzzy Set Theory.

I'm a Bayesian myself; I have little to add to Boole's remarks on
this subject in his _Laws of Thought._  I'm not too worried about
"certainty factors" and similar oddities in the world of probabilistic
computation.  But I shudder at the risks of using military systems
that ignore some of the fundamental a-priori probabilities in the
field!  When such systems take appropriate action, it can only be
considered a fortunate accident.

Col. G. L. Sicherman

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
 Re: "Eye focusing found to be VDT hazard."
</A>
</H3>
<address>
    Brint Cooper 
&lt;<A HREF="mailto:abc@BRL.MIL">
abc@BRL.MIL
</A>&gt;
</address>
<i>
Fri, 12 Aug 88 19:53:07 EDT
</i><PRE>

Denis Haskin quotes the Boston Globe, "A deterioration in eye focusing among
  people in their 20s and 30s was the No. 1 problem found in 153 patients
  treated at the university's Video Display Terminal Eye Clinic..."

Then, he reports his own experience, "I've been working with display
screens for about the last five years,...on my last exam the doctor
recommended (glasses and) I have noticed a difference."

	I suggest that this sort of thing proves nothing.  All my life, I have
known people who read a great deal in their childhood and wound up with extreme
nearsightedness.  I knew a chap who repaired small timepieces most of his life
and, in his 60's was nearly blind.  No one suggested that books and precision
repair are risky to one's vision.  Perhaps any intensive visual activity,
unbroken over long periods of time, can lead to vision problems.  I suggest
that multiply blind, retrospective and comparitive studies of all these risk
phenomena are long overdue.

	"Risks of using computers must be assessed against the risks of not
using computers."                                         _Brint

</PRE>
<HR><H3><A NAME="subj4.2">
 Eye Focusing and VDTs
</A>
</H3>
<address>
"Anthony G. Atkielski, Honeywell Bull Inc." 
&lt;<A HREF="mailto:Atkielski@HIS-PHOENIX-MULTICS.ARPA">
Atkielski@HIS-PHOENIX-MULTICS.ARPA
</A>&gt;
</address>
<i>
Fri, 12 Aug 88 19:46 MST
</i><PRE>

I've been working with VDTs since 1980, and I'm now 27 years old.  Long ago I
noticed that my right eye didn't focus very well on distant objects.  The way
that eye behaved (trying to focus, overcorrecting, etc.) made me suspect that
the constant close-up work with the VDT was reducing the ability of my eye to
accommodate for distant vision.  The problem goes away after a couple days away
from the CRT, and no similar problem has manifested in the left eye.  My
ophthalmologist tested my eyes and found nothing wrong (!); he said there was
no evidence to indicate that using VDTs over long periods permanently affects
vision.

It's interesting to see a news item that mentions exactly the problem I've
noticed, among people in my age group.  If there really is a link between VDTs
and some focusing problems, what can I do about it?  I still have to use a VDT
every business day (I'm using one to compose this message).  I'm not going to
get glasses because I have the distinct feeling that the problem would
eventually disappear if I could just stay away from a VDT long enough.  What
are my options?  Didn't anyone notice problems like this in the days before
VDTs?  After all, VDT users aren't the first people to engage themselves in
close-up work for long periods.

Anthony Atkielski, Honeywell Bull Inc.

</PRE>
<HR><H3><A NAME="subj4.3">
Myopia (near-sightedness) and VDT use
</A>
</H3>
<address>
Jeremy Grodberg
&lt;<A HREF="mailto:jgro@pnet06.cts.com ">
jgro@pnet06.cts.com 
</A>&gt;
</address>
<i>
13 Aug 88 22:30:28 GMT
</i><PRE>
Sender: hodge!rusty@uunet.UU.NET

    Are there any studies about extensive VDT use leading to Myopia?  I had
20/20 vision when I started working as a programmer, and it has steadily gotten
worse since.  Further more, when I take a long absence from working (several
weeks), my eysight seems not to change, but when I return to work, it seems to
get worse rapidly.  Maybe its my imagination, but I have no evidence that wht I
thinks is happening isn't.
                                              Jeremy Grodberg

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Can current CAD/simulation methods handle long-term fatigue analysis?
</A>
</H3>
<address>
John R. Galloway 
&lt;<A HREF="mailto:jrg@apple.com">
jrg@apple.com
</A>&gt;
</address>
<i>
Wed, 10 Aug 88 17:24:48 PDT
</i><PRE>

As more and more of the design of (an aircraft say) is done on a computer, less
and less of the design will be handled by "rule of thumb" type decisions.
While this seems a good thing, I wonder if there is a down side concerning
aspects of the design that were implicitly included in the old rule of thumb or
handbook days (from years of experience) and are not necessarily included in
the computer model.  The case I am thinking of is the airliner a few months ago
where the top of the fuselage riped off (en route from one of the Hawaiian
Islands to another).  Are current supercomputer simulation methods capable of
handling the complexity of long-term stess, fatigue, corrosive environments,
etc., all of which were (apparently) factors in the Aloha incident?  Also I am
not at all sure that such things were handled any better before wide-spread use
of CAD -- I am just asking the question.  Any aeronautical engineers out there?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
ATMs and PIN protection: twice silly victims in Boulder
</A>
</H3>
<address>
"Gary McClelland"  
&lt;<A HREF="mailto:MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU">
MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU
</A>&gt;
</address>
<i>
Fri, 12 Aug 88 15:45 MDT
</i><PRE>

The latest ATM scam from Boulder:  The campus newspaper reports that a thief
has been lifting bank cards from unattended backpacks in libraries on campus.
A day or two later, the victim receives a call from a "bank security officer"
saying that a suspect has been caught trying to use victim's stolen bank card
to extract cash from an ATM.  As part of collecting "police report"
information, the "bank security officer" asks victim for the PIN so that he can
complete the investigation.  Victim gives the PIN over the phone and then "bank
security officer" uses the stolen card and the PIN to extract maximum allowable
cash limit.

Is this why it is good to have a human link in computer security systems?

   Gary McClelland, U. of Colorado

      [For those of you whose response is, "What, another silly story like
      this one?", the point is that scams like this succeed with amazing
      frequency.  We've had quite a few.  PGN]

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Orbit 100,000 self-guided "brilliant" weapons, Reagan advised
</A>
</H3>
<address>
Amos Shapir
&lt;<A HREF="mailto:nsc!taux01!taux02.UUCP!amos@Sun.COM ">
nsc!taux01!taux02.UUCP!amos@Sun.COM 
</A>&gt;
</address>
<i>
11 Aug 88 11:06:07 GMT
</i><PRE>
         [in <A HREF="/Risks/7.33.html">RISKS-7.33</A>, contributed by Jon Jacky]

  &gt;"It's effectively a shield over the planet, consisting of these things, and 
  &gt;if anything pierces the shield that doesn't come from an allowed launch 
  &gt;point... it gets knocked off," said Bruce McWilliams, who headed a lab team 
  &gt;that developed the optical sensors for "brilliant pebbles."

How on earth are they going to reprogram these things when new launch points
are used, which did not exist when the `pebbles' were launched?!

Even if they can be made to be reprogrammable, how can anyone be sure
that all 100,000 receive the message?  And that's even before considering
problems like hostile reprogram messages...

Amos Shapir, National Semiconductor (Israel), 6 Maskit st. P.O.B. 3007,
             Herzlia 46104, Israel Tel. +972 52 522261

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.34.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.36.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-77</DOCNO>
<DOCOLDNO>IA012-000129-B048-207</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.36.html 128.240.150.127 19970217022555 text/html 22520
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:24:08 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 36</TITLE>
<LINK REL="Prev" HREF="/Risks/7.35.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.37.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 36</H1>
<H2>  Wednesday 17 August 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Package-deal arguments about VDT's 
</A>
<DD>
<A HREF="#subj1.1">
Philip E. Agre
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Blue Cube new software problems 
</A>
<DD>
<A HREF="#subj2.1">
Randy Neff
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Zero-balance dunning letter 
</A>
<DD>
<A HREF="#subj3.1">
Jerome H. Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Chicago Disaster Conference 
</A>
<DD>
<A HREF="#subj4.1">
Lee S. Ridgway
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Car Electronics sensitive for atmospheric interference 
</A>
<DD>
<A HREF="#subj5.1">
Martin Minow
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  1 in 10 NATO software modules reported incorrect 
</A>
<DD>
<A HREF="#subj6.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Mathematical Error Puts Deficit off by $1.2 billion 
</A>
<DD>
<A HREF="#subj7.1">
PGN
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Package-deal arguments about VDT's
</A>
</H3>
<address>
Philip E. Agre 
&lt;<A HREF="mailto:Agre@WHEATIES.AI.MIT.EDU">
Agre@WHEATIES.AI.MIT.EDU
</A>&gt;
</address>
<i>
Mon, 15 Aug 88 17:31 EDT
</i><PRE>

When someone reports on the downsides of a technological artifact, they are
often labeled an `anti-technologist'.  They are then rhetorically asked if
they would prefer a world without electric lights and antibiotics.  We might
call this a `package-deal argument'.  It presents a monolithic entity called
`technology' and, by asking `are you for it or against it?', demands either
wholesale acceptance or wholesale rejection.

This technique can also be used on a smaller scale.  If someone has been
injured by working with a computer, one can make a package deal of a
monolithic entity called `computers' and say things like, to quote Brint
Cooper in RISKS 7(35),

    "Risks of using computers must be assessed against the risks of not
    using computers."

Frequently such arguments draw subtly bogus analogies to older, `lower'
technologies so as to portray the complainers as irrationally biased against
novelty and change.  Thus, 

    All my life, I have known people who read a great deal in their childhood
    and wound up with extreme nearsightedness.  I knew a chap who repaired
    small timepieces most of his life and, in his 60's was nearly blind.  No
    one suggested that books and precision repair are risky to one's vision.

Note the monolithic entities called `books' and `precision repair'.  Do
`books' cause nearsightedness?  Does `precision repair' cause blindness?
That's not the point.  `Books' and `precision repair' don't `do' anything, 
any more than computers `do' things.  What happens when people read books,
repair watches, or sit at VDT's depends on the context in which they do it.

When a human being is maimed at work, it is a complex social phenomenon.  If
`technology' can send people to the moon and keep track of huge inventories,
then `technology' can alleviate occupational hazards.  Technology is a tool.
The point about occupational visual damage connected to employers' workplace
practices regarding VDT's concerns the economics of industries that use
computers.  Do market forces encourage employers to protect employees or to
destroy them?  The answer to this question has varied at different places 
and times, but very often the answers have been sad ones.

Cooper is certainly correct that proper epidemiology is required with regard
to complaints of eye damage resulting from jobs involving VDT use.  I worry,
though, that in the context of Cooper's rhetoric, his painfully ironic demand
that these studies be `multiply blind', although perhaps methodologically
justified, might reflect a worldview in which `technology' is under attack
from `anti-technologists' who set up Video Display Terminal Eye Clinics in
order to generate pseudo-epidemiological propaganda.  This Manichean sort of
approach to debates about workplace organization is not going to help in
hearing the complaints of the maimed or in making offices and factories into
human places to work.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Blue Cube new software problems
</A>
</H3>
<address>
Randy Neff
&lt;<A HREF="mailto:neff@anna.STANFORD.EDU ">
neff@anna.STANFORD.EDU 
</A>&gt;
</address>
<i>
Mon, 15 Aug 88 21:13:27 pdt
</i><PRE>

From San Francisco Chronicle, Friday, Aug 12, 1988.  pages 1 and A22
(without permission and condensed)

New Pentagon Satellite System Having Troubles
   by John Schneidawind     Chronicle Staff Writer

A program to renovate the Pentagon's super-secret "Blue Cube" satellite-control
system in Sunnyvale is way over budget and behind schedule, according to a
recent congressional report.
    The General Accounting Office estimates that the Air Force program's costs,
orignally pegged at about $600 million in 1980, have ballooned to $1.4 billion
and could rise an additional $450 million before the project is completed.
    The Blue Cube, a top secret computer facility at Onizuka Air Force Base,
just off Highway 101 and Mathilda Avenue, controls satellites transmitting
the nation's most vital military and intelligence secrets. [also next to
Navy's Moffett Field, NASA Ames Research, and Lockheed.]
    The GAO report was issued last Friday [Aug 5], but so far has been 
distributed to only a handful of military experts.   The Chronicle obtained a 
copy of the report.
    The project's problems include glitches in computer software being developed
to process the tremendous amounts of data generated by communications 
satellites orbiting the Earth.
    According to the GAO report, the new system originally was supposed to 
handle 5 million bits of data per second, but it will be able to handle only 
about 1 million.
    The project was originally scheduled to be completed in October 1987 and 
was to have included a facility in Colorado Springs that would help control
the satellites.
    The arrangement would have allowed Sunnyvale and Colorado Springs to 
function as backup operations for each other.
    But the GAO says software problems have pushed the completion of the 
project to 1989 at the earliest.
    "(The) Defense (Department) considers Sunnyvale to be vulnerable to 
failures from earthquakes or other threats such as direct military attack,"
the GAO report notes.
    Officials at the Air Force's Space Command in El Sequndo, which oversees 
operations at the Cube, were not available for comment yesterday.  Officials 
from IBM Corp.'s Federal Systems Division in Bethesda, Md. which built the new
computer equipment and software, also could not be reached.
    The space shuttle is about to return to service, and the main priority will
be to put dozens of military satellites into orbit.
    But unless problems with the new satellite control systems are corrected,
the extra satellites could create capacity problems that may disruput the Blue
Cube's existing satellite control system, the GAO report implies.
    The Blue Cube -- so named because it is housed in a turquoise-colored 
building-- is maintained under contract by Lockheed Missiles and Space Co.
    According to the GAO, the facility monitors and controls 54 orbiting
satellites that provide critical defense communications, navigation, 
surveillance and weather information.   [more on what satellites do]
    However, some of the computer technology used to monitor and control 
orbiting satellites is more than 20 years old, and the Air Force since 1980
has been trying to come up with a new system.
    So great are the problems with the new system that the Air Force has yet
to fully test it successfully, let alone make it fully operational, the GAO
report states.
    As of February 1987, the GAO says, "the new system was averaging only a
69.6 percent success rate in performing satellite contact functions, where 95
percent success is the minimum requirement."
    The Air Force has told the GAO that the success rate is now 90 percent.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Zero-balance dunning letter
</A>
</H3>
<address>
Jerome H. Saltzer 
&lt;<A HREF="mailto:Saltzer@ATHENA.MIT.EDU">
Saltzer@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 16 Aug 88 10:41:33 EDT
</i><PRE>

Just in case anyone thought those stories about dunning letters for zero
balances are apocryphal, yesterday's mail from Bloomingdale's provided a
certifiable example:

     Dear Mrs. Saltzer

     A review of your account shows the amount below to be past due.

     If you feel that this amount is incorrect, please enclose a
     remittance for the correct amount and give us an explanation of
     the deductions on the reverse side of this letter.  Otherwise we
     shall expect payment in full of the amount due.

     We would appreciate your prompt attention to this matter.

     Thank you.
 
     Very truly yours,

     K. George
     Divisional Credit Mgr.
     212-239-0374
     Amount due $******.00

Since the letter seemed very sincere and it requested prompt action, I
immediately called the computer-printed telephone number, and reached a
recording, which said, "The number you have reached, 239-0374, has been
disconnected.  No further information is available about 239-0374."

The people in Bloomingdale's customer service department were profusely
apologetic; "That letter should never have gone out."  "The credit department
moved to a new location about a month ago."  Apparently the computer hasn't
found out about the move yet, and NY Telephone has already forgotten about it.

                			Jerry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
     Chicago Disaster Conference
</A>
</H3>
<address>
"Lee S. Ridgway" 
&lt;<A HREF="mailto:RIDGWAY@MITVMA.MIT.EDU">
RIDGWAY@MITVMA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 16 Aug 88 11:06:12 EDT
</i><PRE>

A boxed article in this morning's Boston Globe (8/16/88) noted that the
organizers of a conference on disasters, slated for Chicago's McCormack Place
in November, had to be cancelled due to lack of interest.

   [UPI in San Francisco Chronicle, 16 Aug 88 quoted the PR firm representative
   representing the organizers: ``It is absolutely amazing, given the things
   that have happened recently...''  ``Canceling this is a bit of a disaster 
   itself.'' ...   PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Car Electronics sensitive for atmospheric interference
</A>
</H3>
<address>
Martin Minow
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
16 Aug 88 11:01
</i><PRE>

From the Stockholm daily newspaper, Dagens Nyheter, 27-Jul-1988.  [My
quick translation.  My notes are in brackets.]

		Danger of Sensitive Car Electronics
			by Anders Lundqvist

Sensitive automobile electronics may be the explanation of the mystery of
"sudden acceleration." Interference in the atmosphere or a poor environment
under the hood can be sufficient to affect the electronics so that the
car unexpectedly speeds away out of control.

This theory was brought forth by the [Swedish Goverment] Traffic Safety
Board [TSV], which is worried about the development of electronics in cars.

"The development can be questioned.  What are the needs?  The engine
compartment is a difficult enviromnent for electronics; and how well
are the components isolated?" wonders Bo Jarleryd at TSV.

Mats Gunnerhed, a departmental director at the National Defense Research
Institute [FOA -- a Swedish equivalent of Mitre] has studied the problem of
sudden acceleration in cars since the summer of 1987.  One explanation is,
according to Gunnerhed, that the circuitboard for the automatic speed control
can be easily damaged [in such a way that the device forces full acceleration.
Gunnerhed demonstrated that a break in a single circuit-board trace can cause
this problem.  There was a note on this in a recent Risks.]  ...

But "sudden acceleration" has even been seen in cars without automatic speed
controls, which caused TSV to become interested in all electronic equipment.
"Scientific reports from Japan show that robots have killed 8 or 9 people
because of errors in the electronics.  Interference from nearby machines has
affected the robot's microprocessors," says Bo Jarleryd.

"The question is how sensitive automobile electronics and their microprocessors
are?  We have received several reports from drivers whose automatic speed
controls have turned off when they are in the vicinity of Arlanda [Stockholm's
airport].  This suggests that atmospheric interference in an area with many
radio [and radar] transmitters may be sufficient to halt the electronics."
[quote not attributed.]

Sudden acceleration cannot be associated with a single brand of automobiles.
owever Audi has been associated with a number of accidents where the car has
unexpectedly sped away.  One accident occurred in Stockholm about two years
ago where a car rushed up on the sidewalk and drove over two pedestrians,
causing the death of an older woman.

The police examination couldn't find anything wrong with the car.

Nor could anyone in the United States find any technical problem with the
800 cars that were involved in accidents caused by sudden acceleration
up to January 1987.

In any case, Audi in the USA decided to recall 250,000 cars in the 1978-1986
model years with automatic transmissions to add an interlock in the
transmission that required the driver to step on the brake before putting
the car in drive.  Even though the problem was, and still is, unsolved.

Even Ford, GM, Volvo, Saab, and Mercedes have had problems since the 1970's.

The American government decided on Monday [25-Jul-1988] to examine a total
of 215,000 German-built Mercedes Benz in the 1984-1988 model years with
gasoline motors and automatic transmission.  This is due to an alarm raised
by the "Center for Automobile Safety" on "sudden acceleration" in the cars.

According to the group, 164 reports of sudden acceleration of Mercedes Benz
have come in.  125 accidents were reported, resulting in 46 injured and one
death.

According to Philipsons, the importer of Mercedes Benz in Sweden, this is
primarily the 300E model with automatic speed control.

[I think there's an old Risks item noting a "sport" played by truckers with
high-powered CB radios, where they zap cars trying to pass them, causing
their electronic fuel injection to fail.  Also, note a recent Risks I posted
about the recall to fix the automatic speed control in my Volvo.]

[Translated by Martin Minow, minow%thundr.dec@decwrl.dec.com]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
1 in 10 NATO software modules reported incorrect (COMPASS '88 report)
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Tue, 16 Aug 88 08:47:06 PDT
</i><PRE>

I attended COMPASS '88, held June 27 - July 1 at the National Bureau of
Standards in Maryland.  COMPASS (for "Computer Assurance") is an
annual meeting devoted to the safety and security aspects of computer systems.

John Cullyer from the Royal Signals and Radar Establishment (RSRE), the central
electronics research laboratory of the UK Ministry of Defence (MOD). gave a
paper on his group's VIPER microprocessor, a 32-bit RISC chip designed for
safety-critical applications.

The VIPER project fits into a larger computer safety program at RSRE, and
Cullyer tried to convince the audience of the necessity for developing systems
with a great deal of mathematical rigor. Cullyer explained that RSRE's safety
program derived from MOD's concern over the integrity and safety of its
computer-based weapons and vehicles.  RSRE performed a study of NATO software
in the early 80's, using a static analysis technique in which a program is
represented as a directed graph, various expressions are associated with the
arcs and conclusions regarding correctness are derived from them. (Several
automated tools based on the RSRE work are on the market, including MALPAS from
Rex, Thompson and Partners, and SPADE, from Program Validation Ltd.  Cullyer
said a similar idea was behind an American tool called DAVE).  Of the modules
(a program is composed of many modules) which 
RSRE sampled from the NATO inventory, 1 in 10 were
found to contain errors, and of those, 1 in 20 (or 1 in 200 overall) had errors
serious enough to result in loss of the vehicle or plant!  About the same
findings were made whether the code came from Britain, the USA, or West
Germany.

But the MOD was really roused by several "near-miss" accidents which Cullyer
said he was not permitted to discuss.  He mentioned in conversation that one
incident involving "general ordnance" might have resulted in hundreds of
deaths. A military board of inquiry determined that computer problems were at
fault. Studies determined that incidents derived with approximately equal
frequency from three kinds of problems: incorrect or incomplete specifications,
errors in programs, and "unexpected functionality" from microprocessors. This
last item came as a bit of a surprise; what it meant was that the processor as
delivered simply did not behave as described in its assembly language
programming manual.  VIPER is an attempt to address this problem.  The project
was felt to be so urgent that it was funded within 48 hours of submission.

Cullyer closed his talk with a warning: "I don't think we have all pursuaded
our bosses that there is a problem.  If we do not implement these methods,
there will be a lot of accidents and a lot of people will die.  If we do
implement them there will still be accidents, but we will limit the
casualties." He also mentioned that new MOD software procurement standards
(which he helped draft) will require formal development techniques for critical
software.  He added that he thought British law and tradition were more
protective of people and sensitive to safety concerns than in the USA.  For
example, MOD regulations explicitly prohibit any cost saving that might
increase hazard to life -- you are not allowed to trade lives off against
money.

(This is an excerpt from a report on COMPASS '88 that will appear in the
October issue of ACM SOFTWARE ENGINEERING NOTES.  The conference proceedings
including Cullyer's paper on VIPER are available $30.00 from COMPASS '88, PO
Box 5314, Rockville, MD 20851)

- - Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Mathematical Error Puts Deficit off by $1.2 billion
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:NEUMANN@csl.sri.com">
NEUMANN@csl.sri.com
</A>&gt;
</address>
<i>
Wed 17 Aug 88 16:48:47-PDT
</i><PRE>

WASHINGTON (AP) -- A $1.2 billion mathematical error by the Reagan
administration in calculating the size of next year's federal deficit could
spark a fight within Congress when lawmakers return to the capital next month.
The mistaken estimate, which under the Gramm-Rudman balanced-budget law cannot
be rectified, is preventing the spending of $1.2 billion at a time when
legislators are struggling to decide which among several competing spending
bills they will pass. ...  OMB first made the error when calculating the rate
of spending in a foreign military sales program in an August 1987 deficit
report...  [From the San Jose Mercury News, 17 August 1988]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.35.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.37.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-78</DOCNO>
<DOCOLDNO>IA012-000129-B048-238</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.37.html 128.240.150.127 19970217022617 text/html 22630
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:24:43 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 37</TITLE>
<LINK REL="Prev" HREF="/Risks/7.36.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.38.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 37</H1>
<H2>Friday 19 August 1988</H2>
<H3>Forum on Risks to the Public in Computers and Related Systems</H3>
<I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">Virus insurance</A>
<DD><A HREF="#subj1.1">Rodney Hoffman</A><BR></DD>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">Blind faith in overly electronic locks</A></DT>
<DD><A HREF="#subj2.1">Leonard N. Foner</A><BR></DD>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">Fewer
Charges Now Require a Signature</A></DT>
<DD><A HREF="#subj3.1">Kian-Tat Lim</A><BR></DD>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">Re:
Danger of Sensitive Car Electronics</A></DT>
<DD><A HREF="#subj4.1">Hugh Davies</A></DD>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">Virus insurance</A></H3>
<ADDRESS>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM</A>&gt;
</ADDRESS>
<I>17 Aug 88 15:39:55 PDT (Wednesday)</I>
<P>
A front-page article by James Daly in the August 15 `ComputerWorld' surveys
availability of insurance against computer viruses.  Excerpts:
</P>
<BLOCKQUOTE>
  ... A recent survey of insurers providing computer security policies
  revealed an industry with not only a dearth of knowledge about viruses
  but an inability to determine whether policyholders are now or will
  ever be covered.  And at least one underwriter has also begun to 
  specifically reject virus protection....
<P>  
  Even where virus protection is not specifically excluded, an enormous
  gray area exists.  &quot;We're looking into it, but we're not sure it would
  be covered anyway,&quot; said [one insurer].  Others put it more bluntly.  
  &quot;I don't think you'll see coverage ever offered,&quot; said [a computer 
  security lawyer]....
</P><P>  
  At a recent American Bankers Association conference, a speaker from 
  Lloyds of London said the number of outstanding computer crime-related
  claims would devastate the industry if they were all brought to fruition.
  And the virus outbreak has made a bad situation even worse....
</P><P>  
  Additionally, it has always been difficult to put a dollar value on 
  information, and some assert that if everyone hit by a virus made a claim,
  the courts would be tied up for eons just figuring out how much the data
  was worth.
</P><P>  
  ... The deductible on many [computer security] policies ... often begins 
  at around $10,000, but may skyrocket to $3 million at large banks....
</P><P>  
  One underlying problem, most underwriters admit, is that they cannot
  keep pace with changes in the technology.... The Surety Association of
  America, a quilt of nearly 600 insurance underwriters, has formed a 
  committee to begin reworking some of its policies, and computer viruses
  &quot;will certainly be on the agenda,&quot; said [the assoc. V.P.].... 
</P><P>  
  &quot;We're doing like everyone else: trying to understand the technical 
  aspects of the virus,&quot; said [one insurance company senior V.P.]. &quot;Maybe
  then we will be able to relate it to some coverage.&quot;
</BLOCKQUOTE>

<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">Blind faith in overly electronic locks</A></H3>
<address>
Leonard N. Foner
&lt;<A HREF="mailto:foner@wheaties.ai.mit.edu">
foner@wheaties.ai.mit.edu</A>&gt;
</address>
<I>Thu, 18 Aug 88 00:03:05 EDT</I>
<P>
I work at a rapidly-growing company in Cambridge (currently about 160 people)
that just recently expanded to the third floor of our current building.
</P><P>
Prior to the expansion, we had a keypad on the first-floor door that would be
used to open the door from the outside.  To open the door from the inside, you
turned a mechanical latch that overrode the electric one (probably a
spring-coupled system like many other standard electric latches).  The second
floor was locked with a completely nonelectronic lock, and is the main entrance
for visitors and other such people.
</P><P>
Well.  Shortly after we expanded to the third floor, the main door to the space
acquired a locking device which was essentially a metal plate bolted to the top
of one door in a double door.  (The other door just uses the up-and-down slides
that lock it in place in the floor and ceiling unless you've got the first door
open---you've probably seen the type).  When the door with the metal plate is
closed, it contacts a very strong electromagnet mounted at the top of the frame
that holds the door shut with a theoretical strength of about a metric ton.
</P><P>
This magnet is controlled by a motion sensor mounted on the inside of the
space, on the wall to one side of the door.  The motion sensor presumably is
wired to the central alarm system (i.e., not in series with the actual
electromagnet).
</P><P>
Stop and think a moment about the implications of this.  Think you've got them
all?
</P><P>
It gets better.  It turns out that when the system was installed, *no one was
told* that there was a motion sensor on the inside.  The door automatically
locked at 6pm.  Immediately thereafter, somebody tried to get out on his way to
the airport, stopped a moment just inside the door to check something on his
person, and tried to open the door.
</P><P>
Surprise.
</P><P>
With the magnet on, turning the (unlocked) knob does nothing, because the door
is physically held closed.  Further, we had someone on the outside
(coincidentally) who was trying to get in.  What *they* didn't know (again,
because the alarm company didn't tell anyone else what they were doing) was
that they had to hit the # key on the keypad after entering the combination.
So the keypad was essentially inoperable, too.
</P><P>
It turned out that it took about fifteen minutes for us to open the door, from
either direction.  No one on the inside was moving enough for the motion sensor
to notice them (they were pushing on the door, to no avail, or typing on an
alarm control panel which seemed dead and was, in fact, not connected to
anything).  Eventually, someone happened to step back and scratch their head or
something, at the same time someone was pulling on the outside of the door, and
it magically and mysteriously opened with no effort at all.
</P><P>
No one knew why the door had unlocked, so the person who was now late for the
airport departed, while we opened the adjoining door so we could close the
magnetically locked one to figure out what was going on without risking being
locked in.
</P><P>
It took us another fifteen minutes to finally notice the correlation between
movement and the magnet.  (Since the magnet turning off is not audible, unlike
a latch retracting, we had to park one person leaning on the door to guarantee
that we'd know when it opened.  And the motion sensor, since it looks sideways
across the door, and very high off the ground, is not very sensitive to short
or medium people walking *toward* the door.)  Another few minutes of work
yielded the procedure for the keypad, and we were all set---or were we?
</P><P>
I had had bad misgivings about the magnet from the moment I had seen workmen
installing it, and it turns out that they have been borne out.  Consider, for
example, that there is no switch, not anywhere, that is directly in series with
the magnet's power supply.  Any failure of the motion sensor, its wiring to the
alarm, or the alarm itself could jam the magnet on, with no remedy except
unscrewing the (obviously nonmagnetic and probably aluminum) casing of the
magnet and cutting the leads.  Given that the case has about ten phillips-head
screws, I wouldn't like to try this in a fire---especially when you consider
how long it generally takes to find a phillips-head screwdriver and a pair of
diagonals...
</P><P>
Incidentally, the alarm and the magnet are battery-backed.  Even a fire that
killed the 120V power would not unlock the door, and if it burned through or
shorted, as appropriate, the correct wires, you can guess the outcome.
</P><P>
So once I realized how insanely they had designed the system (what's
wrong with an ordinary latch?), I went to our chief administrative
officer, who's also in charge of things like alarms, and asked her to
put a manual override on the magnet.  I drew a schematic to indicate
that the switch should be in series with the magnet itself, not
connected to the alarm's logic.  It only took *three days* to convince
her of the necessity for the change...
</P><P>
I also asked how the fire marshall could possibly approve such a dangerous fire
exit.  She gave the incomprehensible answer that the alarm people *were*
firemen.  Since I'm not aware that the fire department routinely double-dips by
working as alarm installers in their off hours, I let it drop there.  I'll
probably ask the fire marshall to come take a look if things don't improve.
</P><P>
So the alarm people, who were initially rather startled that we didn't trust
their alarm to work perfectly in all cases, even in the event of a fire, said
that asking for a switch wasn't totally a new concept, and installed one (no
doubt anything they can charge us a bundle for makes good sense to them).  This
switch is the sort that is labelled "Pull in case of fire" and generally makes
it look like it's a bad thing to pull the switch casually (it looks pretty
non-resettable).  This makes me hesitant to test it.  However, the fact that
the switch is on the wall under the motion sensor, rather than between the
magnet and the alarm (which is in a room on the *opposite side* of the door
from the motion sensor) makes me believe that the switch is simply in series
(or parallel, if it's normally-open) with the motion sensor.  This removes one
point of failure (the motion sensor), but still leaves all of its wiring and
the central alarm's logic circuits, which have already (in two weeks of
operation) demonstrated themselves to be unreliable.  (No one could get in on
Saturday.  The alarm company insisted that the logic had gotten wedged because
someone had entered their combination "too quickly" on the keypad outside.  I
don't know whether to believe them---and assume that the engineer who designed
the alarm is incompetent---or disbelieve them---and assume that the maintenance
guys are incompetent.  Neither is very reassuring in the face of this
non-overrideable lock.)
</P><P>
So we're left with a system that is difficult to test (sometime late at night I
will almost certainly disassemble the various pieces to see where the wires go,
and thus where the switch is in the circuit), unfriendly (the motion sensor is
not very sensitive, requiring people to often walk back and forth, jump up and
down, or wave things to get out), insecure (sticking a piece of paper on a coat
hanger between the gap in the two doors and waving it vigorously enough should
open them, if it's a sufficiently large piece of paper), and dangerous
(multiple points of failure all leading to being locked in).
</P><P>
Whatever became of good, old-fashioned mechanical locks?
</P><P>
To top it off, the second floor just got an electronically controlled latch
(not an electromagnet, but again with no obvious mechanical override), and it,
too, is attached to a motion sensor...
</P>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">Fewer Charges Now Require a Signature (L.A. Times)</A></H3>
<address>
Kian-Tat Lim
&lt;<A HREF="mailto:lim@csvax.caltech.edu ">
lim@csvax.caltech.edu</A>&gt;
</address>
<I>Fri, 19 Aug 88 00:29:09 PDT</I>
<P>
Fewer Charges Now Require a Signature<BR>
By Albert B. Crenshaw, the Washington Post<BR>
Los Angeles Times, August 18, 1988, page IV-3
</P><P>
WASHINGTON - A hotel in Richmond, Va., discovers some telephone charges after a
guest has checked out.  No problem.  An employee telephones the guest and tells
him the hotel will simply put the charges on his credit card.
</P><P>
A restaurant in Washington demands a credit card number when taking
reservations.  If the guests fail to show, a $15 charge is placed on the credit
card.
</P><P>
A busy professional spots an appealing item in a catalogue, dials an 800
number and says, "Ship it and put it on my credit card."
</P><P>
These transactions, like millions of others in today's charge-it world, have
one thing in common.  A charge was recorded on a credit card but no signed
document changed hands.
</P><P>
Signatures Not Required
</P><P>
The signature, in fact, is rapidly becoming obsolete in credit card
transactions.
</P><P>
Having a customer sign a slip when he or she buys something is already "less
significant than it was" in the past, said Dan Brigham of Visa International.
Credit cards today are evolving into "a national payment system," said Spencer
Nilson, publisher of the Nilson Report, a California-based newsletter that
tracks the credit card industry.</P><P>
"It allows you to do things you cannot do with cash," such as make
long-distance transactions, Nilson said.  "That is what people pay interest
for, what they pay fees for," and as the system becomes increasingly electronic
"the trend is for more transactions to be without signatures," he
added.
</P><P>
"Nothing in the law specifically requires a signature" in a credit card
transaction, said Elgie Holstein of Bankcard Holders of America, a
Virginia-based consumer group.
</P><P>
"The issue is positive identification of the card member," said Philip Riese
of American Express.  This can be done several ways -- by comparing the
signature on the card to the one on the charge slip, by using a personal
identification number similar to those for automated teller machines, and by
"what is known generically as 'signature on file,' " Riese said.
</P><P>
In the third case, which arises mostly in telephone transactions, the burden
is on the merchant to ascertain the cardholder's identity, though American
Express helps by providing an address-verification system that matches the
cardholder's address against the one to which merchandise is to be
sent.
</P><P>
In some cases signatures are being dropped for in-person transactions,
especially where signing a slip may be viewed as an impediment to a speedy
sale.
</P><P>
For example, Visa and Arby's, the roast beef chain, are experimenting with
putting fast food on plastic.  In an effort to keep the fast food fast, they
require no signature for purchases under $25.
</P><P>
The clerk merely "swipes" the customer's Visa card through a magnetic stripe
reader, which checks a "hot sheet" to see if the card is OK.  If it is, then
the customer is on his way.
</P><P>
The experiment promises to put fast food where mail order and other forms of
remote marketing have been for years.  The appeal to these marketers is
obvious.  Customers enjoy the convenience and merchants find they are able to
capture more impulse business -- sales that would be lost if the buyer had to
write out a check and mail it in.
</P><P>
While acknowledging the convenience, hover, many customers feel just a bit
nervous at this "loosey goosey" system, as Holstein termed it, of telephone and
other signatureless transactions.
</P><P>
But lawyers and others who follow the industry agree that it is the merchant
and the card issuer that bear the bulk of the risk.
</P><P>
Under the Truth in Lending Act, consumers are generally protected from losses
of more then $50 due to unauthorized use of their credit card.  And in
practice, said Holstein, the customer's chance of successfully disputing a
charge "is in fact enhanced when they don't have your signature."
</P><P>
The law specifically states that if a card issuer seeks to collect a disputed
charge, "the burden of proof is upon the card issuer to show that the use (of
the card) was authorized" by the cardholder, he added.
</P><P>
Visa's Brigham said that, if a cardholder swears in an affidavit that he did
not authorize a disputed transaction, "that's generally the end of
it."
</P><P>
This does not mean, however, that there is no risk for the cardholder.
 Nilson noted that fraud by "telemarketing" is increasing rapidly and that
these thieves prey particularly on those who are not aware of their rights or
who may for some reason be unwilling to assert them.
</P><P>
Many of these scams are aimed at merchants by crooks who collect card
numbers, run up a lot of charges and quickly skip before the cardholders begin
to complain.
</P><P>
But other are aimed at the cardholders themselves.
Nilson said purchasers of pornography offer a fertile field for such scams.
Some thieves even make deals with pornography sellers to buy the right to
collect their credit card accounts.  They then run up phony charges with the
numbers. Often, he said, cardholders pay up for fear that any dispute
would reveal what they had been involved with.
</P><P>
In other cases, cardholders may find the issuer willing to go to court with
even marginal cases if the amount involved is large enough.
In addition to being a payment system, credit cards are on their way to
becoming a national identity card system, as anyone who has tried to check in
to a hotel recently can attest.
Businesses that use credit cards as identification are "trying to confirm who
you are, that you're not a phony," Nilson said.  They regard the credit card
"as sort of a monitor.  If you don't have one it doesn't mean you're rejected
but it triggers something else," such as requirement for further
identification.  
</P>
<A NAME="subj4"><IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">Re: Danger of Sensitive Car Electronics</A></H3>
<ADDRESS>
&lt;<A HREF="mailto:&quot;hugh_davies.WGC1RX&quot;@Xerox.COM">
&quot;hugh_davies.WGC1RX&quot;@Xerox.COM</A>&gt;
</ADDRESS>
<I>19 Aug 88 06:52:54 PDT (Friday)</I>
<OL>
<LI>In the UK, there is a an area where two large motorways (freeways) converge
(the M1 and M6) near Rugby. This area also contains 2 large radio transmitting
stations - the BBC transmitter at Daventry and the Home Office transmitter at
Rugby (which transmits the MSF time standard, among other things). This area is
renowned for the failure rate of electronic engine management systems, which
upon the cars involved being towed from the area prove to be perfectly
functional. As a result, local car dealers have named the area 'the Black
Triangle'.</LI>

<LI>The radio literature is full of instances of interference with car control
systems by radio transmitters mounted in the vehicle. My last car would quite
happily sound its 'seat belt warning' upon every tranmission on certain
frequencies. I have also set off at least one shop (store) burglar alarm whilst
transmitting when outside the shop.</LI>
</OL>
<P>
The phenomenon of EMC problems (Electromagnetic Compatibility) is well known in
the radio, computer and communications industries. There is a large short-fall
in the numbers of EMC engineers available in the industry, and in the case of
the UK, there are no egress regulations anyway, which leads to a total lack of
interest among manufacturers of electronic equipment. The fact that poor egress
specifications also lead to poor ingress specifications also seems not to
bother the manufacturers of cars, computers, radios, TVs, VCRs, etc. The EEC,
through the CEPT, is about to enact an ingress specification, but it is to a
very low standard, mainly aimed at preventing interference by CB. The FCC
standard appears to be much better, and, by European standards, reasonably well
enforced.
</P><P>
Many digital electronics engineers are poorly trained in analogue electronics,
and may not realise the magnitude of the problem. It is quite possible for the
amounts of RF induced by proximity to radio transmitters to reach the Volt
level, at significant currents. There are well documented problems with systems
adjacent to multi-megawatt radio transmitters, such as those ecperienced in the
national stadium in Jeddah.  Most microcomputers are poorly, if at all screened
in this respect - they are usually housed in plastic enclosures. Whilst the car
is probably one of the most hostile environments known to engineers, it is
quite possible for it to become more hostile yet in the prescence of large
amounts of RF.
</P><ADDRESS>
Hugh Davies.
</ADDRESS>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.36.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.38.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-79</DOCNO>
<DOCOLDNO>IA012-000129-B048-261</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.38.html 128.240.150.127 19970217022637 text/html 25854
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:24:59 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 38</TITLE>
<LINK REL="Prev" HREF="/Risks/7.37.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.39.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 38</H1>
<H2>  Monday 22 August 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
British vs American safety rules 
</A>
<DD>
<A HREF="#subj1.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Another boundary case bug 
</A>
<DD>
<A HREF="#subj2.1">
Tom Lane
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Retired couple jolted by $5 million electric bill 
</A>
<DD>
<A HREF="#subj3.1">
David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Hotel could get soaked in lawsuit? 
</A>
<DD>
<A HREF="#subj4.1">
Don Chiasson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  RISKS contributions 
</A>
<DD>
<A HREF="#subj5.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Risks of CAD programs 
</A>
<DD>
<A HREF="#subj6.1">
Alan Kaminsky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Can current CAD/simulation methods handle long-term fatigue analysis?    
</A>
<DD>
<A HREF="#subj7.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Vincennes and Cascaded Inference 
</A>
<DD>
<A HREF="#subj8.1">
Carl Feehrer
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
British vs American safety rules
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 19 Aug 88 23:51:36 EDT
</i><PRE>

&gt; ... He added that he thought British law and tradition were more
&gt; protective of people and sensitive to safety concerns than in the USA.  For
&gt; example, MOD regulations explicitly prohibit any cost saving that might
&gt; increase hazard to life -- you are not allowed to trade lives off against
&gt; money.

Britons should not consider this reassuring; it is, in fact, alarming.
This rule was obviously written by a politician (possibly not an elected
one or a recognized one, mind you...), not by an experienced engineer.
It is *always* necessary to trade lives off against money, because there
is no limit to the money that can be spent adding more 9's on the end of
99.9999% reliability.  What this rule is doing is guaranteeing that the
risks and tradeoffs will not be discussed openly!

Consider what is likely to happen.  Manufacturers, under pressure to keep
costs under control, will quietly and privately evaluate the tradeoffs.
Since they are forbidden to introduce changes that increase hazards, yet
may need to make changes as the customer (the government) shifts its
priorities around, the obvious thing to do is to start out with the
cheapest and *most hazardous* version.  If this can be gotten past the
inspectors somehow -- nobody should be surprised if manufacturers are
less than completely open about hazard analyses! -- then with luck, all
further changes that affect safety can be in the direction of improved
safety.  At higher cost, of course.  Assuming that it can be funded in
that year's budget, of course.

Is this rule really serving its intended purpose?

Henry Spencer @ U of Toronto Zoology  

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Another boundary case bug
</A>
</H3>
<address>
&lt;<A HREF="mailto:Tom.Lane@ZOG.CS.CMU.EDU">
Tom.Lane@ZOG.CS.CMU.EDU
</A>&gt;
</address>
<i>
Sun, 21 Aug 88 16:19:35 EDT
</i><PRE>

Just in case you thought this kind of thing no longer happens in 1988...

The Pittsburgh city water authority just switched over to a new billing
system.  My first new-format bill reads as follows:

	Previous reading: 988  (thousand gallons)
	Current reading:    2
	Amount used:        0

Sure enough, all customers whose meters "wrapped around" during the past
quarter received minimum bills.  "We didn't catch it until after the first
batch of bills went out," according to the customer assistance person I
spoke to.  Those customers who don't call in to ask about it will not be
billed for the difference until next quarter; the difference in my case was
only about $20, but I suspect that the authority may lose a good bit in
interest overall.

I find it interesting that the bill wasn't for -986K gallons.  Perhaps the
programmer actually thought about the case current reading &lt; old reading,
and concluded it would always represent a reading error; or maybe it's just
a byproduct of some data format declaration.
                              				tom lane

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Retired couple jolted by $5 million electric bill
</A>
</H3>
<address>
attcan!lsuc!dave@uunet.UU.NET     
&lt;<A HREF="mailto:David Sherman">
David Sherman
</A>&gt;
</address>
<i>
Sat, 20 Aug 88 00:00:07 EDT
</i><PRE>

TAMPA (AP) - A retired couple got a jolt from their July electric bill --
$5,062,599.57 U.S.  An offer by Tampa Electric Co. for them to pay "budget"
monthly instalments of $62,582.27 didn't help.  Company officials apologized
to Jim and Winnie Schoelkopf after the mistake was blamed on a computer
operator.  The correct bill was for $146.76.  
[from the Toronto Star, 29 July 1988]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Hotel could get soaked in lawsuit?
</A>
</H3>
<address>
 Don Chiasson 
&lt;<A HREF="mailto:G.CHIASSON@DREA-XX.ARPA">
G.CHIASSON@DREA-XX.ARPA
</A>&gt;
</address>
<i>
Mon, 22 Aug 88 14:03:27 ADT
</i><PRE>

                 Faulty Bath Shower Blamed for Air Crash
                 From Canadian Aviation, Aug 88, p. 8

  A U.S. pilot has sued the Marriott hotel chain for $7 million, claiming
  that he was struck in the head by a faulty shower head, causing a flashback
  nine months later that led to the crash of his helicopter.  Joseph Mendes
  claims that Marriott was negligent because he was injured when struck by a
  pulsating shower head that came loose and fell on him in 1987 when he was
  staying at the Marriott hotel in Lexington, KY.  Mendes says that he "has
  suffered a psychic [sic] trauma known as and referred to as post-traumatic
  stress disorder which is continuing in nature."  His suit alleges that "as a
  direct and proximate result" of the alleged disorder, Mendes suffered a
  flashback while piloting a helicopter last March, "thereby losing control of
  the helicopter and causing it to crash to the ground."

What has this got to do with computers?  Without knowing more about the
incident, I have some difficulty in seeing a *falling* shower head as being a
"direct and proximate" cause.  If businesses and individuals must defend
themselves from suits such as this they will have to keep detailed records of
any incident that happens to a customer or visitor.  Did the incident happen
how, when and where he claims, and if so did he report it promptly?  Such
records are most likely to be kept on computers.  What are the implications for
privacy?

  [The usual privacy problems exist.  More significantly, the trustworthiness
  of computer evidence is always in doubt.  It is too easy to fudge the data
  subsequently, even in the presence of time-stamps, cryptoseals, etc.  (The 
  most serious problem is probably the increase in frivilous lawsuits.) PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
RISKS contributions [I try to sun-dry sundry messages...]
</A>
</H3>
<address>
Peter G. Neumann 
&lt;<A HREF="mailto:Neumann@KL.SRI.COM">
Neumann@KL.SRI.COM
</A>&gt;
</address>
<i>
Mon, 22 Aug 88 14:28:45 PDT
</i><PRE>

The backlog of contributions is enormous, but the topics and subject material
are really rather marginal.  There are at least 15 messages on VDTs (eyes,
backs, eyesight changes, etc.), and scads on the use of signatures, credit
cards, vending machines, and on into the night.  Much of it has drifted widely
from computer relevance, coherence, nonrepetitiousness, etc., and so I am
inclined to suggest we all take a rest for a while until some more exciting
material materializes.  I get more hate mail when I let marginal stuff through
than when I don't, so perhaps I'll try to keep the standards up.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Risks of CAD programs
</A>
</H3>
<address>
&lt;<A HREF="mailto:ark%hoder@CS.RIT.EDU">
ark%hoder@CS.RIT.EDU
</A>&gt;
</address>
<i>
Mon, 22 Aug 88 10:12:09 EDT
</i><PRE>

My father has worked as a civil engineer for forty years.  Recently I had
a conversation with him on how civil engineering design methods have changed
since when he started, especially with the recent widespread use of CAD
programs.  This made me think of a RISK in using such programs.

He described his latest design project.  A vacuum vessel had a large circular
opening that was covered with a flat plate.  The plate needed to have
several irregular holes at odd positions, for mounting pieces of equipment.
Since one side of the plate was under vacuum, the plate bulged inwards,
destroying the alignment between the mounted pieces of equipment.  His task
was to design a set of stiffening braces to control the bulge.

In the "old days," he said, a plate with stiffening braces and irregularly-
placed holes would be impossible to analyze.  It would have been easy to
determine the amount of bulge for a plate with braces but _without_ holes,
or with, say, one circular hole in the plate's center.  In fact, he could
look up the solution in any standard textbook.  The holes would increase the
bulge, but to an unknown extent.  He would have made a guess at the amount,
thrown in a generous safety factor, and designed the braces accordingly.

Nowadays, he uses a computer program (NASTRAN) to do finite-element analysis.
He built a model of his plate, holes and all, ran the machine for x minutes,
and found out exactly where and how much the plate would bulge for a given
vacuum level.  He then knew just how much stiffening would be needed.

Now for the RISK.  With a detailed picture of the exact stresses and
deflections on a particular structural member, the engineer can justify
designing with a smaller safety margin.  No longer are large safety factors
needed to compensate for the inability to do exact analysis.  Instead, one
can design with a smaller margin and reduce the cost (fewer or smaller
braces are needed).

Do practicing civil engineers reduce their safety margins these days because
they use computer-aided analysis?  How much?  How small a safety margin is
small enough?  How well-validated are the structural analysis programs in
common use?  Do they always give accurate answers?  Do engineers include in
their safety margins any consideration of inaccuracies or bugs in their
programs ("I'd better add x% in case my program's results are off")?  I'd
appreciate hearing from anyone who knows.

Alan Kaminsky, School of Computer Science, Rochester Institute of Technology

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Can current CAD/simulation methods handle long-term fatigue analysis?
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 17 Aug 88 23:23:56 EDT
</i><PRE>

&gt;...  Are current supercomputer simulation methods capable of
&gt;handling the complexity of long-term stess, fatigue, corrosive environments,
&gt;etc., all of which were (apparently) factors in the Aloha incident?  Also I am
&gt;not at all sure that such things were handled any better before wide-spread use
&gt;of CAD -- I am just asking the question.  Any aeronautical engineers out there?

Well, I'm not an aeronautical engineer, but maybe I'll do... :-)  As I
understand it, metal fatigue in general is poorly understood, and there
is really no way of calculating it.  The whole area is still very much
rule-of-thumb engineering plus empirical testing.  There are rules that
give a rough idea of the fatigue life of an airframe, after which a big
safety margin is added (we're talking factor of 2, not 10%).  Even this
is only a tentative number.  Most any large, volume-production aircraft
will have one of the early prototypes shunted off into a corner to be the
"fatigue test" specimen, which means that it spends years (literally)
having its wings bent back and forth and pressurization cycled up and down
and generally having stresses applied in a speeded-up, exaggerated simulation
of real service life.  The objective is to keep the fatigue-test aircraft
well ahead of all the real ones, while watching it carefully for signs
of fatigue cracks.

Even so, one still gets surprises.  Not just the occasional accidents, but
also more mundane discoveries of cracks; fatigue-life estimates are not
trusted very much, and aircraft are inspected regularly.  Now and then
such an inspection yields a surprise, and the manufacturer or the FAA sends
the other users of that aircraft a telegram saying "inspect area XXX right
away and let us know if you find cracks".  This seldom makes the news, but
it happens with some frequency.

I guess this is not a bad example of how to manage a poorly-known risk...

				Henry Spencer @ U of Toronto Zoology
				uunet!attcan!utzoo!henry henry@zoo.toronto.edu

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Vincennes and Cascaded Inference
</A>
</H3>
<address>
&lt;<A HREF="mailto:CFEEHRER@G.BBN.COM">
CFEEHRER@G.BBN.COM
</A>&gt;
</address>
<i>
16 Aug 1988 07:32-EDT
</i><PRE>

Thank you for the comments and interest in the cascaded inference notion.  As a
newcomer to the Comp.Risks forum, I judged that the Bayesian approach to
decision making, if not cascaded inference, per se, had probably been kicked
around before, and I didn't quite know quite where to start.  I'll try here to
be a little more crisp in my arguments and provide some references to the
general area.  When I have something better than this 300 baud connection,
maybe I can push on!

        First ...  to get some of the fuzz out of the earlier arguments!:
(Please note that I am indebted to Clifford Johnson -- 11 Aug -- for forcing me
to make some of the assumptions clearer.)

        (1) Although the Vincennes affair provides fertile ground for the
imagination, little enough is available in the common media, my only source, to
get any kind of closure on the validity or truth of assertions.  After Seymour
Hirsch writes a book, I'll feel more comfortable with any position I take! I'm
drawn to the case only because I think it is altogether likely -- and I think
newspaper reports bear it out so far -- that not all of the information that
could have been brought to bear on the decision was used, and some of the
information that was used was "noisy" in ways that could have misled decision
makers if they didn't have means for coping with it.Those characteristics can
be identified in almost any post-analysis of a complex decision situation,
whether things went well or badly, and I take it on faith that they can be
found here.  To observe them again would be almost trivial if it were not for
the fact that their ubiquity argues, at least to me, that we had better soon
figure out how to mitigate their impact.

        (2) I DO NOT want to argue that crucial decisions should be automated,
except where human and/or system response times are so long that non-automated
decisions are impractical.  I DO want to argue that decision makers should be
taught how to make the best use of all of the information they have and then be
provided with the best computerized aids to diagnosis and inference that we can
devise.  I think we put individual decision makers, whole systems, and maybe
the entire world at risk if we do otherwise.

        (3) We need to keep in mind that "hit" and "false alarm" rates are
inextricably associated.  If one MUST avoid a Stark, then one will occasionally
have a Vincennes.  There is no level of system perfection that can, in
principle, destroy that association.  Ironically, it may be that, unless we are
very careful in their design, the more complex our systems are made to be in
the interest of greater accuracy, the more false alarms may ocur and need to be
dealt with.

        (4) I have little interest in defending Bayes Theorem or, for that
matter, any particular method of statistical inference (e.g., Neyman-Pearson
methods).  We know pretty well the limitations of probabilitic statements in
the context of low frequency events.  (Or even high frequency events, for that
matter: "So the probability of rain is .6! Do I take the umbrella or not?!")
And I certainly don't want to suggest that military commanders and CEOs and
surgeons should sit around with calculators and compute posterior odds,
F-ratios,ts, etc.  If it makes any sense to do that, it should be done
automatically as part of a computer-based decision support system!

I DO want to suggest that the Bayesian model, and to a lesser extent, classical
N/P models, have been extremely useful in highlighting the fact that human
decision makers do not typically extract from data, whatever their quality, as
much information as is justified.  On some occasions, that "shortcoming"
results in the need for more data to be acquired and processed, thus incurring
additional costs in resources and time.  On other occasions, particularly if
time is critical, it can result in the choice of an incorrect hypothesis.

Now, there are two questions concerning that finding: Why?, and What can be
done about it?  I'd like to contribute some stuff on those questions and get
your reactions, but it's a big topic and a digression at this point.  If
anybody is interested, HOLLER!

        (5) I agree thoroughly with CJ that there is a welter of data and no
"unequivocal attack warnings" (until a hostile action has been taken) -- that's
precisely why it's an interesting problem.A few years ago, several colleagues
and I were studying (with their cooperation) the decisions of nuclear power
plant operators who were on duty at times during which plant instabilities
occurred and who, for considerable periods, were in doubt about what had gone
wrong and what the current states of their plants were.  Two of these
instabilities had resulted in radioactive releases.  If you've been in a plant
when things start to go bad, you know something about the enormity of data that
suddenly comes your way, the confusion and tension it can produce, and how
critical it can be that things get figured out quickly and correctly ...  you
don't simply "turn it off" and fix it later! I think the operators on Vincennes
must have endured a very similar situation.

        (6) I can also agree that (a) Captain's role (could) be reduced to
"second-guessing" the computer, although I know too little about SOPs in this
case to have much confidence in that judgment.  (If the system is built that
way and the SOP reads that way, serious mistakes have been made.  Similar
problems have arisen in the design of advanced tactical and commercial aircraft
and have become real concerns.)  I disagree that there is a moral issue in
second-guessing so long as there is total uncertainty and a guess is truly
called for.  I believe that there are moral issues in this whole thing but that
they lie elsewhere.

        (7) I still have difficulty, in principle, with the argument that there
cannot be (should not be?)  decision thresholds (or decision criteria, if you
will).  Ultimately, there must be the decision to shoot or not to shoot, to buy
or to sell, to cut or not to cut, to render a guilty or a not-guilty verdict,
etc.  In any of these situations, of course, one can almost always defer action
in the hope that more information may become available and clarify the issue.
But that choice is usually not without cost and, eventually, a course of action
must be taken that is based on what can be inferred.  A criterion for that
decision MUST be defined.  For me, it is not the concept of "threshold", per
se, but our inabiliity to help the decision maker understand whether or not
it's been reached and/or whether it CAN be reached given the validity, and
reliability of the available data that presents the problem.

There are some interesting data on the ordering of radiological tests that bear
on the this last point.  Namely, it can be shown that, in order to be
"perfectly sure", some physicians may order tests to be performed that could
not, under the very most favorable circumstances, produce increments in
confidence great enough to affirm or disaffirm their preliminary diagnosis.  A
reason seems to be that many are untrained in the utilization of the "yield"
statistic -- a quantitative estimate of false positive and false alarm rates
based on experience and generally available for standard diagnostic tests.  For
this knowledge may be substituted a naive belief that if enough tests are
performed, the truth will out (before the patient packs it in!).

        (8) Here are some initial references on the cascaded
inference stuff.  Some may be hard to find, so I'll provide some
Xeroxed pages from the last reference if you drop me a SASE.  The
pages summarize some of the arguments in the references:

The earliest paper I'm aware of that sets the stage for a prescriptive
approach: Dodson, J.D.  Simulation system design for a TEAS simulation research
facility.  Report AFCRL 1112 and Planning Research Corporation, LA, Nov.  15,
1961.

A very concise/well-written statement of a Bayesian prescriptive approach (my
favorite!): Schum, D.A. and DuCharme, W.M.  Comments on the relationship
between the impact and the reliabiliity of evidence.  Org.  Behav.  and Human
Perf., 1971, 6, 111-131.

Examples of attempts to provide empirical models of what untrained DMs actually
do:  Snapper, K.J.  and Fryback, D.G.  Inference based on unreliable reports.
J.  exp.  Psychol., 1971, 87, 401-404.

Gettys, C.F., Kelly, C.W., and Petersen, C.R.  Best guess hypothesis in
multi-stage inference.  Org.  Behav.  and Human Perf., 1973, 10, 364-373.

Funaro, J.F.  An empirical analysis of five descriptive models for cascaded
inference.  Rice Univ., Dept.  of Psychology Research Report Series, Report No.
74-2, May 1974.

A different approach, inspired by Bayesian thinking but developed within the
signal detection framework and applied to medical diagnosis (references in here
are also useful) -- Swets, J.A.  and Pickett, R.M.  Evaluation of Diagnostic
Systems: Methods from Signal Detection Theory.  New York: Academic Press, 1982.

Nickerson, R.S.  and Feehrer, C.E.  Decision Making and Training: A Review of
Theoretical and Empirical Studies of Decision Making and Their Implications for
the Training of Decision Makers.  Tech.  Rept.  No.  NAVTRAEQUIPCEN
73-C-0128-1, August, 1975.

        That's a start.  Maybe I can sort through the many others and make
recommendations if we really get into this area.  Some are fascinating!
                                                                         --Carl

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.37.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.39.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-80</DOCNO>
<DOCOLDNO>IA012-000129-B048-288</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.39.html 128.240.150.127 19970217022652 text/html 22557
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:25:19 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 39</TITLE>
<LINK REL="Prev" HREF="/Risks/7.38.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.40.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 39</H1>
<H2>  Wednesday 24 August 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Computers and Gambling 
</A>
<DD>
<A HREF="#subj1.1">
George Michaelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Car engines become target for hackers 
</A>
<DD>
<A HREF="#subj2.1">
George Michaelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Vincennes and Non-Computer Verification 
</A>
<DD>
<A HREF="#subj3.1">
David Collier-Brown
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Shades of War Games 
</A>
<DD>
<A HREF="#subj4.1">
Doug Mosher
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Emissions testing risk 
</A>
<DD>
<A HREF="#subj5.1">
Levy
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: British vs. American safety rules 
</A>
<DD>
<A HREF="#subj6.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Re: Structural analysis programs 
</A>
<DD>
<A HREF="#subj7.1">
Stephen D. Crocker
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Danger of Sensitive Car Electronics 
</A>
<DD>
<A HREF="#subj8.1">
Will Martin
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Computers and Gambling
</A>
</H3>
<address>
George Michaelson 
&lt;<A HREF="mailto:munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET">
munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 24 Aug 88 13:22:23 +1000
</i><PRE>

  "GAME BANDITS FOIL POLICE" (`Australian' computers section, 23 August 1988)

Victorian &amp; N.S.W Police are noting an increased use of "bent"
one-arm-bandits used to finance drug &amp; other big-money crime.
The head of the racing and gaming squad reported machines that:

 "..appear to run legitimate amusement games but with the flick 
 of a switch they are converted to gambling machines.

 Machines of greater sophistication are now starting to appear
 with a second switch that totally erases the computer program
 [sic] which runs the illegal games.

 If that happens we are powerless to prosecute."

George Michaelson
CSIRO Division of Information Technology 55 Barry St, Carlton, Vic 3053 Oz

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Car engines become target for hackers
</A>
</H3>
<address>
George Michaelson 
&lt;<A HREF="mailto:munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET">
munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 24 Aug 88 13:34:54 +1000
</i><PRE>

Extracts from the australian  of 23/8/88:

Computer hackers have found a way to make cars go faster.  They are breaking
into tiny engine management computers and reprogramming them to give family
cars extra acceleration.

One large motor company is about to fit a secret detector "to foil hackers and
safeguard used car buyers from being duped".

Computer tweaking can seriously damage a turbocharged engine, particularly if
it is driven on "full boost:  over a long stretch of road; and there are
"growing signs of fraudulent warranty claims" an industry official says.

It costs about $800 to have the engine computer tweaked by specialist
hacking-tuning companies.  There are alternative go-faster computer chips ready
to be installed while you wait.  Customers include owners of every
computer-controlled car in the book.  Computer buffs can do themselves for
about $20.

Motor companies are now planning to guard themselves against warranty claims
that might arise through unauthorised computer up-rating resulting in engine
failure.  The new electronic detector will record a cars computer instructions
when the vehicle is brought in for breakdowns to be repaired under warranty.
False instructions will be detected and the owner told the change has
invalidated the guarantee.

Insurers say the unauthorised modifications will invalidate the insurance
policy.
      
George Michaelson, CSIRO Division of Information Technology

     [Early issues of risks have addressed this problem in the USA.  For
     example, <A HREF="/Risks/4.12.html">RISKS-4.12</A> noted the reprogramming of an 1984 Firebird.  PGN]

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Vincennes and Non-Computer Verification [CFeehrer <A HREF="/Risks/7.38.html">RISKS-7.38</A> (and 33)]
</A>
</H3>
<address>
David Collier-Brown
&lt;<A HREF="mailto:daveb@geac ">
daveb@geac 
</A>&gt;
</address>
<i>
Wed, 24 Aug 88 10:12:23 EDT
</i><PRE>

  One point that I did not see in the discussion to date (which CFeehrer
inadvertently reminded me of), was the peculiar position of the Captain of the
Vincennes:  He had no independent means of verifying the correctness of the
information his battle-management system was using.
  He was faced with making a decision with doubtfull information,
information which did not become "better" over time, and before a
certain time, after which it would be too late to defend himself
against an aircraft and he would have the greater risk of defending
himself against a missle.
  Not a good situation to be in.

  Yet it is a perfectly "ordinary" consideration in war to try to
verify the poor, incomplete and fragmented information which a
commander has to deal with.  If your air force says an enemy column
is near, you send out a scouting force to verify that this really is
th enemy you're worried about (and to slow it down if it is).  If
your radar says a bear bomber is approaching the coast of Labrador,
you send out aircraft to have a look, and hopefully send the bear on
its way.
  In the case of the Vincennes, where was the air patrols which
should have accompanied any major combat vessel?  Where was the
captain's eyes and first line of defense against air attack?
  Even in peacekeeping operations, one tries to have sufficient
support arms nearby and available on a moment's notice (SOS tasks if
they're artillery, combat air patrols if they're air force, etc.)

  Indeed, **what happened** in the case of the Vincennes?  Was the
U.S.operating naval patrols in a war zone without air support?  If
so, why?

  What kind of faith are we placing in electronics if we send major
vessels out "alone" into war zones, even on non-warlike missions,
without providing them with mobile forces to identify and hopefully
deal with air attacks, and nearby support forces for backup?

David Collier-Brown, 78 Hillcrest Ave, Willowdale, Ontario
{yunexus,utgpu}!geac!lethe!dave

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Shades of War Games (Source passwords)
</A>
</H3>
<address>
&lt;<A HREF="mailto:SPGDCM%UCBCMSA.Berkeley.EDU@jade.Berkeley.EDU">
SPGDCM%UCBCMSA.Berkeley.EDU@jade.Berkeley.EDU
</A>&gt;
</address>
<i>
Tue, 23 Aug 88 16:45:27 PDT
</i><PRE>
Really-From: Doug Mosher

I just received a mailed promotional piece from The Source, a well-known info
network. It included an application form.

To my astonishment, it included a blank for "Mother's Maiden Name (for
verification of ID or Password if lost):_______________________________".

Good Heavens! This implies that a publically obtainable, permanent fact about
me could be used to obtain my password, or equivalently, that this factoid IS
in effect my password regardless of what I select. Need I say more?

      [Surprised?  PGN]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Emissions testing risk
</A>
</H3>
<address>
&lt;<A HREF="mailto:att!ttrdc!levy@ucbvax.Berkeley.EDU">
att!ttrdc!levy@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Tue, 23 Aug 88 00:16:20 PDT
</i><PRE>

In the Chicago area, for the last two years, there has been a program of auto
emissions testing, administered by the IEPA (Illinois Environmental Protection
Agency).  Auto, truck, and van owners here are required by law, upon mailed
notice, to bring their vehicles annually to special testing stations.  At a
testing station, an attendant puts a sensor probe in a vehicle's tailpipe; the
driver idles the engine at low and high speeds, and the machinery checks the
pollutant emissions.  When the test is finished, the attendant keys in the
car's vehicle identification number (read from a pre-test windshield sticker
that is peeled off) and the results are recorded in an IEPA computer database.

If a notified vehicle owner neglects to have the vehicle tested (or fails three
tests in a month and does not qualify for a waiver by having certain required
service done on the vehicle) the owner will be sent a series of followup
notices over several weeks.  If these are not heeded, the vehicle owner's
driver's license is suspended and this fact recorded in a police data base.
The owner becomes liable to arrest should he or she drive while the license is
suspended and be ticketed or stopped for even a minor traffic offense.

Personally, I believe in emissions control and emissions testing (how could I
say otherwise after the stand I recently took in rec.autos? :-) but, of course,
the computerization of the system is liable to the usual snafus we all know and
love to hate.  As printed in the Sunday, August 21 Chicago Tribune headline
article, "100,000 drivers risk jail under clean-air law" (almost all of these
are because of genuine negligence to obey the law, rather than computer
foulups, but this is still pertinent to RISKS):

  ... Joel Aaseby of Elmhurst ... was issued a traffic ticket following a
  minor accident in Elmhurst.  "They ran my name through the police computer,
  and there was the notice of my suspended license," Aaseby said.  "... I had
  to go down to the station under arrest and fill out a bond card."

  What made Aaseby's experience upsetting for him was that he had passed the
  auto emissions test, but in the process one of the testing clerks punched the
  wrong vehicle identification number into the computer.  Aaseby got several
  more notices that he had failed the tests and that his license was about to
  be suspended.  "Numerous times I mailed them [the secretary of state's
  office] all the documentation that I had passed, but never heard back until I
  was arrested," he said.

  "Now I have a court date, and I will take my documentation to court and I'm
  confident the judge will understand, but do you have any idea how much
  aggravation I have gone through, especially since the news- paper listings of
  arrests has my name on the top of the list this week for driving with a
  suspended license?" he said.

  "We have heard these kinds of stories," [Cinda Schien, Illinois EPA
  spokeswoman] said.  "But hopefully we have got [sic] rid of these problems.
  We think we are fortunate we haven't had more.  "Remember, we are dealing
  with 2.5 million cars and numerous mailings for each one.  We basically had
  to invent the wheel for the first couple of years," she said.

What bothers me the most about this is not the foul-ups themselves (there are
almost bound to be problems in any massive endeavor of this sort) but rather
the apparent refusal of the people administering this system (and the
associated law enforcement system) to take full responsibility for foulups when
they do happen, and their apparent propensity to believe they're not really
happening.  Why else, for example, would Schien have spoken of "hav[ing] heard
these kind of stories" instead of something like "being aware of occurrences
like this"?  Do I smell some bureaucratic CYA here?

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: British vs. American safety rules
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Tue, 23 Aug 88 10:02:20 PDT
</i><PRE>

&gt;&gt; (I reported) (British Ministry of Defense) regulations explicitly
&gt;&gt; prohibit any cost saving that might increase hazard to life -- you
&gt;&gt; are not allowed to trade lives off against money
&gt;
&gt; (Henry Spencer replied) Britons should not consider this reassuring;
&gt; it is, in fact, alarming.  This rule was obviously written by a politician
&gt; ... not by an experienced engineer

Cullyer said that he himself had a hand in drafting some of these MOD regs,
although he didn't go into detail about who wrote what at the level of chapter
and verse.  Whoever was responsible, Cullyer was clearly approving of this
particular requirement.  He is certainly an "experienced engineer" - - and
evidently a good one; several people at the conference (including our
moderator, Peter Neumann) said the VIPER work appeared to be the greatest
practical achievement yet made in the formal verification field.

&gt; (Henry asks) is this rule really serving the intended purpose?

I should emphasize that Cullyer was not reading verbatim from the rulebook -
this was his verbal paraphrase of the intent of the regulations.  The point
Henry makes - that you can ALWAYS propose some change that appears to increase
the safety but also increases the cost - does require a response.  I can only
say that Cullyer and his group appeared sharp enough so that I assume this was
dealt with in some reasonable way.  I gathered from the context of what he was
saying that the intent of the rules was that shortcuts should not be taken 
to meet schedules or budgets if these resulted in violations of accepted 
standards and practices - and that these standards should be kept high.

&gt; What this rule is doing is guaranteeing that the risks and tradeoffs
&gt; will not be discussed openly!

In fact Cullyer, who is an employee if the British MOD, gave a franker 
description at a public meeting of software problems within his organization 
than I have ever heard in public from any employee of the United States 
Department of Defense (or any other public or private organization, for that
matter).  I am not aware of any United States studies like 
the NATO software study, in which samples of software from the field were 
systematically examined for latent faults, prior to any accidents - and 
then the results were reported at a meeting in a foreign country.  I 
emphasize that Cullyer's presentation did not have the connotations of
aggrieved victimization usually associated with "whistleblowing" in this
country - rather the RSRE group and the MOD administration were engaged in
a constructive effort to be as thorough as possible.

&gt; (Henry suggests we) consider what is likely to happen.  ...  Manufacturers
&gt; will privately evaluate the tradeoffs - the obvious thing to is to start out
&gt; with the cheapest and *most hazardous* version.

I understood Cullyer's larger point about the difference between the two
countries to be that the climate in Britain is such that the pressures
encouraging this kind of adversarial legalistic maneuvering are somewhat less
than in the US.  I would add my personal observation that if Cullyer is any
example, British civil servants are afforded higher status and respect than
many of their counterparts in the United States, therefore manufacturers
realize that the reviewers who evaluate their products may be at least as smart
as they are, and will recognize ploys such as the one Henry describes.

I think Cullyer's point regarding the regulations was that it is possible to do
a better job at designing safe computer-controlled equipment than is now common
practice.  It need not even be all that much more expensive, but people do not
do it because they do not know how, or are unwilling to expend any additional
effort.  He noted that it took a certain amount of goading from people in
authority to make the point that safety should be an important design goal, and
that a good way to do that was to announce that products found wanting will be
rejected.

I also understood Cullyer to mean that when designing things like fly-by-wire
aircraft, nuclear weapons fuses, and nuclear power plants, it was necessary
that a degree of goodwill and cooperation exist among all parties, and that
excessive attention to cost-cutting would just get everyone into big trouble;
if the budgetary pressures are all that pressing, the project should perhaps
not be undertaken.

&gt; It is *always* necessary to trade lives off against money, because there
&gt; is no limit to the money that can be spent adding 9's to the end of
&gt; 99.9999% reliability

Interestingly, another of Cullyer's points was that statistical reliability
estimates with lots of 9's in them were not meaningful, and he did take
personal credit for writing the MOD regulations that say that such claims will
not be regarded seriously! Actually several speakers at COMPASS made this
point.  It is discussed at some length in the report that will appear in the
October 88 ACM SOFTWARE ENGINEERING NOTES, and I will post an excerpt to RISKS.

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Re: Structural analysis programs (<A HREF="/Risks/7.38.html">RISKS-7.38</A>)
</A>
</H3>
<address>
Stephen D. Crocker
&lt;<A HREF="mailto:crocker@tis-w.arpa ">
crocker@tis-w.arpa 
</A>&gt;
</address>
<i>
Mon, 22 Aug 88 17:57:51 PDT
</i><PRE>

Alan Kaminsky suggests detailed structural analysis programs, e.g. NASTRAN,
are making it possible for engineers to justify smaller safety margins, and
he asks in various ways if this represents a RISK.

This reminded me that current practice for design and implemention of
software  has a complementary RISK.  It is quite common for computer
system designers to select hardware that has more memory and speed than
they think they're going to need.  "Safety factors" of two to four are
often considered reasonable if they don't increase the cost too much.
However, this safety margin usually has far less basis than a NASTRAN
analysis, and the results are often expensive.  Sometimes the slack is
consumed during implementation when it's discovered that the program just
doesn't run as fast as it was expected to, and sometimes the slack is consumed
during operation.  It is not uncommon for simple "data overrun" conditions to
lead to software crashes because the programmer never expected the input to
exceed the computer's speed.

The state of the art would be in far better shape if we had tools as
useful as NASTRAN for sizing computer systems.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Danger of Sensitive Car Electronics
</A>
</H3>
<address>
Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Mon, 22 Aug 88 16:13:59 CDT
</i><PRE>

Interesting that this topic should be brought up just now. I just received
in the mail a catalog on "Electrical Noise and Interference Control Courses,
Publications, &amp; Services" from Interference Control Technologies (Star Route
625, PO Box D, Gainesville, VA, 22065 (703)347-0030), which has on its cover
a rather strange painting of a car going through a guardrail and over a cliff
as the result of a radio transmitter radiating above a mountain tunnel
opening. I say "strange" because the angle of the car and the tire tracks
look unnatural, but then I'm no traffic-accident specialist.

Anyway, those interested in this topic may want to write for this catalog
(it is the "September-February" issue) -- the company holds seminars and
puts out books and symposium proceedings on the topic of EMC and EMI.

There's also a free controlled-circulation magazine on the subject; write
to EMC Technology, Circulation Dept, PO Box D, Gainesville, VA 22065
Note the similarity to the above address -- I guess they are all part of
the same organization.

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.38.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.40.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-81</DOCNO>
<DOCOLDNO>IA012-000129-B048-311</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.40.html 128.240.150.127 19970217022707 text/html 28062
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:25:34 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 40</TITLE>
<LINK REL="Prev" HREF="/Risks/7.39.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.41.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.39.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.41.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 40</H1>
<H2>  Thursday 25 August 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Car engines become target for hackers 
</A>
<DD>
<A HREF="#subj1.1">
Jerome H. Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: IL car emissions testing process and enforcement errors 
</A>
<DD>
<A HREF="#subj2.1">
Will Martin
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Danger of Sensitive Car Electronics 
</A>
<DD>
<A HREF="#subj3.1">
Henry Schaffer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Automobile computer modifications 
</A>
<DD>
<A HREF="#subj4.1">
George Tomasevich
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Statistical reliability estimation criticized 
</A>
<DD>
<A HREF="#subj5.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Can current CAD/simulation methods handle long-term fatigue analysis?    
</A>
<DD>
<A HREF="#subj6.1">
Gerry Kokodyniak
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Boundary Cases 
</A>
<DD>
<A HREF="#subj7.1">
James Peterson
</A><br>
<A HREF="#subj7.2">
 John Bruner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Mother's maiden name == arbitrary password 
</A>
<DD>
<A HREF="#subj8.1">
Walter Smith
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Risks of EFT agreements 
</A>
<DD>
<A HREF="#subj9.1">
Doug Claar
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Chile con backbones 
</A>
<DD>
<A HREF="#subj10.1">
Joe McMahon via Martin Minow from VIRUS-L
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  An item by Mark Garvin on SoftGuard and the Trojan horse "SUG" 
</A>
<DD>
<A HREF="#subj11.1">
from VIRUS-L
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Car engines become target for hackers  (<A HREF="/Risks/7.39.html">RISKS-7.39</A>)
</A>
</H3>
<address>
Jerome H. Saltzer 
&lt;<A HREF="mailto:Saltzer@ATHENA.MIT.EDU">
Saltzer@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Wed, 24 Aug 88 18:23:33 EDT
</i><PRE>

&gt; False instructions will be detected and the owner told the change has
&gt; invalidated the guarantee.

That approach has an interesting implication.  It seems to mean that in order
to do a new microcode release the manufacturer will have to make sure that
every service agency gets that release before any cars using the new release
roll off the production line.  In the past, delay in getting the latest update
to a service agency would simply mean that the service agency didn't have
enough information to do certain kinds of service on your new car.  Now, it may
mean that they will challenge your warranty.  I wonder if the high-level
executives who thought up that idea have checked it through with the people who
do microcode releases.
                        			Jerry

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Re: IL car emissions testing process and enforcement errors
</A>
</H3>
<address>
    Will Martin -- AMXAL-RI 
&lt;<A HREF="mailto:wmartin@ALMSA-1.ARPA">
wmartin@ALMSA-1.ARPA
</A>&gt;
</address>
<i>
Thu, 25 Aug 88 9:52:38 CDT
</i><PRE>

When I first heard of this, it did seem a poorly-designed system. It relates a
variable which could be greater than 1, the number of cars a person may own,
with a single item -- the owner's driver's license.  Suppose you own three
cars. One of them fails the test, and you may decide to stop driving that one
for a while before getting it fixed.  Meanwhile, you drive the other(s), which
passed the test. The law would STILL suspend your driver's license due to that
one car's failure. How do they handle cars being restored or otherwise in a
perpetual state of disrepair, anyway? The emissions-test failure should be
related to the specific vehicle, not to the owner. (What about cars that are
owned by corporations or otherwise not tied to an individual, also?)

Again, there is an obvious way around this. The registered owners of private
cars in IL should be non-drivers. Put your car(s) in your child's name, or in
the name of your dog or a made-up name at your address. Then, the emissions
test failures would relate to a name which did not match any driver's license,
so the driver would not have his/her license suspended no matter the result of
the test. As long as the taxes on the car are paid, and the license plates
and/or stickers bought, it is still perfectly legal. I can see there being a
bit of extra effort when you sell the car, as you would have to transfer
ownership back to yourself before the sale took place, but that could probably
be done with a single notarized document.

When 30% or so of the computer-matches for owners of cars that failed the tests
come back with "no license on record", I guarantee the badly-designed law will
be changed! (Of course, no guarantee that it will be replaced with anything
better, given the history of incompetence in legislation through the ages...
:-) At least the people can strike back at the system for a while, using this
tactic.
                                        Will Martin

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
re: Danger of Sensitive Car Electronics
</A>
</H3>
<address>
Henry Schaffer 
&lt;<A HREF="mailto:hes@uncecs.edu">
hes@uncecs.edu
</A>&gt;
</address>
<i>
Thu, 25 Aug 88 09:31:36 edt
</i><PRE>

  Will Martin &lt;wmartin@ALMSA-1.ARPA&gt; mentioned a catalog "Electrical
Noise and Interference Control" with a cover picture of a car going
through a guard rail on a cliff.  The heading by the car is "ANOTHER
EMI INCIDENT?".   This is certainly a dramatic and provocative
picture.  The "About the Cover" explanation in the catalog (quoted
below) is interesting both for what it says and for what it 
implies:

  "The installation of microprocessors for controlling critical
automotive functions (engine control, braking, acceleration) has
dramatically increased the modern vehicle's vulnerability to
interference.  Even the malfunction of non-critical functions (power
sun roofs and windows, hood and trunk releases) has caused property
damage, injury and even death.

  "Although automotive travel has become safer, there are a growing
number of complaints related to "unintended' acceleration as recorded
by the National Highway Traffic Safety Administration.  Dr. Roger L.
McCarthy, P.E., of Failure Analysis Associates expects the trend to
increase since the "overwhelming majority of vehicles produced since
1981 have had computer-controled engines."  Complaints of braking
system failure, sometimes simultaneous with  unintended acceleration,
and the inability to confirm the validity of these complaints in
subsequent tests make the problem difficult to investigate or
substantiate.  Dr. McCarthy asserts, however, that "it would be
equally erroneous to dismiss all such complaints as untrue.  The
problems associated with detecting and reproducing all types of
transient electrical phenomena are well known, and phenomena such as
single event upsets, where a transient electromagnetic disturbance
changes the system state, only complicate things further."

  "The detection and measurement of, design against, and retrofit to prevent
electromagnetic interference is a science and a necessary developmental phase
of any successful product -- commercial, industrial or military.  This catalog
is your guide to the latest in theory application and pragmatic approaches to
the control of electrical noise interference.
                                              --henry schaffer  n c state univ

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Automobile computer modifications (Re: <A HREF="/Risks/7.39.html">RISKS-7.39</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:att!homxb!twitch!grt@ucbvax.Berkeley.EDU">
att!homxb!twitch!grt@ucbvax.Berkeley.EDU
</A>&gt;
</address>
<i>
Thu, 25 Aug 88 07:25:04 PDT
</i><PRE>

Virtually all issues of Porsche Panorama have ads for ROM modifications
for Porsches.  They usually claim some number or percentage increase
of horsepower, and they frequently contain disclaimers or warnings in
small print, especially with respect to street legality in California.
I drive at race tracks, but I don't know if people are using modified ROMs.
There are certainly some rather hot cars around.  The 944 has a switch that
tells the computer when full throttle is applied.  Someone told me that
I could get more power if I disconnected that switch.  A more ordinary
situation is drivability problems when the computer malfunctions.  Sometimes
I wish my car had a logic analyzer so I could figure out what is happening.
The computer costs $1400, so I do not want to carry a spare one just to avoid
getting stranded somewhere.

George Tomasevich, att!twitch!grt     	AT&amp;T Bell Laboratories, Holmdel, NJ

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Statistical reliability estimation criticized (COMPASS '88 report)
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Wed, 24 Aug 88 16:34:21 PDT
</i><PRE>

&gt; (Henry Spencer writes) ... there is no limit to the money that can be
&gt; spent adding 9's to the end of 99.9999% reliability.

An important question asks whether those extra 9's are meaningful at all.  One
sometimes hears statements like, "for safety critical systems the probability
of failure should be less than 10 ** -9" (ten to the minus nine power, or one
in a billion).  One even hears claims that the probability of failure of some
system _actually is_ less than 10 ** -9 per hour.  Is it meaningful to make
such requirements for computer systems, or to claim that such a requirement has
been met?  The apparent consensus at COMPASS '88 (a meeting devoted to the
safety and security aspects of computer systems held last June) was no, it is
not.

Sal Bavuso of NASA-Langley Research Center recalled that the 10 ** -9 figure
was derived from historical accident data for airframe failures: the
probability of things like wings breaking off was observed to be about 10 ** -8
per hour of flight, so it seemed reasonable to require that control system
failures not add significantly to the risk.  Mike DeWalt of the Federal
Aviation Administration pointed out that that 10 ** -9 figure was meant to
apply to things that break or wear out, where it is reasonable to expect
failures to appear randomly. He explained it was never intended to apply to
design errors, which are what software errors are.  John Cullyer of the British
Royal Signals and Radar Establishment also said that the 10 ** -9 figure was
meaningful when applied to analog computers composed of operational amplifiers,
which are used in some autolander systems, but is not applicable to digital
systems.

Douglas R. Miller gave a talk titled, "The Role of Statistical Methods in
Software Safety Assurance" (it does not appear in the COMPASS proceedings but
is available from the author at George Washington University).  To explain his
rather negative view of claims of very low failure probabilites, he postulated
a system in which the probability of failing a test was random and was
distributed in a Poisson fashion.  He did a simple derivation to determine how
many consecutive failure-free tests would be needed to establish with 99
percent confidence that the failure probability was less than some number. For
example, how many successful tests must be run to establish with 99 percent
confidence that the probabilitiy of failure is less than 1 in a billion? Common
sense suggests that it must be at least a billion, perhaps more. Miller derived
that you actually need around 4.61 billlion, and presented the rule of thumb
that to obtain confidence that the probability of failure is less than 10 ** -
-N, you need about 10 ** +(N + 0.5) trials. He pointed out that in most cases
it is only practical to test up to around 10 ** 5 trials, which can only reveal
bugs that appear with frequency 10 ** -4.5 or greater.

Miller said that people sometimes say that good engineering practices ensure that the probability of failure is much less than 10 ** -4.5.  But, he said,
this is rather illogical if testing reveals any errors at all.  If the tests
reveal frequent bugs, why should you believe that your good engineering
practices have prevented the subtle ones?

Cullyer said, "Let's throw out the 10 ** -9" - and many of the audience
responded with enthusiastic applause.  Someone asked if he would accept a
failure probability of only 10 ** -4 or 10 ** -5 for nuclear weapons safety.
He responded, "In the weapons area there should be no room for probability.  If
something is unthinkable, don't let it happen.  You either certify it or you
don't - one or zero."

Nevertheless, statistical claims are very ingrained among some systems safety
practitioners.  Nancy Leveson of the University of California at Irvine
recalled a conversation with an engineer who kept pointing to a box on fault
tree labelled, "software failure."  He wanted to know what number to fill in
for that probability of that event.  Leveson tried to explain that there was no
meaningful number, but he persisted.  Finally she answered, "Just write 1.0."

(This is an excerpt from a report on COMPASS '88 that will appear in the
October issue of ACM SOFTWARE ENGINEERING NOTES).

- - Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Can current CAD/simulation methods handle long-term fatigue analysis?
</A>
</H3>
<address>
Gerry Kokodyniak 
&lt;<A HREF="mailto:kokody2%me.toronto.edu@RELAY.CS.NET">
kokody2%me.toronto.edu@RELAY.CS.NET
</A>&gt;
</address>
<i>
Thu, 25 Aug 88 13:35:47 EDT
</i><PRE>
Re: RISKS DIGEST 7.38

Henry Spencer &lt;henry@zoo.toronto.edu&gt; in RISKS DIGEST 7.38 states:
# As I understand it, metal fatigue in general is poorly understood, and there
# is really no way of calculating it.

Metal fatigue can be calculated with a reasonable amount of accuracy. 

#              ..................      The whole area is still very much
# rule-of-thumb engineering plus empirical testing.  There are rules that
# give a rough idea of the fatigue life of an airframe, after which a big
# safety margin is added (we're talking factor of 2, not 10%).  Even this
# is only a tentative number. 

Most aircraft design use a 10% to 20% safety factor. A safety factor of
two would make an aircraft so heavy it would never leave the ground.
Adding a safety factor of two, without making a component bulkier would 
mean a shift towards high strength alloys. As a general rule of thumb, 
high strength alloys tend to be more brittle and therefore less damage 
tolerant. These "high strength" alloys could catastrophically fail due 
to microscopic sized cracks. A very bad feature in regards to inspection.

The problem is not so much that fatigue behaviour is not understood very
well as that the actual loading conditions can never be acurately modeled.
An example is a turbulent flight vs. a smooth flight; poor engine maintenance;
airlines allowing luggage past the allowed weight limits; rough landings by
"rough" pilots. There are many factors that influence the actual loading
conditions.  Because the load cannot be modeled accurately, any technique 
i.e. F.E.M to just using a stress formula will be out. Regular inspections
are meant to catch cracks (caused from abnormal/normal loads before they
have a chance to propagate to dangerous sizes i.e. the critical crack length).

Without Computer Aided Engineering / Finite Element Methods, the space
shuttle would never have flown at all. The FEM was used in applications
from modeling fluid dynamic flow over the shuttle to stress analysis
to thermal modeling. FEM can be used in coordination with fracture
mechanics models to model cracks and to determine the damage tolerance
of the component being modeled.

Last point, CAE &amp; FEM can be very powerful tools when coordinated with
Fracture Mechanics data obtained from experiments. There are many FEM
codes that allow one to enter such data and have elements that model
cracks and crack propagation very well. These can be powerful tools if 
used properly. 
                    				Gerry Kokodyniak

Gerry Kokodyniak, Ph.D. Student, Dept of Mechanical Engineering, U. of Toronto
USENET: kokody2@me.toronto.edu               Structural Integrity Fatigue and 
BITNET: kokody2@ME.UTORONTO                    Fracture Research Laboratory
UUCP:   {linus,allegra,decvax,floyd}!utcsri!me!kokody2  (416) 978-6853

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Boundary Cases
</A>
</H3>
<address>
James Peterson 
&lt;<A HREF="mailto:peterson%sw.MCC.COM@MCC.COM">
peterson%sw.MCC.COM@MCC.COM
</A>&gt;
</address>
<i>
Tue, 23 Aug 88 17:37:33 CDT
</i><PRE>

Vol 7, Issue 38 contained two articles that are more related than they might
seem:  Tom Lane mentioned a problem with a water billing system that ignored
the wrap-around case of a meter that went from 998 to 2 and David Sherman
mentioned a Florida couple that got a $5,062,599.57 electric bill.

The wrap-around problem is when a current meter reading is less than the
previous one.  In Tom's case it was because of the limited number of digits on
the meter.  His system was programmed to ignore it, possibly as an assumed
input error.  "Obviously" in this case, it should have been wrap around.

A few years ago, however, my meter was replaced.  The reading one month was
0456 and the next month it was 0002.  The billing program assumed it was wrap
around and charged me for 9546 units -- about 2000 times my normal usage.  Last
month, however I had an actual misreading -- the previous reading was 0680 and
the current reading was 0660 (the 0680 we suspect should have been 0630).
Service has improved however, because they caught that one somehow and simply
sent me a corrected bill with a credit for the misbilling.

The problem is how to identify a wrap-around as different from a misreading or
a new meter.  The only solution I can figure is to keep a history on-line of
what the recent periodic bills have been. When new bills are calculated, the
new bill is compared with the on-line history.  Bills which are way out of line
(like the Florida case) can be easily caught that way.  This is a simple sanity
check and seems to be basically what people do.

Does anyone know if this scheme is used in periodic billings (like utilities or
charge cards?).

There can admittedly be problems -- during start-up there is no past history to
work from (at one job, the operator entered my yearly salary as a monthly
salary and my first paycheck was $12,000) and sometimes things simply change
(like the change in a credit card usage for the yearly vacation), but it would
seem to be a valuable way to catch a lot of the outlandish billing problems
that you see blamed on computers.
                                                    jim

</PRE>
<HR><H3><A NAME="subj7.2">
Re: Another boundary case bug
</A>
</H3>
<address>
John Bruner 
&lt;<A HREF="mailto:nlp3!jdb@mordor.s1.gov">
nlp3!jdb@mordor.s1.gov
</A>&gt;
</address>
<i>
Thu, 25 Aug 88 15:42:45 PDT
</i><PRE>

Tom Lane's problem with his water meter calls to mind a problem I had
about a year ago with mine.  My new home had a brand-new water meter
with a digital (odometer-style) readout.  The water bill for my first
month was over $400.

When I checked my meter it appeared to me that the meter reader had
misread it by a factor of ten.  I called the water company.  They
said yes, the bill did seem high, but they sent someone else out to
double-check it and I really was using that much water.  The water
consumption on my bill was given in units of CCF.  I asked if this
represented 100 cubic feet.  They didn't know.  (Recently I noticed
that they've added an line to the bill that does indeed define CCF
as 100 cubic feet, or about 750 gallons.)  I could not reason with
them about this -- their attitude was that I clearly did not know
what I was talking about (!).

Finally I convinced them to send someone around to look at it with me
present.  With the company representative watching the meter I flushed
a toilet.  By my calculations the toilet consumed 4 gallons.  By
theirs it consumed 40.  I pointed out that the meter was clearly
labelled CUBIC FEET, that it read in units of 1 cubic foot, and that
to read it they needed to discard the last two digits.

Finally I found out the problem: the older digital meters read 10's of
cubic feet, and the 10's digit was white-on-black, so all the meter
reader had to do was copy down the digits that were black-on-white.
In my case, though, because he didn't know what the billing units
were, he couldn't convert cubic feet to CCF.  All of the digits on my
meter were black-on-white, so he just guessed.  A considerable effort
on my part was required to undo the effects of his guess.

The solution to my problem: the water company replaced the meter with
one of the older ones.

John D. Bruner		Natural Language Incorporated
nlp3!jdb		1786 Fifth Street, Berkeley CA  94710	(415) 841-3500

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Mother's maiden name == arbitrary password
</A>
</H3>
<address>
Walter Smith 
&lt;<A HREF="mailto:wrs@apple.com">
wrs@apple.com
</A>&gt;
</address>
<i>
Wed, 24 Aug 88 20:14:23 PDT
</i><PRE>

Institutions have used "your mother's maiden name" as a password for years.
The wonderful thing is that you can *lie* with no ill effects.  When you
see "Mother's maiden name" on a form, think of it as "Password (must be
a last name)".
                      [This was also noted by several other contributors.  PGN]

The really frightening "factoid" coming into common use is the last N
digits of your social security number.  I've seen two or three touch-tone
operated banking systems that use it.  One of them even said something like
"Your account is secure from unauthorized access, because your personal
code number must be entered first.  The code is the last four digits of
your social security number."

- Walt
  Apple Computer Inc., 20525 Mariani Ave. MS 46-A, Cupertino CA 95014

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Risks of EFT agreements
</A>
</H3>
<address>
Doug Claar 
&lt;<A HREF="mailto:dclaar%hpda@sde.hp.com">
dclaar%hpda@sde.hp.com
</A>&gt;
</address>
<i>
Thu, 25 Aug 88 12:49:00 pdt
</i><PRE>

I recently received an application to sign up for our Credit Union's 
phone-based electronic funds transfer system. The application required
three items: my account number, my self-assigned PIN, and my signature
agreeing to be responsible for any transactions completed with my PIN!
To make matters worse, the application itself is a fold-in-half and 
mail thing, with pre-paid postage on one part of the outside, and big
advertisements of what is inside on the other side. Finally, by signing
the agreement, you agree to be governed by the Credit Union's rules
regarding EFT, which you are not given, but which will be sent later.
So many risks from one little application...

Doug Claar, HP Information Software Division
UUCP: { ihnp4 | mcvax!decvax }!hplabs!hpda!dclaar -or- ucbvax!hpda!dclaar
ARPA: dclaar%hpda@hplabs.HP.COM

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Chile con backbones 
</A>
</H3>
<address>
Martin Minow THUNDR::MINOW ML3-5/U26 223-9922
&lt;<A HREF="mailto:minow%thundr.DEC@decwrl.dec.com ">
minow%thundr.DEC@decwrl.dec.com 
</A>&gt;
</address>
<i>
24 Aug 88 14:25
</i><PRE>
Originally-From: THUNDR::DECWRL::"XRJDM@SCFVM.BITNET" "Joe McMahon"
Via: Virus Discussion List &lt;VIRUS-L@LEHIIBM1.BITNET&gt;

Anyone who has been running with the University of Chile as their closest
backbone server may have noticed bizarre things lately. There were some
problems; the newest node list changes the weights of the link to try to keep
North American mail from going to South America first (and getting delayed).
--- Joe M.

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
An item by Mark Garvin on Softguard and the Trojan horse "SUG"
</A>
</H3>
<address>
&lt;<A HREF="mailto:Neumann@csl.sri.com">
Neumann@csl.sri.com
</A>&gt;
</address>
<i>
Thursday, 25 Aug 88 18:00:05 PDT
</i><PRE>

A rather extraordinary message from ZDABADE%VAX1.CC.LEHIGH.EDU@CUNYVM.CUNY.EDU
appeared on VIRUS-L, describing Trojan horses (often named "SUG") that have
been promoted as SoftGuard/SuperLock UNPROTECTORS (lock-breakers).  The file is
rather long (about the size of a typical RISKS issue) and of particular
interest to those concerned with Trojan horses and legal implications.  The
full text can be FTPed from KL.SRI.COM stripe:&lt;risks&gt;risks-7.40softguard.  PGN]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.39.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.41.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-82</DOCNO>
<DOCOLDNO>IA012-000129-B048-335</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.41.html 128.240.150.127 19970217022723 text/html 27486
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:25:50 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 41</TITLE>
<LINK REL="Prev" HREF="/Risks/7.40.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.42.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 41</H1>
<H2>  Wednesday 31 August 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
The Marconi Deaths 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  $300,000 Automatic Teller Theft (Sort Of)  
</A>
<DD>
<A HREF="#subj2.1">
Henry Cox
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Car engines become target for hackers 
</A>
<DD>
<A HREF="#subj3.1">
Jeffrey Mogul
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Blinker failure in 87 Ford Mustang 
</A>
<DD>
<A HREF="#subj4.1">
Tim Thomas
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Risks of locking systems 
</A>
<DD>
<A HREF="#subj5.1">
Andrew Birner
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Electronic 1040s 
</A>
<DD>
<A HREF="#subj6.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Water seepage stops Computer controlled monorail 
</A>
<DD>
<A HREF="#subj7.1">
George Michaelson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Fewer Charges Now Require a Signature 
</A>
<DD>
<A HREF="#subj8.1">
David Sherman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Continental Bank Drops Retail Accounts 
</A>
<DD>
<A HREF="#subj9.1">
Patrick A. Townson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
The Marconi Deaths
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Wed, 31 Aug 88 10:57:28 WET DST
</i><PRE>

Last week a further Marconi employeee died in somewhat mysterious
circumstances.  I did not see any original press reports, but only the attached
editorial from the Independent. The Independent is not a sensationalist
tabloid, but rather a highly respected and respectable national newspaper here,
so the fact that it chose to devote its leading editorial to the Marconi issue
is of some note. The result provides what I would regard as a balanced summary
and commentary, which I therefore thought was worthy of passing onto the RISKS
readership, given the previous coverage of these matters in RISKS.

Brian Randell, Computing Laboratory, University of Newcastle upon Tyne

    [For those of you wishing to comment on the relevance of this topic,
    the plausibility of conspiracy theories, the credibility of the 
    debunkers, etc., please first dig up the back issues on this topic, namely
    <A HREF="/Risks/4.74.html">RISKS-4.74</A>, 81, 83.  And let's keep the speculation down on this one.  On
    the other hand, if there is any DEFINITIVE knowledge, let's hear it. PGN]


DEATHS WHICH MUST BE INVESTIGATED

The Independent, Friday 26 August 1988

(Reprinted in full, without permission)

  The police said it was suicide, and no doubt they were right. Ex-Brigadier
Peter Ferry, a marketing manager at Marconi's Command and Control Systems
centre at Frimley, Surrey, had apparently killed himself by inserting mains
electric wires into his mouth and then turning on the power. The method chosen
was perhaps marginally more grisly than in the case of several other Marconi
employees. In 1986, for example, Ashad Sharif, a computer analyst who worked
for Marconi Defence Systems in Stanmore, Middlesex, tied one end of a rope
around his neck, another to a tree, and put his car into gear. Two months
earlier, the body of Vimal Dajibhai, a software engineer responsible for
checking the guidance systems of Tigerfish torpedos for Marconi Underwater
Systems, was found under Clifton suspension bridge at Bristol. In March 1987,
David Sands, a project manager working on secret satellite radar at Marconi's
sister company Easams, in Camberley, drove up a slip road on his way to work
and into a cafe at an estimated 80mph. A year later Trevor Knight, a computer
engineer at Marconi's space and defence base in Stanmore, died in his
fume-filled car at his home in Hertfordshire. Earlier, two other Marconi
employees, Victor Moore, a design engineer, and Roger Hill, a draughtsman, had
killed themselves, both seemingly
 as a result of work pressures.

  There have been at least half a dozen more untoward deaths among defence
scientists and others working in the defence field. Marconi is not alone, but
it is well in the lead. The best efforts of investigative journalists have
failed to establish a link either between the various deaths or between the
deaths of the Marconi staff and the Ministry of Defence inquiry, now two years
old, into some (pounds)3bn worth of defence contracts awarded to GEC-Marconi.
No doubt in several instances pressure of work was the main factor: in a field
where millions of pounds hang on the securing of contracts, it can be intense,
especially if the Ministry of Defence investigators are hovering, as they had
been at Frimley, Brigadier Ferry's base. It is hard to believe, however, that
other factors have not also been at work. The pressure of work is also fierce
in the money markets of the City, where equally large sums are at stake. Yet
the suicide rate remains unremarkable.

  Mr Ferry's death on Tuesday must add to the concern already aroused by the
alarming sequence of deaths in the defence industry. He had apparently been
depressed since his car collided with a lorry a month ago; but suicide seems an
extreme reaction. In such instances where no foul play is suspected, the
inquiries of both police and coroners are likely to be brief, partly for the
sake of the distressed relatives. They will not be concerned with establishing
a connection with comparable deaths in different counties. Since these cases
have been spread wide, there is now a case for pulling the threads together. It
may be that there is no conspiracy and no concerted skullduggery. But these
have been talented men. To allay anxieties, a senior police officer should be
appointed to head a coordinated investigation into the underlying causes of so
high a death rate.

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
$300,000 Automatic Teller Theft (Sort Of)
</A>
</H3>
<address>
Henry Cox  
&lt;<A HREF="mailto:cox%spock.ee.mcgill.ca@Larry.McRCIM.McGill.EDU">
cox%spock.ee.mcgill.ca@Larry.McRCIM.McGill.EDU
</A>&gt;
</address>
<i>
Wed, 31 Aug 88 14:30:32 edt
</i><PRE>

THEFTS FORM AUTOMATIC TELLERS WON'T HURT CLIENTS: DESGARDINS
(From the Montreal Gazette, Monday 29 August, 1988)

Desjardins credit union customers are being told not to worry about the theft
this year of $300,000 from automatic tellers. [ What, me worry? ]

Bruno Morin, Desjardins senior vice-president in charge of administration, said
the money disappeared from three locations between February and June.  Morin
assured automatic teller customers that their transactions won't be affected by
the unsolved crime, believed to be "an inside job".  The amounts stolen are
guaranteed by insurers.  He added that some changes have been implemented which
should avoid any similar thefts.  Morin dismissed reports that the $300,000 was
stolen by thieves who tampered with the credit union's computer information
system.  "The computer had nothing to do with it.  People got in and stole the
reserves.  It's pure and simple."

What isn't so simple is finding out who took the money.  We know exactly the
hour and minute the money was stolen and where it was stolen from - just not
who did it,", he added.  Although Morin wouldn't divulge which automatic
tellers were hit, he didsay non was on the island of Montreal.  One was in
Longueuil [ a suburb on the South Shore ], he said.

Francois Aubin, a public affairs vice-president of Desjardins, said the money
appears to have been taken when the machines were being loaded.  The automatic
tellers are supplied by money by Desjardins employees as well as Secur, an
affiliated security company.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Car engines become target for hackers  (<A HREF="/Risks/7.39.html">RISKS-7.39</A>)
</A>
</H3>
<address>
Jeffrey Mogul
&lt;<A HREF="mailto:mogul@decwrl.dec.com ">
mogul@decwrl.dec.com 
</A>&gt;
</address>
<i>
26 Aug 1988 1313-PDT (Friday)
</i><PRE>

In <A HREF="/Risks/7.40.html">RISKS-7.40</A>, Jerry Saltzer worries that if auto repair places must
verify the microcode in a car computer, that there will be problems
with out-of-date service information; a service agency that hadn't yet
received (or had already discarded) the microcode for YOUR car might
challenge your warranty.

This seems like an obvious application of digital signatures:  dedicate
some portion of the ROM to a value derived from an encryption of the
rest of the ROM (plus some standard validation pattern).  ROM hackers
without the encryption key could not generate a valid ROM signature.

Key security is clearly problematic; it would be greatly simplified if
a public-key system is used, so that rather than requiring key security
at ever repair shop, the key need be known only when the ROM code is
compiled at the manufacturer.  Since it doesn't matter how long the crypto
function takes to compute, any sound public-key system could be used
(perhaps avoiding large license fees).

10 years ago, Jerry wrote an article for Operating Systems Review pointing out
some problems with digital signatures; but since nobody is going to try to
disclaim one of these ROM signatures, the problems he raised then do not apply
here.
                                       -Jeff

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Blinker failure in 87 Ford Mustang
</A>
</H3>
<address>
&lt;<A HREF="mailto:thomas@xenurus.gould.com">
thomas@xenurus.gould.com
</A>&gt;
</address>
<i>
Wed, 31 Aug 88 17:59:09 CDT
</i><PRE>

Reading the discussion of car acceleration problems in RISKS has prompted me to
write of a personal experience I have had with my 1987 Ford Mustang.  I was on
a trip to Kentucky about 6 months ago, and while in one of the towns had an
interesting problem.  I suddenly noticed that, although I was using the turn
signal arm appropriately for all of my actions, the turn signals did not seem
to be activated on the dashboard.  I quickly turned down a side street, put the
car in park (but didn't turn the engine off), and had a friend of mine who was
with me get out and check the turn signals.  Sure enough, they were *not* being
activated!

Being of the experimental sort, I then proceeded to put on the emergency
flashers, which worked correctly.  I shut them off and once again tried the
turn signals.  Low and behold (you guessed it), the turn signals worked fine!
What went through my mind at that point was, what if I had been in an accident
and someone accused me of not properly signaling?  What could I say in my
defense?  Would anyone believe me?

I did not report this to the dealership since I considered it an intermittent
computer problem that they would probably *never* find.  Also, the problem has
never reoccurred (to my knowledge).  The problem may not be computer related,
but it sure sounds like it is!

Tim Thomas, Gould CSD Urbana, Urbana, IL 61801  
   (217) 384-8718    uucp: ihnp4!uiucuxc!ccvaxa!thomas

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Risks of locking systems
</A>
</H3>
<address>
Andrew Birner 
&lt;<A HREF="mailto:Andrew-Birner%ZENITH.CP6%LADC@BCO-MULTICS.ARPA">
Andrew-Birner%ZENITH.CP6%LADC@BCO-MULTICS.ARPA
</A>&gt;
</address>
<i>
Sat, 27 Aug 88 12:37 PDT
</i><PRE>

 In Risks 7.37, Leonard N. Foner (foner@wheaties.ai.mit.edu) writes:

&gt;  Whatever happened to good, old-fashioned mechanical locks?

Not even a simple mechanical lock can protect you when the locking system
is poorly designed.  The scheme installed in our computer room a few years
back illustrates this:
 The computer room is acessible from two sides.  On one side is a simple
double door (for bringing in supplies, etc.), secured with a basic jimmy-
proof cylinder lock.  Maintenance has a key to this, so that they can get
in to check the air conditioning filters and water lines.  On the other
side, we installed a vestibule with output bins, to protect our operators
from chatty users.
 The door from the vestibule to the computer room has a mechanical combination
lock; you punch in some numbers and turn the knob, and the door (usually)
opens.  From inside the computer room, the door is opened by simply turning
a crank.  Clearly, if you don't know the combination, you can get from the
computer room to the vestibule, but not back in again.
 After we installed the vestibule, we replaced the old door to the corridor.
We changed the direction of swing, and also got rid of the door knob, so
that users could just push it open.  Of course, we still wanted to lock the
vestibule during off hours, so we asked maintenance to install a deadbolt,
which they cheerfully did.  This deadbolt was actuated by a key on the
outside (corridor side), and had NO ACTUATOR AT ALL on the vestibule side!
 This arrangement made it perfectly possible for someone to get trapped
in the vestibule, with NO WAY OUT!  I complained of this, but nothing
came of it; maintenance apparently decided the probability was low enough
that they needn't worry.  I doubt the fire inspector would have been
impressed, but this didn't seem to bother anyone.
 About a year after this was installed, a maintenance engineer entered the
room via the back entrance, to clean the AC water filters.  After filling
a bucket with water, he decided to go out the front way, since it was
closer to where he wanted to dump this water.  He went into the vestibule,
letting the door latch behind him, and tried to open the corridor door--which
was, of course, locked!  Naturally, he didn't know the combination (why should
he?  He had a key, after all...), so he was quite effectively trapped.
 Since he didn't feel like waiting until the watchman came by, our hero kicked
his way out through our output bins, doing a fair amount of damage.  There is
now an actuator for the deadbolt on the inside of the vestibule...
                                                                 Andrew Birner

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Electronic 1040s
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
31 Aug 88 12:24:39 PDT (Wednesday)
</i><PRE>

From the August 31, 1988 'Wall Street Journal':

   Electronic filing [of tax returns] advanced despite computer software
   snags, says the General Accounting Office.  Such filing of computer-
   ready returns by preparers speeds processing and refunds and slashes
   errors.  The IRS plans to expand it to 48 districts in 1989 and to all
   63 in 1990; volume could reach 35 million returns in 1993.  Congress's
   General Accounting Office reports that IRS successes in handling about
   580,000 such returns from 16 districts this year came despite glitches
   that prompted the IRS to make many software corrections without the
   required testing of effects.
   
   As a result, the IRS is waiting for final corrections before going back
   to make permanent electronic records of the returns.  Now it is
   examining ways to eliminate the need to submit signatures and W-2 tax-
   withholding forms separately on paper.  And it will work to recruit
   smaller return preparers for 1989; this year, H&amp;R Block offices filed
   82% of all the electronic returns....
   
   The IRS's Greensboro district, covering North Carolina, this year 
   produced 123,386 electronic returns -- over 21% of all such filings.
   The Dallas district ranked second with 70,832 returns, or over 12%.

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
water seepage stops Computer controlled monorail
</A>
</H3>
<address>
George Michaelson 
&lt;<A HREF="mailto:munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET">
munnari!ditmela.oz.au!G.Michaelson@uunet.UU.NET
</A>&gt;
</address>
<i>
Thu, 01 Sep 88 10:29:15 +1000
</i><PRE>

Details in "COMPUTING australia" of Aug 29

Water seepage into Sydney's new monorail PLC (Programmable Logic Controller)
halted the system. the GEC-Digital 140 PLC which is located in the nose of the
train has been tested with an HP analyser to try and simulate the fault.

The monorail is highly automated.  One breakdown had dozens of passengers stuck
in a sealed environment for over 2 hours, with complaints about heat &amp; lack of
fresh air.  Many people resent the monorail as a pointless and expensive
intrusion into the city, but there have also been fears voiced about the safety
of automated systems like this.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Fewer Charges Now Require a Signature
</A>
</H3>
<address>
attcan!lsuc!dave@uunet.UU.NET 
&lt;<A HREF="mailto:David Sherman">
David Sherman
</A>&gt;
</address>
<i>
Sun, 28 Aug 88 23:09:58 EDT
</i><PRE>

Petro-Canada, the government-owned oil company that competes on the market here
with the rest of the biggies, switched to a "no signature" system a few months
ago.  You get your card back along with what looks like a normal cash-register
receipt.  It has a line for signing on it, but you only get one copy and the
attendant tells you that's all there is.

The first time this happened to me, I did a doubletake, thought a second and
decided that if they didn't WANT my signature, I wasn't going to complain.  A
couple of months later an article in the Toronto Star noted that Petro-Canada
will change this policy, due to customer complaints (people somehow think that
not signing a credit card slip makes them more liable to false charges).  Last
time I was at a Petro-Canada, they were still doing it, though.

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Continental Bank Drops Retail Accounts
</A>
</H3>
<address>
&lt;<A HREF="mailto:sun!portal!cup.portal.com!Patrick_A_Townson@unix.SRI.COM ">
sun!portal!cup.portal.com!Patrick_A_Townson@unix.SRI.COM 
</A>&gt;
</address>
<i>
Sun Aug 28 11:06:22 1988
</i><PRE>
           [PATRICK: Sorry, mail to you fails, thus no earlier responses.  PGN]

On August 15, 1988, Continental Illinois National Bank of Chicago discontinued
retail banking operations. All retail checking and savings accounts on that
day were transferred intact to the First National Bank of Chicago.

Most readers will recall that during 1984, Continental went belly-up. Unlike
many other banks which have collapsed, Continental was given a huge infusion
of money by the feds and kept afloat. Over the three years which followed,
Continental again squandered alot of its money, leading the feds to demand
some radical changes in one of the largest banks in the world, and the largest
bank in Chicago.

One of these changes was to get rid of all non-profitable banking business,
which was defined to include retail accounts, or the accounts of little folks
like you and I. Many of us with Continental accounts in the dark days of 1984
stuck it out without batting an eye. This time around, we were given no choice
in the matter of our bank loyalties.

The switch to First National Bank was announced several months ago. The
change became effective on Monday, August 15. *No action of any sort was
required of customers.*  We did not have to do a thing. Beginning about
August 5, FNB began mailing out new ATM cards and PINS. Several days
later, they began mailing out new checks. About 40,000 customers of
Continental were involved, so there were some errors in getting the new
checks and ATM cards out to the proper address, but these are now largely
resolved.

We were told to begin using our new checks from FNB on Friday, August 12,
under the assumption these checks would not reach clearing until at least
August 15. We had to discontinue the use of the Continental ATM cards on
Friday, August 12 at 2:00 PM, and were allowed to begin using the cards from
FNB as of Monday, August 15 at 8:00 AM. Our only real inconvenience was the
inability to use Cash Station machines over that weekend. Continental will
continue to manually clear checks written before August 15 which come through
for the next two months. They will be forwarded to FNB to be charged on our
accounts. Continental issued a final statement on August 15, and waived the
usual service charges for the final month. For about ninety percent of the
old Continental customers, they will have the same closing date on their
statements from First National Bank.

As an added courtesy, FNB *will not have service charges of any kind* on these
accounts transferred from Continental for one year, until 9-89. The first
batch of 300 checks on the new account are free. There will be no ATM fees.
There will be no per-check or monthly fees. Since the accounts were not
considered 'new accounts' under federal regulations, the new supply of checks
for each customer began numbering at 1001 instead of 101 as on new accounts,
and the original date of opening was omitted from the face of the check.

FNB also took over the branch bank facility Continental had operated at 1150
North Clark Street on the corner of Division Street, and will continue to
operate it as a branch bank. Since both banks belong locally to the Cash
Station network, there is no difference in the location of ATM's in the
area. Continental belonged nationally to the PLUS network, and FNB is in
the CIRRUS network, so there will be some differences when travelling
outside the Chicago area, but these should be minimal.

On Monday, August 15, the teller lines at FNB were *much longer* than
usual, as large numbers of former Continental customers qued up to make
sure their money had actually been transferred without a hitch. Of course
those of us ATM devotees who wanted to check merely had to go to any
machine and inquire, to make sure everything was okay.

People who had not received their new check stock and ATM cards as of August
15 were issued temporary checks on the spot in the bank, and ATM cards were
printed on an embossing machine nearby. Perhaps several hundred out of the
40,000 customers transferred had failed to receive either their new checks,
their ATM card or their PIN by the cutover date, but overall, the transition
was quite smooth. Employees were stationed in the lobby at Continental for
about two weeks before and after the change, handing out information on the
transfer. One customer service representative will continue to be on duty
in the lobby of Continental for about another month.

Although I did have a fight with FNB about fifteen years ago which obliged
me to sue them (I won the matter!), I have decided I will try them again
for awhile, especially since the account is free of all charges for the
next year. I might add the checkstock is more attractive also. My new
account has a picture of the Chicago skyline on the check.

My pay-by-telephone account was also automatically switched over. We have
here in the Chicago area a system by which the utilities (gas, phone and
electric) can be paid through a simple phone call to a central computer, and
I was concerned at first if this would be changed also. It was, so far as
I know, with no hitches whatsoever.

The cash machines are responding a little differently though. Under the old
Continental account the machines would accept 'split deposits', that is, you
could deposit a check and take cash back from the deposit. Under the new
account with FNB -- even though its the same Cash Station network -- you
have to make two transactions: one to deposit the check, the other to
withdraw the desired cash. Likewise, under Continental, you could not get
your balance on line until about two months ago. FNB says they have always
offered that to their customers. At Continental, we could ask the machine
to give us the time, date, and nature of the last transaction; FNB says
they are unable to do this.  Etcetera...small minor differences, but overall
a very smooth conversion of accounts.

Continental's credit card portfolio was sold about a year ago to First
National, so VISA and MASTERCHARGE cards from that bank have already been
getting processed for several months by the FNB card center in Elgin, IL.
About 2000-3000 Continental customers decided not to make the switch, and
sought out new banking arrangements of their own during the summer.

Patrick Townson

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.40.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.42.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-83</DOCNO>
<DOCOLDNO>IA012-000129-B048-357</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.42.html 128.240.150.127 19970217022740 text/html 26667
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:26:05 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 42</TITLE>
<LINK REL="Prev" HREF="/Risks/7.41.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.43.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 42</H1>
<H2> Thursday 1 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
"Pizzamation" traces phone calls, matches addresses 
</A>
<DD>
<A HREF="#subj1.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Skylab and Sunspot Activity 
</A>
<DD>
<A HREF="#subj2.1">
PGN
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Denial of Service in Wembley-on-the-Motown 
</A>
<DD>
<A HREF="#subj3.1">
Behrooz Parhami
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Calculations with wrapped numbers 
</A>
<DD>
<A HREF="#subj4.1">
Mike Linnig
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Meter reading follies 
</A>
<DD>
<A HREF="#subj5.1">
Chris Jones
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Re: abnormal bills 
</A>
<DD>
<A HREF="#subj6.1">
Ted Lee
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Risks of CAD programs 
</A>
<DD>
<A HREF="#subj7.1">
Mike A. Gigante
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Re: Risks of CAD programs 
</A>
<DD>
<A HREF="#subj8.1">
Sam Crowley
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj9">
  Can current CAD/simulation methods handle long-term fatigue analysis?    
</A>
<DD>
<A HREF="#subj9.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj10">
  Re: Vincennes and Non-Computer Verification 
</A>
<DD>
<A HREF="#subj10.1">
Henry Spencer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj11">
  Re: Computers and Gambling 
</A>
<DD>
<A HREF="#subj11.1">
Jim Frost
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj12">
  Automatic Bank Procedures 
</A>
<DD>
<A HREF="#subj12.1">
David A. Honig
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Pizzamation" traces phone calls, matches addresses
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Thu, 01 Sep 88 09:10:40 PDT
</i><PRE>

Excerpted from a story in THE SEATTLE POST-INTELLIGENCER,
18 August 1988, pps. B5 and B8:

CHAINS ARE PUTTING THE BYTE ON PIZZA DELIVERIES by Jim Erickson

Tim Turnpaugh was caught off guard recently when he telephoned for a pizza
to be delivered to his home.  When he got the pizza company on the line, 
the person taking orders greeted him by name like an old friend -- before
Turnpaugh could identify himself -- and cheerily asked if he'd like the same
toppings he asked for on a previous order.

"I didn't have to give them directions to my house, nothing," he said.
Everything the company needed to know was gathered during a previous purchase
and stored in the memory of a computer, ready for instant regurgitation.
This is the brave new world of pizzamation.

Godfather's pizza in Washington [state] is one such firm on the cutting edge
of pizza technology.  Inside a gray-walled, nondescript building in a 
Renton [Seattle suburb] business park, 80 desktop computers are lined up in
rows at Godfather's state communications center.   Not a single pizza oven is
in sight.  On a hectic Friday night, as many as 50 part-time employees sit in
front of the tricolor screens, taking orders. ...  If you've called before,
the computer instantly identifies and recognizes your telephone number, and
retrieves information from previous orders.  "Customers don't even know a
lot of the time they've reached a centralized system," said Donna Brown,
manager of the center.  "They still think they're calling a local restaurant."
...

After the order is placed, the computer decides which of 51 restaurants or
outlets in Western Washington, or 10 in Eastern Washington, is closest to the
customer.  The computer totals the price and relays the order and delivery
instructions to the kitchen of a restaurant or outlet, where it comes out on
a network printer. ...

Brown said the system allows the company to keep track of sales data, and 
since it records addresses -- more than 500,000 are stored in Godfather's 
memory banks -- it can be used for direct-mail marketing. ...

Cathy Nichols, owner of four franchised Domino's Pizza stores in Renton
and Maple Valley, installed computers early this year ... Since the computer
matches phone numbers with addresses, it also helps smoke out young pranksters
who habitually order unwanted pizzas for the unsuspecting. ...
                     [Not if they are smart enough to read a phone book.  PGN]

Some customers may worry that their local pizza retailer may be keeping records
on their eating habits as well as detailed directions to their house.  It can
be unsettling to think that the Big Cheese is watching you.  Nichols
acknowledged that large, centralized systems are "kind of scary."  "There's one
number in the state that you call, and they know everything about you."

Bill Brown of Godfather's said she could recall only three people who asked
that their records be purged, and only because they didn't want to wind up 
on mailing lists.  Their records were immediately removed, she said, adding
that Godfather's does not sell its mailing list to other companies.

[This is the first confirmed report I have seen of marketing outfits tracing
calls, although I have heard rumors of other systems in which calling an 800-
number in response to some promotion would put your phone number on a list that
would later be matched in order to derive your name and address.  It is my
observation that most people believe that "tracing a call" is still a
difficult, time consuming process that cannot be done routinely.  This story
shows that it is a service phone companies offer to commercial customers,
although I have not seen any reports of it also being offered to residential
customers (who would then be able to ignore calls from marketers, cranks, etc.)
Jonathan Jacky, University of Washington]

    [In an unrelated development, some of the pizza outfitters are selling
    leather pizza outfits -- that is, protective clothing for the pizzas.  If
    the pizza chains are going into leather, maybe S&amp;M now stands for salami
    and mushrooms.  PGN]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Skylab and Sunspot Activity 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Fri, 26 Aug 1988 14:30:16 PDT
</i><PRE>

There is an article by Richard A. Kerr entitled ``Heads Up! Sunspots Are
Dragging Down Satellites'', Science, vol 241, 19 August 1988, p. 902.  He
discusses the ups and downs of sunspot activity, and recalls that the last time
a relative maximum was reached in 1979, the 85-ton Skylab satellite was downed
as a result of the increased drag from the sun-swollen atmosphere.  The
predictability of future activity is apparently very poor.  Computer relevance?
Well, just one more thing to remember next time you put a computer in space to
control something, along with cosmic rays, laser beams, meteorites, space junk,
and other assorted hazards.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Denial of Service in Wembley-on-the-Motown 
</A>
</H3>
<address>
Peter Neumann 
&lt;<A HREF="mailto:neumann@csl.sri.com">
neumann@csl.sri.com
</A>&gt;
</address>
<i>
Wed, 31 Aug 1988 18:34:41 PDT
</i><PRE>

Stevie Wonder's birthday concert for Nelson Mandela at Wembley was disrupted
when someone stole a portable digital audio tape machine and a computer disk
drive that links into his Synclavier.  After a three-hour delay during which he
could not perform the intended program without the equipment, only two songs
were sung and the synthesizer pieces were omitted completely.  (The equipment
was later found.)  [From England's COMPUTING, 16 June 1988, p.3, contributed by
Behrooz Parhami, Computer Science, Carleton University, Ottawa CANADA K1S 5B6]

    [Here is another example of the risk of becoming completely dependent on
    technology -- no longer being able to function without it.  On the other
    hand, the equipment is presumably so reliable that there is little 
    incentive to provide much in the way of backup facilities?]

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Calculations with wrapped numbers (<A HREF="/Risks/7.40.html">RISKS-7.40</A>)
</A>
</H3>
<address>
&lt;<A HREF="mailto:linnig@skvax1.csc.ti.com">
linnig@skvax1.csc.ti.com
</A>&gt;
</address>
<i>
Mon, 29 Aug 88 16:19:22 CDT
</i><PRE>

James Peterson &lt;peterson%sw.MCC.COM@MCC.COM&gt; writes:
&gt;The problem is how to identify a wrap-around as different from a misreading...

We had a similar problem with wrapped data on a missile guidance system. Every
few milliseconds we would get a target position update.  To smooth out
the noise we'd average the new input with the old.  Since target positions
were in degrees from true north they ranged from -180 to + 180 degrees.

The problem occurs when the previous value is -175 or so and the new
value is +175.  What is the average?   Adding and dividing by two doesn't
cut it (zero is certainly NOT the answer).

I don't remember how we solved this particular problem, but I have thought
about it since then.  Imagine trying to compute the average position of the
second hand on a clock.  You sample the position once a second for sixty
seconds.  Ok, now what is the average?
                                         	Mike Linnig

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
meter reading follies
</A>
</H3>
<address>
Chris Jones 
&lt;<A HREF="mailto:ksr!clj@harvard.harvard.edu">
ksr!clj@harvard.harvard.edu
</A>&gt;
</address>
<i>
Fri, 26 Aug 88 15:42:34 EDT
</i><PRE>

About three years ago I had an extended interaction with our gas company
(Boston Gas), because of an error which was allowed to override all other
readings.  Boston Gas replaced our meters as part of what they say is a program
to replace the meters every seven years.  (In fact, I notice that they have
replaced the meters three times in the thirteen years we've owned the house,
but it certainly doesn't bother me to have the gas company look at our service
and say it looks non-explosive).  The old meters were the boxes with which I
was familiar; the new meters were smaller by about 50% in volume, and had
digital readouts.

As is standard practice, which practice had, until then, been working smoothly,
our old reading was sent in along with our new reading.

It took many months of ridiculous bills, and numerous (well, four) trips by the
gas company to notice that we were being billed amazingly incorrectly.  The
things that went wrong were:

1. The initial reading was wrong (*THIS* was the uncorrectable
   mistake).  I was *AT LAST* able to convince the gas company that
   all of our data made sense if they first assumed that the first
   meter reading had been made from right to left instead of left to
   right (this is a somewhat obvious mistake since non-digital meters
   should be read from right to left).

2. Since my wife and I were not at home during the normal working
   hours of Boston Gas's meter readers, we were sent estimated bills
   for months (about 14, all told).  It occurs to me that the price of
   the gas fluctuated during this time, and they have no way of
   knowing when we were using high-priced gas and when we were using
   low-priced gas.  It  probably didn't make more of a difference than
   writng them 10 letters did, which is what we, in fact, did.

3. MOST ANNOYINGLY, eventually our gas meter reading caught up to what
   BG thought made sense.  So, they called us, since now their bills
   showed that instead of owing them about $1300, they had overcharged
   us by about $400.  It *only now* had become a problem that they
   wanted to solve.  It took me about 10 minutes on the phone to
   convince the service person that I understood what was going on.
   As a matter of fact, when they finally read our meter, and believed
   the reading, it turned out that they owed us $5, which I declined
   to accept, knowing that, in New England in the middle of winter, I
   had impending multi-hundred dollar heating bills and could wait
   several weeks to realize my $5 credit.

So, what had happened?  One incorrect reading had been accepted as correct, and
someone (or someone's algorithm) had summarily rejected all subsequent
readings, even though an examination of them would have revealed that they were
all consistent ****with the exception of the initial reading****!!!!

It works to be first, even if you're wrong.

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Re: abnormal bills
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 26 Aug 88 01:33 EDT
</i><PRE>

Yes, some periodic billers do notice abnormal bills.  When I first installed a
modem on my Apple (must have been about five years ago) our oldest son, then
about seventh grade, used it to call the usual local bulletin boards.  (By the
way, they outgrow the habit -- neither of our two kids has bothered in the last
several years.) On some of them there were posted the usual lists of bulletin
boards all over the place, national and international.  ("for neat stuff call
01144 ...") Somehow either we or the U.S. public education system had neglected
to inform grade school students that any phone number over seven digits cost
money, and real long numbers cost lots of money.  Needless to say, the next
month's phone bill was out of sight. (I vaguely remember it was about $300,
when usually it was around $20 or so.)  We almost immediately got a call from
the phone company asking if there was some kind of error and whether the bill
should be corrected.  I'm afraid I didn't have the presence of mind to ask how
they noticed it.

(And no, it wasn't a "small town" phenomenon:  the Twin Cities metropolitan
area is about 2 million people and incidentally has one of the geographically
largest toll-free phone systems in the country.)
                                                           Ted Lee

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Risks of CAD programs (<A HREF="/Risks/7.38.html">RISKS-7.38</A>)
</A>
</H3>
<address>
Mike A. Gigante
&lt;<A HREF="mailto:munnari!cidam.rmit.oz.au!mg@uunet.UU.NET ">
munnari!cidam.rmit.oz.au!mg@uunet.UU.NET 
</A>&gt;
</address>
<i>
Sun, 28 Aug 88 09:22:52 EST
</i><PRE>

&gt; Do practicing civil engineers reduce their safety margins these days because
&gt; they use computer-aided analysis?  How much?  How small a safety margin ...
&gt; Alan Kaminsky, School of Computer Science, Rochester Institute of Technology

In my previous life, I was an Aeronautical Structures Engineer specializing
in CAD/FEM at an active design organization.

FEM isn't new, computers were being used in the 50's to do structural
analysis (matrix methods on mainly truss structures), then and now, the 
programs are not a panacea for an indepth knowledge of both teh behaviour
of structures and of how the program works. Any engineer using these methods
without that understanding is both incompetent to do the design and dangerous.
There are a million different ways to represent your structural model with
a wide variation in the quality of the results, you need to know what you
are doing and what simplifying assumptions have been made in the element
formulation!

Luckily, there are a number of checks in the engineering design process. there
are regulatory authorities who need to independently varify the design (at least
for aeronautical, automotive and civil). These independent checks often include
physical tests and 'rule-of-thumb' calculation checks to catch gross errors.

On validation of the programs, packages like NASTRAN have been in regular
use for ~20 years. For routine use by a competent designer, they are fairly
robust.

Simply adding a large safety factor is not a solution. for financial and
performance reasons, the product should be as close to the bone as
possible. A good analysis program and in-depth understanding of structural
behaviour can give you a better product (or a product that will actually
take off with its full load!). 

Something you need to realize is that the safety factors generally fall 
into two catagories

1) Loads 2) structural failure

By better understanding the modes of failure etc, the SF on 2) can be
reduced (and even more importantly, a surprise falure mode won't catch you
out!). The SF on loads (1) is most often regulated and hence cannot be
lowered. It is these SFs that 'protect' you.         Mike

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Risks of CAD programs (<A HREF="/Risks/7.38.html">RISKS-7.38</A>)
</A>
</H3>
<address>
Sam Crowley
&lt;<A HREF="mailto:astroatc!crowley@spool.cs.wisc.edu ">
astroatc!crowley@spool.cs.wisc.edu 
</A>&gt;
</address>
<i>
Tue, 23 Aug 88 16:56:50 CDT
</i><PRE>

&gt; Alan Kaminsky, School of Computer Science, Rochester Institute of Technology
&gt; Now for the RISK.  With a detailed picture of the exact stresses and
&gt; deflections on a particular structural member, the engineer can justify
&gt; designing with a smaller safety margin...

    The term "smaller safety margin" should be "known safety margin" and the 
term "large safety factors" should be "large estimated safety factors". When a
guess was made at the amount with a generous safety margin tossed in, the
exact safety margin is still unknown. An estimate of the safety margin could 
be made depending on the accuracy of the guess. 
                                              Sam Crowley  astroatc!crowley

</PRE>
<A NAME="subj9"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj9.1">
Can current CAD/simulation methods handle long-term fatigue analysis?
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Wed, 31 Aug 88 23:08:24 EDT
</i><PRE>
Re: <A HREF="/Risks/7.38.html">RISKS-7.38</A> and 40

&gt; Metal fatigue can be calculated with a reasonable amount of accuracy. 

It is possible that my information is out of date.  However, Aloha Airlines
might dispute the matter!  If fatigue calculation for real structures under
real conditions is indeed accurate and practical, it is not being used very
widely, for some reason.  I'd be interested to see references on this.

&gt; Most aircraft design use a 10% to 20% safety factor. A safety factor of
&gt; two would make an aircraft so heavy it would never leave the ground.

For structural weights, yes, 10-20% is normal.  But what I was thinking of
was fatigue life, which -- at least in the military aircraft that are the
ones I know most about -- is treated *very* conservatively.

Henry Spencer U.Toronto Zoology uunet!attcan!utzoo!henryhenry@zoo.toronto.edu

</PRE>
<A NAME="subj10"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj10.1">
Re: Vincennes and Non-Computer Verification
</A>
</H3>
<address>
&lt;<A HREF="mailto:attcan!utzoo!henry@uunet.UU.NET">
attcan!utzoo!henry@uunet.UU.NET
</A>&gt;
</address>
<i>
Fri, 26 Aug 88 23:04:02 EDT
</i><PRE>

&gt; Indeed, **what happened** in the case of the Vincennes?  Was the U.S.
&gt; operating naval patrols in a war zone without air support?  If so, why?

The underlying problem here is simply that today's US Navy is not built
for environments like the Gulf War.  Their air support is concentrated
in a handful of big, expensive, conspicuous, vulnerable carriers that
cannot be risked in the Gulf.  If the Vincennes had had a Harrier parked
on its helipad ready to go, that would have been different, but it didn't.
In an area as small as the Gulf, things happen quickly and there is no
time to call up distant support forces.  It's not practical to maintain
airborne patrols on speculation -- too costly, not just in money but in
wear and tear on men and machines, and in outright accidental losses.
(A significant fraction of the British Harrier losses in the Falklands
War were accidents not involving enemy action.)

Henry Spencer @ U of Toronto Zoology

</PRE>
<A NAME="subj11"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj11.1">
Re: Computers and Gambling (<A HREF="/Risks/7.39.html">RISKS-7.39</A>)
</A>
</H3>
<address>
Jim Frost
&lt;<A HREF="mailto:madd@bu-it.BU.EDU ">
madd@bu-it.BU.EDU 
</A>&gt;
</address>
<i>
Sat, 27 Aug 88 13:58:50 EDT
</i><PRE>

It's my observation regarding modified electronic games:

| [games] "..appear to run legitimate amusement games but with the flick 
| of a switch they are converted to gambling machines.
|
| Machines of greater sophistication are now starting to appear
| with a second switch that totally erases the computer program
| [sic] which runs the illegal games.
|
| If that happens we are powerless to prosecute."

Modified games must have some sort of mechanism (either mechanical or human)
to pay off a win.  The existence of such a mechanism, especially if it were
mechanical, could be used as proof that the machine had been used for
gambling.  I'm not a lawyer so I can't speculate on how well this might hold
up in court though.
                                                     jim frost   

    [Assuming the machine is in the "gambling" state rather than the normal 
    "non-gambling" state, authorized surreptitiously by some trusted agent,
    such a payoff "mechanism" could be a screen message that asks you to type
    in suitable identification and then show up at the cashier's office.  If
    the program then immediately returns the machine to its normal non-gambling
    state, that could be rather hard to detect unless someone were looking
    for it explicitly.  One can conjure up all sorts of variants on this
    topic, but the problem is a valid one.  PGN]

</PRE>
<A NAME="subj12"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj12.1">
Automatic Bank Procedures
</A>
</H3>
<address>
"David A. Honig" 
&lt;<A HREF="mailto:honig@BONNIE.ICS.UCI.EDU">
honig@BONNIE.ICS.UCI.EDU
</A>&gt;
</address>
<i>
Thu, 01 Sep 88 13:09:15 -0700
</i><PRE>

My bank, Home Federal in Ca., has a policy of locking an account (at
least to ATM transactions) after * 3 months * of inactivity.  This
policy is implemented automatically by their computers.  You cannot
even check your balance using your ATM card when this is in effect.

This happened to me a year ago, also: that time the ATM swallowed my
card because my savings account was "inactive" for a year. I had been
trying to access my *active* checking account.  Several days later I
got my card back, after going to the bank.  I had to withdraw a dollar
from savings, then redeposit, to reactivate it.

This time when I asked the bank person I spoke with if he could do this
administrative No-Op over the phone.  He asked his supervisor, and said yes.
I had given only the following information: my name, checking and savings
account-numbers, and the ATM-card-number.  Furthermore, he had called me
back at a number that was not my home phone.

The phone mediated account re-activation contrasts with their
conservative, automatic security policy; on the other hand, it seems
they have struck an interesting balance between security and customer
convenience.  That tradeoff is important to many computer RISKS.

David Honig, Dept of Info &amp; Comp. Sci, Univ. of Ca., Irvine 92717

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.41.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.43.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-84</DOCNO>
<DOCOLDNO>IA012-000131-B033-249</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.43.html 128.240.150.127 19970217022841 text/html 19959
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:26:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 43</TITLE>
<LINK REL="Prev" HREF="/Risks/7.42.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.44.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 43</H1>
<H2> Friday 2 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Statistical reliability estimation criticized 
</A>
<DD>
<A HREF="#subj1.1">
Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Calling party identification 
</A>
<DD>
<A HREF="#subj2.1">
Mark W. Eichin
</A><br>
<A HREF="#subj2.2">
 TMPLee
</A><br>
<A HREF="#subj2.3">
 anonymous
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Automotive EMI - a personal experience 
</A>
<DD>
<A HREF="#subj3.1">
Scott C. Crumpton
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  The mental tyranny of a cash register 
</A>
<DD>
<A HREF="#subj4.1">
Steven C. Den Beste
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Intoximeter risks 
</A>
<DD>
<A HREF="#subj5.1">
Andrew Vaught
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  SSNs, Passports 
</A>
<DD>
<A HREF="#subj6.1">
Chris Hibbert
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Statistical reliability estimation criticized (Jon Jacky, RISKS 7.40)
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK">
Brian_Randell%newcastle.ac.uk@NSS.Cs.Ucl.AC.UK
</A>&gt;
</address>
<i>
Fri, 2 Sep 88 11:07:59 WET DST
</i><PRE>

Re: Jon Jacky's message, stating that:
&gt;John Cullyer of the British Royal Signals and Radar Establishment ...
&gt;said, "Let's throw out the 10 ** -9" - and many of the audience
&gt;responded with enthusiastic applause.  Someone asked if he would accept a
&gt;failure probability of only 10 ** -4 or 10 ** -5 for nuclear weapons safety.
&gt;He responded, "In the weapons area there should be no room for probability.  
&gt;If something is unthinkable, don't let it happen.  You either certify it or 
&gt;you don't - one or zero."

I'm appalled by this comment, if it is reported as accurately as I fear it is!
Just because something is "unthinkable" doesn't mean that *any* particular
technology, such as certification, will *guarantee* that it will not happen,
and that no measures need be taken, or even considered, to allow for the
possibility of failure. (This is the sort of thinking which has "justified" the
reported lack of planning in the UK for dealing with Chernobyl-scale
catastrophes at nuclear power stations.)

I find the following attitude much more professional. (The quote comes from the
review by Tom de Marco of "Principles of Software Engineering Management", by
Gilb and Finzi, in IEEE Computer for August 1988):

 "We must quantify everything that matters to eventual project success or
 failure. Everything - particularly those product characteristics that we treat
 as unquantifiable (flexibility, "user-friendliness," net benefit, etc.) -
 must be scaled and targeted. Some of the quantifications will be "fuzzy"
 in Gilb's terms, but even fuzzy numbers are far better than no numbers at all.
 The very act of coming up with the best-effort quantification of these factors
 guides us towards success and knowing how well we are doing along the way."

Otherwise, how will the Cullyers of this world for example (i) choose between
rival certification techniques, (ii) know when certification is "complete", or
(iii) decide how to divide a finite budget between certification and
complementary approaches to reducing the likelihood of having to experience,
and apologise for, an "unthinkable" occurrence. (In fact I fear I know the
answer - by blind faith and misguided eloquence!)

All this is not to say that naive unjustifiable quantification, such as often
accompanies the bandying around of figures like 10 ** -9, any more
professional.  However the fact that such naivete occurs is no reason to
abandon attempts to find means of making, justifying and intelligently using,
quantified reliability assessments, even w.r.t. design errors, especially with
systems whose failures would be truly catastrophic.
                                                          Brian Randell

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Calling party identification 
</A>
</H3>
<address>
Mark W. Eichin 
&lt;<A HREF="mailto:eichin@ATHENA.MIT.EDU">
eichin@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 1 Sep 88 22:22:08 EDT
</i><PRE>

&gt;... It is my observation that most people believe that "tracing a call" is
&gt;still a difficult, time consuming process that cannot be done routinely. This 
&gt;story shows that it is a service phone companies offer to commercial 
&gt;customers, although I have not seen any reports of it also being offered to 
&gt;residential customers ...

I believe the New Jersey telco offered digital display of incoming number to
private subscribers a year ago; here at MIT, with the installation of a 5ESS
system with full ISDN support available to offices, the digital set
automatically displays the phone number the call came from (if it was within
MIT; apparently there isn't software in place to track calls from other
switches yet, the display merely indicates "Outside"). The documentation for
the dormitory phones included mention of a ``privacy code'' which meant dialing
65 before any phone number; the pamphlet with the phone didn't actually explain
what the privacy code *did* however.

Mark Eichin, SIPB Member &amp; Project Athena ``Watchmaker'' 

</PRE>
<HR><H3><A NAME="subj2.2">
Calling party identification  Phone number tracing
</A>
</H3>
<address>
&lt;<A HREF="mailto:TMPLee@DOCKMASTER.ARPA">
TMPLee@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Thu, 1 Sep 88 22:42 EDT
</i><PRE>

Our local cable company must use the same kind of connection to the phone
company that the pizza place mentioned in <A HREF="/Risks/7.42.html">RISKS-7.42</A> does.  They have several
pay-by-view channels and a set of incoming phone numbers.  To order a
pay-by-view event all you do is dial something like 938-77xx where the xx is
the "ordering" code for the particular movie or live event (local sports, etc.)
you want.  A computer answers the call and is somehow told where the call was
from; it looks that up in a data base, finds the i.d.  of your cable box and
enables the show.  (It goes on your bill, of course.)  Rather clever, actually:
no human operators and it works from either a dial phone or a touch tone phone.
Don't use it much, and apart from misdialling the only "risk" I have is
remembering to use line 1 rather than line 2.
                                                         Ted Lee

</PRE>
<HR><H3><A NAME="subj2.3">
Calling party identification
</A>
</H3>
<address>
&lt;<A HREF="mailto:[anonymous]">
[anonymous]
</A>&gt;
</address>
<i>
Thu, 1 Sep 88 19:57:52 xDT
</i><PRE>

While there is work going on to allow for the identification of calling parties
by the callee, such systems are not generally implemented and won't be for some
time to come.  There are some limited test projects, but I don't believe that
any large-scale operation of the sort implied is currently operational.

Most likely what is actually happening is that the first question people are
asked when they call the pizza folks is "what is your phone number?"  Then
the computer operator punches that in and up pops all the info from any
previous call.  It is unlikely that they are receiving the calling party's
number in realtime.  It IS true that with some long-distance carriers' 800
callers numbers are made available to the callee, but this is done on a
billing cycle basis (i.e., in the billing statement) and not in realtime.
If it turns out the pizza folks ARE receiving the number ID in realtime,
then they are in one of the test groups and one can't help but wonder how
many folks in the area realize the ramifications of this all (see below).

Now, in the middle future the issue of the callee being able to receive the
number of the caller will be a significant one for us all.  The technology is
being put into place.  At first glance, many people might say, "Gee, how neat,
I'll know the numbers of the phone solicitors who bother me."  But think again.
It would work both ways.  Do you really want YOUR phone number recorded (and
possibly later called back with solicitations, matched with addresses for
mailings, etc.)  whenever you call a business, possibly from your private line
you only intend to use for outgoing calls, or from some friend's house or
business from where you happened to make the call?  If you make a business call
from home, do you necessarily want the person receiving the call to immediately
have your home number?  Do they have any right to that number rather than
calling you back on the office number you might give them?  There are a variety
of complex ramifications.

Even worse, if YOU could see the callers' numbers on calls YOU receive, you
might be disappointed at much of what you'd see.  Most big solicitation
businesses use special outward-calls-only trunking groups; you would frequently
see undialable numbers like 012-4161 on your display.  Such info isn't going to
do you a lot of good without a lot of hassling with telco for info (which they
might well be unwilling to give you).

And what about obscene phone calls and such?  Won't this system help stop them?
Well, maybe some dummies would get caught, but there are one hell of a lot of
payphones out there and people could easily move from one to another
indefinitely...

The issue of privacy of callers' numbers is thus more complicated than it might
appear at first.  Some proposals call for unlisted numbers not to routinely
display on callee displays.  Some other plans propose a control prefix (e.g.
"*21") which you could dial before dialing a phone number if you want to block
number display for that particular call.

All in all the issues involved are quite complex.  The time to start thinking
about them is now.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
 Automotive EMI - a personal experience
</A>
</H3>
<address>
Scott C. Crumpton
&lt;<A HREF="mailto:NESCC%NERVM.BITNET@CUNYVM.CUNY.EDU ">
NESCC%NERVM.BITNET@CUNYVM.CUNY.EDU 
</A>&gt;
</address>
<i>
Fri, 26 Aug 1988 09:51:42 LCL
</i><PRE>

There is a section of road that I frequently drive which comes within about 600
feet of a TV (ch 20) transmitter tower.  Within a distance of approximately 1/4
mi of the tower, the cruise control on my 87 Volvo 240DL will not set properly.
The "set" button acts like "resume", causing a normal rate of acceleration up
to the previously set speed.  This behavior is repeatable in this location,
however I have not noticed any other symptoms or occurrences in other locations.

Considering the "success" that I have had getting minor problems (like cold
start stalling) fixed at the local Volvo dealer, I don't think I'll be taking
this one to them.  I will probably attempt to fix it myself with some ferrite
chokes and a little shielding.
                                            ---Scott.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
The mental tyranny of a cash register
</A>
</H3>
<address>
&lt;<A HREF="mailto:denbeste@OAKLAND.BBN.COM">
denbeste@OAKLAND.BBN.COM
</A>&gt;
</address>
<i>
Mon, 29 Aug 88 12:01:58 -0400
</i><PRE>

Last Saturday I was in a local mall, and being thirsty I went to a cookie-
over-the-counter store which was handy, and ordered a "medium rootbeer", price
listed as $.75. I proffered a dollar, and was given $0.19 change.

[It should be explained at this point that Massachussetts has a 5% sales tax.
However, this would have fallen under the restaurant and meal tax, which also
happens to be 5%.]

"Wait a minute", I said, "The sales tax on this should be 4 cents, not 6."

"I know. The cash register is broken. But that is what it says to give you, so
that's what I have to do." [I suspect my memory may be making his words a bit
different - please bear with me.]

"Give me the rest of my change!"

"There's no way for me to do that." I walked away snarling.

Actually, of course, he could just have hit "No Sale" and gotten two more
pennies out of the till. But, having done so, at the end of the shift the till
would have contained less money than the cash register said it should, and he
would've had to make up the difference out of his own pocket. Given a choice
between it being his money and being mine, he wanted it to be mine.

Both of us were trapped by a cash register which had been programmed for an 8%
sales tax.

Now that I've cooled down, I'm not even sure that he thought it through to the
point I gave two paragraphs ago. I think his reaction was merely: Do what the
machine says, even if you KNOW it is wrong.

Editorial point: Shades of the Vincennes.
   We are the elite - we understand, at least in principle, what
goes on inside of virtually anything which is computerized. This makes us free
- we know enough to know that the computer can be just as wrong as a person
can, since a person decided ahead of time what it would do. It is only a
machine, and is just as fallible as its creators.
   But for those out there who truly have no idea what a computer is, it has
become a kind of oracle or demigod: You follow its orders and you DO NOT
QUESTION, because it is smarter than you. Perhaps this is why some people
flatly refuse to use automated tellers at banks, and literally refuse to touch
a computer keyboard even when urged. Those who mess with the gods get turned to
spiders.
   When put in a job-related situation where interaction with a computer is
unavoidable, the computer truly becomes almost a deity: YOU DO NOT QUESTION.
("We are sorry, Mr. Thompson, but our computer says that you are dead. We do
not do business with corpses.")

[Maybe I HAVEN'T cooled down, after all.]

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
     Intoximeter risks
</A>
</H3>
<address>
        Andrew Vaught 
&lt;<A HREF="mailto:29284843%WSUVM1.BITNET@CUNYVM.CUNY.EDU">
29284843%WSUVM1.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Thu, 01 Sep 88 13:33:56 PLT
</i><PRE>

{Taken from the 24 August 1988 Spokesman-Review without permission}

      GASSED OR DRUNK?  PRISONER FILLS 'ER UP

  While official witnesses looked on, a Bonner County Jail prisoner swigged a
  paper cup full of gasoline last week in an effort to prove himself innocent
  of drunk driving.  Sagle resident Barry Joe Raynor, 20, claims he was
  siphoning gasoline just before he was arrested for drunken driving last Jan
  14, said his attorney Jonathon Cottrell.  When the case goes to trial in 1st
  District Magistrate Court next week, Cottrell and Raynor will argue it was
  gasoline on his breath that lit up the scoreboard on Bonner County's
  intoximeter the night he was arrested.

[The article goes on to say why drinking gasoline is not a real good idea and
how drinking a cup of gasoline showed a .28 percent blood alcohol level one
hour later.]

Although the article never mentions what kind of `intoximeter' is actually used
in the tests, it is pretty obvious that it is not directly measuring blood
alcohol content, but some other telltale that allows it to be fooled by
gasoline.

   [NPR this morning noted that when the tape recording of the arrest was
   played in court, Raynor sounded so intoxicated that he simply gave up on his
   gas defense.  OK.  This item thus appears to not be RISKS related, although
   the risk of false positives on such tests is always a risk that must be
   recognized.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
SSNs, Passports
</A>
</H3>
<address>
&lt;<A HREF="mailto:Hibbert.pa@Xerox.COM">
Hibbert.pa@Xerox.COM
</A>&gt;
</address>
<i>
Wed, 31 Aug 88 17:45:40 PDT
</i><PRE>

I was just looking through Robert Ellis Smith's "Report on the Collection and
Use of Social Security Numbers", and on the final page he added a note about
SSN's and the Passport office.  Since there was some unresolved discussion of
this at the beginning of the year, I thought I would forward the information.

Smith says that as of the beginning of this year, SSN's are required on
passport applications, and failure to include it may result in a $500 fine.
I'm as puzzled by this as the people who reported similar things in January.  I
don't know why the passport office doesn't refuse to handle applications
without SSNs and just forget about the fine.

The reason they want the number in the first place is apparently so that the
IRS can make sure that Americans living abroad file returns.

If there really is a fine, then it should be mentioned in the requisite Privacy
Act notice along with a statement as to whether disclosure has an impact on
you're getting a passport.

The "Report on the Collection and Use of Social Security Numbers" can be
ordered from the Privacy Journal, P.O. Box 15300, Washington DC 20003.  Their
phone number is (202) 547-2865.  I was dissapointed in the level of the report.
It's mostly a sampler of case histories of people who were burned in various
ways by abuse of their numbers.  It contains little in the way of privacy
advice that hasn't already appeared here.
                                                    Chris

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.42.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.44.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-85</DOCNO>
<DOCOLDNO>IA012-000131-B033-266</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.44.html 128.240.150.127 19970217022855 text/html 20704
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:27:23 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 44</TITLE>
<LINK REL="Prev" HREF="/Risks/7.43.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.45.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 44</H1>
<H2> Monday 5 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Re: "Pizzamation" and Call Tracing    
</A>
<DD>
<A HREF="#subj1.1">
Bob N. Mayo
</A><br>
<A HREF="#subj1.2">
 Edwin Wiles
</A><br>
<A HREF="#subj1.3">
 Patrick A. Townson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  COMPASS REPORT in RISKS 7.40 
</A>
<DD>
<A HREF="#subj2.1">
Bev Littlewood via Brian Randell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Statistical reliability estimation 
</A>
<DD>
<A HREF="#subj3.1">
Lance J. Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Re: Calculations with wrapped numbers 
</A>
<DD>
<A HREF="#subj4.1">
Bruce Karsh
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
Re: "Pizzamation"
</A>
</H3>
<address>
Bob N. Mayo @ U.W. Madison Computer Sciences
&lt;<A HREF="mailto:mayo@cs.wisc.edu ">
mayo@cs.wisc.edu 
</A>&gt;
</address>
<i>
Sat, 3 Sep 88 13:17:29 CDT
</i><PRE>

Godfather's Pizza [phone (206) 223-1111] claims that they don't get told the
customer's phone number.  This contradicts the previous article which claims
that they automatically receive your number, that is then used to display
your "pizza-history".  

When I called them to ask about this, Godfather's claimed that they ask you 
for your phone number and then set up an "account" for you.  They specifically
stated that they do not automatically receive customer's phone numbers.

Can anybody account for this discrepancy?  I can think of several 
possibilities:

	+ The previous article was in error.
	+ They have discontinued this practice. (Perhaps due to poor reception
	  from the public?)
	+ Godfather's didn't tell me the truth.

Anybody know?
--Bob
      [Most likely the first one.  PGN]

</PRE>
<HR><H3><A NAME="subj1.2">
Re: Pizzamation and FGD lines...
</A>
</H3>
<address>
Edwin Wiles
&lt;<A HREF="mailto:netxcom!ewiles@uunet.UU.NET ">
netxcom!ewiles@uunet.UU.NET 
</A>&gt;
</address>
<i>
Sat, 3 Sep 88 02:08:10 EDT
</i><PRE>
Organization: NetExpress Communications, Inc., Vienna, VA

On a standard telephone line, it is still difficult to 'trace a call'.  In
all probability these businesses are using what are known as "Feature Group
D" lines; which have aprox 6 to 8 wires, as compared to the 2 to 4 wires of
a normal telephone line.

Feature Group D service is designed to tell you both the number dialed,
and the number that is doing the dialing.  The extra lines are used for
signaling the address information.

[I know whereof I speak, our company is using FGD lines, and I had to design
a program to interface with the phone company protocols.  Not easy....]

Yes, personally I would like one of these lines, with a smart phone to
block unwanted calls.  However, such phones already exist, that work over
standard phone lines, the caller simply has to punch a few more digits
(like a PIN) to let your phone know that they are allowed to talk to you.
The nice thing about a FGD line, is that you can reject the call without
actually having answered it, thereby allowing the caller to avoid paying
the phone company for a call that you'd reject anyway.

Edwin Wiles, NetExpress Comm., Inc., 1953 Gallows Rd. Suite 300 Vienna, VA 22180

</PRE>
<HR><H3><A NAME="subj1.3">
Automatic Number ID: Great Idea!
</A>
</H3>
<address>
&lt;<A HREF="mailto:sun!portal!cup.portal.com!Patrick_A_Townson@unix.SRI.COM">
sun!portal!cup.portal.com!Patrick_A_Townson@unix.SRI.COM
</A>&gt;
</address>
<i>
Sat Sep  3 13:25:31 1988
</i><PRE>
      [Note: This address for PAT is bogus, and does not work.  Try
      "sun!portal!cup.portal.com!username"@Sun.COM or
      "sun!portal!cup.portal.com!username"@uunet.UU.NET]

A recent article here by Anonymous warned of the 'dire consequences' all of
us would face when Automatic Number Identification on a real time basis
became a routine feature.

I have to disagree, wholeheartedly. ANI will be one of the best, and most
useful additions to telephony that I can think of.

I consider an unsolicited phone call to be an invasion of my privacy. If you
feel you have the right to call me and refuse to identify yourself, then I
maintain I have the right to come to your front door and refuse to identify
myself.

While it is true, as Anonymous pointed out that phone solicitors and the like
frequently work from phones with special types of circuit numbers which cannot
be easily traced by someone with ANI, the fact remains that ANI will bring a
virtual halt to most of the hacking and phreaking and obscene calls which
plague many people. Yes, as Anonymous points out (an appropriate handle,
considering the gist of his message, no?) people can move around from one
payphone to another, endlessly, continuing to create their havoc in whatever
form it takes, but in reality, most people will not take portable modems and
terminals with them to the pay phone on the corner just so they can call
someone's BBS and harass them Anonymously.

Having ANI implemented will simply make it too inconvenient for most of the
low-life scum who hide behind their telephone to continue their practices. As
for legitimate reasons to not want your number displayed to the called party,
I can't think of any. Again, you have to make the analogy of going to see
someone in person. It is completely unfair and unrealistic to say that you
have the right to disturb someone at whatever they were doing and that they
in turn have no right to demand to know who you are.

In summary, I believe you have the right to use the phone as a method of
quick, almost instant communication with others. You do not have the right
to use the phone as a way to remain Anonymous. Having a non-published number
is a different matter altogether, since you are protecting yourself against
persons who might call you. The way you protect your privacy when calling
someone else is to *simply not make the call at all* if there is something
which will be said which you would not want traced back to yourself.

Anonymous is also making the assumption that the people who aquire your number
via ANI will automatically abuse the information. This is mostly false.

If and when ANI at the subscriber level becomes available here in Chicago, I
will be one of the first to subscribe. And when a call is received and the
read out shows that the person has deliberatly blocked their number from my
view, I will probably answer the phone and state that they are welcome to call
back making the information available, and pending that action, the present
call is being terminated now. (click).

Patrick Townson

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
COMPASS REPORT in RISKS 7.40
</A>
</H3>
<address>
Brian Randell 
&lt;<A HREF="mailto:Brian_Randell@newcastle.ac.uk">
Brian_Randell@newcastle.ac.uk
</A>&gt;
</address>
<i>
Mon, 5 Sep 88 16:11:01 WET DST
</i><PRE>

Here are comments by Prof. Bev Littlewood - unfortunately not a RISKS reader -
on Jon Jacky's report from COMPASS 88, which I am posting to RISKS on his behalf.

To Brian Randell:

&gt;The recent report of COMPASS 88, if accurate, contained some pretty shocking
&gt;things.  John Cullyer is quoted as saying "Let's throw out the 10**-9", a view 
&gt;that brought audience applause.  He went on to say, when questioned about
&gt;nuclear weapons safety, that "in the weapons area there should be no room
&gt;for probability.  If something is unthinkable, don't let it happen.  You 
&gt;either certify it or you don't - one or zero."
&gt;
&gt;The last sentence worries me.  He appears to be asserting that it is possible
&gt;to certify (note that word) that a system is perfect (i.e. that the unthink-
&gt;able will not happen).  Does he really mean this?  What about design flaws, 
&gt;specification errors?  It seems to me that this attitude, prevalent on the 
&gt;wilder fringes of the formalist community in the UK, seeks to turn a wish
&gt;into a fact.  Of course, we would all like to be able to remove the uncertainty
&gt;which is present in the process of building systems, but that uncertainty 
&gt;is a fact of life.  There is an intrinsic limit to the extent to which we
&gt;can formalise the problem domain, even if we are successful in current attempts
&gt;to formalise later stages of design.
&gt;
&gt;If an element of uncertainty is inevitable, we need a calculus of uncertainty.
&gt;The only one we have is probability (see, for example, de Finetti on the
&gt;'inevitability' of probability as a means of describing uncertainty).
&gt;
&gt;Nancy Leveson's remarks are just as bad, although possibly more amusing.
&gt;Nancy told the story of her encounter with an engineer who wanted to know
&gt;what number to fill in for the probability of the event labelled "software
&gt;failure" on a fault tree.  Leveson tried to explain that there was no number
&gt;but he persisted.  Finally she answered, "Just write 1.0."
&gt;
&gt;Leveson is LITERALLY correct - the software will ultimately fail with certainty
&gt;- but the engineer is asking a responsible question.  He wants to know how 
&gt;frequently the software will fail so that he can make scientifically informed
&gt;judgements to aid in the engineering decisions he must take.
&gt;
&gt;There is a lot of confusion in this area, and some of it seems to centre 
&gt;around figures like 10**-9.  Many people do not seem able to distinguish 
&gt;between such a figure being MEANINGFUL (which it is), and being ACHIEVABLE
&gt;(which it probably isn't) and ASSURABLE (which it certainly isn't).
&gt;
&gt;Consider the 10**-9 failures per hour for the Airbus A320 fly-by-wire system.
&gt;This is often taken to be 'meaningless' because it is so small.  However, if
&gt;we assume aircraft fly 5000 hours each year, that each has a 20 year life, and 
&gt;that the fleet size is 1000, we arrive at a 100,000,000 hours in the air for
&gt;the fleet life.  10**-9 then translates into an approximate 1 in 10 chance
&gt;of failure in the life of the fleet.  This is an 'ordinary' probability 
&gt;which is meaningful to anyone and could, for example, be used as part of 
&gt;a calculation to fix insurance rates (I wonder how they were actually fixed?).
&gt;
&gt;Digressing for a moment, it is interesting in the case of the A320 that the
&gt;manufacturers are on record as stating 10**-9 per hour is a REQUIREMENT for
&gt;this system (because, again as they say, failures cannot be tolerated).  It
&gt;is obvious that achievement of this 'requirement' has not been demonstrated,
&gt;and one wonders how reliable the system actually is.  Presumably it falls 
&gt;far short of 10**-9.  This presents a difficulty, because the manufacturers
&gt;were so confident of their ability to make it sufficiently reliable that they
&gt;did not provide a fully functioning mechanical back-up for use in the event 
&gt;of complete system loss.  If this were to occur, the pilot only has trim and
&gt;rudder to fly the aircraft.  The aircraft has been landed in this configur-
&gt;ation, but I am told that it is not easy (an understatement) and airline 
&gt;pilots will not be trained for such landings.
&gt;
&gt;Returning to the main theme, I think that probability statements representing
&gt;very high reliabilities are meaningful and necessary for safety-critical 
&gt;systems.  But, of course, I agree with Miller that they are essentially
&gt;inpossible to measure and so in practice we shall not be able to assure 
&gt;ourselves that we have achieved what is necessary (even if, by some miracle,
&gt;such a reliability had in fact been achieved).
&gt;
&gt;Thus far I suppose we are not in too great disagreement with the likes of 
&gt;Cullyer and Leveson.  It is when we start to consider the implications of
&gt;our inability to assure very high reliabilities that we start to differ.
&gt;They seem to think that this is due in some way to defects in statistical
&gt;methodology and that we should therefore have no more truck with statistics 
&gt;(and statisticians?).  In fact, of course, the problem is due to the intrinsic
&gt;paucity of information about such systems, when compared with the very strong
&gt;statements we wish to make.  Improvement of statistical methodology will not
&gt;be able to dent this problem.  But that does not mean that Cullyer-type 
&gt;'certification' can be used instead (unless he means by this a assurance that
&gt;the failure rate is ZERO - and I do not believe this is the case).  Rather
&gt;it means that we are in a genuine impasse, and perhaps ought to face the 
&gt;unpalatable view that we should not be building systems which require a 
&gt;reliability which is not assurable.
&gt;
&gt;
&gt;Bev Littlewood, Centre for Software Reliability, The City University, London.
&gt;
&gt;email: sd396@city.ac.uk
&gt;
&gt;


--
Brian Randell, Computing Laboratory, University of Newcastle upon Tyne

JANET =	Brian_Randell@uk.ac.newcastle
ARPA  =	Brian_Randell@newcastle.ac.uk
UUCP  =	...!ukc!newcastle.ac.uk!Brian_Randell
PHONE =	+44 91 222 7923

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     Statistical reliability estimation (Brian Randell, RISKS 7.43)
</A>
</H3>
<address>
Lance J. Hoffman 
&lt;<A HREF="mailto:LANCE%GWUVM.BITNET@CUNYVM.CUNY.EDU">
LANCE%GWUVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Fri, 2 Sep 1988 20:00 EDT
</i><PRE>

&gt; "...The very act of coming up with the best-effort quantification of these
&gt;factors [flexibility, user-friendliness, net benefit, etc.] guides us
&gt;towards success and knowing how well we are doing along the way" - Gilb and
&gt;Finzi, quoted by Randell

This is certainly true.  In the majority of risk analyses I've seen, the end
product was secondary to the learning process that took place as people did
it (and often implemented immediate simple fixes along the way).  There is,
however, a quasi-religious debate between the quantitative types and the
qualitative types.  Moreover, the issues of risk perception and risk
communication often dominate the technical issues (and, in my opinion,
properly so).  Stu Katzke of NBS and Sylvan Pinsky of the National Computer
Security Center have developed an initial risk model for computer security,
which is published in Proc. 1st Risk Model Builders Symp., Martin-Marietta,
Denver, 1988.  Copies of the entire proceedings will be given out, I am
told, to attendees at the upcoming Baltimore computer security conference
sponsored by NBS and NCSC.  And much food for thought if found in a journal
I find that few computer security types get, Risk Analysis, published by the
Society for Risk Analysis, published by Plenum Press.  It is the official
journal of the society, 8000 Westpark Drive, Suite 400, McLean VA 22102
(says the masthead).  Many of the authors of papers here have been working
on computer and noncomputer risks for a long time.
   Sample articles from the 9/87 issue: Impact of AI on the Risk Analysis
Profession; Informing and Educating the Public about Risk; Book Reviews;
Software Review (WHAZAN, for assessing chemical process hazards); and more.
You get the idea.
      - Lance Hoffman, George Washington University (LANCE@GWUVM.BITNET)

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Calculations with wrapped numbers
</A>
</H3>
<address>
Bruce Karsh
&lt;<A HREF="mailto:karsh@sgi.com ">
karsh@sgi.com 
</A>&gt;
</address>
<i>
Fri, 2 Sep 88 20:51:28 PDT
</i><PRE>

&gt; The problem occurs when the previous value is -175 or so and the new
&gt; value is +175.  What is the average?   Adding and dividing by two doesn't
&gt; cut it (zero is certainly NOT the answer).

&gt; I don't remember how we solved this particular problem, but I have thought
&gt; about it since then.  Imagine trying to compute the average position of the
&gt; second hand on a clock.  You sample the position once a second for sixty
&gt; seconds.  Ok, now what is the average?

A good way to estimate an average angle, A, from a set of angle measurements
a[i] 0&lt;=i&lt;N, is:

                       sum_i_from_1_to_N sin(a[i])
	a = arctangent ---------------------------
                       sum_i_from_1_to_N cos(a[i])

A very careful study of the properties of this estimator is in the book
"Statistics On Spheres", Geoffrey S. Watson, University of Arkansas Lecture
Notes in the Mathematical Sciences, 1983 John Wiley &amp; Sons, Inc.

The importance of this to RISKS is that the problem of computing an average
angle comes up all the time in computing.  An answer to the problem was
published at least as long ago as 1983 and probably known for a long time
before that.

Yet people try to calculate average angles in all kinds of ways, too many of
which give terribly wrong answers!

The problem is that the people who design and program software are not always
aware of the techniques that they need to make correct programs.  There are
untold thousands of computational techniques, ... certainly more than we can
expect people who program numerical methods to know.

The average angle problem is not the only one that people regularly program
incorrectly.  A recent discussion in comp.graphics illustrated how frequently
wrong solutions are given to the problem of calculating whether or not a point
is inside a polygon.  Similarly, people regularly code incorrect procedures 
which purport to determine whether or not two line segments intersect.

We need to better reference materials on numerical methods.  Most
numerical methods books concentrate on finding solutions to {differential,
linear, integral, ...etc} equations and on computing values of special
functions.  But we need references on less classical problems.  For example,
how many more times are people going to program bad solutions to the point-in-
polygon problem?  How many system failures are we going to tolerate because of
wrong solutions to the line intersection problem?  We need to be able to look
up solutions to these problems.

Of course, if such a reference book were produced, how many programmers would
actually use it?

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.43.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.45.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-86</DOCNO>
<DOCOLDNO>IA012-000131-B033-281</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.45.html 128.240.150.127 19970217022907 text/html 21667
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:27:36 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 45</TITLE>
<LINK REL="Prev" HREF="/Risks/7.44.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.46.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.44.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.46.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 45</H1>
<H2> Wednesday 7 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Cheater software 
</A>
<DD>
<A HREF="#subj1.1">
Rodney Hoffman
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Re: COMPASS REPORT 
</A>
<DD>
<A HREF="#subj2.1">
Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Risks Digest 7.44 
</A>
<DD>
<A HREF="#subj3.1">
Jerome H. Saltzer
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Display of telephone numbers 
</A>
<DD>
<A HREF="#subj4.1">
Bruce O'Neel
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Telephones and privacy 
</A>
<DD>
<A HREF="#subj5.1">
C.H. Longmore
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Gambling with video arcade machines 
</A>
<DD>
<A HREF="#subj6.1">
Mike Blackwell
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Video Games 
</A>
<DD>
<A HREF="#subj7.1">
Ed Nilges
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Wembley-on-the-Motown 
</A>
<DD>
<A HREF="#subj8.1">
Jeffrey R. Kell
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
"Cheater software"
</A>
</H3>
<address>
Rodney Hoffman 
&lt;<A HREF="mailto:Hoffman.es@Xerox.COM">
Hoffman.es@Xerox.COM
</A>&gt;
</address>
<i>
6 Sep 88 08:06:50 PDT (Tuesday)
</i><PRE>

&gt;From a story by Kim Murphy in the Sept. 3 'Los Angeles Times':

   General Dynamics Corp. was accused of using "cheater software" and 
   other fraudulent practices to falsify tests and supply defective 
   components for the U.S. Navy's Phalanx anti-missile gun system and 
   the Standard Missile program.

   In a lawsuit filed in Los Angeles federal court, one former and four 
   current General Dynamics employees -- technicians, supervisors and
   quality-control specialists -- accused the St. Louis-based defense 
   contractor of encouraging its employees to engage in widespread test
   falsifications that may have compromised the integrity of the two 
   weapons systems....

   A "cheater software" computer program allows company technicians to 
   begin running a test, then abort it and obtain a passing reading, the 
   suit contends....

   [more on other, non-software-related means used to falsify tests]

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
"COMPASS REPORT in RISKS 7.40 (Bev Littlewood via Brian Randell)"
</A>
</H3>
<address>
&lt;<A HREF="mailto:leveson@electron.LCS.MIT.EDU">
leveson@electron.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 06 Sep 88 16:58:42 -0400
</i><PRE>
Re: <A HREF="/Risks/7.44.html">RISKS-7.44</A>

Wait a minute.  I have been tarred with an opinion that I do not have and
have never espoused.

&gt;Nancy Leveson's remarks are just as bad, although possibly more amusing.
&gt;Nancy told the story of her encounter with an engineer who wanted to know
&gt;what number to fill in for the probability of the event labeled "software
&gt;failure" on a fault tree.  Leveson tried to explain that there was no number
&gt;but he persisted.  Finally she answered, "Just write 1.0."
&gt;
&gt;Leveson is LITERALLY correct - the software will ultimately fail with certainty
&gt;- but the engineer is asking a responsible question.  He wants to know how 
&gt;frequently the software will fail so that he can make scientifically informed
&gt;judgments to aid in the engineering decisions he must take.

I did not say his question was irresponsible, only that it was unanswerable
at this time with the confidence that he wants.  Since we cannot measure
such low reliability numbers, then these types of systems should not be built 
to depend on the correct operation of the computer, i.e., the fault tree 
should take the conservative view of assigning 1.0 to the probability of 
failure of the software and, therefore, the builders will be required to show 
that the system is safe even if the software fails.  For example, a fully 
automated nuclear power plant safety system or fly-by-wire aircraft might be 
considered safe enough if there are usable and reliable back-up systems that 
do not rely on proper operation of a computer.   The problem with the Airbus
320 appears to be that they are relying on the computers and not taking the
need for back-up systems seriously.  The same, unfortunately, is also true
for the nuclear power plant design that the engineer I was speaking with
was evaluating.

&gt;Thus far I suppose we are not in too great disagreement with the likes of 
&gt;Cullyer and Leveson.  

How did my opinions on the subject (which were never stated in the original
message from Jon Jacky) and John Cullyer's get lumped together?  I am not
usually accused of agreeing with anyone :-).

&gt;They seem to think that this is due in some way to defects in statistical
&gt;methodology and that we should therefore have no more truck with statistics 
&gt;(and statisticians?).  

I have never made such a statement or implied this.  I am in favor of 
research in software reliability (and safety) measurement and in its use 
currently for systems that do not involve loss of life and therefore
do not require very low numbers and high confidence.

&gt;Improvement of statistical methodology will not
&gt;be able to dent this problem.  But that does not mean that Cullyer-type 
&gt;'certification' can be used instead (unless he means by this a assurance that
&gt;the failure rate is ZERO - and I do not believe this is the case).  Rather
&gt;it means that we are in a genuine impasse, and perhaps ought to face the 
&gt;unpalatable view that we should not be building systems which require a 
&gt;reliability which is not assurable.

Most systems are not 100% safe, nor does society require them to be.  We
usually require only an acceptable level of safety.  The problem is in
Bev's equating failure-free and safe.  Making them failure-free would
certainly work, but it is not necessary.  For example, aircraft are not
failure-free, but they seem to have a safety level that is acceptable
to society.  What we need to eliminate is catastrophic failure modes, not
necessarily ALL failure modes.  If we had to do the latter, we would need
to abandon much of current technology.  I personally feel that there are other 
solutions (which I have written extensively about) than just not building 
systems with computers.  That is, I believe we can build adequately safe 
systems without requiring 10**-9 reliability.  Unfortunately, not many 
software engineers know enough about system safety to build such software 
systems and the system safety engineers do not understand computers.  

JANET =	Brian_Randell@uk.ac.newcastle

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Automatic Number ID: Great Idea! (<A HREF="/Risks/7.44.html">RISKS-7.44</A>)
</A>
</H3>
<address>
Jerome H. Saltzer 
&lt;<A HREF="mailto:Saltzer@ATHENA.MIT.EDU">
Saltzer@ATHENA.MIT.EDU
</A>&gt;
</address>
<i>
Tue, 6 Sep 88 13:47:33 EDT
</i><PRE>

In "Automatic Number ID: Great Idea!", Patrick Townson makes several
good arguments favoring Automatic Number Identification (ANI).  I
agree that on balance ANI will be a good thing once the novelty wears
off and people become accustomed to the new rules of the game.  But
Townson may be carrying a good argument a little too far when he
says,

&gt;   As for legitimate reasons to not want your number displayed to
&gt;   the called party, I can't think of any.

I assume that he took that somewhat polar position in order to draw
out suggestions for legitimate reasons, so here are a couple of cases
in which maintaining the privacy of the caller does seem to make some
sense:

     1.  Hotlines (e.g., drug-abuse and suicide) and police
     department tip numbers depend on anonymity of the caller to
     perform a function that is usually considered to have some value
     to society.  Some police departments maintain a line separate
     from 911 (which often has an ANI feature) just for this purpose.
     If the caller of a hotline knew that the calling number would be
     automatically recorded, at least some of the information that
     flows in this way would dry up, and some of the help dispensed
     this way would not be.  (The technique of dialing a prefix code
     to block automatic number identification caters to this
     requirement.  I doubt that many hotlines would take Townson's
     hard-nosed approach and refuse to accept a call from a
     prospective suicide who has blocked ANI.)

     2.  When a private party calls on a "big organization," (for
     example, making ten queries to stock trading companies about their
     commission rates in anticipation of opening one account) there is
     an understandable preference for not leaving one's number,
     simply to avoid unwanted followup calls (e.g., from hungry
     brokers).  Again, the ANI-blocking prefix satisfies this
     requirement, because no hungry stockbroker is going to refuse a
     call that sounds like it comes from a promising prospect.

Townson's polar position might be plausible if you assume telephones
are answered only by private individuals.  He is well-advised to
refuse anonymous calls to his bulletin board and welcome to refuse
them at his private phone.  But I believe that the need for blocking
ANI remains for other situations.

					Jerry

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Re: Display of telephone numbers on receiving party's phone
</A>
</H3>
<address>
Bruce O'Neel 
&lt;<A HREF="mailto:XRBEO%VPFVM.BITNET@CUNYVM.CUNY.EDU">
XRBEO%VPFVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Tue, 06 Sep 88 17:30:25 EDT
</i><PRE>

I much prefer using a prefix ( *21 say) only when you WANT the number
to be known, rather than when you DO NOT want the callee to see it.

bruce

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Re: Telephones and Privacy
</A>
</H3>
<address>
C H Longmore 
&lt;<A HREF="mailto:CCAse7-16@birmingham.ac.uk">
CCAse7-16@birmingham.ac.uk
</A>&gt;
</address>
<i>
Tue, 6 Sep 88 20:28+0100
</i><PRE>

Patrick Townson's article in RISKS 7.44 states:

&gt; Having ANI implemented will simply make it too inconvenient for most of the
&gt; low-life scum who hide behind their telephone to continue their practices.
&gt; As for legitimate reasons to not want your number displayed to the called 
&gt; party, I can't think of any. Again, you have to make the analogy of going
&gt; to see someone in person. It is completely unfair and unrealistic to say 
&gt; that you have the right to disturb someone at whatever they were doing and 
&gt; that they in turn have no right to demand to know who you are.

How could you apply this to a situation where [as in the UK] certain police
forces operate systems whereby people can give information to the police
*anonymously* by calling a device as simple as an answering machine?

How could you apply it to a situation where a potential customer wishes to
obtain a quote by phone *without* running the risk of that company using the
information so gained to apply the hard-sell.

Can you imagine someone using a confidential medical advice line (such as an
AIDS advisory service) if there was a possibility of the call being easily
traced?

How many people would telephone up the Samaritans if their number wasn't
confidential?

In the UK these are not problems....  yet.  Our current telephone network is
not capable of supporting these features....  yet.

It *should* be possible to conceal your own telephone number from the person
you are calling..  however, it is also the right of the person receiving the
call to refuse to communicate with anybody who does not want his/her telephone
number revealed.  The latter is easy enough to implement....  a simple
user-settable switch on the telephone is all that is needed.

The 'privacy' argument has two sides....  it is the right of an individual
*not* to have their phone number displayed, but it is also the right of the
individual *not* to answer anonymous calls.  A problem to which the solution
seems easy enough....  (now prove otherwise!)

                              Conrad H Longmore
   Computer Science Dept, University of Birmingham, Birmingham B15 2TT, UK.

             email: CCAse7-16%multics.bham.ac.uk@cunyvm.cuny.edu

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Gambling with video arcade machines
</A>
</H3>
<address>
&lt;<A HREF="mailto:Mike.Blackwell@ROVER.RI.CMU.EDU">
Mike.Blackwell@ROVER.RI.CMU.EDU
</A>&gt;
</address>
<i>
Tue, 6 Sep 1988 17:34-EDT
</i><PRE>

I was once called to be an expert witness in a case involving gambling
with video poker machines. The case never went to trial, but I did gain
some insight as to how they work.

In a typical video card machine, you put in your quarter, and earn one
card hand (five card draw or blackjack are the most common). You play
the hand (discarding and drawing new cards - no betting here, you just
get one shot), and at the end win so may points for your final hand
(from zero for a bad hand, one for two-pair, two for three-of-a-kind,
up to maybe 500 for a royal-flush). In a real gambling machine (like in
Vegas), you'll get quarters for your points - they spit right out of
the machine. In a non-gambling arcade machine, you just get free games
for your points. This is legal, no different than winning free games or
extra time at Space Invaders (in Pennsylvania, at least, playing video
poker is considered to require skill...).

What makes the arcade style card machine a gambling device is the
addition of a "knock-off" switch. This is a switch, either directly on
the machine, or wired from the bar, which zeros out the any free games.
How it works is you rack up your zillion free games, find the barkeeper
(or whoever, but this seems to usually take place in bars), and he'll
pay you one quarter for each free game you've won. Then he'll clear the
free games from the machine. It is solely the presence of this knock-off
switch that classifies the machine as a gambling device. Apparently
(though I was never able to confirm this), simply power cycling the
machine does not clear free games.

Even if a bar is not caught paying off, the game distributor can be
tried for providing machines with knock-off switches.

		-m-

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Video Games
</A>
</H3>
<address>
Ed Nilges 
&lt;<A HREF="mailto:EGNILGES@PUCC.Princeton.EDU">
EGNILGES@PUCC.Princeton.EDU
</A>&gt;
</address>
<i>
Tue, 06 Sep 88 13:27:04 EDT
</i><PRE>

How many computer professionals have noticed the continual technical
improvement of video games in the past couple of years, and the
concomitant decline of their social and moral content?  Nintendo and
other Japanese companies, with little knowledge or care about the
effect of racial tensions on American cities, market games such as
Ninja Warriors vs. Bad Dudes, which feature a Caucasian-looking
(or Japanese) hero, fighting black villains.  The video game user
manipulates the characters in a seedy back-alley environment featuring
garbage cans and rats...an offensive comment, on the face of it, on
the state of the inner city.

Other games allow players to act as contra rebels or air force pilots,
without teaching them either the misery of dying in a jungle, or the
difficulty of qualifying to be an Air Force enlisted man, let alone
pilot.

The graphics are beautiful: the content is vile.  Surely it's our
responsibility as computer professionals to protest this application
of a technology which could improve lives.  While the Japanese are to be
applauded for making technology affordable, they are to be condemned
for taking technology developed in the US, and using it to degrade people
in this way.

Perhaps the most effective thing for computer people to do is to
approach restaurant owners in their own community who operate such
machines and explain their concerns as professionals and, if applicable,
as parents.  Video game parlor operators are obviously not going to
listen, but restaurant owners may.

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Re: Wembley-on-the-Motown (RISKS 7.42)
</A>
</H3>
<address>
Jeffrey R Kell 
&lt;<A HREF="mailto:JEFF@UTCVM.BITNET">
JEFF@UTCVM.BITNET
</A>&gt;
</address>
<i>
Tue, 06 Sep 88 10:11:27 EDT
</i><PRE>

(I play keyboards/synthesizer part-time aside from my "real" job...)
Any electronic musical equipment, especially anything constantly moved with
a traveling show, is far from being highly reliable.  The newest electronic
keyboards are probably the most sensitive of all.  You are fortunate to get
predictable results in a controlled (studio) environment, let alone have
a delicate piece of equipment be thrown around by the road crew, plugged
into unstable power sources and subjected to varying temperature conditions.

Original synthesizers (Moog, Arp) with their knobs, switches, and patch cords
took some time to set properly, but they did STAY SET, other than perhaps
small tuning adjustments.  The second generation could record these settings
in small internal memories, thus making the first synthesizer "programs".
The third generation was practically all digital (notably Korg, Yamaha) with
settings programmed as parameters, and internal memory grew to several K-bytes
of RAM, often with battery backup and cassette backup.  The latest generation
recreates sounds from digital samples, much like a CD Disk player.  The
Synclavier mentioned is one of the top-of-the-line of these types.  I own a
Korg DSS-1 (standard disclaimers) which has 768K RAM, a 3.5 diskette drive,
and can turn out a 48KHz sample rate at 14 bit resolution.  Very nice, but
one minor power glitch and memory is lost must be rebooted (about 30 seconds,
but rather annoying in the middle of a song).  I was once stuck on an out-of-
town job with two third-generation Poly-800's which were packed by a member
of the road crew and inadvertently left turned on (they can operate from
batteries alone) resulting in loss of memory (and cassette backup at home).

The risk of high-tech music can also be heard in CD disks.  They sound
superb when they work, but go far off into the ozone when they fail.
Quite a far cry from the brief bump of a phonograph needle skipping a groove.

I have caught myself longing for the days of the trusty piano which, with
a tuning or two a year, always got the job done.  At least in that respect, I
find it easier to relate to the techno-phobes who distrust automation.

Jeffrey R Kell, Dir Tech Services, Admin Computing, 117 Hunter Hall,
Univ of Tennessee at Chattanooga, Chattanooga, TN  37403          

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.44.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.46.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-87</DOCNO>
<DOCOLDNO>IA012-000131-B033-293</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.46.html 128.240.150.127 19970217022918 text/html 21916
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:27:49 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 46</TITLE>
<LINK REL="Prev" HREF="/Risks/7.45.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.47.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.45.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.47.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 46</H1>
<H2> Wednesday 7 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
Airbus vs U.K. MOD development standards 
</A>
<DD>
<A HREF="#subj1.1">
Lorenzo Strigini
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Vincennes: Rules of engagement violated by AI heuristic? 
</A>
<DD>
<A HREF="#subj2.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Re: Statistical reliability estimation and "certification" 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  A Computer Virus Case Goes to Trial 
</A>
<DD>
<A HREF="#subj4.1">
Joe Morris
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  Computers and guns 
</A>
<DD>
<A HREF="#subj5.1">
Gary Sanders
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Automatic Call Tracing and 911 Emergency Numbers 
</A>
<DD>
<A HREF="#subj6.1">
Gary McClelland
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  Automatic Number ID: Bad Idea! 
</A>
<DD>
<A HREF="#subj7.1">
Andrew Klossner
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
     Airbus vs U.K. MOD development standards
</A>
</H3>
<address>

&lt;<A HREF="mailto:PROCIS@ICNUCEVM.BITNET">
PROCIS@ICNUCEVM.BITNET
</A>&gt;
</address>
<i>
Wed, 7 Sep 88 18:31 SET
</i><PRE>

From "Systems International", August 1988 issue, editorial page: "In his recent
lecture entitled "Should we trust computers?" given to the British Computer
Society, Martin Thomas, chairman of Praxis, said ...... the computer systems
used on the ill-fated A320 at the Paris Air Show were developed using
techniques 'the UK Ministry of Defence would find unacceptable for safety
critical _military_ software in the future'".  Can anyone give a first-hand
account of that lecture, or a more complete citation, or somehow shed more
light on the issue? I am curious about a) how far that future is; b) which of
the new rules would the A-320 development violate; c) how many current systems
would be found to violate those rules, and how many to respect them.

Lorenzo Strigini

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
Vincennes: Rules of engagement violated by AI heuristic?
</A>
</H3>
<address>
Clifford Johnson 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Wed,  7 Sep 88 00:00:32 PDT
</i><PRE>

A recent contribution noted that the Airbus shot down by the Vincennes had been
within binocular range of the ship, and inferred that binoculars were superior
to the Aegis system.  This is invalid.  Reportedly, there was an obscuring
haze, and, besides, even had the plane been identified as an Iranian Airbus, it
would have been shot down, according to the Pentagon's latest report, which
states that the Captain was fully aware that the plane may well have been a
commercial flight, e.g.:  "On the Vincennes, an officer watches the plane
slowly rising.  He jumps to his feet and says 'possible comair,' for commercial
aircraft, to the ship's commanding officer, Capt.  Will. C. Rogers.  The
Captain acknowledges this." (See NYT, Aug.20, for this and the other info. I
report.)

Another contribution citing the Vincennes noted the tendency for computer
output to be definitive, right or wrong.  This analogy is valid.  It was not
the Aegis giving bad data, but it was the Aegis giving a procedurally
*conclusive* categorization, together with the duty-imposed rules of
engagement, that caused what the military now boasts was a "prudent," albeit
automatic, killing of 290 civilians.  Thus:  (1) from the moment of take-off,
the plane was formally characterized as hostile merely because the airfield was
not wholly civilian, and this characterization would be definitively "correct"
until disproven by the flight's obeying the ship's radioed warnings; (2) the
rules of engagement next required that protection of armed-to-the-teeth U.S.
militia have top priority, above protection of defenseless civilians in
transit.  (Since the latter protection was the purported mission of the
Vincennes, this seems to me a code of cowardice rather than a rule of
engagement.) These rules required the shootdown.  The Aegis did its job and the
Captain his mandated duty, and they conclusively saved the Vincennes from the
risk posed by a lumbering Iranian Airbus that would not immediately respond to
radioed warnings.

JCS Chairman Crowe explained that all fault lay with Iran, because it was
"unconscionable" for the Iranians to permit a civilian airliner to take off
amid hostilities (which the air controllers are simply presumed to have known
about) and to ignore warnings.  According to the NYT, Crowe asserted that the
plane would have been shot down IN ANY CASE given lack of proof that it was not
hostile.  Such "shoot-on-suspicion" rules of engagement Crowe claimed to be
wise policy.  (To me it is chilling that the U.S.  calls the shootdown a
commendable "We'd-do-it-again" preprogrammed procedure, rather than a wildly
mistaken massacre; this kindles memory of Reagan's ire after the KAL007
shootdown:  "Shooting down a plane, even one with hundreds of innocent men,
women, children, and babies, is part of their normal procedure.")

The Pentagon's support of the shootdown as a prudent necessity fails to address
the official notice provided by the U.S. re its rules of engagement in the
Gulf, which stated:  "United States Navy ship captains realize that not all
commercial aircraft transmit their proper IFF code or remain in the proper
airways and will take this into account when they encounter such an aircraft."
So it seems a post-facto revision of the rules of engagement to assert that
failure to respond to warnings is per se sufficient cause for deadly force
*until proven otherwise*.  That is, Rule Of Engagement number (1) above was in
violation of the declared Rules Of Engagement.  The U.S. should have informed
the airlines that all planes taking off from Bandar Abbas were presumed hostile
until proven otherwise, instead of informing them that no such presumption
would apply even if such a plane strayed from its corridoor and failed to
broadcast civilian codes, let alone if it was within its corridoor and did emit
civilian codes.

One natural question naturally not commented on in the Pentagon's report is the
applicability of the word "panic," although it notes:  "At every opportunity
when the ship's internal communication link is silent, an officer known as the
tactical information co-ordinator calls the attention of the other officers to
his belief that the plane is accelerating and descending.  His computer
terminal, like others on the ship, actually shows the aircraft rising...
'Towards the end,' wrote Gen. George B. Crist, 'it is reported he was yelling
out loud.'" By not even reprimanding this officer, and by ultimately blaming
inadequate but correctable video displays, the Pentagon is materially
announcing that misreading computer consoles is an accepted, large risk that
higly-trained crewmen cannot be expected to avoid, and which absolves Captain,
crew, and computer from all responsibility.

Interest has been expressed in the numerical/logical algorithms whereby
computerized sensors declare a detection as hostile.  The above illustrates
that declaration of hostility is not merely a simple sensor in-/de-duction, but
as much an "IF-THEN" heuristic/rule-of-thumb, e.g.:  "IF TAKE-OFF FROM NOT NOT
MILITARY AIRFIELD AND ALERT-LEVEL ABOVE 2, UNTIL AFFIRMATIVE RADIO RESPONSE
THEN BLIP IS HOSTILE THEN SHOOT ON APPROACH." What is ordinarily construed as
objective inference, is in fact a mandated conditional *definition*.
(Likewise, it is linguistically predefined that the United States is "under
attack" -- which triggers and authorizes retaliation -- if a nuclear attack
warning level exceeds a certain threshold, euphemistically dubbed "the
President's Launch Under Attack threshold".)

Re purely statistical sensor detection, I recommend "Data Fusion" in Defense
Electronic's first annual C3I Handbook (1986).  It provides a comprehensive
table of techniques, which include Bayesian, frequentist, maximum likelihood,
evidential, pattern-matching, associative, syntactic, and heuristic
methodologies.  A basic division is into "hard" sensors, that declare an attack
in binary form (yes/no), and "soft" sensors, that provide a probability
estimate that a detection is hostile.

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Re: Statistical reliability estimation and "certification"
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Wed, 07 Sep 88 08:43:03 PDT
</i><PRE>

Postings by Brian Randell, Bev Littlewood and others responding to my COMPASS
trip report suggest that some clarification may be required.  I am confident 
that I quoted Cullyer, Leveson and others accurately; I took careful notes 
on the spot.  However ---

- I should emphasize that skeptical comments regarding statistical reliability
estimation were limited to the context of *a priori predictions* of the
reliability of *software* - that is, predicitions of software reliability made
prior to experience in the field.   Regarding their opinions on statistical
reliability estimation and life in general, I cannot say.  I did note that
Cullyer and others did remark that a priori estimates could be useful for
*hardware*  systems, where failure histories for the components were known.

- - There seems to be a misunderstanding regarding the term "certification" - in
particular, Cullyer's remark that "you either certify (a product) or you don't
- - one or zero."   Apparently some readers understood "certification" in this
context to refer to some formal validation technique, which Cullyer was
claiming was "perfect" in some sense.  I believe that was not the intended
meaning.  It is necessary to distinguish *validation* from *certification*.
Validation is the technical process of determining whether a product conforms
to its requirements. Nobody at COMPASS claimed that any validation technique
was perfect, although people did claim that some techniques were better than
others. Certification is the administrative act of releasing a
potentially hazardous product for sale or use. Certification IS one or zero.  
The necessity for basing a yes-no decision on less-than-totally-conclusive 
technical information is the certifier's dilemma.

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
A Computer Virus Case Goes to Trial
</A>
</H3>
<address>
Joe Morris (jcmorris@mitre.arpa) 
&lt;<A HREF="mailto:jcmorris@mitre.arpa">
jcmorris@mitre.arpa
</A>&gt;
</address>
<i>
Wed, 07 Sep 88 13:05:09 EDT
</i><PRE>

From the _Washington_Post_, 7 September 88, page C-1 (without permission):

  JURY SELECTION IN 1ST `VIRUS' TRIAL BEGINS (AP)

Fort Worth, Sept. 6 -- Jury selection began today in the criminal trial 
of a 40-year-old programmer accused of using a computer "virus" to sabotage
thousands of records at his former work place.
The trial is expected to last about two weeks.

Donald G. Burleson faces up to 10 years in jail and a $5,000 fine if convicted
in the trial, a first for the computer industry.  Burleson was indicted on
charges of burglary and harmful access [sic] to a computer in connection with
computer damage at a securities firm, said Nell Garrison, clerk of the state
criminal district court in Fort Worth.  Through his lawyer, Jack Beech,
Burleson denies the charges but has declined further comment.

The firm has been awarded $12,000 in a civil lawsuit against Burleson.
Pretrial motions were scheduled to be heard today, followed by jury selection,
Garrison said.

Burleson is accused of planting a piece of computer software known as a
virus in the computer system at USPA&amp;IRA Co. two days after he was fired.
A virus is a computer program, often hidden in apparently normal computer
software, that instructs the computer to change or destroy information at
a given time or after a certain sequence of commands.  [Trojan horse???]

USPA officials claim Burleson went into the comapny's offices one night and
planted a virus in its computer records that would wipe out sales commissions
records every month.  The virus was discovered two days later, after it had
eliminated 168,000 records.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
computers and guns
</A>
</H3>
<address>
Gary Sanders
&lt;<A HREF="mailto:gws%n8emr%osu-cis@pyramid.com ">
gws%n8emr%osu-cis@pyramid.com 
</A>&gt;
</address>
<i>
7 Sep 88 02:47:32 GMT
</i><PRE>

	A funny thing happened on the way to the data call..

I was sitting at home one cool evening, flipping through the channels on the TV
not much on, even with cable...  Every once in a while I would hear my modem
dial out out the one of the many news feed sites, and hear the many machines
and men calling in.. I was about ready to nod off (again), but someone
was knocking rather rudely on the door.

I jump up and answer the door briefly (no pun) forgetting that I only had only
my boxers on.. Well I crack the door open and it was a nice man in blue...  Yes
the police office stop by, ? to say hi? NO!, to collect for the policeman's
ball (...), NO! Someone had called 911, in fact they called 911 three times in
a row. I assured them that I didn't call but they wanted to look around and
make sure I did have any dead bodies lying around so i ran in and put some
pants on and unhooked the chain on the door.

They checked out the living room, then headed to the bed rooms.  One bedroom is
a bed room and one is a computer center, radio room (ham) and electronic scrap
room (my play room).  After one pulled his guns out, I got a little worried.
Why did they have their guns out, I had forgotten that I had 2 UZI water guns
hanging on the wall in my play room, that along with the radio, flashing lights
and other terrors looking electronic gimos in the room, It must have spooked
them a little.

Well they finally figured out that the guns were plastic and that
I didn't have any real bombs in the room, they put away their guns.

Now they wanted to know why I called 911 three times, I told them that
I had not, but they were not convinced, Well I ask them what number
the call came from they said xxx.yyyy, hey that's not my number, it's 
zzz.aaaa then it came to me, the other number was my data line...
I have no phone on the line, so it must have been the computer
calling someone. Have you ever tried to convince a police officer that
your computer was calling 911 by itself.. It doesn't work... They said
that the dispatcher had called back but I had hung up on them, actually
my modem was very polite and answered the phone and only became rude
when it heard a human, then it hung on them..  Well, They left and told 
me (and my computer) to be careful and not dial 911 unless it's a real 
emergency... I say ok, and close the door.

I still wasn't sure why my system was calling 911, I didn't have 911 in the
Systems file... or did I.. I check it out and found the problem. I call a site
with a phone number of 891-11xx and from the logfile I had called the site 3
times a short time before the police arrived. It looked like MA Bell had take a
little to long to give dialtone and the first digit was dropped. So If you want
to save yourself some trouble check out your Sys files and hide your water
guns...

	This did happen several months ago, GUNs and ALL.. 
Every one in a while, like tonight I get a visit from the local PD... 
I give them the story and they look around say code 4 to the dispatcher
and leave..... Oh well life and data goes on...

Gary W. Sanders				HAM/SWL BBS 614-457-4227
(uucp) gws@n8emr 			(uucp) osu-cis!n8emr!gws
(packet) N8EMR @ W8CQK			(cis) 72277,1325

    [This one could become a classic like the Israeli bugspray-in-the-toilet
    story, which resurfaced after previously appearing in an old-yarn book.  
    We have had a variety of cases just like this in the past.  But it serves 
    as another reminder of how easily it can happen.  PGN]

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
Automatic Call Tracing and 911 Emergency Numbers
</A>
</H3>
<address>
&lt;<A HREF="mailto:MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU">
MCCLELLAND_G%CUBLDR@VAXF.COLORADO.EDU
</A>&gt;
</address>
<i>
Tue, 6 Sep 88 22:41 MDT
</i><PRE>

Our local county government just worked a deal whereby for a small fee added
to each customer's phone bill, the county's centralized 911 emergency
switchboard would be provided with a display of all incoming phone numbers
and addresses.  I'm rather glad that the next time I call 911 all that
information will be communicated automatically (but I hope it will still be
verified orally whenever possible).  However, I suppose that once we pay for
the installation of the necessary technology the local telco will be able to
sell it as a service to other businesses.  As previous notes have suggested,
there are many privacy issues to consider here but there are benefits that
also need to be considered as well.
                                               Gary McClelland

   [911 ANI in LA noted by  paulb@ncc1701.tti.com paulb@ttidca.TTI.COM 
   (Paul Blumstein).] 

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
Automatic Number ID: Bad Idea!
</A>
</H3>
<address>
Andrew Klossner 
&lt;<A HREF="mailto:andrew%frip.gwd.tek.com@RELAY.CS.NET">
andrew%frip.gwd.tek.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
Tue,  6 Sep 88 11:00:22 PDT
</i><PRE>

[This discussion has gotten pretty far from RISKS.]

	"I consider an unsolicited phone call to be an invasion of my
	privacy. If you feel you have the right to call me and refuse
	to identify yourself, then I maintain I have the right to come
	to your front door and refuse to identify myself."

This is the wrong analogy.  Consider a world in which, when you wonder
into a shop with an idle question, the shopkeeper can, without your
permission, divine your identity.  There's a world of difference
between "Good afternoon, what's your name? If you won't tell me, get
out" and "Good afternoon, I have recorded your name and there's nothing
you can do about it."
                          [Also remarked upon by Hugh Pritchard.  PGN]
          
	"Anonymous is also making the assumption that the people who
	a[c]quire your number via ANI will automatically abuse the
	information. This is mostly false."

This is a Pollyanna attitude.  I have worked for telephone/junk-mail
solicitors (in my starving student days) who would drool at the thought
of abusing this information.  As an example of privacy abuse, consider
Radio Shack's policy of demanding full identification, even of cash
customers, for purposes of composing a mailing list.

  -=- Andrew Klossner   (decvax!tektronix!tekecs!andrew)       [UUCP]

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.45.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.47.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-88</DOCNO>
<DOCOLDNO>IA012-000131-B034-18</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.47.html 128.240.150.127 19970217022944 text/html 19428
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:28:14 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 47</TITLE>
<LINK REL="Prev" HREF="/Risks/7.46.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.48.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.46.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.48.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 47</H1>
<H2> Thursday 8 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
COMPASS report in RISKS 7.40 
</A>
<DD>
<A HREF="#subj1.1">
Jean-Claude Laprie
</A><br>
<A HREF="#subj1.2">
 Nancy Leveson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Calling number delivery (ANI) (John 
</A>
<DD>
<A HREF="#subj2.1">
J.) McHarry
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  More on Automatic Call Tracing and 911 Emergency Numbers    (Robin j. Herbison, Al Stangenberger
</A>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Another ANI scam 
</A>
<DD>
<A HREF="#subj4.1">
Brent Laminack
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
COMPASS report in RISKS 7.40
</A>
</H3>
<address>
Jean-Claude Laprie
&lt;<A HREF="mailto:laprie@laas.laas.fr ">
laprie@laas.laas.fr 
</A>&gt;
</address>
<i>
Thu, 8 Sep 88 08:58:07 -0200
</i><PRE>

Brian Randell forwarded me the Jon Jacky's report from COMPASS'88, and asked to
comment it. These comments can be summarized by: FRIGHTENED!

I am frightened to see attendants to a congress devoted to safety 
issues debating on topics (the 10**-9 figure and the like) when 
ignoring, or wanting to ignore, their real origin and their meaning: 
no significant contribution to the mortality rate in industrialized 
countries (see the statistics from OMS, the world wealth 
organization).

I am frightened to see that they are confusing evaluation of a 
product and evaluation of a process: as a direct consequence of the 
former, such reliability goals cannot, by essence, be statistically 
assessed for a given product.

I am frightened to see specialists of safety who do not seem aware of one of
the major criticisms of the Inquiry Commission after the Challenger accident,
i.e. that NASA had neglected quantitative evaluations.

Jean-Claude Laprie, LAAS-CNRS, Toulouse, France. 

</PRE>
<HR><H3><A NAME="subj1.2">
COMPASS '88 re-revisited
</A>
</H3>
<address>
&lt;<A HREF="mailto:leveson@electron.LCS.MIT.EDU">
leveson@electron.LCS.MIT.EDU
</A>&gt;
</address>
<i>
Thu, 08 Sep 88 16:01:40 -0400
</i><PRE>

I shall let Bev have the last word in this argument, especially since I
cannot figure out what we are arguing about.  As far as I can tell, we
are in violent agreement.  But he does issue a challenge to which I feel 
I should respond, i.e.,  

&gt;Maybe Nancy could tell us how she would reduce catastrophic failure rates to
&gt;acceptable levels and demonstrate the achievement of such levels?  

I do not believe that we should be talking about catastrophic failures at
all.  Catastrophic failures or accidents usually involve aspects of the
environment that are not under the control of the designer of the system.
Computers do not usually have catastrophic failures (unless one considers 
the problems of electrical shock or fire, which are usually minimal).  I prefer
the word used by Safety Engineers, i.e., hazards (states of the system being 
designed that could lead to accidents or catastrophic failures given certain 
environmental conditions).  As a component of a larger, potentially hazardous
system, computer software can certainly contribute to the system hazards
and thus has some hazardous (but not necessarily catastrophic) failure modes.
Considering only catastrophic failures limits the problem too much.

So how can software-related hazards be eliminated or reduced? The practice 
of System Safety Engineering provides some direction.  Details will be in 
my book (coming out next year from Addison-Wesley) and my survey article also 
describes this (in less detail) but briefly:  The first step is to identify 
the hazards of the system being designed.  System safety engineers call this a 
Preliminary Hazard Analysis.  This part of the process often involves
knowledge of previous systems and accidents and requires more creativity
for one-of-a-kind or first-time systems.  However, even these can be
analyzed using information about general types of hazards such as
electrical shock, chemical effects, or radioactivity exposure.  Analysis
techniques, e.g., Failure Modes and Effects Analysis (although this is
usually used more often for reliability analysis than for safety analysis)
and Fault Tree Analysis, are used to determine plausible events that
could create hazards.   Design procedures are then used to try
to eliminate or minimize these hazards by either preventing the 
precipitating events from occurring (i.e., designing them out), minimizing
the probability of their occurrence, or minimizing their chance of leading
to the hazard.  Bev should note, here, that probability is involved and
thus measurement or estimation.  But the key is that measurement alone
leads us to a fatalistic yes/no choice whereas measurement combined with
design allows us some further options in attempting to find designs that
have acceptable risk.  

My books and reference materials are currently somewhere over the state
of Kansas, so system safety engineers may need to correct some of the
following.  But the general goal of system safety design is to eliminate
single events that can lead to hazards and to minimize the probability
of multiple events or sequences of events leading to a hazard.  Thus the 
desire of the engineer with whom I spoke to get a number for the
event of a particular type of software behavior.  Since I did not know
of any way that he could obtain this number with the amount of certainly
he and I felt were necessary when a nuclear plant meltdown was involved, 
I thought it best for him to use 1.0 for this probability and design 
around this event (i.e., design the system so that the event would not
cause a hazard).

Engineers have various ways of eliminating hazardous events (what I referred
to sloppily in my previous message as "catastrophic failure modes) from 
systems or minimizing their probability of occurrence.  For example, the 
hazard of electrical shock can be eliminated by designing a purely mechanical 
system.  This is a rather extreme solution, however, and often unacceptable.  
Another less extreme solution is to use interlocks to prevent certain events 
or to ensure proper sequencing of events.  For example, a door over a high 
voltage area is often used to protect against accidents.  The door can be 
designed so that when it is open (and the high voltage equipment exposed), 
the circuit is broken.  

Note that the use of interlocks are often simply a matter of designing
the system so that multiple independent failures are required for hazards 
to arise:  The interlocks themselves may fail.  Assuming that common point 
failure modes (which engineers have techniques for identifying) are eliminated 
or minimized, then risk will be reduced.  Probabilistic Risk Assessment (PRA) 
can be used to determine if the risk is acceptable, but even for 
non-computerized systems PRA is controversial and criticized as inexact.  The 
most accepted use of PRA is for comparison of alternative designs.  PRA has 
been primarily used in the assessment of the safety of nuclear power plants,  
and there is at least one interesting critique of this use that has been 
published by the Union of Concerned Scientists.  

Several accidents I have heard about have occurred when computer subsystems
replaced electro/mechanical subsystems without replacing the interlocks that 
maintained adequate levels of risk.   The same mechanical interlocks or back-up
systems can be included to protect against computer errors (probably the safest
since we can assess the risk involved fairly accurately using historical 
information) and/or various kinds of interlocks can be included in the 
software.  In this case, software reliability assessment is involved since 
the reliability of the software interlocks will be crucial.  Since these 
software interlocks are often quite simple and limited in required 
functionality, I believe (and I realize that others might not agree with me), 
high reliability MAY be achievable by using sophisticated software engineering 
techniques including, perhaps, formal methods.  I might be willing to accept 
subjective assessments of risk here if the software is simple enough whereas 
Bev might not.  If subjective types of assessment (including the use of formal 
methods) is not acceptable, then we may be forced to rely on mechanical 
back-ups, probably in addition to the software interlocks (again, the goal is
to require as many independent failures as possible for a hazard to occur).  
[Note that some hazards are unavoidable, and the design goal then becomes
minimizing the amount of time in the hazardous state.]  Probably neither Bev 
nor I would agree to the use of another computer as the backup, even if the 
code is written by a separate group of people because of the problem of 
eliminating common failure modes, i.e., non-independent failures 
(e.g., the same software requirements specification).  The point is that this 
does not mean that the reliability of the entire software system (which may 
be quite large and complex) needs to be ultra-high, only the smaller 
safety-critical parts.  If the software is designed, as is common with 
software engineers who do not know enough about safety, so that it is 
ALL potentially safety-critical, then the problem becomes quite overwhelming, 
and Bev and I (and others) find ourselves with planes or other devices 
that we do not feel safe using.

Hopefully, I have not made too many mistakes in this brief summary of System
Safety Engineering.  If I have, I am sure that the other Risks readers will
correct me :-).
                                        Nancy

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Calling number delivery
</A>
</H3>
<address>
John (J.) McHarry 
&lt;<A HREF="mailto:MCHARRY@BNR.CA">
MCHARRY@BNR.CA
</A>&gt;
</address>
<i>
8 Sep 88 13:41:00 EDT
</i><PRE>

     The telephone feature of delivering the calling number to the terminating
line is part of a group of features called
'CLASS', although there are other ways it could be done in certain
special cases.  There are a number of Bellcore publications that
describe it in some detail.  Among these are TR-TSY-000031 on the
basic feature,  (TA) 000030 on the signalling between office and
customer terminal, 000391 on the feature to block delivery of the
calling number, 000218 on selective call reject, and (TA) 000220,
also related to selective call reject.  TAs are an early version
of TRs.  If you don't find one in a reference,look for the other.
There are several other TRs that relate to these features, but this
list should sate most of us.
     Calling number delivery, selective call reject, and calling number
delivery blocking are all involved with the 'Signalling System 7' which is just
beginning to be deployed amongst local exchanges, although some of the long
distance carriers are much farther along.  Among other advantages, SS7 enables
the transfer of much more information between network nodes than was previously
generally available.  This should allow the introduction of many new network
services in the near future.  On the other hand, CLASS and calling number
delivery in particular will not likely become common until large areas are cut
over to SS7, since otherwise they would not work much of the time.  (Only
within the local switching office, or among those that had already implemented
SS7)
     It looks to me like a subscriber to calling number delivery gets telemetry
intended to allow display of the number calling concurrently with ringing.  I
suppose proper customer premise equipment could pick this off and feed it into
a computer or use it to determine what to do with the call, eg. route to an
answering machine only if not long distance.  If the number isn't available, as
would be the case if the originating and terminating offices were not linked by
SS7, the telemetry sends ten 0s.  If the number is available but the originator
is blocking delivery, it sends ten 1s.
     Calling number delivery blocking is itself a CLASS feature that can be set
on by a service order or, depending upon the tariffed offering, turned on or
off on a per call basis.  How it is offered, if at all, is up to the local
telco and PUC.  The TR makes it look to me like it is not available to party
line subscribers.  I think there is a technical reason for this.
     Selective call reject allows the subscriber to set up a list of up to N
directory numbers (N might be on the order of 6 to 24) that would be sent to
'treatment' instead of ringing the subscriber's phone.  A caller using blocking
could be put on this list after one call by using a control that says, in
effect, add the last caller to my list, but that number could not be read from
the list by the subscriber.  It doesn't look to me like the blocking code
itself can be put on the list; maybe somebody else knows a way or has tried it.
Call reject can be turned on or off also, and can be maintained from either a
DTMF or dial phone.
     There might be something here for everybody.  If I can block delivery of
my number and Mr. Townson can send me to treatment we would be almost as well
off as with Internet addressing from Bitnet to Portal.
     The foregoing opinions and interpretations are mine, not my employer's.
My interpretations of the referenced documents are based on a cursory reading.
They probably contain some errors.

     John McHarry                    McHarry%BNR.CA.Bitnet@wiscvm.wisc.edu

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
     More on Automatic Call Tracing and 911 Emergency Numbers
</A>
</H3>
<address>
        Robin j. Herbison 
&lt;<A HREF="mailto:LADY%APLVM.BITNET@CUNYVM.CUNY.EDU">
LADY%APLVM.BITNET@CUNYVM.CUNY.EDU
</A>&gt;
</address>
<i>
Thu, 08 Sep 88 16:47:11 EDT
</i><PRE>

  A co-worker of mine called the Police last year to report a burglar alarm in
his neighborhood which was going off.  (He lives in Baltimore County,
Maryland.)  The dispatcher received the phone number, his name and an address
automatically.

The 911 dispatcher read back the address that was displayed.  It was where they
had lived two(2!) years previously.  When they moved, they kept the old phone
number and gave the phone company his the address.  Unfortunately, the change
of address was not passed on to 911.

Although it would be nice to have 911 come if you were in trouble and
and could only lift the phone, I would like them to arrive at the
Current address.  (I know the people who live at my old address do not
know my current address, although I assume they have a current phone
phone book.  Since I am listed, They could direct the police to my home.)

Quite a waste of time, esp. in an emergency.

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
ANI on 911 calls
</A>
</H3>
<address>
&lt;<A HREF="mailto:forags@violet.Berkeley.EDU">
forags@violet.Berkeley.EDU
</A>&gt;
</address>
<i>
Thu, 8 Sep 88 08:38:42 PDT
</i><PRE>

The Alameda County phone book has a privacy notice right below the 911 number
which warns callers about ANI and advises them to use the regular 7-digit
number if they don't want their number displayed on the dispatcher's console.
-Al Stangenberger

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
Another ANI scam (Re: <A HREF="/Risks/7.45.html">RISKS-7.45</A>)
</A>
</H3>
<address>
Brent
&lt;<A HREF="mailto:brent%itm@gatech.edu ">
brent%itm@gatech.edu 
</A>&gt;
</address>
<i>
8 Sep 88 13:15:59 GMT
</i><PRE>

    Here's another scam for ANI.  Set up a free phone service:
time and weather, point spread predictions, sports score line,
Dow Jones business news brief.  It's just a taped message someone
can call into.  Now set up a PC to capture the ANI information on
people who call.  Take the diskette of phone numbers to a service
that offers CNA (customer name and address) and presto!  You have
yet another profiled mailing list ready to be sold to hungry marketers
of sports equipment, business journals, etc.  Where'd they get MY
name? you ask.  You'll never know.

    ANI is going to be big business.  Just north of Atlanta is one of the new
AT&amp;T regional billing centers.  Their goal is to fully integrate ANI with their
customer inquiry department.  So when you call 1-800 whatever, the AT&amp;T rep
will answer "Good morning Mr. Jones, how's the weather in Macon?  I'll bet
you're calling about that collect call to Bogota."  They'll have your name,
address, and billing info on the screen in front of them as they answer your
call.

    Hmmm... try forwarding your calls to AT&amp;T.  What will happen?

        Brent Laminack (gatech!itm!brent)

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.46.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.48.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
<DOC>
<DOCNO>WT11-B31-89</DOCNO>
<DOCOLDNO>IA012-000131-B034-35</DOCOLDNO>
<DOCHDR>
http://catless.ncl.ac.uk:80/Risks/7.48.html 128.240.150.127 19970217022958 text/html 25014
HTTP/1.0 200 OK
MIME-Version: 1.0
Date: Mon, 17 Feb 1997 02:28:26 GMT
Server: phttpd/0.99.72
Content-Type: text/html
</DOCHDR>
<HTML><HEAD><TITLE>The Risks Digest Volume 7: Issue 48</TITLE>
<LINK REL="Prev" HREF="/Risks/7.47.html">
<LINK REL="Up" HREF="/Risks/index.7.html">
<LINK REL="Next" HREF="/Risks/7.49.html">
<LINK REL="Help" HREF="/Risks">
<LINK REV="made" HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">
</HEAD><BODY><HR>
<A HREF="/Risks/7.47.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.49.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
<H1>The Risks Digest Volume 7: Issue 48</H1>
<H2> Friday 9 September 1988  </H2>
    <H3>Forum on Risks to the Public in Computers and Related Systems</H3>
    <I><A HREF="http://www.acm.org">ACM</A>
Committee on Computers and Public Policy, Peter G. Neumann, moderator</I>
<H2>Contents</H2><DL>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj1">
COMPASS 88 
</A>
<DD>
<A HREF="#subj1.1">
Bev Littlewood
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj2">
  Safety Engineering 
</A>
<DD>
<A HREF="#subj2.1">
WHMurray
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj3">
  Technical naivete revealed by responses to VINCENNES incident 
</A>
<DD>
<A HREF="#subj3.1">
Jon Jacky
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj4">
  Vincennes: Rules of engagement violated by AI heuristic? 
</A>
<DD>
<A HREF="#subj4.1">
Clifford Johnson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj5">
  ANI Response 
</A>
<DD>
<A HREF="#subj5.1">
Patrick A. Townson
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj6">
  Proposed ANI Enhancement 
</A>
<DD>
<A HREF="#subj6.1">
Rob Boudrie
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj7">
  ANI blocking defeats purpose 
</A>
<DD>
<A HREF="#subj7.1">
Bob Philhower
</A><br>
<DT><IMG SRC="/Images/redball.gif" ALT= "o"><A HREF="#subj8">
  Credit Card Loss Woes 
</A>
<DD>
<A HREF="#subj8.1">
Clay Jackson
</A><br>
</DL>

<A NAME="subj1"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj1.1">
 COMPASS 88
</A>
</H3>
<address>
B.Littlewood 
&lt;<A HREF="mailto:sd396@CITY.AC.UK">
sd396@CITY.AC.UK
</A>&gt;
</address>
<i>
9 Sep 1988 16:05:35-WET DST
</i><PRE>

Nancy says she is going to let me have the last word in this saga.  Unfort-
unately, it is not clear whether my last comments represented this 'last
word': after all, Nancy only responded with a mere two page reply - this
probably doesn't count!

She is right that we agree on more things than we disagree.  But it is the
disagreements that are much more interesting to discuss.  So here goes once
more . . .

I ended my previous note by asking Nancy how she would "reduce catastrophic
failure rates to acceptable levels and demonstrate the achievement of such
levels".  Her reply falls far short of answering this question.  Indeed, it
is largely a recital of elementary 'good practice' (in England we say "teaching
your granny to suck eggs").

Let me spell it out again.  First of all, by the phrase "catastrophic failure
rate" (to which Nancy takes exception) I meant merely the rate at which her
"catastrophic failure modes" show themselves in operational use.  It is this
rate determines in a formal way how we can talk about safety in a quantitative
way for some systems (it is not appropriate for all systems).

Even quite unsophisticated members of society can appreciate concepts like
this when they are presented appropriately, so it represents part of a fromal-
ism which also has intuitive appeal.  A safe system is one that does certain
specified nasty things SUFFICIENTLY INFREQUENTLY.

In my earlier note I agreed with Nancy that we only want "an acceptable
level of safety".  We seem to be in dispute about what this means, how we
can get it, and how we can assure ourselves that we got it.  I think there are
three stages to this:

1.  We need to decide what are the nasty undesirable events (e.g loss of life,
or loss of airframe, in civil aviation).

2.  We need to decide how frequently we can tolerate these events (e.g. 10**-7
per hour for some airliner events)

3.  We need ways of ACHIEVING such an "acceptable level of safety", and of
DEMONSTRATING ITS ACHIEVEMENT in each particular context.

As I understand it, Nancy does not wish to define "acceptable level of safety"
in a way akin to 1 and 2.  I remain puzzled, therefore, as to what she does
mean by such a phrase.  It is difficult, therefore, to know whether her
claims to be able to achieve an "acceptable level of safety" by "other
solutions" should be given any credence.

Certainly, the methodology in her latest note (whilst being good practice and
probably necessary) falls woefully short of satisfying 3 above.  I am prepared
to accept that use of these techniques is better than not using them: they
are likely to improve safety/reliability.  Knowing that they will increase
safety, however, is far short of knowing that their use will be sufficient
to achieve a particular goal of "acceptable safety" as defined in 1 and 2.
They do not assist at all in telling us what level has been achieved.

No, it seems to me that Nancy is claiming that certain "good practice" is
a solution to our problems.  I agree that her "good practice" is a lot better
than most ACTUAL practice, but I remain sceptical about its efficacy.

In case this sounds merely academic (must stop using that pejoratively), a cynic
for civil airliners is even worse than Nancy's suggestions.  As I understand,
the A320 fly-by-wire was certificated against RTCA Do178A.  This appears to
have no definition of "acceptable level of safety" and, worse, lays down
only very minimal "good practice".  To give them their due, Airbus Industrie
seem to have been sufficiently embarassed by this state of affairs that they
got embroiled in 10**-9 and all that.  The system is certificated in Europe,
the thing is carrying passengers, yet, I believe, it cannot be asserted in
any scientifcally meaningful way that it has an "acceptable level of safety".


This brings me to Peter Neumann's elucidation of John Cullyer's original
remarks at COMPASS.  Now that they are clarified they seem ever more appalling!
Certification seems to merely mean that a certain formal test (e.g. conformance
to Do178A procedures) has been passed.  This test might even relate only to
"good practice", I suppose, and need not involve any evaluation of product
behaviour (as is the case for Do178A).  Yet Cullyer suggests that such a
certification should be used instead of evaluation of achieved safety/
reliability.

It is clear that certification of this kind will not assure us that a particular
product will be sufficiently safe.  Could John tell us how he would go about
getting such an assurance?


Finally, a slightly mischievous plug for the probabilistic/statistical approach.
I suppose one of the most extreme problems which gives rise to the difficulty
of the assurance problem lies in the correctness (or not) of the specification.
And one of the most difficult problems there concern omissions from the
specification: things that should have been thought of, but weren't.  I think
it is clear that none of the techniques suggested by John Cullyer or Nancy
Leveson can attempt to quantify the inpact of such omissions on system
reliability (although they may help to identify some of them).  Only the statist
for a certain time without revealing the effects of such omissions, we can
estimate their contribution to its unreliability.  This if the flip side of the
excellent work of Doug Miller described at the COMPASS meeting.  OF COURSE, this
reliability (Miller'spoint).  OF COURSE, it occurs too late in the life
cycle (we want the assurance at a time when we can do something about impending
problems).  Even so, I don't think any of the other approaches do anything
about evaluation here.

Bev Littlewood
Centre for Software Reliability
London EC1V 0HB


PS  I'm out next week.  Since I'm betting Nancy can't resist breaking her
uncharacteristic vow of silence, a reply might take some time.  A relief to
everyone, no doubt . . .

</PRE>
<A NAME="subj2"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj2.1">
 Safety Engineering
</A>
</H3>
<address>
&lt;<A HREF="mailto:WHMurray@DOCKMASTER.ARPA">
WHMurray@DOCKMASTER.ARPA
</A>&gt;
</address>
<i>
Fri, 9 Sep 88 08:54 EDT
</i><PRE>

Nancy Levenson's latest was a breath of fresh air.  It put some
rationality into what was becoming a silly discussion.

In it she comments:

&gt;..again, the goal is to require as many independent failures as
&gt;possible for a hazard to occur.    

Before anyone gets too carried away with that strategy, I would simply
point out that their are limits to its effectiveness.  There is a point
at which adding additional safeguards and redundancies begins to add
complexity and failure modes of their own.  The great northeastern
blackouts are examples of what happens when this strategy is carried too
far.

William Hugh Murray, Fellow, Information System Security, Ernst &amp; Whinney
2000 National City Center Cleveland, Ohio 44114                          
21 Locust Avenue, Suite 2D, New Canaan, Connecticut 06840                

</PRE>
<A NAME="subj3"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj3.1">
Technical naivete revealed by responses to VINCENNES incident
</A>
</H3>
<address>
Jon Jacky
&lt;<A HREF="mailto:jon@june.cs.washington.edu ">
jon@june.cs.washington.edu 
</A>&gt;
</address>
<i>
Fri, 09 Sep 88 09:36:54 PDT
</i><PRE>

Last night (Thurs. Sept 8, 1988) I heard another story about the VINCENNES
/Iran Air incident on the NPR radio news program, "All Things Considered."
The occasion was a presentation by the Navy to the Senate Armed Services
Committee.  No new information was presented, but several comments by the
participants and by the commentators was quite revealing of attitudes about
computing among lay people.  First there was a tape of a Navy official (whose
name I did not catch) telling the Committee (this is a close paraphrase;
I took notes immediately after hearing the story):

"We have determined that the Aegis radars and computers functioned 
correctly and that the misidentification of an Airbus airliner as an F-14
was due to human error induced by combat stress.  ... The operator interpreted
a display indicating the Airbus was at 12,000 feet and flying level as
indicating it was
at 7,500 feet and descending toward the ship ... However, we are looking
at the user interface - what we show on the displays - there may be some
room for improvement there, to make it even more user-friendly than it
is now..."

The interesting bit in this passage is calling the mininterpretation of the 
display "operator error" rather than "design error."

Even more interesting was an interview with retired Navy Commander James
Meachum (I'm unsure of the spelling of the last name).  Meachum is now the
defense reporter for THE ECONOMIST, a highly regarded British weekly news
magazine.  The interviewer asked if Meachum agreed with the "human error/
combat stress" explanation for the incident.  Meachum replied:

"There's an aircraft out there, what's its heading and speed?  That's 
a very straightforward problem and I can't believe the system could have
gotten that wrong ... It's been very thoroughly tested.  It is possible that
some other part of the system might have failed, but I doubt it..."

This statement reveals two very common misconceptions about computer systems
that I encounter all the time.  The first is, "if it seems simple to me, then
the computer must get it right."  The other is, "if the system passes a test,
then it will also perform correctly on other cases that seem similar to me."

Both of these attitudes are simply anthropomorphic superstitions, but they
are very deeply seated in lay people.  I have found 
myself trying to convince my
colleagues at work that results from a program that I wrote were probably
in error and should be investigated, while they maintain the results "must
be right" because "we tested a case just like that."

The effect of these misconceptions is to discourage thorough investigations
of possible problems.  I now doubt the frequently heard assertion that
the Vincennes actually did correctly identify the altitude and heading of
the Airbus.  This assertion is supposed to have been proved by examining
"files" or "tapes" from the Vincennes.  Does anyone know if these records
include videotapes of what was actually shown on the displays at the time of 
the incident?  If not, why do they think they know what the operator saw?
Or, do the tapes actually capture data from some point 
nearer the signal source,
"upstream" from the displays?  Have the investigators assumed that the
displays "certainly must have" shown images consistent with the data on the
tapes?  I have always thought the operator's report of the altitude and
heading sounded a bit too specific to explain away as the result of stress.

Why is it that people "just can't believe" that the computers might have 
scrambled this up, but can easily believe that the operators did scramble it 
up?

- Jonathan Jacky, University of Washington

</PRE>
<A NAME="subj4"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj4.1">
Vincennes: Rules of engagement violated by AI heuristic?
</A>
</H3>
<address>
"Clifford Johnson" 
&lt;<A HREF="mailto:GA.CJJ@Forsythe.Stanford.EDU">
GA.CJJ@Forsythe.Stanford.EDU
</A>&gt;
</address>
<i>
Fri,  9 Sep 88 09:28:27 PDT
</i><PRE>

&gt;     "Not transmitting proper IFF will be taken into account"
&gt;              AND
&gt;     "Not remaining in proper airways will be taken into account"
&gt;              IMPLIES
&gt;     "Not responding to warnings will be taken into account"
&gt; doesn't hold.

What I said does hold, if the declaration is to be given a reasonable
construction.  Note my use of the word "seems":

        So it seems a post-facto revision of the
        rules of engagement to assert that failure to respond to
        warnings is per se sufficient cause for deadly force *until
        proven otherwise.*

The U.S. declaration that Captains would take into account the fact that
commercial planes might behave *very* irregularly, a fortiori implies they
would strongly credit that such a plane behaving only *slightly* irregularly
(and ignoring or delaying response to warnings was in fact usual) would be
construed as commercial.  Thus, the rule that conclusively defined every plane
taking off from Bandas Abas as hostile until *proven* otherwise squelches this
promised caution.

True, there was no declaration that the U.S. would not shoot down a plane
thought probably or possibly commercial, but if this were not the case, then
the declaration would be purposeless, and misleading at best.

</PRE>
<A NAME="subj5"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj5.1">
ANI Response
</A>
</H3>
<address>
&lt;<A HREF="mailto:sun!portal!cup.portal.com!Patrick_A_Townson@unix.SRI.COM">
sun!portal!cup.portal.com!Patrick_A_Townson@unix.SRI.COM
</A>&gt;
</address>
<i>
Thu Sep  8 17:48:01 1988
</i><PRE>

Recent correspondents in RISKS have challenged my comment 'no good reason to
conceal telephone number'. Examples of 'good reasons' include calls to hot
lines, counseling services, police officials, and others.

Here in Illinois, the law which enabled 911 Service, and required its
implementation in all communities in the state also required that every Police
Department have a seven digit administrative telephone number to receive
non-emergency calls and calls made 'in confidence' by the caller. The Chicago
Police Department &amp; Fire Department can be reached through the main centrex
number for the City of Chicago Offices: 312 - PIG - 4000. To reach individual
police officers, etc, just dial PIG and the desired 4 digit extension. And
not that I would expect everyone to know it, but you *can* override ANI on
911 calls in most cases by knowing which *seven digit number* 911 is translated
into by your local phone office. Here in Chicago it is (or was) 312-787-0000.
Calling that number reaches 'Chicago Emergency' just as surely as 911, and
with only a blank screen for the dispatcher to look at in return. Apparently
when you dial 911, your central office translates it into a seven digit number
and sends encoded information containing *your number, and address* to the
dispatcher when it puts the call through to the ACD (automatic call
distributor) at the police station.

Since posting my original article a couple days ago, I have researched this
a bit further and find the general thinking among folks I have contacted at
Illinois Bell is that there will be specific exemptions in the tariff for
calls to crisis lines, counseling services and similar where those groups will
NOT be permitted to subscribe to ANI signaling service. And those exceptions
mentioned by the writers here do make good sense.

As for stockbrokers and others who are likely to try and make a hard sell,
what do you do now when these people routinely ask for your phone number in
the process of taking your order/giving information? Refuse to give it? Give
a false number? Whatever happened to your spines? Just say NO to the broker.
Just say no to the Operator Who Is Standing By To Take Your Call Now....

Patrick Townson

</PRE>
<A NAME="subj6"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj6.1">
 Proposed ANI Enhancement
</A>
</H3>
<address>
&lt;<A HREF="mailto:ROB.B%te-cad.prime.com@RELAY.CS.NET">
ROB.B%te-cad.prime.com@RELAY.CS.NET
</A>&gt;
</address>
<i>
09 Sep 88 00:30:10 EDT
</i><PRE>

If digital data is going to be transmitted with phone calls, why not
add a "classification code" (perhaps 3 digits) which may optionally be sent
by the caller.  Add to this legislation which requires all human telephone
solicitors to send a digital class code of "001" with their calls, and all
tape playing sales machine generated calls to carry a class code of "002".
The phone company could then offer a "class selection" service whereby the
subscriber could make his phone inaccessible to selected classes of calls.

This is not without (manual) precedent.  All companies using tape playing sales
machines within Massachusetts are required by law to check the numbers they
will call against a phone company maintained list of subscribers who have
requested not to be bothered by these machines.  This list must really work -
I was on such a list and have only recently begun to recieve that form of
harrassment, commencing right after my area code was changed from 617 to 508.

                                        Rob Boudrie

</PRE>
<A NAME="subj7"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj7.1">
ANI blocking defeats purpose
</A>
</H3>
<address>
Bob Philhower
&lt;<A HREF="mailto:philhowr@unix.cie.rpi.edu ">
philhowr@unix.cie.rpi.edu 
</A>&gt;
</address>
<i>
Fri, 9 Sep 88 10:09:55 EDT
</i><PRE>

It is naive to think that an ANI system with a blocking feature
(i.e. you prepend the number you dial with something like *21 to prevent
 your own phone number from being available to the party you call) would
have any effects on those who abuse the anonymity of the current system.
Anyone that concerned about his/her privacy would purchase a device to 
sit on the phone line and recognize the first dialed number, delay it, and
send *21 before it.  (If these don't appear immediately, I would certainly
market them myself.)

</PRE>
<A NAME="subj8"> <IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"></A>
<H3><A NAME="subj8.1">
Credit Card Loss Woes
</A>
</H3>
<address>
&lt;<A HREF="mailto:microsof!clayj@beaver.cs.washington.edu">
microsof!clayj@beaver.cs.washington.edu
</A>&gt;
</address>
<i>
Fri Sep  9 08:49:04 1988
</i><PRE>

Here's yet another potential problem when one loses a credit card:

Last Monday (9/5) I left my cash machine "Access Card" hanging in an ATM.
Fortunately, this particular machine (a Fujitsu) is smart enough to capture
cards left in it by forgetful users. 

The real problems started when I discovered the card missing about 1900
on Tuesday (9/6).  Since I had no idea where I might have left it, I decided
to be safe, and called the phone number given on the back of my wife's card
for reporting lost or stolen cards. I was greeted at that number by a recording,
which informed me that the issuing bank's offices were closed for the day,
and gave me ANOTHER 800 number to call to report a missing/stolen card.  I
called the second number, and a human answered "National Credit Center", and
took down the expected information about my lost card, including my
work and home phone numbers, address, and mother's maiden name. She did seem
a bit comfused as to the type of card I was reporting as missing, and had
no idea if my wife's Access Card (with the same account number) would be
blocked as a result of this action.

On Wednesday, during business hours (about 1300, or 18 hours AFTER I reported
the card missing), I called the issuing bank's card office, and checked to
see if they had in fact received the report.  They had NOT yet received the
report, and had no other indication that the card was missing.  I gave
them another report, and they "blocked" the card. On a hunch, I called the
branch (of the same bank) where the Cash Machine I had last used was located,
and they told me "Yes, the machine did capture your card, and we destroyed it,
since we were unable to contact you".  I have no idea why they were 
"unable to contact" me, since they have on file (I verified them) there
at the branch (it's our "home" branch) correct phone numbers for me, both
at work and at home, we have an answering machine at home, and my wife was
home all day on both Tuesday and Wednesday!  It also amazes me that the
Card Dept of the same bank had NO IDEA that the card had in fact been
recovered on Tuesday, OVER 24 hours before I called (the bank) to report
the card missing.

The last, and worst, part is that on Thursday, in the space of about 3
hours, we received 4 separate phone calls (3 at home and one at work) from
"Credit Card Protection" services.  They ALL began with some variation
on the theme "We understand you've just lost a credit card" (two of them
knew the NAME of the card we had lost, one just said "credit card" and
one said "MasterCard).  Obviously, SOME organization (either the bank or
the "National Credit Center" had, in less than 48 hours, given (or sold)
our name, phone number, and the fact that we had lost some sort of card
to not one, but FOUR separate companies.

To the bank's credit, when I called their "Corporate Affairs Officer", he
was almost as unhappy as I was, and has promised me a full investigation
and return phone call. He assured me that the selling of that information
was "against corporate policy, and possibly state or federal laws".  I'll
post a followup to this forum with the results of his findings.

Clay Jackson, Microsoft, Redmond, WA    {...microsoft!clayj}

</PRE>

<IMG SRC="/Images/Lines/hrfadeblue.gif" ALT="---------------------------------------------"><P>
<A HREF="/Risks/7.47.html"><IMG SRC="/Images/Buttons/granite_left.gif" ALT="Previous Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/index.7.html"><IMG SRC="/Images/Buttons/granite_up.gif" ALT="Index" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks/7.49.html"><IMG SRC="/Images/Buttons/granite_right.gif" ALT="Next Issue" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks"><IMG SRC="/Images/Buttons/granite_i.gif" ALT="Info" WIDTH="30" HEIGHT="30"></A>
<A HREF="/Risks.data/search.html"><IMG SRC="/Images/Buttons/granite_qm.gif" ALT="Searching" WIDTH="30" HEIGHT="30"></A>
<A HREF="mailto:risks@csl.sri.com"><IMG SRC="/Images/Buttons/granite_submit.gif" ALT="Submit Article" WIDTH="30" HEIGHT="30"></A>
<HR>
Report problems with the web pages to <A HREF="mailto:Lindsay.Marshall@newcastle.ac.uk">Lindsay.Marshall@newcastle.ac.uk</A>.
</BODY></HTML>
</DOC>
